INFO 06-01 00:47:16 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:47:17 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-8/adapters_256_slots_128_rate_3.2-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-8/adapters_256_slots_128_rate_3.2-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 66, 34560, 34560, 66, 34560, 1080, 34560, 66, 1080, 66, 34560, 1080, 1080, 1080, 1080, 34560, 66, 66, 66, 1080, 34560, 66, 34560, 34560, 1080, 1080, 1080, 66, 34560, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 34560, 1080, 66, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 66, 34560, 34560, 1080, 66, 66, 34560, 1080, 66, 1080, 1080, 34560, 1080, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 34560, 34560, 66, 34560, 66, 1080, 34560, 34560, 34560, 1080, 66, 34560, 1080, 66, 66, 66, 66, 66, 34560, 1080, 66, 34560, 66, 34560, 66, 66, 1080, 1080, 34560, 1080, 34560, 66, 1080, 66, 34560, 34560, 66, 34560, 1080, 66, 34560, 66, 66, 34560, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 66, 1080, 34560, 34560, 66, 34560, 1080, 66, 1080, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 1080, 34560, 34560, 1080, 66, 34560, 66, 1080, 1080, 66, 1080, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 34560, 66, 34560, 66, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 1080, 1080, 66, 1080, 34560, 1080, 1080, 34560, 66, 34560, 34560, 1080, 66, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 66, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 34560, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 66, 66, 66, 66]
Prompts retrieved: 3069570 . Total input tokens: 684327705 . Total output tokens: 614027875
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.682746922131628,
    "estimated_duration": 3600.008815009067,
    "input_throughput": 4980.2872496452055,
    "output_throughput": 4366.508752551599,
    "total_throughput": 9346.796002196805,
    "itl": 195.83901672886353,
    "ttft": 2158262.2546428163,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1413,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.324469182177095,
    "arrivals": 1021838,
    "finished_requests": 72396,
    "scheduler_time": 99.80533518118482
}
#Debug simulation 
Total elapsed time: 5.6828850489109755. Arrivals time: 0.41111998492851853 Scheduler time: 5.159032855182886 Scheduler overhead time: 0.030395237263292074 Adapter cache time: 0.03603136818856001 Engine time: 0.03224918060004711 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-16/adapters_256_slots_128_rate_3.2-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-16/adapters_256_slots_128_rate_3.2-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 66, 34560, 34560, 66, 34560, 1080, 34560, 66, 1080, 66, 34560, 1080, 1080, 1080, 1080, 34560, 66, 66, 66, 1080, 34560, 66, 34560, 34560, 1080, 1080, 1080, 66, 34560, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 34560, 1080, 66, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 66, 34560, 34560, 1080, 66, 66, 34560, 1080, 66, 1080, 1080, 34560, 1080, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 34560, 34560, 66, 34560, 66, 1080, 34560, 34560, 34560, 1080, 66, 34560, 1080, 66, 66, 66, 66, 66, 34560, 1080, 66, 34560, 66, 34560, 66, 66, 1080, 1080, 34560, 1080, 34560, 66, 1080, 66, 34560, 34560, 66, 34560, 1080, 66, 34560, 66, 66, 34560, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 66, 1080, 34560, 34560, 66, 34560, 1080, 66, 1080, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 1080, 34560, 34560, 1080, 66, 34560, 66, 1080, 1080, 66, 1080, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 34560, 66, 34560, 66, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 1080, 1080, 66, 1080, 34560, 1080, 1080, 34560, 66, 34560, 34560, 1080, 66, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 66, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 34560, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 66, 66, 66, 66]
Prompts retrieved: 3069570 . Total input tokens: 684327705 . Total output tokens: 614027875
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.408636653795838,
    "estimated_duration": 3600.079263110229,
    "input_throughput": 4979.900354891456,
    "output_throughput": 4366.21553338247,
    "total_throughput": 9346.115888273926,
    "itl": 195.8531148994452,
    "ttft": 2158324.7396975225,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1413,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.616375381762575,
    "arrivals": 1021838,
    "finished_requests": 72393,
    "scheduler_time": 99.7996490597698
}
#Debug simulation 
Total elapsed time: 5.408772626891732. Arrivals time: 0.304129168856889 Scheduler time: 4.997593398205936 Scheduler overhead time: 0.0294554284773767 Adapter cache time: 0.03372089006006718 Engine time: 0.03033549804240465 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-32/adapters_256_slots_128_rate_3.2-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-32/adapters_256_slots_128_rate_3.2-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 66, 34560, 34560, 66, 34560, 1080, 34560, 66, 1080, 66, 34560, 1080, 1080, 1080, 1080, 34560, 66, 66, 66, 1080, 34560, 66, 34560, 34560, 1080, 1080, 1080, 66, 34560, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 34560, 1080, 66, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 66, 34560, 34560, 1080, 66, 66, 34560, 1080, 66, 1080, 1080, 34560, 1080, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 34560, 34560, 66, 34560, 66, 1080, 34560, 34560, 34560, 1080, 66, 34560, 1080, 66, 66, 66, 66, 66, 34560, 1080, 66, 34560, 66, 34560, 66, 66, 1080, 1080, 34560, 1080, 34560, 66, 1080, 66, 34560, 34560, 66, 34560, 1080, 66, 34560, 66, 66, 34560, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 66, 1080, 34560, 34560, 66, 34560, 1080, 66, 1080, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 1080, 34560, 34560, 1080, 66, 34560, 66, 1080, 1080, 66, 1080, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 34560, 66, 34560, 66, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 1080, 1080, 66, 1080, 34560, 1080, 1080, 34560, 66, 34560, 34560, 1080, 66, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 66, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 34560, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 66, 66, 66, 66]
Prompts retrieved: 3069570 . Total input tokens: 684327705 . Total output tokens: 614027875
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.382858087308705,
    "estimated_duration": 3600.0640794766664,
    "input_throughput": 4877.653456255323,
    "output_throughput": 4278.206904094587,
    "total_throughput": 9155.86036034991,
    "itl": 163.7186561180679,
    "ttft": 2171942.7064464204,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1390,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.5475038446485465,
    "arrivals": 1021838,
    "finished_requests": 70875,
    "scheduler_time": 105.46214887079482
}
#Debug simulation 
Total elapsed time: 5.382980617228895. Arrivals time: 0.31802451238036156 Scheduler time: 4.940206867177039 Scheduler overhead time: 0.03473143978044391 Adapter cache time: 0.03801620099693537 Engine time: 0.03592204209417105 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-16/adapters_256_slots_128_rate_3.2-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-16/adapters_256_slots_128_rate_3.2-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 66, 34560, 34560, 66, 34560, 1080, 34560, 66, 1080, 66, 34560, 1080, 1080, 1080, 1080, 34560, 66, 66, 66, 1080, 34560, 66, 34560, 34560, 1080, 1080, 1080, 66, 34560, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 34560, 1080, 66, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 66, 34560, 34560, 1080, 66, 66, 34560, 1080, 66, 1080, 1080, 34560, 1080, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 34560, 34560, 66, 34560, 66, 1080, 34560, 34560, 34560, 1080, 66, 34560, 1080, 66, 66, 66, 66, 66, 34560, 1080, 66, 34560, 66, 34560, 66, 66, 1080, 1080, 34560, 1080, 34560, 66, 1080, 66, 34560, 34560, 66, 34560, 1080, 66, 34560, 66, 66, 34560, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 66, 1080, 34560, 34560, 66, 34560, 1080, 66, 1080, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 1080, 34560, 34560, 1080, 66, 34560, 66, 1080, 1080, 66, 1080, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 34560, 66, 34560, 66, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 1080, 1080, 66, 1080, 34560, 1080, 1080, 34560, 66, 34560, 34560, 1080, 66, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 66, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 34560, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 66, 66, 66, 66]
Prompts retrieved: 3069570 . Total input tokens: 684327705 . Total output tokens: 614027875
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.584806950297207,
    "estimated_duration": 3600.127612952205,
    "input_throughput": 4980.122908837016,
    "output_throughput": 4366.36466536518,
    "total_throughput": 9346.487574202198,
    "itl": 195.84526117971748,
    "ttft": 2158305.680173706,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1413,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.4431309667438486,
    "arrivals": 1021838,
    "finished_requests": 72396,
    "scheduler_time": 99.80547133962047
}
#Debug simulation 
Total elapsed time: 5.584928170312196. Arrivals time: 0.3289362844079733 Scheduler time: 5.143277333583683 Scheduler overhead time: 0.030468969605863094 Adapter cache time: 0.036530422512441874 Engine time: 0.031707220710814 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-32/adapters_256_slots_128_rate_3.2-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-32/adapters_256_slots_128_rate_3.2-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 66, 34560, 34560, 66, 34560, 1080, 34560, 66, 1080, 66, 34560, 1080, 1080, 1080, 1080, 34560, 66, 66, 66, 1080, 34560, 66, 34560, 34560, 1080, 1080, 1080, 66, 34560, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 34560, 1080, 66, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 66, 34560, 34560, 1080, 66, 66, 34560, 1080, 66, 1080, 1080, 34560, 1080, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 34560, 34560, 66, 34560, 66, 1080, 34560, 34560, 34560, 1080, 66, 34560, 1080, 66, 66, 66, 66, 66, 34560, 1080, 66, 34560, 66, 34560, 66, 66, 1080, 1080, 34560, 1080, 34560, 66, 1080, 66, 34560, 34560, 66, 34560, 1080, 66, 34560, 66, 66, 34560, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 66, 1080, 34560, 34560, 66, 34560, 1080, 66, 1080, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 1080, 34560, 34560, 1080, 66, 34560, 66, 1080, 1080, 66, 1080, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 34560, 66, 34560, 66, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 1080, 1080, 66, 1080, 34560, 1080, 1080, 34560, 66, 34560, 34560, 1080, 66, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 66, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 34560, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 66, 66, 66, 66]
Prompts retrieved: 3069570 . Total input tokens: 684327705 . Total output tokens: 614027875
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 5.481163220014423,
    "estimated_duration": 3600.115589795116,
    "input_throughput": 4877.583666973132,
    "output_throughput": 4278.145691671118,
    "total_throughput": 9155.729358644248,
    "itl": 163.72090868920384,
    "ttft": 2171962.881969137,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1390,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.59893714329225,
    "arrivals": 1021838,
    "finished_requests": 70875,
    "scheduler_time": 105.46222589064864
}
#Debug simulation 
Total elapsed time: 5.48129933513701. Arrivals time: 0.31708860443904996 Scheduler time: 5.03828197484836 Scheduler overhead time: 0.03533204318955541 Adapter cache time: 0.03791692480444908 Engine time: 0.036269677337259054 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-16/adapters_256_slots_128_rate_3.2-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-16/adapters_256_slots_128_rate_3.2-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 66, 34560, 34560, 66, 34560, 1080, 34560, 66, 1080, 66, 34560, 1080, 1080, 1080, 1080, 34560, 66, 66, 66, 1080, 34560, 66, 34560, 34560, 1080, 1080, 1080, 66, 34560, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 34560, 1080, 66, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 66, 34560, 34560, 1080, 66, 66, 34560, 1080, 66, 1080, 1080, 34560, 1080, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 34560, 34560, 66, 34560, 66, 1080, 34560, 34560, 34560, 1080, 66, 34560, 1080, 66, 66, 66, 66, 66, 34560, 1080, 66, 34560, 66, 34560, 66, 66, 1080, 1080, 34560, 1080, 34560, 66, 1080, 66, 34560, 34560, 66, 34560, 1080, 66, 34560, 66, 66, 34560, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 66, 1080, 34560, 34560, 66, 34560, 1080, 66, 1080, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 1080, 34560, 34560, 1080, 66, 34560, 66, 1080, 1080, 66, 1080, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 34560, 66, 34560, 66, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 1080, 1080, 66, 1080, 34560, 1080, 1080, 34560, 66, 34560, 34560, 1080, 66, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 66, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 34560, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 66, 66, 66, 66]
Prompts retrieved: 3069570 . Total input tokens: 684327705 . Total output tokens: 614027875
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.816112678032368,
    "estimated_duration": 3600.1315630640383,
    "input_throughput": 4980.531596111854,
    "output_throughput": 4366.489314246313,
    "total_throughput": 9347.020910358167,
    "itl": 195.8321283840864,
    "ttft": 2158270.61896455,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1413,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.224941066696661,
    "arrivals": 1021838,
    "finished_requests": 72400,
    "scheduler_time": 99.81128936272927
}
#Debug simulation 
Total elapsed time: 5.816243172157556. Arrivals time: 0.4109440394677222 Scheduler time: 5.29133007209748 Scheduler overhead time: 0.031080790795385838 Adapter cache time: 0.036409880965948105 Engine time: 0.032196139451116323 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-32/adapters_256_slots_128_rate_3.2-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-32/adapters_256_slots_128_rate_3.2-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 66, 34560, 34560, 66, 34560, 1080, 34560, 66, 1080, 66, 34560, 1080, 1080, 1080, 1080, 34560, 66, 66, 66, 1080, 34560, 66, 34560, 34560, 1080, 1080, 1080, 66, 34560, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 34560, 1080, 66, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 66, 34560, 34560, 1080, 66, 66, 34560, 1080, 66, 1080, 1080, 34560, 1080, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 34560, 34560, 66, 34560, 66, 1080, 34560, 34560, 34560, 1080, 66, 34560, 1080, 66, 66, 66, 66, 66, 34560, 1080, 66, 34560, 66, 34560, 66, 66, 1080, 1080, 34560, 1080, 34560, 66, 1080, 66, 34560, 34560, 66, 34560, 1080, 66, 34560, 66, 66, 34560, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 66, 1080, 34560, 34560, 66, 34560, 1080, 66, 1080, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 1080, 34560, 34560, 1080, 66, 34560, 66, 1080, 1080, 66, 1080, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 34560, 66, 34560, 66, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 1080, 1080, 66, 1080, 34560, 1080, 1080, 34560, 66, 34560, 34560, 1080, 66, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 66, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 34560, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 66, 66, 66, 66]
Prompts retrieved: 3069570 . Total input tokens: 684327705 . Total output tokens: 614027875
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.56377754593268,
    "estimated_duration": 3600.182448501574,
    "input_throughput": 4877.49308574863,
    "output_throughput": 4278.066242562336,
    "total_throughput": 9155.559328310967,
    "itl": 163.7239049211925,
    "ttft": 2171987.999844636,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1390,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.665712403878568,
    "arrivals": 1021838,
    "finished_requests": 70875,
    "scheduler_time": 105.46230933658457
}
#Debug simulation 
Total elapsed time: 5.563901448156685. Arrivals time: 0.3095498331822455 Scheduler time: 5.126769789028913 Scheduler overhead time: 0.03577924985438585 Adapter cache time: 0.038258456625044346 Engine time: 0.036948675755411386 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-8/adapters_256_slots_128_rate_3.2-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-8/adapters_256_slots_128_rate_3.2-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 33, 34560, 34560, 33, 34560, 1080, 34560, 33, 1080, 33, 34560, 1080, 1080, 1080, 1080, 34560, 33, 33, 33, 1080, 34560, 33, 34560, 34560, 1080, 1080, 1080, 33, 34560, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 34560, 1080, 33, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 33, 34560, 34560, 1080, 33, 33, 34560, 1080, 33, 1080, 1080, 34560, 1080, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 34560, 34560, 33, 34560, 33, 1080, 34560, 34560, 34560, 1080, 33, 34560, 1080, 33, 33, 33, 33, 33, 34560, 1080, 33, 34560, 33, 34560, 33, 33, 1080, 1080, 34560, 1080, 34560, 33, 1080, 33, 34560, 34560, 33, 34560, 1080, 33, 34560, 33, 33, 34560, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 33, 1080, 34560, 34560, 33, 34560, 1080, 33, 1080, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 1080, 34560, 34560, 1080, 33, 34560, 33, 1080, 1080, 33, 1080, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 34560, 33, 34560, 33, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 1080, 1080, 33, 1080, 34560, 1080, 1080, 34560, 33, 34560, 34560, 1080, 33, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 33, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 34560, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 33, 33, 33, 33]
Prompts retrieved: 3066765 . Total input tokens: 683706646 . Total output tokens: 613459381
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.771225332748145,
    "estimated_duration": 3600.0501626268433,
    "input_throughput": 4951.060456056073,
    "output_throughput": 4380.73118083791,
    "total_throughput": 9331.791636893982,
    "itl": 196.01159611739612,
    "ttft": 2159253.4941429254,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1402,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.290803816993834,
    "arrivals": 1020948,
    "finished_requests": 72479,
    "scheduler_time": 100.04720234683174
}
#Debug simulation 
Total elapsed time: 5.771344979759306. Arrivals time: 0.34932764060795307 Scheduler time: 5.306219095829874 Scheduler overhead time: 0.031193239614367485 Adapter cache time: 0.038043173495680094 Engine time: 0.03218395169824362 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-16/adapters_256_slots_128_rate_3.2-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-16/adapters_256_slots_128_rate_3.2-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 33, 34560, 34560, 33, 34560, 1080, 34560, 33, 1080, 33, 34560, 1080, 1080, 1080, 1080, 34560, 33, 33, 33, 1080, 34560, 33, 34560, 34560, 1080, 1080, 1080, 33, 34560, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 34560, 1080, 33, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 33, 34560, 34560, 1080, 33, 33, 34560, 1080, 33, 1080, 1080, 34560, 1080, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 34560, 34560, 33, 34560, 33, 1080, 34560, 34560, 34560, 1080, 33, 34560, 1080, 33, 33, 33, 33, 33, 34560, 1080, 33, 34560, 33, 34560, 33, 33, 1080, 1080, 34560, 1080, 34560, 33, 1080, 33, 34560, 34560, 33, 34560, 1080, 33, 34560, 33, 33, 34560, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 33, 1080, 34560, 34560, 33, 34560, 1080, 33, 1080, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 1080, 34560, 34560, 1080, 33, 34560, 33, 1080, 1080, 33, 1080, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 34560, 33, 34560, 33, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 1080, 1080, 33, 1080, 34560, 1080, 1080, 34560, 33, 34560, 34560, 1080, 33, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 33, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 34560, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 33, 33, 33, 33]
Prompts retrieved: 3066765 . Total input tokens: 683706646 . Total output tokens: 613459381
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.33482786314562,
    "estimated_duration": 3600.11014784363,
    "input_throughput": 4950.757967968193,
    "output_throughput": 4380.472083457202,
    "total_throughput": 9331.230051425395,
    "itl": 196.0266032248268,
    "ttft": 2159314.0745384265,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1402,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.569592587691682,
    "arrivals": 1020948,
    "finished_requests": 72476,
    "scheduler_time": 100.04152169451203
}
#Debug simulation 
Total elapsed time: 5.334967785980552. Arrivals time: 0.2648374489508569 Scheduler time: 4.965155662968755 Scheduler overhead time: 0.029080922715365887 Adapter cache time: 0.03215383132919669 Engine time: 0.030212383717298508 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-32/adapters_256_slots_128_rate_3.2-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-32/adapters_256_slots_128_rate_3.2-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 33, 34560, 34560, 33, 34560, 1080, 34560, 33, 1080, 33, 34560, 1080, 1080, 1080, 1080, 34560, 33, 33, 33, 1080, 34560, 33, 34560, 34560, 1080, 1080, 1080, 33, 34560, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 34560, 1080, 33, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 33, 34560, 34560, 1080, 33, 33, 34560, 1080, 33, 1080, 1080, 34560, 1080, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 34560, 34560, 33, 34560, 33, 1080, 34560, 34560, 34560, 1080, 33, 34560, 1080, 33, 33, 33, 33, 33, 34560, 1080, 33, 34560, 33, 34560, 33, 33, 1080, 1080, 34560, 1080, 34560, 33, 1080, 33, 34560, 34560, 33, 34560, 1080, 33, 34560, 33, 33, 34560, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 33, 1080, 34560, 34560, 33, 34560, 1080, 33, 1080, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 1080, 34560, 34560, 1080, 33, 34560, 33, 1080, 1080, 33, 1080, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 34560, 33, 34560, 33, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 1080, 1080, 33, 1080, 34560, 1080, 1080, 34560, 33, 34560, 34560, 1080, 33, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 33, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 34560, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 33, 33, 33, 33]
Prompts retrieved: 3066765 . Total input tokens: 683706646 . Total output tokens: 613459381
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.621189631987363,
    "estimated_duration": 3600.1470816711985,
    "input_throughput": 4844.680954507997,
    "output_throughput": 4294.287608056111,
    "total_throughput": 9138.968562564107,
    "itl": 164.3083049070857,
    "ttft": 2172787.724274342,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1374,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.486329385768565,
    "arrivals": 1020948,
    "finished_requests": 70931,
    "scheduler_time": 105.58974682218637
}
#Debug simulation 
Total elapsed time: 5.6213109330274165. Arrivals time: 0.4209175165742636 Scheduler time: 5.073332011234015 Scheduler overhead time: 0.03535615326836705 Adapter cache time: 0.03891905024647713 Engine time: 0.036423284094780684 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-16/adapters_256_slots_128_rate_3.2-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-16/adapters_256_slots_128_rate_3.2-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 33, 34560, 34560, 33, 34560, 1080, 34560, 33, 1080, 33, 34560, 1080, 1080, 1080, 1080, 34560, 33, 33, 33, 1080, 34560, 33, 34560, 34560, 1080, 1080, 1080, 33, 34560, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 34560, 1080, 33, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 33, 34560, 34560, 1080, 33, 33, 34560, 1080, 33, 1080, 1080, 34560, 1080, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 34560, 34560, 33, 34560, 33, 1080, 34560, 34560, 34560, 1080, 33, 34560, 1080, 33, 33, 33, 33, 33, 34560, 1080, 33, 34560, 33, 34560, 33, 33, 1080, 1080, 34560, 1080, 34560, 33, 1080, 33, 34560, 34560, 33, 34560, 1080, 33, 34560, 33, 33, 34560, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 33, 1080, 34560, 34560, 33, 34560, 1080, 33, 1080, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 1080, 34560, 34560, 1080, 33, 34560, 33, 1080, 1080, 33, 1080, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 34560, 33, 34560, 33, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 1080, 1080, 33, 1080, 34560, 1080, 1080, 34560, 33, 34560, 34560, 1080, 33, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 33, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 34560, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 33, 33, 33, 33]
Prompts retrieved: 3066765 . Total input tokens: 683706646 . Total output tokens: 613459381
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.941611583344638,
    "estimated_duration": 3600.163993534057,
    "input_throughput": 4950.903912158518,
    "output_throughput": 4380.5926697574505,
    "total_throughput": 9331.49658191597,
    "itl": 196.0175321896267,
    "ttft": 2159298.0348157235,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1402,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.404520079041762,
    "arrivals": 1020948,
    "finished_requests": 72479,
    "scheduler_time": 100.04731699186202
}
#Debug simulation 
Total elapsed time: 5.941687813960016. Arrivals time: 0.7626122888177633 Scheduler time: 5.0702351070940495 Scheduler overhead time: 0.029614970553666353 Adapter cache time: 0.03476311080157757 Engine time: 0.030799525324255228 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-32/adapters_256_slots_128_rate_3.2-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-32/adapters_256_slots_128_rate_3.2-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 33, 34560, 34560, 33, 34560, 1080, 34560, 33, 1080, 33, 34560, 1080, 1080, 1080, 1080, 34560, 33, 33, 33, 1080, 34560, 33, 34560, 34560, 1080, 1080, 1080, 33, 34560, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 34560, 1080, 33, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 33, 34560, 34560, 1080, 33, 33, 34560, 1080, 33, 1080, 1080, 34560, 1080, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 34560, 34560, 33, 34560, 33, 1080, 34560, 34560, 34560, 1080, 33, 34560, 1080, 33, 33, 33, 33, 33, 34560, 1080, 33, 34560, 33, 34560, 33, 33, 1080, 1080, 34560, 1080, 34560, 33, 1080, 33, 34560, 34560, 33, 34560, 1080, 33, 34560, 33, 33, 34560, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 33, 1080, 34560, 34560, 33, 34560, 1080, 33, 1080, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 1080, 34560, 34560, 1080, 33, 34560, 33, 1080, 1080, 33, 1080, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 34560, 33, 34560, 33, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 1080, 1080, 33, 1080, 34560, 1080, 1080, 34560, 33, 34560, 34560, 1080, 33, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 33, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 34560, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 33, 33, 33, 33]
Prompts retrieved: 3066765 . Total input tokens: 683706646 . Total output tokens: 613459381
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 5.426438742782921,
    "estimated_duration": 3600.0167384871174,
    "input_throughput": 4844.8246958234,
    "output_throughput": 4294.216144810662,
    "total_throughput": 9139.040840634061,
    "itl": 164.30997895799553,
    "ttft": 2172711.3395962473,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1374,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.536127885188871,
    "arrivals": 1020948,
    "finished_requests": 70929,
    "scheduler_time": 105.5844166474668
}
#Debug simulation 
Total elapsed time: 5.4265494998544455. Arrivals time: 0.3543088324368 Scheduler time: 4.949702639598399 Scheduler overhead time: 0.03425405081361532 Adapter cache time: 0.03642686177045107 Engine time: 0.036072374787181616 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-16/adapters_256_slots_128_rate_3.2-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-16/adapters_256_slots_128_rate_3.2-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 33, 34560, 34560, 33, 34560, 1080, 34560, 33, 1080, 33, 34560, 1080, 1080, 1080, 1080, 34560, 33, 33, 33, 1080, 34560, 33, 34560, 34560, 1080, 1080, 1080, 33, 34560, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 34560, 1080, 33, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 33, 34560, 34560, 1080, 33, 33, 34560, 1080, 33, 1080, 1080, 34560, 1080, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 34560, 34560, 33, 34560, 33, 1080, 34560, 34560, 34560, 1080, 33, 34560, 1080, 33, 33, 33, 33, 33, 34560, 1080, 33, 34560, 33, 34560, 33, 33, 1080, 1080, 34560, 1080, 34560, 33, 1080, 33, 34560, 34560, 33, 34560, 1080, 33, 34560, 33, 33, 34560, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 33, 1080, 34560, 34560, 33, 34560, 1080, 33, 1080, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 1080, 34560, 34560, 1080, 33, 34560, 33, 1080, 1080, 33, 1080, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 34560, 33, 34560, 33, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 1080, 1080, 33, 1080, 34560, 1080, 1080, 34560, 33, 34560, 34560, 1080, 33, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 33, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 34560, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 33, 33, 33, 33]
Prompts retrieved: 3066765 . Total input tokens: 683706646 . Total output tokens: 613459381
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.471748150885105,
    "estimated_duration": 3600.1711973626248,
    "input_throughput": 4950.894005556559,
    "output_throughput": 4380.5839043302285,
    "total_throughput": 9331.477909886788,
    "itl": 196.00648797177126,
    "ttft": 2159258.9058730444,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1402,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.192050513452738,
    "arrivals": 1020948,
    "finished_requests": 72479,
    "scheduler_time": 100.05314066868706
}
#Debug simulation 
Total elapsed time: 5.4718595049344. Arrivals time: 0.29810615675523877 Scheduler time: 5.065939246211201 Scheduler overhead time: 0.02971544209867716 Adapter cache time: 0.03364121727645397 Engine time: 0.03079886082559824 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-32/adapters_256_slots_128_rate_3.2-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-32/adapters_256_slots_128_rate_3.2-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 33, 34560, 34560, 33, 34560, 1080, 34560, 33, 1080, 33, 34560, 1080, 1080, 1080, 1080, 34560, 33, 33, 33, 1080, 34560, 33, 34560, 34560, 1080, 1080, 1080, 33, 34560, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 34560, 1080, 33, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 33, 34560, 34560, 1080, 33, 33, 34560, 1080, 33, 1080, 1080, 34560, 1080, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 34560, 34560, 33, 34560, 33, 1080, 34560, 34560, 34560, 1080, 33, 34560, 1080, 33, 33, 33, 33, 33, 34560, 1080, 33, 34560, 33, 34560, 33, 33, 1080, 1080, 34560, 1080, 34560, 33, 1080, 33, 34560, 34560, 33, 34560, 1080, 33, 34560, 33, 33, 34560, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 33, 1080, 34560, 34560, 33, 34560, 1080, 33, 1080, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 1080, 34560, 34560, 1080, 33, 34560, 33, 1080, 1080, 33, 1080, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 34560, 33, 34560, 33, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 1080, 1080, 33, 1080, 34560, 1080, 1080, 34560, 33, 34560, 34560, 1080, 33, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 33, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 34560, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 33, 33, 33, 33]
Prompts retrieved: 3066765 . Total input tokens: 683706646 . Total output tokens: 613459381
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.570962063036859,
    "estimated_duration": 3600.080576495018,
    "input_throughput": 4844.73878553594,
    "output_throughput": 4294.139998124954,
    "total_throughput": 9138.878783660895,
    "itl": 164.31282024821144,
    "ttft": 2172736.0535144117,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1374,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.599885054901243,
    "arrivals": 1020948,
    "finished_requests": 70929,
    "scheduler_time": 105.58449748571722
}
#Debug simulation 
Total elapsed time: 5.571116690058261. Arrivals time: 0.3166253278031945 Scheduler time: 5.127298907842487 Scheduler overhead time: 0.035385506227612495 Adapter cache time: 0.03867660881951451 Engine time: 0.03668381413444877 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-8/adapters_256_slots_128_rate_3.2-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-8/adapters_256_slots_128_rate_3.2-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 270, 34560, 34560, 270, 34560, 540, 34560, 270, 540, 270, 34560, 540, 540, 540, 540, 34560, 270, 270, 270, 540, 34560, 270, 34560, 34560, 540, 540, 540, 270, 34560, 270, 540, 540, 270, 540, 270, 270, 540, 540, 34560, 540, 270, 540, 34560, 540, 540, 34560, 540, 34560, 270, 34560, 34560, 540, 270, 270, 34560, 540, 270, 540, 540, 34560, 540, 270, 270, 34560, 34560, 34560, 34560, 34560, 34560, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 34560, 34560, 270, 34560, 270, 540, 34560, 34560, 34560, 540, 270, 34560, 540, 270, 270, 270, 270, 270, 34560, 540, 270, 34560, 270, 34560, 270, 270, 540, 540, 34560, 540, 34560, 270, 540, 270, 34560, 34560, 270, 34560, 540, 270, 34560, 270, 270, 34560, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 270, 540, 34560, 34560, 270, 34560, 540, 270, 540, 34560, 270, 270, 270, 270, 270, 270, 34560, 270, 270, 270, 34560, 270, 540, 34560, 34560, 540, 270, 34560, 270, 540, 540, 270, 540, 270, 34560, 270, 270, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 540, 34560, 540, 34560, 270, 34560, 270, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 540, 540, 270, 540, 34560, 540, 540, 34560, 270, 34560, 34560, 540, 270, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 270, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 34560, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 34560, 540, 270, 270, 270, 270]
Prompts retrieved: 3041010 . Total input tokens: 677979927 . Total output tokens: 608266809
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.77091189334169,
    "estimated_duration": 3600.018270545061,
    "input_throughput": 5115.184872995634,
    "output_throughput": 4512.01404529002,
    "total_throughput": 9627.198918285652,
    "itl": 190.04908682454888,
    "ttft": 2145891.465693378,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1280,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.917424312234025,
    "arrivals": 1012432,
    "finished_requests": 74513,
    "scheduler_time": 103.00123350919488
}
#Debug simulation 
Total elapsed time: 5.771053818054497. Arrivals time: 0.35211314307525754 Scheduler time: 5.306941298302263 Scheduler overhead time: 0.031157497316598892 Adapter cache time: 0.03423468116670847 Engine time: 0.032291095703840256 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-16/adapters_256_slots_128_rate_3.2-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-16/adapters_256_slots_128_rate_3.2-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 270, 34560, 34560, 270, 34560, 540, 34560, 270, 540, 270, 34560, 540, 540, 540, 540, 34560, 270, 270, 270, 540, 34560, 270, 34560, 34560, 540, 540, 540, 270, 34560, 270, 540, 540, 270, 540, 270, 270, 540, 540, 34560, 540, 270, 540, 34560, 540, 540, 34560, 540, 34560, 270, 34560, 34560, 540, 270, 270, 34560, 540, 270, 540, 540, 34560, 540, 270, 270, 34560, 34560, 34560, 34560, 34560, 34560, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 34560, 34560, 270, 34560, 270, 540, 34560, 34560, 34560, 540, 270, 34560, 540, 270, 270, 270, 270, 270, 34560, 540, 270, 34560, 270, 34560, 270, 270, 540, 540, 34560, 540, 34560, 270, 540, 270, 34560, 34560, 270, 34560, 540, 270, 34560, 270, 270, 34560, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 270, 540, 34560, 34560, 270, 34560, 540, 270, 540, 34560, 270, 270, 270, 270, 270, 270, 34560, 270, 270, 270, 34560, 270, 540, 34560, 34560, 540, 270, 34560, 270, 540, 540, 270, 540, 270, 34560, 270, 270, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 540, 34560, 540, 34560, 270, 34560, 270, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 540, 540, 270, 540, 34560, 540, 540, 34560, 270, 34560, 34560, 540, 270, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 270, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 34560, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 34560, 540, 270, 270, 270, 270]
Prompts retrieved: 3041010 . Total input tokens: 677979927 . Total output tokens: 608266809
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.782613604329526,
    "estimated_duration": 3600.063063779211,
    "input_throughput": 5114.578182047436,
    "output_throughput": 4511.574300853999,
    "total_throughput": 9626.152482901436,
    "itl": 190.06124606513055,
    "ttft": 2145972.6996931136,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1280,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.1753875887859495,
    "arrivals": 1012432,
    "finished_requests": 74506,
    "scheduler_time": 102.99553724926801
}
#Debug simulation 
Total elapsed time: 5.782716101035476. Arrivals time: 0.34094452299177647 Scheduler time: 5.331148167606443 Scheduler overhead time: 0.03096514707431197 Adapter cache time: 0.03326057828962803 Engine time: 0.03205422544851899 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-32/adapters_256_slots_128_rate_3.2-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-32/adapters_256_slots_128_rate_3.2-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 270, 34560, 34560, 270, 34560, 540, 34560, 270, 540, 270, 34560, 540, 540, 540, 540, 34560, 270, 270, 270, 540, 34560, 270, 34560, 34560, 540, 540, 540, 270, 34560, 270, 540, 540, 270, 540, 270, 270, 540, 540, 34560, 540, 270, 540, 34560, 540, 540, 34560, 540, 34560, 270, 34560, 34560, 540, 270, 270, 34560, 540, 270, 540, 540, 34560, 540, 270, 270, 34560, 34560, 34560, 34560, 34560, 34560, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 34560, 34560, 270, 34560, 270, 540, 34560, 34560, 34560, 540, 270, 34560, 540, 270, 270, 270, 270, 270, 34560, 540, 270, 34560, 270, 34560, 270, 270, 540, 540, 34560, 540, 34560, 270, 540, 270, 34560, 34560, 270, 34560, 540, 270, 34560, 270, 270, 34560, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 270, 540, 34560, 34560, 270, 34560, 540, 270, 540, 34560, 270, 270, 270, 270, 270, 270, 34560, 270, 270, 270, 34560, 270, 540, 34560, 34560, 540, 270, 34560, 270, 540, 540, 270, 540, 270, 34560, 270, 270, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 540, 34560, 540, 34560, 270, 34560, 270, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 540, 540, 270, 540, 34560, 540, 540, 34560, 270, 34560, 34560, 540, 270, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 270, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 34560, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 34560, 540, 270, 270, 270, 270]
Prompts retrieved: 3041010 . Total input tokens: 677979927 . Total output tokens: 608266809
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.4683359721675515,
    "estimated_duration": 3600.169200565891,
    "input_throughput": 4986.457857919069,
    "output_throughput": 4403.568031610309,
    "total_throughput": 9390.025889529377,
    "itl": 159.5104015684865,
    "ttft": 2160094.124018291,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.102237847018927,
    "arrivals": 1012432,
    "finished_requests": 72664,
    "scheduler_time": 108.46100603767718
}
#Debug simulation 
Total elapsed time: 5.468459350056946. Arrivals time: 0.2823741934262216 Scheduler time: 5.066794046200812 Scheduler overhead time: 0.03526972606778145 Adapter cache time: 0.03171217208728194 Engine time: 0.036016222555190325 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-16-16/adapters_256_slots_128_rate_3.2-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-16-16/adapters_256_slots_128_rate_3.2-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 270, 34560, 34560, 270, 34560, 540, 34560, 270, 540, 270, 34560, 540, 540, 540, 540, 34560, 270, 270, 270, 540, 34560, 270, 34560, 34560, 540, 540, 540, 270, 34560, 270, 540, 540, 270, 540, 270, 270, 540, 540, 34560, 540, 270, 540, 34560, 540, 540, 34560, 540, 34560, 270, 34560, 34560, 540, 270, 270, 34560, 540, 270, 540, 540, 34560, 540, 270, 270, 34560, 34560, 34560, 34560, 34560, 34560, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 34560, 34560, 270, 34560, 270, 540, 34560, 34560, 34560, 540, 270, 34560, 540, 270, 270, 270, 270, 270, 34560, 540, 270, 34560, 270, 34560, 270, 270, 540, 540, 34560, 540, 34560, 270, 540, 270, 34560, 34560, 270, 34560, 540, 270, 34560, 270, 270, 34560, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 270, 540, 34560, 34560, 270, 34560, 540, 270, 540, 34560, 270, 270, 270, 270, 270, 270, 34560, 270, 270, 270, 34560, 270, 540, 34560, 34560, 540, 270, 34560, 270, 540, 540, 270, 540, 270, 34560, 270, 270, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 540, 34560, 540, 34560, 270, 34560, 270, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 540, 540, 270, 540, 34560, 540, 540, 34560, 270, 34560, 34560, 540, 270, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 270, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 34560, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 34560, 540, 270, 270, 270, 270]
Prompts retrieved: 3041010 . Total input tokens: 677979927 . Total output tokens: 608266809
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.859211273025721,
    "estimated_duration": 3600.119841558743,
    "input_throughput": 5115.040557101835,
    "output_throughput": 4511.8867467942755,
    "total_throughput": 9626.927303896111,
    "itl": 190.05423267081989,
    "ttft": 2145930.8404148105,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1280,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.018895581823267,
    "arrivals": 1012432,
    "finished_requests": 74513,
    "scheduler_time": 103.00133325316517
}
#Debug simulation 
Total elapsed time: 5.859348439145833. Arrivals time: 0.3208596953190863 Scheduler time: 5.427754322066903 Scheduler overhead time: 0.03138197027146816 Adapter cache time: 0.03298660786822438 Engine time: 0.032078367192298174 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-16-32/adapters_256_slots_128_rate_3.2-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-16-32/adapters_256_slots_128_rate_3.2-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 270, 34560, 34560, 270, 34560, 540, 34560, 270, 540, 270, 34560, 540, 540, 540, 540, 34560, 270, 270, 270, 540, 34560, 270, 34560, 34560, 540, 540, 540, 270, 34560, 270, 540, 540, 270, 540, 270, 270, 540, 540, 34560, 540, 270, 540, 34560, 540, 540, 34560, 540, 34560, 270, 34560, 34560, 540, 270, 270, 34560, 540, 270, 540, 540, 34560, 540, 270, 270, 34560, 34560, 34560, 34560, 34560, 34560, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 34560, 34560, 270, 34560, 270, 540, 34560, 34560, 34560, 540, 270, 34560, 540, 270, 270, 270, 270, 270, 34560, 540, 270, 34560, 270, 34560, 270, 270, 540, 540, 34560, 540, 34560, 270, 540, 270, 34560, 34560, 270, 34560, 540, 270, 34560, 270, 270, 34560, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 270, 540, 34560, 34560, 270, 34560, 540, 270, 540, 34560, 270, 270, 270, 270, 270, 270, 34560, 270, 270, 270, 34560, 270, 540, 34560, 34560, 540, 270, 34560, 270, 540, 540, 270, 540, 270, 34560, 270, 270, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 540, 34560, 540, 34560, 270, 34560, 270, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 540, 540, 270, 540, 34560, 540, 540, 34560, 270, 34560, 34560, 540, 270, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 270, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 34560, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 34560, 540, 270, 270, 270, 270]
Prompts retrieved: 3041010 . Total input tokens: 677979927 . Total output tokens: 608266809
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 5.588352798949927,
    "estimated_duration": 3600.0430138892457,
    "input_throughput": 4986.022647715015,
    "output_throughput": 4403.287110415532,
    "total_throughput": 9389.309758130546,
    "itl": 159.51148346698832,
    "ttft": 2160129.0895477287,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.148892501778885,
    "arrivals": 1012432,
    "finished_requests": 72659,
    "scheduler_time": 108.45577569215119
}
#Debug simulation 
Total elapsed time: 5.588472391013056. Arrivals time: 0.2975480491295457 Scheduler time: 5.167553505394608 Scheduler overhead time: 0.03610097663477063 Adapter cache time: 0.033444270957261324 Engine time: 0.03714604675769806 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_16-16-16/adapters_256_slots_128_rate_3.2-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_16-16-16/adapters_256_slots_128_rate_3.2-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 270, 34560, 34560, 270, 34560, 540, 34560, 270, 540, 270, 34560, 540, 540, 540, 540, 34560, 270, 270, 270, 540, 34560, 270, 34560, 34560, 540, 540, 540, 270, 34560, 270, 540, 540, 270, 540, 270, 270, 540, 540, 34560, 540, 270, 540, 34560, 540, 540, 34560, 540, 34560, 270, 34560, 34560, 540, 270, 270, 34560, 540, 270, 540, 540, 34560, 540, 270, 270, 34560, 34560, 34560, 34560, 34560, 34560, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 34560, 34560, 270, 34560, 270, 540, 34560, 34560, 34560, 540, 270, 34560, 540, 270, 270, 270, 270, 270, 34560, 540, 270, 34560, 270, 34560, 270, 270, 540, 540, 34560, 540, 34560, 270, 540, 270, 34560, 34560, 270, 34560, 540, 270, 34560, 270, 270, 34560, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 270, 540, 34560, 34560, 270, 34560, 540, 270, 540, 34560, 270, 270, 270, 270, 270, 270, 34560, 270, 270, 270, 34560, 270, 540, 34560, 34560, 540, 270, 34560, 270, 540, 540, 270, 540, 270, 34560, 270, 270, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 540, 34560, 540, 34560, 270, 34560, 270, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 540, 540, 270, 540, 34560, 540, 540, 34560, 270, 34560, 34560, 540, 270, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 270, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 34560, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 34560, 540, 270, 270, 270, 270]
Prompts retrieved: 3041010 . Total input tokens: 677979927 . Total output tokens: 608266809
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.702986416872591,
    "estimated_duration": 3600.139964310885,
    "input_throughput": 5115.236124861325,
    "output_throughput": 4512.160682927614,
    "total_throughput": 9627.39680778894,
    "itl": 190.0461236779314,
    "ttft": 2145897.693039743,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1280,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.8272643774746857,
    "arrivals": 1012432,
    "finished_requests": 74518,
    "scheduler_time": 103.00719024544135
}
#Debug simulation 
Total elapsed time: 5.7031141156330705. Arrivals time: 0.2928210776299238 Scheduler time: 5.301023680716753 Scheduler overhead time: 0.03126103989779949 Adapter cache time: 0.03146750247105956 Engine time: 0.03214816888794303 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_16-16-32/adapters_256_slots_128_rate_3.2-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_16-16-32/adapters_256_slots_128_rate_3.2-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 270, 34560, 34560, 270, 34560, 540, 34560, 270, 540, 270, 34560, 540, 540, 540, 540, 34560, 270, 270, 270, 540, 34560, 270, 34560, 34560, 540, 540, 540, 270, 34560, 270, 540, 540, 270, 540, 270, 270, 540, 540, 34560, 540, 270, 540, 34560, 540, 540, 34560, 540, 34560, 270, 34560, 34560, 540, 270, 270, 34560, 540, 270, 540, 540, 34560, 540, 270, 270, 34560, 34560, 34560, 34560, 34560, 34560, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 34560, 34560, 270, 34560, 270, 540, 34560, 34560, 34560, 540, 270, 34560, 540, 270, 270, 270, 270, 270, 34560, 540, 270, 34560, 270, 34560, 270, 270, 540, 540, 34560, 540, 34560, 270, 540, 270, 34560, 34560, 270, 34560, 540, 270, 34560, 270, 270, 34560, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 270, 540, 34560, 34560, 270, 34560, 540, 270, 540, 34560, 270, 270, 270, 270, 270, 270, 34560, 270, 270, 270, 34560, 270, 540, 34560, 34560, 540, 270, 34560, 270, 540, 540, 270, 540, 270, 34560, 270, 270, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 540, 34560, 540, 34560, 270, 34560, 270, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 540, 540, 270, 540, 34560, 540, 540, 34560, 270, 34560, 34560, 540, 270, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 270, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 34560, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 34560, 540, 270, 270, 270, 270]
Prompts retrieved: 3041010 . Total input tokens: 677979927 . Total output tokens: 608266809
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.565395961049944,
    "estimated_duration": 3600.1006840012014,
    "input_throughput": 4985.9427764809725,
    "output_throughput": 4403.216574038102,
    "total_throughput": 9389.159350519076,
    "itl": 159.51398431830427,
    "ttft": 2160151.714007894,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.206487735956947,
    "arrivals": 1012432,
    "finished_requests": 72659,
    "scheduler_time": 108.45585056997764
}
#Debug simulation 
Total elapsed time: 5.565533069893718. Arrivals time: 0.2932434882968664 Scheduler time: 5.150442282203585 Scheduler overhead time: 0.03586990386247635 Adapter cache time: 0.033069062512367964 Engine time: 0.03640325786545873 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-8/adapters_256_slots_128_rate_3.2-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-8/adapters_256_slots_128_rate_3.2-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 135, 34560, 34560, 135, 34560, 540, 34560, 135, 540, 135, 34560, 540, 540, 540, 540, 34560, 135, 135, 135, 540, 34560, 135, 34560, 34560, 540, 540, 540, 135, 34560, 135, 540, 540, 135, 540, 135, 135, 540, 540, 34560, 540, 135, 540, 34560, 540, 540, 34560, 540, 34560, 135, 34560, 34560, 540, 135, 135, 34560, 540, 135, 540, 540, 34560, 540, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 34560, 34560, 135, 34560, 135, 540, 34560, 34560, 34560, 540, 135, 34560, 540, 135, 135, 135, 135, 135, 34560, 540, 135, 34560, 135, 34560, 135, 135, 540, 540, 34560, 540, 34560, 135, 540, 135, 34560, 34560, 135, 34560, 540, 135, 34560, 135, 135, 34560, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 135, 540, 34560, 34560, 135, 34560, 540, 135, 540, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 540, 34560, 34560, 540, 135, 34560, 135, 540, 540, 135, 540, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 540, 34560, 540, 34560, 135, 34560, 135, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 540, 540, 135, 540, 34560, 540, 540, 34560, 135, 34560, 34560, 540, 135, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 135, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 34560, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 34560, 540, 135, 135, 135, 135]
Prompts retrieved: 3029535 . Total input tokens: 675430113 . Total output tokens: 605954314
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.652592475991696,
    "estimated_duration": 3600.017512340262,
    "input_throughput": 5185.874217557263,
    "output_throughput": 4575.261632350419,
    "total_throughput": 9761.135849907681,
    "itl": 187.46243595856188,
    "ttft": 2134240.35653304,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1085,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.320629202167117,
    "arrivals": 1008682,
    "finished_requests": 75566,
    "scheduler_time": 104.52990650451164
}
#Debug simulation 
Total elapsed time: 5.652710476424545. Arrivals time: 0.2854320635087788 Scheduler time: 5.263586596120149 Scheduler overhead time: 0.03074070531874895 Adapter cache time: 0.02710308274254203 Engine time: 0.031520525459200144 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-16/adapters_256_slots_128_rate_3.2-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-16/adapters_256_slots_128_rate_3.2-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 135, 34560, 34560, 135, 34560, 540, 34560, 135, 540, 135, 34560, 540, 540, 540, 540, 34560, 135, 135, 135, 540, 34560, 135, 34560, 34560, 540, 540, 540, 135, 34560, 135, 540, 540, 135, 540, 135, 135, 540, 540, 34560, 540, 135, 540, 34560, 540, 540, 34560, 540, 34560, 135, 34560, 34560, 540, 135, 135, 34560, 540, 135, 540, 540, 34560, 540, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 34560, 34560, 135, 34560, 135, 540, 34560, 34560, 34560, 540, 135, 34560, 540, 135, 135, 135, 135, 135, 34560, 540, 135, 34560, 135, 34560, 135, 135, 540, 540, 34560, 540, 34560, 135, 540, 135, 34560, 34560, 135, 34560, 540, 135, 34560, 135, 135, 34560, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 135, 540, 34560, 34560, 135, 34560, 540, 135, 540, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 540, 34560, 34560, 540, 135, 34560, 135, 540, 540, 135, 540, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 540, 34560, 540, 34560, 135, 34560, 135, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 540, 540, 135, 540, 34560, 540, 540, 34560, 135, 34560, 34560, 540, 135, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 135, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 34560, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 34560, 540, 135, 135, 135, 135]
Prompts retrieved: 3029535 . Total input tokens: 675430113 . Total output tokens: 605954314
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.769844990223646,
    "estimated_duration": 3600.017075432813,
    "input_throughput": 5185.1504059201725,
    "output_throughput": 4574.93413361655,
    "total_throughput": 9760.084539536721,
    "itl": 187.47255277524684,
    "ttft": 2134272.901907405,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1084,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5333601723588113,
    "arrivals": 1008682,
    "finished_requests": 75560,
    "scheduler_time": 104.52397941277388
}
#Debug simulation 
Total elapsed time: 5.7699660789221525. Arrivals time: 0.3031115457415581 Scheduler time: 5.361734123434871 Scheduler overhead time: 0.030910019762814045 Adapter cache time: 0.028383827302604914 Engine time: 0.03166748117655516 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-32/adapters_256_slots_128_rate_3.2-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-32/adapters_256_slots_128_rate_3.2-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 135, 34560, 34560, 135, 34560, 540, 34560, 135, 540, 135, 34560, 540, 540, 540, 540, 34560, 135, 135, 135, 540, 34560, 135, 34560, 34560, 540, 540, 540, 135, 34560, 135, 540, 540, 135, 540, 135, 135, 540, 540, 34560, 540, 135, 540, 34560, 540, 540, 34560, 540, 34560, 135, 34560, 34560, 540, 135, 135, 34560, 540, 135, 540, 540, 34560, 540, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 34560, 34560, 135, 34560, 135, 540, 34560, 34560, 34560, 540, 135, 34560, 540, 135, 135, 135, 135, 135, 34560, 540, 135, 34560, 135, 34560, 135, 135, 540, 540, 34560, 540, 34560, 135, 540, 135, 34560, 34560, 135, 34560, 540, 135, 34560, 135, 135, 34560, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 135, 540, 34560, 34560, 135, 34560, 540, 135, 540, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 540, 34560, 34560, 540, 135, 34560, 135, 540, 540, 135, 540, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 540, 34560, 540, 34560, 135, 34560, 135, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 540, 540, 135, 540, 34560, 540, 540, 34560, 135, 34560, 34560, 540, 135, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 135, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 34560, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 34560, 540, 135, 135, 135, 135]
Prompts retrieved: 3029535 . Total input tokens: 675430113 . Total output tokens: 605954314
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.791512185707688,
    "estimated_duration": 3600.0285394237994,
    "input_throughput": 5043.032798541592,
    "output_throughput": 4458.893818261012,
    "total_throughput": 9501.926616802602,
    "itl": 157.29084231106037,
    "ttft": 2150719.938178706,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1055,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4463111366331147,
    "arrivals": 1008682,
    "finished_requests": 73506,
    "scheduler_time": 109.87339187254254
}
#Debug simulation 
Total elapsed time: 5.791626941878349. Arrivals time: 0.3051336891949177 Scheduler time: 5.361594817135483 Scheduler overhead time: 0.03760817460715771 Adapter cache time: 0.0316328601911664 Engine time: 0.038372807670384645 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-16/adapters_256_slots_128_rate_3.2-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-16/adapters_256_slots_128_rate_3.2-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 135, 34560, 34560, 135, 34560, 540, 34560, 135, 540, 135, 34560, 540, 540, 540, 540, 34560, 135, 135, 135, 540, 34560, 135, 34560, 34560, 540, 540, 540, 135, 34560, 135, 540, 540, 135, 540, 135, 135, 540, 540, 34560, 540, 135, 540, 34560, 540, 540, 34560, 540, 34560, 135, 34560, 34560, 540, 135, 135, 34560, 540, 135, 540, 540, 34560, 540, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 34560, 34560, 135, 34560, 135, 540, 34560, 34560, 34560, 540, 135, 34560, 540, 135, 135, 135, 135, 135, 34560, 540, 135, 34560, 135, 34560, 135, 135, 540, 540, 34560, 540, 34560, 135, 540, 135, 34560, 34560, 135, 34560, 540, 135, 34560, 135, 135, 34560, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 135, 540, 34560, 34560, 135, 34560, 540, 135, 540, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 540, 34560, 34560, 540, 135, 34560, 135, 540, 540, 135, 540, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 540, 34560, 540, 34560, 135, 34560, 135, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 540, 540, 135, 540, 34560, 540, 540, 34560, 135, 34560, 34560, 540, 135, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 135, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 34560, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 34560, 540, 135, 135, 135, 135]
Prompts retrieved: 3029535 . Total input tokens: 675430113 . Total output tokens: 605954314
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.489368359092623,
    "estimated_duration": 3600.1009274532976,
    "input_throughput": 5185.754059735923,
    "output_throughput": 4575.155622554049,
    "total_throughput": 9760.909682289972,
    "itl": 187.46666694917042,
    "ttft": 2134271.7306845468,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1085,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.403965339479004,
    "arrivals": 1008682,
    "finished_requests": 75566,
    "scheduler_time": 104.52998548012958
}
#Debug simulation 
Total elapsed time: 5.4894685642793775. Arrivals time: 0.26671692822128534 Scheduler time: 5.123059764970094 Scheduler overhead time: 0.029872597195208073 Adapter cache time: 0.025429326575249434 Engine time: 0.030548177659511566 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-32/adapters_256_slots_128_rate_3.2-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-32/adapters_256_slots_128_rate_3.2-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 135, 34560, 34560, 135, 34560, 540, 34560, 135, 540, 135, 34560, 540, 540, 540, 540, 34560, 135, 135, 135, 540, 34560, 135, 34560, 34560, 540, 540, 540, 135, 34560, 135, 540, 540, 135, 540, 135, 135, 540, 540, 34560, 540, 135, 540, 34560, 540, 540, 34560, 540, 34560, 135, 34560, 34560, 540, 135, 135, 34560, 540, 135, 540, 540, 34560, 540, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 34560, 34560, 135, 34560, 135, 540, 34560, 34560, 34560, 540, 135, 34560, 540, 135, 135, 135, 135, 135, 34560, 540, 135, 34560, 135, 34560, 135, 135, 540, 540, 34560, 540, 34560, 135, 540, 135, 34560, 34560, 135, 34560, 540, 135, 34560, 135, 135, 34560, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 135, 540, 34560, 34560, 135, 34560, 540, 135, 540, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 540, 34560, 34560, 540, 135, 34560, 135, 540, 540, 135, 540, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 540, 34560, 540, 34560, 135, 34560, 135, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 540, 540, 135, 540, 34560, 540, 540, 34560, 135, 34560, 34560, 540, 135, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 135, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 34560, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 34560, 540, 135, 135, 135, 135]
Prompts retrieved: 3029535 . Total input tokens: 675430113 . Total output tokens: 605954314
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 5.668799958191812,
    "estimated_duration": 3600.068618347946,
    "input_throughput": 5042.976655353661,
    "output_throughput": 4458.84417818854,
    "total_throughput": 9501.8208335422,
    "itl": 157.2924875565637,
    "ttft": 2150736.296796588,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1055,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.486300840713077,
    "arrivals": 1008682,
    "finished_requests": 73506,
    "scheduler_time": 109.87348109263922
}
#Debug simulation 
Total elapsed time: 5.668936763890088. Arrivals time: 0.2928637224249542 Scheduler time: 5.255480338819325 Scheduler overhead time: 0.03655891818925738 Adapter cache time: 0.029667013324797153 Engine time: 0.03740077978000045 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-16/adapters_256_slots_128_rate_3.2-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-16/adapters_256_slots_128_rate_3.2-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 135, 34560, 34560, 135, 34560, 540, 34560, 135, 540, 135, 34560, 540, 540, 540, 540, 34560, 135, 135, 135, 540, 34560, 135, 34560, 34560, 540, 540, 540, 135, 34560, 135, 540, 540, 135, 540, 135, 135, 540, 540, 34560, 540, 135, 540, 34560, 540, 540, 34560, 540, 34560, 135, 34560, 34560, 540, 135, 135, 34560, 540, 135, 540, 540, 34560, 540, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 34560, 34560, 135, 34560, 135, 540, 34560, 34560, 34560, 540, 135, 34560, 540, 135, 135, 135, 135, 135, 34560, 540, 135, 34560, 135, 34560, 135, 135, 540, 540, 34560, 540, 34560, 135, 540, 135, 34560, 34560, 135, 34560, 540, 135, 34560, 135, 135, 34560, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 135, 540, 34560, 34560, 135, 34560, 540, 135, 540, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 540, 34560, 34560, 540, 135, 34560, 135, 540, 540, 135, 540, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 540, 34560, 540, 34560, 135, 34560, 135, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 540, 540, 135, 540, 34560, 540, 540, 34560, 135, 34560, 34560, 540, 135, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 135, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 34560, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 34560, 540, 135, 135, 135, 135]
Prompts retrieved: 3029535 . Total input tokens: 675430113 . Total output tokens: 605954314
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.878021894954145,
    "estimated_duration": 3600.1539623589024,
    "input_throughput": 5186.028762993976,
    "output_throughput": 4575.451820179089,
    "total_throughput": 9761.480583173065,
    "itl": 187.4602092791782,
    "ttft": 2134237.149154373,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1085,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2442045699687823,
    "arrivals": 1008682,
    "finished_requests": 75571,
    "scheduler_time": 104.53604628156785
}
#Debug simulation 
Total elapsed time: 5.878157493658364. Arrivals time: 0.40576886804774404 Scheduler time: 5.365585403051227 Scheduler overhead time: 0.0312185175716877 Adapter cache time: 0.029090047348290682 Engine time: 0.03220166452229023 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-32/adapters_256_slots_128_rate_3.2-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-32/adapters_256_slots_128_rate_3.2-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 135, 34560, 34560, 135, 34560, 540, 34560, 135, 540, 135, 34560, 540, 540, 540, 540, 34560, 135, 135, 135, 540, 34560, 135, 34560, 34560, 540, 540, 540, 135, 34560, 135, 540, 540, 135, 540, 135, 135, 540, 540, 34560, 540, 135, 540, 34560, 540, 540, 34560, 540, 34560, 135, 34560, 34560, 540, 135, 135, 34560, 540, 135, 540, 540, 34560, 540, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 34560, 34560, 135, 34560, 135, 540, 34560, 34560, 34560, 540, 135, 34560, 540, 135, 135, 135, 135, 135, 34560, 540, 135, 34560, 135, 34560, 135, 135, 540, 540, 34560, 540, 34560, 135, 540, 135, 34560, 34560, 135, 34560, 540, 135, 34560, 135, 135, 34560, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 135, 540, 34560, 34560, 135, 34560, 540, 135, 540, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 540, 34560, 34560, 540, 135, 34560, 135, 540, 540, 135, 540, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 540, 34560, 540, 34560, 135, 34560, 135, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 540, 540, 135, 540, 34560, 540, 540, 34560, 135, 34560, 34560, 540, 135, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 135, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 34560, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 34560, 540, 135, 135, 135, 135]
Prompts retrieved: 3029535 . Total input tokens: 675430113 . Total output tokens: 605954314
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.716551559045911,
    "estimated_duration": 3600.116476404957,
    "input_throughput": 5042.90961667148,
    "output_throughput": 4458.784904656619,
    "total_throughput": 9501.694521328098,
    "itl": 157.2945166300722,
    "ttft": 2150754.6746776025,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1055,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.534087279550777,
    "arrivals": 1008682,
    "finished_requests": 73506,
    "scheduler_time": 109.87355271085879
}
#Debug simulation 
Total elapsed time: 5.7166437758132815. Arrivals time: 0.3113135634921491 Scheduler time: 5.282814169768244 Scheduler overhead time: 0.036637571174651384 Adapter cache time: 0.031158494297415018 Engine time: 0.037700691260397434 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-8/adapters_256_slots_128_rate_3.2-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-8/adapters_256_slots_128_rate_3.2-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 66, 34560, 34560, 66, 34560, 540, 34560, 66, 540, 66, 34560, 540, 540, 540, 540, 34560, 66, 66, 66, 540, 34560, 66, 34560, 34560, 540, 540, 540, 66, 34560, 66, 540, 540, 66, 540, 66, 66, 540, 540, 34560, 540, 66, 540, 34560, 540, 540, 34560, 540, 34560, 66, 34560, 34560, 540, 66, 66, 34560, 540, 66, 540, 540, 34560, 540, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 34560, 34560, 66, 34560, 66, 540, 34560, 34560, 34560, 540, 66, 34560, 540, 66, 66, 66, 66, 66, 34560, 540, 66, 34560, 66, 34560, 66, 66, 540, 540, 34560, 540, 34560, 66, 540, 66, 34560, 34560, 66, 34560, 540, 66, 34560, 66, 66, 34560, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 66, 540, 34560, 34560, 66, 34560, 540, 66, 540, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 540, 34560, 34560, 540, 66, 34560, 66, 540, 540, 66, 540, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 540, 34560, 540, 34560, 66, 34560, 66, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 540, 540, 66, 540, 34560, 540, 540, 34560, 66, 34560, 34560, 540, 66, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 66, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 34560, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 34560, 540, 66, 66, 66, 66]
Prompts retrieved: 3023670 . Total input tokens: 674122022 . Total output tokens: 604779064
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 6.227933241054416,
    "estimated_duration": 3600.082985462721,
    "input_throughput": 5258.511838878286,
    "output_throughput": 4623.613140923349,
    "total_throughput": 9882.124979801634,
    "itl": 185.38104872005837,
    "ttft": 2134683.765060032,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 894,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7360760430759408,
    "arrivals": 1006798,
    "finished_requests": 76195,
    "scheduler_time": 105.56378980348398
}
#Debug simulation 
Total elapsed time: 6.228022572118789. Arrivals time: 0.7153169065713882 Scheduler time: 5.406446408946067 Scheduler overhead time: 0.031450062058866024 Adapter cache time: 0.027503809425979853 Engine time: 0.0327597763389349 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-16/adapters_256_slots_128_rate_3.2-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-16/adapters_256_slots_128_rate_3.2-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 66, 34560, 34560, 66, 34560, 540, 34560, 66, 540, 66, 34560, 540, 540, 540, 540, 34560, 66, 66, 66, 540, 34560, 66, 34560, 34560, 540, 540, 540, 66, 34560, 66, 540, 540, 66, 540, 66, 66, 540, 540, 34560, 540, 66, 540, 34560, 540, 540, 34560, 540, 34560, 66, 34560, 34560, 540, 66, 66, 34560, 540, 66, 540, 540, 34560, 540, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 34560, 34560, 66, 34560, 66, 540, 34560, 34560, 34560, 540, 66, 34560, 540, 66, 66, 66, 66, 66, 34560, 540, 66, 34560, 66, 34560, 66, 66, 540, 540, 34560, 540, 34560, 66, 540, 66, 34560, 34560, 66, 34560, 540, 66, 34560, 66, 66, 34560, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 66, 540, 34560, 34560, 66, 34560, 540, 66, 540, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 540, 34560, 34560, 540, 66, 34560, 66, 540, 540, 66, 540, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 540, 34560, 540, 34560, 66, 34560, 66, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 540, 540, 66, 540, 34560, 540, 540, 34560, 66, 34560, 34560, 540, 66, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 66, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 34560, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 34560, 540, 66, 66, 66, 66]
Prompts retrieved: 3023670 . Total input tokens: 674122022 . Total output tokens: 604779064
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.771054399665445,
    "estimated_duration": 3600.100480082349,
    "input_throughput": 5258.4335089355545,
    "output_throughput": 4623.370123163693,
    "total_throughput": 9881.803632099247,
    "itl": 185.3903662287883,
    "ttft": 2134725.875912513,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 893,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.910368960590571,
    "arrivals": 1006798,
    "finished_requests": 76193,
    "scheduler_time": 105.5590322885568
}
#Debug simulation 
Total elapsed time: 5.7711928971111774. Arrivals time: 0.31411215011030436 Scheduler time: 5.352802189998329 Scheduler overhead time: 0.03115613618865609 Adapter cache time: 0.026314432732760906 Engine time: 0.032356413546949625 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-32/adapters_256_slots_128_rate_3.2-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-32/adapters_256_slots_128_rate_3.2-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 66, 34560, 34560, 66, 34560, 540, 34560, 66, 540, 66, 34560, 540, 540, 540, 540, 34560, 66, 66, 66, 540, 34560, 66, 34560, 34560, 540, 540, 540, 66, 34560, 66, 540, 540, 66, 540, 66, 66, 540, 540, 34560, 540, 66, 540, 34560, 540, 540, 34560, 540, 34560, 66, 34560, 34560, 540, 66, 66, 34560, 540, 66, 540, 540, 34560, 540, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 34560, 34560, 66, 34560, 66, 540, 34560, 34560, 34560, 540, 66, 34560, 540, 66, 66, 66, 66, 66, 34560, 540, 66, 34560, 66, 34560, 66, 66, 540, 540, 34560, 540, 34560, 66, 540, 66, 34560, 34560, 66, 34560, 540, 66, 34560, 66, 66, 34560, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 66, 540, 34560, 34560, 66, 34560, 540, 66, 540, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 540, 34560, 34560, 540, 66, 34560, 66, 540, 540, 66, 540, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 540, 34560, 540, 34560, 66, 34560, 66, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 540, 540, 66, 540, 34560, 540, 540, 34560, 66, 34560, 34560, 540, 66, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 66, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 34560, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 34560, 540, 66, 66, 66, 66]
Prompts retrieved: 3023670 . Total input tokens: 674122022 . Total output tokens: 604779064
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.753887171857059,
    "estimated_duration": 3600.069498208195,
    "input_throughput": 5101.684011695114,
    "output_throughput": 4492.216888604283,
    "total_throughput": 9593.900900299397,
    "itl": 155.72653560431016,
    "ttft": 2151089.2266567587,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 866,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8292673848941736,
    "arrivals": 1006798,
    "finished_requests": 73944,
    "scheduler_time": 110.8036590651308
}
#Debug simulation 
Total elapsed time: 5.753999753855169. Arrivals time: 0.29082072293385863 Scheduler time: 5.342459386214614 Scheduler overhead time: 0.03743792697787285 Adapter cache time: 0.027783540543168783 Engine time: 0.03833753615617752 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-16/adapters_256_slots_128_rate_3.2-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-16/adapters_256_slots_128_rate_3.2-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 66, 34560, 34560, 66, 34560, 540, 34560, 66, 540, 66, 34560, 540, 540, 540, 540, 34560, 66, 66, 66, 540, 34560, 66, 34560, 34560, 540, 540, 540, 66, 34560, 66, 540, 540, 66, 540, 66, 66, 540, 540, 34560, 540, 66, 540, 34560, 540, 540, 34560, 540, 34560, 66, 34560, 34560, 540, 66, 66, 34560, 540, 66, 540, 540, 34560, 540, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 34560, 34560, 66, 34560, 66, 540, 34560, 34560, 34560, 540, 66, 34560, 540, 66, 66, 66, 66, 66, 34560, 540, 66, 34560, 66, 34560, 66, 66, 540, 540, 34560, 540, 34560, 66, 540, 66, 34560, 34560, 66, 34560, 540, 66, 34560, 66, 66, 34560, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 66, 540, 34560, 34560, 66, 34560, 540, 66, 540, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 540, 34560, 34560, 540, 66, 34560, 66, 540, 540, 66, 540, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 540, 34560, 540, 34560, 66, 34560, 66, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 540, 540, 66, 540, 34560, 540, 540, 34560, 66, 34560, 34560, 540, 66, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 66, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 34560, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 34560, 540, 66, 66, 66, 66]
Prompts retrieved: 3023670 . Total input tokens: 674122022 . Total output tokens: 604779064
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.7244877750054,
    "estimated_duration": 3600.152097586336,
    "input_throughput": 5258.410891220968,
    "output_throughput": 4623.524381417006,
    "total_throughput": 9881.935272637973,
    "itl": 185.38443319638168,
    "ttft": 2134711.809568206,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 894,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.805081251498753,
    "arrivals": 1006798,
    "finished_requests": 76195,
    "scheduler_time": 105.56389671858939
}
#Debug simulation 
Total elapsed time: 5.724586523137987. Arrivals time: 0.30926881544291973 Scheduler time: 5.312729110941291 Scheduler overhead time: 0.030975199304521084 Adapter cache time: 0.025377918500453234 Engine time: 0.03194754850119352 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-32/adapters_256_slots_128_rate_3.2-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-32/adapters_256_slots_128_rate_3.2-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 66, 34560, 34560, 66, 34560, 540, 34560, 66, 540, 66, 34560, 540, 540, 540, 540, 34560, 66, 66, 66, 540, 34560, 66, 34560, 34560, 540, 540, 540, 66, 34560, 66, 540, 540, 66, 540, 66, 66, 540, 540, 34560, 540, 66, 540, 34560, 540, 540, 34560, 540, 34560, 66, 34560, 34560, 540, 66, 66, 34560, 540, 66, 540, 540, 34560, 540, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 34560, 34560, 66, 34560, 66, 540, 34560, 34560, 34560, 540, 66, 34560, 540, 66, 66, 66, 66, 66, 34560, 540, 66, 34560, 66, 34560, 66, 66, 540, 540, 34560, 540, 34560, 66, 540, 66, 34560, 34560, 66, 34560, 540, 66, 34560, 66, 66, 34560, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 66, 540, 34560, 34560, 66, 34560, 540, 66, 540, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 540, 34560, 34560, 540, 66, 34560, 66, 540, 540, 66, 540, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 540, 34560, 540, 34560, 66, 34560, 66, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 540, 540, 66, 540, 34560, 540, 540, 34560, 66, 34560, 34560, 540, 66, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 66, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 34560, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 34560, 540, 66, 66, 66, 66]
Prompts retrieved: 3023670 . Total input tokens: 674122022 . Total output tokens: 604779064
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 5.775174789130688,
    "estimated_duration": 3600.102157007024,
    "input_throughput": 5101.637731099575,
    "output_throughput": 4492.176136869676,
    "total_throughput": 9593.813867969251,
    "itl": 155.7278632138809,
    "ttft": 2151102.730979356,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 866,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.861837615575644,
    "arrivals": 1006798,
    "finished_requests": 73944,
    "scheduler_time": 110.80374763330612
}
#Debug simulation 
Total elapsed time: 5.775280618108809. Arrivals time: 0.29197562066838145 Scheduler time: 5.362988969776779 Scheduler overhead time: 0.03690156573429704 Adapter cache time: 0.027728057466447353 Engine time: 0.038257923908531666 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-16/adapters_256_slots_128_rate_3.2-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-16/adapters_256_slots_128_rate_3.2-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 66, 34560, 34560, 66, 34560, 540, 34560, 66, 540, 66, 34560, 540, 540, 540, 540, 34560, 66, 66, 66, 540, 34560, 66, 34560, 34560, 540, 540, 540, 66, 34560, 66, 540, 540, 66, 540, 66, 66, 540, 540, 34560, 540, 66, 540, 34560, 540, 540, 34560, 540, 34560, 66, 34560, 34560, 540, 66, 66, 34560, 540, 66, 540, 540, 34560, 540, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 34560, 34560, 66, 34560, 66, 540, 34560, 34560, 34560, 540, 66, 34560, 540, 66, 66, 66, 66, 66, 34560, 540, 66, 34560, 66, 34560, 66, 66, 540, 540, 34560, 540, 34560, 66, 540, 66, 34560, 34560, 66, 34560, 540, 66, 34560, 66, 66, 34560, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 66, 540, 34560, 34560, 66, 34560, 540, 66, 540, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 540, 34560, 34560, 540, 66, 34560, 66, 540, 540, 66, 540, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 540, 34560, 540, 34560, 66, 34560, 66, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 540, 540, 66, 540, 34560, 540, 540, 34560, 66, 34560, 34560, 540, 66, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 66, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 34560, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 34560, 540, 66, 66, 66, 66]
Prompts retrieved: 3023670 . Total input tokens: 674122022 . Total output tokens: 604779064
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 6.029033162165433,
    "estimated_duration": 3600.019899738379,
    "input_throughput": 5258.603987543447,
    "output_throughput": 4623.694163804387,
    "total_throughput": 9882.298151347835,
    "itl": 185.3780500706397,
    "ttft": 2134658.152831431,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 894,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.673104963642487,
    "arrivals": 1006798,
    "finished_requests": 76195,
    "scheduler_time": 105.56367515845369
}
#Debug simulation 
Total elapsed time: 6.02914157230407. Arrivals time: 0.388367862906307 Scheduler time: 5.5338081191293895 Scheduler overhead time: 0.03230895334854722 Adapter cache time: 0.026741972658783197 Engine time: 0.033071001060307026 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-32/adapters_256_slots_128_rate_3.2-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-32/adapters_256_slots_128_rate_3.2-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 66, 34560, 34560, 66, 34560, 540, 34560, 66, 540, 66, 34560, 540, 540, 540, 540, 34560, 66, 66, 66, 540, 34560, 66, 34560, 34560, 540, 540, 540, 66, 34560, 66, 540, 540, 66, 540, 66, 66, 540, 540, 34560, 540, 66, 540, 34560, 540, 540, 34560, 540, 34560, 66, 34560, 34560, 540, 66, 66, 34560, 540, 66, 540, 540, 34560, 540, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 34560, 34560, 66, 34560, 66, 540, 34560, 34560, 34560, 540, 66, 34560, 540, 66, 66, 66, 66, 66, 34560, 540, 66, 34560, 66, 34560, 66, 66, 540, 540, 34560, 540, 34560, 66, 540, 66, 34560, 34560, 66, 34560, 540, 66, 34560, 66, 66, 34560, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 66, 540, 34560, 34560, 66, 34560, 540, 66, 540, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 540, 34560, 34560, 540, 66, 34560, 66, 540, 540, 66, 540, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 540, 34560, 540, 34560, 66, 34560, 66, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 540, 540, 66, 540, 34560, 540, 540, 34560, 66, 34560, 34560, 540, 66, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 66, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 34560, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 34560, 540, 66, 66, 66, 66]
Prompts retrieved: 3023670 . Total input tokens: 674122022 . Total output tokens: 604779064
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.529415221884847,
    "estimated_duration": 3600.0944358563065,
    "input_throughput": 5101.773113802033,
    "output_throughput": 4492.334656258311,
    "total_throughput": 9594.107770060344,
    "itl": 155.7259796294445,
    "ttft": 2151108.6511371587,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 866,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9014500582963487,
    "arrivals": 1006798,
    "finished_requests": 73946,
    "scheduler_time": 110.8028111900154
}
#Debug simulation 
Total elapsed time: 5.529523370787501. Arrivals time: 0.2747019096277654 Scheduler time: 5.140067900065333 Scheduler overhead time: 0.03571751434355974 Adapter cache time: 0.02573620993643999 Engine time: 0.03674270398914814 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-8/adapters_256_slots_128_rate_3.2-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-8/adapters_256_slots_128_rate_3.2-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 33, 34560, 34560, 33, 34560, 540, 34560, 33, 540, 33, 34560, 540, 540, 540, 540, 34560, 33, 33, 33, 540, 34560, 33, 34560, 34560, 540, 540, 540, 33, 34560, 33, 540, 540, 33, 540, 33, 33, 540, 540, 34560, 540, 33, 540, 34560, 540, 540, 34560, 540, 34560, 33, 34560, 34560, 540, 33, 33, 34560, 540, 33, 540, 540, 34560, 540, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 34560, 34560, 33, 34560, 33, 540, 34560, 34560, 34560, 540, 33, 34560, 540, 33, 33, 33, 33, 33, 34560, 540, 33, 34560, 33, 34560, 33, 33, 540, 540, 34560, 540, 34560, 33, 540, 33, 34560, 34560, 33, 34560, 540, 33, 34560, 33, 33, 34560, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 33, 540, 34560, 34560, 33, 34560, 540, 33, 540, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 540, 34560, 34560, 540, 33, 34560, 33, 540, 540, 33, 540, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 540, 34560, 540, 34560, 33, 34560, 33, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 540, 540, 33, 540, 34560, 540, 540, 34560, 33, 34560, 34560, 540, 33, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 33, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 34560, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 34560, 540, 33, 33, 33, 33]
Prompts retrieved: 3020865 . Total input tokens: 673492761 . Total output tokens: 604222272
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.696422188077122,
    "estimated_duration": 3600.022417069218,
    "input_throughput": 5250.853969789751,
    "output_throughput": 4635.854188259938,
    "total_throughput": 9886.708158049689,
    "itl": 185.51968597902328,
    "ttft": 2134669.9800268477,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 757,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.316789222157139,
    "arrivals": 1005871,
    "finished_requests": 76355,
    "scheduler_time": 105.74629684814607
}
#Debug simulation 
Total elapsed time: 5.696527462918311. Arrivals time: 0.32659702142700553 Scheduler time: 5.26686984160915 Scheduler overhead time: 0.030883213505148888 Adapter cache time: 0.025712839793413877 Engine time: 0.032200719229876995 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-16/adapters_256_slots_128_rate_3.2-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-16/adapters_256_slots_128_rate_3.2-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 33, 34560, 34560, 33, 34560, 540, 34560, 33, 540, 33, 34560, 540, 540, 540, 540, 34560, 33, 33, 33, 540, 34560, 33, 34560, 34560, 540, 540, 540, 33, 34560, 33, 540, 540, 33, 540, 33, 33, 540, 540, 34560, 540, 33, 540, 34560, 540, 540, 34560, 540, 34560, 33, 34560, 34560, 540, 33, 33, 34560, 540, 33, 540, 540, 34560, 540, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 34560, 34560, 33, 34560, 33, 540, 34560, 34560, 34560, 540, 33, 34560, 540, 33, 33, 33, 33, 33, 34560, 540, 33, 34560, 33, 34560, 33, 33, 540, 540, 34560, 540, 34560, 33, 540, 33, 34560, 34560, 33, 34560, 540, 33, 34560, 33, 33, 34560, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 33, 540, 34560, 34560, 33, 34560, 540, 33, 540, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 540, 34560, 34560, 540, 33, 34560, 33, 540, 540, 33, 540, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 540, 34560, 540, 34560, 33, 34560, 33, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 540, 540, 33, 540, 34560, 540, 540, 34560, 33, 34560, 34560, 540, 33, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 33, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 34560, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 34560, 540, 33, 33, 33, 33]
Prompts retrieved: 3020865 . Total input tokens: 673492761 . Total output tokens: 604222272
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.580960738006979,
    "estimated_duration": 3600.102601676255,
    "input_throughput": 5250.698963745781,
    "output_throughput": 4635.646493027581,
    "total_throughput": 9886.34545677336,
    "itl": 185.5271967010716,
    "ttft": 2134715.278235147,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 758,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4691214014822673,
    "arrivals": 1005871,
    "finished_requests": 76354,
    "scheduler_time": 105.74424834670795
}
#Debug simulation 
Total elapsed time: 5.581076364964247. Arrivals time: 0.33764358842745423 Scheduler time: 5.146318519953638 Scheduler overhead time: 0.030299815349280834 Adapter cache time: 0.022031062748283148 Engine time: 0.030885597225278616 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-32/adapters_256_slots_128_rate_3.2-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-32/adapters_256_slots_128_rate_3.2-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 33, 34560, 34560, 33, 34560, 540, 34560, 33, 540, 33, 34560, 540, 540, 540, 540, 34560, 33, 33, 33, 540, 34560, 33, 34560, 34560, 540, 540, 540, 33, 34560, 33, 540, 540, 33, 540, 33, 33, 540, 540, 34560, 540, 33, 540, 34560, 540, 540, 34560, 540, 34560, 33, 34560, 34560, 540, 33, 33, 34560, 540, 33, 540, 540, 34560, 540, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 34560, 34560, 33, 34560, 33, 540, 34560, 34560, 34560, 540, 33, 34560, 540, 33, 33, 33, 33, 33, 34560, 540, 33, 34560, 33, 34560, 33, 33, 540, 540, 34560, 540, 34560, 33, 540, 33, 34560, 34560, 33, 34560, 540, 33, 34560, 33, 33, 34560, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 33, 540, 34560, 34560, 33, 34560, 540, 33, 540, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 540, 34560, 34560, 540, 33, 34560, 33, 540, 540, 33, 540, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 540, 34560, 540, 34560, 33, 34560, 33, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 540, 540, 33, 540, 34560, 540, 540, 34560, 33, 34560, 34560, 540, 33, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 33, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 34560, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 34560, 540, 33, 33, 33, 33]
Prompts retrieved: 3020865 . Total input tokens: 673492761 . Total output tokens: 604222272
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.6546918652020395,
    "estimated_duration": 3600.1316037735833,
    "input_throughput": 5091.008334469955,
    "output_throughput": 4504.74282190156,
    "total_throughput": 9595.751156371516,
    "itl": 156.5201280005708,
    "ttft": 2150110.609033124,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 733,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.392778113521633,
    "arrivals": 1005871,
    "finished_requests": 74074,
    "scheduler_time": 110.7894220883542
}
#Debug simulation 
Total elapsed time: 5.654793166089803. Arrivals time: 0.3173769246786833 Scheduler time: 5.220350340008736 Scheduler overhead time: 0.036204615607857704 Adapter cache time: 0.026977173518389463 Engine time: 0.03711944492533803 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-16/adapters_256_slots_128_rate_3.2-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-16/adapters_256_slots_128_rate_3.2-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 33, 34560, 34560, 33, 34560, 540, 34560, 33, 540, 33, 34560, 540, 540, 540, 540, 34560, 33, 33, 33, 540, 34560, 33, 34560, 34560, 540, 540, 540, 33, 34560, 33, 540, 540, 33, 540, 33, 33, 540, 540, 34560, 540, 33, 540, 34560, 540, 540, 34560, 540, 34560, 33, 34560, 34560, 540, 33, 33, 34560, 540, 33, 540, 540, 34560, 540, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 34560, 34560, 33, 34560, 33, 540, 34560, 34560, 34560, 540, 33, 34560, 540, 33, 33, 33, 33, 33, 34560, 540, 33, 34560, 33, 34560, 33, 33, 540, 540, 34560, 540, 34560, 33, 540, 33, 34560, 34560, 33, 34560, 540, 33, 34560, 33, 33, 34560, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 33, 540, 34560, 34560, 33, 34560, 540, 33, 540, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 540, 34560, 34560, 540, 33, 34560, 33, 540, 540, 33, 540, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 540, 34560, 540, 34560, 33, 34560, 33, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 540, 540, 33, 540, 34560, 540, 540, 34560, 33, 34560, 34560, 540, 33, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 33, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 34560, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 34560, 540, 33, 33, 33, 33]
Prompts retrieved: 3020865 . Total input tokens: 673492761 . Total output tokens: 604222272
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.69130271486938,
    "estimated_duration": 3600.102012464032,
    "input_throughput": 5250.737877580867,
    "output_throughput": 4635.751693207538,
    "total_throughput": 9886.489570788404,
    "itl": 185.52163535489166,
    "ttft": 2134686.1746191345,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 758,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3775960501516074,
    "arrivals": 1005871,
    "finished_requests": 76355,
    "scheduler_time": 105.74711801760199
}
#Debug simulation 
Total elapsed time: 5.6914063869044185. Arrivals time: 0.30324558401480317 Scheduler time: 5.288604931905866 Scheduler overhead time: 0.0308104339055717 Adapter cache time: 0.023135673254728317 Engine time: 0.031390074640512466 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-32/adapters_256_slots_128_rate_3.2-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-32/adapters_256_slots_128_rate_3.2-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 33, 34560, 34560, 33, 34560, 540, 34560, 33, 540, 33, 34560, 540, 540, 540, 540, 34560, 33, 33, 33, 540, 34560, 33, 34560, 34560, 540, 540, 540, 33, 34560, 33, 540, 540, 33, 540, 33, 33, 540, 540, 34560, 540, 33, 540, 34560, 540, 540, 34560, 540, 34560, 33, 34560, 34560, 540, 33, 33, 34560, 540, 33, 540, 540, 34560, 540, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 34560, 34560, 33, 34560, 33, 540, 34560, 34560, 34560, 540, 33, 34560, 540, 33, 33, 33, 33, 33, 34560, 540, 33, 34560, 33, 34560, 33, 33, 540, 540, 34560, 540, 34560, 33, 540, 33, 34560, 34560, 33, 34560, 540, 33, 34560, 33, 33, 34560, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 33, 540, 34560, 34560, 33, 34560, 540, 33, 540, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 540, 34560, 34560, 540, 33, 34560, 33, 540, 540, 33, 540, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 540, 34560, 540, 34560, 33, 34560, 33, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 540, 540, 33, 540, 34560, 540, 540, 34560, 33, 34560, 34560, 540, 33, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 33, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 34560, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 34560, 540, 33, 33, 33, 33]
Prompts retrieved: 3020865 . Total input tokens: 673492761 . Total output tokens: 604222272
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 5.607529740314931,
    "estimated_duration": 3600.1589743010427,
    "input_throughput": 5090.9696296281945,
    "output_throughput": 4504.708574195282,
    "total_throughput": 9595.678203823476,
    "itl": 156.52121990792895,
    "ttft": 2150122.1984243155,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 733,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.420066685173661,
    "arrivals": 1005871,
    "finished_requests": 74074,
    "scheduler_time": 110.78950404418413
}
#Debug simulation 
Total elapsed time: 5.607639501336962. Arrivals time: 0.2983549553900957 Scheduler time: 5.194424410816282 Scheduler overhead time: 0.03577375039458275 Adapter cache time: 0.025771753396838903 Engine time: 0.036776221822947264 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-16/adapters_256_slots_128_rate_3.2-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-16/adapters_256_slots_128_rate_3.2-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 33, 34560, 34560, 33, 34560, 540, 34560, 33, 540, 33, 34560, 540, 540, 540, 540, 34560, 33, 33, 33, 540, 34560, 33, 34560, 34560, 540, 540, 540, 33, 34560, 33, 540, 540, 33, 540, 33, 33, 540, 540, 34560, 540, 33, 540, 34560, 540, 540, 34560, 540, 34560, 33, 34560, 34560, 540, 33, 33, 34560, 540, 33, 540, 540, 34560, 540, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 34560, 34560, 33, 34560, 33, 540, 34560, 34560, 34560, 540, 33, 34560, 540, 33, 33, 33, 33, 33, 34560, 540, 33, 34560, 33, 34560, 33, 33, 540, 540, 34560, 540, 34560, 33, 540, 33, 34560, 34560, 33, 34560, 540, 33, 34560, 33, 33, 34560, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 33, 540, 34560, 34560, 33, 34560, 540, 33, 540, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 540, 34560, 34560, 540, 33, 34560, 33, 540, 540, 33, 540, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 540, 34560, 540, 34560, 33, 34560, 33, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 540, 540, 33, 540, 34560, 540, 540, 34560, 33, 34560, 34560, 540, 33, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 33, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 34560, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 34560, 540, 33, 33, 33, 33]
Prompts retrieved: 3020865 . Total input tokens: 673492761 . Total output tokens: 604222272
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.721189574804157,
    "estimated_duration": 3600.17330156117,
    "input_throughput": 5250.993609613823,
    "output_throughput": 4636.050990312699,
    "total_throughput": 9887.044599926521,
    "itl": 185.5173792364015,
    "ttft": 2134686.521876538,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 757,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2634680732409036,
    "arrivals": 1005871,
    "finished_requests": 76361,
    "scheduler_time": 105.7522830686118
}
#Debug simulation 
Total elapsed time: 5.721297401934862. Arrivals time: 0.31972860265523195 Scheduler time: 5.299846237525344 Scheduler overhead time: 0.031009460799396038 Adapter cache time: 0.024658106733113527 Engine time: 0.031800560653209686 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-32/adapters_256_slots_128_rate_3.2-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-32/adapters_256_slots_128_rate_3.2-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 33, 34560, 34560, 33, 34560, 540, 34560, 33, 540, 33, 34560, 540, 540, 540, 540, 34560, 33, 33, 33, 540, 34560, 33, 34560, 34560, 540, 540, 540, 33, 34560, 33, 540, 540, 33, 540, 33, 33, 540, 540, 34560, 540, 33, 540, 34560, 540, 540, 34560, 540, 34560, 33, 34560, 34560, 540, 33, 33, 34560, 540, 33, 540, 540, 34560, 540, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 34560, 34560, 33, 34560, 33, 540, 34560, 34560, 34560, 540, 33, 34560, 540, 33, 33, 33, 33, 33, 34560, 540, 33, 34560, 33, 34560, 33, 33, 540, 540, 34560, 540, 34560, 33, 540, 33, 34560, 34560, 33, 34560, 540, 33, 34560, 33, 33, 34560, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 33, 540, 34560, 34560, 33, 34560, 540, 33, 540, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 540, 34560, 34560, 540, 33, 34560, 33, 540, 540, 33, 540, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 540, 34560, 540, 34560, 33, 34560, 33, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 540, 540, 33, 540, 34560, 540, 540, 34560, 33, 34560, 34560, 540, 33, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 33, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 34560, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 34560, 540, 33, 33, 33, 33]
Prompts retrieved: 3020865 . Total input tokens: 673492761 . Total output tokens: 604222272
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.957231693901122,
    "estimated_duration": 3600.020607467633,
    "input_throughput": 5090.720581427886,
    "output_throughput": 4504.658380666173,
    "total_throughput": 9595.378962094059,
    "itl": 156.52312978127205,
    "ttft": 2150132.596216338,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 732,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.449633410871039,
    "arrivals": 1005871,
    "finished_requests": 74070,
    "scheduler_time": 110.78434208951064
}
#Debug simulation 
Total elapsed time: 5.957349777687341. Arrivals time: 0.2943014930933714 Scheduler time: 5.543015762232244 Scheduler overhead time: 0.03791378252208233 Adapter cache time: 0.026101418770849705 Engine time: 0.03852543607354164 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-8/adapters_256_slots_128_rate_3.2-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-8/adapters_256_slots_128_rate_3.2-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 135, 34560, 34560, 135, 34560, 270, 34560, 135, 270, 135, 34560, 270, 270, 270, 270, 34560, 135, 135, 135, 270, 34560, 135, 34560, 34560, 270, 270, 270, 135, 34560, 135, 270, 270, 135, 270, 135, 135, 270, 270, 34560, 270, 135, 270, 34560, 270, 270, 34560, 270, 34560, 135, 34560, 34560, 270, 135, 135, 34560, 270, 135, 270, 270, 34560, 270, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 34560, 34560, 135, 34560, 135, 270, 34560, 34560, 34560, 270, 135, 34560, 270, 135, 135, 135, 135, 135, 34560, 270, 135, 34560, 135, 34560, 135, 135, 270, 270, 34560, 270, 34560, 135, 270, 135, 34560, 34560, 135, 34560, 270, 135, 34560, 135, 135, 34560, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 135, 270, 34560, 34560, 135, 34560, 270, 135, 270, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 270, 34560, 34560, 270, 135, 34560, 135, 270, 270, 135, 270, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 270, 34560, 270, 34560, 135, 34560, 135, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 270, 270, 135, 270, 34560, 270, 270, 34560, 135, 34560, 34560, 270, 135, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 135, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 34560, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 34560, 270, 135, 135, 135, 135]
Prompts retrieved: 3006585 . Total input tokens: 670334443 . Total output tokens: 601394933
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.907818295061588,
    "estimated_duration": 3600.092092146606,
    "input_throughput": 5348.267629598157,
    "output_throughput": 4727.7307258691335,
    "total_throughput": 10075.99835546729,
    "itl": 181.97279257257173,
    "ttft": 2122056.436772915,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 721,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.206611663375556,
    "arrivals": 1001073,
    "finished_requests": 77817,
    "scheduler_time": 107.81338768249383
}
#Debug simulation 
Total elapsed time: 5.907925002742559. Arrivals time: 0.43417583080008626 Scheduler time: 5.373599621467292 Scheduler overhead time: 0.031255791429430246 Adapter cache time: 0.022288907319307327 Engine time: 0.03231577388942242 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-16/adapters_256_slots_128_rate_3.2-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-16/adapters_256_slots_128_rate_3.2-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 135, 34560, 34560, 135, 34560, 270, 34560, 135, 270, 135, 34560, 270, 270, 270, 270, 34560, 135, 135, 135, 270, 34560, 135, 34560, 34560, 270, 270, 270, 135, 34560, 135, 270, 270, 135, 270, 135, 135, 270, 270, 34560, 270, 135, 270, 34560, 270, 270, 34560, 270, 34560, 135, 34560, 34560, 270, 135, 135, 34560, 270, 135, 270, 270, 34560, 270, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 34560, 34560, 135, 34560, 135, 270, 34560, 34560, 34560, 270, 135, 34560, 270, 135, 135, 135, 135, 135, 34560, 270, 135, 34560, 135, 34560, 135, 135, 270, 270, 34560, 270, 34560, 135, 270, 135, 34560, 34560, 135, 34560, 270, 135, 34560, 135, 135, 34560, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 135, 270, 34560, 34560, 135, 34560, 270, 135, 270, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 270, 34560, 34560, 270, 135, 34560, 135, 270, 270, 135, 270, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 270, 34560, 270, 34560, 135, 34560, 135, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 270, 270, 135, 270, 34560, 270, 270, 34560, 135, 34560, 34560, 270, 135, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 135, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 34560, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 34560, 270, 135, 135, 135, 135]
Prompts retrieved: 3006585 . Total input tokens: 670334443 . Total output tokens: 601394933
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 6.006958082783967,
    "estimated_duration": 3600.041021608329,
    "input_throughput": 5347.651286317626,
    "output_throughput": 4727.381132006328,
    "total_throughput": 10075.032418323954,
    "itl": 181.97928919348922,
    "ttft": 2122083.5708544194,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 721,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3531778014311624,
    "arrivals": 1001073,
    "finished_requests": 77810,
    "scheduler_time": 107.80773219183276
}
#Debug simulation 
Total elapsed time: 6.007079910952598. Arrivals time: 0.33816851768642664 Scheduler time: 5.565869402140379 Scheduler overhead time: 0.031698846723884344 Adapter cache time: 0.023842004593461752 Engine time: 0.032913546077907085 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-32/adapters_256_slots_128_rate_3.2-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-32/adapters_256_slots_128_rate_3.2-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 135, 34560, 34560, 135, 34560, 270, 34560, 135, 270, 135, 34560, 270, 270, 270, 270, 34560, 135, 135, 135, 270, 34560, 135, 34560, 34560, 270, 270, 270, 135, 34560, 135, 270, 270, 135, 270, 135, 135, 270, 270, 34560, 270, 135, 270, 34560, 270, 270, 34560, 270, 34560, 135, 34560, 34560, 270, 135, 135, 34560, 270, 135, 270, 270, 34560, 270, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 34560, 34560, 135, 34560, 135, 270, 34560, 34560, 34560, 270, 135, 34560, 270, 135, 135, 135, 135, 135, 34560, 270, 135, 34560, 135, 34560, 135, 135, 270, 270, 34560, 270, 34560, 135, 270, 135, 34560, 34560, 135, 34560, 270, 135, 34560, 135, 135, 34560, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 135, 270, 34560, 34560, 135, 34560, 270, 135, 270, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 270, 34560, 34560, 270, 135, 34560, 135, 270, 270, 135, 270, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 270, 34560, 270, 34560, 135, 34560, 135, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 270, 270, 135, 270, 34560, 270, 270, 34560, 135, 34560, 34560, 270, 135, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 135, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 34560, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 34560, 270, 135, 135, 135, 135]
Prompts retrieved: 3006585 . Total input tokens: 670334443 . Total output tokens: 601394933
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.657003703992814,
    "estimated_duration": 3600.013619220287,
    "input_throughput": 5169.98349690441,
    "output_throughput": 4575.284080055066,
    "total_throughput": 9745.267576959475,
    "itl": 153.0690640104875,
    "ttft": 2140151.2763045575,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 698,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.282545231375845,
    "arrivals": 1001073,
    "finished_requests": 75240,
    "scheduler_time": 112.79751012250689
}
#Debug simulation 
Total elapsed time: 5.657099209725857. Arrivals time: 0.2641973760910332 Scheduler time: 5.2835900550708175 Scheduler overhead time: 0.0359785589389503 Adapter cache time: 0.019953244365751743 Engine time: 0.036757759749889374 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-16/adapters_256_slots_128_rate_3.2-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-16/adapters_256_slots_128_rate_3.2-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 135, 34560, 34560, 135, 34560, 270, 34560, 135, 270, 135, 34560, 270, 270, 270, 270, 34560, 135, 135, 135, 270, 34560, 135, 34560, 34560, 270, 270, 270, 135, 34560, 135, 270, 270, 135, 270, 135, 135, 270, 270, 34560, 270, 135, 270, 34560, 270, 270, 34560, 270, 34560, 135, 34560, 34560, 270, 135, 135, 34560, 270, 135, 270, 270, 34560, 270, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 34560, 34560, 135, 34560, 135, 270, 34560, 34560, 34560, 270, 135, 34560, 270, 135, 135, 135, 135, 135, 34560, 270, 135, 34560, 135, 34560, 135, 135, 270, 270, 34560, 270, 34560, 135, 270, 135, 34560, 34560, 135, 34560, 270, 135, 34560, 135, 135, 34560, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 135, 270, 34560, 34560, 135, 34560, 270, 135, 270, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 270, 34560, 34560, 270, 135, 34560, 135, 270, 270, 135, 270, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 270, 34560, 270, 34560, 135, 34560, 135, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 270, 270, 135, 270, 34560, 270, 270, 34560, 135, 34560, 34560, 270, 135, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 135, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 34560, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 34560, 270, 135, 135, 135, 135]
Prompts retrieved: 3006585 . Total input tokens: 670334443 . Total output tokens: 601394933
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.967701903078705,
    "estimated_duration": 3600.145999906541,
    "input_throughput": 5348.18754586615,
    "output_throughput": 4727.659933914303,
    "total_throughput": 10075.847479780454,
    "itl": 181.97540965564266,
    "ttft": 2122078.447913975,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 721,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2604266641451822,
    "arrivals": 1001073,
    "finished_requests": 77817,
    "scheduler_time": 107.81348044159226
}
#Debug simulation 
Total elapsed time: 5.9678159658797085. Arrivals time: 0.43750571459531784 Scheduler time: 5.429854332935065 Scheduler overhead time: 0.031712958589196205 Adapter cache time: 0.021748593542724848 Engine time: 0.032373624853789806 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-32/adapters_256_slots_128_rate_3.2-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-32/adapters_256_slots_128_rate_3.2-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 135, 34560, 34560, 135, 34560, 270, 34560, 135, 270, 135, 34560, 270, 270, 270, 270, 34560, 135, 135, 135, 270, 34560, 135, 34560, 34560, 270, 270, 270, 135, 34560, 135, 270, 270, 135, 270, 135, 135, 270, 270, 34560, 270, 135, 270, 34560, 270, 270, 34560, 270, 34560, 135, 34560, 34560, 270, 135, 135, 34560, 270, 135, 270, 270, 34560, 270, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 34560, 34560, 135, 34560, 135, 270, 34560, 34560, 34560, 270, 135, 34560, 270, 135, 135, 135, 135, 135, 34560, 270, 135, 34560, 135, 34560, 135, 135, 270, 270, 34560, 270, 34560, 135, 270, 135, 34560, 34560, 135, 34560, 270, 135, 34560, 135, 135, 34560, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 135, 270, 34560, 34560, 135, 34560, 270, 135, 270, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 270, 34560, 34560, 270, 135, 34560, 135, 270, 270, 135, 270, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 270, 34560, 270, 34560, 135, 34560, 135, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 270, 270, 135, 270, 34560, 270, 270, 34560, 135, 34560, 34560, 270, 135, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 135, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 34560, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 34560, 270, 135, 135, 135, 135]
Prompts retrieved: 3006585 . Total input tokens: 670334443 . Total output tokens: 601394933
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 6.380893968977034,
    "estimated_duration": 3600.0416239183114,
    "input_throughput": 5169.943279639792,
    "output_throughput": 4575.248488952956,
    "total_throughput": 9745.19176859275,
    "itl": 153.07016821608744,
    "ttft": 2140163.2315836754,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 698,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3104625719599463,
    "arrivals": 1001073,
    "finished_requests": 75240,
    "scheduler_time": 112.79759747997107
}
#Debug simulation 
Total elapsed time: 6.38099682610482. Arrivals time: 0.871669337619096 Scheduler time: 5.391601701732725 Scheduler overhead time: 0.03746097441762686 Adapter cache time: 0.024526676628738642 Engine time: 0.038388583809137344 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-16/adapters_256_slots_128_rate_3.2-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-16/adapters_256_slots_128_rate_3.2-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 135, 34560, 34560, 135, 34560, 270, 34560, 135, 270, 135, 34560, 270, 270, 270, 270, 34560, 135, 135, 135, 270, 34560, 135, 34560, 34560, 270, 270, 270, 135, 34560, 135, 270, 270, 135, 270, 135, 135, 270, 270, 34560, 270, 135, 270, 34560, 270, 270, 34560, 270, 34560, 135, 34560, 34560, 270, 135, 135, 34560, 270, 135, 270, 270, 34560, 270, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 34560, 34560, 135, 34560, 135, 270, 34560, 34560, 34560, 270, 135, 34560, 270, 135, 135, 135, 135, 135, 34560, 270, 135, 34560, 135, 34560, 135, 135, 270, 270, 34560, 270, 34560, 135, 270, 135, 34560, 34560, 135, 34560, 270, 135, 34560, 135, 135, 34560, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 135, 270, 34560, 34560, 135, 34560, 270, 135, 270, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 270, 34560, 34560, 270, 135, 34560, 135, 270, 270, 135, 270, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 270, 34560, 270, 34560, 135, 34560, 135, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 270, 270, 135, 270, 34560, 270, 270, 34560, 135, 34560, 34560, 270, 135, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 135, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 34560, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 34560, 270, 135, 135, 135, 135]
Prompts retrieved: 3006585 . Total input tokens: 670334443 . Total output tokens: 601394933
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 6.159738255199045,
    "estimated_duration": 3600.0411940566823,
    "input_throughput": 5348.343244457009,
    "output_throughput": 4727.7975674552845,
    "total_throughput": 10076.140811912293,
    "itl": 181.97044149241444,
    "ttft": 2122034.8551150337,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 721,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.155826262624429,
    "arrivals": 1001073,
    "finished_requests": 77817,
    "scheduler_time": 107.81327499322767
}
#Debug simulation 
Total elapsed time: 6.159842017106712. Arrivals time: 0.4650409962050617 Scheduler time: 5.591205312404782 Scheduler overhead time: 0.032359219156205654 Adapter cache time: 0.022976723965257406 Engine time: 0.03326591523364186 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-32/adapters_256_slots_128_rate_3.2-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-32/adapters_256_slots_128_rate_3.2-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 135, 34560, 34560, 135, 34560, 270, 34560, 135, 270, 135, 34560, 270, 270, 270, 270, 34560, 135, 135, 135, 270, 34560, 135, 34560, 34560, 270, 270, 270, 135, 34560, 135, 270, 270, 135, 270, 135, 135, 270, 270, 34560, 270, 135, 270, 34560, 270, 270, 34560, 270, 34560, 135, 34560, 34560, 270, 135, 135, 34560, 270, 135, 270, 270, 34560, 270, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 34560, 34560, 135, 34560, 135, 270, 34560, 34560, 34560, 270, 135, 34560, 270, 135, 135, 135, 135, 135, 34560, 270, 135, 34560, 135, 34560, 135, 135, 270, 270, 34560, 270, 34560, 135, 270, 135, 34560, 34560, 135, 34560, 270, 135, 34560, 135, 135, 34560, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 135, 270, 34560, 34560, 135, 34560, 270, 135, 270, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 270, 34560, 34560, 270, 135, 34560, 135, 270, 270, 135, 270, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 270, 34560, 270, 34560, 135, 34560, 135, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 270, 270, 135, 270, 34560, 270, 270, 34560, 135, 34560, 34560, 270, 135, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 135, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 34560, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 34560, 270, 135, 135, 135, 135]
Prompts retrieved: 3006585 . Total input tokens: 670334443 . Total output tokens: 601394933
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.801486522890627,
    "estimated_duration": 3600.0727563492233,
    "input_throughput": 5169.898571403914,
    "output_throughput": 4575.208923472721,
    "total_throughput": 9745.107494876635,
    "itl": 153.07143277183468,
    "ttft": 2140176.1667115497,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 698,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.341523757204419,
    "arrivals": 1001073,
    "finished_requests": 75240,
    "scheduler_time": 112.79766872566415
}
#Debug simulation 
Total elapsed time: 5.801632766146213. Arrivals time: 0.30593259586021304 Scheduler time: 5.382092135492712 Scheduler overhead time: 0.03648658562451601 Adapter cache time: 0.022820291109383106 Engine time: 0.03743780544027686 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-8/adapters_256_slots_128_rate_3.2-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-8/adapters_256_slots_128_rate_3.2-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 66, 34560, 34560, 66, 34560, 270, 34560, 66, 270, 66, 34560, 270, 270, 270, 270, 34560, 66, 66, 66, 270, 34560, 66, 34560, 34560, 270, 270, 270, 66, 34560, 66, 270, 270, 66, 270, 66, 66, 270, 270, 34560, 270, 66, 270, 34560, 270, 270, 34560, 270, 34560, 66, 34560, 34560, 270, 66, 66, 34560, 270, 66, 270, 270, 34560, 270, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 34560, 34560, 66, 34560, 66, 270, 34560, 34560, 34560, 270, 66, 34560, 270, 66, 66, 66, 66, 66, 34560, 270, 66, 34560, 66, 34560, 66, 66, 270, 270, 34560, 270, 34560, 66, 270, 66, 34560, 34560, 66, 34560, 270, 66, 34560, 66, 66, 34560, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 66, 270, 34560, 34560, 66, 34560, 270, 66, 270, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 270, 34560, 34560, 270, 66, 34560, 66, 270, 270, 66, 270, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 270, 34560, 270, 34560, 66, 34560, 66, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 270, 270, 66, 270, 34560, 270, 270, 34560, 66, 34560, 34560, 270, 66, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 66, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 34560, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 34560, 270, 66, 66, 66, 66]
Prompts retrieved: 3000720 . Total input tokens: 669021209 . Total output tokens: 600212181
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.910391869023442,
    "estimated_duration": 3600.037845095298,
    "input_throughput": 5387.023090999374,
    "output_throughput": 4780.187803704729,
    "total_throughput": 10167.210894704103,
    "itl": 180.40993694209212,
    "ttft": 2118429.081957568,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 589,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8026272811764186,
    "arrivals": 999127,
    "finished_requests": 78586,
    "scheduler_time": 108.93159140286858
}
#Debug simulation 
Total elapsed time: 5.9105098359286785. Arrivals time: 0.3314219992607832 Scheduler time: 5.479247215669602 Scheduler overhead time: 0.03187510836869478 Adapter cache time: 0.020625701174139977 Engine time: 0.03266645036637783 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-16/adapters_256_slots_128_rate_3.2-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-16/adapters_256_slots_128_rate_3.2-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 66, 34560, 34560, 66, 34560, 270, 34560, 66, 270, 66, 34560, 270, 270, 270, 270, 34560, 66, 66, 66, 270, 34560, 66, 34560, 34560, 270, 270, 270, 66, 34560, 66, 270, 270, 66, 270, 66, 66, 270, 270, 34560, 270, 66, 270, 34560, 270, 270, 34560, 270, 34560, 66, 34560, 34560, 270, 66, 66, 34560, 270, 66, 270, 270, 34560, 270, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 34560, 34560, 66, 34560, 66, 270, 34560, 34560, 34560, 270, 66, 34560, 270, 66, 66, 66, 66, 66, 34560, 270, 66, 34560, 66, 34560, 66, 66, 270, 270, 34560, 270, 34560, 66, 270, 66, 34560, 34560, 66, 34560, 270, 66, 34560, 66, 66, 34560, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 66, 270, 34560, 34560, 66, 34560, 270, 66, 270, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 270, 34560, 34560, 270, 66, 34560, 66, 270, 270, 66, 270, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 270, 34560, 270, 34560, 66, 34560, 66, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 270, 270, 66, 270, 34560, 270, 270, 34560, 66, 34560, 34560, 270, 66, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 66, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 34560, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 34560, 270, 66, 66, 66, 66]
Prompts retrieved: 3000720 . Total input tokens: 669021209 . Total output tokens: 600212181
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.91026543173939,
    "estimated_duration": 3600.161448695008,
    "input_throughput": 5386.838139447824,
    "output_throughput": 4780.023686503808,
    "total_throughput": 10166.861825951632,
    "itl": 180.41543330029637,
    "ttft": 2118482.2742187604,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 589,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9249863463919672,
    "arrivals": 999127,
    "finished_requests": 78586,
    "scheduler_time": 108.93191687222712
}
#Debug simulation 
Total elapsed time: 5.910371521953493. Arrivals time: 0.3158081155270338 Scheduler time: 5.494937070645392 Scheduler overhead time: 0.03179552499204874 Adapter cache time: 0.020131762139499187 Engine time: 0.032974733505398035 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-32/adapters_256_slots_128_rate_3.2-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-32/adapters_256_slots_128_rate_3.2-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 66, 34560, 34560, 66, 34560, 270, 34560, 66, 270, 66, 34560, 270, 270, 270, 270, 34560, 66, 66, 66, 270, 34560, 66, 34560, 34560, 270, 270, 270, 66, 34560, 66, 270, 270, 66, 270, 66, 66, 270, 270, 34560, 270, 66, 270, 34560, 270, 270, 34560, 270, 34560, 66, 34560, 34560, 270, 66, 66, 34560, 270, 66, 270, 270, 34560, 270, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 34560, 34560, 66, 34560, 66, 270, 34560, 34560, 34560, 270, 66, 34560, 270, 66, 66, 66, 66, 66, 34560, 270, 66, 34560, 66, 34560, 66, 66, 270, 270, 34560, 270, 34560, 66, 270, 66, 34560, 34560, 66, 34560, 270, 66, 34560, 66, 66, 34560, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 66, 270, 34560, 34560, 66, 34560, 270, 66, 270, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 270, 34560, 34560, 270, 66, 34560, 66, 270, 270, 66, 270, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 270, 34560, 270, 34560, 66, 34560, 66, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 270, 270, 66, 270, 34560, 270, 270, 34560, 66, 34560, 34560, 270, 66, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 66, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 34560, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 34560, 270, 66, 66, 66, 66]
Prompts retrieved: 3000720 . Total input tokens: 669021209 . Total output tokens: 600212181
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.736735906917602,
    "estimated_duration": 3600.0651595313884,
    "input_throughput": 5195.678181123465,
    "output_throughput": 4620.616645217964,
    "total_throughput": 9816.29482634143,
    "itl": 152.27262966659947,
    "ttft": 2136198.5878137555,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 568,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8602452289685723,
    "arrivals": 999127,
    "finished_requests": 75811,
    "scheduler_time": 113.73021602640614
}
#Debug simulation 
Total elapsed time: 5.73685096995905. Arrivals time: 0.3118869196623564 Scheduler time: 5.3113446100614965 Scheduler overhead time: 0.03681543841958046 Adapter cache time: 0.021811118815094233 Engine time: 0.03788868151605129 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-16/adapters_256_slots_128_rate_3.2-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-16/adapters_256_slots_128_rate_3.2-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 66, 34560, 34560, 66, 34560, 270, 34560, 66, 270, 66, 34560, 270, 270, 270, 270, 34560, 66, 66, 66, 270, 34560, 66, 34560, 34560, 270, 270, 270, 66, 34560, 66, 270, 270, 66, 270, 66, 66, 270, 270, 34560, 270, 66, 270, 34560, 270, 270, 34560, 270, 34560, 66, 34560, 34560, 270, 66, 66, 34560, 270, 66, 270, 270, 34560, 270, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 34560, 34560, 66, 34560, 66, 270, 34560, 34560, 34560, 270, 66, 34560, 270, 66, 66, 66, 66, 66, 34560, 270, 66, 34560, 66, 34560, 66, 66, 270, 270, 34560, 270, 34560, 66, 270, 66, 34560, 34560, 66, 34560, 270, 66, 34560, 66, 66, 34560, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 66, 270, 34560, 34560, 66, 34560, 270, 66, 270, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 270, 34560, 34560, 270, 66, 34560, 66, 270, 270, 66, 270, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 270, 34560, 270, 34560, 66, 34560, 66, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 270, 270, 66, 270, 34560, 270, 270, 34560, 66, 34560, 34560, 270, 66, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 66, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 34560, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 34560, 270, 66, 66, 66, 66]
Prompts retrieved: 3000720 . Total input tokens: 669021209 . Total output tokens: 600212181
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.765305256005377,
    "estimated_duration": 3600.086741380499,
    "input_throughput": 5386.949924590795,
    "output_throughput": 4780.12287931736,
    "total_throughput": 10167.072803908155,
    "itl": 180.41225252464378,
    "ttft": 2118448.976431063,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 589,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8514391890726907,
    "arrivals": 999127,
    "finished_requests": 78586,
    "scheduler_time": 108.93167578012076
}
#Debug simulation 
Total elapsed time: 5.765420158859342. Arrivals time: 0.2831449192017317 Scheduler time: 5.387782970443368 Scheduler overhead time: 0.030969613697379827 Adapter cache time: 0.01731977378949523 Engine time: 0.031825232319533825 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-32/adapters_256_slots_128_rate_3.2-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-32/adapters_256_slots_128_rate_3.2-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 66, 34560, 34560, 66, 34560, 270, 34560, 66, 270, 66, 34560, 270, 270, 270, 270, 34560, 66, 66, 66, 270, 34560, 66, 34560, 34560, 270, 270, 270, 66, 34560, 66, 270, 270, 66, 270, 66, 66, 270, 270, 34560, 270, 66, 270, 34560, 270, 270, 34560, 270, 34560, 66, 34560, 34560, 270, 66, 66, 34560, 270, 66, 270, 270, 34560, 270, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 34560, 34560, 66, 34560, 66, 270, 34560, 34560, 34560, 270, 66, 34560, 270, 66, 66, 66, 66, 66, 34560, 270, 66, 34560, 66, 34560, 66, 66, 270, 270, 34560, 270, 34560, 66, 270, 66, 34560, 34560, 66, 34560, 270, 66, 34560, 66, 66, 34560, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 66, 270, 34560, 34560, 66, 34560, 270, 66, 270, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 270, 34560, 34560, 270, 66, 34560, 66, 270, 270, 66, 270, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 270, 34560, 270, 34560, 66, 34560, 66, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 270, 270, 66, 270, 34560, 270, 270, 34560, 66, 34560, 34560, 270, 66, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 66, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 34560, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 34560, 270, 66, 66, 66, 66]
Prompts retrieved: 3000720 . Total input tokens: 669021209 . Total output tokens: 600212181
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 5.791922301985323,
    "estimated_duration": 3600.087621842785,
    "input_throughput": 5195.645763317711,
    "output_throughput": 4620.587815439128,
    "total_throughput": 9816.233578756839,
    "itl": 152.27347068721957,
    "ttft": 2136208.4604566023,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 568,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8826294029504111,
    "arrivals": 999127,
    "finished_requests": 75811,
    "scheduler_time": 113.73029416383945
}
#Debug simulation 
Total elapsed time: 5.792036822065711. Arrivals time: 0.31679266411811113 Scheduler time: 5.362222958356142 Scheduler overhead time: 0.03683152748271823 Adapter cache time: 0.021171882282942533 Engine time: 0.037881029304116964 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-16/adapters_256_slots_128_rate_3.2-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-16/adapters_256_slots_128_rate_3.2-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 66, 34560, 34560, 66, 34560, 270, 34560, 66, 270, 66, 34560, 270, 270, 270, 270, 34560, 66, 66, 66, 270, 34560, 66, 34560, 34560, 270, 270, 270, 66, 34560, 66, 270, 270, 66, 270, 66, 66, 270, 270, 34560, 270, 66, 270, 34560, 270, 270, 34560, 270, 34560, 66, 34560, 34560, 270, 66, 66, 34560, 270, 66, 270, 270, 34560, 270, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 34560, 34560, 66, 34560, 66, 270, 34560, 34560, 34560, 270, 66, 34560, 270, 66, 66, 66, 66, 66, 34560, 270, 66, 34560, 66, 34560, 66, 66, 270, 270, 34560, 270, 34560, 66, 270, 66, 34560, 34560, 66, 34560, 270, 66, 34560, 66, 66, 34560, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 66, 270, 34560, 34560, 66, 34560, 270, 66, 270, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 270, 34560, 34560, 270, 66, 34560, 66, 270, 270, 66, 270, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 270, 34560, 270, 34560, 66, 34560, 66, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 270, 270, 66, 270, 34560, 270, 270, 34560, 66, 34560, 34560, 270, 66, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 66, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 34560, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 34560, 270, 66, 66, 66, 66]
Prompts retrieved: 3000720 . Total input tokens: 669021209 . Total output tokens: 600212181
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.940248968079686,
    "estimated_duration": 3600.192384640186,
    "input_throughput": 5386.821293978781,
    "output_throughput": 4780.092328793686,
    "total_throughput": 10166.913622772467,
    "itl": 180.40830619127055,
    "ttft": 2118464.3682069676,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 589,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7611396236973558,
    "arrivals": 999127,
    "finished_requests": 78587,
    "scheduler_time": 108.93750408457184
}
#Debug simulation 
Total elapsed time: 5.940369313117117. Arrivals time: 0.3336903271265328 Scheduler time: 5.50635605212301 Scheduler overhead time: 0.03178107412531972 Adapter cache time: 0.020671912003308535 Engine time: 0.03310474939644337 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-32/adapters_256_slots_128_rate_3.2-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-32/adapters_256_slots_128_rate_3.2-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 66, 34560, 34560, 66, 34560, 270, 34560, 66, 270, 66, 34560, 270, 270, 270, 270, 34560, 66, 66, 66, 270, 34560, 66, 34560, 34560, 270, 270, 270, 66, 34560, 66, 270, 270, 66, 270, 66, 66, 270, 270, 34560, 270, 66, 270, 34560, 270, 270, 34560, 270, 34560, 66, 34560, 34560, 270, 66, 66, 34560, 270, 66, 270, 270, 34560, 270, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 34560, 34560, 66, 34560, 66, 270, 34560, 34560, 34560, 270, 66, 34560, 270, 66, 66, 66, 66, 66, 34560, 270, 66, 34560, 66, 34560, 66, 66, 270, 270, 34560, 270, 34560, 66, 270, 66, 34560, 34560, 66, 34560, 270, 66, 34560, 66, 66, 34560, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 66, 270, 34560, 34560, 66, 34560, 270, 66, 270, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 270, 34560, 34560, 270, 66, 34560, 66, 270, 270, 66, 270, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 270, 34560, 270, 34560, 66, 34560, 66, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 270, 270, 66, 270, 34560, 270, 270, 34560, 66, 34560, 34560, 270, 66, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 66, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 34560, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 34560, 270, 66, 66, 66, 66]
Prompts retrieved: 3000720 . Total input tokens: 669021209 . Total output tokens: 600212181
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.99521145503968,
    "estimated_duration": 3600.114343671144,
    "input_throughput": 5195.607198666412,
    "output_throughput": 4620.553519152195,
    "total_throughput": 9816.160717818606,
    "itl": 152.274535080459,
    "ttft": 2136219.6030249707,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 568,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9092892056703523,
    "arrivals": 999127,
    "finished_requests": 75811,
    "scheduler_time": 113.73035618950165
}
#Debug simulation 
Total elapsed time: 5.995318631641567. Arrivals time: 0.32014144910499454 Scheduler time: 5.55673707742244 Scheduler overhead time: 0.03870376152917743 Adapter cache time: 0.022091439925134182 Engine time: 0.03971095848828554 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-8/adapters_256_slots_128_rate_3.2-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-8/adapters_256_slots_128_rate_3.2-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 33, 34560, 34560, 33, 34560, 270, 34560, 33, 270, 33, 34560, 270, 270, 270, 270, 34560, 33, 33, 33, 270, 34560, 33, 34560, 34560, 270, 270, 270, 33, 34560, 33, 270, 270, 33, 270, 33, 33, 270, 270, 34560, 270, 33, 270, 34560, 270, 270, 34560, 270, 34560, 33, 34560, 34560, 270, 33, 33, 34560, 270, 33, 270, 270, 34560, 270, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 34560, 34560, 33, 34560, 33, 270, 34560, 34560, 34560, 270, 33, 34560, 270, 33, 33, 33, 33, 33, 34560, 270, 33, 34560, 33, 34560, 33, 33, 270, 270, 34560, 270, 34560, 33, 270, 33, 34560, 34560, 33, 34560, 270, 33, 34560, 33, 33, 34560, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 33, 270, 34560, 34560, 33, 34560, 270, 33, 270, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 270, 34560, 34560, 270, 33, 34560, 33, 270, 270, 33, 270, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 270, 34560, 270, 34560, 33, 34560, 33, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 270, 270, 33, 270, 34560, 270, 270, 34560, 33, 34560, 34560, 270, 33, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 33, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 34560, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 34560, 270, 33, 33, 33, 33]
Prompts retrieved: 2997915 . Total input tokens: 668391315 . Total output tokens: 599640789
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.820164436008781,
    "estimated_duration": 3600.183680798569,
    "input_throughput": 5441.314870816462,
    "output_throughput": 4786.09857933081,
    "total_throughput": 10227.413450147273,
    "itl": 178.92311478216922,
    "ttft": 2114467.2647898635,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 513,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5700302126375212,
    "arrivals": 998127,
    "finished_requests": 79389,
    "scheduler_time": 109.25432350888721
}
#Debug simulation 
Total elapsed time: 5.820270758122206. Arrivals time: 0.3058255654759705 Scheduler time: 5.417258542496711 Scheduler overhead time: 0.03153500286862254 Adapter cache time: 0.01861910754814744 Engine time: 0.032541890162974596 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-16/adapters_256_slots_128_rate_3.2-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-16/adapters_256_slots_128_rate_3.2-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 33, 34560, 34560, 33, 34560, 270, 34560, 33, 270, 33, 34560, 270, 270, 270, 270, 34560, 33, 33, 33, 270, 34560, 33, 34560, 34560, 270, 270, 270, 33, 34560, 33, 270, 270, 33, 270, 33, 33, 270, 270, 34560, 270, 33, 270, 34560, 270, 270, 34560, 270, 34560, 33, 34560, 34560, 270, 33, 33, 34560, 270, 33, 270, 270, 34560, 270, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 34560, 34560, 33, 34560, 33, 270, 34560, 34560, 34560, 270, 33, 34560, 270, 33, 33, 33, 33, 33, 34560, 270, 33, 34560, 33, 34560, 33, 33, 270, 270, 34560, 270, 34560, 33, 270, 33, 34560, 34560, 33, 34560, 270, 33, 34560, 33, 33, 34560, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 33, 270, 34560, 34560, 33, 34560, 270, 33, 270, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 270, 34560, 34560, 270, 33, 34560, 33, 270, 270, 33, 270, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 270, 34560, 270, 34560, 33, 34560, 33, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 270, 270, 33, 270, 34560, 270, 270, 34560, 33, 34560, 34560, 270, 33, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 33, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 34560, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 34560, 270, 33, 33, 33, 33]
Prompts retrieved: 2997915 . Total input tokens: 668391315 . Total output tokens: 599640789
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.881696907337755,
    "estimated_duration": 3600.086372546604,
    "input_throughput": 5441.314449948357,
    "output_throughput": 4786.226833722152,
    "total_throughput": 10227.541283670509,
    "itl": 178.92949362552096,
    "ttft": 2114435.669057009,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 513,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.669958042325457,
    "arrivals": 998127,
    "finished_requests": 79387,
    "scheduler_time": 109.24851530146258
}
#Debug simulation 
Total elapsed time: 5.881832770071924. Arrivals time: 0.30379891861230135 Scheduler time: 5.4790597297251225 Scheduler overhead time: 0.03203705418854952 Adapter cache time: 0.01897797593846917 Engine time: 0.033147471491247416 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-32/adapters_256_slots_128_rate_3.2-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-32/adapters_256_slots_128_rate_3.2-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 33, 34560, 34560, 33, 34560, 270, 34560, 33, 270, 33, 34560, 270, 270, 270, 270, 34560, 33, 33, 33, 270, 34560, 33, 34560, 34560, 270, 270, 270, 33, 34560, 33, 270, 270, 33, 270, 33, 33, 270, 270, 34560, 270, 33, 270, 34560, 270, 270, 34560, 270, 34560, 33, 34560, 34560, 270, 33, 33, 34560, 270, 33, 270, 270, 34560, 270, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 34560, 34560, 33, 34560, 33, 270, 34560, 34560, 34560, 270, 33, 34560, 270, 33, 33, 33, 33, 33, 34560, 270, 33, 34560, 33, 34560, 33, 33, 270, 270, 34560, 270, 34560, 33, 270, 33, 34560, 34560, 33, 34560, 270, 33, 34560, 33, 33, 34560, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 33, 270, 34560, 34560, 33, 34560, 270, 33, 270, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 270, 34560, 34560, 270, 33, 34560, 33, 270, 270, 33, 270, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 270, 34560, 270, 34560, 33, 34560, 33, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 270, 270, 33, 270, 34560, 270, 270, 34560, 33, 34560, 34560, 270, 33, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 33, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 34560, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 34560, 270, 33, 33, 33, 33]
Prompts retrieved: 2997915 . Total input tokens: 668391315 . Total output tokens: 599640789
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 6.064170816913247,
    "estimated_duration": 3600.022448914942,
    "input_throughput": 5260.783028091465,
    "output_throughput": 4629.875851197451,
    "total_throughput": 9890.658879288916,
    "itl": 151.8750305656709,
    "ttft": 2132221.6722466266,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 506,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6509749631770054,
    "arrivals": 998127,
    "finished_requests": 76701,
    "scheduler_time": 113.86969461723181
}
#Debug simulation 
Total elapsed time: 6.064290632959455. Arrivals time: 0.4165955064818263 Scheduler time: 5.530858021695167 Scheduler overhead time: 0.03809743234887719 Adapter cache time: 0.02234517876058817 Engine time: 0.0387859083712101 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-16/adapters_256_slots_128_rate_3.2-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-16/adapters_256_slots_128_rate_3.2-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 33, 34560, 34560, 33, 34560, 270, 34560, 33, 270, 33, 34560, 270, 270, 270, 270, 34560, 33, 33, 33, 270, 34560, 33, 34560, 34560, 270, 270, 270, 33, 34560, 33, 270, 270, 33, 270, 33, 33, 270, 270, 34560, 270, 33, 270, 34560, 270, 270, 34560, 270, 34560, 33, 34560, 34560, 270, 33, 33, 34560, 270, 33, 270, 270, 34560, 270, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 34560, 34560, 33, 34560, 33, 270, 34560, 34560, 34560, 270, 33, 34560, 270, 33, 33, 33, 33, 33, 34560, 270, 33, 34560, 33, 34560, 33, 33, 270, 270, 34560, 270, 34560, 33, 270, 33, 34560, 34560, 33, 34560, 270, 33, 34560, 33, 33, 34560, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 33, 270, 34560, 34560, 33, 34560, 270, 33, 270, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 270, 34560, 34560, 270, 33, 34560, 33, 270, 270, 33, 270, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 270, 34560, 270, 34560, 33, 34560, 33, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 270, 270, 33, 270, 34560, 270, 270, 34560, 33, 34560, 34560, 270, 33, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 33, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 34560, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 34560, 270, 33, 33, 33, 33]
Prompts retrieved: 2997915 . Total input tokens: 668391315 . Total output tokens: 599640789
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.939197986852378,
    "estimated_duration": 3600.027300035934,
    "input_throughput": 5441.403735967355,
    "output_throughput": 4786.305370469832,
    "total_throughput": 10227.709106437187,
    "itl": 178.92702634921176,
    "ttft": 2114406.7251392663,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 513,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6111203164700374,
    "arrivals": 998127,
    "finished_requests": 79387,
    "scheduler_time": 109.24828051663613
}
#Debug simulation 
Total elapsed time: 5.939291446004063. Arrivals time: 0.3200753824785352 Scheduler time: 5.5190910724923015 Scheduler overhead time: 0.03222073242068291 Adapter cache time: 0.019778584130108356 Engine time: 0.033278063870966434 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-32/adapters_256_slots_128_rate_3.2-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-32/adapters_256_slots_128_rate_3.2-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 33, 34560, 34560, 33, 34560, 270, 34560, 33, 270, 33, 34560, 270, 270, 270, 270, 34560, 33, 33, 33, 270, 34560, 33, 34560, 34560, 270, 270, 270, 33, 34560, 33, 270, 270, 33, 270, 33, 33, 270, 270, 34560, 270, 33, 270, 34560, 270, 270, 34560, 270, 34560, 33, 34560, 34560, 270, 33, 33, 34560, 270, 33, 270, 270, 34560, 270, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 34560, 34560, 33, 34560, 33, 270, 34560, 34560, 34560, 270, 33, 34560, 270, 33, 33, 33, 33, 33, 34560, 270, 33, 34560, 33, 34560, 33, 33, 270, 270, 34560, 270, 34560, 33, 270, 33, 34560, 34560, 33, 34560, 270, 33, 34560, 33, 33, 34560, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 33, 270, 34560, 34560, 33, 34560, 270, 33, 270, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 270, 34560, 34560, 270, 33, 34560, 33, 270, 270, 33, 270, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 270, 34560, 270, 34560, 33, 34560, 33, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 270, 270, 33, 270, 34560, 270, 270, 34560, 33, 34560, 34560, 270, 33, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 33, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 34560, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 34560, 270, 33, 33, 33, 33]
Prompts retrieved: 2997915 . Total input tokens: 668391315 . Total output tokens: 599640789
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 5.817842175718397,
    "estimated_duration": 3600.0402562873523,
    "input_throughput": 5260.757005959522,
    "output_throughput": 4629.852949808126,
    "total_throughput": 9890.609955767648,
    "itl": 151.8756875306873,
    "ttft": 2132230.312018041,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 506,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6687062470614962,
    "arrivals": 998127,
    "finished_requests": 76701,
    "scheduler_time": 113.86977070576937
}
#Debug simulation 
Total elapsed time: 5.817949258722365. Arrivals time: 0.31525158043950796 Scheduler time: 5.3876965385861695 Scheduler overhead time: 0.037549523171037436 Adapter cache time: 0.021563398651778698 Engine time: 0.03851613961160183 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-16/adapters_256_slots_128_rate_3.2-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-16/adapters_256_slots_128_rate_3.2-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 33, 34560, 34560, 33, 34560, 270, 34560, 33, 270, 33, 34560, 270, 270, 270, 270, 34560, 33, 33, 33, 270, 34560, 33, 34560, 34560, 270, 270, 270, 33, 34560, 33, 270, 270, 33, 270, 33, 33, 270, 270, 34560, 270, 33, 270, 34560, 270, 270, 34560, 270, 34560, 33, 34560, 34560, 270, 33, 33, 34560, 270, 33, 270, 270, 34560, 270, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 34560, 34560, 33, 34560, 33, 270, 34560, 34560, 34560, 270, 33, 34560, 270, 33, 33, 33, 33, 33, 34560, 270, 33, 34560, 33, 34560, 33, 33, 270, 270, 34560, 270, 34560, 33, 270, 33, 34560, 34560, 33, 34560, 270, 33, 34560, 33, 33, 34560, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 33, 270, 34560, 34560, 33, 34560, 270, 33, 270, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 270, 34560, 34560, 270, 33, 34560, 33, 270, 270, 33, 270, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 270, 34560, 270, 34560, 33, 34560, 33, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 270, 270, 33, 270, 34560, 270, 270, 34560, 33, 34560, 34560, 270, 33, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 33, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 34560, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 34560, 270, 33, 33, 33, 33]
Prompts retrieved: 2997915 . Total input tokens: 668391315 . Total output tokens: 599640789
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.985850497614592,
    "estimated_duration": 3600.147442731777,
    "input_throughput": 5441.369641554289,
    "output_throughput": 4786.146754846605,
    "total_throughput": 10227.516396400893,
    "itl": 178.92151316983293,
    "ttft": 2114450.3679987397,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 513,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5338958012847985,
    "arrivals": 998127,
    "finished_requests": 79389,
    "scheduler_time": 109.25421985338866
}
#Debug simulation 
Total elapsed time: 5.985967242624611. Arrivals time: 0.306322431191802 Scheduler time: 5.579834294971079 Scheduler overhead time: 0.032587011344730854 Adapter cache time: 0.019115976989269257 Engine time: 0.033096295315772295 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-32/adapters_256_slots_128_rate_3.2-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-32/adapters_256_slots_128_rate_3.2-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 33, 34560, 34560, 33, 34560, 270, 34560, 33, 270, 33, 34560, 270, 270, 270, 270, 34560, 33, 33, 33, 270, 34560, 33, 34560, 34560, 270, 270, 270, 33, 34560, 33, 270, 270, 33, 270, 33, 33, 270, 270, 34560, 270, 33, 270, 34560, 270, 270, 34560, 270, 34560, 33, 34560, 34560, 270, 33, 33, 34560, 270, 33, 270, 270, 34560, 270, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 34560, 34560, 33, 34560, 33, 270, 34560, 34560, 34560, 270, 33, 34560, 270, 33, 33, 33, 33, 33, 34560, 270, 33, 34560, 33, 34560, 33, 33, 270, 270, 34560, 270, 34560, 33, 270, 33, 34560, 34560, 33, 34560, 270, 33, 34560, 33, 33, 34560, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 33, 270, 34560, 34560, 33, 34560, 270, 33, 270, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 270, 34560, 34560, 270, 33, 34560, 33, 270, 270, 33, 270, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 270, 34560, 270, 34560, 33, 34560, 33, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 270, 270, 33, 270, 34560, 270, 270, 34560, 33, 34560, 34560, 270, 33, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 33, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 34560, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 34560, 270, 33, 33, 33, 33]
Prompts retrieved: 2997915 . Total input tokens: 668391315 . Total output tokens: 599640789
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.994647107087076,
    "estimated_duration": 3600.063959652316,
    "input_throughput": 5260.722368340664,
    "output_throughput": 4629.822466156883,
    "total_throughput": 9890.544834497547,
    "itl": 151.87660406728853,
    "ttft": 2132240.814753964,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 506,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6923479589074832,
    "arrivals": 998127,
    "finished_requests": 76701,
    "scheduler_time": 113.86983235890507
}
#Debug simulation 
Total elapsed time: 5.994742838200182. Arrivals time: 0.3935733316466212 Scheduler time: 5.486395795829594 Scheduler overhead time: 0.03767991065979004 Adapter cache time: 0.020617606583982706 Engine time: 0.03891678899526596 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-8/adapters_256_slots_128_rate_3.2-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-8/adapters_256_slots_128_rate_3.2-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 66, 34560, 34560, 66, 34560, 135, 34560, 66, 135, 66, 34560, 135, 135, 135, 135, 34560, 66, 66, 66, 135, 34560, 66, 34560, 34560, 135, 135, 135, 66, 34560, 66, 135, 135, 66, 135, 66, 66, 135, 135, 34560, 135, 66, 135, 34560, 135, 135, 34560, 135, 34560, 66, 34560, 34560, 135, 66, 66, 34560, 135, 66, 135, 135, 34560, 135, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 34560, 34560, 66, 34560, 66, 135, 34560, 34560, 34560, 135, 66, 34560, 135, 66, 66, 66, 66, 66, 34560, 135, 66, 34560, 66, 34560, 66, 66, 135, 135, 34560, 135, 34560, 66, 135, 66, 34560, 34560, 66, 34560, 135, 66, 34560, 66, 66, 34560, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 66, 135, 34560, 34560, 66, 34560, 135, 66, 135, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 135, 34560, 34560, 135, 66, 34560, 66, 135, 135, 66, 135, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 135, 34560, 135, 34560, 66, 34560, 66, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 135, 135, 66, 135, 34560, 135, 135, 34560, 66, 34560, 34560, 135, 66, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 66, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 34560, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 34560, 135, 66, 66, 66, 66]
Prompts retrieved: 2989245 . Total input tokens: 666447743 . Total output tokens: 597918174
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 6.1522289789281785,
    "estimated_duration": 3600.0074914496427,
    "input_throughput": 5475.547494503244,
    "output_throughput": 4840.5307603909905,
    "total_throughput": 10316.078254894235,
    "itl": 177.85130052580547,
    "ttft": 2114006.8546877713,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 411,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2578604627563694,
    "arrivals": 995247,
    "finished_requests": 79683,
    "scheduler_time": 110.33348222247984
}
#Debug simulation 
Total elapsed time: 6.152328614611179. Arrivals time: 0.43425107141956687 Scheduler time: 5.618289560079575 Scheduler overhead time: 0.032915492076426744 Adapter cache time: 0.017989085987210274 Engine time: 0.033857015892863274 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-16/adapters_256_slots_128_rate_3.2-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-16/adapters_256_slots_128_rate_3.2-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 66, 34560, 34560, 66, 34560, 135, 34560, 66, 135, 66, 34560, 135, 135, 135, 135, 34560, 66, 66, 66, 135, 34560, 66, 34560, 34560, 135, 135, 135, 66, 34560, 66, 135, 135, 66, 135, 66, 66, 135, 135, 34560, 135, 66, 135, 34560, 135, 135, 34560, 135, 34560, 66, 34560, 34560, 135, 66, 66, 34560, 135, 66, 135, 135, 34560, 135, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 34560, 34560, 66, 34560, 66, 135, 34560, 34560, 34560, 135, 66, 34560, 135, 66, 66, 66, 66, 66, 34560, 135, 66, 34560, 66, 34560, 66, 66, 135, 135, 34560, 135, 34560, 66, 135, 66, 34560, 34560, 66, 34560, 135, 66, 34560, 66, 66, 34560, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 66, 135, 34560, 34560, 66, 34560, 135, 66, 135, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 135, 34560, 34560, 135, 66, 34560, 66, 135, 135, 66, 135, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 135, 34560, 135, 34560, 66, 34560, 66, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 135, 135, 66, 135, 34560, 135, 135, 34560, 66, 34560, 34560, 135, 66, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 66, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 34560, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 34560, 135, 66, 66, 66, 66]
Prompts retrieved: 2989245 . Total input tokens: 666447743 . Total output tokens: 597918174
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 6.3849789053201675,
    "estimated_duration": 3600.0936559882434,
    "input_throughput": 5475.41644290611,
    "output_throughput": 4840.4149072662085,
    "total_throughput": 10315.831350172319,
    "itl": 177.8548979104618,
    "ttft": 2114044.620507623,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 411,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3437259556865384,
    "arrivals": 995247,
    "finished_requests": 79683,
    "scheduler_time": 110.3337812681275
}
#Debug simulation 
Total elapsed time: 6.385047561023384. Arrivals time: 0.7266661110334098 Scheduler time: 5.560297265648842 Scheduler overhead time: 0.03258106857538223 Adapter cache time: 0.017219741363078356 Engine time: 0.03337585926055908 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-32/adapters_256_slots_128_rate_3.2-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-32/adapters_256_slots_128_rate_3.2-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 66, 34560, 34560, 66, 34560, 135, 34560, 66, 135, 66, 34560, 135, 135, 135, 135, 34560, 66, 66, 66, 135, 34560, 66, 34560, 34560, 135, 135, 135, 66, 34560, 66, 135, 135, 66, 135, 66, 66, 135, 135, 34560, 135, 66, 135, 34560, 135, 135, 34560, 135, 34560, 66, 34560, 34560, 135, 66, 66, 34560, 135, 66, 135, 135, 34560, 135, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 34560, 34560, 66, 34560, 66, 135, 34560, 34560, 34560, 135, 66, 34560, 135, 66, 66, 66, 66, 66, 34560, 135, 66, 34560, 66, 34560, 66, 66, 135, 135, 34560, 135, 34560, 66, 135, 66, 34560, 34560, 66, 34560, 135, 66, 34560, 66, 66, 34560, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 66, 135, 34560, 34560, 66, 34560, 135, 66, 135, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 135, 34560, 34560, 135, 66, 34560, 66, 135, 135, 66, 135, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 135, 34560, 135, 34560, 66, 34560, 66, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 135, 135, 66, 135, 34560, 135, 135, 34560, 66, 34560, 34560, 135, 66, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 66, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 34560, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 34560, 135, 66, 66, 66, 66]
Prompts retrieved: 2989245 . Total input tokens: 666447743 . Total output tokens: 597918174
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.92699034884572,
    "estimated_duration": 3600.0872786527843,
    "input_throughput": 5271.796356865617,
    "output_throughput": 4669.545402324492,
    "total_throughput": 9941.341759190109,
    "itl": 150.57714169164026,
    "ttft": 2133633.6273324657,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 398,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3027145728282705,
    "arrivals": 995247,
    "finished_requests": 76746,
    "scheduler_time": 114.94041684480601
}
#Debug simulation 
Total elapsed time: 5.927110762801021. Arrivals time: 0.37548452941700816 Scheduler time: 5.440657104831189 Scheduler overhead time: 0.037539859768003225 Adapter cache time: 0.017550261225551367 Engine time: 0.038332272320985794 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-16/adapters_256_slots_128_rate_3.2-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-16/adapters_256_slots_128_rate_3.2-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 66, 34560, 34560, 66, 34560, 135, 34560, 66, 135, 66, 34560, 135, 135, 135, 135, 34560, 66, 66, 66, 135, 34560, 66, 34560, 34560, 135, 135, 135, 66, 34560, 66, 135, 135, 66, 135, 66, 66, 135, 135, 34560, 135, 66, 135, 34560, 135, 135, 34560, 135, 34560, 66, 34560, 34560, 135, 66, 66, 34560, 135, 66, 135, 135, 34560, 135, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 34560, 34560, 66, 34560, 66, 135, 34560, 34560, 34560, 135, 66, 34560, 135, 66, 66, 66, 66, 66, 34560, 135, 66, 34560, 66, 34560, 66, 66, 135, 135, 34560, 135, 34560, 66, 135, 66, 34560, 34560, 66, 34560, 135, 66, 34560, 66, 66, 34560, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 66, 135, 34560, 34560, 66, 34560, 135, 66, 135, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 135, 34560, 34560, 135, 66, 34560, 66, 135, 135, 66, 135, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 135, 34560, 135, 34560, 66, 34560, 66, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 135, 135, 66, 135, 34560, 135, 135, 34560, 66, 34560, 34560, 135, 66, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 66, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 34560, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 34560, 135, 66, 66, 66, 66]
Prompts retrieved: 2989245 . Total input tokens: 666447743 . Total output tokens: 597918174
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 6.197887759655714,
    "estimated_duration": 3600.039486900789,
    "input_throughput": 5475.498830422475,
    "output_throughput": 4840.4877400391215,
    "total_throughput": 10315.986570461597,
    "itl": 177.85270068620497,
    "ttft": 2114018.90125738,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 411,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2897913736524063,
    "arrivals": 995247,
    "finished_requests": 79683,
    "scheduler_time": 110.33354676269592
}
#Debug simulation 
Total elapsed time: 6.197994585614651. Arrivals time: 0.42845349246636033 Scheduler time: 5.669316315092146 Scheduler overhead time: 0.033069567289203405 Adapter cache time: 0.017848734743893147 Engine time: 0.03411712683737278 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-32/adapters_256_slots_128_rate_3.2-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-32/adapters_256_slots_128_rate_3.2-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 66, 34560, 34560, 66, 34560, 135, 34560, 66, 135, 66, 34560, 135, 135, 135, 135, 34560, 66, 66, 66, 135, 34560, 66, 34560, 34560, 135, 135, 135, 66, 34560, 66, 135, 135, 66, 135, 66, 66, 135, 135, 34560, 135, 66, 135, 34560, 135, 135, 34560, 135, 34560, 66, 34560, 34560, 135, 66, 66, 34560, 135, 66, 135, 135, 34560, 135, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 34560, 34560, 66, 34560, 66, 135, 34560, 34560, 34560, 135, 66, 34560, 135, 66, 66, 66, 66, 66, 34560, 135, 66, 34560, 66, 34560, 66, 66, 135, 135, 34560, 135, 34560, 66, 135, 66, 34560, 34560, 66, 34560, 135, 66, 34560, 66, 66, 34560, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 66, 135, 34560, 34560, 66, 34560, 135, 66, 135, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 135, 34560, 34560, 135, 66, 34560, 66, 135, 135, 66, 135, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 135, 34560, 135, 34560, 66, 34560, 66, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 135, 135, 66, 135, 34560, 135, 135, 34560, 66, 34560, 34560, 135, 66, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 66, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 34560, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 34560, 135, 66, 66, 66, 66]
Prompts retrieved: 2989245 . Total input tokens: 666447743 . Total output tokens: 597918174
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 6.247351733036339,
    "estimated_duration": 3600.103577445415,
    "input_throughput": 5271.7724897979715,
    "output_throughput": 4669.524261834905,
    "total_throughput": 9941.296751632875,
    "itl": 150.57772740118722,
    "ttft": 2133641.2484949958,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 398,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3189368112757853,
    "arrivals": 995247,
    "finished_requests": 76746,
    "scheduler_time": 114.9404933990017
}
#Debug simulation 
Total elapsed time: 6.247469685971737. Arrivals time: 0.6945860334672034 Scheduler time: 5.440999140031636 Scheduler overhead time: 0.03785555204376578 Adapter cache time: 0.017622819170355797 Engine time: 0.03886224841699004 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-16/adapters_256_slots_128_rate_3.2-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-16/adapters_256_slots_128_rate_3.2-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 66, 34560, 34560, 66, 34560, 135, 34560, 66, 135, 66, 34560, 135, 135, 135, 135, 34560, 66, 66, 66, 135, 34560, 66, 34560, 34560, 135, 135, 135, 66, 34560, 66, 135, 135, 66, 135, 66, 66, 135, 135, 34560, 135, 66, 135, 34560, 135, 135, 34560, 135, 34560, 66, 34560, 34560, 135, 66, 66, 34560, 135, 66, 135, 135, 34560, 135, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 34560, 34560, 66, 34560, 66, 135, 34560, 34560, 34560, 135, 66, 34560, 135, 66, 66, 66, 66, 66, 34560, 135, 66, 34560, 66, 34560, 66, 66, 135, 135, 34560, 135, 34560, 66, 135, 66, 34560, 34560, 66, 34560, 135, 66, 34560, 66, 66, 34560, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 66, 135, 34560, 34560, 66, 34560, 135, 66, 135, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 135, 34560, 34560, 135, 66, 34560, 66, 135, 135, 66, 135, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 135, 34560, 135, 34560, 66, 34560, 66, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 135, 135, 66, 135, 34560, 135, 135, 34560, 66, 34560, 34560, 135, 66, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 66, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 34560, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 34560, 135, 66, 66, 66, 66]
Prompts retrieved: 2989245 . Total input tokens: 666447743 . Total output tokens: 597918174
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.9790206821635365,
    "estimated_duration": 3600.167689459196,
    "input_throughput": 5475.561335022482,
    "output_throughput": 4840.5498030059225,
    "total_throughput": 10316.111138028406,
    "itl": 177.84949703359362,
    "ttft": 2114037.6799250864,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 411,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2289106712047875,
    "arrivals": 995247,
    "finished_requests": 79687,
    "scheduler_time": 110.33934520875896
}
#Debug simulation 
Total elapsed time: 5.979144854936749. Arrivals time: 0.38860585493966937 Scheduler time: 5.494555710349232 Scheduler overhead time: 0.03231231402605772 Adapter cache time: 0.015604618936777115 Engine time: 0.0331909223459661 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-32/adapters_256_slots_128_rate_3.2-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-32/adapters_256_slots_128_rate_3.2-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 66, 34560, 34560, 66, 34560, 135, 34560, 66, 135, 66, 34560, 135, 135, 135, 135, 34560, 66, 66, 66, 135, 34560, 66, 34560, 34560, 135, 135, 135, 66, 34560, 66, 135, 135, 66, 135, 66, 66, 135, 135, 34560, 135, 66, 135, 34560, 135, 135, 34560, 135, 34560, 66, 34560, 34560, 135, 66, 66, 34560, 135, 66, 135, 135, 34560, 135, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 34560, 34560, 66, 34560, 66, 135, 34560, 34560, 34560, 135, 66, 34560, 135, 66, 66, 66, 66, 66, 34560, 135, 66, 34560, 66, 34560, 66, 66, 135, 135, 34560, 135, 34560, 66, 135, 66, 34560, 34560, 66, 34560, 135, 66, 34560, 66, 66, 34560, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 66, 135, 34560, 34560, 66, 34560, 135, 66, 135, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 135, 34560, 34560, 135, 66, 34560, 66, 135, 135, 66, 135, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 135, 34560, 135, 34560, 66, 34560, 66, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 135, 135, 66, 135, 34560, 135, 135, 34560, 66, 34560, 34560, 135, 66, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 66, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 34560, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 34560, 135, 66, 66, 66, 66]
Prompts retrieved: 2989245 . Total input tokens: 666447743 . Total output tokens: 597918174
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 6.1366507932543755,
    "estimated_duration": 3600.121488965069,
    "input_throughput": 5271.7462613896105,
    "output_throughput": 4669.501029764585,
    "total_throughput": 9941.247291154195,
    "itl": 150.57839851759516,
    "ttft": 2133648.7138630957,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 398,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3367938489466924,
    "arrivals": 995247,
    "finished_requests": 76746,
    "scheduler_time": 114.94054788100229
}
#Debug simulation 
Total elapsed time: 6.136751507874578. Arrivals time: 0.390904544852674 Scheduler time: 5.630494830198586 Scheduler overhead time: 0.039204359985888004 Adapter cache time: 0.018164152279496193 Engine time: 0.03972984943538904 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-8/adapters_256_slots_128_rate_3.2-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-8/adapters_256_slots_128_rate_3.2-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 33, 34560, 34560, 33, 34560, 135, 34560, 33, 135, 33, 34560, 135, 135, 135, 135, 34560, 33, 33, 33, 135, 34560, 33, 34560, 34560, 135, 135, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 33, 135, 135, 34560, 135, 33, 135, 34560, 135, 135, 34560, 135, 34560, 33, 34560, 34560, 135, 33, 33, 34560, 135, 33, 135, 135, 34560, 135, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 34560, 34560, 33, 34560, 33, 135, 34560, 34560, 34560, 135, 33, 34560, 135, 33, 33, 33, 33, 33, 34560, 135, 33, 34560, 33, 34560, 33, 33, 135, 135, 34560, 135, 34560, 33, 135, 33, 34560, 34560, 33, 34560, 135, 33, 34560, 33, 33, 34560, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 33, 135, 34560, 34560, 33, 34560, 135, 33, 135, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 135, 34560, 34560, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 135, 34560, 135, 34560, 33, 34560, 33, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 135, 135, 33, 135, 34560, 135, 135, 34560, 33, 34560, 34560, 135, 33, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 33, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 34560, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 34560, 135, 33, 33, 33, 33]
Prompts retrieved: 2986440 . Total input tokens: 665820289 . Total output tokens: 597372628
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 6.312493592035025,
    "estimated_duration": 3600.1194790811737,
    "input_throughput": 5555.5647850622445,
    "output_throughput": 4859.722323567228,
    "total_throughput": 10415.287108629473,
    "itl": 175.8990768730907,
    "ttft": 2102910.649509904,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 351,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0742311981203978,
    "arrivals": 994382,
    "finished_requests": 80348,
    "scheduler_time": 110.97289082213659
}
#Debug simulation 
Total elapsed time: 6.312600275035948. Arrivals time: 0.3452259423211217 Scheduler time: 5.867103342432529 Scheduler overhead time: 0.03339165169745684 Adapter cache time: 0.01696023577824235 Engine time: 0.034489565063267946 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-16/adapters_256_slots_128_rate_3.2-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-16/adapters_256_slots_128_rate_3.2-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 33, 34560, 34560, 33, 34560, 135, 34560, 33, 135, 33, 34560, 135, 135, 135, 135, 34560, 33, 33, 33, 135, 34560, 33, 34560, 34560, 135, 135, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 33, 135, 135, 34560, 135, 33, 135, 34560, 135, 135, 34560, 135, 34560, 33, 34560, 34560, 135, 33, 33, 34560, 135, 33, 135, 135, 34560, 135, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 34560, 34560, 33, 34560, 33, 135, 34560, 34560, 34560, 135, 33, 34560, 135, 33, 33, 33, 33, 33, 34560, 135, 33, 34560, 33, 34560, 33, 33, 135, 135, 34560, 135, 34560, 33, 135, 33, 34560, 34560, 33, 34560, 135, 33, 34560, 33, 33, 34560, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 33, 135, 34560, 34560, 33, 34560, 135, 33, 135, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 135, 34560, 34560, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 135, 34560, 135, 34560, 33, 34560, 33, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 135, 135, 33, 135, 34560, 135, 135, 34560, 33, 34560, 34560, 135, 33, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 33, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 34560, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 34560, 135, 33, 33, 33, 33]
Prompts retrieved: 2986440 . Total input tokens: 665820289 . Total output tokens: 597372628
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 6.250069055706263,
    "estimated_duration": 3600.03324021744,
    "input_throughput": 5555.394538188219,
    "output_throughput": 4859.547352108155,
    "total_throughput": 10414.941890296373,
    "itl": 175.90103936849792,
    "ttft": 2102914.419828862,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 351,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1475705299363528,
    "arrivals": 994382,
    "finished_requests": 80345,
    "scheduler_time": 110.96809869192846
}
#Debug simulation 
Total elapsed time: 6.250183785799891. Arrivals time: 0.47239713091403246 Scheduler time: 5.677941843401641 Scheduler overhead time: 0.0330762998200953 Adapter cache time: 0.016534936148673296 Engine time: 0.03486372763291001 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-32/adapters_256_slots_128_rate_3.2-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-32/adapters_256_slots_128_rate_3.2-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 33, 34560, 34560, 33, 34560, 135, 34560, 33, 135, 33, 34560, 135, 135, 135, 135, 34560, 33, 33, 33, 135, 34560, 33, 34560, 34560, 135, 135, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 33, 135, 135, 34560, 135, 33, 135, 34560, 135, 135, 34560, 135, 34560, 33, 34560, 34560, 135, 33, 33, 34560, 135, 33, 135, 135, 34560, 135, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 34560, 34560, 33, 34560, 33, 135, 34560, 34560, 34560, 135, 33, 34560, 135, 33, 33, 33, 33, 33, 34560, 135, 33, 34560, 33, 34560, 33, 33, 135, 135, 34560, 135, 34560, 33, 135, 33, 34560, 34560, 33, 34560, 135, 33, 34560, 33, 33, 34560, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 33, 135, 34560, 34560, 33, 34560, 135, 33, 135, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 135, 34560, 34560, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 135, 34560, 135, 34560, 33, 34560, 33, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 135, 135, 33, 135, 34560, 135, 135, 34560, 33, 34560, 34560, 135, 33, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 33, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 34560, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 34560, 135, 33, 33, 33, 33]
Prompts retrieved: 2986440 . Total input tokens: 665820289 . Total output tokens: 597372628
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 6.126264275051653,
    "estimated_duration": 3600.0357729292127,
    "input_throughput": 5354.999287774874,
    "output_throughput": 4683.337906467942,
    "total_throughput": 10038.337194242817,
    "itl": 149.39546767059812,
    "ttft": 2122899.3792259,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 334,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0937649717368245,
    "arrivals": 994382,
    "finished_requests": 77441,
    "scheduler_time": 115.4560745134113
}
#Debug simulation 
Total elapsed time: 6.1263632429763675. Arrivals time: 0.4865340213291347 Scheduler time: 5.526973094325513 Scheduler overhead time: 0.03814891166985035 Adapter cache time: 0.017743271309882402 Engine time: 0.03917693952098489 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-16/adapters_256_slots_128_rate_3.2-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-16/adapters_256_slots_128_rate_3.2-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 33, 34560, 34560, 33, 34560, 135, 34560, 33, 135, 33, 34560, 135, 135, 135, 135, 34560, 33, 33, 33, 135, 34560, 33, 34560, 34560, 135, 135, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 33, 135, 135, 34560, 135, 33, 135, 34560, 135, 135, 34560, 135, 34560, 33, 34560, 34560, 135, 33, 33, 34560, 135, 33, 135, 135, 34560, 135, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 34560, 34560, 33, 34560, 33, 135, 34560, 34560, 34560, 135, 33, 34560, 135, 33, 33, 33, 33, 33, 34560, 135, 33, 34560, 33, 34560, 33, 33, 135, 135, 34560, 135, 34560, 33, 135, 33, 34560, 34560, 33, 34560, 135, 33, 34560, 33, 33, 34560, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 33, 135, 34560, 34560, 33, 34560, 135, 33, 135, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 135, 34560, 34560, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 135, 34560, 135, 34560, 33, 34560, 33, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 135, 135, 33, 135, 34560, 135, 135, 34560, 33, 34560, 34560, 135, 33, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 33, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 34560, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 34560, 135, 33, 33, 33, 33]
Prompts retrieved: 2986440 . Total input tokens: 665820289 . Total output tokens: 597372628
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 6.232369340956211,
    "estimated_duration": 3600.172450260144,
    "input_throughput": 5555.548595610957,
    "output_throughput": 4859.78053599509,
    "total_throughput": 10415.329131606046,
    "itl": 175.9001477211177,
    "ttft": 2102947.657676402,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 351,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0997648776788287,
    "arrivals": 994382,
    "finished_requests": 80349,
    "scheduler_time": 110.9737610019418
}
#Debug simulation 
Total elapsed time: 6.232469009235501. Arrivals time: 0.49696498923003674 Scheduler time: 5.636129808612168 Scheduler overhead time: 0.03337128786370158 Adapter cache time: 0.016839484684169292 Engine time: 0.033914736937731504 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-32/adapters_256_slots_128_rate_3.2-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-32/adapters_256_slots_128_rate_3.2-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 33, 34560, 34560, 33, 34560, 135, 34560, 33, 135, 33, 34560, 135, 135, 135, 135, 34560, 33, 33, 33, 135, 34560, 33, 34560, 34560, 135, 135, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 33, 135, 135, 34560, 135, 33, 135, 34560, 135, 135, 34560, 135, 34560, 33, 34560, 34560, 135, 33, 33, 34560, 135, 33, 135, 135, 34560, 135, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 34560, 34560, 33, 34560, 33, 135, 34560, 34560, 34560, 135, 33, 34560, 135, 33, 33, 33, 33, 33, 34560, 135, 33, 34560, 33, 34560, 33, 33, 135, 135, 34560, 135, 34560, 33, 135, 33, 34560, 34560, 33, 34560, 135, 33, 34560, 33, 33, 34560, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 33, 135, 34560, 34560, 33, 34560, 135, 33, 135, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 135, 34560, 34560, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 135, 34560, 135, 34560, 33, 34560, 33, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 135, 135, 33, 135, 34560, 135, 135, 34560, 33, 34560, 34560, 135, 33, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 33, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 34560, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 34560, 135, 33, 33, 33, 33]
Prompts retrieved: 2986440 . Total input tokens: 665820289 . Total output tokens: 597372628
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 6.051230221055448,
    "estimated_duration": 3600.0498128102736,
    "input_throughput": 5354.978403743543,
    "output_throughput": 4683.3196418575635,
    "total_throughput": 10038.298045601106,
    "itl": 149.39593800468074,
    "ttft": 2122906.363391499,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 334,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1077236420288732,
    "arrivals": 994382,
    "finished_requests": 77441,
    "scheduler_time": 115.45615572418824
}
#Debug simulation 
Total elapsed time: 6.051359026227146. Arrivals time: 0.4526951052248478 Scheduler time: 5.487868421711028 Scheduler overhead time: 0.03781731566414237 Adapter cache time: 0.01674638083204627 Engine time: 0.0387657443061471 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-16/adapters_256_slots_128_rate_3.2-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-16/adapters_256_slots_128_rate_3.2-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 33, 34560, 34560, 33, 34560, 135, 34560, 33, 135, 33, 34560, 135, 135, 135, 135, 34560, 33, 33, 33, 135, 34560, 33, 34560, 34560, 135, 135, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 33, 135, 135, 34560, 135, 33, 135, 34560, 135, 135, 34560, 135, 34560, 33, 34560, 34560, 135, 33, 33, 34560, 135, 33, 135, 135, 34560, 135, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 34560, 34560, 33, 34560, 33, 135, 34560, 34560, 34560, 135, 33, 34560, 135, 33, 33, 33, 33, 33, 34560, 135, 33, 34560, 33, 34560, 33, 33, 135, 135, 34560, 135, 34560, 33, 135, 33, 34560, 34560, 33, 34560, 135, 33, 34560, 33, 33, 34560, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 33, 135, 34560, 34560, 33, 34560, 135, 33, 135, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 135, 34560, 34560, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 135, 34560, 135, 34560, 33, 34560, 33, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 135, 135, 33, 135, 34560, 135, 135, 34560, 33, 34560, 34560, 135, 33, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 33, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 34560, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 34560, 135, 33, 33, 33, 33]
Prompts retrieved: 2986440 . Total input tokens: 665820289 . Total output tokens: 597372628
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 6.718585191760212,
    "estimated_duration": 3600.0946502978672,
    "input_throughput": 5555.60310014215,
    "output_throughput": 4859.755839628394,
    "total_throughput": 10415.358939770544,
    "itl": 175.89807290866838,
    "ttft": 2102899.1549509605,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 351,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0495076535106633,
    "arrivals": 994382,
    "finished_requests": 80348,
    "scheduler_time": 110.97278558340042
}
#Debug simulation 
Total elapsed time: 6.718679192010313. Arrivals time: 0.8956933380104601 Scheduler time: 5.722736448049545 Scheduler overhead time: 0.03332814434543252 Adapter cache time: 0.01702561741694808 Engine time: 0.03446007426828146 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-32/adapters_256_slots_128_rate_3.2-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-32/adapters_256_slots_128_rate_3.2-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 33, 34560, 34560, 33, 34560, 135, 34560, 33, 135, 33, 34560, 135, 135, 135, 135, 34560, 33, 33, 33, 135, 34560, 33, 34560, 34560, 135, 135, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 33, 135, 135, 34560, 135, 33, 135, 34560, 135, 135, 34560, 135, 34560, 33, 34560, 34560, 135, 33, 33, 34560, 135, 33, 135, 135, 34560, 135, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 34560, 34560, 33, 34560, 33, 135, 34560, 34560, 34560, 135, 33, 34560, 135, 33, 33, 33, 33, 33, 34560, 135, 33, 34560, 33, 34560, 33, 33, 135, 135, 34560, 135, 34560, 33, 135, 33, 34560, 34560, 33, 34560, 135, 33, 34560, 33, 33, 34560, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 33, 135, 34560, 34560, 33, 34560, 135, 33, 135, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 135, 34560, 34560, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 135, 34560, 135, 34560, 33, 34560, 33, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 135, 135, 33, 135, 34560, 135, 135, 34560, 33, 34560, 34560, 135, 33, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 33, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 34560, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 34560, 135, 33, 33, 33, 33]
Prompts retrieved: 2986440 . Total input tokens: 665820289 . Total output tokens: 597372628
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 6.236020657699555,
    "estimated_duration": 3600.064709405534,
    "input_throughput": 5354.956245545747,
    "output_throughput": 4683.30026289557,
    "total_throughput": 10038.256508441316,
    "itl": 149.39647389556788,
    "ttft": 2122913.100663802,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 334,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1225625888258262,
    "arrivals": 994382,
    "finished_requests": 77441,
    "scheduler_time": 115.45621337266407
}
#Debug simulation 
Total elapsed time: 6.236126316711307. Arrivals time: 0.4426502729766071 Scheduler time: 5.678503880742937 Scheduler overhead time: 0.03941577719524503 Adapter cache time: 0.016827537678182125 Engine time: 0.04052468854933977 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-8/adapters_256_slots_128_rate_3.2-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-8/adapters_256_slots_128_rate_3.2-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [66, 66, 34560, 33, 34560, 34560, 33, 34560, 66, 34560, 33, 66, 33, 34560, 66, 66, 66, 66, 34560, 33, 33, 33, 66, 34560, 33, 34560, 34560, 66, 66, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 33, 66, 66, 34560, 66, 33, 66, 34560, 66, 66, 34560, 66, 34560, 33, 34560, 34560, 66, 33, 33, 34560, 66, 33, 66, 66, 34560, 66, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 34560, 34560, 33, 34560, 33, 66, 34560, 34560, 34560, 66, 33, 34560, 66, 33, 33, 33, 33, 33, 34560, 66, 33, 34560, 33, 34560, 33, 33, 66, 66, 34560, 66, 34560, 33, 66, 33, 34560, 34560, 33, 34560, 66, 33, 34560, 33, 33, 34560, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 33, 66, 34560, 34560, 33, 34560, 66, 33, 66, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 66, 34560, 34560, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 66, 34560, 66, 34560, 33, 34560, 33, 66, 34560, 66, 34560, 66, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 66, 66, 33, 66, 34560, 66, 66, 34560, 33, 34560, 34560, 66, 33, 34560, 34560, 66, 66, 34560, 34560, 66, 66, 66, 66, 34560, 34560, 66, 66, 34560, 33, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 34560, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 34560, 66, 33, 33, 33, 33]
Prompts retrieved: 2980575 . Total input tokens: 664496257 . Total output tokens: 596195076
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 6.391907526180148,
    "estimated_duration": 3600.0127021665962,
    "input_throughput": 5538.829901349957,
    "output_throughput": 4891.653851499402,
    "total_throughput": 10430.483752849359,
    "itl": 175.71585341122807,
    "ttft": 2107396.3280967725,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 279,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8538760805572372,
    "arrivals": 992438,
    "finished_requests": 80788,
    "scheduler_time": 111.58279837424536
}
#Debug simulation 
Total elapsed time: 6.392019289080054. Arrivals time: 0.6606137356720865 Scheduler time: 5.638012218289077 Scheduler overhead time: 0.032541405875235796 Adapter cache time: 0.012255433481186628 Engine time: 0.03360545029863715 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-16/adapters_256_slots_128_rate_3.2-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-16/adapters_256_slots_128_rate_3.2-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [66, 66, 34560, 33, 34560, 34560, 33, 34560, 66, 34560, 33, 66, 33, 34560, 66, 66, 66, 66, 34560, 33, 33, 33, 66, 34560, 33, 34560, 34560, 66, 66, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 33, 66, 66, 34560, 66, 33, 66, 34560, 66, 66, 34560, 66, 34560, 33, 34560, 34560, 66, 33, 33, 34560, 66, 33, 66, 66, 34560, 66, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 34560, 34560, 33, 34560, 33, 66, 34560, 34560, 34560, 66, 33, 34560, 66, 33, 33, 33, 33, 33, 34560, 66, 33, 34560, 33, 34560, 33, 33, 66, 66, 34560, 66, 34560, 33, 66, 33, 34560, 34560, 33, 34560, 66, 33, 34560, 33, 33, 34560, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 33, 66, 34560, 34560, 33, 34560, 66, 33, 66, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 66, 34560, 34560, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 66, 34560, 66, 34560, 33, 34560, 33, 66, 34560, 66, 34560, 66, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 66, 66, 33, 66, 34560, 66, 66, 34560, 33, 34560, 34560, 66, 33, 34560, 34560, 66, 66, 34560, 34560, 66, 66, 66, 66, 34560, 34560, 66, 66, 34560, 33, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 34560, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 34560, 66, 33, 33, 33, 33]
Prompts retrieved: 2980575 . Total input tokens: 664496257 . Total output tokens: 596195076
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 6.043860962148756,
    "estimated_duration": 3600.066470869155,
    "input_throughput": 5538.747176294767,
    "output_throughput": 4891.580792325886,
    "total_throughput": 10430.327968620653,
    "itl": 175.71785484334413,
    "ttft": 2107423.474474536,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 279,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9073625942785338,
    "arrivals": 992438,
    "finished_requests": 80788,
    "scheduler_time": 111.58308056306889
}
#Debug simulation 
Total elapsed time: 6.043972079176456. Arrivals time: 0.30447188625112176 Scheduler time: 5.646171052008867 Scheduler overhead time: 0.032554174307733774 Adapter cache time: 0.012362572364509106 Engine time: 0.0334815694950521 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-32/adapters_256_slots_128_rate_3.2-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-32/adapters_256_slots_128_rate_3.2-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [66, 66, 34560, 33, 34560, 34560, 33, 34560, 66, 34560, 33, 66, 33, 34560, 66, 66, 66, 66, 34560, 33, 33, 33, 66, 34560, 33, 34560, 34560, 66, 66, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 33, 66, 66, 34560, 66, 33, 66, 34560, 66, 66, 34560, 66, 34560, 33, 34560, 34560, 66, 33, 33, 34560, 66, 33, 66, 66, 34560, 66, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 34560, 34560, 33, 34560, 33, 66, 34560, 34560, 34560, 66, 33, 34560, 66, 33, 33, 33, 33, 33, 34560, 66, 33, 34560, 33, 34560, 33, 33, 66, 66, 34560, 66, 34560, 33, 66, 33, 34560, 34560, 33, 34560, 66, 33, 34560, 33, 33, 34560, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 33, 66, 34560, 34560, 33, 34560, 66, 33, 66, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 66, 34560, 34560, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 66, 34560, 66, 34560, 33, 34560, 33, 66, 34560, 66, 34560, 66, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 66, 66, 33, 66, 34560, 66, 66, 34560, 33, 34560, 34560, 66, 33, 34560, 34560, 66, 66, 34560, 34560, 66, 66, 66, 66, 34560, 34560, 66, 66, 34560, 33, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 34560, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 34560, 66, 33, 33, 33, 33]
Prompts retrieved: 2980575 . Total input tokens: 664496257 . Total output tokens: 596195076
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 6.024668857920915,
    "estimated_duration": 3600.0154385769347,
    "input_throughput": 5328.339093896379,
    "output_throughput": 4712.848955644115,
    "total_throughput": 10041.188049540495,
    "itl": 149.41174791758675,
    "ttft": 2127101.1241738377,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 274,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8936169710941657,
    "arrivals": 992438,
    "finished_requests": 77699,
    "scheduler_time": 115.92441255265703
}
#Debug simulation 
Total elapsed time: 6.024771905038506. Arrivals time: 0.33381999004632235 Scheduler time: 5.5800230274908245 Scheduler overhead time: 0.03866230929270387 Adapter cache time: 0.014603371266275644 Engine time: 0.0398072418756783 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-16/adapters_256_slots_128_rate_3.2-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-16/adapters_256_slots_128_rate_3.2-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [66, 66, 34560, 33, 34560, 34560, 33, 34560, 66, 34560, 33, 66, 33, 34560, 66, 66, 66, 66, 34560, 33, 33, 33, 66, 34560, 33, 34560, 34560, 66, 66, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 33, 66, 66, 34560, 66, 33, 66, 34560, 66, 66, 34560, 66, 34560, 33, 34560, 34560, 66, 33, 33, 34560, 66, 33, 66, 66, 34560, 66, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 34560, 34560, 33, 34560, 33, 66, 34560, 34560, 34560, 66, 33, 34560, 66, 33, 33, 33, 33, 33, 34560, 66, 33, 34560, 33, 34560, 33, 33, 66, 66, 34560, 66, 34560, 33, 66, 33, 34560, 34560, 33, 34560, 66, 33, 34560, 33, 33, 34560, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 33, 66, 34560, 34560, 33, 34560, 66, 33, 66, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 66, 34560, 34560, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 66, 34560, 66, 34560, 33, 34560, 33, 66, 34560, 66, 34560, 66, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 66, 66, 33, 66, 34560, 66, 66, 34560, 33, 34560, 34560, 66, 33, 34560, 34560, 66, 66, 34560, 34560, 66, 66, 66, 66, 34560, 34560, 66, 66, 34560, 33, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 34560, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 34560, 66, 33, 33, 33, 33]
Prompts retrieved: 2980575 . Total input tokens: 664496257 . Total output tokens: 596195076
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 6.620893345680088,
    "estimated_duration": 3600.0311078764807,
    "input_throughput": 5538.801583234583,
    "output_throughput": 4891.628842170608,
    "total_throughput": 10430.430425405191,
    "itl": 175.71662454281602,
    "ttft": 2107405.052756105,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 279,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8722233968926622,
    "arrivals": 992438,
    "finished_requests": 80788,
    "scheduler_time": 111.58285676777419
}
#Debug simulation 
Total elapsed time: 6.620963796041906. Arrivals time: 0.708087342325598 Scheduler time: 5.815686057321727 Scheduler overhead time: 0.03351111523807049 Adapter cache time: 0.013273308053612709 Engine time: 0.035005723126232624 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-32/adapters_256_slots_128_rate_3.2-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-32/adapters_256_slots_128_rate_3.2-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [66, 66, 34560, 33, 34560, 34560, 33, 34560, 66, 34560, 33, 66, 33, 34560, 66, 66, 66, 66, 34560, 33, 33, 33, 66, 34560, 33, 34560, 34560, 66, 66, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 33, 66, 66, 34560, 66, 33, 66, 34560, 66, 66, 34560, 66, 34560, 33, 34560, 34560, 66, 33, 33, 34560, 66, 33, 66, 66, 34560, 66, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 34560, 34560, 33, 34560, 33, 66, 34560, 34560, 34560, 66, 33, 34560, 66, 33, 33, 33, 33, 33, 34560, 66, 33, 34560, 33, 34560, 33, 33, 66, 66, 34560, 66, 34560, 33, 66, 33, 34560, 34560, 33, 34560, 66, 33, 34560, 33, 33, 34560, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 33, 66, 34560, 34560, 33, 34560, 66, 33, 66, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 66, 34560, 34560, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 66, 34560, 66, 34560, 33, 34560, 33, 66, 34560, 66, 34560, 66, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 66, 66, 33, 66, 34560, 66, 66, 34560, 33, 34560, 34560, 66, 33, 34560, 34560, 66, 66, 34560, 34560, 66, 66, 66, 66, 34560, 34560, 66, 66, 34560, 33, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 34560, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 34560, 66, 33, 33, 33, 33]
Prompts retrieved: 2980575 . Total input tokens: 664496257 . Total output tokens: 596195076
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 5.861677206587046,
    "estimated_duration": 3600.026201874677,
    "input_throughput": 5328.323163317843,
    "output_throughput": 4712.834865247635,
    "total_throughput": 10041.158028565478,
    "itl": 149.41208096254616,
    "ttft": 2127106.6561490246,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 274,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9043060429394291,
    "arrivals": 992438,
    "finished_requests": 77699,
    "scheduler_time": 115.9244867785621
}
#Debug simulation 
Total elapsed time: 5.861779522616416. Arrivals time: 0.32408560113981366 Scheduler time: 5.429696991108358 Scheduler overhead time: 0.037736430298537016 Adapter cache time: 0.014306999277323484 Engine time: 0.03858063230291009 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-16/adapters_256_slots_128_rate_3.2-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-16/adapters_256_slots_128_rate_3.2-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [66, 66, 34560, 33, 34560, 34560, 33, 34560, 66, 34560, 33, 66, 33, 34560, 66, 66, 66, 66, 34560, 33, 33, 33, 66, 34560, 33, 34560, 34560, 66, 66, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 33, 66, 66, 34560, 66, 33, 66, 34560, 66, 66, 34560, 66, 34560, 33, 34560, 34560, 66, 33, 33, 34560, 66, 33, 66, 66, 34560, 66, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 34560, 34560, 33, 34560, 33, 66, 34560, 34560, 34560, 66, 33, 34560, 66, 33, 33, 33, 33, 33, 34560, 66, 33, 34560, 33, 34560, 33, 33, 66, 66, 34560, 66, 34560, 33, 66, 33, 34560, 34560, 33, 34560, 66, 33, 34560, 33, 33, 34560, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 33, 66, 34560, 34560, 33, 34560, 66, 33, 66, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 66, 34560, 34560, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 66, 34560, 66, 34560, 33, 34560, 33, 66, 34560, 66, 34560, 66, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 66, 66, 33, 66, 34560, 66, 66, 34560, 33, 34560, 34560, 66, 33, 34560, 34560, 66, 66, 34560, 34560, 66, 66, 66, 66, 34560, 34560, 66, 66, 34560, 33, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 34560, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 34560, 66, 33, 33, 33, 33]
Prompts retrieved: 2980575 . Total input tokens: 664496257 . Total output tokens: 596195076
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 6.119722778908908,
    "estimated_duration": 3600.1921539418463,
    "input_throughput": 5538.908799122422,
    "output_throughput": 4891.862224830703,
    "total_throughput": 10430.771023953126,
    "itl": 175.7144703689082,
    "ttft": 2107406.0718931234,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 279,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8342240322777081,
    "arrivals": 992438,
    "finished_requests": 80795,
    "scheduler_time": 111.58886961433399
}
#Debug simulation 
Total elapsed time: 6.119843922089785. Arrivals time: 0.3383526476100087 Scheduler time: 5.685897178947926 Scheduler overhead time: 0.033051230013370514 Adapter cache time: 0.013662877958267927 Engine time: 0.03364536026492715 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-32/adapters_256_slots_128_rate_3.2-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-32/adapters_256_slots_128_rate_3.2-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [66, 66, 34560, 33, 34560, 34560, 33, 34560, 66, 34560, 33, 66, 33, 34560, 66, 66, 66, 66, 34560, 33, 33, 33, 66, 34560, 33, 34560, 34560, 66, 66, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 33, 66, 66, 34560, 66, 33, 66, 34560, 66, 66, 34560, 66, 34560, 33, 34560, 34560, 66, 33, 33, 34560, 66, 33, 66, 66, 34560, 66, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 34560, 34560, 33, 34560, 33, 66, 34560, 34560, 34560, 66, 33, 34560, 66, 33, 33, 33, 33, 33, 34560, 66, 33, 34560, 33, 34560, 33, 33, 66, 66, 34560, 66, 34560, 33, 66, 33, 34560, 34560, 33, 34560, 66, 33, 34560, 33, 33, 34560, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 33, 66, 34560, 34560, 33, 34560, 66, 33, 66, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 66, 34560, 34560, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 66, 34560, 66, 34560, 33, 34560, 33, 66, 34560, 66, 34560, 66, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 66, 66, 33, 66, 34560, 66, 66, 34560, 33, 34560, 34560, 66, 33, 34560, 34560, 66, 66, 34560, 34560, 66, 66, 66, 66, 34560, 34560, 66, 66, 34560, 33, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 34560, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 34560, 66, 33, 33, 33, 33]
Prompts retrieved: 2980575 . Total input tokens: 664496257 . Total output tokens: 596195076
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 6.401203662157059,
    "estimated_duration": 3600.037824959966,
    "input_throughput": 5328.30596028899,
    "output_throughput": 4712.819649384843,
    "total_throughput": 10041.125609673833,
    "itl": 149.41249456677315,
    "ttft": 2127112.245070216,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 274,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9158753912895964,
    "arrivals": 992438,
    "finished_requests": 77699,
    "scheduler_time": 115.92454051550968
}
#Debug simulation 
Total elapsed time: 6.401291230227798. Arrivals time: 0.7005457347258925 Scheduler time: 5.590454123914242 Scheduler overhead time: 0.03858355339616537 Adapter cache time: 0.014462437946349382 Engine time: 0.0393782127648592 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-8/adapters_256_slots_128_rate_1.6-0.8-0.4_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-8/adapters_256_slots_128_rate_1.6-0.8-0.4_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 4320, 17280, 17280, 4320, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 8640, 8640, 8640, 8640, 17280, 4320, 4320, 4320, 8640, 17280, 4320, 17280, 17280, 8640, 8640, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 4320, 17280, 8640, 4320, 8640, 8640, 17280, 8640, 4320, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 17280, 17280, 4320, 17280, 4320, 8640, 17280, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 8640, 4320, 17280, 4320, 17280, 4320, 4320, 8640, 8640, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 17280, 4320, 17280, 8640, 4320, 8640, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 4320, 4320, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 17280, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 17280, 4320, 17280, 4320, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 17280, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 4320, 4320, 4320, 4320]
Prompts retrieved: 2587680 . Total input tokens: 577057570 . Total output tokens: 517693652
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 20.574459788389504,
    "estimated_duration": 3600.005525120902,
    "input_throughput": 4674.010048758162,
    "output_throughput": 4120.005343464545,
    "total_throughput": 8794.015392222707,
    "itl": 208.1055692646642,
    "ttft": 2163103.2509240685,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 948,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9013423812483152,
    "arrivals": 861811,
    "finished_requests": 68018,
    "scheduler_time": 93.99719256375106
}
#Debug simulation 
Total elapsed time: 20.57458788435906. Arrivals time: 0.4592994465492666 Scheduler time: 19.99100979277864 Scheduler overhead time: 0.039300786796957254 Adapter cache time: 0.03005212778225541 Engine time: 0.03980097034946084 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-16/adapters_256_slots_128_rate_1.6-0.8-0.4_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-16/adapters_256_slots_128_rate_1.6-0.8-0.4_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 4320, 17280, 17280, 4320, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 8640, 8640, 8640, 8640, 17280, 4320, 4320, 4320, 8640, 17280, 4320, 17280, 17280, 8640, 8640, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 4320, 17280, 8640, 4320, 8640, 8640, 17280, 8640, 4320, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 17280, 17280, 4320, 17280, 4320, 8640, 17280, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 8640, 4320, 17280, 4320, 17280, 4320, 4320, 8640, 8640, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 17280, 4320, 17280, 8640, 4320, 8640, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 4320, 4320, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 17280, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 17280, 4320, 17280, 4320, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 17280, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 4320, 4320, 4320, 4320]
Prompts retrieved: 2587680 . Total input tokens: 577057570 . Total output tokens: 517693652
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 18.95222480269149,
    "estimated_duration": 3600.0964083519143,
    "input_throughput": 4667.906659670014,
    "output_throughput": 4107.753605068018,
    "total_throughput": 8775.660264738033,
    "itl": 208.31962226127683,
    "ttft": 2164180.7226497107,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1015,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3094771033176262,
    "arrivals": 861811,
    "finished_requests": 67868,
    "scheduler_time": 93.8507402508952
}
#Debug simulation 
Total elapsed time: 18.952363470569253. Arrivals time: 0.4692999180406332 Scheduler time: 18.360302912071347 Scheduler overhead time: 0.03868120443075895 Adapter cache time: 0.0308525119908154 Engine time: 0.03867990197613835 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-32/adapters_256_slots_128_rate_1.6-0.8-0.4_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-32/adapters_256_slots_128_rate_1.6-0.8-0.4_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 4320, 17280, 17280, 4320, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 8640, 8640, 8640, 8640, 17280, 4320, 4320, 4320, 8640, 17280, 4320, 17280, 17280, 8640, 8640, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 4320, 17280, 8640, 4320, 8640, 8640, 17280, 8640, 4320, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 17280, 17280, 4320, 17280, 4320, 8640, 17280, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 8640, 4320, 17280, 4320, 17280, 4320, 4320, 8640, 8640, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 17280, 4320, 17280, 8640, 4320, 8640, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 4320, 4320, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 17280, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 17280, 4320, 17280, 4320, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 17280, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 4320, 4320, 4320, 4320]
Prompts retrieved: 2587680 . Total input tokens: 577057570 . Total output tokens: 517693652
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 10.429556155577302,
    "estimated_duration": 3600.136257086992,
    "input_throughput": 4467.265362065263,
    "output_throughput": 3941.1763852184527,
    "total_throughput": 8408.441747283716,
    "itl": 177.79932745178294,
    "ttft": 2189285.3012220818,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1817,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.940841196551869,
    "arrivals": 861811,
    "finished_requests": 65047,
    "scheduler_time": 97.07652223667783
}
#Debug simulation 
Total elapsed time: 10.429679336957633. Arrivals time: 0.765408837236464 Scheduler time: 9.53334929421544 Scheduler overhead time: 0.03485738439485431 Adapter cache time: 0.04586575226858258 Engine time: 0.034901412669569254 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-16-16/adapters_256_slots_128_rate_1.6-0.8-0.4_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-16-16/adapters_256_slots_128_rate_1.6-0.8-0.4_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 4320, 17280, 17280, 4320, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 8640, 8640, 8640, 8640, 17280, 4320, 4320, 4320, 8640, 17280, 4320, 17280, 17280, 8640, 8640, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 4320, 17280, 8640, 4320, 8640, 8640, 17280, 8640, 4320, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 17280, 17280, 4320, 17280, 4320, 8640, 17280, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 8640, 4320, 17280, 4320, 17280, 4320, 4320, 8640, 8640, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 17280, 4320, 17280, 8640, 4320, 8640, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 4320, 4320, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 17280, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 17280, 4320, 17280, 4320, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 17280, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 4320, 4320, 4320, 4320]
Prompts retrieved: 2587680 . Total input tokens: 577057570 . Total output tokens: 517693652
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 21.08950765663758,
    "estimated_duration": 3600.0676171065434,
    "input_throughput": 4673.929434004302,
    "output_throughput": 4119.934283879049,
    "total_throughput": 8793.86371788335,
    "itl": 208.1087567125759,
    "ttft": 2163132.7715416043,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 948,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.963275204875941,
    "arrivals": 861811,
    "finished_requests": 68018,
    "scheduler_time": 93.99735172569807
}
#Debug simulation 
Total elapsed time: 21.089645985048264. Arrivals time: 0.4376043579541147 Scheduler time: 20.527555943932384 Scheduler overhead time: 0.04094629222527146 Adapter cache time: 0.0276248836889863 Engine time: 0.0408666767179966 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-16-32/adapters_256_slots_128_rate_1.6-0.8-0.4_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-16-32/adapters_256_slots_128_rate_1.6-0.8-0.4_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 4320, 17280, 17280, 4320, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 8640, 8640, 8640, 8640, 17280, 4320, 4320, 4320, 8640, 17280, 4320, 17280, 17280, 8640, 8640, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 4320, 17280, 8640, 4320, 8640, 8640, 17280, 8640, 4320, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 17280, 17280, 4320, 17280, 4320, 8640, 17280, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 8640, 4320, 17280, 4320, 17280, 4320, 4320, 8640, 8640, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 17280, 4320, 17280, 8640, 4320, 8640, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 4320, 4320, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 17280, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 17280, 4320, 17280, 4320, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 17280, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 4320, 4320, 4320, 4320]
Prompts retrieved: 2587680 . Total input tokens: 577057570 . Total output tokens: 517693652
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 10.322843766305596,
    "estimated_duration": 3600.0116199610093,
    "input_throughput": 4467.2003031407385,
    "output_throughput": 3941.1425566881,
    "total_throughput": 8408.342859828837,
    "itl": 177.8066367950289,
    "ttft": 2189179.503253492,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1816,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.014507487416172,
    "arrivals": 861811,
    "finished_requests": 65040,
    "scheduler_time": 97.07123796465638
}
#Debug simulation 
Total elapsed time: 10.322952534072101. Arrivals time: 0.40834215097129345 Scheduler time: 9.778369392734021 Scheduler overhead time: 0.0359968077391386 Adapter cache time: 0.04869535053148866 Engine time: 0.0357873379252851 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_16-16-16/adapters_256_slots_128_rate_1.6-0.8-0.4_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_16-16-16/adapters_256_slots_128_rate_1.6-0.8-0.4_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 4320, 17280, 17280, 4320, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 8640, 8640, 8640, 8640, 17280, 4320, 4320, 4320, 8640, 17280, 4320, 17280, 17280, 8640, 8640, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 4320, 17280, 8640, 4320, 8640, 8640, 17280, 8640, 4320, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 17280, 17280, 4320, 17280, 4320, 8640, 17280, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 8640, 4320, 17280, 4320, 17280, 4320, 4320, 8640, 8640, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 17280, 4320, 17280, 8640, 4320, 8640, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 4320, 4320, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 17280, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 17280, 4320, 17280, 4320, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 17280, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 4320, 4320, 4320, 4320]
Prompts retrieved: 2587680 . Total input tokens: 577057570 . Total output tokens: 517693652
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 20.36378414509818,
    "estimated_duration": 3600.166332753327,
    "input_throughput": 4674.067652627251,
    "output_throughput": 4120.038528513261,
    "total_throughput": 8794.10618114051,
    "itl": 208.1029966851024,
    "ttft": 2163088.054261911,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 948,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.834567679567199,
    "arrivals": 861811,
    "finished_requests": 68022,
    "scheduler_time": 94.00303019255762
}
#Debug simulation 
Total elapsed time: 20.363912309985608. Arrivals time: 0.4744929661974311 Scheduler time: 19.76832362776622 Scheduler overhead time: 0.03871235577389598 Adapter cache time: 0.029896868858486414 Engine time: 0.03774674003943801 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_16-16-32/adapters_256_slots_128_rate_1.6-0.8-0.4_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_16-16-32/adapters_256_slots_128_rate_1.6-0.8-0.4_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 4320, 17280, 17280, 4320, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 8640, 8640, 8640, 8640, 17280, 4320, 4320, 4320, 8640, 17280, 4320, 17280, 17280, 8640, 8640, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 4320, 17280, 8640, 4320, 8640, 8640, 17280, 8640, 4320, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 17280, 17280, 4320, 17280, 4320, 8640, 17280, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 8640, 4320, 17280, 4320, 17280, 4320, 4320, 8640, 8640, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 17280, 4320, 17280, 8640, 4320, 8640, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 4320, 4320, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 17280, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 17280, 4320, 17280, 4320, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 17280, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 4320, 4320, 4320, 4320]
Prompts retrieved: 2587680 . Total input tokens: 577057570 . Total output tokens: 517693652
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 10.16020079003647,
    "estimated_duration": 3600.0881768894697,
    "input_throughput": 4467.105306819198,
    "output_throughput": 3941.058747138461,
    "total_throughput": 8408.164053957658,
    "itl": 177.81017971465704,
    "ttft": 2189206.8140860465,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1816,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.090965789556359,
    "arrivals": 861811,
    "finished_requests": 65040,
    "scheduler_time": 97.07133659104717
}
#Debug simulation 
Total elapsed time: 10.160362470895052. Arrivals time: 0.40697714732959867 Scheduler time: 9.618504758458585 Scheduler overhead time: 0.03548111533746123 Adapter cache time: 0.048819564282894135 Engine time: 0.03497465141117573 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-8/adapters_256_slots_128_rate_1.6-0.8-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-8/adapters_256_slots_128_rate_1.6-0.8-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 1080, 17280, 17280, 1080, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 8640, 8640, 8640, 8640, 17280, 1080, 1080, 1080, 8640, 17280, 1080, 17280, 17280, 8640, 8640, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 1080, 17280, 8640, 1080, 8640, 8640, 17280, 8640, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 8640, 17280, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 8640, 1080, 17280, 1080, 17280, 1080, 1080, 8640, 8640, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 17280, 1080, 17280, 8640, 1080, 8640, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 17280, 1080, 17280, 1080, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 17280, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 1080, 1080, 1080, 1080]
Prompts retrieved: 2312280 . Total input tokens: 515501074 . Total output tokens: 462498738
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 18.588822663296014,
    "estimated_duration": 3600.1224708022564,
    "input_throughput": 4704.504676538346,
    "output_throughput": 4110.849316940611,
    "total_throughput": 8815.353993478957,
    "itl": 207.48874963222252,
    "ttft": 2155983.5952901626,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 751,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2984262956935417,
    "arrivals": 769968,
    "finished_requests": 68144,
    "scheduler_time": 93.91529236226114
}
#Debug simulation 
Total elapsed time: 18.58895172039047. Arrivals time: 0.4407513062469661 Scheduler time: 18.032109774649143 Scheduler overhead time: 0.038717580027878284 Adapter cache time: 0.02452053176239133 Engine time: 0.03777845948934555 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-16/adapters_256_slots_128_rate_1.6-0.8-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-16/adapters_256_slots_128_rate_1.6-0.8-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 1080, 17280, 17280, 1080, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 8640, 8640, 8640, 8640, 17280, 1080, 1080, 1080, 8640, 17280, 1080, 17280, 17280, 8640, 8640, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 1080, 17280, 8640, 1080, 8640, 8640, 17280, 8640, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 8640, 17280, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 8640, 1080, 17280, 1080, 17280, 1080, 1080, 8640, 8640, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 17280, 1080, 17280, 8640, 1080, 8640, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 17280, 1080, 17280, 1080, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 17280, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 1080, 1080, 1080, 1080]
Prompts retrieved: 2312280 . Total input tokens: 515501074 . Total output tokens: 462498738
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 17.789822516031563,
    "estimated_duration": 3600.040474094623,
    "input_throughput": 4703.974891909756,
    "output_throughput": 4110.61322962533,
    "total_throughput": 8814.588121535086,
    "itl": 207.4947598754033,
    "ttft": 2156030.6157887164,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 751,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4490082400548316,
    "arrivals": 769968,
    "finished_requests": 68136,
    "scheduler_time": 93.90962901630377
}
#Debug simulation 
Total elapsed time: 17.789940690156072. Arrivals time: 0.45062070107087493 Scheduler time: 17.226165211293846 Scheduler overhead time: 0.03797969641163945 Adapter cache time: 0.0240094312466681 Engine time: 0.036811488680541515 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-32/adapters_256_slots_128_rate_1.6-0.8-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-32/adapters_256_slots_128_rate_1.6-0.8-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 1080, 17280, 17280, 1080, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 8640, 8640, 8640, 8640, 17280, 1080, 1080, 1080, 8640, 17280, 1080, 17280, 17280, 8640, 8640, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 1080, 17280, 8640, 1080, 8640, 8640, 17280, 8640, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 8640, 17280, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 8640, 1080, 17280, 1080, 17280, 1080, 1080, 8640, 8640, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 17280, 1080, 17280, 8640, 1080, 8640, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 17280, 1080, 17280, 1080, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 17280, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 1080, 1080, 1080, 1080]
Prompts retrieved: 2312280 . Total input tokens: 515501074 . Total output tokens: 462498738
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 9.432713652960956,
    "estimated_duration": 3600.1877103876936,
    "input_throughput": 4495.840023368391,
    "output_throughput": 3933.3193541941946,
    "total_throughput": 8429.159377562584,
    "itl": 177.7278427982793,
    "ttft": 2183054.8917047353,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1279,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.182693452872273,
    "arrivals": 769968,
    "finished_requests": 65184,
    "scheduler_time": 96.8723819717211
}
#Debug simulation 
Total elapsed time: 9.43283744668588. Arrivals time: 0.3058621250092983 Scheduler time: 9.012435337528586 Scheduler overhead time: 0.03396505070850253 Adapter cache time: 0.03177996585145593 Engine time: 0.033779327757656574 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-16-16/adapters_256_slots_128_rate_1.6-0.8-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-16-16/adapters_256_slots_128_rate_1.6-0.8-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 1080, 17280, 17280, 1080, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 8640, 8640, 8640, 8640, 17280, 1080, 1080, 1080, 8640, 17280, 1080, 17280, 17280, 8640, 8640, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 1080, 17280, 8640, 1080, 8640, 8640, 17280, 8640, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 8640, 17280, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 8640, 1080, 17280, 1080, 17280, 1080, 1080, 8640, 8640, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 17280, 1080, 17280, 8640, 1080, 8640, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 17280, 1080, 17280, 1080, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 17280, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 1080, 1080, 1080, 1080]
Prompts retrieved: 2312280 . Total input tokens: 515501074 . Total output tokens: 462498738
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 18.01225658180192,
    "estimated_duration": 3600.171887161415,
    "input_throughput": 4704.440101984674,
    "output_throughput": 4110.792890966335,
    "total_throughput": 8815.232992951009,
    "itl": 207.4911757632633,
    "ttft": 2156004.469361621,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 751,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3476766010816004,
    "arrivals": 769968,
    "finished_requests": 68144,
    "scheduler_time": 93.9154584159484
}
#Debug simulation 
Total elapsed time: 18.012404076755047. Arrivals time: 0.44757384341210127 Scheduler time: 17.450376506429166 Scheduler overhead time: 0.03787286579608917 Adapter cache time: 0.02426417311653495 Engine time: 0.03772801114246249 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-16-32/adapters_256_slots_128_rate_1.6-0.8-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-16-32/adapters_256_slots_128_rate_1.6-0.8-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 1080, 17280, 17280, 1080, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 8640, 8640, 8640, 8640, 17280, 1080, 1080, 1080, 8640, 17280, 1080, 17280, 17280, 8640, 8640, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 1080, 17280, 8640, 1080, 8640, 8640, 17280, 8640, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 8640, 17280, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 8640, 1080, 17280, 1080, 17280, 1080, 1080, 8640, 8640, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 17280, 1080, 17280, 8640, 1080, 8640, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 17280, 1080, 17280, 1080, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 17280, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 1080, 1080, 1080, 1080]
Prompts retrieved: 2312280 . Total input tokens: 515501074 . Total output tokens: 462498738
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 10.307510579004884,
    "estimated_duration": 3600.0634305666113,
    "input_throughput": 4495.249406606411,
    "output_throughput": 3934.5892852145157,
    "total_throughput": 8429.838691820927,
    "itl": 177.66577681573602,
    "ttft": 2183433.599228748,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1298,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.300281920507538,
    "arrivals": 769968,
    "finished_requests": 65158,
    "scheduler_time": 96.88818306329917
}
#Debug simulation 
Total elapsed time: 10.307615343015641. Arrivals time: 0.4027860010974109 Scheduler time: 9.779411686118692 Scheduler overhead time: 0.035715832840651274 Adapter cache time: 0.03911117231473327 Engine time: 0.0350364726036787 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_16-16-16/adapters_256_slots_128_rate_1.6-0.8-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_16-16-16/adapters_256_slots_128_rate_1.6-0.8-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 1080, 17280, 17280, 1080, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 8640, 8640, 8640, 8640, 17280, 1080, 1080, 1080, 8640, 17280, 1080, 17280, 17280, 8640, 8640, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 1080, 17280, 8640, 1080, 8640, 8640, 17280, 8640, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 8640, 17280, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 8640, 1080, 17280, 1080, 17280, 1080, 1080, 8640, 8640, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 17280, 1080, 17280, 8640, 1080, 8640, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 17280, 1080, 17280, 1080, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 17280, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 1080, 1080, 1080, 1080]
Prompts retrieved: 2312280 . Total input tokens: 515501074 . Total output tokens: 462498738
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 17.831324629019946,
    "estimated_duration": 3600.069437609816,
    "input_throughput": 4704.57397934102,
    "output_throughput": 4110.909874512263,
    "total_throughput": 8815.483853853282,
    "itl": 207.48610728421522,
    "ttft": 2155962.4484443995,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 751,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.245527771471491,
    "arrivals": 769968,
    "finished_requests": 68144,
    "scheduler_time": 93.9151576939315
}
#Debug simulation 
Total elapsed time: 17.83147404389456. Arrivals time: 0.4660606039687991 Scheduler time: 17.25322090415284 Scheduler overhead time: 0.037090457044541836 Adapter cache time: 0.02424680907279253 Engine time: 0.03623189404606819 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_16-16-32/adapters_256_slots_128_rate_1.6-0.8-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_16-16-32/adapters_256_slots_128_rate_1.6-0.8-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 1080, 17280, 17280, 1080, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 8640, 8640, 8640, 8640, 17280, 1080, 1080, 1080, 8640, 17280, 1080, 17280, 17280, 8640, 8640, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 1080, 17280, 8640, 1080, 8640, 8640, 17280, 8640, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 8640, 17280, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 8640, 1080, 17280, 1080, 17280, 1080, 1080, 8640, 8640, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 17280, 1080, 17280, 8640, 1080, 8640, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 17280, 1080, 17280, 1080, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 17280, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 1080, 1080, 1080, 1080]
Prompts retrieved: 2312280 . Total input tokens: 515501074 . Total output tokens: 462498738
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 10.40573626710102,
    "estimated_duration": 3600.118862349084,
    "input_throughput": 4495.180192311886,
    "output_throughput": 3934.528703521045,
    "total_throughput": 8429.70889583293,
    "itl": 177.66826264908926,
    "ttft": 2183454.445091814,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1298,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.355613586530117,
    "arrivals": 769968,
    "finished_requests": 65158,
    "scheduler_time": 96.88828317979595
}
#Debug simulation 
Total elapsed time: 10.405882128048688. Arrivals time: 0.3900867812335491 Scheduler time: 9.889530039392412 Scheduler overhead time: 0.036228492856025696 Adapter cache time: 0.03850084263831377 Engine time: 0.03572269529104233 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-8/adapters_256_slots_128_rate_1.6-0.8-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-8/adapters_256_slots_128_rate_1.6-0.8-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 540, 17280, 17280, 540, 17280, 8640, 17280, 540, 8640, 540, 17280, 8640, 8640, 8640, 8640, 17280, 540, 540, 540, 8640, 17280, 540, 17280, 17280, 8640, 8640, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 540, 8640, 8640, 17280, 8640, 540, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 540, 17280, 17280, 8640, 540, 540, 17280, 8640, 540, 8640, 8640, 17280, 8640, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 8640, 540, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 540, 17280, 17280, 540, 17280, 540, 8640, 17280, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 540, 540, 540, 17280, 8640, 540, 17280, 540, 17280, 540, 540, 8640, 8640, 17280, 8640, 17280, 540, 8640, 540, 17280, 17280, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 17280, 540, 17280, 8640, 540, 8640, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 8640, 17280, 17280, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 17280, 540, 17280, 540, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 8640, 8640, 17280, 540, 17280, 17280, 8640, 540, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 540, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 17280, 540, 8640, 540, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 540, 540, 540, 540]
Prompts retrieved: 2266380 . Total input tokens: 505284175 . Total output tokens: 453316467
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 15.84829548932612,
    "estimated_duration": 3600.0862722863303,
    "input_throughput": 4673.659109095313,
    "output_throughput": 4103.111393110847,
    "total_throughput": 8776.77050220616,
    "itl": 208.36643322516406,
    "ttft": 2155058.069872932,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 769,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.353515075084333,
    "arrivals": 754714,
    "finished_requests": 67934,
    "scheduler_time": 93.60813282613415
}
#Debug simulation 
Total elapsed time: 15.848405488301069. Arrivals time: 0.3994700741022825 Scheduler time: 15.340311024338007 Scheduler overhead time: 0.035680864471942186 Adapter cache time: 0.024204885587096214 Engine time: 0.03493118239566684 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-16/adapters_256_slots_128_rate_1.6-0.8-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-16/adapters_256_slots_128_rate_1.6-0.8-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 540, 17280, 17280, 540, 17280, 8640, 17280, 540, 8640, 540, 17280, 8640, 8640, 8640, 8640, 17280, 540, 540, 540, 8640, 17280, 540, 17280, 17280, 8640, 8640, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 540, 8640, 8640, 17280, 8640, 540, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 540, 17280, 17280, 8640, 540, 540, 17280, 8640, 540, 8640, 8640, 17280, 8640, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 8640, 540, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 540, 17280, 17280, 540, 17280, 540, 8640, 17280, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 540, 540, 540, 17280, 8640, 540, 17280, 540, 17280, 540, 540, 8640, 8640, 17280, 8640, 17280, 540, 8640, 540, 17280, 17280, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 17280, 540, 17280, 8640, 540, 8640, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 8640, 17280, 17280, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 17280, 540, 17280, 540, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 8640, 8640, 17280, 540, 17280, 17280, 8640, 540, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 540, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 17280, 540, 8640, 540, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 540, 540, 540, 540]
Prompts retrieved: 2266380 . Total input tokens: 505284175 . Total output tokens: 453316467
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 15.19394220598042,
    "estimated_duration": 3600.2061274003377,
    "input_throughput": 4665.95922720956,
    "output_throughput": 4102.062070169292,
    "total_throughput": 8768.021297378851,
    "itl": 208.40992399307976,
    "ttft": 2154180.164307262,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 828,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7008976646396388,
    "arrivals": 754714,
    "finished_requests": 67883,
    "scheduler_time": 93.6384953193849
}
#Debug simulation 
Total elapsed time: 15.194074160885066. Arrivals time: 0.5476924227550626 Scheduler time: 14.53628884954378 Scheduler overhead time: 0.035815049428492785 Adapter cache time: 0.02516595833003521 Engine time: 0.03498571692034602 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-32/adapters_256_slots_128_rate_1.6-0.8-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-32/adapters_256_slots_128_rate_1.6-0.8-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 540, 17280, 17280, 540, 17280, 8640, 17280, 540, 8640, 540, 17280, 8640, 8640, 8640, 8640, 17280, 540, 540, 540, 8640, 17280, 540, 17280, 17280, 8640, 8640, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 540, 8640, 8640, 17280, 8640, 540, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 540, 17280, 17280, 8640, 540, 540, 17280, 8640, 540, 8640, 8640, 17280, 8640, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 8640, 540, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 540, 17280, 17280, 540, 17280, 540, 8640, 17280, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 540, 540, 540, 17280, 8640, 540, 17280, 540, 17280, 540, 540, 8640, 8640, 17280, 8640, 17280, 540, 8640, 540, 17280, 17280, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 17280, 540, 17280, 8640, 540, 8640, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 8640, 17280, 17280, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 17280, 540, 17280, 540, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 8640, 8640, 17280, 540, 17280, 17280, 8640, 540, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 540, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 17280, 540, 8640, 540, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 540, 540, 540, 540]
Prompts retrieved: 2266380 . Total input tokens: 505284175 . Total output tokens: 453316467
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 9.312078262213618,
    "estimated_duration": 3600.056042062825,
    "input_throughput": 4469.856250009783,
    "output_throughput": 3932.4732266912147,
    "total_throughput": 8402.329476700997,
    "itl": 177.43902418402953,
    "ttft": 2179223.3433204126,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1232,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.027169909682061,
    "arrivals": 754714,
    "finished_requests": 65016,
    "scheduler_time": 96.92832297808022
}
#Debug simulation 
Total elapsed time: 9.312201354186982. Arrivals time: 0.4854406025260687 Scheduler time: 8.705149960704148 Scheduler overhead time: 0.035262887831777334 Adapter cache time: 0.036097615491598845 Engine time: 0.034764223266392946 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-16-16/adapters_256_slots_128_rate_1.6-0.8-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-16-16/adapters_256_slots_128_rate_1.6-0.8-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 540, 17280, 17280, 540, 17280, 8640, 17280, 540, 8640, 540, 17280, 8640, 8640, 8640, 8640, 17280, 540, 540, 540, 8640, 17280, 540, 17280, 17280, 8640, 8640, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 540, 8640, 8640, 17280, 8640, 540, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 540, 17280, 17280, 8640, 540, 540, 17280, 8640, 540, 8640, 8640, 17280, 8640, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 8640, 540, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 540, 17280, 17280, 540, 17280, 540, 8640, 17280, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 540, 540, 540, 17280, 8640, 540, 17280, 540, 17280, 540, 540, 8640, 8640, 17280, 8640, 17280, 540, 8640, 540, 17280, 17280, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 17280, 540, 17280, 8640, 540, 8640, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 8640, 17280, 17280, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 17280, 540, 17280, 540, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 8640, 8640, 17280, 540, 17280, 17280, 8640, 540, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 540, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 17280, 540, 8640, 540, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 540, 540, 540, 540]
Prompts retrieved: 2266380 . Total input tokens: 505284175 . Total output tokens: 453316467
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 15.894725881051272,
    "estimated_duration": 3600.2276331029057,
    "input_throughput": 4687.461105189966,
    "output_throughput": 4114.4053958703125,
    "total_throughput": 8801.866501060278,
    "itl": 207.63653464451883,
    "ttft": 2156603.4835972805,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 787,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4610387461562433,
    "arrivals": 754714,
    "finished_requests": 68148,
    "scheduler_time": 93.9364351695461
}
#Debug simulation 
Total elapsed time: 15.89484886918217. Arrivals time: 0.9177566701546311 Scheduler time: 14.866538869217038 Scheduler overhead time: 0.03588609118014574 Adapter cache time: 0.02577326726168394 Engine time: 0.03461775556206703 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-16-32/adapters_256_slots_128_rate_1.6-0.8-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-16-32/adapters_256_slots_128_rate_1.6-0.8-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 540, 17280, 17280, 540, 17280, 8640, 17280, 540, 8640, 540, 17280, 8640, 8640, 8640, 8640, 17280, 540, 540, 540, 8640, 17280, 540, 17280, 17280, 8640, 8640, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 540, 8640, 8640, 17280, 8640, 540, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 540, 17280, 17280, 8640, 540, 540, 17280, 8640, 540, 8640, 8640, 17280, 8640, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 8640, 540, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 540, 17280, 17280, 540, 17280, 540, 8640, 17280, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 540, 540, 540, 17280, 8640, 540, 17280, 540, 17280, 540, 540, 8640, 8640, 17280, 8640, 17280, 540, 8640, 540, 17280, 17280, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 17280, 540, 17280, 8640, 540, 8640, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 8640, 17280, 17280, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 17280, 540, 17280, 540, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 8640, 8640, 17280, 540, 17280, 17280, 8640, 540, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 540, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 17280, 540, 8640, 540, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 540, 540, 540, 540]
Prompts retrieved: 2266380 . Total input tokens: 505284175 . Total output tokens: 453316467
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 9.461459004785866,
    "estimated_duration": 3600.109620397722,
    "input_throughput": 4471.085799387894,
    "output_throughput": 3932.4880330827154,
    "total_throughput": 8403.57383247061,
    "itl": 177.42541076180422,
    "ttft": 2180462.5576298553,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1096,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.6259811822324997,
    "arrivals": 754714,
    "finished_requests": 65072,
    "scheduler_time": 96.91738105877208
}
#Debug simulation 
Total elapsed time: 9.461571692023426. Arrivals time: 0.359063683077693 Scheduler time: 8.983951821923256 Scheduler overhead time: 0.03519374644383788 Adapter cache time: 0.03289267048239708 Engine time: 0.03485024068504572 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_16-16-16/adapters_256_slots_128_rate_1.6-0.8-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_16-16-16/adapters_256_slots_128_rate_1.6-0.8-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 540, 17280, 17280, 540, 17280, 8640, 17280, 540, 8640, 540, 17280, 8640, 8640, 8640, 8640, 17280, 540, 540, 540, 8640, 17280, 540, 17280, 17280, 8640, 8640, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 540, 8640, 8640, 17280, 8640, 540, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 540, 17280, 17280, 8640, 540, 540, 17280, 8640, 540, 8640, 8640, 17280, 8640, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 8640, 540, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 540, 17280, 17280, 540, 17280, 540, 8640, 17280, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 540, 540, 540, 17280, 8640, 540, 17280, 540, 17280, 540, 540, 8640, 8640, 17280, 8640, 17280, 540, 8640, 540, 17280, 17280, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 17280, 540, 17280, 8640, 540, 8640, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 8640, 17280, 17280, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 17280, 540, 17280, 540, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 8640, 8640, 17280, 540, 17280, 17280, 8640, 540, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 540, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 17280, 540, 8640, 540, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 540, 540, 540, 540]
Prompts retrieved: 2266380 . Total input tokens: 505284175 . Total output tokens: 453316467
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 15.508637498132885,
    "estimated_duration": 3600.031978856595,
    "input_throughput": 4673.729594297651,
    "output_throughput": 4103.173273669527,
    "total_throughput": 8776.902867967177,
    "itl": 208.3636840472358,
    "ttft": 2155035.4244470918,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 769,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2993486767797284,
    "arrivals": 754714,
    "finished_requests": 67934,
    "scheduler_time": 93.60800579459774
}
#Debug simulation 
Total elapsed time: 15.508780666161329. Arrivals time: 0.48860283102840185 Scheduler time: 14.913852892350405 Scheduler overhead time: 0.03477206686511636 Adapter cache time: 0.02334993425756693 Engine time: 0.03408337663859129 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_16-16-32/adapters_256_slots_128_rate_1.6-0.8-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_16-16-32/adapters_256_slots_128_rate_1.6-0.8-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 540, 17280, 17280, 540, 17280, 8640, 17280, 540, 8640, 540, 17280, 8640, 8640, 8640, 8640, 17280, 540, 540, 540, 8640, 17280, 540, 17280, 17280, 8640, 8640, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 540, 8640, 8640, 17280, 8640, 540, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 540, 17280, 17280, 8640, 540, 540, 17280, 8640, 540, 8640, 8640, 17280, 8640, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 8640, 540, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 540, 17280, 17280, 540, 17280, 540, 8640, 17280, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 540, 540, 540, 17280, 8640, 540, 17280, 540, 17280, 540, 540, 8640, 8640, 17280, 8640, 17280, 540, 8640, 540, 17280, 17280, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 17280, 540, 17280, 8640, 540, 8640, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 8640, 17280, 17280, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 17280, 540, 17280, 540, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 8640, 8640, 17280, 540, 17280, 17280, 8640, 540, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 540, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 17280, 540, 8640, 540, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 540, 540, 540, 540]
Prompts retrieved: 2266380 . Total input tokens: 505284175 . Total output tokens: 453316467
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 9.53509725164622,
    "estimated_duration": 3600.1564834139795,
    "input_throughput": 4471.027599538119,
    "output_throughput": 3932.436844127048,
    "total_throughput": 8403.464443665167,
    "itl": 177.42756887257136,
    "ttft": 2180480.930492334,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1096,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.672761590778878,
    "arrivals": 754714,
    "finished_requests": 65072,
    "scheduler_time": 96.91746366652339
}
#Debug simulation 
Total elapsed time: 9.535272207576782. Arrivals time: 0.3768612099811435 Scheduler time: 9.036173546686769 Scheduler overhead time: 0.035723940934985876 Adapter cache time: 0.035431640688329935 Engine time: 0.03528452850878239 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-8/adapters_256_slots_128_rate_1.6-0.8-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-8/adapters_256_slots_128_rate_1.6-0.8-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 270, 17280, 17280, 270, 17280, 8640, 17280, 270, 8640, 270, 17280, 8640, 8640, 8640, 8640, 17280, 270, 270, 270, 8640, 17280, 270, 17280, 17280, 8640, 8640, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 270, 8640, 8640, 17280, 8640, 270, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 270, 17280, 17280, 8640, 270, 270, 17280, 8640, 270, 8640, 8640, 17280, 8640, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 8640, 270, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 270, 17280, 17280, 270, 17280, 270, 8640, 17280, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 270, 270, 270, 17280, 8640, 270, 17280, 270, 17280, 270, 270, 8640, 8640, 17280, 8640, 17280, 270, 8640, 270, 17280, 17280, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 17280, 270, 17280, 8640, 270, 8640, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 8640, 17280, 17280, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 17280, 270, 17280, 270, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 8640, 8640, 17280, 270, 17280, 17280, 8640, 270, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 270, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 17280, 270, 8640, 270, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 270, 270, 270, 270]
Prompts retrieved: 2243430 . Total input tokens: 500187779 . Total output tokens: 448743425
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 14.563868469092995,
    "estimated_duration": 3600.119869334678,
    "input_throughput": 4623.187728211925,
    "output_throughput": 4092.686503442163,
    "total_throughput": 8715.874231654088,
    "itl": 210.22612870108344,
    "ttft": 2157522.458362604,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 532,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6281794797722455,
    "arrivals": 746983,
    "finished_requests": 67234,
    "scheduler_time": 93.30128420863711
}
#Debug simulation 
Total elapsed time: 14.564016513060778. Arrivals time: 0.4552994454279542 Scheduler time: 14.006011538207531 Scheduler overhead time: 0.03452580654993653 Adapter cache time: 0.02003770787268877 Engine time: 0.03412917675450444 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-16/adapters_256_slots_128_rate_1.6-0.8-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-16/adapters_256_slots_128_rate_1.6-0.8-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 270, 17280, 17280, 270, 17280, 8640, 17280, 270, 8640, 270, 17280, 8640, 8640, 8640, 8640, 17280, 270, 270, 270, 8640, 17280, 270, 17280, 17280, 8640, 8640, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 270, 8640, 8640, 17280, 8640, 270, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 270, 17280, 17280, 8640, 270, 270, 17280, 8640, 270, 8640, 8640, 17280, 8640, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 8640, 270, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 270, 17280, 17280, 270, 17280, 270, 8640, 17280, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 270, 270, 270, 17280, 8640, 270, 17280, 270, 17280, 270, 270, 8640, 8640, 17280, 8640, 17280, 270, 8640, 270, 17280, 17280, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 17280, 270, 17280, 8640, 270, 8640, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 8640, 17280, 17280, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 17280, 270, 17280, 270, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 8640, 8640, 17280, 270, 17280, 17280, 8640, 270, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 270, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 17280, 270, 8640, 270, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 270, 270, 270, 270]
Prompts retrieved: 2243430 . Total input tokens: 500187779 . Total output tokens: 448743425
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 14.831739824265242,
    "estimated_duration": 3600.189805156246,
    "input_throughput": 4625.43835220857,
    "output_throughput": 4094.555508958851,
    "total_throughput": 8719.99386116742,
    "itl": 210.19298425244887,
    "ttft": 2157659.430223499,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 565,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8401500891242226,
    "arrivals": 746983,
    "finished_requests": 67260,
    "scheduler_time": 93.30255504126512
}
#Debug simulation 
Total elapsed time: 14.831875511910766. Arrivals time: 0.5783770717680454 Scheduler time: 14.147256724070758 Scheduler overhead time: 0.03553530387580395 Adapter cache time: 0.0211997521109879 Engine time: 0.035213833674788475 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-32/adapters_256_slots_128_rate_1.6-0.8-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-32/adapters_256_slots_128_rate_1.6-0.8-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 270, 17280, 17280, 270, 17280, 8640, 17280, 270, 8640, 270, 17280, 8640, 8640, 8640, 8640, 17280, 270, 270, 270, 8640, 17280, 270, 17280, 17280, 8640, 8640, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 270, 8640, 8640, 17280, 8640, 270, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 270, 17280, 17280, 8640, 270, 270, 17280, 8640, 270, 8640, 8640, 17280, 8640, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 8640, 270, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 270, 17280, 17280, 270, 17280, 270, 8640, 17280, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 270, 270, 270, 17280, 8640, 270, 17280, 270, 17280, 270, 270, 8640, 8640, 17280, 8640, 17280, 270, 8640, 270, 17280, 17280, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 17280, 270, 17280, 8640, 270, 8640, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 8640, 17280, 17280, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 17280, 270, 17280, 270, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 8640, 8640, 17280, 270, 17280, 17280, 8640, 270, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 270, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 17280, 270, 8640, 270, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 270, 270, 270, 270]
Prompts retrieved: 2243430 . Total input tokens: 500187779 . Total output tokens: 448743425
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 8.758448733948171,
    "estimated_duration": 3600.191185465843,
    "input_throughput": 4438.712606295173,
    "output_throughput": 3932.1472862748087,
    "total_throughput": 8370.85989256998,
    "itl": 178.41316969926598,
    "ttft": 2182649.4193107816,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 907,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.963157340045995,
    "arrivals": 746983,
    "finished_requests": 64518,
    "scheduler_time": 96.74377041083389
}
#Debug simulation 
Total elapsed time: 8.758564099203795. Arrivals time: 0.45381513331085443 Scheduler time: 8.19231134466827 Scheduler overhead time: 0.034394362941384315 Adapter cache time: 0.028576391749083996 Engine time: 0.03412410570308566 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-16-16/adapters_256_slots_128_rate_1.6-0.8-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-16-16/adapters_256_slots_128_rate_1.6-0.8-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 270, 17280, 17280, 270, 17280, 8640, 17280, 270, 8640, 270, 17280, 8640, 8640, 8640, 8640, 17280, 270, 270, 270, 8640, 17280, 270, 17280, 17280, 8640, 8640, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 270, 8640, 8640, 17280, 8640, 270, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 270, 17280, 17280, 8640, 270, 270, 17280, 8640, 270, 8640, 8640, 17280, 8640, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 8640, 270, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 270, 17280, 17280, 270, 17280, 270, 8640, 17280, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 270, 270, 270, 17280, 8640, 270, 17280, 270, 17280, 270, 270, 8640, 8640, 17280, 8640, 17280, 270, 8640, 270, 17280, 17280, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 17280, 270, 17280, 8640, 270, 8640, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 8640, 17280, 17280, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 17280, 270, 17280, 270, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 8640, 8640, 17280, 270, 17280, 17280, 8640, 270, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 270, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 17280, 270, 8640, 270, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 270, 270, 270, 270]
Prompts retrieved: 2243430 . Total input tokens: 500187779 . Total output tokens: 448743425
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 14.662602826952934,
    "estimated_duration": 3600.156047797188,
    "input_throughput": 4623.141269163571,
    "output_throughput": 4092.6453754734684,
    "total_throughput": 8715.78664463704,
    "itl": 210.2278911950295,
    "ttft": 2157536.6607364444,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 532,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6642539142072137,
    "arrivals": 746983,
    "finished_requests": 67234,
    "scheduler_time": 93.30138823666215
}
#Debug simulation 
Total elapsed time: 14.662742638029158. Arrivals time: 0.6148355742916465 Scheduler time: 13.944363590795547 Scheduler overhead time: 0.034692682791501284 Adapter cache time: 0.02027500607073307 Engine time: 0.034556346479803324 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-16-32/adapters_256_slots_128_rate_1.6-0.8-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-16-32/adapters_256_slots_128_rate_1.6-0.8-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 270, 17280, 17280, 270, 17280, 8640, 17280, 270, 8640, 270, 17280, 8640, 8640, 8640, 8640, 17280, 270, 270, 270, 8640, 17280, 270, 17280, 17280, 8640, 8640, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 270, 8640, 8640, 17280, 8640, 270, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 270, 17280, 17280, 8640, 270, 270, 17280, 8640, 270, 8640, 8640, 17280, 8640, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 8640, 270, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 270, 17280, 17280, 270, 17280, 270, 8640, 17280, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 270, 270, 270, 17280, 8640, 270, 17280, 270, 17280, 270, 270, 8640, 8640, 17280, 8640, 17280, 270, 8640, 270, 17280, 17280, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 17280, 270, 17280, 8640, 270, 8640, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 8640, 17280, 17280, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 17280, 270, 17280, 270, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 8640, 8640, 17280, 270, 17280, 17280, 8640, 270, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 270, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 17280, 270, 8640, 270, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 270, 270, 270, 270]
Prompts retrieved: 2243430 . Total input tokens: 500187779 . Total output tokens: 448743425
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 9.26914752786979,
    "estimated_duration": 3600.0229750698163,
    "input_throughput": 4438.7913940160615,
    "output_throughput": 3932.0618501679082,
    "total_throughput": 8370.85324418397,
    "itl": 178.41388138050652,
    "ttft": 2182582.5246653566,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 907,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.999500184319913,
    "arrivals": 746983,
    "finished_requests": 64515,
    "scheduler_time": 96.73836443487998
}
#Debug simulation 
Total elapsed time: 9.269252286292613. Arrivals time: 0.8143925270996988 Scheduler time: 8.337692221160978 Scheduler overhead time: 0.03501554066315293 Adapter cache time: 0.03164707915857434 Engine time: 0.03482988243922591 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_16-16-16/adapters_256_slots_128_rate_1.6-0.8-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_16-16-16/adapters_256_slots_128_rate_1.6-0.8-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 270, 17280, 17280, 270, 17280, 8640, 17280, 270, 8640, 270, 17280, 8640, 8640, 8640, 8640, 17280, 270, 270, 270, 8640, 17280, 270, 17280, 17280, 8640, 8640, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 270, 8640, 8640, 17280, 8640, 270, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 270, 17280, 17280, 8640, 270, 270, 17280, 8640, 270, 8640, 8640, 17280, 8640, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 8640, 270, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 270, 17280, 17280, 270, 17280, 270, 8640, 17280, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 270, 270, 270, 17280, 8640, 270, 17280, 270, 17280, 270, 270, 8640, 8640, 17280, 8640, 17280, 270, 8640, 270, 17280, 17280, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 17280, 270, 17280, 8640, 270, 8640, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 8640, 17280, 17280, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 17280, 270, 17280, 270, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 8640, 8640, 17280, 270, 17280, 17280, 8640, 270, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 270, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 17280, 270, 8640, 270, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 270, 270, 270, 270]
Prompts retrieved: 2243430 . Total input tokens: 500187779 . Total output tokens: 448743425
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 14.560603900812566,
    "estimated_duration": 3600.074704621346,
    "input_throughput": 4623.245728382909,
    "output_throughput": 4092.73784821355,
    "total_throughput": 8715.98357659646,
    "itl": 210.2241675005964,
    "ttft": 2157504.312469892,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 532,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5907067568879378,
    "arrivals": 746983,
    "finished_requests": 67234,
    "scheduler_time": 93.30094856852703
}
#Debug simulation 
Total elapsed time: 14.560752269811928. Arrivals time: 0.6221962096169591 Scheduler time: 13.836315993685275 Scheduler overhead time: 0.03436745051294565 Adapter cache time: 0.02011538576334715 Engine time: 0.03370602382346988 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_16-16-32/adapters_256_slots_128_rate_1.6-0.8-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_16-16-32/adapters_256_slots_128_rate_1.6-0.8-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 270, 17280, 17280, 270, 17280, 8640, 17280, 270, 8640, 270, 17280, 8640, 8640, 8640, 8640, 17280, 270, 270, 270, 8640, 17280, 270, 17280, 17280, 8640, 8640, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 270, 8640, 8640, 17280, 8640, 270, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 270, 17280, 17280, 8640, 270, 270, 17280, 8640, 270, 8640, 8640, 17280, 8640, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 8640, 270, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 270, 17280, 17280, 270, 17280, 270, 8640, 17280, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 270, 270, 270, 17280, 8640, 270, 17280, 270, 17280, 270, 270, 8640, 8640, 17280, 8640, 17280, 270, 8640, 270, 17280, 17280, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 17280, 270, 17280, 8640, 270, 8640, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 8640, 17280, 17280, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 17280, 270, 17280, 270, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 8640, 8640, 17280, 270, 17280, 17280, 8640, 270, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 270, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 17280, 270, 8640, 270, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 270, 270, 270, 270]
Prompts retrieved: 2243430 . Total input tokens: 500187779 . Total output tokens: 448743425
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 9.253245068714023,
    "estimated_duration": 3600.0622926726323,
    "input_throughput": 4438.742916344615,
    "output_throughput": 3932.0189066759617,
    "total_throughput": 8370.761823020577,
    "itl": 178.41564395648936,
    "ttft": 2182597.4796270714,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 907,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0387353656813785,
    "arrivals": 746983,
    "finished_requests": 64515,
    "scheduler_time": 96.73844685636804
}
#Debug simulation 
Total elapsed time: 9.25335306674242. Arrivals time: 0.8009749935008585 Scheduler time: 8.340655855368823 Scheduler overhead time: 0.03496198728680611 Adapter cache time: 0.026729740668088198 Engine time: 0.03446408361196518 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-8/adapters_256_slots_128_rate_1.6-0.8-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-8/adapters_256_slots_128_rate_1.6-0.8-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 135, 17280, 17280, 135, 17280, 8640, 17280, 135, 8640, 135, 17280, 8640, 8640, 8640, 8640, 17280, 135, 135, 135, 8640, 17280, 135, 17280, 17280, 8640, 8640, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 135, 8640, 8640, 17280, 8640, 135, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 135, 17280, 17280, 8640, 135, 135, 17280, 8640, 135, 8640, 8640, 17280, 8640, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 8640, 135, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 135, 17280, 17280, 135, 17280, 135, 8640, 17280, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 135, 135, 135, 17280, 8640, 135, 17280, 135, 17280, 135, 135, 8640, 8640, 17280, 8640, 17280, 135, 8640, 135, 17280, 17280, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 17280, 135, 17280, 8640, 135, 8640, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 8640, 17280, 17280, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 17280, 135, 17280, 135, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 8640, 8640, 17280, 135, 17280, 17280, 8640, 135, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 135, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 17280, 135, 8640, 135, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 135, 135, 135, 135]
Prompts retrieved: 2231955 . Total input tokens: 497616808 . Total output tokens: 446425470
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 14.133259650319815,
    "estimated_duration": 3600.171100701235,
    "input_throughput": 4676.72911343589,
    "output_throughput": 4092.1902287172998,
    "total_throughput": 8768.91934215319,
    "itl": 208.4203338192544,
    "ttft": 2155354.162974592,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 499,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5271833842224611,
    "arrivals": 743226,
    "finished_requests": 67914,
    "scheduler_time": 93.40043823413278
}
#Debug simulation 
Total elapsed time: 14.133368238341063. Arrivals time: 0.7596457079052925 Scheduler time: 13.271427815780044 Scheduler overhead time: 0.034740209113806486 Adapter cache time: 0.019200931768864393 Engine time: 0.034206745214760303 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-16/adapters_256_slots_128_rate_1.6-0.8-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-16/adapters_256_slots_128_rate_1.6-0.8-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 135, 17280, 17280, 135, 17280, 8640, 17280, 135, 8640, 135, 17280, 8640, 8640, 8640, 8640, 17280, 135, 135, 135, 8640, 17280, 135, 17280, 17280, 8640, 8640, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 135, 8640, 8640, 17280, 8640, 135, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 135, 17280, 17280, 8640, 135, 135, 17280, 8640, 135, 8640, 8640, 17280, 8640, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 8640, 135, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 135, 17280, 17280, 135, 17280, 135, 8640, 17280, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 135, 135, 135, 17280, 8640, 135, 17280, 135, 17280, 135, 135, 8640, 8640, 17280, 8640, 17280, 135, 8640, 135, 17280, 17280, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 17280, 135, 17280, 8640, 135, 8640, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 8640, 17280, 17280, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 17280, 135, 17280, 135, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 8640, 8640, 17280, 135, 17280, 17280, 8640, 135, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 135, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 17280, 135, 8640, 135, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 135, 135, 135, 135]
Prompts retrieved: 2231955 . Total input tokens: 497616808 . Total output tokens: 446425470
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 14.27342593902722,
    "estimated_duration": 3600.051768046449,
    "input_throughput": 4676.338587524108,
    "output_throughput": 4091.975046234927,
    "total_throughput": 8768.313633759035,
    "itl": 208.42693946070813,
    "ttft": 2155347.4924632804,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 499,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6325918866996718,
    "arrivals": 743226,
    "finished_requests": 67909,
    "scheduler_time": 93.3949522334784
}
#Debug simulation 
Total elapsed time: 14.273517177905887. Arrivals time: 0.7178770890459418 Scheduler time: 13.453053446486592 Scheduler overhead time: 0.0344419302418828 Adapter cache time: 0.01950147608295083 Engine time: 0.03437812114134431 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-32/adapters_256_slots_128_rate_1.6-0.8-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-32/adapters_256_slots_128_rate_1.6-0.8-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 135, 17280, 17280, 135, 17280, 8640, 17280, 135, 8640, 135, 17280, 8640, 8640, 8640, 8640, 17280, 135, 135, 135, 8640, 17280, 135, 17280, 17280, 8640, 8640, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 135, 8640, 8640, 17280, 8640, 135, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 135, 17280, 17280, 8640, 135, 135, 17280, 8640, 135, 8640, 8640, 17280, 8640, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 8640, 135, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 135, 17280, 17280, 135, 17280, 135, 8640, 17280, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 135, 135, 135, 17280, 8640, 135, 17280, 135, 17280, 135, 135, 8640, 8640, 17280, 8640, 17280, 135, 8640, 135, 17280, 17280, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 17280, 135, 17280, 8640, 135, 8640, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 8640, 17280, 17280, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 17280, 135, 17280, 135, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 8640, 8640, 17280, 135, 17280, 17280, 8640, 135, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 135, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 17280, 135, 8640, 135, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 135, 135, 135, 135]
Prompts retrieved: 2231955 . Total input tokens: 497616808 . Total output tokens: 446425470
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 8.377722878940403,
    "estimated_duration": 3600.08053005824,
    "input_throughput": 4493.89225183201,
    "output_throughput": 3932.8964676717796,
    "total_throughput": 8426.78871950379,
    "itl": 178.24966234432102,
    "ttft": 2179612.4903234313,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 849,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.776853069476767,
    "arrivals": 743226,
    "finished_requests": 65253,
    "scheduler_time": 96.69175237611405
}
#Debug simulation 
Total elapsed time: 8.377809986937791. Arrivals time: 0.6784815336577594 Scheduler time: 7.590408700052649 Scheduler overhead time: 0.034345290157943964 Adapter cache time: 0.025038385298103094 Engine time: 0.03412886755540967 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-16/adapters_256_slots_128_rate_1.6-0.8-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-16/adapters_256_slots_128_rate_1.6-0.8-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 135, 17280, 17280, 135, 17280, 8640, 17280, 135, 8640, 135, 17280, 8640, 8640, 8640, 8640, 17280, 135, 135, 135, 8640, 17280, 135, 17280, 17280, 8640, 8640, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 135, 8640, 8640, 17280, 8640, 135, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 135, 17280, 17280, 8640, 135, 135, 17280, 8640, 135, 8640, 8640, 17280, 8640, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 8640, 135, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 135, 17280, 17280, 135, 17280, 135, 8640, 17280, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 135, 135, 135, 17280, 8640, 135, 17280, 135, 17280, 135, 135, 8640, 8640, 17280, 8640, 17280, 135, 8640, 135, 17280, 17280, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 17280, 135, 17280, 8640, 135, 8640, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 8640, 17280, 17280, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 17280, 135, 17280, 135, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 8640, 8640, 17280, 135, 17280, 17280, 8640, 135, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 135, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 17280, 135, 8640, 135, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 135, 135, 135, 135]
Prompts retrieved: 2231955 . Total input tokens: 497616808 . Total output tokens: 446425470
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 14.176098787225783,
    "estimated_duration": 3600.209245760973,
    "input_throughput": 4676.67956239615,
    "output_throughput": 4092.146871003879,
    "total_throughput": 8768.826433400029,
    "itl": 208.42205438587987,
    "ttft": 2155371.137666233,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 499,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5651736591570033,
    "arrivals": 743226,
    "finished_requests": 67914,
    "scheduler_time": 93.40059301889342
}
#Debug simulation 
Total elapsed time: 14.176198979374021. Arrivals time: 0.7853273972868919 Scheduler time: 13.288930535316467 Scheduler overhead time: 0.03485336434096098 Adapter cache time: 0.018892907071858644 Engine time: 0.03421388380229473 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-32/adapters_256_slots_128_rate_1.6-0.8-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-32/adapters_256_slots_128_rate_1.6-0.8-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 135, 17280, 17280, 135, 17280, 8640, 17280, 135, 8640, 135, 17280, 8640, 8640, 8640, 8640, 17280, 135, 135, 135, 8640, 17280, 135, 17280, 17280, 8640, 8640, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 135, 8640, 8640, 17280, 8640, 135, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 135, 17280, 17280, 8640, 135, 135, 17280, 8640, 135, 8640, 8640, 17280, 8640, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 8640, 135, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 135, 17280, 17280, 135, 17280, 135, 8640, 17280, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 135, 135, 135, 17280, 8640, 135, 17280, 135, 17280, 135, 135, 8640, 8640, 17280, 8640, 17280, 135, 8640, 135, 17280, 17280, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 17280, 135, 17280, 8640, 135, 8640, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 8640, 17280, 17280, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 17280, 135, 17280, 135, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 8640, 8640, 17280, 135, 17280, 17280, 8640, 135, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 135, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 17280, 135, 8640, 135, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 135, 135, 135, 135]
Prompts retrieved: 2231955 . Total input tokens: 497616808 . Total output tokens: 446425470
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 8.41719310497865,
    "estimated_duration": 3600.113575710989,
    "input_throughput": 4493.851002132598,
    "output_throughput": 3932.8603673854313,
    "total_throughput": 8426.711369518029,
    "itl": 178.25111263505147,
    "ttft": 2179626.5802989574,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 849,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8098005615174744,
    "arrivals": 743226,
    "finished_requests": 65253,
    "scheduler_time": 96.69185053684673
}
#Debug simulation 
Total elapsed time: 8.41728333197534. Arrivals time: 0.6243955180980265 Scheduler time: 7.683466692455113 Scheduler overhead time: 0.03450001077726483 Adapter cache time: 0.024853212293237448 Engine time: 0.03454919531941414 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-16/adapters_256_slots_128_rate_1.6-0.8-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-16/adapters_256_slots_128_rate_1.6-0.8-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 135, 17280, 17280, 135, 17280, 8640, 17280, 135, 8640, 135, 17280, 8640, 8640, 8640, 8640, 17280, 135, 135, 135, 8640, 17280, 135, 17280, 17280, 8640, 8640, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 135, 8640, 8640, 17280, 8640, 135, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 135, 17280, 17280, 8640, 135, 135, 17280, 8640, 135, 8640, 8640, 17280, 8640, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 8640, 135, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 135, 17280, 17280, 135, 17280, 135, 8640, 17280, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 135, 135, 135, 17280, 8640, 135, 17280, 135, 17280, 135, 135, 8640, 8640, 17280, 8640, 17280, 135, 8640, 135, 17280, 17280, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 17280, 135, 17280, 8640, 135, 8640, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 8640, 17280, 17280, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 17280, 135, 17280, 135, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 8640, 8640, 17280, 135, 17280, 17280, 8640, 135, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 135, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 17280, 135, 8640, 135, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 135, 135, 135, 135]
Prompts retrieved: 2231955 . Total input tokens: 497616808 . Total output tokens: 446425470
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 14.485278261825442,
    "estimated_duration": 3600.135810109105,
    "input_throughput": 4676.774957411882,
    "output_throughput": 4092.2303427085203,
    "total_throughput": 8769.005300120401,
    "itl": 208.41868377515613,
    "ttft": 2155337.890894934,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 499,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4920350971561696,
    "arrivals": 743226,
    "finished_requests": 67914,
    "scheduler_time": 93.4002959290099
}
#Debug simulation 
Total elapsed time: 14.485407846048474. Arrivals time: 0.7624739985913038 Scheduler time: 13.619862826541066 Scheduler overhead time: 0.034622302278876305 Adapter cache time: 0.019483332987874746 Engine time: 0.03461031895130873 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-32/adapters_256_slots_128_rate_1.6-0.8-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-32/adapters_256_slots_128_rate_1.6-0.8-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 135, 17280, 17280, 135, 17280, 8640, 17280, 135, 8640, 135, 17280, 8640, 8640, 8640, 8640, 17280, 135, 135, 135, 8640, 17280, 135, 17280, 17280, 8640, 8640, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 135, 8640, 8640, 17280, 8640, 135, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 135, 17280, 17280, 8640, 135, 135, 17280, 8640, 135, 8640, 8640, 17280, 8640, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 8640, 135, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 135, 17280, 17280, 135, 17280, 135, 8640, 17280, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 135, 135, 135, 17280, 8640, 135, 17280, 135, 17280, 135, 135, 8640, 8640, 17280, 8640, 17280, 135, 8640, 135, 17280, 17280, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 17280, 135, 17280, 8640, 135, 8640, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 8640, 17280, 17280, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 17280, 135, 17280, 135, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 8640, 8640, 17280, 135, 17280, 17280, 8640, 135, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 135, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 17280, 135, 8640, 135, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 135, 135, 135, 135]
Prompts retrieved: 2231955 . Total input tokens: 497616808 . Total output tokens: 446425470
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 8.250623672734946,
    "estimated_duration": 3600.152665368533,
    "input_throughput": 4493.802208897129,
    "output_throughput": 3932.8176652616003,
    "total_throughput": 8426.619874158729,
    "itl": 178.25282725614306,
    "ttft": 2179642.196124121,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 849,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8487842353061064,
    "arrivals": 743226,
    "finished_requests": 65253,
    "scheduler_time": 96.6919565206359
}
#Debug simulation 
Total elapsed time: 8.250747286714613. Arrivals time: 0.6996369790285826 Scheduler time: 7.442186780273914 Scheduler overhead time: 0.03430073242634535 Adapter cache time: 0.02586365770548582 Engine time: 0.03363218763843179 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-8/adapters_256_slots_128_rate_1.6-0.8-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-8/adapters_256_slots_128_rate_1.6-0.8-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 66, 17280, 17280, 66, 17280, 8640, 17280, 66, 8640, 66, 17280, 8640, 8640, 8640, 8640, 17280, 66, 66, 66, 8640, 17280, 66, 17280, 17280, 8640, 8640, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 66, 8640, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 66, 17280, 17280, 8640, 66, 66, 17280, 8640, 66, 8640, 8640, 17280, 8640, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 8640, 66, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 66, 17280, 17280, 66, 17280, 66, 8640, 17280, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 66, 66, 66, 17280, 8640, 66, 17280, 66, 17280, 66, 66, 8640, 8640, 17280, 8640, 17280, 66, 8640, 66, 17280, 17280, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 8640, 17280, 17280, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 17280, 66, 17280, 66, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 8640, 8640, 17280, 66, 17280, 17280, 8640, 66, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 66, 8640, 66, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 66, 66, 66, 66]
Prompts retrieved: 2226090 . Total input tokens: 496312659 . Total output tokens: 445233650
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 12.521790960803628,
    "estimated_duration": 3600.132773757437,
    "input_throughput": 4667.626461582328,
    "output_throughput": 4107.0715801872875,
    "total_throughput": 8774.698041769616,
    "itl": 208.5857767938486,
    "ttft": 2155070.175996063,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 648,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9831960580684573,
    "arrivals": 741292,
    "finished_requests": 67691,
    "scheduler_time": 93.67769126452035
}
#Debug simulation 
Total elapsed time: 12.521880177780986. Arrivals time: 0.4133551483973861 Scheduler time: 12.010962824802846 Scheduler overhead time: 0.0332169970497489 Adapter cache time: 0.017863469198346138 Engine time: 0.03269737120717764 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-16/adapters_256_slots_128_rate_1.6-0.8-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-16/adapters_256_slots_128_rate_1.6-0.8-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 66, 17280, 17280, 66, 17280, 8640, 17280, 66, 8640, 66, 17280, 8640, 8640, 8640, 8640, 17280, 66, 66, 66, 8640, 17280, 66, 17280, 17280, 8640, 8640, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 66, 8640, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 66, 17280, 17280, 8640, 66, 66, 17280, 8640, 66, 8640, 8640, 17280, 8640, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 8640, 66, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 66, 17280, 17280, 66, 17280, 66, 8640, 17280, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 66, 66, 66, 17280, 8640, 66, 17280, 66, 17280, 66, 66, 8640, 8640, 17280, 8640, 17280, 66, 8640, 66, 17280, 17280, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 8640, 17280, 17280, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 17280, 66, 17280, 66, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 8640, 8640, 17280, 66, 17280, 17280, 8640, 66, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 66, 8640, 66, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 66, 66, 66, 66]
Prompts retrieved: 2226090 . Total input tokens: 496312659 . Total output tokens: 445233650
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 12.968731340020895,
    "estimated_duration": 3600.1648257316015,
    "input_throughput": 4672.758002567675,
    "output_throughput": 4113.322782934164,
    "total_throughput": 8786.08078550184,
    "itl": 208.26717500127543,
    "ttft": 2156170.3363253972,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 648,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.113248578025965,
    "arrivals": 741292,
    "finished_requests": 67795,
    "scheduler_time": 93.82432302400771
}
#Debug simulation 
Total elapsed time: 12.968840193003416. Arrivals time: 0.39123604353517294 Scheduler time: 12.47665055654943 Scheduler overhead time: 0.03430666634812951 Adapter cache time: 0.018147376365959644 Engine time: 0.03431601682677865 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-32/adapters_256_slots_128_rate_1.6-0.8-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-32/adapters_256_slots_128_rate_1.6-0.8-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 66, 17280, 17280, 66, 17280, 8640, 17280, 66, 8640, 66, 17280, 8640, 8640, 8640, 8640, 17280, 66, 66, 66, 8640, 17280, 66, 17280, 17280, 8640, 8640, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 66, 8640, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 66, 17280, 17280, 8640, 66, 66, 17280, 8640, 66, 8640, 8640, 17280, 8640, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 8640, 66, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 66, 17280, 17280, 66, 17280, 66, 8640, 17280, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 66, 66, 66, 17280, 8640, 66, 17280, 66, 17280, 66, 66, 8640, 8640, 17280, 8640, 17280, 66, 8640, 66, 17280, 17280, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 8640, 17280, 17280, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 17280, 66, 17280, 66, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 8640, 8640, 17280, 66, 17280, 17280, 8640, 66, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 66, 8640, 66, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 66, 66, 66, 66]
Prompts retrieved: 2226090 . Total input tokens: 496312659 . Total output tokens: 445233650
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 8.427617841400206,
    "estimated_duration": 3600.0775668875776,
    "input_throughput": 4461.858029877725,
    "output_throughput": 3930.038933086639,
    "total_throughput": 8391.896962964363,
    "itl": 178.18391498566268,
    "ttft": 2179922.644245483,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 701,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2910012929327803,
    "arrivals": 741292,
    "finished_requests": 64737,
    "scheduler_time": 96.74981438951839
}
#Debug simulation 
Total elapsed time: 8.427727288100868. Arrivals time: 0.7077382602728903 Scheduler time: 7.612195190507919 Scheduler overhead time: 0.034176759887486696 Adapter cache time: 0.024059027433395386 Engine time: 0.03415136132389307 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-16/adapters_256_slots_128_rate_1.6-0.8-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-16/adapters_256_slots_128_rate_1.6-0.8-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 66, 17280, 17280, 66, 17280, 8640, 17280, 66, 8640, 66, 17280, 8640, 8640, 8640, 8640, 17280, 66, 66, 66, 8640, 17280, 66, 17280, 17280, 8640, 8640, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 66, 8640, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 66, 17280, 17280, 8640, 66, 66, 17280, 8640, 66, 8640, 8640, 17280, 8640, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 8640, 66, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 66, 17280, 17280, 66, 17280, 66, 8640, 17280, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 66, 66, 66, 17280, 8640, 66, 17280, 66, 17280, 66, 66, 8640, 8640, 17280, 8640, 17280, 66, 8640, 66, 17280, 17280, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 8640, 17280, 17280, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 17280, 66, 17280, 66, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 8640, 8640, 17280, 66, 17280, 17280, 8640, 66, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 66, 8640, 66, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 66, 66, 66, 66]
Prompts retrieved: 2226090 . Total input tokens: 496312659 . Total output tokens: 445233650
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 12.76736156316474,
    "estimated_duration": 3600.0787602255923,
    "input_throughput": 4672.869712146475,
    "output_throughput": 4113.421118340212,
    "total_throughput": 8786.290830486687,
    "itl": 208.26300526321882,
    "ttft": 2156137.88361807,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 648,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.027443561153472,
    "arrivals": 741292,
    "finished_requests": 67795,
    "scheduler_time": 93.8240625348528
}
#Debug simulation 
Total elapsed time: 12.767471092287451. Arrivals time: 0.4190453374758363 Scheduler time: 12.24770936369896 Scheduler overhead time: 0.033826525788754225 Adapter cache time: 0.019497905392199755 Engine time: 0.03326642978936434 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-32/adapters_256_slots_128_rate_1.6-0.8-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-32/adapters_256_slots_128_rate_1.6-0.8-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 66, 17280, 17280, 66, 17280, 8640, 17280, 66, 8640, 66, 17280, 8640, 8640, 8640, 8640, 17280, 66, 66, 66, 8640, 17280, 66, 17280, 17280, 8640, 8640, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 66, 8640, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 66, 17280, 17280, 8640, 66, 66, 17280, 8640, 66, 8640, 8640, 17280, 8640, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 8640, 66, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 66, 17280, 17280, 66, 17280, 66, 8640, 17280, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 66, 66, 66, 17280, 8640, 66, 17280, 66, 17280, 66, 66, 8640, 8640, 17280, 8640, 17280, 66, 8640, 66, 17280, 17280, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 8640, 17280, 17280, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 17280, 66, 17280, 66, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 8640, 8640, 17280, 66, 17280, 17280, 8640, 66, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 66, 8640, 66, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 66, 66, 66, 66]
Prompts retrieved: 2226090 . Total input tokens: 496312659 . Total output tokens: 445233650
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 8.05072273593396,
    "estimated_duration": 3600.1040634714846,
    "input_throughput": 4461.82519082819,
    "output_throughput": 3930.0100081987716,
    "total_throughput": 8391.835199026962,
    "itl": 178.1850491987337,
    "ttft": 2179934.3739040326,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 701,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3174095880799017,
    "arrivals": 741292,
    "finished_requests": 64737,
    "scheduler_time": 96.74990267829881
}
#Debug simulation 
Total elapsed time: 8.05081995204091. Arrivals time: 0.3538794689811766 Scheduler time: 7.589583565015346 Scheduler overhead time: 0.03425884200260043 Adapter cache time: 0.024014077614992857 Engine time: 0.03385486686602235 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-16/adapters_256_slots_128_rate_1.6-0.8-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-16/adapters_256_slots_128_rate_1.6-0.8-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 66, 17280, 17280, 66, 17280, 8640, 17280, 66, 8640, 66, 17280, 8640, 8640, 8640, 8640, 17280, 66, 66, 66, 8640, 17280, 66, 17280, 17280, 8640, 8640, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 66, 8640, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 66, 17280, 17280, 8640, 66, 66, 17280, 8640, 66, 8640, 8640, 17280, 8640, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 8640, 66, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 66, 17280, 17280, 66, 17280, 66, 8640, 17280, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 66, 66, 66, 17280, 8640, 66, 17280, 66, 17280, 66, 66, 8640, 8640, 17280, 8640, 17280, 66, 8640, 66, 17280, 17280, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 8640, 17280, 17280, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 17280, 66, 17280, 66, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 8640, 8640, 17280, 66, 17280, 17280, 8640, 66, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 66, 8640, 66, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 66, 66, 66, 66]
Prompts retrieved: 2226090 . Total input tokens: 496312659 . Total output tokens: 445233650
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 12.52469876781106,
    "estimated_duration": 3600.0216872044703,
    "input_throughput": 4652.945580727167,
    "output_throughput": 4091.9925711445608,
    "total_throughput": 8744.938151871727,
    "itl": 209.2083970709621,
    "ttft": 2156656.633403966,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 532,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5907067568879378,
    "arrivals": 741292,
    "finished_requests": 67451,
    "scheduler_time": 93.37054245432518
}
#Debug simulation 
Total elapsed time: 12.524795609991997. Arrivals time: 0.7374647352844477 Scheduler time: 11.690058530773968 Scheduler overhead time: 0.03294335212558508 Adapter cache time: 0.01743154413998127 Engine time: 0.03296986222267151 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-32/adapters_256_slots_128_rate_1.6-0.8-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-32/adapters_256_slots_128_rate_1.6-0.8-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 66, 17280, 17280, 66, 17280, 8640, 17280, 66, 8640, 66, 17280, 8640, 8640, 8640, 8640, 17280, 66, 66, 66, 8640, 17280, 66, 17280, 17280, 8640, 8640, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 66, 8640, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 66, 17280, 17280, 8640, 66, 66, 17280, 8640, 66, 8640, 8640, 17280, 8640, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 8640, 66, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 66, 17280, 17280, 66, 17280, 66, 8640, 17280, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 66, 66, 66, 17280, 8640, 66, 17280, 66, 17280, 66, 66, 8640, 8640, 17280, 8640, 17280, 66, 8640, 66, 17280, 17280, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 8640, 17280, 17280, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 17280, 66, 17280, 66, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 8640, 8640, 17280, 66, 17280, 17280, 8640, 66, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 66, 8640, 66, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 66, 66, 66, 66]
Prompts retrieved: 2226090 . Total input tokens: 496312659 . Total output tokens: 445233650
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 8.172038294840604,
    "estimated_duration": 3600.1364675962623,
    "input_throughput": 4461.785030811613,
    "output_throughput": 3929.9746349467214,
    "total_throughput": 8391.759665758334,
    "itl": 178.18649231932577,
    "ttft": 2179947.6302966024,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 701,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.349728311188526,
    "arrivals": 741292,
    "finished_requests": 64737,
    "scheduler_time": 96.74998807999887
}
#Debug simulation 
Total elapsed time: 8.172178027685732. Arrivals time: 0.3660618010908365 Scheduler time: 7.6960632763803005 Scheduler overhead time: 0.034717950504273176 Adapter cache time: 0.025300055742263794 Engine time: 0.0344672747887671 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-8/adapters_256_slots_128_rate_1.6-0.8-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-8/adapters_256_slots_128_rate_1.6-0.8-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 33, 17280, 17280, 33, 17280, 8640, 17280, 33, 8640, 33, 17280, 8640, 8640, 8640, 8640, 17280, 33, 33, 33, 8640, 17280, 33, 17280, 17280, 8640, 8640, 8640, 33, 17280, 33, 8640, 8640, 33, 8640, 33, 33, 8640, 8640, 17280, 8640, 33, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 33, 17280, 17280, 8640, 33, 33, 17280, 8640, 33, 8640, 8640, 17280, 8640, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 8640, 33, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 33, 17280, 17280, 33, 17280, 33, 8640, 17280, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 33, 33, 33, 17280, 8640, 33, 17280, 33, 17280, 33, 33, 8640, 8640, 17280, 8640, 17280, 33, 8640, 33, 17280, 17280, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 33, 8640, 17280, 17280, 33, 17280, 8640, 33, 8640, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 8640, 17280, 17280, 8640, 33, 17280, 33, 8640, 8640, 33, 8640, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 17280, 33, 17280, 33, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 8640, 8640, 33, 8640, 17280, 8640, 8640, 17280, 33, 17280, 17280, 8640, 33, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 33, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 17280, 33, 8640, 33, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 33, 33, 33, 33]
Prompts retrieved: 2223285 . Total input tokens: 495676136 . Total output tokens: 444666343
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 12.09682355588302,
    "estimated_duration": 3600.128160347948,
    "input_throughput": 4684.990158341993,
    "output_throughput": 4110.963371528862,
    "total_throughput": 8795.953529870854,
    "itl": 207.87279612949345,
    "ttft": 2149763.8949851035,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 644,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.970954107092726,
    "arrivals": 740358,
    "finished_requests": 68213,
    "scheduler_time": 93.85966288128533
}
#Debug simulation 
Total elapsed time: 12.09696086263284. Arrivals time: 0.41980759473517537 Scheduler time: 11.57955675246194 Scheduler overhead time: 0.03304382041096687 Adapter cache time: 0.018091516103595495 Engine time: 0.0326905632391572 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-16/adapters_256_slots_128_rate_1.6-0.8-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-16/adapters_256_slots_128_rate_1.6-0.8-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 33, 17280, 17280, 33, 17280, 8640, 17280, 33, 8640, 33, 17280, 8640, 8640, 8640, 8640, 17280, 33, 33, 33, 8640, 17280, 33, 17280, 17280, 8640, 8640, 8640, 33, 17280, 33, 8640, 8640, 33, 8640, 33, 33, 8640, 8640, 17280, 8640, 33, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 33, 17280, 17280, 8640, 33, 33, 17280, 8640, 33, 8640, 8640, 17280, 8640, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 8640, 33, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 33, 17280, 17280, 33, 17280, 33, 8640, 17280, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 33, 33, 33, 17280, 8640, 33, 17280, 33, 17280, 33, 33, 8640, 8640, 17280, 8640, 17280, 33, 8640, 33, 17280, 17280, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 33, 8640, 17280, 17280, 33, 17280, 8640, 33, 8640, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 8640, 17280, 17280, 8640, 33, 17280, 33, 8640, 8640, 33, 8640, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 17280, 33, 17280, 33, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 8640, 8640, 33, 8640, 17280, 8640, 8640, 17280, 33, 17280, 17280, 8640, 33, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 33, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 17280, 33, 8640, 33, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 33, 33, 33, 33]
Prompts retrieved: 2223285 . Total input tokens: 495676136 . Total output tokens: 444666343
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 12.364541558083147,
    "estimated_duration": 3600.038434568061,
    "input_throughput": 4692.424346860297,
    "output_throughput": 4115.22162034293,
    "total_throughput": 8807.645967203227,
    "itl": 207.65503226567765,
    "ttft": 2150359.735388626,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 639,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.086338125371846,
    "arrivals": 740358,
    "finished_requests": 68341,
    "scheduler_time": 93.93704829046321
}
#Debug simulation 
Total elapsed time: 12.364653856959194. Arrivals time: 0.5307872388511896 Scheduler time: 11.734396184328943 Scheduler overhead time: 0.03383422642946243 Adapter cache time: 0.01773869339376688 Engine time: 0.033823037054389715 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-32/adapters_256_slots_128_rate_1.6-0.8-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-32/adapters_256_slots_128_rate_1.6-0.8-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 33, 17280, 17280, 33, 17280, 8640, 17280, 33, 8640, 33, 17280, 8640, 8640, 8640, 8640, 17280, 33, 33, 33, 8640, 17280, 33, 17280, 17280, 8640, 8640, 8640, 33, 17280, 33, 8640, 8640, 33, 8640, 33, 33, 8640, 8640, 17280, 8640, 33, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 33, 17280, 17280, 8640, 33, 33, 17280, 8640, 33, 8640, 8640, 17280, 8640, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 8640, 33, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 33, 17280, 17280, 33, 17280, 33, 8640, 17280, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 33, 33, 33, 17280, 8640, 33, 17280, 33, 17280, 33, 33, 8640, 8640, 17280, 8640, 17280, 33, 8640, 33, 17280, 17280, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 33, 8640, 17280, 17280, 33, 17280, 8640, 33, 8640, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 8640, 17280, 17280, 8640, 33, 17280, 33, 8640, 8640, 33, 8640, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 17280, 33, 17280, 33, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 8640, 8640, 33, 8640, 17280, 8640, 8640, 17280, 33, 17280, 17280, 8640, 33, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 33, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 17280, 33, 8640, 33, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 33, 33, 33, 33]
Prompts retrieved: 2223285 . Total input tokens: 495676136 . Total output tokens: 444666343
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 7.980505638290197,
    "estimated_duration": 3600.120392987223,
    "input_throughput": 4476.808895445514,
    "output_throughput": 3932.9251398316364,
    "total_throughput": 8409.73403527715,
    "itl": 178.49257336897836,
    "ttft": 2174944.0268776203,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 681,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.225409451033924,
    "arrivals": 740358,
    "finished_requests": 65208,
    "scheduler_time": 96.70852415269388
}
#Debug simulation 
Total elapsed time: 7.980602846015245. Arrivals time: 0.36361177964136004 Scheduler time: 7.507119184359908 Scheduler overhead time: 0.03504755347967148 Adapter cache time: 0.02461537951603532 Engine time: 0.03458654275164008 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-16/adapters_256_slots_128_rate_1.6-0.8-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-16/adapters_256_slots_128_rate_1.6-0.8-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 33, 17280, 17280, 33, 17280, 8640, 17280, 33, 8640, 33, 17280, 8640, 8640, 8640, 8640, 17280, 33, 33, 33, 8640, 17280, 33, 17280, 17280, 8640, 8640, 8640, 33, 17280, 33, 8640, 8640, 33, 8640, 33, 33, 8640, 8640, 17280, 8640, 33, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 33, 17280, 17280, 8640, 33, 33, 17280, 8640, 33, 8640, 8640, 17280, 8640, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 8640, 33, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 33, 17280, 17280, 33, 17280, 33, 8640, 17280, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 33, 33, 33, 17280, 8640, 33, 17280, 33, 17280, 33, 33, 8640, 8640, 17280, 8640, 17280, 33, 8640, 33, 17280, 17280, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 33, 8640, 17280, 17280, 33, 17280, 8640, 33, 8640, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 8640, 17280, 17280, 8640, 33, 17280, 33, 8640, 8640, 33, 8640, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 17280, 33, 17280, 33, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 8640, 8640, 33, 8640, 17280, 8640, 8640, 17280, 33, 17280, 17280, 8640, 33, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 33, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 17280, 33, 8640, 33, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 33, 33, 33, 33]
Prompts retrieved: 2223285 . Total input tokens: 495676136 . Total output tokens: 444666343
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 12.31239442806691,
    "estimated_duration": 3600.174057878218,
    "input_throughput": 4684.930430819337,
    "output_throughput": 4110.91096210011,
    "total_throughput": 8795.841392919447,
    "itl": 207.87500012175204,
    "ttft": 2149784.144705999,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 644,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0167091459291857,
    "arrivals": 740358,
    "finished_requests": 68213,
    "scheduler_time": 93.85980537267147
}
#Debug simulation 
Total elapsed time: 12.312540451996028. Arrivals time: 0.4178745006211102 Scheduler time: 11.793935077264905 Scheduler overhead time: 0.03379710344597697 Adapter cache time: 0.0191376400180161 Engine time: 0.03373466385528445 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-32/adapters_256_slots_128_rate_1.6-0.8-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-32/adapters_256_slots_128_rate_1.6-0.8-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 33, 17280, 17280, 33, 17280, 8640, 17280, 33, 8640, 33, 17280, 8640, 8640, 8640, 8640, 17280, 33, 33, 33, 8640, 17280, 33, 17280, 17280, 8640, 8640, 8640, 33, 17280, 33, 8640, 8640, 33, 8640, 33, 33, 8640, 8640, 17280, 8640, 33, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 33, 17280, 17280, 8640, 33, 33, 17280, 8640, 33, 8640, 8640, 17280, 8640, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 8640, 33, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 33, 17280, 17280, 33, 17280, 33, 8640, 17280, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 33, 33, 33, 17280, 8640, 33, 17280, 33, 17280, 33, 33, 8640, 8640, 17280, 8640, 17280, 33, 8640, 33, 17280, 17280, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 33, 8640, 17280, 17280, 33, 17280, 8640, 33, 8640, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 8640, 17280, 17280, 8640, 33, 17280, 33, 8640, 8640, 33, 8640, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 17280, 33, 17280, 33, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 8640, 8640, 33, 8640, 17280, 8640, 8640, 17280, 33, 17280, 17280, 8640, 33, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 33, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 17280, 33, 8640, 33, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 33, 33, 33, 33]
Prompts retrieved: 2223285 . Total input tokens: 495676136 . Total output tokens: 444666343
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 7.987838432192802,
    "estimated_duration": 3600.1476433487965,
    "input_throughput": 4476.775009429389,
    "output_throughput": 3932.8953705991717,
    "total_throughput": 8409.670380028561,
    "itl": 178.49375714679,
    "ttft": 2174955.751469072,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 681,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.252572268899533,
    "arrivals": 740358,
    "finished_requests": 65208,
    "scheduler_time": 96.7086116964213
}
#Debug simulation 
Total elapsed time: 7.987956059165299. Arrivals time: 0.3452352164313197 Scheduler time: 7.536072950810194 Scheduler overhead time: 0.03473245445638895 Adapter cache time: 0.02210678905248642 Engine time: 0.0343824946321547 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-16/adapters_256_slots_128_rate_1.6-0.8-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-16/adapters_256_slots_128_rate_1.6-0.8-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 33, 17280, 17280, 33, 17280, 8640, 17280, 33, 8640, 33, 17280, 8640, 8640, 8640, 8640, 17280, 33, 33, 33, 8640, 17280, 33, 17280, 17280, 8640, 8640, 8640, 33, 17280, 33, 8640, 8640, 33, 8640, 33, 33, 8640, 8640, 17280, 8640, 33, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 33, 17280, 17280, 8640, 33, 33, 17280, 8640, 33, 8640, 8640, 17280, 8640, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 8640, 33, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 33, 17280, 17280, 33, 17280, 33, 8640, 17280, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 33, 33, 33, 17280, 8640, 33, 17280, 33, 17280, 33, 33, 8640, 8640, 17280, 8640, 17280, 33, 8640, 33, 17280, 17280, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 33, 8640, 17280, 17280, 33, 17280, 8640, 33, 8640, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 8640, 17280, 17280, 8640, 33, 17280, 33, 8640, 8640, 33, 8640, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 17280, 33, 17280, 33, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 8640, 8640, 33, 8640, 17280, 8640, 8640, 17280, 33, 17280, 17280, 8640, 33, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 33, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 17280, 33, 8640, 33, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 33, 33, 33, 33]
Prompts retrieved: 2223285 . Total input tokens: 495676136 . Total output tokens: 444666343
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 12.68971905997023,
    "estimated_duration": 3600.062415941322,
    "input_throughput": 4688.430379779034,
    "output_throughput": 4110.688452086329,
    "total_throughput": 8799.118831865362,
    "itl": 207.8884407040793,
    "ttft": 2148657.223670852,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 646,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9315724905067737,
    "arrivals": 740358,
    "finished_requests": 68259,
    "scheduler_time": 93.82260287138573
}
#Debug simulation 
Total elapsed time: 12.689823511987925. Arrivals time: 0.47450530668720603 Scheduler time: 12.114116211421788 Scheduler overhead time: 0.03369971876963973 Adapter cache time: 0.01961637381464243 Engine time: 0.03378625400364399 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-32/adapters_256_slots_128_rate_1.6-0.8-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-32/adapters_256_slots_128_rate_1.6-0.8-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 33, 17280, 17280, 33, 17280, 8640, 17280, 33, 8640, 33, 17280, 8640, 8640, 8640, 8640, 17280, 33, 33, 33, 8640, 17280, 33, 17280, 17280, 8640, 8640, 8640, 33, 17280, 33, 8640, 8640, 33, 8640, 33, 33, 8640, 8640, 17280, 8640, 33, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 33, 17280, 17280, 8640, 33, 33, 17280, 8640, 33, 8640, 8640, 17280, 8640, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 8640, 33, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 33, 17280, 17280, 33, 17280, 33, 8640, 17280, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 33, 33, 33, 17280, 8640, 33, 17280, 33, 17280, 33, 33, 8640, 8640, 17280, 8640, 17280, 33, 8640, 33, 17280, 17280, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 33, 8640, 17280, 17280, 33, 17280, 8640, 33, 8640, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 8640, 17280, 17280, 8640, 33, 17280, 33, 8640, 8640, 33, 8640, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 17280, 33, 17280, 33, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 8640, 8640, 33, 8640, 17280, 8640, 8640, 17280, 33, 17280, 17280, 8640, 33, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 33, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 17280, 33, 8640, 33, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 33, 33, 33, 33]
Prompts retrieved: 2223285 . Total input tokens: 495676136 . Total output tokens: 444666343
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 7.7563229887746274,
    "estimated_duration": 3600.1775464607313,
    "input_throughput": 4476.737825289861,
    "output_throughput": 3932.862703929549,
    "total_throughput": 8409.60052921941,
    "itl": 178.49505257114075,
    "ttft": 2174968.781087039,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 681,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2823759162798574,
    "arrivals": 740358,
    "finished_requests": 65208,
    "scheduler_time": 96.70871116099673
}
#Debug simulation 
Total elapsed time: 7.756434767972678. Arrivals time: 0.32469608495011926 Scheduler time: 7.327308751642704 Scheduler overhead time: 0.033690658397972584 Adapter cache time: 0.021773281041532755 Engine time: 0.03376459004357457 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-8/adapters_256_slots_128_rate_1.6-0.4-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-8/adapters_256_slots_128_rate_1.6-0.4-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 1080, 17280, 17280, 1080, 17280, 4320, 17280, 1080, 4320, 1080, 17280, 4320, 4320, 4320, 4320, 17280, 1080, 1080, 1080, 4320, 17280, 1080, 17280, 17280, 4320, 4320, 4320, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 1080, 17280, 17280, 4320, 1080, 1080, 17280, 4320, 1080, 4320, 4320, 17280, 4320, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 4320, 1080, 4320, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 4320, 17280, 17280, 17280, 4320, 1080, 17280, 4320, 1080, 1080, 1080, 1080, 1080, 17280, 4320, 1080, 17280, 1080, 17280, 1080, 1080, 4320, 4320, 17280, 4320, 17280, 1080, 4320, 1080, 17280, 17280, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 1080, 4320, 17280, 17280, 1080, 17280, 4320, 1080, 4320, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 4320, 17280, 17280, 4320, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 17280, 1080, 17280, 1080, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 4320, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 1080, 17280, 17280, 4320, 1080, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 17280, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 1080, 1080, 1080, 1080]
Prompts retrieved: 1945080 . Total input tokens: 433756482 . Total output tokens: 389122472
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 10.718192907050252,
    "estimated_duration": 3600.0256195006014,
    "input_throughput": 4648.947748966763,
    "output_throughput": 4088.7497911867404,
    "total_throughput": 8737.697540153504,
    "itl": 208.95835617345625,
    "ttft": 2137533.2147858553,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 835,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.555507266183902,
    "arrivals": 648144,
    "finished_requests": 67889,
    "scheduler_time": 93.21183907573642
}
#Debug simulation 
Total elapsed time: 10.718312697019428. Arrivals time: 0.35994214145466685 Scheduler time: 10.257435958366841 Scheduler overhead time: 0.031470794696360826 Adapter cache time: 0.025073888711631298 Engine time: 0.030931302346289158 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-16/adapters_256_slots_128_rate_1.6-0.4-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-16/adapters_256_slots_128_rate_1.6-0.4-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 1080, 17280, 17280, 1080, 17280, 4320, 17280, 1080, 4320, 1080, 17280, 4320, 4320, 4320, 4320, 17280, 1080, 1080, 1080, 4320, 17280, 1080, 17280, 17280, 4320, 4320, 4320, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 1080, 17280, 17280, 4320, 1080, 1080, 17280, 4320, 1080, 4320, 4320, 17280, 4320, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 4320, 1080, 4320, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 4320, 17280, 17280, 17280, 4320, 1080, 17280, 4320, 1080, 1080, 1080, 1080, 1080, 17280, 4320, 1080, 17280, 1080, 17280, 1080, 1080, 4320, 4320, 17280, 4320, 17280, 1080, 4320, 1080, 17280, 17280, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 1080, 4320, 17280, 17280, 1080, 17280, 4320, 1080, 4320, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 4320, 17280, 17280, 4320, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 17280, 1080, 17280, 1080, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 4320, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 1080, 17280, 17280, 4320, 1080, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 17280, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 1080, 1080, 1080, 1080]
Prompts retrieved: 1945080 . Total input tokens: 433756482 . Total output tokens: 389122472
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 11.010487671010196,
    "estimated_duration": 3600.1931814700943,
    "input_throughput": 4648.731375344121,
    "output_throughput": 4088.5594905741787,
    "total_throughput": 8737.2908659183,
    "itl": 208.9670017559526,
    "ttft": 2137604.433443259,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 835,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.722645207340834,
    "arrivals": 648144,
    "finished_requests": 67889,
    "scheduler_time": 93.21226310402471
}
#Debug simulation 
Total elapsed time: 11.010607257951051. Arrivals time: 0.4175780168734491 Scheduler time: 10.486447778064758 Scheduler overhead time: 0.03196014603599906 Adapter cache time: 0.029047932010143995 Engine time: 0.03193456958979368 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-32/adapters_256_slots_128_rate_1.6-0.4-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-32/adapters_256_slots_128_rate_1.6-0.4-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 1080, 17280, 17280, 1080, 17280, 4320, 17280, 1080, 4320, 1080, 17280, 4320, 4320, 4320, 4320, 17280, 1080, 1080, 1080, 4320, 17280, 1080, 17280, 17280, 4320, 4320, 4320, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 1080, 17280, 17280, 4320, 1080, 1080, 17280, 4320, 1080, 4320, 4320, 17280, 4320, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 4320, 1080, 4320, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 4320, 17280, 17280, 17280, 4320, 1080, 17280, 4320, 1080, 1080, 1080, 1080, 1080, 17280, 4320, 1080, 17280, 1080, 17280, 1080, 1080, 4320, 4320, 17280, 4320, 17280, 1080, 4320, 1080, 17280, 17280, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 1080, 4320, 17280, 17280, 1080, 17280, 4320, 1080, 4320, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 4320, 17280, 17280, 4320, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 17280, 1080, 17280, 1080, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 4320, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 1080, 17280, 17280, 4320, 1080, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 17280, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 1080, 1080, 1080, 1080]
Prompts retrieved: 1945080 . Total input tokens: 433756482 . Total output tokens: 389122472
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 8.520402657799423,
    "estimated_duration": 3600.062648067488,
    "input_throughput": 4462.864280604822,
    "output_throughput": 3935.137908670756,
    "total_throughput": 8398.002189275578,
    "itl": 178.4280404770072,
    "ttft": 2162268.757753355,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1155,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.77528208861122,
    "arrivals": 648144,
    "finished_requests": 65221,
    "scheduler_time": 96.5188264398578
}
#Debug simulation 
Total elapsed time: 8.520515435840935. Arrivals time: 0.35550899989902973 Scheduler time: 8.043564344290644 Scheduler overhead time: 0.035245025996118784 Adapter cache time: 0.03485824819654226 Engine time: 0.03552006417885423 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-16-16/adapters_256_slots_128_rate_1.6-0.4-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-16-16/adapters_256_slots_128_rate_1.6-0.4-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 1080, 17280, 17280, 1080, 17280, 4320, 17280, 1080, 4320, 1080, 17280, 4320, 4320, 4320, 4320, 17280, 1080, 1080, 1080, 4320, 17280, 1080, 17280, 17280, 4320, 4320, 4320, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 1080, 17280, 17280, 4320, 1080, 1080, 17280, 4320, 1080, 4320, 4320, 17280, 4320, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 4320, 1080, 4320, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 4320, 17280, 17280, 17280, 4320, 1080, 17280, 4320, 1080, 1080, 1080, 1080, 1080, 17280, 4320, 1080, 17280, 1080, 17280, 1080, 1080, 4320, 4320, 17280, 4320, 17280, 1080, 4320, 1080, 17280, 17280, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 1080, 4320, 17280, 17280, 1080, 17280, 4320, 1080, 4320, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 4320, 17280, 17280, 4320, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 17280, 1080, 17280, 1080, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 4320, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 1080, 17280, 17280, 4320, 1080, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 17280, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 1080, 1080, 1080, 1080]
Prompts retrieved: 1945080 . Total input tokens: 433756482 . Total output tokens: 389122472
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 10.749560886994004,
    "estimated_duration": 3600.0854334971755,
    "input_throughput": 4648.870508537372,
    "output_throughput": 4088.681858225004,
    "total_throughput": 8737.552366762377,
    "itl": 208.96156921586962,
    "ttft": 2137558.3157578264,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 835,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6151846385909954,
    "arrivals": 648144,
    "finished_requests": 67889,
    "scheduler_time": 93.21197569983019
}
#Debug simulation 
Total elapsed time: 10.749800045974553. Arrivals time: 0.3963314313441515 Scheduler time: 10.25000641355291 Scheduler overhead time: 0.03161150496453047 Adapter cache time: 0.027381351683288813 Engine time: 0.031008551828563213 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-16-32/adapters_256_slots_128_rate_1.6-0.4-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-16-32/adapters_256_slots_128_rate_1.6-0.4-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 1080, 17280, 17280, 1080, 17280, 4320, 17280, 1080, 4320, 1080, 17280, 4320, 4320, 4320, 4320, 17280, 1080, 1080, 1080, 4320, 17280, 1080, 17280, 17280, 4320, 4320, 4320, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 1080, 17280, 17280, 4320, 1080, 1080, 17280, 4320, 1080, 4320, 4320, 17280, 4320, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 4320, 1080, 4320, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 4320, 17280, 17280, 17280, 4320, 1080, 17280, 4320, 1080, 1080, 1080, 1080, 1080, 17280, 4320, 1080, 17280, 1080, 17280, 1080, 1080, 4320, 4320, 17280, 4320, 17280, 1080, 4320, 1080, 17280, 17280, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 1080, 4320, 17280, 17280, 1080, 17280, 4320, 1080, 4320, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 4320, 17280, 17280, 4320, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 17280, 1080, 17280, 1080, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 4320, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 1080, 17280, 17280, 4320, 1080, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 17280, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 1080, 1080, 1080, 1080]
Prompts retrieved: 1945080 . Total input tokens: 433756482 . Total output tokens: 389122472
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 8.366987185087055,
    "estimated_duration": 3600.10840127873,
    "input_throughput": 4462.807562764853,
    "output_throughput": 3935.0878976222175,
    "total_throughput": 8397.89546038707,
    "itl": 178.43012531597597,
    "ttft": 2162286.7485828376,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1155,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.8209307130798664,
    "arrivals": 648144,
    "finished_requests": 65221,
    "scheduler_time": 96.5189310266726
}
#Debug simulation 
Total elapsed time: 8.367101947776973. Arrivals time: 0.35011329501867294 Scheduler time: 7.899764564819634 Scheduler overhead time: 0.034570795483887196 Adapter cache time: 0.032570486422628164 Engine time: 0.034624156542122364 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_16-16-16/adapters_256_slots_128_rate_1.6-0.4-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_16-16-16/adapters_256_slots_128_rate_1.6-0.4-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 1080, 17280, 17280, 1080, 17280, 4320, 17280, 1080, 4320, 1080, 17280, 4320, 4320, 4320, 4320, 17280, 1080, 1080, 1080, 4320, 17280, 1080, 17280, 17280, 4320, 4320, 4320, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 1080, 17280, 17280, 4320, 1080, 1080, 17280, 4320, 1080, 4320, 4320, 17280, 4320, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 4320, 1080, 4320, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 4320, 17280, 17280, 17280, 4320, 1080, 17280, 4320, 1080, 1080, 1080, 1080, 1080, 17280, 4320, 1080, 17280, 1080, 17280, 1080, 1080, 4320, 4320, 17280, 4320, 17280, 1080, 4320, 1080, 17280, 17280, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 1080, 4320, 17280, 17280, 1080, 17280, 4320, 1080, 4320, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 4320, 17280, 17280, 4320, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 17280, 1080, 17280, 1080, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 4320, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 1080, 17280, 17280, 4320, 1080, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 17280, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 1080, 1080, 1080, 1080]
Prompts retrieved: 1945080 . Total input tokens: 433756482 . Total output tokens: 389122472
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 10.6539889969863,
    "estimated_duration": 3600.203767958935,
    "input_throughput": 4648.911028024597,
    "output_throughput": 4088.716625155175,
    "total_throughput": 8737.627653179772,
    "itl": 208.95474014147854,
    "ttft": 2137571.9930140427,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 835,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.496691996243265,
    "arrivals": 648144,
    "finished_requests": 67892,
    "scheduler_time": 93.21786591935283
}
#Debug simulation 
Total elapsed time: 10.654101961757988. Arrivals time: 0.36500275880098343 Scheduler time: 10.187262306921184 Scheduler overhead time: 0.031289591919630766 Adapter cache time: 0.02597875939682126 Engine time: 0.031175449956208467 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_16-16-32/adapters_256_slots_128_rate_1.6-0.4-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_16-16-32/adapters_256_slots_128_rate_1.6-0.4-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 1080, 17280, 17280, 1080, 17280, 4320, 17280, 1080, 4320, 1080, 17280, 4320, 4320, 4320, 4320, 17280, 1080, 1080, 1080, 4320, 17280, 1080, 17280, 17280, 4320, 4320, 4320, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 1080, 17280, 17280, 4320, 1080, 1080, 17280, 4320, 1080, 4320, 4320, 17280, 4320, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 4320, 1080, 4320, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 4320, 17280, 17280, 17280, 4320, 1080, 17280, 4320, 1080, 1080, 1080, 1080, 1080, 17280, 4320, 1080, 17280, 1080, 17280, 1080, 1080, 4320, 4320, 17280, 4320, 17280, 1080, 4320, 1080, 17280, 17280, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 1080, 4320, 17280, 17280, 1080, 17280, 4320, 1080, 4320, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 4320, 17280, 17280, 4320, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 17280, 1080, 17280, 1080, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 4320, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 1080, 17280, 17280, 4320, 1080, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 17280, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 1080, 1080, 1080, 1080]
Prompts retrieved: 1945080 . Total input tokens: 433756482 . Total output tokens: 389122472
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 8.274865116924047,
    "estimated_duration": 3600.1598056804296,
    "input_throughput": 4462.743841162189,
    "output_throughput": 3935.0317109944203,
    "total_throughput": 8397.775552156609,
    "itl": 178.432522712293,
    "ttft": 2162306.9125039685,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1155,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.8722382579371915,
    "arrivals": 648144,
    "finished_requests": 65221,
    "scheduler_time": 96.51902788356253
}
#Debug simulation 
Total elapsed time: 8.275050768163055. Arrivals time: 0.3352485462091863 Scheduler time: 7.824311465956271 Scheduler overhead time: 0.03425290249288082 Adapter cache time: 0.03182002389803529 Engine time: 0.03398594772443175 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-8/adapters_256_slots_128_rate_1.6-0.4-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-8/adapters_256_slots_128_rate_1.6-0.4-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 540, 17280, 17280, 540, 17280, 4320, 17280, 540, 4320, 540, 17280, 4320, 4320, 4320, 4320, 17280, 540, 540, 540, 4320, 17280, 540, 17280, 17280, 4320, 4320, 4320, 540, 17280, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 17280, 4320, 540, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 540, 17280, 17280, 4320, 540, 540, 17280, 4320, 540, 4320, 4320, 17280, 4320, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 17280, 17280, 540, 17280, 540, 4320, 17280, 17280, 17280, 4320, 540, 17280, 4320, 540, 540, 540, 540, 540, 17280, 4320, 540, 17280, 540, 17280, 540, 540, 4320, 4320, 17280, 4320, 17280, 540, 4320, 540, 17280, 17280, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 540, 4320, 17280, 17280, 540, 17280, 4320, 540, 4320, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 4320, 17280, 17280, 4320, 540, 17280, 540, 4320, 4320, 540, 4320, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 17280, 540, 17280, 540, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 4320, 4320, 540, 4320, 17280, 4320, 4320, 17280, 540, 17280, 17280, 4320, 540, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 540, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 17280, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 540, 540, 540, 540]
Prompts retrieved: 1899180 . Total input tokens: 423567319 . Total output tokens: 379831664
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 9.058473736047745,
    "estimated_duration": 3600.211547715889,
    "input_throughput": 4632.981917571551,
    "output_throughput": 4092.975039022029,
    "total_throughput": 8725.95695659358,
    "itl": 209.39624808592706,
    "ttft": 2134196.279841874,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 846,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5891726313671635,
    "arrivals": 632850,
    "finished_requests": 67517,
    "scheduler_time": 93.17864172816638
}
#Debug simulation 
Total elapsed time: 9.058592504821718. Arrivals time: 0.31691799219697714 Scheduler time: 8.646434004884213 Scheduler overhead time: 0.02986033633351326 Adapter cache time: 0.022880765609443188 Engine time: 0.029433016665279865 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-16/adapters_256_slots_128_rate_1.6-0.4-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-16/adapters_256_slots_128_rate_1.6-0.4-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 540, 17280, 17280, 540, 17280, 4320, 17280, 540, 4320, 540, 17280, 4320, 4320, 4320, 4320, 17280, 540, 540, 540, 4320, 17280, 540, 17280, 17280, 4320, 4320, 4320, 540, 17280, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 17280, 4320, 540, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 540, 17280, 17280, 4320, 540, 540, 17280, 4320, 540, 4320, 4320, 17280, 4320, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 17280, 17280, 540, 17280, 540, 4320, 17280, 17280, 17280, 4320, 540, 17280, 4320, 540, 540, 540, 540, 540, 17280, 4320, 540, 17280, 540, 17280, 540, 540, 4320, 4320, 17280, 4320, 17280, 540, 4320, 540, 17280, 17280, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 540, 4320, 17280, 17280, 540, 17280, 4320, 540, 4320, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 4320, 17280, 17280, 4320, 540, 17280, 540, 4320, 4320, 540, 4320, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 17280, 540, 17280, 540, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 4320, 4320, 540, 4320, 17280, 4320, 4320, 17280, 540, 17280, 17280, 4320, 540, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 540, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 17280, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 540, 540, 540, 540]
Prompts retrieved: 1899180 . Total input tokens: 423567319 . Total output tokens: 379831664
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 9.525107361841947,
    "estimated_duration": 3600.1524157794797,
    "input_throughput": 4632.484426743103,
    "output_throughput": 4092.965046539458,
    "total_throughput": 8725.44947328256,
    "itl": 209.40808746684684,
    "ttft": 2134248.7041552207,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 846,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7612560950429237,
    "arrivals": 632850,
    "finished_requests": 67510,
    "scheduler_time": 93.17300110796779
}
#Debug simulation 
Total elapsed time: 9.525274820625782. Arrivals time: 0.3828898468054831 Scheduler time: 9.03756905393675 Scheduler overhead time: 0.03156262682750821 Adapter cache time: 0.028114823158830404 Engine time: 0.03138004522770643 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-32/adapters_256_slots_128_rate_1.6-0.4-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-32/adapters_256_slots_128_rate_1.6-0.4-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 540, 17280, 17280, 540, 17280, 4320, 17280, 540, 4320, 540, 17280, 4320, 4320, 4320, 4320, 17280, 540, 540, 540, 4320, 17280, 540, 17280, 17280, 4320, 4320, 4320, 540, 17280, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 17280, 4320, 540, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 540, 17280, 17280, 4320, 540, 540, 17280, 4320, 540, 4320, 4320, 17280, 4320, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 17280, 17280, 540, 17280, 540, 4320, 17280, 17280, 17280, 4320, 540, 17280, 4320, 540, 540, 540, 540, 540, 17280, 4320, 540, 17280, 540, 17280, 540, 540, 4320, 4320, 17280, 4320, 17280, 540, 4320, 540, 17280, 17280, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 540, 4320, 17280, 17280, 540, 17280, 4320, 540, 4320, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 4320, 17280, 17280, 4320, 540, 17280, 540, 4320, 4320, 540, 4320, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 17280, 540, 17280, 540, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 4320, 4320, 540, 4320, 17280, 4320, 4320, 17280, 540, 17280, 17280, 4320, 540, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 540, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 17280, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 540, 540, 540, 540]
Prompts retrieved: 1899180 . Total input tokens: 423567319 . Total output tokens: 379831664
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 6.970712253823876,
    "estimated_duration": 3600.110195401256,
    "input_throughput": 4436.925297565692,
    "output_throughput": 3929.0869535240518,
    "total_throughput": 8366.012251089744,
    "itl": 178.035201870992,
    "ttft": 2157217.062092443,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1215,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9693596343509228,
    "arrivals": 632850,
    "finished_requests": 64675,
    "scheduler_time": 96.56823197094728
}
#Debug simulation 
Total elapsed time: 6.970789497718215. Arrivals time: 0.2276095962151885 Scheduler time: 6.635069606360048 Scheduler overhead time: 0.03288112673908472 Adapter cache time: 0.02799510397017002 Engine time: 0.03252860018983483 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-16-16/adapters_256_slots_128_rate_1.6-0.4-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-16-16/adapters_256_slots_128_rate_1.6-0.4-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 540, 17280, 17280, 540, 17280, 4320, 17280, 540, 4320, 540, 17280, 4320, 4320, 4320, 4320, 17280, 540, 540, 540, 4320, 17280, 540, 17280, 17280, 4320, 4320, 4320, 540, 17280, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 17280, 4320, 540, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 540, 17280, 17280, 4320, 540, 540, 17280, 4320, 540, 4320, 4320, 17280, 4320, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 17280, 17280, 540, 17280, 540, 4320, 17280, 17280, 17280, 4320, 540, 17280, 4320, 540, 540, 540, 540, 540, 17280, 4320, 540, 17280, 540, 17280, 540, 540, 4320, 4320, 17280, 4320, 17280, 540, 4320, 540, 17280, 17280, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 540, 4320, 17280, 17280, 540, 17280, 4320, 540, 4320, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 4320, 17280, 17280, 4320, 540, 17280, 540, 4320, 4320, 540, 4320, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 17280, 540, 17280, 540, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 4320, 4320, 540, 4320, 17280, 4320, 4320, 17280, 540, 17280, 17280, 4320, 540, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 540, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 17280, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 540, 540, 540, 540]
Prompts retrieved: 1899180 . Total input tokens: 423567319 . Total output tokens: 379831664
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 9.306767425034195,
    "estimated_duration": 3600.0426098357784,
    "input_throughput": 4632.625723494083,
    "output_throughput": 4093.089887253355,
    "total_throughput": 8725.715610747438,
    "itl": 209.4025225986559,
    "ttft": 2134203.726919518,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 846,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6517525497008827,
    "arrivals": 632850,
    "finished_requests": 67510,
    "scheduler_time": 93.17269870958165
}
#Debug simulation 
Total elapsed time: 9.306878149043769. Arrivals time: 0.3813848881982267 Scheduler time: 8.822737994138151 Scheduler overhead time: 0.030425085686147213 Adapter cache time: 0.028657695278525352 Engine time: 0.030244714114814997 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-16-32/adapters_256_slots_128_rate_1.6-0.4-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-16-32/adapters_256_slots_128_rate_1.6-0.4-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 540, 17280, 17280, 540, 17280, 4320, 17280, 540, 4320, 540, 17280, 4320, 4320, 4320, 4320, 17280, 540, 540, 540, 4320, 17280, 540, 17280, 17280, 4320, 4320, 4320, 540, 17280, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 17280, 4320, 540, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 540, 17280, 17280, 4320, 540, 540, 17280, 4320, 540, 4320, 4320, 17280, 4320, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 17280, 17280, 540, 17280, 540, 4320, 17280, 17280, 17280, 4320, 540, 17280, 4320, 540, 540, 540, 540, 540, 17280, 4320, 540, 17280, 540, 17280, 540, 540, 4320, 4320, 17280, 4320, 17280, 540, 4320, 540, 17280, 17280, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 540, 4320, 17280, 17280, 540, 17280, 4320, 540, 4320, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 4320, 17280, 17280, 4320, 540, 17280, 540, 4320, 4320, 540, 4320, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 17280, 540, 17280, 540, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 4320, 4320, 540, 4320, 17280, 4320, 4320, 17280, 540, 17280, 17280, 4320, 540, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 540, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 17280, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 540, 540, 540, 540]
Prompts retrieved: 1899180 . Total input tokens: 423567319 . Total output tokens: 379831664
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 7.221189844887704,
    "estimated_duration": 3600.1584648058056,
    "input_throughput": 4436.865809144769,
    "output_throughput": 3929.0342739852135,
    "total_throughput": 8365.900083129984,
    "itl": 178.03736003346776,
    "ttft": 2157235.9172934983,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1215,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.017523334547874,
    "arrivals": 632850,
    "finished_requests": 64675,
    "scheduler_time": 96.56833767534158
}
#Debug simulation 
Total elapsed time: 7.2212966731749475. Arrivals time: 0.3323584725148976 Scheduler time: 6.773283991962671 Scheduler overhead time: 0.03389475308358669 Adapter cache time: 0.032817269675433636 Engine time: 0.0337455328553915 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_16-16-16/adapters_256_slots_128_rate_1.6-0.4-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_16-16-16/adapters_256_slots_128_rate_1.6-0.4-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 540, 17280, 17280, 540, 17280, 4320, 17280, 540, 4320, 540, 17280, 4320, 4320, 4320, 4320, 17280, 540, 540, 540, 4320, 17280, 540, 17280, 17280, 4320, 4320, 4320, 540, 17280, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 17280, 4320, 540, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 540, 17280, 17280, 4320, 540, 540, 17280, 4320, 540, 4320, 4320, 17280, 4320, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 17280, 17280, 540, 17280, 540, 4320, 17280, 17280, 17280, 4320, 540, 17280, 4320, 540, 540, 540, 540, 540, 17280, 4320, 540, 17280, 540, 17280, 540, 540, 4320, 4320, 17280, 4320, 17280, 540, 4320, 540, 17280, 17280, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 540, 4320, 17280, 17280, 540, 17280, 4320, 540, 4320, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 4320, 17280, 17280, 4320, 540, 17280, 540, 4320, 4320, 540, 4320, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 17280, 540, 17280, 540, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 4320, 4320, 540, 4320, 17280, 4320, 4320, 17280, 540, 17280, 17280, 4320, 540, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 540, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 17280, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 540, 540, 540, 540]
Prompts retrieved: 1899180 . Total input tokens: 423567319 . Total output tokens: 379831664
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 9.708585754036903,
    "estimated_duration": 3600.150669200799,
    "input_throughput": 4632.61194668344,
    "output_throughput": 4093.368959825069,
    "total_throughput": 8725.980906508508,
    "itl": 209.4115642618772,
    "ttft": 2134002.310794792,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 840,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5116422477177753,
    "arrivals": 632850,
    "finished_requests": 67512,
    "scheduler_time": 93.1760036496329
}
#Debug simulation 
Total elapsed time: 9.708725654985756. Arrivals time: 0.357143291272223 Scheduler time: 9.247033487539738 Scheduler overhead time: 0.032143655233085155 Adapter cache time: 0.026594698894768953 Engine time: 0.03172584204003215 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_16-16-32/adapters_256_slots_128_rate_1.6-0.4-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_16-16-32/adapters_256_slots_128_rate_1.6-0.4-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 540, 17280, 17280, 540, 17280, 4320, 17280, 540, 4320, 540, 17280, 4320, 4320, 4320, 4320, 17280, 540, 540, 540, 4320, 17280, 540, 17280, 17280, 4320, 4320, 4320, 540, 17280, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 17280, 4320, 540, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 540, 17280, 17280, 4320, 540, 540, 17280, 4320, 540, 4320, 4320, 17280, 4320, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 17280, 17280, 540, 17280, 540, 4320, 17280, 17280, 17280, 4320, 540, 17280, 4320, 540, 540, 540, 540, 540, 17280, 4320, 540, 17280, 540, 17280, 540, 540, 4320, 4320, 17280, 4320, 17280, 540, 4320, 540, 17280, 17280, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 540, 4320, 17280, 17280, 540, 17280, 4320, 540, 4320, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 4320, 17280, 17280, 4320, 540, 17280, 540, 4320, 4320, 540, 4320, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 17280, 540, 17280, 540, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 4320, 4320, 540, 4320, 17280, 4320, 4320, 17280, 540, 17280, 17280, 4320, 540, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 540, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 17280, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 540, 540, 540, 540]
Prompts retrieved: 1899180 . Total input tokens: 423567319 . Total output tokens: 379831664
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 7.328020503744483,
    "estimated_duration": 3600.0167456353847,
    "input_throughput": 4436.890750401459,
    "output_throughput": 3929.0845013843177,
    "total_throughput": 8365.975251785776,
    "itl": 178.0432523718584,
    "ttft": 2157130.5690560355,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1215,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.070591432415004,
    "arrivals": 632850,
    "finished_requests": 64671,
    "scheduler_time": 96.56312248459987
}
#Debug simulation 
Total elapsed time: 7.328155411873013. Arrivals time: 0.3535283268429339 Scheduler time: 6.856035418342799 Scheduler overhead time: 0.03406895371153951 Adapter cache time: 0.035368642304092646 Engine time: 0.03369088377803564 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-8/adapters_256_slots_128_rate_1.6-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-8/adapters_256_slots_128_rate_1.6-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 270, 17280, 17280, 270, 17280, 4320, 17280, 270, 4320, 270, 17280, 4320, 4320, 4320, 4320, 17280, 270, 270, 270, 4320, 17280, 270, 17280, 17280, 4320, 4320, 4320, 270, 17280, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 17280, 4320, 270, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 270, 17280, 17280, 4320, 270, 270, 17280, 4320, 270, 4320, 4320, 17280, 4320, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 17280, 17280, 270, 17280, 270, 4320, 17280, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 270, 270, 270, 17280, 4320, 270, 17280, 270, 17280, 270, 270, 4320, 4320, 17280, 4320, 17280, 270, 4320, 270, 17280, 17280, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 270, 4320, 17280, 17280, 270, 17280, 4320, 270, 4320, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 4320, 17280, 17280, 4320, 270, 17280, 270, 4320, 4320, 270, 4320, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 17280, 270, 17280, 270, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 4320, 4320, 270, 4320, 17280, 4320, 4320, 17280, 270, 17280, 17280, 4320, 270, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 270, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 17280, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 270, 270, 270, 270]
Prompts retrieved: 1876230 . Total input tokens: 418371695 . Total output tokens: 375262201
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 8.455414616968483,
    "estimated_duration": 3600.08750102766,
    "input_throughput": 4652.925517843212,
    "output_throughput": 4093.113291216858,
    "total_throughput": 8746.03880906007,
    "itl": 208.84306526882844,
    "ttft": 2136907.705086848,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 836,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.558567753927835,
    "arrivals": 625482,
    "finished_requests": 67615,
    "scheduler_time": 93.18512052087166
}
#Debug simulation 
Total elapsed time: 8.455527054145932. Arrivals time: 0.35273804794996977 Scheduler time: 8.002321052365005 Scheduler overhead time: 0.030830663163214922 Adapter cache time: 0.02574874134734273 Engine time: 0.030390363186597824 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-16/adapters_256_slots_128_rate_1.6-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-16/adapters_256_slots_128_rate_1.6-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 270, 17280, 17280, 270, 17280, 4320, 17280, 270, 4320, 270, 17280, 4320, 4320, 4320, 4320, 17280, 270, 270, 270, 4320, 17280, 270, 17280, 17280, 4320, 4320, 4320, 270, 17280, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 17280, 4320, 270, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 270, 17280, 17280, 4320, 270, 270, 17280, 4320, 270, 4320, 4320, 17280, 4320, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 17280, 17280, 270, 17280, 270, 4320, 17280, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 270, 270, 270, 17280, 4320, 270, 17280, 270, 17280, 270, 270, 4320, 4320, 17280, 4320, 17280, 270, 4320, 270, 17280, 17280, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 270, 4320, 17280, 17280, 270, 17280, 4320, 270, 4320, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 4320, 17280, 17280, 4320, 270, 17280, 270, 4320, 4320, 270, 4320, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 17280, 270, 17280, 270, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 4320, 4320, 270, 4320, 17280, 4320, 4320, 17280, 270, 17280, 17280, 4320, 270, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 270, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 17280, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 270, 270, 270, 270]
Prompts retrieved: 1876230 . Total input tokens: 418371695 . Total output tokens: 375262201
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 8.497994012665004,
    "estimated_duration": 3600.194652238726,
    "input_throughput": 4652.860919501538,
    "output_throughput": 4094.517220293491,
    "total_throughput": 8747.37813979503,
    "itl": 208.88256088021072,
    "ttft": 2136933.870429303,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 850,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7760764634516146,
    "arrivals": 625482,
    "finished_requests": 67621,
    "scheduler_time": 93.18220941029585
}
#Debug simulation 
Total elapsed time: 8.498105128761381. Arrivals time: 0.33754387544468045 Scheduler time: 8.062837275210768 Scheduler overhead time: 0.03000055719166994 Adapter cache time: 0.024464566726237535 Engine time: 0.03000824060291052 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-32/adapters_256_slots_128_rate_1.6-0.4-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-32/adapters_256_slots_128_rate_1.6-0.4-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 270, 17280, 17280, 270, 17280, 4320, 17280, 270, 4320, 270, 17280, 4320, 4320, 4320, 4320, 17280, 270, 270, 270, 4320, 17280, 270, 17280, 17280, 4320, 4320, 4320, 270, 17280, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 17280, 4320, 270, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 270, 17280, 17280, 4320, 270, 270, 17280, 4320, 270, 4320, 4320, 17280, 4320, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 17280, 17280, 270, 17280, 270, 4320, 17280, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 270, 270, 270, 17280, 4320, 270, 17280, 270, 17280, 270, 270, 4320, 4320, 17280, 4320, 17280, 270, 4320, 270, 17280, 17280, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 270, 4320, 17280, 17280, 270, 17280, 4320, 270, 4320, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 4320, 17280, 17280, 4320, 270, 17280, 270, 4320, 4320, 270, 4320, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 17280, 270, 17280, 270, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 4320, 4320, 270, 4320, 17280, 4320, 4320, 17280, 270, 17280, 17280, 4320, 270, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 270, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 17280, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 270, 270, 270, 270]
Prompts retrieved: 1876230 . Total input tokens: 418371695 . Total output tokens: 375262201
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 6.740034301765263,
    "estimated_duration": 3600.023099785286,
    "input_throughput": 4456.2591837138,
    "output_throughput": 3927.8970184506247,
    "total_throughput": 8384.156202164424,
    "itl": 177.54370964334646,
    "ttft": 2160950.508896768,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1177,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.845611978229078,
    "arrivals": 625482,
    "finished_requests": 64738,
    "scheduler_time": 96.57320293571047
}
#Debug simulation 
Total elapsed time: 6.740152899641544. Arrivals time: 0.3552944832481444 Scheduler time: 6.272298546973616 Scheduler overhead time: 0.0333207156509161 Adapter cache time: 0.030651584267616272 Engine time: 0.033512331545352936 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-16-16/adapters_256_slots_128_rate_1.6-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-16-16/adapters_256_slots_128_rate_1.6-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 270, 17280, 17280, 270, 17280, 4320, 17280, 270, 4320, 270, 17280, 4320, 4320, 4320, 4320, 17280, 270, 270, 270, 4320, 17280, 270, 17280, 17280, 4320, 4320, 4320, 270, 17280, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 17280, 4320, 270, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 270, 17280, 17280, 4320, 270, 270, 17280, 4320, 270, 4320, 4320, 17280, 4320, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 17280, 17280, 270, 17280, 270, 4320, 17280, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 270, 270, 270, 17280, 4320, 270, 17280, 270, 17280, 270, 270, 4320, 4320, 17280, 4320, 17280, 270, 4320, 270, 17280, 17280, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 270, 4320, 17280, 17280, 270, 17280, 4320, 270, 4320, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 4320, 17280, 17280, 4320, 270, 17280, 270, 4320, 4320, 270, 4320, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 17280, 270, 17280, 270, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 4320, 4320, 270, 4320, 17280, 4320, 4320, 17280, 270, 17280, 17280, 4320, 270, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 270, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 17280, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 270, 270, 270, 270]
Prompts retrieved: 1876230 . Total input tokens: 418371695 . Total output tokens: 375262201
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 8.328673833981156,
    "estimated_duration": 3600.1554369821133,
    "input_throughput": 4652.837715818664,
    "output_throughput": 4093.036053007844,
    "total_throughput": 8745.873768826508,
    "itl": 208.84656308868136,
    "ttft": 2136934.9982465077,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 836,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6263465952547067,
    "arrivals": 625482,
    "finished_requests": 67615,
    "scheduler_time": 93.18527763392292
}
#Debug simulation 
Total elapsed time: 8.328787568025291. Arrivals time: 0.3445661715231836 Scheduler time: 7.8857106366194785 Scheduler overhead time: 0.030167449731379747 Adapter cache time: 0.025261371862143278 Engine time: 0.029802795499563217 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-16-32/adapters_256_slots_128_rate_1.6-0.4-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-16-32/adapters_256_slots_128_rate_1.6-0.4-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 270, 17280, 17280, 270, 17280, 4320, 17280, 270, 4320, 270, 17280, 4320, 4320, 4320, 4320, 17280, 270, 270, 270, 4320, 17280, 270, 17280, 17280, 4320, 4320, 4320, 270, 17280, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 17280, 4320, 270, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 270, 17280, 17280, 4320, 270, 270, 17280, 4320, 270, 4320, 4320, 17280, 4320, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 17280, 17280, 270, 17280, 270, 4320, 17280, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 270, 270, 270, 17280, 4320, 270, 17280, 270, 17280, 270, 270, 4320, 4320, 17280, 4320, 17280, 270, 4320, 270, 17280, 17280, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 270, 4320, 17280, 17280, 270, 17280, 4320, 270, 4320, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 4320, 17280, 17280, 4320, 270, 17280, 270, 4320, 4320, 270, 4320, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 17280, 270, 17280, 270, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 4320, 4320, 270, 4320, 17280, 4320, 4320, 17280, 270, 17280, 17280, 4320, 270, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 270, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 17280, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 270, 270, 270, 270]
Prompts retrieved: 1876230 . Total input tokens: 418371695 . Total output tokens: 375262201
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 6.678026783280075,
    "estimated_duration": 3600.068092420256,
    "input_throughput": 4456.203490644213,
    "output_throughput": 3927.84792870226,
    "total_throughput": 8384.051419346473,
    "itl": 177.5457565484734,
    "ttft": 2160967.981970959,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1177,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.890506079979236,
    "arrivals": 625482,
    "finished_requests": 64738,
    "scheduler_time": 96.57330146896963
}
#Debug simulation 
Total elapsed time: 6.678138709161431. Arrivals time: 0.3075497136451304 Scheduler time: 6.258400706574321 Scheduler overhead time: 0.033389484975486994 Adapter cache time: 0.02983117150142789 Engine time: 0.0339727895334363 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_16-16-16/adapters_256_slots_128_rate_1.6-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_16-16-16/adapters_256_slots_128_rate_1.6-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 270, 17280, 17280, 270, 17280, 4320, 17280, 270, 4320, 270, 17280, 4320, 4320, 4320, 4320, 17280, 270, 270, 270, 4320, 17280, 270, 17280, 17280, 4320, 4320, 4320, 270, 17280, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 17280, 4320, 270, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 270, 17280, 17280, 4320, 270, 270, 17280, 4320, 270, 4320, 4320, 17280, 4320, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 17280, 17280, 270, 17280, 270, 4320, 17280, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 270, 270, 270, 17280, 4320, 270, 17280, 270, 17280, 270, 270, 4320, 4320, 17280, 4320, 17280, 270, 4320, 270, 17280, 17280, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 270, 4320, 17280, 17280, 270, 17280, 4320, 270, 4320, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 4320, 17280, 17280, 4320, 270, 17280, 270, 4320, 4320, 270, 4320, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 17280, 270, 17280, 270, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 4320, 4320, 270, 4320, 17280, 4320, 4320, 17280, 270, 17280, 17280, 4320, 270, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 270, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 17280, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 270, 270, 270, 270]
Prompts retrieved: 1876230 . Total input tokens: 418371695 . Total output tokens: 375262201
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 8.52891723671928,
    "estimated_duration": 3600.0284661235146,
    "input_throughput": 4653.0018186320885,
    "output_throughput": 4093.1804119502294,
    "total_throughput": 8746.182230582317,
    "itl": 208.8400772687403,
    "ttft": 2136883.6128622494,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 836,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.499682046538167,
    "arrivals": 625482,
    "finished_requests": 67615,
    "scheduler_time": 93.18497132400853
}
#Debug simulation 
Total elapsed time: 8.52902149176225. Arrivals time: 0.37444104719907045 Scheduler time: 8.054984346032143 Scheduler overhead time: 0.030623084399849176 Adapter cache time: 0.024910578969866037 Engine time: 0.03056875616312027 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_16-16-32/adapters_256_slots_128_rate_1.6-0.4-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_16-16-32/adapters_256_slots_128_rate_1.6-0.4-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 270, 17280, 17280, 270, 17280, 4320, 17280, 270, 4320, 270, 17280, 4320, 4320, 4320, 4320, 17280, 270, 270, 270, 4320, 17280, 270, 17280, 17280, 4320, 4320, 4320, 270, 17280, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 17280, 4320, 270, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 270, 17280, 17280, 4320, 270, 270, 17280, 4320, 270, 4320, 4320, 17280, 4320, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 17280, 17280, 270, 17280, 270, 4320, 17280, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 270, 270, 270, 17280, 4320, 270, 17280, 270, 17280, 270, 270, 4320, 4320, 17280, 4320, 17280, 270, 4320, 270, 17280, 17280, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 270, 4320, 17280, 17280, 270, 17280, 4320, 270, 4320, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 4320, 17280, 17280, 4320, 270, 17280, 270, 4320, 4320, 270, 4320, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 17280, 270, 17280, 270, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 4320, 4320, 270, 4320, 17280, 4320, 4320, 17280, 270, 17280, 17280, 4320, 270, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 270, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 17280, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 270, 270, 270, 270]
Prompts retrieved: 1876230 . Total input tokens: 418371695 . Total output tokens: 375262201
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 7.0048236469738185,
    "estimated_duration": 3600.121516333064,
    "input_throughput": 4456.137362924453,
    "output_throughput": 3927.7896415015884,
    "total_throughput": 8383.927004426041,
    "itl": 177.5481769667271,
    "ttft": 2160988.2294803346,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1177,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9438256854192026,
    "arrivals": 625482,
    "finished_requests": 64738,
    "scheduler_time": 96.57340577638956
}
#Debug simulation 
Total elapsed time: 7.004968754015863. Arrivals time: 0.37291210936382413 Scheduler time: 6.514569682069123 Scheduler overhead time: 0.03462872840464115 Adapter cache time: 0.032429730985313654 Engine time: 0.034662369173020124 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-8/adapters_256_slots_128_rate_1.6-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-8/adapters_256_slots_128_rate_1.6-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 135, 17280, 17280, 135, 17280, 4320, 17280, 135, 4320, 135, 17280, 4320, 4320, 4320, 4320, 17280, 135, 135, 135, 4320, 17280, 135, 17280, 17280, 4320, 4320, 4320, 135, 17280, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 17280, 4320, 135, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 135, 17280, 17280, 4320, 135, 135, 17280, 4320, 135, 4320, 4320, 17280, 4320, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 17280, 17280, 135, 17280, 135, 4320, 17280, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 135, 135, 135, 17280, 4320, 135, 17280, 135, 17280, 135, 135, 4320, 4320, 17280, 4320, 17280, 135, 4320, 135, 17280, 17280, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 135, 4320, 17280, 17280, 135, 17280, 4320, 135, 4320, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 4320, 17280, 17280, 4320, 135, 17280, 135, 4320, 4320, 135, 4320, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 17280, 135, 17280, 135, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 4320, 4320, 135, 4320, 17280, 4320, 4320, 17280, 135, 17280, 17280, 4320, 135, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 135, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 17280, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 135, 135, 135, 135]
Prompts retrieved: 1864755 . Total input tokens: 415800092 . Total output tokens: 372975680
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 7.98630205867812,
    "estimated_duration": 3600.0819930051643,
    "input_throughput": 4661.820489813474,
    "output_throughput": 4091.482368629172,
    "total_throughput": 8753.302858442645,
    "itl": 208.89497453838976,
    "ttft": 2132194.4357483126,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 777,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.377998977035796,
    "arrivals": 621618,
    "finished_requests": 67926,
    "scheduler_time": 93.21318037422704
}
#Debug simulation 
Total elapsed time: 7.986420837696642. Arrivals time: 0.3571280357427895 Scheduler time: 7.533236084505916 Scheduler overhead time: 0.029621184803545475 Adapter cache time: 0.023632694501429796 Engine time: 0.029645877424627542 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-16/adapters_256_slots_128_rate_1.6-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-16/adapters_256_slots_128_rate_1.6-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 135, 17280, 17280, 135, 17280, 4320, 17280, 135, 4320, 135, 17280, 4320, 4320, 4320, 4320, 17280, 135, 135, 135, 4320, 17280, 135, 17280, 17280, 4320, 4320, 4320, 135, 17280, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 17280, 4320, 135, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 135, 17280, 17280, 4320, 135, 135, 17280, 4320, 135, 4320, 4320, 17280, 4320, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 17280, 17280, 135, 17280, 135, 4320, 17280, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 135, 135, 135, 17280, 4320, 135, 17280, 135, 17280, 135, 135, 4320, 4320, 17280, 4320, 17280, 135, 4320, 135, 17280, 17280, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 135, 4320, 17280, 17280, 135, 17280, 4320, 135, 4320, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 4320, 17280, 17280, 4320, 135, 17280, 135, 4320, 4320, 135, 4320, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 17280, 135, 17280, 135, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 4320, 4320, 135, 4320, 17280, 4320, 4320, 17280, 135, 17280, 17280, 4320, 135, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 135, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 17280, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 135, 135, 135, 135]
Prompts retrieved: 1864755 . Total input tokens: 415800092 . Total output tokens: 372975680
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 7.791237044148147,
    "estimated_duration": 3600.088276533634,
    "input_throughput": 4662.42039380258,
    "output_throughput": 4090.5655275151744,
    "total_throughput": 8752.985921317755,
    "itl": 208.88761182768727,
    "ttft": 2132185.295364815,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 806,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6302134143305067,
    "arrivals": 621618,
    "finished_requests": 67919,
    "scheduler_time": 93.20791384448249
}
#Debug simulation 
Total elapsed time: 7.791357141919434. Arrivals time: 0.3094149469397962 Scheduler time: 7.387318958994001 Scheduler overhead time: 0.02983467373996973 Adapter cache time: 0.021682635881006718 Engine time: 0.029738918878138065 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-32/adapters_256_slots_128_rate_1.6-0.4-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-32/adapters_256_slots_128_rate_1.6-0.4-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 135, 17280, 17280, 135, 17280, 4320, 17280, 135, 4320, 135, 17280, 4320, 4320, 4320, 4320, 17280, 135, 135, 135, 4320, 17280, 135, 17280, 17280, 4320, 4320, 4320, 135, 17280, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 17280, 4320, 135, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 135, 17280, 17280, 4320, 135, 135, 17280, 4320, 135, 4320, 4320, 17280, 4320, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 17280, 17280, 135, 17280, 135, 4320, 17280, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 135, 135, 135, 17280, 4320, 135, 17280, 135, 17280, 135, 135, 4320, 4320, 17280, 4320, 17280, 135, 4320, 135, 17280, 17280, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 135, 4320, 17280, 17280, 135, 17280, 4320, 135, 4320, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 4320, 17280, 17280, 4320, 135, 17280, 135, 4320, 4320, 135, 4320, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 17280, 135, 17280, 135, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 4320, 4320, 135, 4320, 17280, 4320, 4320, 17280, 135, 17280, 17280, 4320, 135, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 135, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 17280, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 135, 135, 135, 135]
Prompts retrieved: 1864755 . Total input tokens: 415800092 . Total output tokens: 372975680
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 6.550411315169185,
    "estimated_duration": 3600.0418280823023,
    "input_throughput": 4465.128120070418,
    "output_throughput": 3928.2804687670127,
    "total_throughput": 8393.40858883743,
    "itl": 177.67591299883782,
    "ttft": 2156472.518534124,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1104,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.6085962125099704,
    "arrivals": 621618,
    "finished_requests": 65063,
    "scheduler_time": 96.5903184601421
}
#Debug simulation 
Total elapsed time: 6.550523090176284. Arrivals time: 0.38163434201851487 Scheduler time: 6.055184608325362 Scheduler overhead time: 0.034026690758764744 Adapter cache time: 0.030122146010398865 Engine time: 0.034126670099794865 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-16/adapters_256_slots_128_rate_1.6-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-16/adapters_256_slots_128_rate_1.6-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 135, 17280, 17280, 135, 17280, 4320, 17280, 135, 4320, 135, 17280, 4320, 4320, 4320, 4320, 17280, 135, 135, 135, 4320, 17280, 135, 17280, 17280, 4320, 4320, 4320, 135, 17280, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 17280, 4320, 135, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 135, 17280, 17280, 4320, 135, 135, 17280, 4320, 135, 4320, 4320, 17280, 4320, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 17280, 17280, 135, 17280, 135, 4320, 17280, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 135, 135, 135, 17280, 4320, 135, 17280, 135, 17280, 135, 135, 4320, 4320, 17280, 4320, 17280, 135, 4320, 135, 17280, 17280, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 135, 4320, 17280, 17280, 135, 17280, 4320, 135, 4320, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 4320, 17280, 17280, 4320, 135, 17280, 135, 4320, 4320, 135, 4320, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 17280, 135, 17280, 135, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 4320, 4320, 135, 4320, 17280, 4320, 4320, 17280, 135, 17280, 17280, 4320, 135, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 135, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 17280, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 135, 135, 135, 135]
Prompts retrieved: 1864755 . Total input tokens: 415800092 . Total output tokens: 372975680
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 7.926244891248643,
    "estimated_duration": 3600.1581738164587,
    "input_throughput": 4662.67874619661,
    "output_throughput": 4090.6497128675333,
    "total_throughput": 8753.328459064143,
    "itl": 208.881423460589,
    "ttft": 2132164.307125586,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 806,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.527247394083514,
    "arrivals": 621618,
    "finished_requests": 67925,
    "scheduler_time": 93.21199807968904
}
#Debug simulation 
Total elapsed time: 7.926381404045969. Arrivals time: 0.3725146781653166 Scheduler time: 7.454122776165605 Scheduler overhead time: 0.030260806903243065 Adapter cache time: 0.025575543753802776 Engine time: 0.030390566680580378 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-32/adapters_256_slots_128_rate_1.6-0.4-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-32/adapters_256_slots_128_rate_1.6-0.4-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 135, 17280, 17280, 135, 17280, 4320, 17280, 135, 4320, 135, 17280, 4320, 4320, 4320, 4320, 17280, 135, 135, 135, 4320, 17280, 135, 17280, 17280, 4320, 4320, 4320, 135, 17280, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 17280, 4320, 135, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 135, 17280, 17280, 4320, 135, 135, 17280, 4320, 135, 4320, 4320, 17280, 4320, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 17280, 17280, 135, 17280, 135, 4320, 17280, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 135, 135, 135, 17280, 4320, 135, 17280, 135, 17280, 135, 135, 4320, 4320, 17280, 4320, 17280, 135, 4320, 135, 17280, 17280, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 135, 4320, 17280, 17280, 135, 17280, 4320, 135, 4320, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 4320, 17280, 17280, 4320, 135, 17280, 135, 4320, 4320, 135, 4320, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 17280, 135, 17280, 135, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 4320, 4320, 135, 4320, 17280, 4320, 4320, 17280, 135, 17280, 17280, 4320, 135, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 135, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 17280, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 135, 135, 135, 135]
Prompts retrieved: 1864755 . Total input tokens: 415800092 . Total output tokens: 372975680
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 6.507977735251188,
    "estimated_duration": 3600.085440592099,
    "input_throughput": 4465.0740281753515,
    "output_throughput": 3928.232880404665,
    "total_throughput": 8393.306908580018,
    "itl": 177.67789835796415,
    "ttft": 2156489.7098934613,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1104,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.6521070226095587,
    "arrivals": 621618,
    "finished_requests": 65063,
    "scheduler_time": 96.59042015987653
}
#Debug simulation 
Total elapsed time: 6.508078552316874. Arrivals time: 0.32939638616517186 Scheduler time: 6.063591904006898 Scheduler overhead time: 0.034280505031347275 Adapter cache time: 0.030998519621789455 Engine time: 0.03435002313926816 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-16/adapters_256_slots_128_rate_1.6-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-16/adapters_256_slots_128_rate_1.6-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 135, 17280, 17280, 135, 17280, 4320, 17280, 135, 4320, 135, 17280, 4320, 4320, 4320, 4320, 17280, 135, 135, 135, 4320, 17280, 135, 17280, 17280, 4320, 4320, 4320, 135, 17280, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 17280, 4320, 135, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 135, 17280, 17280, 4320, 135, 135, 17280, 4320, 135, 4320, 4320, 17280, 4320, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 17280, 17280, 135, 17280, 135, 4320, 17280, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 135, 135, 135, 17280, 4320, 135, 17280, 135, 17280, 135, 135, 4320, 4320, 17280, 4320, 17280, 135, 4320, 135, 17280, 17280, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 135, 4320, 17280, 17280, 135, 17280, 4320, 135, 4320, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 4320, 17280, 17280, 4320, 135, 17280, 135, 4320, 4320, 135, 4320, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 17280, 135, 17280, 135, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 4320, 4320, 135, 4320, 17280, 4320, 4320, 17280, 135, 17280, 17280, 4320, 135, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 135, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 17280, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 135, 135, 135, 135]
Prompts retrieved: 1864755 . Total input tokens: 415800092 . Total output tokens: 372975680
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 8.11352720996365,
    "estimated_duration": 3600.009717843656,
    "input_throughput": 4661.804915919076,
    "output_throughput": 4091.512844254962,
    "total_throughput": 8753.317760174037,
    "itl": 208.8916319232641,
    "ttft": 2132175.890823594,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 777,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.323269079138945,
    "arrivals": 621618,
    "finished_requests": 67925,
    "scheduler_time": 93.21260393886448
}
#Debug simulation 
Total elapsed time: 8.113645120058209. Arrivals time: 0.4115563593804836 Scheduler time: 7.6037663305178285 Scheduler overhead time: 0.030050449538975954 Adapter cache time: 0.02485595876350999 Engine time: 0.030006649903953075 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-32/adapters_256_slots_128_rate_1.6-0.4-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-32/adapters_256_slots_128_rate_1.6-0.4-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 135, 17280, 17280, 135, 17280, 4320, 17280, 135, 4320, 135, 17280, 4320, 4320, 4320, 4320, 17280, 135, 135, 135, 4320, 17280, 135, 17280, 17280, 4320, 4320, 4320, 135, 17280, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 17280, 4320, 135, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 135, 17280, 17280, 4320, 135, 135, 17280, 4320, 135, 4320, 4320, 17280, 4320, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 17280, 17280, 135, 17280, 135, 4320, 17280, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 135, 135, 135, 17280, 4320, 135, 17280, 135, 17280, 135, 135, 4320, 4320, 17280, 4320, 17280, 135, 4320, 135, 17280, 17280, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 135, 4320, 17280, 17280, 135, 17280, 4320, 135, 4320, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 4320, 17280, 17280, 4320, 135, 17280, 135, 4320, 4320, 135, 4320, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 17280, 135, 17280, 135, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 4320, 4320, 135, 4320, 17280, 4320, 4320, 17280, 135, 17280, 17280, 4320, 135, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 135, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 17280, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 135, 135, 135, 135]
Prompts retrieved: 1864755 . Total input tokens: 415800092 . Total output tokens: 372975680
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 6.421795325819403,
    "estimated_duration": 3600.011326199325,
    "input_throughput": 4464.7820641634435,
    "output_throughput": 3929.826525000407,
    "total_throughput": 8394.60858916385,
    "itl": 177.93958199685696,
    "ttft": 2156328.616757483,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1097,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.6762681109086186,
    "arrivals": 621618,
    "finished_requests": 65076,
    "scheduler_time": 96.5538389185783
}
#Debug simulation 
Total elapsed time: 6.421931532211602. Arrivals time: 0.30338442511856556 Scheduler time: 6.00831756554544 Scheduler overhead time: 0.03356353333219886 Adapter cache time: 0.027674879413098097 Engine time: 0.03382339607924223 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-8/adapters_256_slots_128_rate_1.6-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-8/adapters_256_slots_128_rate_1.6-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 66, 17280, 17280, 66, 17280, 4320, 17280, 66, 4320, 66, 17280, 4320, 4320, 4320, 4320, 17280, 66, 66, 66, 4320, 17280, 66, 17280, 17280, 4320, 4320, 4320, 66, 17280, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 17280, 4320, 66, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 66, 17280, 17280, 4320, 66, 66, 17280, 4320, 66, 4320, 4320, 17280, 4320, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 17280, 17280, 66, 17280, 66, 4320, 17280, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 66, 66, 66, 17280, 4320, 66, 17280, 66, 17280, 66, 66, 4320, 4320, 17280, 4320, 17280, 66, 4320, 66, 17280, 17280, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 66, 4320, 17280, 17280, 66, 17280, 4320, 66, 4320, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 4320, 17280, 17280, 4320, 66, 17280, 66, 4320, 4320, 66, 4320, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 17280, 66, 17280, 66, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 4320, 4320, 66, 4320, 17280, 4320, 4320, 17280, 66, 17280, 17280, 4320, 66, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 66, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 17280, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 66, 66, 66, 66]
Prompts retrieved: 1858890 . Total input tokens: 414477948 . Total output tokens: 371780131
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 7.534852256067097,
    "estimated_duration": 3600.193405644651,
    "input_throughput": 4654.831313708064,
    "output_throughput": 4094.7061279782392,
    "total_throughput": 8749.537441686303,
    "itl": 209.00910726016866,
    "ttft": 2135766.5858519417,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 745,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2800633692299446,
    "arrivals": 619780,
    "finished_requests": 67612,
    "scheduler_time": 93.18842798386875
}
#Debug simulation 
Total elapsed time: 7.534961198922247. Arrivals time: 0.34909146511927247 Scheduler time: 7.087320691905916 Scheduler overhead time: 0.03094377974048257 Adapter cache time: 0.023086972068995237 Engine time: 0.03069817367941141 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-16/adapters_256_slots_128_rate_1.6-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-16/adapters_256_slots_128_rate_1.6-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 66, 17280, 17280, 66, 17280, 4320, 17280, 66, 4320, 66, 17280, 4320, 4320, 4320, 4320, 17280, 66, 66, 66, 4320, 17280, 66, 17280, 17280, 4320, 4320, 4320, 66, 17280, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 17280, 4320, 66, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 66, 17280, 17280, 4320, 66, 66, 17280, 4320, 66, 4320, 4320, 17280, 4320, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 17280, 17280, 66, 17280, 66, 4320, 17280, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 66, 66, 66, 17280, 4320, 66, 17280, 66, 17280, 66, 66, 4320, 4320, 17280, 4320, 17280, 66, 4320, 66, 17280, 17280, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 66, 4320, 17280, 17280, 66, 17280, 4320, 66, 4320, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 4320, 17280, 17280, 4320, 66, 17280, 66, 4320, 4320, 66, 4320, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 17280, 66, 17280, 66, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 4320, 4320, 66, 4320, 17280, 4320, 4320, 17280, 66, 17280, 17280, 4320, 66, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 66, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 17280, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 66, 66, 66, 66]
Prompts retrieved: 1858890 . Total input tokens: 414477948 . Total output tokens: 371780131
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 7.08511986490339,
    "estimated_duration": 3600.1152072325167,
    "input_throughput": 4654.674652170849,
    "output_throughput": 4094.6070199047203,
    "total_throughput": 8749.281672075569,
    "itl": 209.0174882815622,
    "ttft": 2135786.9700856213,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 745,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4335195101960627,
    "arrivals": 619780,
    "finished_requests": 67608,
    "scheduler_time": 93.18273121813561
}
#Debug simulation 
Total elapsed time: 7.08522887295112. Arrivals time: 0.2997216614894569 Scheduler time: 6.694798848126084 Scheduler overhead time: 0.029004091396927834 Adapter cache time: 0.01998300990089774 Engine time: 0.02876498969271779 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-32/adapters_256_slots_128_rate_1.6-0.4-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-32/adapters_256_slots_128_rate_1.6-0.4-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 66, 17280, 17280, 66, 17280, 4320, 17280, 66, 4320, 66, 17280, 4320, 4320, 4320, 4320, 17280, 66, 66, 66, 4320, 17280, 66, 17280, 17280, 4320, 4320, 4320, 66, 17280, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 17280, 4320, 66, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 66, 17280, 17280, 4320, 66, 66, 17280, 4320, 66, 4320, 4320, 17280, 4320, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 17280, 17280, 66, 17280, 66, 4320, 17280, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 66, 66, 66, 17280, 4320, 66, 17280, 66, 17280, 66, 66, 4320, 4320, 17280, 4320, 17280, 66, 4320, 66, 17280, 17280, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 66, 4320, 17280, 17280, 66, 17280, 4320, 66, 4320, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 4320, 17280, 17280, 4320, 66, 17280, 66, 4320, 4320, 66, 4320, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 17280, 66, 17280, 66, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 4320, 4320, 66, 4320, 17280, 4320, 4320, 17280, 66, 17280, 17280, 4320, 66, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 66, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 17280, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 66, 66, 66, 66]
Prompts retrieved: 1858890 . Total input tokens: 414477948 . Total output tokens: 371780131
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 6.441849427297711,
    "estimated_duration": 3600.0446328892554,
    "input_throughput": 4460.836916655531,
    "output_throughput": 3928.531293971617,
    "total_throughput": 8389.368210627148,
    "itl": 177.68904075105672,
    "ttft": 2159880.3598900917,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1003,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2792797216400142,
    "arrivals": 619780,
    "finished_requests": 64762,
    "scheduler_time": 96.57634174094964
}
#Debug simulation 
Total elapsed time: 6.44192228326574. Arrivals time: 0.6258524055592716 Scheduler time: 5.7066989406012 Scheduler overhead time: 0.03344419691711664 Adapter cache time: 0.02735867304727435 Engine time: 0.03346087085083127 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-16/adapters_256_slots_128_rate_1.6-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-16/adapters_256_slots_128_rate_1.6-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 66, 17280, 17280, 66, 17280, 4320, 17280, 66, 4320, 66, 17280, 4320, 4320, 4320, 4320, 17280, 66, 66, 66, 4320, 17280, 66, 17280, 17280, 4320, 4320, 4320, 66, 17280, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 17280, 4320, 66, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 66, 17280, 17280, 4320, 66, 66, 17280, 4320, 66, 4320, 4320, 17280, 4320, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 17280, 17280, 66, 17280, 66, 4320, 17280, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 66, 66, 66, 17280, 4320, 66, 17280, 66, 17280, 66, 66, 4320, 4320, 17280, 4320, 17280, 66, 4320, 66, 17280, 17280, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 66, 4320, 17280, 17280, 66, 17280, 4320, 66, 4320, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 4320, 17280, 17280, 4320, 66, 17280, 66, 4320, 4320, 66, 4320, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 17280, 66, 17280, 66, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 4320, 4320, 66, 4320, 17280, 4320, 4320, 17280, 66, 17280, 17280, 4320, 66, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 66, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 17280, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 66, 66, 66, 66]
Prompts retrieved: 1858890 . Total input tokens: 414477948 . Total output tokens: 371780131
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 7.4375618272461,
    "estimated_duration": 3600.023822257446,
    "input_throughput": 4654.792808979818,
    "output_throughput": 4094.7109596503756,
    "total_throughput": 8749.503768630193,
    "itl": 209.01298230612215,
    "ttft": 2135747.8283879734,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 745,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3424027541838437,
    "arrivals": 619780,
    "finished_requests": 67608,
    "scheduler_time": 93.18246299905583
}
#Debug simulation 
Total elapsed time: 7.437713417224586. Arrivals time: 0.3383643110282719 Scheduler time: 7.000671751331538 Scheduler overhead time: 0.030648119281977415 Adapter cache time: 0.02351059764623642 Engine time: 0.030836277175694704 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-32/adapters_256_slots_128_rate_1.6-0.4-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-32/adapters_256_slots_128_rate_1.6-0.4-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 66, 17280, 17280, 66, 17280, 4320, 17280, 66, 4320, 66, 17280, 4320, 4320, 4320, 4320, 17280, 66, 66, 66, 4320, 17280, 66, 17280, 17280, 4320, 4320, 4320, 66, 17280, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 17280, 4320, 66, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 66, 17280, 17280, 4320, 66, 66, 17280, 4320, 66, 4320, 4320, 17280, 4320, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 17280, 17280, 66, 17280, 66, 4320, 17280, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 66, 66, 66, 17280, 4320, 66, 17280, 66, 17280, 66, 66, 4320, 4320, 17280, 4320, 17280, 66, 4320, 66, 17280, 17280, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 66, 4320, 17280, 17280, 66, 17280, 4320, 66, 4320, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 4320, 17280, 17280, 4320, 66, 17280, 66, 4320, 4320, 66, 4320, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 17280, 66, 17280, 66, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 4320, 4320, 66, 4320, 17280, 4320, 4320, 17280, 66, 17280, 17280, 4320, 66, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 66, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 17280, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 66, 66, 66, 66]
Prompts retrieved: 1858890 . Total input tokens: 414477948 . Total output tokens: 371780131
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 6.037974341306835,
    "estimated_duration": 3600.052383111078,
    "input_throughput": 4460.8609239518655,
    "output_throughput": 3928.731722447163,
    "total_throughput": 8389.592646399029,
    "itl": 177.6573910169198,
    "ttft": 2160002.8801691094,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1001,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.311296081226315,
    "arrivals": 619780,
    "finished_requests": 64764,
    "scheduler_time": 96.57840983380534
}
#Debug simulation 
Total elapsed time: 6.038077614270151. Arrivals time: 0.2845958461984992 Scheduler time: 5.647112322039902 Scheduler overhead time: 0.032883419655263424 Adapter cache time: 0.02589390706270933 Engine time: 0.032759588211774826 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-16/adapters_256_slots_128_rate_1.6-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-16/adapters_256_slots_128_rate_1.6-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 66, 17280, 17280, 66, 17280, 4320, 17280, 66, 4320, 66, 17280, 4320, 4320, 4320, 4320, 17280, 66, 66, 66, 4320, 17280, 66, 17280, 17280, 4320, 4320, 4320, 66, 17280, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 17280, 4320, 66, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 66, 17280, 17280, 4320, 66, 66, 17280, 4320, 66, 4320, 4320, 17280, 4320, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 17280, 17280, 66, 17280, 66, 4320, 17280, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 66, 66, 66, 17280, 4320, 66, 17280, 66, 17280, 66, 66, 4320, 4320, 17280, 4320, 17280, 66, 4320, 66, 17280, 17280, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 66, 4320, 17280, 17280, 66, 17280, 4320, 66, 4320, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 4320, 17280, 17280, 4320, 66, 17280, 66, 4320, 4320, 66, 4320, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 17280, 66, 17280, 66, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 4320, 4320, 66, 4320, 17280, 4320, 4320, 17280, 66, 17280, 17280, 4320, 66, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 66, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 17280, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 66, 66, 66, 66]
Prompts retrieved: 1858890 . Total input tokens: 414477948 . Total output tokens: 371780131
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 7.265029829926789,
    "estimated_duration": 3600.0272902195316,
    "input_throughput": 4655.1966551836995,
    "output_throughput": 4095.6750633689976,
    "total_throughput": 8750.871718552697,
    "itl": 209.0273810192798,
    "ttft": 2135515.9134209496,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 732,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.188716815868352,
    "arrivals": 619780,
    "finished_requests": 67606,
    "scheduler_time": 93.18644466215875
}
#Debug simulation 
Total elapsed time: 7.265131142921746. Arrivals time: 0.34856295539066195 Scheduler time: 6.820599210448563 Scheduler overhead time: 0.030068374704569578 Adapter cache time: 0.022975876927375793 Engine time: 0.029684864450246096 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-32/adapters_256_slots_128_rate_1.6-0.4-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-32/adapters_256_slots_128_rate_1.6-0.4-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 66, 17280, 17280, 66, 17280, 4320, 17280, 66, 4320, 66, 17280, 4320, 4320, 4320, 4320, 17280, 66, 66, 66, 4320, 17280, 66, 17280, 17280, 4320, 4320, 4320, 66, 17280, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 17280, 4320, 66, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 66, 17280, 17280, 4320, 66, 66, 17280, 4320, 66, 4320, 4320, 17280, 4320, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 17280, 17280, 66, 17280, 66, 4320, 17280, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 66, 66, 66, 17280, 4320, 66, 17280, 66, 17280, 66, 66, 4320, 4320, 17280, 4320, 17280, 66, 4320, 66, 17280, 17280, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 66, 4320, 17280, 17280, 66, 17280, 4320, 66, 4320, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 4320, 17280, 17280, 4320, 66, 17280, 66, 4320, 4320, 66, 4320, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 17280, 66, 17280, 66, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 4320, 4320, 66, 4320, 17280, 4320, 4320, 17280, 66, 17280, 17280, 4320, 66, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 66, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 17280, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 66, 66, 66, 66]
Prompts retrieved: 1858890 . Total input tokens: 414477948 . Total output tokens: 371780131
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 6.164017035625875,
    "estimated_duration": 3600.098872684373,
    "input_throughput": 4460.803319000386,
    "output_throughput": 3928.680989101267,
    "total_throughput": 8389.484308101653,
    "itl": 177.65953146946876,
    "ttft": 2160020.7417505574,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1001,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3576992284134444,
    "arrivals": 619780,
    "finished_requests": 64764,
    "scheduler_time": 96.57849625995327
}
#Debug simulation 
Total elapsed time: 6.164119884837419. Arrivals time: 0.32273078989237547 Scheduler time: 5.7311166687868536 Scheduler overhead time: 0.03356624348089099 Adapter cache time: 0.028179137967526913 Engine time: 0.033336253836750984 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-8/adapters_256_slots_128_rate_1.6-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-8/adapters_256_slots_128_rate_1.6-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 33, 17280, 17280, 33, 17280, 4320, 17280, 33, 4320, 33, 17280, 4320, 4320, 4320, 4320, 17280, 33, 33, 33, 4320, 17280, 33, 17280, 17280, 4320, 4320, 4320, 33, 17280, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 17280, 4320, 33, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 33, 17280, 17280, 4320, 33, 33, 17280, 4320, 33, 4320, 4320, 17280, 4320, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 17280, 17280, 33, 17280, 33, 4320, 17280, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 33, 33, 33, 17280, 4320, 33, 17280, 33, 17280, 33, 33, 4320, 4320, 17280, 4320, 17280, 33, 4320, 33, 17280, 17280, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 33, 4320, 17280, 17280, 33, 17280, 4320, 33, 4320, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 4320, 17280, 17280, 4320, 33, 17280, 33, 4320, 4320, 33, 4320, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 17280, 33, 17280, 33, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 4320, 4320, 33, 4320, 17280, 4320, 4320, 17280, 33, 17280, 17280, 4320, 33, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 33, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 17280, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 33, 33, 33, 33]
Prompts retrieved: 1856085 . Total input tokens: 413843494 . Total output tokens: 371231399
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 7.471295112743974,
    "estimated_duration": 3600.084237889302,
    "input_throughput": 4645.279636513389,
    "output_throughput": 4093.429493927618,
    "total_throughput": 8738.709130441008,
    "itl": 209.42598663808656,
    "ttft": 2131595.8707659505,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 651,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.992377521300256,
    "arrivals": 618816,
    "finished_requests": 67693,
    "scheduler_time": 93.17044810490455
}
#Debug simulation 
Total elapsed time: 7.471431306563318. Arrivals time: 0.36033666878938675 Scheduler time: 7.013820408843458 Scheduler overhead time: 0.030549849383533 Adapter cache time: 0.02226116554811597 Engine time: 0.03071180870756507 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-16/adapters_256_slots_128_rate_1.6-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-16/adapters_256_slots_128_rate_1.6-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 33, 17280, 17280, 33, 17280, 4320, 17280, 33, 4320, 33, 17280, 4320, 4320, 4320, 4320, 17280, 33, 33, 33, 4320, 17280, 33, 17280, 17280, 4320, 4320, 4320, 33, 17280, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 17280, 4320, 33, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 33, 17280, 17280, 4320, 33, 33, 17280, 4320, 33, 4320, 4320, 17280, 4320, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 17280, 17280, 33, 17280, 33, 4320, 17280, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 33, 33, 33, 17280, 4320, 33, 17280, 33, 17280, 33, 33, 4320, 4320, 17280, 4320, 17280, 33, 4320, 33, 17280, 17280, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 33, 4320, 17280, 17280, 33, 17280, 4320, 33, 4320, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 4320, 17280, 17280, 4320, 33, 17280, 33, 4320, 4320, 33, 4320, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 17280, 33, 17280, 33, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 4320, 4320, 33, 4320, 17280, 4320, 4320, 17280, 33, 17280, 17280, 4320, 33, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 33, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 17280, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 33, 33, 33, 33]
Prompts retrieved: 1856085 . Total input tokens: 413843494 . Total output tokens: 371231399
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 7.148673682939261,
    "estimated_duration": 3600.060648619371,
    "input_throughput": 4645.0273015297835,
    "output_throughput": 4093.146598974969,
    "total_throughput": 8738.173900504753,
    "itl": 209.43021794684293,
    "ttft": 2131619.4049303834,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 651,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.123444514865992,
    "arrivals": 618816,
    "finished_requests": 67689,
    "scheduler_time": 93.16691594472287
}
#Debug simulation 
Total elapsed time: 7.148772841319442. Arrivals time: 0.3312505376525223 Scheduler time: 6.726069027092308 Scheduler overhead time: 0.02909951563924551 Adapter cache time: 0.02019231952726841 Engine time: 0.029114294331520796 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-32/adapters_256_slots_128_rate_1.6-0.4-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-32/adapters_256_slots_128_rate_1.6-0.4-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 33, 17280, 17280, 33, 17280, 4320, 17280, 33, 4320, 33, 17280, 4320, 4320, 4320, 4320, 17280, 33, 33, 33, 4320, 17280, 33, 17280, 17280, 4320, 4320, 4320, 33, 17280, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 17280, 4320, 33, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 33, 17280, 17280, 4320, 33, 33, 17280, 4320, 33, 4320, 4320, 17280, 4320, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 17280, 17280, 33, 17280, 33, 4320, 17280, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 33, 33, 33, 17280, 4320, 33, 17280, 33, 17280, 33, 33, 4320, 4320, 17280, 4320, 17280, 33, 4320, 33, 17280, 17280, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 33, 4320, 17280, 17280, 33, 17280, 4320, 33, 4320, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 4320, 17280, 17280, 4320, 33, 17280, 33, 4320, 4320, 33, 4320, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 17280, 33, 17280, 33, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 4320, 4320, 33, 4320, 17280, 4320, 4320, 17280, 33, 17280, 17280, 4320, 33, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 33, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 17280, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 33, 33, 33, 33]
Prompts retrieved: 1856085 . Total input tokens: 413843494 . Total output tokens: 371231399
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 6.028052175883204,
    "estimated_duration": 3600.187039337551,
    "input_throughput": 4450.3268371712475,
    "output_throughput": 3930.3846842923135,
    "total_throughput": 8380.711521463561,
    "itl": 178.1318673643387,
    "ttft": 2156498.6407736363,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 913,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.98613991806281,
    "arrivals": 618816,
    "finished_requests": 64837,
    "scheduler_time": 96.54856475913203
}
#Debug simulation 
Total elapsed time: 6.028161528054625. Arrivals time: 0.2721940870396793 Scheduler time: 5.65079400409013 Scheduler overhead time: 0.03316340781748295 Adapter cache time: 0.023635768331587315 Engine time: 0.03327649645507336 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-16/adapters_256_slots_128_rate_1.6-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-16/adapters_256_slots_128_rate_1.6-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 33, 17280, 17280, 33, 17280, 4320, 17280, 33, 4320, 33, 17280, 4320, 4320, 4320, 4320, 17280, 33, 33, 33, 4320, 17280, 33, 17280, 17280, 4320, 4320, 4320, 33, 17280, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 17280, 4320, 33, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 33, 17280, 17280, 4320, 33, 33, 17280, 4320, 33, 4320, 4320, 17280, 4320, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 17280, 17280, 33, 17280, 33, 4320, 17280, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 33, 33, 33, 17280, 4320, 33, 17280, 33, 17280, 33, 33, 4320, 4320, 17280, 4320, 17280, 33, 4320, 33, 17280, 17280, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 33, 4320, 17280, 17280, 33, 17280, 4320, 33, 4320, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 4320, 17280, 17280, 4320, 33, 17280, 33, 4320, 4320, 33, 4320, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 17280, 33, 17280, 33, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 4320, 4320, 33, 4320, 17280, 4320, 4320, 17280, 33, 17280, 17280, 4320, 33, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 33, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 17280, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 33, 33, 33, 33]
Prompts retrieved: 1856085 . Total input tokens: 413843494 . Total output tokens: 371231399
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 7.762165937107056,
    "estimated_duration": 3600.1348521172404,
    "input_throughput": 4645.214328614653,
    "output_throughput": 4093.3719444796207,
    "total_throughput": 8738.586273094274,
    "itl": 209.42858241763005,
    "ttft": 2131616.879528339,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 651,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0425426418147863,
    "arrivals": 618816,
    "finished_requests": 67693,
    "scheduler_time": 93.17057429825633
}
#Debug simulation 
Total elapsed time: 7.762282830197364. Arrivals time: 0.4102389458566904 Scheduler time: 7.252076622564346 Scheduler overhead time: 0.031523396261036396 Adapter cache time: 0.022649018093943596 Engine time: 0.03167470032349229 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-32/adapters_256_slots_128_rate_1.6-0.4-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-32/adapters_256_slots_128_rate_1.6-0.4-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 33, 17280, 17280, 33, 17280, 4320, 17280, 33, 4320, 33, 17280, 4320, 4320, 4320, 4320, 17280, 33, 33, 33, 4320, 17280, 33, 17280, 17280, 4320, 4320, 4320, 33, 17280, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 17280, 4320, 33, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 33, 17280, 17280, 4320, 33, 33, 17280, 4320, 33, 4320, 4320, 17280, 4320, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 17280, 17280, 33, 17280, 33, 4320, 17280, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 33, 33, 33, 17280, 4320, 33, 17280, 33, 17280, 33, 33, 4320, 4320, 17280, 4320, 17280, 33, 4320, 33, 17280, 17280, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 33, 4320, 17280, 17280, 33, 17280, 4320, 33, 4320, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 4320, 17280, 17280, 4320, 33, 17280, 33, 4320, 4320, 33, 4320, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 17280, 33, 17280, 33, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 4320, 4320, 33, 4320, 17280, 4320, 4320, 17280, 33, 17280, 17280, 4320, 33, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 33, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 17280, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 33, 33, 33, 33]
Prompts retrieved: 1856085 . Total input tokens: 413843494 . Total output tokens: 371231399
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 6.290403762832284,
    "estimated_duration": 3600.0229919214544,
    "input_throughput": 4450.45935427447,
    "output_throughput": 3930.4907306849564,
    "total_throughput": 8380.950084959426,
    "itl": 178.1331444417799,
    "ttft": 2156391.0485718427,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 913,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0209737168997504,
    "arrivals": 618816,
    "finished_requests": 64836,
    "scheduler_time": 96.54327720019083
}
#Debug simulation 
Total elapsed time: 6.290527346078306. Arrivals time: 0.33501722756773233 Scheduler time: 5.844037159811705 Scheduler overhead time: 0.034258024767041206 Adapter cache time: 0.027562722098082304 Engine time: 0.034165505319833755 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-16/adapters_256_slots_128_rate_1.6-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-16/adapters_256_slots_128_rate_1.6-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 33, 17280, 17280, 33, 17280, 4320, 17280, 33, 4320, 33, 17280, 4320, 4320, 4320, 4320, 17280, 33, 33, 33, 4320, 17280, 33, 17280, 17280, 4320, 4320, 4320, 33, 17280, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 17280, 4320, 33, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 33, 17280, 17280, 4320, 33, 33, 17280, 4320, 33, 4320, 4320, 17280, 4320, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 17280, 17280, 33, 17280, 33, 4320, 17280, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 33, 33, 33, 17280, 4320, 33, 17280, 33, 17280, 33, 33, 4320, 4320, 17280, 4320, 17280, 33, 4320, 33, 17280, 17280, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 33, 4320, 17280, 17280, 33, 17280, 4320, 33, 4320, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 4320, 17280, 17280, 4320, 33, 17280, 33, 4320, 4320, 33, 4320, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 17280, 33, 17280, 33, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 4320, 4320, 33, 4320, 17280, 4320, 4320, 17280, 33, 17280, 17280, 4320, 33, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 33, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 17280, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 33, 33, 33, 33]
Prompts retrieved: 1856085 . Total input tokens: 413843494 . Total output tokens: 371231399
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 7.396879930049181,
    "estimated_duration": 3600.0382415499917,
    "input_throughput": 4645.338987510245,
    "output_throughput": 4093.481794142036,
    "total_throughput": 8738.82078165228,
    "itl": 209.42370370978577,
    "ttft": 2131576.2467708606,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 651,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.946522741981284,
    "arrivals": 618816,
    "finished_requests": 67693,
    "scheduler_time": 93.17030654483466
}
#Debug simulation 
Total elapsed time: 7.39698198903352. Arrivals time: 0.35925258602946997 Scheduler time: 6.942174257710576 Scheduler overhead time: 0.0303543321788311 Adapter cache time: 0.021432159934192896 Engine time: 0.03028940549120307 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-32/adapters_256_slots_128_rate_1.6-0.4-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-32/adapters_256_slots_128_rate_1.6-0.4-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 33, 17280, 17280, 33, 17280, 4320, 17280, 33, 4320, 33, 17280, 4320, 4320, 4320, 4320, 17280, 33, 33, 33, 4320, 17280, 33, 17280, 17280, 4320, 4320, 4320, 33, 17280, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 17280, 4320, 33, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 33, 17280, 17280, 4320, 33, 33, 17280, 4320, 33, 4320, 4320, 17280, 4320, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 17280, 17280, 33, 17280, 33, 4320, 17280, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 33, 33, 33, 17280, 4320, 33, 17280, 33, 17280, 33, 33, 4320, 4320, 17280, 4320, 17280, 33, 4320, 33, 17280, 17280, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 33, 4320, 17280, 17280, 33, 17280, 4320, 33, 4320, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 4320, 17280, 17280, 4320, 33, 17280, 33, 4320, 4320, 33, 4320, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 17280, 33, 17280, 33, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 4320, 4320, 33, 4320, 17280, 4320, 4320, 17280, 33, 17280, 17280, 4320, 33, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 33, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 17280, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 33, 33, 33, 33]
Prompts retrieved: 1856085 . Total input tokens: 413843494 . Total output tokens: 371231399
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 6.295566843356937,
    "estimated_duration": 3600.0659288295838,
    "input_throughput": 4450.406274978644,
    "output_throughput": 3930.443852899176,
    "total_throughput": 8380.85012787782,
    "itl": 178.13514876384477,
    "ttft": 2156408.112186756,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 913,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0634784967080075,
    "arrivals": 618816,
    "finished_requests": 64836,
    "scheduler_time": 96.54337824800388
}
#Debug simulation 
Total elapsed time: 6.295676987152547. Arrivals time: 0.33376945555210114 Scheduler time: 5.850924882572144 Scheduler overhead time: 0.0342811718583107 Adapter cache time: 0.02702301600947976 Engine time: 0.03406287869438529 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-8/adapters_256_slots_128_rate_1.6-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-8/adapters_256_slots_128_rate_1.6-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 540, 17280, 17280, 540, 17280, 1080, 17280, 540, 1080, 540, 17280, 1080, 1080, 1080, 1080, 17280, 540, 540, 540, 1080, 17280, 540, 17280, 17280, 1080, 1080, 1080, 540, 17280, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 17280, 1080, 540, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 540, 17280, 17280, 1080, 540, 540, 17280, 1080, 540, 1080, 1080, 17280, 1080, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 17280, 17280, 540, 17280, 540, 1080, 17280, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 540, 540, 540, 17280, 1080, 540, 17280, 540, 17280, 540, 540, 1080, 1080, 17280, 1080, 17280, 540, 1080, 540, 17280, 17280, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 540, 1080, 17280, 17280, 540, 17280, 1080, 540, 1080, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 1080, 17280, 17280, 1080, 540, 17280, 540, 1080, 1080, 540, 1080, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 17280, 540, 17280, 540, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 1080, 1080, 540, 1080, 17280, 1080, 1080, 17280, 540, 17280, 17280, 1080, 540, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 540, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 17280, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 540, 540, 540, 540]
Prompts retrieved: 1623780 . Total input tokens: 362007641 . Total output tokens: 324668356
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 6.227329880930483,
    "estimated_duration": 3600.016483761955,
    "input_throughput": 4630.206854659002,
    "output_throughput": 4091.5762653974502,
    "total_throughput": 8721.783120056452,
    "itl": 209.8674179696639,
    "ttft": 2112685.6087381607,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1678,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.135498434319303,
    "arrivals": 541365,
    "finished_requests": 67471,
    "scheduler_time": 92.93402937778825
}
#Debug simulation 
Total elapsed time: 6.227458904031664. Arrivals time: 0.42490717954933643 Scheduler time: 5.690859192982316 Scheduler overhead time: 0.030179817229509354 Adapter cache time: 0.0381336216814816 Engine time: 0.029919735621660948 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-16/adapters_256_slots_128_rate_1.6-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-16/adapters_256_slots_128_rate_1.6-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 540, 17280, 17280, 540, 17280, 1080, 17280, 540, 1080, 540, 17280, 1080, 1080, 1080, 1080, 17280, 540, 540, 540, 1080, 17280, 540, 17280, 17280, 1080, 1080, 1080, 540, 17280, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 17280, 1080, 540, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 540, 17280, 17280, 1080, 540, 540, 17280, 1080, 540, 1080, 1080, 17280, 1080, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 17280, 17280, 540, 17280, 540, 1080, 17280, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 540, 540, 540, 17280, 1080, 540, 17280, 540, 17280, 540, 540, 1080, 1080, 17280, 1080, 17280, 540, 1080, 540, 17280, 17280, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 540, 1080, 17280, 17280, 540, 17280, 1080, 540, 1080, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 1080, 17280, 17280, 1080, 540, 17280, 540, 1080, 1080, 540, 1080, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 17280, 540, 17280, 540, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 1080, 1080, 540, 1080, 17280, 1080, 1080, 17280, 540, 17280, 17280, 1080, 540, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 540, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 17280, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 540, 540, 540, 540]
Prompts retrieved: 1623780 . Total input tokens: 362007641 . Total output tokens: 324668356
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 6.213879827875644,
    "estimated_duration": 3600.131796781368,
    "input_throughput": 4629.851055703512,
    "output_throughput": 4091.183554215436,
    "total_throughput": 8721.034609918948,
    "itl": 209.88437129204206,
    "ttft": 2112816.225561738,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1678,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.473705365543593,
    "arrivals": 541365,
    "finished_requests": 67465,
    "scheduler_time": 92.92934006818281
}
#Debug simulation 
Total elapsed time: 6.213987524621189. Arrivals time: 0.4238699935376644 Scheduler time: 5.678845698479563 Scheduler overhead time: 0.03009120700880885 Adapter cache time: 0.037874612491577864 Engine time: 0.02982976520434022 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-32/adapters_256_slots_128_rate_1.6-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-32/adapters_256_slots_128_rate_1.6-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 540, 17280, 17280, 540, 17280, 1080, 17280, 540, 1080, 540, 17280, 1080, 1080, 1080, 1080, 17280, 540, 540, 540, 1080, 17280, 540, 17280, 17280, 1080, 1080, 1080, 540, 17280, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 17280, 1080, 540, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 540, 17280, 17280, 1080, 540, 540, 17280, 1080, 540, 1080, 1080, 17280, 1080, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 17280, 17280, 540, 17280, 540, 1080, 17280, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 540, 540, 540, 17280, 1080, 540, 17280, 540, 17280, 540, 540, 1080, 1080, 17280, 1080, 17280, 540, 1080, 540, 17280, 17280, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 540, 1080, 17280, 17280, 540, 17280, 1080, 540, 1080, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 1080, 17280, 17280, 1080, 540, 17280, 540, 1080, 1080, 540, 1080, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 17280, 540, 17280, 540, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 1080, 1080, 540, 1080, 17280, 1080, 1080, 17280, 540, 17280, 17280, 1080, 540, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 540, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 17280, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 540, 540, 540, 540]
Prompts retrieved: 1623780 . Total input tokens: 362007641 . Total output tokens: 324668356
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.390970112755895,
    "estimated_duration": 3600.0782628909947,
    "input_throughput": 4438.300179388017,
    "output_throughput": 3928.953752422431,
    "total_throughput": 8367.253931810446,
    "itl": 178.57644563724844,
    "ttft": 2139483.3858003784,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2351,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.687489359825819,
    "arrivals": 541365,
    "finished_requests": 64719,
    "scheduler_time": 96.25125049939312
}
#Debug simulation 
Total elapsed time: 5.391061631962657. Arrivals time: 0.33943999418988824 Scheduler time: 4.924508752301335 Scheduler overhead time: 0.03252528002485633 Adapter cache time: 0.04701066203415394 Engine time: 0.03265229519456625 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-16-16/adapters_256_slots_128_rate_1.6-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-16-16/adapters_256_slots_128_rate_1.6-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 540, 17280, 17280, 540, 17280, 1080, 17280, 540, 1080, 540, 17280, 1080, 1080, 1080, 1080, 17280, 540, 540, 540, 1080, 17280, 540, 17280, 17280, 1080, 1080, 1080, 540, 17280, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 17280, 1080, 540, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 540, 17280, 17280, 1080, 540, 540, 17280, 1080, 540, 1080, 1080, 17280, 1080, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 17280, 17280, 540, 17280, 540, 1080, 17280, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 540, 540, 540, 17280, 1080, 540, 17280, 540, 17280, 540, 540, 1080, 1080, 17280, 1080, 17280, 540, 1080, 540, 17280, 17280, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 540, 1080, 17280, 17280, 540, 17280, 1080, 540, 1080, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 1080, 17280, 17280, 1080, 540, 17280, 540, 1080, 1080, 540, 1080, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 17280, 540, 17280, 540, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 1080, 1080, 540, 1080, 17280, 1080, 1080, 17280, 540, 17280, 17280, 1080, 540, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 540, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 17280, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 540, 540, 540, 540]
Prompts retrieved: 1623780 . Total input tokens: 362007641 . Total output tokens: 324668356
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 6.516729953698814,
    "estimated_duration": 3600.1447504534062,
    "input_throughput": 4630.041888704811,
    "output_throughput": 4091.4304898837527,
    "total_throughput": 8721.472378588564,
    "itl": 209.87441073147758,
    "ttft": 2112734.8054348356,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1678,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.263278776546812,
    "arrivals": 541365,
    "finished_requests": 67471,
    "scheduler_time": 92.93417321316531
}
#Debug simulation 
Total elapsed time: 6.516938261687756. Arrivals time: 0.8384589357301593 Scheduler time: 5.555415261071175 Scheduler overhead time: 0.029481321573257446 Adapter cache time: 0.05060922773554921 Engine time: 0.02971868123859167 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-16-32/adapters_256_slots_128_rate_1.6-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-16-32/adapters_256_slots_128_rate_1.6-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 540, 17280, 17280, 540, 17280, 1080, 17280, 540, 1080, 540, 17280, 1080, 1080, 1080, 1080, 17280, 540, 540, 540, 1080, 17280, 540, 17280, 17280, 1080, 1080, 1080, 540, 17280, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 17280, 1080, 540, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 540, 17280, 17280, 1080, 540, 540, 17280, 1080, 540, 1080, 1080, 17280, 1080, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 17280, 17280, 540, 17280, 540, 1080, 17280, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 540, 540, 540, 17280, 1080, 540, 17280, 540, 17280, 540, 540, 1080, 1080, 17280, 1080, 17280, 540, 1080, 540, 17280, 17280, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 540, 1080, 17280, 17280, 540, 17280, 1080, 540, 1080, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 1080, 17280, 17280, 1080, 540, 17280, 540, 1080, 1080, 540, 1080, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 17280, 540, 17280, 540, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 1080, 1080, 540, 1080, 17280, 1080, 1080, 17280, 540, 17280, 17280, 1080, 540, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 540, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 17280, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 540, 540, 540, 540]
Prompts retrieved: 1623780 . Total input tokens: 362007641 . Total output tokens: 324668356
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 5.208809202071279,
    "estimated_duration": 3600.0281531924543,
    "input_throughput": 4438.389179215347,
    "output_throughput": 3929.038162509014,
    "total_throughput": 8367.427341724362,
    "itl": 178.57855972780757,
    "ttft": 2139531.107151029,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2351,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.781307396683687,
    "arrivals": 541365,
    "finished_requests": 64720,
    "scheduler_time": 96.24700083315828
}
#Debug simulation 
Total elapsed time: 5.208886415231973. Arrivals time: 0.2620644080452621 Scheduler time: 4.821507942862809 Scheduler overhead time: 0.03252023737877607 Adapter cache time: 0.04583466146141291 Engine time: 0.03224584273993969 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_16-16-16/adapters_256_slots_128_rate_1.6-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_16-16-16/adapters_256_slots_128_rate_1.6-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 540, 17280, 17280, 540, 17280, 1080, 17280, 540, 1080, 540, 17280, 1080, 1080, 1080, 1080, 17280, 540, 540, 540, 1080, 17280, 540, 17280, 17280, 1080, 1080, 1080, 540, 17280, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 17280, 1080, 540, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 540, 17280, 17280, 1080, 540, 540, 17280, 1080, 540, 1080, 1080, 17280, 1080, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 17280, 17280, 540, 17280, 540, 1080, 17280, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 540, 540, 540, 17280, 1080, 540, 17280, 540, 17280, 540, 540, 1080, 1080, 17280, 1080, 17280, 540, 1080, 540, 17280, 17280, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 540, 1080, 17280, 17280, 540, 17280, 1080, 540, 1080, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 1080, 17280, 17280, 1080, 540, 17280, 540, 1080, 1080, 540, 1080, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 17280, 540, 17280, 540, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 1080, 1080, 540, 1080, 17280, 1080, 1080, 17280, 540, 17280, 17280, 1080, 540, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 540, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 17280, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 540, 540, 540, 540]
Prompts retrieved: 1623780 . Total input tokens: 362007641 . Total output tokens: 324668356
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.737154971808195,
    "estimated_duration": 3600.1324153819214,
    "input_throughput": 4630.353019454583,
    "output_throughput": 4091.5750590349717,
    "total_throughput": 8721.928078489555,
    "itl": 209.86129777735516,
    "ttft": 2112659.879899529,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1678,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.017304394845709,
    "arrivals": 541365,
    "finished_requests": 67473,
    "scheduler_time": 92.93999086703226
}
#Debug simulation 
Total elapsed time: 5.7372336578555405. Arrivals time: 0.2748137218877673 Scheduler time: 5.360180105548352 Scheduler overhead time: 0.028459854889661074 Adapter cache time: 0.03254969837144017 Engine time: 0.028445801697671413 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_16-16-32/adapters_256_slots_128_rate_1.6-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_16-16-32/adapters_256_slots_128_rate_1.6-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 540, 17280, 17280, 540, 17280, 1080, 17280, 540, 1080, 540, 17280, 1080, 1080, 1080, 1080, 17280, 540, 540, 540, 1080, 17280, 540, 17280, 17280, 1080, 1080, 1080, 540, 17280, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 17280, 1080, 540, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 540, 17280, 17280, 1080, 540, 540, 17280, 1080, 540, 1080, 1080, 17280, 1080, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 17280, 17280, 540, 17280, 540, 1080, 17280, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 540, 540, 540, 17280, 1080, 540, 17280, 540, 17280, 540, 540, 1080, 1080, 17280, 1080, 17280, 540, 1080, 540, 17280, 17280, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 540, 1080, 17280, 17280, 540, 17280, 1080, 540, 1080, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 1080, 17280, 17280, 1080, 540, 17280, 540, 1080, 1080, 540, 1080, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 17280, 540, 17280, 540, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 1080, 1080, 540, 1080, 17280, 1080, 1080, 17280, 540, 17280, 17280, 1080, 540, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 540, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 17280, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 540, 540, 540, 540]
Prompts retrieved: 1623780 . Total input tokens: 362007641 . Total output tokens: 324668356
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.2365325056016445,
    "estimated_duration": 3600.1644613471162,
    "input_throughput": 4438.054197674465,
    "output_throughput": 3929.230498183094,
    "total_throughput": 8367.28469585756,
    "itl": 178.59282125613225,
    "ttft": 2139498.029621399,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2359,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.914906998388146,
    "arrivals": 541365,
    "finished_requests": 64721,
    "scheduler_time": 96.2477453875267
}
#Debug simulation 
Total elapsed time: 5.236648777965456. Arrivals time: 0.28792546410113573 Scheduler time: 4.8237521084956825 Scheduler overhead time: 0.03230371279641986 Adapter cache time: 0.04545262362807989 Engine time: 0.03244539676234126 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-8/adapters_256_slots_128_rate_1.6-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-8/adapters_256_slots_128_rate_1.6-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 270, 17280, 17280, 270, 17280, 1080, 17280, 270, 1080, 270, 17280, 1080, 1080, 1080, 1080, 17280, 270, 270, 270, 1080, 17280, 270, 17280, 17280, 1080, 1080, 1080, 270, 17280, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 17280, 1080, 270, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 270, 17280, 17280, 1080, 270, 270, 17280, 1080, 270, 1080, 1080, 17280, 1080, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 17280, 17280, 270, 17280, 270, 1080, 17280, 17280, 17280, 1080, 270, 17280, 1080, 270, 270, 270, 270, 270, 17280, 1080, 270, 17280, 270, 17280, 270, 270, 1080, 1080, 17280, 1080, 17280, 270, 1080, 270, 17280, 17280, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 270, 1080, 17280, 17280, 270, 17280, 1080, 270, 1080, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 1080, 17280, 17280, 1080, 270, 17280, 270, 1080, 1080, 270, 1080, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 17280, 270, 17280, 270, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 1080, 1080, 270, 1080, 17280, 1080, 1080, 17280, 270, 17280, 17280, 1080, 270, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 270, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 17280, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 270, 270, 270, 270]
Prompts retrieved: 1600830 . Total input tokens: 356917788 . Total output tokens: 320016626
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.314614596776664,
    "estimated_duration": 3600.0138128550707,
    "input_throughput": 4658.647402994055,
    "output_throughput": 4086.845152500059,
    "total_throughput": 8745.492555494113,
    "itl": 209.44253032145,
    "ttft": 2108855.018825751,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1948,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.961830125181176,
    "arrivals": 533687,
    "finished_requests": 67540,
    "scheduler_time": 92.95364068291126
}
#Debug simulation 
Total elapsed time: 5.314687946811318. Arrivals time: 0.22174935694783926 Scheduler time: 4.9868581322953105 Scheduler overhead time: 0.028284309897571802 Adapter cache time: 0.03673544339835644 Engine time: 0.028217706829309464 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-16/adapters_256_slots_128_rate_1.6-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-16/adapters_256_slots_128_rate_1.6-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 270, 17280, 17280, 270, 17280, 1080, 17280, 270, 1080, 270, 17280, 1080, 1080, 1080, 1080, 17280, 270, 270, 270, 1080, 17280, 270, 17280, 17280, 1080, 1080, 1080, 270, 17280, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 17280, 1080, 270, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 270, 17280, 17280, 1080, 270, 270, 17280, 1080, 270, 1080, 1080, 17280, 1080, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 17280, 17280, 270, 17280, 270, 1080, 17280, 17280, 17280, 1080, 270, 17280, 1080, 270, 270, 270, 270, 270, 17280, 1080, 270, 17280, 270, 17280, 270, 270, 1080, 1080, 17280, 1080, 17280, 270, 1080, 270, 17280, 17280, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 270, 1080, 17280, 17280, 270, 17280, 1080, 270, 1080, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 1080, 17280, 17280, 1080, 270, 17280, 270, 1080, 1080, 270, 1080, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 17280, 270, 17280, 270, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 1080, 1080, 270, 1080, 17280, 1080, 1080, 17280, 270, 17280, 17280, 1080, 270, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 270, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 17280, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 270, 270, 270, 270]
Prompts retrieved: 1600830 . Total input tokens: 356917788 . Total output tokens: 320016626
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.345913799945265,
    "estimated_duration": 3600.175919195934,
    "input_throughput": 4657.84016569535,
    "output_throughput": 4086.1975442815506,
    "total_throughput": 8744.037709976901,
    "itl": 209.46179713863393,
    "ttft": 2109012.6995334695,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1940,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.331054295445584,
    "arrivals": 533687,
    "finished_requests": 67532,
    "scheduler_time": 92.94893312966461
}
#Debug simulation 
Total elapsed time: 5.3460045997053385. Arrivals time: 0.25549327163025737 Scheduler time: 4.984305277001113 Scheduler overhead time: 0.028256522957235575 Adapter cache time: 0.036736417561769485 Engine time: 0.02837561070919037 
