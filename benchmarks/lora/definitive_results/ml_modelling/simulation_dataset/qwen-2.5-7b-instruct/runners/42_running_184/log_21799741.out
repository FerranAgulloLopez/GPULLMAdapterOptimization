INFO 06-01 00:46:59 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:46:59 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-8/adapters_96_slots_96_rate_3.2-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-8/adapters_96_slots_96_rate_3.2-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 1080, 34560, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 66, 34560, 1080, 66, 66, 1080, 34560, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 34560, 1080, 1080, 66, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 66, 34560, 1080, 1080, 1080, 34560, 34560, 66, 66, 1080, 66, 34560, 66, 66, 34560, 66, 1080, 1080, 66, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 66, 66, 34560, 1080, 34560, 66, 1080, 34560, 66, 34560, 1080, 66, 34560, 66, 66, 34560, 66, 66, 1080]
Prompts retrieved: 1142592 . Total input tokens: 254865998 . Total output tokens: 228602465
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.313473612070084,
    "estimated_duration": 3600.087712335118,
    "input_throughput": 6869.088471169462,
    "output_throughput": 6066.444138338546,
    "total_throughput": 12935.532609508007,
    "itl": 142.025973005639,
    "ttft": 1781919.9944976824,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29380682341754405,
    "arrivals": 381260,
    "finished_requests": 99690,
    "scheduler_time": 61.83470004504078
}
#Debug simulation 
Total elapsed time: 7.3135841358453035. Arrivals time: 0.3015532726421952 Scheduler time: 6.8920002188533545 Scheduler overhead time: 0.03918224526569247 Adapter cache time: 0.021125363651663065 Engine time: 0.041109056212008 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-16/adapters_96_slots_96_rate_3.2-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-16/adapters_96_slots_96_rate_3.2-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 1080, 34560, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 66, 34560, 1080, 66, 66, 1080, 34560, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 34560, 1080, 1080, 66, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 66, 34560, 1080, 1080, 1080, 34560, 34560, 66, 66, 1080, 66, 34560, 66, 66, 34560, 66, 1080, 1080, 66, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 66, 66, 34560, 1080, 34560, 66, 1080, 34560, 66, 34560, 1080, 66, 34560, 66, 66, 34560, 66, 66, 1080]
Prompts retrieved: 1142592 . Total input tokens: 254865998 . Total output tokens: 228602465
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.311340226326138,
    "estimated_duration": 3600.1184584517287,
    "input_throughput": 6869.1423033439005,
    "output_throughput": 6066.421772519248,
    "total_throughput": 12935.564075863149,
    "itl": 142.02610324244628,
    "ttft": 1781940.8882008533,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31319492869079113,
    "arrivals": 381260,
    "finished_requests": 99691,
    "scheduler_time": 61.83514507332412
}
#Debug simulation 
Total elapsed time: 7.311485294252634. Arrivals time: 0.2930419323965907 Scheduler time: 6.898373383097351 Scheduler overhead time: 0.03926508687436581 Adapter cache time: 0.021124882623553276 Engine time: 0.04108744207769632 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-32/adapters_96_slots_96_rate_3.2-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-32/adapters_96_slots_96_rate_3.2-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 1080, 34560, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 66, 34560, 1080, 66, 66, 1080, 34560, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 34560, 1080, 1080, 66, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 66, 34560, 1080, 1080, 1080, 34560, 34560, 66, 66, 1080, 66, 34560, 66, 66, 34560, 66, 1080, 1080, 66, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 66, 66, 34560, 1080, 34560, 66, 1080, 34560, 66, 34560, 1080, 66, 34560, 66, 66, 34560, 66, 66, 1080]
Prompts retrieved: 1142592 . Total input tokens: 254865998 . Total output tokens: 228602465
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.290972802788019,
    "estimated_duration": 3600.0879701041504,
    "input_throughput": 6859.719874924489,
    "output_throughput": 6059.2113807066025,
    "total_throughput": 12918.931255631092,
    "itl": 140.21709139566923,
    "ttft": 1783082.2156843948,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31376164913177523,
    "arrivals": 381260,
    "finished_requests": 99559,
    "scheduler_time": 61.36439774351038
}
#Debug simulation 
Total elapsed time: 7.291066148784012. Arrivals time: 0.29847254045307636 Scheduler time: 6.871095476672053 Scheduler overhead time: 0.039790038019418716 Adapter cache time: 0.021547857206314802 Engine time: 0.04145377408713102 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-16/adapters_96_slots_96_rate_3.2-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-16/adapters_96_slots_96_rate_3.2-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 1080, 34560, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 66, 34560, 1080, 66, 66, 1080, 34560, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 34560, 1080, 1080, 66, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 66, 34560, 1080, 1080, 1080, 34560, 34560, 66, 66, 1080, 66, 34560, 66, 66, 34560, 66, 1080, 1080, 66, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 66, 66, 34560, 1080, 34560, 66, 1080, 34560, 66, 34560, 1080, 66, 34560, 66, 66, 34560, 66, 66, 1080]
Prompts retrieved: 1142592 . Total input tokens: 254865998 . Total output tokens: 228602465
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 7.287067721132189,
    "estimated_duration": 3600.0996009561286,
    "input_throughput": 6869.178284243076,
    "output_throughput": 6066.453548729511,
    "total_throughput": 12935.631832972585,
    "itl": 142.0256571508158,
    "ttft": 1781929.5310007073,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3001198785007001,
    "arrivals": 381260,
    "finished_requests": 99691,
    "scheduler_time": 61.83508309004209
}
#Debug simulation 
Total elapsed time: 7.287168647162616. Arrivals time: 0.2940220800228417 Scheduler time: 6.873345249332488 Scheduler overhead time: 0.03933399822562933 Adapter cache time: 0.021171261090785265 Engine time: 0.040835521183907986 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-32/adapters_96_slots_96_rate_3.2-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-32/adapters_96_slots_96_rate_3.2-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 1080, 34560, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 66, 34560, 1080, 66, 66, 1080, 34560, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 34560, 1080, 1080, 66, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 66, 34560, 1080, 1080, 1080, 34560, 34560, 66, 66, 1080, 66, 34560, 66, 66, 34560, 66, 1080, 1080, 66, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 66, 66, 34560, 1080, 34560, 66, 1080, 34560, 66, 34560, 1080, 66, 34560, 66, 66, 34560, 66, 66, 1080]
Prompts retrieved: 1142592 . Total input tokens: 254865998 . Total output tokens: 228602465
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 7.299091838765889,
    "estimated_duration": 3600.0931028119608,
    "input_throughput": 6859.710094916924,
    "output_throughput": 6059.202741996244,
    "total_throughput": 12918.912836913169,
    "itl": 140.2171912788956,
    "ttft": 1783085.9716710586,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3177857702970504,
    "arrivals": 381260,
    "finished_requests": 99559,
    "scheduler_time": 61.364372889292454
}
#Debug simulation 
Total elapsed time: 7.299192475620657. Arrivals time: 0.29679758474230766 Scheduler time: 6.881226072087884 Scheduler overhead time: 0.03977803839370608 Adapter cache time: 0.02145307371392846 Engine time: 0.04120849305763841 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-16/adapters_96_slots_96_rate_3.2-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-16/adapters_96_slots_96_rate_3.2-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 1080, 34560, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 66, 34560, 1080, 66, 66, 1080, 34560, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 34560, 1080, 1080, 66, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 66, 34560, 1080, 1080, 1080, 34560, 34560, 66, 66, 1080, 66, 34560, 66, 66, 34560, 66, 1080, 1080, 66, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 66, 66, 34560, 1080, 34560, 66, 1080, 34560, 66, 34560, 1080, 66, 34560, 66, 66, 34560, 66, 66, 1080]
Prompts retrieved: 1142592 . Total input tokens: 254865998 . Total output tokens: 228602465
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.327941386029124,
    "estimated_duration": 3600.0579437509764,
    "input_throughput": 6868.932218972786,
    "output_throughput": 6066.3437481357005,
    "total_throughput": 12935.275967108486,
    "itl": 142.02553974104373,
    "ttft": 1781927.570059025,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2870448283106092,
    "arrivals": 381260,
    "finished_requests": 99689,
    "scheduler_time": 61.83419313292171
}
#Debug simulation 
Total elapsed time: 7.328052535187453. Arrivals time: 0.32231234665960073 Scheduler time: 6.8863003817386925 Scheduler overhead time: 0.03920285543426871 Adapter cache time: 0.02098915260285139 Engine time: 0.04073766712099314 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-32/adapters_96_slots_96_rate_3.2-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-32/adapters_96_slots_96_rate_3.2-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 1080, 34560, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 66, 34560, 1080, 66, 66, 1080, 34560, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 34560, 1080, 1080, 66, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 66, 34560, 1080, 1080, 1080, 34560, 34560, 66, 66, 1080, 66, 34560, 66, 66, 34560, 66, 1080, 1080, 66, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 66, 66, 34560, 1080, 34560, 66, 1080, 34560, 66, 34560, 1080, 66, 34560, 66, 66, 34560, 66, 66, 1080]
Prompts retrieved: 1142592 . Total input tokens: 254865998 . Total output tokens: 228602465
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.3006350812502205,
    "estimated_duration": 3600.09745950573,
    "input_throughput": 6859.701793570484,
    "output_throughput": 6059.195409391744,
    "total_throughput": 12918.89720296223,
    "itl": 140.21727142417893,
    "ttft": 1783089.1189409532,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3218098914623256,
    "arrivals": 381260,
    "finished_requests": 99559,
    "scheduler_time": 61.36435798027074
}
#Debug simulation 
Total elapsed time: 7.30073114996776. Arrivals time: 0.29357096878811717 Scheduler time: 6.885002658702433 Scheduler overhead time: 0.03995420737192035 Adapter cache time: 0.021737865637987852 Engine time: 0.0413781781680882 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-8/adapters_96_slots_96_rate_3.2-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-8/adapters_96_slots_96_rate_3.2-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 1080, 34560, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 33, 34560, 1080, 33, 33, 1080, 34560, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 34560, 1080, 1080, 33, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 33, 34560, 1080, 1080, 1080, 34560, 34560, 33, 33, 1080, 33, 34560, 33, 33, 34560, 33, 1080, 1080, 33, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 33, 33, 34560, 1080, 34560, 33, 1080, 34560, 33, 34560, 1080, 33, 34560, 33, 33, 34560, 33, 33, 1080]
Prompts retrieved: 1141536 . Total input tokens: 254627313 . Total output tokens: 228396762
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.440969957970083,
    "estimated_duration": 3600.1548520672463,
    "input_throughput": 6964.558478811694,
    "output_throughput": 6134.5208491013755,
    "total_throughput": 13099.079327913068,
    "itl": 140.11625725394424,
    "ttft": 1775710.5851149636,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 95,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2907463356736113,
    "arrivals": 380865,
    "finished_requests": 101074,
    "scheduler_time": 62.530783307505345
}
#Debug simulation 
Total elapsed time: 7.4410844380036. Arrivals time: 0.3431652458384633 Scheduler time: 6.975690374150872 Scheduler overhead time: 0.040131894405931234 Adapter cache time: 0.021489761769771576 Engine time: 0.0416890773922205 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-16/adapters_96_slots_96_rate_3.2-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-16/adapters_96_slots_96_rate_3.2-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 1080, 34560, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 33, 34560, 1080, 33, 33, 1080, 34560, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 34560, 1080, 1080, 33, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 33, 34560, 1080, 1080, 1080, 34560, 34560, 33, 33, 1080, 33, 34560, 33, 33, 34560, 33, 1080, 1080, 33, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 33, 33, 34560, 1080, 34560, 33, 1080, 34560, 33, 34560, 1080, 33, 34560, 33, 33, 34560, 33, 33, 1080]
Prompts retrieved: 1141536 . Total input tokens: 254627313 . Total output tokens: 228396762
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.392455814871937,
    "estimated_duration": 3600.0722062301,
    "input_throughput": 6964.567809670608,
    "output_throughput": 6134.611400788228,
    "total_throughput": 13099.179210458835,
    "itl": 140.11775800902453,
    "ttft": 1775708.0152584335,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 95,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.30979628307744855,
    "arrivals": 380865,
    "finished_requests": 101072,
    "scheduler_time": 62.529094067895706
}
#Debug simulation 
Total elapsed time: 7.392553794197738. Arrivals time: 0.30387882329523563 Scheduler time: 6.967378236353397 Scheduler overhead time: 0.03980375174432993 Adapter cache time: 0.021189235616475344 Engine time: 0.04151683859527111 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-32/adapters_96_slots_96_rate_3.2-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-32/adapters_96_slots_96_rate_3.2-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 1080, 34560, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 33, 34560, 1080, 33, 33, 1080, 34560, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 34560, 1080, 1080, 33, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 33, 34560, 1080, 1080, 1080, 34560, 34560, 33, 33, 1080, 33, 34560, 33, 33, 34560, 33, 1080, 1080, 33, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 33, 33, 34560, 1080, 34560, 33, 1080, 34560, 33, 34560, 1080, 33, 34560, 33, 33, 34560, 33, 33, 1080]
Prompts retrieved: 1141536 . Total input tokens: 254627313 . Total output tokens: 228396762
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.3953600618988276,
    "estimated_duration": 3600.0512046932067,
    "input_throughput": 6956.953269817268,
    "output_throughput": 6128.195891002636,
    "total_throughput": 13085.149160819905,
    "itl": 138.45681515954124,
    "ttft": 1776876.223059955,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 95,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31038088278844983,
    "arrivals": 380865,
    "finished_requests": 100961,
    "scheduler_time": 62.08967118215396
}
#Debug simulation 
Total elapsed time: 7.395462260581553. Arrivals time: 0.3059030487202108 Scheduler time: 6.966964173130691 Scheduler overhead time: 0.0402288818731904 Adapter cache time: 0.02135290950536728 Engine time: 0.04197493474930525 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-16/adapters_96_slots_96_rate_3.2-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-16/adapters_96_slots_96_rate_3.2-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 1080, 34560, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 33, 34560, 1080, 33, 33, 1080, 34560, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 34560, 1080, 1080, 33, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 33, 34560, 1080, 1080, 1080, 34560, 34560, 33, 33, 1080, 33, 34560, 33, 33, 34560, 33, 1080, 1080, 33, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 33, 33, 34560, 1080, 34560, 33, 1080, 34560, 33, 34560, 1080, 33, 34560, 33, 33, 34560, 33, 33, 1080]
Prompts retrieved: 1141536 . Total input tokens: 254627313 . Total output tokens: 228396762
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 7.395380009897053,
    "estimated_duration": 3600.0123652469542,
    "input_throughput": 6964.48330067891,
    "output_throughput": 6134.575595682722,
    "total_throughput": 13099.058896361634,
    "itl": 140.1169140857646,
    "ttft": 1775693.7846017152,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 95,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29672123288735763,
    "arrivals": 380865,
    "finished_requests": 101070,
    "scheduler_time": 62.52809088540439
}
#Debug simulation 
Total elapsed time: 7.395509592723101. Arrivals time: 0.34575857408344746 Scheduler time: 6.92868179641664 Scheduler overhead time: 0.03991273883730173 Adapter cache time: 0.020975190214812756 Engine time: 0.04137841425836086 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-32/adapters_96_slots_96_rate_3.2-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-32/adapters_96_slots_96_rate_3.2-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 1080, 34560, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 33, 34560, 1080, 33, 33, 1080, 34560, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 34560, 1080, 1080, 33, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 33, 34560, 1080, 1080, 1080, 34560, 34560, 33, 33, 1080, 33, 34560, 33, 33, 34560, 33, 1080, 1080, 33, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 33, 33, 34560, 1080, 34560, 33, 1080, 34560, 33, 34560, 1080, 33, 34560, 33, 33, 34560, 33, 33, 1080]
Prompts retrieved: 1141536 . Total input tokens: 254627313 . Total output tokens: 228396762
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 7.394929016940296,
    "estimated_duration": 3600.074004654582,
    "input_throughput": 6956.909210093597,
    "output_throughput": 6128.157079958909,
    "total_throughput": 13085.066290052506,
    "itl": 138.4579867239313,
    "ttft": 1776891.954395542,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 95,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31440500395372506,
    "arrivals": 380865,
    "finished_requests": 100961,
    "scheduler_time": 62.08934079568672
}
#Debug simulation 
Total elapsed time: 7.395025750622153. Arrivals time: 0.3006661329418421 Scheduler time: 6.9719786322675645 Scheduler overhead time: 0.04042131872847676 Adapter cache time: 0.02119809715077281 Engine time: 0.04174187267199159 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-16/adapters_96_slots_96_rate_3.2-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-16/adapters_96_slots_96_rate_3.2-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 1080, 34560, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 33, 34560, 1080, 33, 33, 1080, 34560, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 34560, 1080, 1080, 33, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 33, 34560, 1080, 1080, 1080, 34560, 34560, 33, 33, 1080, 33, 34560, 33, 33, 34560, 33, 1080, 1080, 33, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 33, 33, 34560, 1080, 34560, 33, 1080, 34560, 33, 34560, 1080, 33, 34560, 33, 33, 34560, 33, 33, 1080]
Prompts retrieved: 1141536 . Total input tokens: 254627313 . Total output tokens: 228396762
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.683023109100759,
    "estimated_duration": 3600.1069338393113,
    "input_throughput": 6964.651178641668,
    "output_throughput": 6134.6025009449795,
    "total_throughput": 13099.253679586647,
    "itl": 140.11533618208608,
    "ttft": 1775704.0854741565,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 95,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.284054778015707,
    "arrivals": 380865,
    "finished_requests": 101074,
    "scheduler_time": 62.53026137516061
}
#Debug simulation 
Total elapsed time: 7.683089316356927. Arrivals time: 0.6095746080391109 Scheduler time: 6.9530636495910585 Scheduler overhead time: 0.03973973402753472 Adapter cache time: 0.020866310223937035 Engine time: 0.04106243001297116 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-32/adapters_96_slots_96_rate_3.2-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-32/adapters_96_slots_96_rate_3.2-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 1080, 34560, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 33, 34560, 1080, 33, 33, 1080, 34560, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 34560, 1080, 1080, 33, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 33, 34560, 1080, 1080, 1080, 34560, 34560, 33, 33, 1080, 33, 34560, 33, 33, 34560, 33, 1080, 1080, 33, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 33, 33, 34560, 1080, 34560, 33, 1080, 34560, 33, 34560, 1080, 33, 34560, 33, 33, 34560, 33, 33, 1080]
Prompts retrieved: 1141536 . Total input tokens: 254627313 . Total output tokens: 228396762
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.390487230848521,
    "estimated_duration": 3600.0568504083876,
    "input_throughput": 6956.942359718256,
    "output_throughput": 6128.186280585353,
    "total_throughput": 13085.12864030361,
    "itl": 138.45677794991178,
    "ttft": 1776880.1519838981,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 95,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3183033713325854,
    "arrivals": 380865,
    "finished_requests": 100961,
    "scheduler_time": 62.089624137099754
}
#Debug simulation 
Total elapsed time: 7.390608749818057. Arrivals time: 0.35246559092774987 Scheduler time: 6.915668091736734 Scheduler overhead time: 0.04034997709095478 Adapter cache time: 0.02144120493903756 Engine time: 0.041727352887392044 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-8/adapters_96_slots_96_rate_3.2-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-8/adapters_96_slots_96_rate_3.2-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 34560, 540, 540, 540, 540, 34560, 540, 34560, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 34560, 34560, 540, 270, 34560, 540, 270, 270, 540, 34560, 270, 540, 270, 270, 540, 540, 540, 270, 270, 34560, 540, 540, 270, 34560, 34560, 540, 34560, 34560, 540, 34560, 270, 34560, 540, 540, 540, 34560, 34560, 270, 270, 540, 270, 34560, 270, 270, 34560, 270, 540, 540, 270, 540, 34560, 34560, 34560, 540, 34560, 34560, 270, 270, 34560, 540, 34560, 270, 540, 34560, 270, 34560, 540, 270, 34560, 270, 270, 34560, 270, 270, 540]
Prompts retrieved: 1131840 . Total input tokens: 252483530 . Total output tokens: 226461631
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.572832335252315,
    "estimated_duration": 3600.1277889374524,
    "input_throughput": 6975.845990014751,
    "output_throughput": 6187.231483406379,
    "total_throughput": 13163.07747342113,
    "itl": 139.51726585583356,
    "ttft": 1765434.172794101,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29380682341754405,
    "arrivals": 377686,
    "finished_requests": 101461,
    "scheduler_time": 63.23848258463373
}
#Debug simulation 
Total elapsed time: 7.572929991874844. Arrivals time: 0.33528563287109137 Scheduler time: 7.113169932272285 Scheduler overhead time: 0.04006763128563762 Adapter cache time: 0.023602434433996677 Engine time: 0.04184069484472275 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-16/adapters_96_slots_96_rate_3.2-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-16/adapters_96_slots_96_rate_3.2-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 34560, 540, 540, 540, 540, 34560, 540, 34560, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 34560, 34560, 540, 270, 34560, 540, 270, 270, 540, 34560, 270, 540, 270, 270, 540, 540, 540, 270, 270, 34560, 540, 540, 270, 34560, 34560, 540, 34560, 34560, 540, 34560, 270, 34560, 540, 540, 540, 34560, 34560, 270, 270, 540, 270, 34560, 270, 270, 34560, 270, 540, 540, 270, 540, 34560, 34560, 34560, 540, 34560, 34560, 270, 270, 34560, 540, 34560, 270, 540, 34560, 270, 34560, 540, 270, 34560, 270, 270, 34560, 270, 270, 540]
Prompts retrieved: 1131840 . Total input tokens: 252483530 . Total output tokens: 226461631
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.478502692189068,
    "estimated_duration": 3600.139577020969,
    "input_throughput": 6975.9975863996115,
    "output_throughput": 6187.302887415317,
    "total_throughput": 13163.300473814928,
    "itl": 139.51635308043316,
    "ttft": 1765443.0414727696,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3131949286907911,
    "arrivals": 377686,
    "finished_requests": 101462,
    "scheduler_time": 63.239138434609764
}
#Debug simulation 
Total elapsed time: 7.478615229949355. Arrivals time: 0.3108716392889619 Scheduler time: 7.043556243181229 Scheduler overhead time: 0.04003766505047679 Adapter cache time: 0.023475049063563347 Engine time: 0.041749595664441586 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-32/adapters_96_slots_96_rate_3.2-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-32/adapters_96_slots_96_rate_3.2-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 34560, 540, 540, 540, 540, 34560, 540, 34560, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 34560, 34560, 540, 270, 34560, 540, 270, 270, 540, 34560, 270, 540, 270, 270, 540, 540, 540, 270, 270, 34560, 540, 540, 270, 34560, 34560, 540, 34560, 34560, 540, 34560, 270, 34560, 540, 540, 540, 34560, 34560, 270, 270, 540, 270, 34560, 270, 270, 34560, 270, 540, 540, 270, 540, 34560, 34560, 34560, 540, 34560, 34560, 270, 270, 34560, 540, 34560, 270, 540, 34560, 270, 34560, 540, 270, 34560, 270, 270, 34560, 270, 270, 540]
Prompts retrieved: 1131840 . Total input tokens: 252483530 . Total output tokens: 226461631
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.723919367417693,
    "estimated_duration": 3600.0634329574746,
    "input_throughput": 6969.467196134368,
    "output_throughput": 6182.986054141267,
    "total_throughput": 13152.453250275636,
    "itl": 137.63805386888558,
    "ttft": 1765801.2672966416,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31376164913177523,
    "arrivals": 377686,
    "finished_requests": 101361,
    "scheduler_time": 62.75133218449314
}
#Debug simulation 
Total elapsed time: 7.72401826037094. Arrivals time: 0.5664595388807356 Scheduler time: 7.031822699587792 Scheduler overhead time: 0.040715280920267105 Adapter cache time: 0.024002112448215485 Engine time: 0.041899222414940596 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-16-16/adapters_96_slots_96_rate_3.2-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-16-16/adapters_96_slots_96_rate_3.2-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 34560, 540, 540, 540, 540, 34560, 540, 34560, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 34560, 34560, 540, 270, 34560, 540, 270, 270, 540, 34560, 270, 540, 270, 270, 540, 540, 540, 270, 270, 34560, 540, 540, 270, 34560, 34560, 540, 34560, 34560, 540, 34560, 270, 34560, 540, 540, 540, 34560, 34560, 270, 270, 540, 270, 34560, 270, 270, 34560, 270, 540, 540, 270, 540, 34560, 34560, 34560, 540, 34560, 34560, 270, 270, 34560, 540, 34560, 270, 540, 34560, 270, 34560, 540, 270, 34560, 270, 270, 34560, 270, 270, 540]
Prompts retrieved: 1131840 . Total input tokens: 252483530 . Total output tokens: 226461631
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 7.466375415679067,
    "estimated_duration": 3600.1365225476166,
    "input_throughput": 6975.829067234446,
    "output_throughput": 6187.216473734542,
    "total_throughput": 13163.045540968988,
    "itl": 139.51734886285527,
    "ttft": 1765440.9761158794,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.30011987850070015,
    "arrivals": 377686,
    "finished_requests": 101461,
    "scheduler_time": 63.238540195320496
}
#Debug simulation 
Total elapsed time: 7.466471591964364. Arrivals time: 0.3401458924636245 Scheduler time: 7.001995715778321 Scheduler overhead time: 0.04030377930030227 Adapter cache time: 0.02333823312073946 Engine time: 0.041739281732589006 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-16-32/adapters_96_slots_96_rate_3.2-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-16-32/adapters_96_slots_96_rate_3.2-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 34560, 540, 540, 540, 540, 34560, 540, 34560, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 34560, 34560, 540, 270, 34560, 540, 270, 270, 540, 34560, 270, 540, 270, 270, 540, 540, 540, 270, 270, 34560, 540, 540, 270, 34560, 34560, 540, 34560, 34560, 540, 34560, 270, 34560, 540, 540, 540, 34560, 34560, 270, 270, 540, 270, 34560, 270, 270, 34560, 270, 540, 540, 270, 540, 34560, 34560, 34560, 540, 34560, 34560, 270, 270, 34560, 540, 34560, 270, 540, 34560, 270, 34560, 540, 270, 34560, 270, 270, 34560, 270, 270, 540]
Prompts retrieved: 1131840 . Total input tokens: 252483530 . Total output tokens: 226461631
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 7.441140248905867,
    "estimated_duration": 3600.093740684525,
    "input_throughput": 6969.408523020644,
    "output_throughput": 6182.934002092853,
    "total_throughput": 13152.342525113496,
    "itl": 137.6388272175896,
    "ttft": 1765821.0673036263,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31778577029705046,
    "arrivals": 377686,
    "finished_requests": 101361,
    "scheduler_time": 62.7511944443401
}
#Debug simulation 
Total elapsed time: 7.4412616598419845. Arrivals time: 0.3029765645042062 Scheduler time: 7.012801131233573 Scheduler overhead time: 0.04051440907642245 Adapter cache time: 0.023741990327835083 Engine time: 0.04210478160530329 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_16-16-16/adapters_96_slots_96_rate_3.2-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_16-16-16/adapters_96_slots_96_rate_3.2-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 34560, 540, 540, 540, 540, 34560, 540, 34560, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 34560, 34560, 540, 270, 34560, 540, 270, 270, 540, 34560, 270, 540, 270, 270, 540, 540, 540, 270, 270, 34560, 540, 540, 270, 34560, 34560, 540, 34560, 34560, 540, 34560, 270, 34560, 540, 540, 540, 34560, 34560, 270, 270, 540, 270, 34560, 270, 270, 34560, 270, 540, 540, 270, 540, 34560, 34560, 34560, 540, 34560, 34560, 270, 270, 34560, 540, 34560, 270, 540, 34560, 270, 34560, 540, 270, 34560, 270, 270, 34560, 270, 270, 540]
Prompts retrieved: 1131840 . Total input tokens: 252483530 . Total output tokens: 226461631
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.453864347655326,
    "estimated_duration": 3600.114597217784,
    "input_throughput": 6975.8715512579465,
    "output_throughput": 6187.254154968921,
    "total_throughput": 13163.125706226867,
    "itl": 139.51716400622158,
    "ttft": 1765432.049362175,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2870448283106092,
    "arrivals": 377686,
    "finished_requests": 101461,
    "scheduler_time": 63.238348005844855
}
#Debug simulation 
Total elapsed time: 7.453962180763483. Arrivals time: 0.3392931646667421 Scheduler time: 6.990445260889828 Scheduler overhead time: 0.04002669081091881 Adapter cache time: 0.02355257561430335 Engine time: 0.04184767557308078 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_16-16-32/adapters_96_slots_96_rate_3.2-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_16-16-32/adapters_96_slots_96_rate_3.2-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 34560, 540, 540, 540, 540, 34560, 540, 34560, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 34560, 34560, 540, 270, 34560, 540, 270, 270, 540, 34560, 270, 540, 270, 270, 540, 540, 540, 270, 270, 34560, 540, 540, 270, 34560, 34560, 540, 34560, 34560, 540, 34560, 270, 34560, 540, 540, 540, 34560, 34560, 270, 270, 540, 270, 34560, 270, 270, 34560, 270, 540, 540, 270, 540, 34560, 34560, 34560, 540, 34560, 34560, 270, 270, 34560, 540, 34560, 270, 540, 34560, 270, 34560, 540, 270, 34560, 270, 270, 34560, 270, 270, 540]
Prompts retrieved: 1131840 . Total input tokens: 252483530 . Total output tokens: 226461631
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.4697006163187325,
    "estimated_duration": 3600.0965249462593,
    "input_throughput": 6969.403132982536,
    "output_throughput": 6182.929220302579,
    "total_throughput": 13152.332353285115,
    "itl": 137.63842072330084,
    "ttft": 1765823.5173686007,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.32180989146232564,
    "arrivals": 377686,
    "finished_requests": 101361,
    "scheduler_time": 62.751124623115956
}
#Debug simulation 
Total elapsed time: 7.469799239188433. Arrivals time: 0.34120357036590576 Scheduler time: 7.002793030347675 Scheduler overhead time: 0.04045724403113127 Adapter cache time: 0.02393549494445324 Engine time: 0.04215164389461279 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-8/adapters_96_slots_96_rate_3.2-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-8/adapters_96_slots_96_rate_3.2-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 34560, 540, 540, 540, 540, 34560, 540, 34560, 540, 135, 34560, 135, 135, 34560, 540, 34560, 540, 34560, 34560, 540, 135, 34560, 540, 135, 135, 540, 34560, 135, 540, 135, 135, 540, 540, 540, 135, 135, 34560, 540, 540, 135, 34560, 34560, 540, 34560, 34560, 540, 34560, 135, 34560, 540, 540, 540, 34560, 34560, 135, 135, 540, 135, 34560, 135, 135, 34560, 135, 540, 540, 135, 540, 34560, 34560, 34560, 540, 34560, 34560, 135, 135, 34560, 540, 34560, 135, 540, 34560, 135, 34560, 540, 135, 34560, 135, 135, 34560, 135, 135, 540]
Prompts retrieved: 1127520 . Total input tokens: 251517207 . Total output tokens: 225582276
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.558703862596303,
    "estimated_duration": 3600.131599066067,
    "input_throughput": 7128.232758673958,
    "output_throughput": 6315.087205672668,
    "total_throughput": 13443.319964346627,
    "itl": 136.6964192789608,
    "ttft": 1747061.5486691904,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29380682341754405,
    "arrivals": 376204,
    "finished_requests": 103827,
    "scheduler_time": 64.45784995960304
}
#Debug simulation 
Total elapsed time: 7.558827179018408. Arrivals time: 0.311872776132077 Scheduler time: 7.122865370474756 Scheduler overhead time: 0.04081480950117111 Adapter cache time: 0.021764511242508888 Engine time: 0.0422178041189909 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-16/adapters_96_slots_96_rate_3.2-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-16/adapters_96_slots_96_rate_3.2-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 34560, 540, 540, 540, 540, 34560, 540, 34560, 540, 135, 34560, 135, 135, 34560, 540, 34560, 540, 34560, 34560, 540, 135, 34560, 540, 135, 135, 540, 34560, 135, 540, 135, 135, 540, 540, 540, 135, 135, 34560, 540, 540, 135, 34560, 34560, 540, 34560, 34560, 540, 34560, 135, 34560, 540, 540, 540, 34560, 34560, 135, 135, 540, 135, 34560, 135, 135, 34560, 135, 540, 540, 135, 540, 34560, 34560, 34560, 540, 34560, 34560, 135, 135, 34560, 540, 34560, 135, 540, 34560, 135, 34560, 540, 135, 34560, 135, 135, 34560, 135, 135, 540]
Prompts retrieved: 1127520 . Total input tokens: 251517207 . Total output tokens: 225582276
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.578915927093476,
    "estimated_duration": 3600.053257698728,
    "input_throughput": 7128.299823098772,
    "output_throughput": 6315.059076246185,
    "total_throughput": 13443.358899344958,
    "itl": 136.6976240131911,
    "ttft": 1747048.8588459815,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3131949286907911,
    "arrivals": 376204,
    "finished_requests": 103825,
    "scheduler_time": 64.45602264040465
}
#Debug simulation 
Total elapsed time: 7.579017074778676. Arrivals time: 0.339422982186079 Scheduler time: 7.115591438021511 Scheduler overhead time: 0.04086754797026515 Adapter cache time: 0.021587555296719074 Engine time: 0.04228597739711404 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-32/adapters_96_slots_96_rate_3.2-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-32/adapters_96_slots_96_rate_3.2-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 34560, 540, 540, 540, 540, 34560, 540, 34560, 540, 135, 34560, 135, 135, 34560, 540, 34560, 540, 34560, 34560, 540, 135, 34560, 540, 135, 135, 540, 34560, 135, 540, 135, 135, 540, 540, 540, 135, 135, 34560, 540, 540, 135, 34560, 34560, 540, 34560, 34560, 540, 34560, 135, 34560, 540, 540, 540, 34560, 34560, 135, 135, 540, 135, 34560, 135, 135, 34560, 135, 540, 540, 135, 540, 34560, 34560, 34560, 540, 34560, 34560, 135, 135, 34560, 540, 34560, 135, 540, 34560, 135, 34560, 540, 135, 34560, 135, 135, 34560, 135, 135, 540]
Prompts retrieved: 1127520 . Total input tokens: 251517207 . Total output tokens: 225582276
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.614718387834728,
    "estimated_duration": 3600.1044105280826,
    "input_throughput": 7119.904613055403,
    "output_throughput": 6307.067354379688,
    "total_throughput": 13426.971967435093,
    "itl": 135.08180144004572,
    "ttft": 1748083.1926741588,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31376164913177523,
    "arrivals": 376204,
    "finished_requests": 103694,
    "scheduler_time": 63.99484779573158
}
#Debug simulation 
Total elapsed time: 7.6148299891501665. Arrivals time: 0.3514435435645282 Scheduler time: 7.137869276572019 Scheduler overhead time: 0.04120731679722667 Adapter cache time: 0.021787389181554317 Engine time: 0.04286029934883118 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-16/adapters_96_slots_96_rate_3.2-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-16/adapters_96_slots_96_rate_3.2-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 34560, 540, 540, 540, 540, 34560, 540, 34560, 540, 135, 34560, 135, 135, 34560, 540, 34560, 540, 34560, 34560, 540, 135, 34560, 540, 135, 135, 540, 34560, 135, 540, 135, 135, 540, 540, 540, 135, 135, 34560, 540, 540, 135, 34560, 34560, 540, 34560, 34560, 540, 34560, 135, 34560, 540, 540, 540, 34560, 34560, 135, 135, 540, 135, 34560, 135, 135, 34560, 135, 540, 540, 135, 540, 34560, 34560, 34560, 540, 34560, 34560, 135, 135, 34560, 540, 34560, 135, 540, 34560, 135, 34560, 540, 135, 34560, 135, 135, 34560, 135, 135, 540]
Prompts retrieved: 1127520 . Total input tokens: 251517207 . Total output tokens: 225582276
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 7.604966545943171,
    "estimated_duration": 3600.040024724049,
    "input_throughput": 7128.326025199419,
    "output_throughput": 6315.082289048342,
    "total_throughput": 13443.408314247761,
    "itl": 136.6981345193136,
    "ttft": 1747034.799230766,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.30011987850070015,
    "arrivals": 376204,
    "finished_requests": 103825,
    "scheduler_time": 64.45562245622637
}
#Debug simulation 
Total elapsed time: 7.605090499855578. Arrivals time: 0.3469590647146106 Scheduler time: 7.133519487455487 Scheduler overhead time: 0.04112558299675584 Adapter cache time: 0.021620016545057297 Engine time: 0.04252188699319959 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-32/adapters_96_slots_96_rate_3.2-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-32/adapters_96_slots_96_rate_3.2-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 34560, 540, 540, 540, 540, 34560, 540, 34560, 540, 135, 34560, 135, 135, 34560, 540, 34560, 540, 34560, 34560, 540, 135, 34560, 540, 135, 135, 540, 34560, 135, 540, 135, 135, 540, 540, 540, 135, 135, 34560, 540, 540, 135, 34560, 34560, 540, 34560, 34560, 540, 34560, 135, 34560, 540, 540, 540, 34560, 34560, 135, 135, 540, 135, 34560, 135, 135, 34560, 135, 540, 540, 135, 540, 34560, 34560, 34560, 540, 34560, 34560, 135, 135, 34560, 540, 34560, 135, 540, 34560, 135, 34560, 540, 135, 34560, 135, 135, 34560, 135, 135, 540]
Prompts retrieved: 1127520 . Total input tokens: 251517207 . Total output tokens: 225582276
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 7.610590436961502,
    "estimated_duration": 3600.1093369425816,
    "input_throughput": 7119.894870128722,
    "output_throughput": 6307.058723745128,
    "total_throughput": 13426.95359387385,
    "itl": 135.08191329973013,
    "ttft": 1748086.949838143,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31778577029705046,
    "arrivals": 376204,
    "finished_requests": 103694,
    "scheduler_time": 63.994813458750336
}
#Debug simulation 
Total elapsed time: 7.610691049601883. Arrivals time: 0.3443353585898876 Scheduler time: 7.1404725085012615 Scheduler overhead time: 0.04140058998018503 Adapter cache time: 0.02202039770781994 Engine time: 0.0429623075760901 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-16/adapters_96_slots_96_rate_3.2-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-16/adapters_96_slots_96_rate_3.2-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 34560, 540, 540, 540, 540, 34560, 540, 34560, 540, 135, 34560, 135, 135, 34560, 540, 34560, 540, 34560, 34560, 540, 135, 34560, 540, 135, 135, 540, 34560, 135, 540, 135, 135, 540, 540, 540, 135, 135, 34560, 540, 540, 135, 34560, 34560, 540, 34560, 34560, 540, 34560, 135, 34560, 540, 540, 540, 34560, 34560, 135, 135, 540, 135, 34560, 135, 135, 34560, 135, 540, 540, 135, 540, 34560, 34560, 34560, 540, 34560, 34560, 135, 135, 34560, 540, 34560, 135, 540, 34560, 135, 34560, 540, 135, 34560, 135, 135, 34560, 135, 135, 540]
Prompts retrieved: 1127520 . Total input tokens: 251517207 . Total output tokens: 225582276
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.606758143752813,
    "estimated_duration": 3600.1295160335017,
    "input_throughput": 7128.236883064735,
    "output_throughput": 6315.090859577963,
    "total_throughput": 13443.327742642698,
    "itl": 136.69696822725305,
    "ttft": 1747058.9999384955,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2870448283106092,
    "arrivals": 376204,
    "finished_requests": 103827,
    "scheduler_time": 64.45774049811189
}
#Debug simulation 
Total elapsed time: 7.606880140025169. Arrivals time: 0.3518165936693549 Scheduler time: 7.130621350836009 Scheduler overhead time: 0.04095606319606304 Adapter cache time: 0.02171236416324973 Engine time: 0.04255468025803566 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-32/adapters_96_slots_96_rate_3.2-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-32/adapters_96_slots_96_rate_3.2-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 34560, 540, 540, 540, 540, 34560, 540, 34560, 540, 135, 34560, 135, 135, 34560, 540, 34560, 540, 34560, 34560, 540, 135, 34560, 540, 135, 135, 540, 34560, 135, 540, 135, 135, 540, 540, 540, 135, 135, 34560, 540, 540, 135, 34560, 34560, 540, 34560, 34560, 540, 34560, 135, 34560, 540, 540, 540, 34560, 34560, 135, 135, 540, 135, 34560, 135, 135, 34560, 135, 540, 540, 135, 540, 34560, 34560, 34560, 540, 34560, 34560, 135, 135, 34560, 540, 34560, 135, 540, 34560, 135, 34560, 540, 135, 34560, 135, 135, 34560, 135, 135, 540]
Prompts retrieved: 1127520 . Total input tokens: 251517207 . Total output tokens: 225582276
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.581854223739356,
    "estimated_duration": 3600.113535244717,
    "input_throughput": 7119.88656720451,
    "output_throughput": 6307.051368716503,
    "total_throughput": 13426.937935921012,
    "itl": 135.0817209896223,
    "ttft": 1748090.164554529,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3218098914623257,
    "arrivals": 376204,
    "finished_requests": 103694,
    "scheduler_time": 63.994749242135924
}
#Debug simulation 
Total elapsed time: 7.581946161109954. Arrivals time: 0.3404264794662595 Scheduler time: 7.115909064654261 Scheduler overhead time: 0.04120959108695388 Adapter cache time: 0.021879136096686125 Engine time: 0.043037848081439734 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-8/adapters_96_slots_96_rate_3.2-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-8/adapters_96_slots_96_rate_3.2-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 34560, 540, 540, 540, 540, 34560, 540, 34560, 540, 66, 34560, 66, 66, 34560, 540, 34560, 540, 34560, 34560, 540, 66, 34560, 540, 66, 66, 540, 34560, 66, 540, 66, 66, 540, 540, 540, 66, 66, 34560, 540, 540, 66, 34560, 34560, 540, 34560, 34560, 540, 34560, 66, 34560, 540, 540, 540, 34560, 34560, 66, 66, 540, 66, 34560, 66, 66, 34560, 66, 540, 540, 66, 540, 34560, 34560, 34560, 540, 34560, 34560, 66, 66, 34560, 540, 34560, 66, 540, 34560, 66, 34560, 540, 66, 34560, 66, 66, 34560, 66, 66, 540]
Prompts retrieved: 1125312 . Total input tokens: 251029423 . Total output tokens: 225137120
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.910949071869254,
    "estimated_duration": 3600.041712882543,
    "input_throughput": 7199.614078706551,
    "output_throughput": 6376.62500349728,
    "total_throughput": 13576.23908220383,
    "itl": 135.3270222049463,
    "ttft": 1738553.8818842429,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29380682341754405,
    "arrivals": 375496,
    "finished_requests": 104642,
    "scheduler_time": 65.06353814412309
}
#Debug simulation 
Total elapsed time: 7.911056667100638. Arrivals time: 0.3484432087279856 Scheduler time: 7.439482165966183 Scheduler overhead time: 0.041409655939787626 Adapter cache time: 0.019697351846843958 Engine time: 0.04273471934720874 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-16/adapters_96_slots_96_rate_3.2-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-16/adapters_96_slots_96_rate_3.2-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 34560, 540, 540, 540, 540, 34560, 540, 34560, 540, 66, 34560, 66, 66, 34560, 540, 34560, 540, 34560, 34560, 540, 66, 34560, 540, 66, 66, 540, 34560, 66, 540, 66, 66, 540, 540, 540, 66, 66, 34560, 540, 540, 66, 34560, 34560, 540, 34560, 34560, 540, 34560, 66, 34560, 540, 540, 540, 34560, 34560, 66, 66, 540, 66, 34560, 66, 66, 34560, 66, 540, 540, 66, 540, 34560, 34560, 34560, 540, 34560, 34560, 66, 66, 34560, 540, 34560, 66, 540, 34560, 66, 34560, 540, 66, 34560, 66, 66, 34560, 66, 66, 540]
Prompts retrieved: 1125312 . Total input tokens: 251029423 . Total output tokens: 225137120
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.675337202847004,
    "estimated_duration": 3600.134819470285,
    "input_throughput": 7199.427882485146,
    "output_throughput": 6376.460091396718,
    "total_throughput": 13575.887973881865,
    "itl": 135.32813860593046,
    "ttft": 1738569.7846366395,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3131949286907911,
    "arrivals": 375496,
    "finished_requests": 104642,
    "scheduler_time": 65.06497691008767
}
#Debug simulation 
Total elapsed time: 7.6754371309652925. Arrivals time: 0.31848358316347003 Scheduler time: 7.232595711946487 Scheduler overhead time: 0.041520089376717806 Adapter cache time: 0.019945815671235323 Engine time: 0.043332149274647236 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-32/adapters_96_slots_96_rate_3.2-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-32/adapters_96_slots_96_rate_3.2-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 34560, 540, 540, 540, 540, 34560, 540, 34560, 540, 66, 34560, 66, 66, 34560, 540, 34560, 540, 34560, 34560, 540, 66, 34560, 540, 66, 66, 540, 34560, 66, 540, 66, 66, 540, 540, 540, 66, 66, 34560, 540, 540, 66, 34560, 34560, 540, 34560, 34560, 540, 34560, 66, 34560, 540, 540, 540, 34560, 34560, 66, 66, 540, 66, 34560, 66, 66, 34560, 66, 540, 540, 66, 540, 34560, 34560, 34560, 540, 34560, 34560, 66, 66, 34560, 540, 34560, 66, 540, 34560, 66, 34560, 540, 66, 34560, 66, 66, 34560, 66, 66, 540]
Prompts retrieved: 1125312 . Total input tokens: 251029423 . Total output tokens: 225137120
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.66497913794592,
    "estimated_duration": 3600.0583955365178,
    "input_throughput": 7188.8106126520415,
    "output_throughput": 6364.945087671305,
    "total_throughput": 13553.755700323347,
    "itl": 133.6416841170227,
    "ttft": 1739401.2413037147,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31376164913177523,
    "arrivals": 375496,
    "finished_requests": 104460,
    "scheduler_time": 64.56367196998201
}
#Debug simulation 
Total elapsed time: 7.6650793668814. Arrivals time: 0.3150073103606701 Scheduler time: 7.225003539584577 Scheduler overhead time: 0.04176229005679488 Adapter cache time: 0.019916653633117676 Engine time: 0.04370685387402773 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-16/adapters_96_slots_96_rate_3.2-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-16/adapters_96_slots_96_rate_3.2-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 34560, 540, 540, 540, 540, 34560, 540, 34560, 540, 66, 34560, 66, 66, 34560, 540, 34560, 540, 34560, 34560, 540, 66, 34560, 540, 66, 66, 540, 34560, 66, 540, 66, 66, 540, 540, 540, 66, 66, 34560, 540, 540, 66, 34560, 34560, 540, 34560, 34560, 540, 34560, 66, 34560, 540, 540, 540, 34560, 34560, 66, 66, 540, 66, 34560, 66, 66, 34560, 66, 540, 540, 66, 540, 34560, 34560, 34560, 540, 34560, 34560, 66, 66, 34560, 540, 34560, 66, 540, 34560, 66, 34560, 540, 66, 34560, 66, 66, 34560, 66, 66, 540]
Prompts retrieved: 1125312 . Total input tokens: 251029423 . Total output tokens: 225137120
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 7.650459113996476,
    "estimated_duration": 3600.0447226696565,
    "input_throughput": 7199.608059529749,
    "output_throughput": 6376.619672373574,
    "total_throughput": 13576.227731903324,
    "itl": 135.32686807854185,
    "ttft": 1738555.9730457608,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.30011987850070015,
    "arrivals": 375496,
    "finished_requests": 104642,
    "scheduler_time": 65.0635705786648
}
#Debug simulation 
Total elapsed time: 7.6505562867969275. Arrivals time: 0.34867076901718974 Scheduler time: 7.178300043102354 Scheduler overhead time: 0.04136647377163172 Adapter cache time: 0.019682896323502064 Engine time: 0.04319659899920225 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-32/adapters_96_slots_96_rate_3.2-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-32/adapters_96_slots_96_rate_3.2-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 34560, 540, 540, 540, 540, 34560, 540, 34560, 540, 66, 34560, 66, 66, 34560, 540, 34560, 540, 34560, 34560, 540, 66, 34560, 540, 66, 66, 540, 34560, 66, 540, 66, 66, 540, 540, 540, 66, 66, 34560, 540, 540, 66, 34560, 34560, 540, 34560, 34560, 540, 34560, 66, 34560, 540, 540, 540, 34560, 34560, 66, 66, 540, 66, 34560, 66, 66, 34560, 66, 540, 540, 66, 540, 34560, 34560, 34560, 540, 34560, 34560, 66, 66, 34560, 540, 34560, 66, 540, 34560, 66, 34560, 540, 66, 34560, 66, 66, 34560, 66, 66, 540]
Prompts retrieved: 1125312 . Total input tokens: 251029423 . Total output tokens: 225137120
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 7.666833562310785,
    "estimated_duration": 3600.0624360547263,
    "input_throughput": 7188.802544314146,
    "output_throughput": 6364.937943996167,
    "total_throughput": 13553.740488310314,
    "itl": 133.64171427767135,
    "ttft": 1739404.1804079753,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3177857702970504,
    "arrivals": 375496,
    "finished_requests": 104460,
    "scheduler_time": 64.5636471274729
}
#Debug simulation 
Total elapsed time: 7.666929730214179. Arrivals time: 0.3488269178196788 Scheduler time: 7.192949174437672 Scheduler overhead time: 0.04186015669256449 Adapter cache time: 0.020201916340738535 Engine time: 0.04340636497363448 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-16/adapters_96_slots_96_rate_3.2-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-16/adapters_96_slots_96_rate_3.2-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 34560, 540, 540, 540, 540, 34560, 540, 34560, 540, 66, 34560, 66, 66, 34560, 540, 34560, 540, 34560, 34560, 540, 66, 34560, 540, 66, 66, 540, 34560, 66, 540, 66, 66, 540, 540, 540, 66, 66, 34560, 540, 540, 66, 34560, 34560, 540, 34560, 34560, 540, 34560, 66, 34560, 540, 540, 540, 34560, 34560, 66, 66, 540, 66, 34560, 66, 66, 34560, 66, 540, 540, 66, 540, 34560, 34560, 34560, 540, 34560, 34560, 66, 66, 34560, 540, 34560, 66, 540, 34560, 66, 34560, 540, 66, 34560, 66, 66, 34560, 66, 66, 540]
Prompts retrieved: 1125312 . Total input tokens: 251029423 . Total output tokens: 225137120
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.973765914794058,
    "estimated_duration": 3600.030918137602,
    "input_throughput": 7199.635666853825,
    "output_throughput": 6376.644123899872,
    "total_throughput": 13576.279790753697,
    "itl": 135.3269594539649,
    "ttft": 1738548.0328047369,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2870448283106092,
    "arrivals": 375496,
    "finished_requests": 104642,
    "scheduler_time": 65.06354677814602
}
#Debug simulation 
Total elapsed time: 7.973859944846481. Arrivals time: 0.6196018857881427 Scheduler time: 7.230317949317396 Scheduler overhead time: 0.04171802708879113 Adapter cache time: 0.019779257476329803 Engine time: 0.042952468153089285 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-32/adapters_96_slots_96_rate_3.2-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-32/adapters_96_slots_96_rate_3.2-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 34560, 540, 540, 540, 540, 34560, 540, 34560, 540, 66, 34560, 66, 66, 34560, 540, 34560, 540, 34560, 34560, 540, 66, 34560, 540, 66, 66, 540, 34560, 66, 540, 66, 66, 540, 540, 540, 66, 66, 34560, 540, 540, 66, 34560, 34560, 540, 34560, 34560, 540, 34560, 66, 34560, 540, 540, 540, 34560, 34560, 66, 66, 540, 66, 34560, 66, 66, 34560, 66, 540, 540, 66, 540, 34560, 34560, 34560, 540, 34560, 34560, 66, 66, 34560, 540, 34560, 66, 540, 34560, 66, 34560, 540, 66, 34560, 66, 66, 34560, 66, 66, 540]
Prompts retrieved: 1125312 . Total input tokens: 251029423 . Total output tokens: 225137120
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.661363798193634,
    "estimated_duration": 3600.0691361809636,
    "input_throughput": 7188.789165158713,
    "output_throughput": 6364.926098143738,
    "total_throughput": 13553.715263302453,
    "itl": 133.64178651179154,
    "ttft": 1739409.3005388107,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.32180989146232564,
    "arrivals": 375496,
    "finished_requests": 104460,
    "scheduler_time": 64.56359178206762
}
#Debug simulation 
Total elapsed time: 7.661486120894551. Arrivals time: 0.34712044801563025 Scheduler time: 7.189111853018403 Scheduler overhead time: 0.041747952345758677 Adapter cache time: 0.020422135014086962 Engine time: 0.04334365529939532 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-8/adapters_96_slots_96_rate_3.2-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-8/adapters_96_slots_96_rate_3.2-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 34560, 540, 540, 540, 540, 34560, 540, 34560, 540, 33, 34560, 33, 33, 34560, 540, 34560, 540, 34560, 34560, 540, 33, 34560, 540, 33, 33, 540, 34560, 33, 540, 33, 33, 540, 540, 540, 33, 33, 34560, 540, 540, 33, 34560, 34560, 540, 34560, 34560, 540, 34560, 33, 34560, 540, 540, 540, 34560, 34560, 33, 33, 540, 33, 34560, 33, 33, 34560, 33, 540, 540, 33, 540, 34560, 34560, 34560, 540, 34560, 34560, 33, 33, 34560, 540, 34560, 33, 540, 34560, 33, 34560, 540, 33, 34560, 33, 33, 34560, 33, 33, 540]
Prompts retrieved: 1124256 . Total input tokens: 250788197 . Total output tokens: 224929428
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.699444585014135,
    "estimated_duration": 3600.0002350505997,
    "input_throughput": 7271.79841409984,
    "output_throughput": 6410.3556925672365,
    "total_throughput": 13682.154106667076,
    "itl": 134.13891573185217,
    "ttft": 1731727.6784543807,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29380682341754405,
    "arrivals": 375142,
    "finished_requests": 105556,
    "scheduler_time": 65.39339849403635
}
#Debug simulation 
Total elapsed time: 7.699543838389218. Arrivals time: 0.3143326798453927 Scheduler time: 7.262125299312174 Scheduler overhead time: 0.04159108875319362 Adapter cache time: 0.01890168897807598 Engine time: 0.04317299323156476 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-16/adapters_96_slots_96_rate_3.2-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-16/adapters_96_slots_96_rate_3.2-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 34560, 540, 540, 540, 540, 34560, 540, 34560, 540, 33, 34560, 33, 33, 34560, 540, 34560, 540, 34560, 34560, 540, 33, 34560, 540, 33, 33, 540, 34560, 33, 540, 33, 33, 540, 540, 540, 33, 33, 34560, 540, 540, 33, 34560, 34560, 540, 34560, 34560, 540, 34560, 33, 34560, 540, 540, 540, 34560, 34560, 33, 33, 540, 33, 34560, 33, 33, 34560, 33, 540, 540, 33, 540, 34560, 34560, 34560, 540, 34560, 34560, 33, 33, 34560, 540, 34560, 33, 540, 34560, 33, 34560, 540, 33, 34560, 33, 33, 34560, 33, 33, 540]
Prompts retrieved: 1124256 . Total input tokens: 250788197 . Total output tokens: 224929428
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.702933557331562,
    "estimated_duration": 3600.0304730640587,
    "input_throughput": 7271.806501604071,
    "output_throughput": 6410.386015526752,
    "total_throughput": 13682.192517130823,
    "itl": 134.13883603042308,
    "ttft": 1731734.8804856297,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31319492869079113,
    "arrivals": 375142,
    "finished_requests": 105557,
    "scheduler_time": 65.39386449561789
}
#Debug simulation 
Total elapsed time: 7.703055060934275. Arrivals time: 0.34712575236335397 Scheduler time: 7.2323408727534115 Scheduler overhead time: 0.0417022411711514 Adapter cache time: 0.019036841113120317 Engine time: 0.04328606138005853 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-32/adapters_96_slots_96_rate_3.2-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-32/adapters_96_slots_96_rate_3.2-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 34560, 540, 540, 540, 540, 34560, 540, 34560, 540, 33, 34560, 33, 33, 34560, 540, 34560, 540, 34560, 34560, 540, 33, 34560, 540, 33, 33, 540, 34560, 33, 540, 33, 33, 540, 540, 540, 33, 33, 34560, 540, 540, 33, 34560, 34560, 540, 34560, 34560, 540, 34560, 33, 34560, 540, 540, 540, 34560, 34560, 33, 33, 540, 33, 34560, 33, 33, 34560, 33, 540, 540, 33, 540, 34560, 34560, 34560, 540, 34560, 34560, 33, 33, 34560, 540, 34560, 33, 540, 34560, 33, 34560, 540, 33, 34560, 33, 33, 34560, 33, 33, 540]
Prompts retrieved: 1124256 . Total input tokens: 250788197 . Total output tokens: 224929428
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.705473340116441,
    "estimated_duration": 3600.074815078394,
    "input_throughput": 7261.781585900381,
    "output_throughput": 6402.0111202878215,
    "total_throughput": 13663.792706188202,
    "itl": 132.61093814625633,
    "ttft": 1732239.2243959862,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31376164913177523,
    "arrivals": 375142,
    "finished_requests": 105411,
    "scheduler_time": 64.93357138125829
}
#Debug simulation 
Total elapsed time: 7.705573078710586. Arrivals time: 0.36362002044916153 Scheduler time: 7.217312117572874 Scheduler overhead time: 0.042117788922041655 Adapter cache time: 0.019091191235929728 Engine time: 0.04371327580884099 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-16/adapters_96_slots_96_rate_3.2-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-16/adapters_96_slots_96_rate_3.2-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 34560, 540, 540, 540, 540, 34560, 540, 34560, 540, 33, 34560, 33, 33, 34560, 540, 34560, 540, 34560, 34560, 540, 33, 34560, 540, 33, 33, 540, 34560, 33, 540, 33, 33, 540, 540, 540, 33, 33, 34560, 540, 540, 33, 34560, 34560, 540, 34560, 34560, 540, 34560, 33, 34560, 540, 540, 540, 34560, 34560, 33, 33, 540, 33, 34560, 33, 33, 34560, 33, 540, 540, 33, 540, 34560, 34560, 34560, 540, 34560, 34560, 33, 33, 34560, 540, 34560, 33, 540, 34560, 33, 34560, 540, 33, 34560, 33, 33, 34560, 33, 33, 540]
Prompts retrieved: 1124256 . Total input tokens: 250788197 . Total output tokens: 224929428
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 7.70775376399979,
    "estimated_duration": 3600.0162389105712,
    "input_throughput": 7271.835253699341,
    "output_throughput": 6410.411361639771,
    "total_throughput": 13682.24661533911,
    "itl": 134.13885372488122,
    "ttft": 1731726.6418712717,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.30011987850070015,
    "arrivals": 375142,
    "finished_requests": 105557,
    "scheduler_time": 65.39385969574029
}
#Debug simulation 
Total elapsed time: 7.707854916807264. Arrivals time: 0.32358774775639176 Scheduler time: 7.260989392641932 Scheduler overhead time: 0.041739304549992085 Adapter cache time: 0.01892712013795972 Engine time: 0.04307527747005224 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-32/adapters_96_slots_96_rate_3.2-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-32/adapters_96_slots_96_rate_3.2-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 34560, 540, 540, 540, 540, 34560, 540, 34560, 540, 33, 34560, 33, 33, 34560, 540, 34560, 540, 34560, 34560, 540, 33, 34560, 540, 33, 33, 540, 34560, 33, 540, 33, 33, 540, 540, 540, 33, 33, 34560, 540, 540, 33, 34560, 34560, 540, 34560, 34560, 540, 34560, 33, 34560, 540, 540, 540, 34560, 34560, 33, 33, 540, 33, 34560, 33, 33, 34560, 33, 540, 540, 33, 540, 34560, 34560, 34560, 540, 34560, 34560, 33, 33, 34560, 540, 34560, 33, 540, 34560, 33, 34560, 540, 33, 34560, 33, 33, 34560, 33, 33, 540]
Prompts retrieved: 1124256 . Total input tokens: 250788197 . Total output tokens: 224929428
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 7.705424127168953,
    "estimated_duration": 3600.079143145809,
    "input_throughput": 7261.772855681125,
    "output_throughput": 6402.003423697102,
    "total_throughput": 13663.776279378228,
    "itl": 132.61102622498314,
    "ttft": 1732242.2526319523,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3177857702970504,
    "arrivals": 375142,
    "finished_requests": 105411,
    "scheduler_time": 64.9335523454787
}
#Debug simulation 
Total elapsed time: 7.705537477973849. Arrivals time: 0.347808547783643 Scheduler time: 7.232931803446263 Scheduler overhead time: 0.04202741803601384 Adapter cache time: 0.019042660016566515 Engine time: 0.043947604950517416 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-16/adapters_96_slots_96_rate_3.2-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-16/adapters_96_slots_96_rate_3.2-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 34560, 540, 540, 540, 540, 34560, 540, 34560, 540, 33, 34560, 33, 33, 34560, 540, 34560, 540, 34560, 34560, 540, 33, 34560, 540, 33, 33, 540, 34560, 33, 540, 33, 33, 540, 540, 540, 33, 33, 34560, 540, 540, 33, 34560, 34560, 540, 34560, 34560, 540, 34560, 33, 34560, 540, 540, 540, 34560, 34560, 33, 33, 540, 33, 34560, 33, 33, 34560, 33, 540, 540, 33, 540, 34560, 34560, 34560, 540, 34560, 34560, 33, 33, 34560, 540, 34560, 33, 540, 34560, 33, 34560, 540, 33, 34560, 33, 33, 34560, 33, 33, 540]
Prompts retrieved: 1124256 . Total input tokens: 250788197 . Total output tokens: 224929428
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.665656781755388,
    "estimated_duration": 3600.1050760387534,
    "input_throughput": 7271.655812003361,
    "output_throughput": 6410.253176663553,
    "total_throughput": 13681.908988666914,
    "itl": 134.13896037718752,
    "ttft": 1731752.173335647,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2870448283106092,
    "arrivals": 375142,
    "finished_requests": 105557,
    "scheduler_time": 65.39530286941454
}
#Debug simulation 
Total elapsed time: 7.665757862851024. Arrivals time: 0.34913492714986205 Scheduler time: 7.193375354167074 Scheduler overhead time: 0.04145336430519819 Adapter cache time: 0.019084140192717314 Engine time: 0.04321565851569176 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-32/adapters_96_slots_96_rate_3.2-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-32/adapters_96_slots_96_rate_3.2-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 34560, 540, 540, 540, 540, 34560, 540, 34560, 540, 33, 34560, 33, 33, 34560, 540, 34560, 540, 34560, 34560, 540, 33, 34560, 540, 33, 33, 540, 34560, 33, 540, 33, 33, 540, 540, 540, 33, 33, 34560, 540, 540, 33, 34560, 34560, 540, 34560, 34560, 540, 34560, 33, 34560, 540, 540, 540, 34560, 34560, 33, 33, 540, 33, 34560, 33, 33, 34560, 33, 540, 540, 33, 540, 34560, 34560, 34560, 540, 34560, 34560, 33, 33, 34560, 540, 34560, 33, 540, 34560, 33, 34560, 540, 33, 34560, 33, 33, 34560, 33, 33, 540]
Prompts retrieved: 1124256 . Total input tokens: 250788197 . Total output tokens: 224929428
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.7524282219819725,
    "estimated_duration": 3600.0644857906145,
    "input_throughput": 7261.802421369325,
    "output_throughput": 6402.029488907464,
    "total_throughput": 13663.83191027679,
    "itl": 132.61469798349972,
    "ttft": 1732233.8355532,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.32180989146232564,
    "arrivals": 375142,
    "finished_requests": 105411,
    "scheduler_time": 64.93477749851021
}
#Debug simulation 
Total elapsed time: 7.752540428657085. Arrivals time: 0.3717479556798935 Scheduler time: 7.256756863556802 Scheduler overhead time: 0.042138457763940096 Adapter cache time: 0.019021460320800543 Engine time: 0.0432172566652298 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-8/adapters_96_slots_96_rate_3.2-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-8/adapters_96_slots_96_rate_3.2-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 34560, 270, 270, 270, 270, 34560, 270, 34560, 270, 135, 34560, 135, 135, 34560, 270, 34560, 270, 34560, 34560, 270, 135, 34560, 270, 135, 135, 270, 34560, 135, 270, 135, 135, 270, 270, 270, 135, 135, 34560, 270, 270, 135, 34560, 34560, 270, 34560, 34560, 270, 34560, 135, 34560, 270, 270, 270, 34560, 34560, 135, 135, 270, 135, 34560, 135, 135, 34560, 135, 270, 270, 135, 270, 34560, 34560, 34560, 270, 34560, 34560, 135, 135, 34560, 270, 34560, 135, 270, 34560, 135, 34560, 270, 135, 34560, 135, 135, 34560, 135, 135, 270]
Prompts retrieved: 1118880 . Total input tokens: 249581898 . Total output tokens: 223853690
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.805988499894738,
    "estimated_duration": 3600.008964069245,
    "input_throughput": 7392.133537889749,
    "output_throughput": 6542.415098149453,
    "total_throughput": 13934.548636039202,
    "itl": 131.74102961319406,
    "ttft": 1720749.9802603005,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29380682341754405,
    "arrivals": 373254,
    "finished_requests": 107427,
    "scheduler_time": 66.75065145121401
}
#Debug simulation 
Total elapsed time: 7.806104249786586. Arrivals time: 0.3171724071726203 Scheduler time: 7.365015881601721 Scheduler overhead time: 0.04235461261123419 Adapter cache time: 0.01809836132451892 Engine time: 0.04359301133081317 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-16/adapters_96_slots_96_rate_3.2-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-16/adapters_96_slots_96_rate_3.2-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 34560, 270, 270, 270, 270, 34560, 270, 34560, 270, 135, 34560, 135, 135, 34560, 270, 34560, 270, 34560, 34560, 270, 135, 34560, 270, 135, 135, 270, 34560, 135, 270, 135, 135, 270, 270, 270, 135, 135, 34560, 270, 270, 135, 34560, 34560, 270, 34560, 34560, 270, 34560, 135, 34560, 270, 270, 270, 34560, 34560, 135, 135, 270, 135, 34560, 135, 135, 34560, 135, 270, 270, 135, 270, 34560, 34560, 34560, 270, 34560, 34560, 135, 135, 34560, 270, 34560, 135, 270, 34560, 135, 34560, 270, 135, 34560, 135, 135, 34560, 135, 135, 270]
Prompts retrieved: 1118880 . Total input tokens: 249581898 . Total output tokens: 223853690
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.792422684840858,
    "estimated_duration": 3600.0384556450663,
    "input_throughput": 7392.1074254834875,
    "output_throughput": 6542.36205812411,
    "total_throughput": 13934.469483607598,
    "itl": 131.740729044905,
    "ttft": 1720769.9577825554,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31319492869079113,
    "arrivals": 373254,
    "finished_requests": 107428,
    "scheduler_time": 66.75124943292167
}
#Debug simulation 
Total elapsed time: 7.792515752837062. Arrivals time: 0.3137205778621137 Scheduler time: 7.354904995299876 Scheduler overhead time: 0.04230167483910918 Adapter cache time: 0.01826604688540101 Engine time: 0.04354669479653239 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-32/adapters_96_slots_96_rate_3.2-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-32/adapters_96_slots_96_rate_3.2-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 34560, 270, 270, 270, 270, 34560, 270, 34560, 270, 135, 34560, 135, 135, 34560, 270, 34560, 270, 34560, 34560, 270, 135, 34560, 270, 135, 135, 270, 34560, 135, 270, 135, 135, 270, 270, 270, 135, 135, 34560, 270, 270, 135, 34560, 34560, 270, 34560, 34560, 270, 34560, 135, 34560, 270, 270, 270, 34560, 34560, 135, 135, 270, 135, 34560, 135, 135, 34560, 135, 270, 270, 135, 270, 34560, 34560, 34560, 270, 34560, 34560, 135, 135, 34560, 270, 34560, 135, 270, 34560, 135, 34560, 270, 135, 34560, 135, 135, 34560, 135, 135, 270]
Prompts retrieved: 1118880 . Total input tokens: 249581898 . Total output tokens: 223853690
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.8070205468684435,
    "estimated_duration": 3600.115289525426,
    "input_throughput": 7377.035973617653,
    "output_throughput": 6530.755020098072,
    "total_throughput": 13907.790993715726,
    "itl": 129.9473285002388,
    "ttft": 1722267.5865093013,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3137616491317753,
    "arrivals": 373254,
    "finished_requests": 107224,
    "scheduler_time": 66.17386259916087
}
#Debug simulation 
Total elapsed time: 7.807116868905723. Arrivals time: 0.33027557702735066 Scheduler time: 7.351655734702945 Scheduler overhead time: 0.042812532279640436 Adapter cache time: 0.01828180020675063 Engine time: 0.04411321971565485 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-16/adapters_96_slots_96_rate_3.2-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-16/adapters_96_slots_96_rate_3.2-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 34560, 270, 270, 270, 270, 34560, 270, 34560, 270, 135, 34560, 135, 135, 34560, 270, 34560, 270, 34560, 34560, 270, 135, 34560, 270, 135, 135, 270, 34560, 135, 270, 135, 135, 270, 270, 270, 135, 135, 34560, 270, 270, 135, 34560, 34560, 270, 34560, 34560, 270, 34560, 135, 34560, 270, 270, 270, 34560, 34560, 135, 135, 270, 135, 34560, 135, 135, 34560, 135, 270, 270, 135, 270, 34560, 34560, 34560, 270, 34560, 34560, 135, 135, 34560, 270, 34560, 135, 270, 34560, 135, 34560, 270, 135, 34560, 135, 135, 34560, 135, 135, 270]
Prompts retrieved: 1118880 . Total input tokens: 249581898 . Total output tokens: 223853690
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 7.786983533762395,
    "estimated_duration": 3600.020067561632,
    "input_throughput": 7392.110738433935,
    "output_throughput": 6542.3949194685365,
    "total_throughput": 13934.505657902471,
    "itl": 131.74139232537195,
    "ttft": 1720751.6934329001,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.30011987850070015,
    "arrivals": 373254,
    "finished_requests": 107427,
    "scheduler_time": 66.75065886762616
}
#Debug simulation 
Total elapsed time: 7.787082594819367. Arrivals time: 0.31070823408663273 Scheduler time: 7.353380739688873 Scheduler overhead time: 0.04202485457062721 Adapter cache time: 0.018095882143825293 Engine time: 0.043179708532989025 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-32/adapters_96_slots_96_rate_3.2-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-32/adapters_96_slots_96_rate_3.2-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 34560, 270, 270, 270, 270, 34560, 270, 34560, 270, 135, 34560, 135, 135, 34560, 270, 34560, 270, 34560, 34560, 270, 135, 34560, 270, 135, 135, 270, 34560, 135, 270, 135, 135, 270, 270, 270, 135, 135, 34560, 270, 270, 135, 34560, 34560, 270, 34560, 34560, 270, 34560, 135, 34560, 270, 270, 270, 34560, 34560, 135, 135, 270, 135, 34560, 135, 135, 34560, 135, 270, 270, 135, 270, 34560, 34560, 34560, 270, 34560, 34560, 135, 135, 34560, 270, 34560, 135, 270, 34560, 135, 34560, 270, 135, 34560, 135, 135, 34560, 135, 135, 270]
Prompts retrieved: 1118880 . Total input tokens: 249581898 . Total output tokens: 223853690
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 7.695710945874453,
    "estimated_duration": 3600.1300127048294,
    "input_throughput": 7377.005804311622,
    "output_throughput": 6530.728311763245,
    "total_throughput": 13907.734116074867,
    "itl": 129.9476161455132,
    "ttft": 1722278.240936571,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31778577029705046,
    "arrivals": 373254,
    "finished_requests": 107224,
    "scheduler_time": 66.17391590746917
}
#Debug simulation 
Total elapsed time: 7.695806717034429. Arrivals time: 0.2985156588256359 Scheduler time: 7.273386723361909 Scheduler overhead time: 0.042277376633137465 Adapter cache time: 0.017564720939844847 Engine time: 0.044216365553438663 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-16/adapters_96_slots_96_rate_3.2-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-16/adapters_96_slots_96_rate_3.2-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 34560, 270, 270, 270, 270, 34560, 270, 34560, 270, 135, 34560, 135, 135, 34560, 270, 34560, 270, 34560, 34560, 270, 135, 34560, 270, 135, 135, 270, 34560, 135, 270, 135, 135, 270, 270, 270, 135, 135, 34560, 270, 270, 135, 34560, 34560, 270, 34560, 34560, 270, 34560, 135, 34560, 270, 270, 270, 34560, 34560, 135, 135, 270, 135, 34560, 135, 135, 34560, 135, 270, 270, 135, 270, 34560, 34560, 34560, 270, 34560, 34560, 135, 135, 34560, 270, 34560, 135, 270, 34560, 135, 34560, 270, 135, 34560, 135, 135, 34560, 135, 135, 270]
Prompts retrieved: 1118880 . Total input tokens: 249581898 . Total output tokens: 223853690
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.742130527738482,
    "estimated_duration": 3600.143030524542,
    "input_throughput": 7392.301854218949,
    "output_throughput": 6542.286181493266,
    "total_throughput": 13934.588035712215,
    "itl": 131.74040161695277,
    "ttft": 1720759.8210527985,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2870448283106092,
    "arrivals": 373254,
    "finished_requests": 107434,
    "scheduler_time": 66.75321865987414
}
#Debug simulation 
Total elapsed time: 7.742224957793951. Arrivals time: 0.3038503718562424 Scheduler time: 7.315629167947918 Scheduler overhead time: 0.0420581940561533 Adapter cache time: 0.01743534440174699 Engine time: 0.04368723975494504 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-32/adapters_96_slots_96_rate_3.2-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-32/adapters_96_slots_96_rate_3.2-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 34560, 270, 270, 270, 270, 34560, 270, 34560, 270, 135, 34560, 135, 135, 34560, 270, 34560, 270, 34560, 34560, 270, 135, 34560, 270, 135, 135, 270, 34560, 135, 270, 135, 135, 270, 270, 270, 135, 135, 34560, 270, 270, 135, 34560, 34560, 270, 34560, 34560, 270, 34560, 135, 34560, 270, 270, 270, 34560, 34560, 135, 135, 270, 135, 34560, 135, 135, 34560, 135, 270, 270, 135, 270, 34560, 34560, 34560, 270, 34560, 34560, 135, 135, 34560, 270, 34560, 135, 270, 34560, 135, 34560, 270, 135, 34560, 135, 135, 34560, 135, 135, 270]
Prompts retrieved: 1118880 . Total input tokens: 249581898 . Total output tokens: 223853690
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.727528024930507,
    "estimated_duration": 3600.1390805324045,
    "input_throughput": 7376.987223524837,
    "output_throughput": 6530.711862532549,
    "total_throughput": 13907.699086057386,
    "itl": 129.94215037869412,
    "ttft": 1722285.4107101592,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.32180989146232575,
    "arrivals": 373254,
    "finished_requests": 107224,
    "scheduler_time": 66.17243380663535
}
#Debug simulation 
Total elapsed time: 7.727641248609871. Arrivals time: 0.30656586633995175 Scheduler time: 7.296845683362335 Scheduler overhead time: 0.04241751320660114 Adapter cache time: 0.017970850225538015 Engine time: 0.04390225559473038 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-8/adapters_96_slots_96_rate_3.2-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-8/adapters_96_slots_96_rate_3.2-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 34560, 270, 270, 270, 270, 34560, 270, 34560, 270, 66, 34560, 66, 66, 34560, 270, 34560, 270, 34560, 34560, 270, 66, 34560, 270, 66, 66, 270, 34560, 66, 270, 66, 66, 270, 270, 270, 66, 66, 34560, 270, 270, 66, 34560, 34560, 270, 34560, 34560, 270, 34560, 66, 34560, 270, 270, 270, 34560, 34560, 66, 66, 270, 66, 34560, 66, 66, 34560, 66, 270, 270, 66, 270, 34560, 34560, 34560, 270, 34560, 34560, 66, 66, 34560, 270, 34560, 66, 270, 34560, 66, 34560, 270, 66, 34560, 66, 66, 34560, 66, 66, 270]
Prompts retrieved: 1116672 . Total input tokens: 249089717 . Total output tokens: 223405188
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.840542782098055,
    "estimated_duration": 3600.0005327735666,
    "input_throughput": 7492.467224503198,
    "output_throughput": 6621.125131233208,
    "total_throughput": 14113.592355736406,
    "itl": 130.0829177900137,
    "ttft": 1710045.9211627077,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29380682341754405,
    "arrivals": 372568,
    "finished_requests": 108688,
    "scheduler_time": 67.54768838482634
}
#Debug simulation 
Total elapsed time: 7.8406629571691155. Arrivals time: 0.309297495521605 Scheduler time: 7.408640182111412 Scheduler overhead time: 0.042537274304777384 Adapter cache time: 0.015830892138183117 Engine time: 0.044401252176612616 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-16/adapters_96_slots_96_rate_3.2-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-16/adapters_96_slots_96_rate_3.2-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 34560, 270, 270, 270, 270, 34560, 270, 34560, 270, 66, 34560, 66, 66, 34560, 270, 34560, 270, 34560, 34560, 270, 66, 34560, 270, 66, 66, 270, 34560, 66, 270, 66, 66, 270, 270, 270, 66, 66, 34560, 270, 270, 66, 34560, 34560, 270, 34560, 34560, 270, 34560, 66, 34560, 270, 270, 270, 34560, 34560, 66, 66, 270, 66, 34560, 66, 66, 34560, 66, 270, 270, 66, 270, 34560, 34560, 34560, 270, 34560, 34560, 66, 66, 34560, 270, 34560, 66, 270, 34560, 66, 34560, 270, 66, 34560, 66, 66, 34560, 66, 66, 270]
Prompts retrieved: 1116672 . Total input tokens: 249089717 . Total output tokens: 223405188
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.82005371293053,
    "estimated_duration": 3600.0492972330508,
    "input_throughput": 7492.591287772537,
    "output_throughput": 6621.187664935725,
    "total_throughput": 14113.778952708262,
    "itl": 130.08349477915385,
    "ttft": 1710044.400639483,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3131949286907911,
    "arrivals": 372568,
    "finished_requests": 108691,
    "scheduler_time": 67.54785886955898
}
#Debug simulation 
Total elapsed time: 7.820176023989916. Arrivals time: 0.3090794621966779 Scheduler time: 7.388453255407512 Scheduler overhead time: 0.04254855401813984 Adapter cache time: 0.015999493654817343 Engine time: 0.04419416515156627 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-32/adapters_96_slots_96_rate_3.2-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-32/adapters_96_slots_96_rate_3.2-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 34560, 270, 270, 270, 270, 34560, 270, 34560, 270, 66, 34560, 66, 66, 34560, 270, 34560, 270, 34560, 34560, 270, 66, 34560, 270, 66, 66, 270, 34560, 66, 270, 66, 66, 270, 270, 270, 66, 66, 34560, 270, 270, 66, 34560, 34560, 270, 34560, 34560, 270, 34560, 66, 34560, 270, 270, 270, 34560, 34560, 66, 66, 270, 66, 34560, 66, 66, 34560, 66, 270, 270, 66, 270, 34560, 34560, 34560, 270, 34560, 34560, 66, 66, 34560, 270, 34560, 66, 270, 34560, 66, 34560, 270, 66, 34560, 66, 66, 34560, 66, 66, 270]
Prompts retrieved: 1116672 . Total input tokens: 249089717 . Total output tokens: 223405188
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.803779982030392,
    "estimated_duration": 3600.001227275178,
    "input_throughput": 7479.26189469098,
    "output_throughput": 6610.826912971173,
    "total_throughput": 14090.088807662154,
    "itl": 128.39248904294476,
    "ttft": 1711785.7250446521,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31376164913177523,
    "arrivals": 372568,
    "finished_requests": 108500,
    "scheduler_time": 66.97514309379577
}
#Debug simulation 
Total elapsed time: 7.803872934076935. Arrivals time: 0.30648287665098906 Scheduler time: 7.373696886468679 Scheduler overhead time: 0.04297030158340931 Adapter cache time: 0.015962970443069935 Engine time: 0.044672421645373106 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-16/adapters_96_slots_96_rate_3.2-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-16/adapters_96_slots_96_rate_3.2-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 34560, 270, 270, 270, 270, 34560, 270, 34560, 270, 66, 34560, 66, 66, 34560, 270, 34560, 270, 34560, 34560, 270, 66, 34560, 270, 66, 66, 270, 34560, 66, 270, 66, 66, 270, 270, 270, 66, 66, 34560, 270, 270, 66, 34560, 34560, 270, 34560, 34560, 270, 34560, 66, 34560, 270, 270, 270, 34560, 34560, 66, 66, 270, 66, 34560, 66, 66, 34560, 66, 270, 270, 66, 270, 34560, 34560, 34560, 270, 34560, 34560, 66, 66, 34560, 270, 34560, 66, 270, 34560, 66, 34560, 270, 66, 34560, 66, 66, 34560, 66, 66, 270]
Prompts retrieved: 1116672 . Total input tokens: 249089717 . Total output tokens: 223405188
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 7.834789266809821,
    "estimated_duration": 3600.00682993988,
    "input_throughput": 7492.454118608005,
    "output_throughput": 6621.113549497922,
    "total_throughput": 14113.567668105927,
    "itl": 130.08292366037804,
    "ttft": 1710050.804306089,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.30011987850070015,
    "arrivals": 372568,
    "finished_requests": 108688,
    "scheduler_time": 67.54762281910926
}
#Debug simulation 
Total elapsed time: 7.834884086623788. Arrivals time: 0.3246516897343099 Scheduler time: 7.387736843898892 Scheduler overhead time: 0.0424346667714417 Adapter cache time: 0.015981728676706553 Engine time: 0.04421920469030738 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-32/adapters_96_slots_96_rate_3.2-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-32/adapters_96_slots_96_rate_3.2-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 34560, 270, 270, 270, 270, 34560, 270, 34560, 270, 66, 34560, 66, 66, 34560, 270, 34560, 270, 34560, 34560, 270, 66, 34560, 270, 66, 66, 270, 34560, 66, 270, 66, 66, 270, 270, 270, 66, 66, 34560, 270, 270, 66, 34560, 34560, 270, 34560, 34560, 270, 34560, 66, 34560, 270, 270, 270, 34560, 34560, 66, 66, 270, 66, 34560, 66, 66, 34560, 66, 270, 270, 66, 270, 34560, 34560, 34560, 270, 34560, 34560, 66, 66, 34560, 270, 34560, 66, 270, 34560, 66, 34560, 270, 66, 34560, 66, 66, 34560, 66, 66, 270]
Prompts retrieved: 1116672 . Total input tokens: 249089717 . Total output tokens: 223405188
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 8.070595521945506,
    "estimated_duration": 3600.0047256688326,
    "input_throughput": 7479.2546265332,
    "output_throughput": 6610.820488736572,
    "total_throughput": 14090.075115269772,
    "itl": 128.39247624517225,
    "ttft": 1711788.338521742,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31778577029705046,
    "arrivals": 372568,
    "finished_requests": 108500,
    "scheduler_time": 66.9751024525376
}
#Debug simulation 
Total elapsed time: 8.070661955047399. Arrivals time: 0.5435465327464044 Scheduler time: 7.403745697345585 Scheduler overhead time: 0.043007764499634504 Adapter cache time: 0.01596109662204981 Engine time: 0.04436809476464987 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-16/adapters_96_slots_96_rate_3.2-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-16/adapters_96_slots_96_rate_3.2-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 34560, 270, 270, 270, 270, 34560, 270, 34560, 270, 66, 34560, 66, 66, 34560, 270, 34560, 270, 34560, 34560, 270, 66, 34560, 270, 66, 66, 270, 34560, 66, 270, 66, 66, 270, 270, 270, 66, 66, 34560, 270, 270, 66, 34560, 34560, 270, 34560, 34560, 270, 34560, 66, 34560, 270, 270, 270, 34560, 34560, 66, 66, 270, 66, 34560, 66, 66, 34560, 66, 270, 270, 66, 270, 34560, 34560, 34560, 270, 34560, 34560, 66, 66, 34560, 270, 34560, 66, 270, 34560, 66, 34560, 270, 66, 34560, 66, 66, 34560, 66, 66, 270]
Prompts retrieved: 1116672 . Total input tokens: 249089717 . Total output tokens: 223405188
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.826940955128521,
    "estimated_duration": 3600.1005001787544,
    "input_throughput": 7492.603331118302,
    "output_throughput": 6621.205435463935,
    "total_throughput": 14113.808766582237,
    "itl": 130.0830845290046,
    "ttft": 1710067.375208411,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2870448283106092,
    "arrivals": 372568,
    "finished_requests": 108692,
    "scheduler_time": 67.54887628481045
}
#Debug simulation 
Total elapsed time: 7.827044066973031. Arrivals time: 0.3095159027725458 Scheduler time: 7.395383273251355 Scheduler overhead time: 0.0424205525778234 Adapter cache time: 0.015687705017626286 Engine time: 0.0441492754034698 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-32/adapters_96_slots_96_rate_3.2-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-32/adapters_96_slots_96_rate_3.2-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 34560, 270, 270, 270, 270, 34560, 270, 34560, 270, 66, 34560, 66, 66, 34560, 270, 34560, 270, 34560, 34560, 270, 66, 34560, 270, 66, 66, 270, 34560, 66, 270, 66, 66, 270, 270, 270, 66, 66, 34560, 270, 270, 66, 34560, 34560, 270, 34560, 34560, 270, 34560, 66, 34560, 270, 270, 270, 34560, 34560, 66, 66, 270, 66, 34560, 66, 66, 34560, 66, 270, 270, 66, 270, 34560, 34560, 34560, 270, 34560, 34560, 66, 66, 34560, 270, 34560, 66, 270, 34560, 66, 34560, 270, 66, 34560, 66, 66, 34560, 66, 66, 270]
Prompts retrieved: 1116672 . Total input tokens: 249089717 . Total output tokens: 223405188
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.826789419166744,
    "estimated_duration": 3600.0091856945437,
    "input_throughput": 7479.245360537972,
    "output_throughput": 6610.812298638205,
    "total_throughput": 14090.057659176178,
    "itl": 128.39255717042164,
    "ttft": 1711791.685862408,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.32180989146232564,
    "arrivals": 372568,
    "finished_requests": 108500,
    "scheduler_time": 66.975083486999
}
#Debug simulation 
Total elapsed time: 7.826909555122256. Arrivals time: 0.3053420200012624 Scheduler time: 7.3971707709133625 Scheduler overhead time: 0.04318437213078141 Adapter cache time: 0.016128238756209612 Engine time: 0.04493209021165967 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-8/adapters_96_slots_96_rate_3.2-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-8/adapters_96_slots_96_rate_3.2-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 34560, 270, 270, 270, 270, 34560, 270, 34560, 270, 33, 34560, 33, 33, 34560, 270, 34560, 270, 34560, 34560, 270, 33, 34560, 270, 33, 33, 270, 34560, 33, 270, 33, 33, 270, 270, 270, 33, 33, 34560, 270, 270, 33, 34560, 34560, 270, 34560, 34560, 270, 34560, 33, 34560, 270, 270, 270, 34560, 34560, 33, 33, 270, 33, 34560, 33, 33, 34560, 33, 270, 270, 33, 270, 34560, 34560, 34560, 270, 34560, 34560, 33, 33, 34560, 270, 34560, 33, 270, 34560, 33, 34560, 270, 33, 34560, 33, 33, 34560, 33, 33, 270]
Prompts retrieved: 1115616 . Total input tokens: 248842694 . Total output tokens: 223201576
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.849081640131772,
    "estimated_duration": 3600.0203663539005,
    "input_throughput": 7485.15376519706,
    "output_throughput": 6652.2834770112395,
    "total_throughput": 14137.4372422083,
    "itl": 130.07033768201572,
    "ttft": 1703640.8740326087,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 95,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2907463356736113,
    "arrivals": 372217,
    "finished_requests": 108866,
    "scheduler_time": 67.97629464526698
}
#Debug simulation 
Total elapsed time: 7.849188390187919. Arrivals time: 0.3084073425270617 Scheduler time: 7.4188302885740995 Scheduler overhead time: 0.04254414699971676 Adapter cache time: 0.015214704908430576 Engine time: 0.04425172135233879 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-16/adapters_96_slots_96_rate_3.2-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-16/adapters_96_slots_96_rate_3.2-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 34560, 270, 270, 270, 270, 34560, 270, 34560, 270, 33, 34560, 33, 33, 34560, 270, 34560, 270, 34560, 34560, 270, 33, 34560, 270, 33, 33, 270, 34560, 33, 270, 33, 33, 270, 270, 270, 33, 33, 34560, 270, 270, 33, 34560, 34560, 270, 34560, 34560, 270, 34560, 33, 34560, 270, 270, 270, 34560, 34560, 33, 33, 270, 33, 34560, 33, 33, 34560, 33, 270, 270, 33, 270, 34560, 34560, 34560, 270, 34560, 34560, 33, 33, 34560, 270, 34560, 33, 270, 34560, 33, 34560, 270, 33, 34560, 33, 33, 34560, 33, 33, 270]
Prompts retrieved: 1115616 . Total input tokens: 248842694 . Total output tokens: 223201576
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.851987246889621,
    "estimated_duration": 3600.1147774431665,
    "input_throughput": 7485.102466410296,
    "output_throughput": 6652.405959403632,
    "total_throughput": 14137.508425813929,
    "itl": 130.07249801371154,
    "ttft": 1703653.8068486059,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 95,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3097962830774486,
    "arrivals": 372217,
    "finished_requests": 108871,
    "scheduler_time": 67.97758314762878
}
#Debug simulation 
Total elapsed time: 7.852076448034495. Arrivals time: 0.3082868168130517 Scheduler time: 7.421792761422694 Scheduler overhead time: 0.042519507464021444 Adapter cache time: 0.015204047318547964 Engine time: 0.04436304420232773 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-32/adapters_96_slots_96_rate_3.2-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-32/adapters_96_slots_96_rate_3.2-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 34560, 270, 270, 270, 270, 34560, 270, 34560, 270, 33, 34560, 33, 33, 34560, 270, 34560, 270, 34560, 34560, 270, 33, 34560, 270, 33, 33, 270, 34560, 33, 270, 33, 33, 270, 270, 270, 33, 33, 34560, 270, 270, 33, 34560, 34560, 270, 34560, 34560, 270, 34560, 33, 34560, 270, 270, 270, 34560, 34560, 33, 33, 270, 33, 34560, 33, 33, 34560, 33, 270, 270, 33, 270, 34560, 34560, 34560, 270, 34560, 34560, 33, 33, 34560, 270, 34560, 33, 270, 34560, 33, 34560, 270, 33, 34560, 33, 33, 34560, 33, 33, 270]
Prompts retrieved: 1115616 . Total input tokens: 248842694 . Total output tokens: 223201576
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.857062527909875,
    "estimated_duration": 3600.0955435315664,
    "input_throughput": 7468.624283683332,
    "output_throughput": 6639.907944373811,
    "total_throughput": 14108.532228057142,
    "itl": 128.2198826698346,
    "ttft": 1705359.522580868,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 95,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31038088278844983,
    "arrivals": 372217,
    "finished_requests": 108633,
    "scheduler_time": 67.33827486932026
}
#Debug simulation 
Total elapsed time: 7.8571522939018905. Arrivals time: 0.3076300797984004 Scheduler time: 7.425387777853757 Scheduler overhead time: 0.04312404617667198 Adapter cache time: 0.015429343096911907 Engine time: 0.045311334542930126 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-16/adapters_96_slots_96_rate_3.2-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-16/adapters_96_slots_96_rate_3.2-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 34560, 270, 270, 270, 270, 34560, 270, 34560, 270, 33, 34560, 33, 33, 34560, 270, 34560, 270, 34560, 34560, 270, 33, 34560, 270, 33, 33, 270, 34560, 33, 270, 33, 33, 270, 270, 270, 33, 33, 34560, 270, 270, 33, 34560, 34560, 270, 34560, 34560, 270, 34560, 33, 34560, 270, 270, 270, 34560, 34560, 33, 33, 270, 33, 34560, 33, 33, 34560, 33, 270, 270, 33, 270, 34560, 34560, 34560, 270, 34560, 34560, 33, 33, 34560, 270, 34560, 33, 270, 34560, 33, 34560, 270, 33, 34560, 33, 33, 34560, 33, 33, 270]
Prompts retrieved: 1115616 . Total input tokens: 248842694 . Total output tokens: 223201576
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 7.862698892131448,
    "estimated_duration": 3600.0667420281497,
    "input_throughput": 7485.084286192741,
    "output_throughput": 6652.242782173604,
    "total_throughput": 14137.327068366345,
    "itl": 130.0716079482226,
    "ttft": 1703649.2937857239,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 95,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29672123288735763,
    "arrivals": 372217,
    "finished_requests": 108867,
    "scheduler_time": 67.9768714605716
}
#Debug simulation 
Total elapsed time: 7.862786217126995. Arrivals time: 0.30766764655709267 Scheduler time: 7.432921760715544 Scheduler overhead time: 0.04258928168565035 Adapter cache time: 0.015544455498456955 Engine time: 0.04420990776270628 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-32/adapters_96_slots_96_rate_3.2-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-32/adapters_96_slots_96_rate_3.2-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 34560, 270, 270, 270, 270, 34560, 270, 34560, 270, 33, 34560, 33, 33, 34560, 270, 34560, 270, 34560, 34560, 270, 33, 34560, 270, 33, 33, 270, 34560, 33, 270, 33, 33, 270, 270, 270, 33, 33, 34560, 270, 270, 33, 34560, 34560, 270, 34560, 34560, 270, 34560, 33, 34560, 270, 270, 270, 34560, 34560, 33, 33, 270, 33, 34560, 33, 33, 34560, 33, 270, 270, 33, 270, 34560, 34560, 34560, 270, 34560, 34560, 33, 33, 34560, 270, 34560, 33, 270, 34560, 33, 34560, 270, 33, 34560, 33, 33, 34560, 33, 33, 270]
Prompts retrieved: 1115616 . Total input tokens: 248842694 . Total output tokens: 223201576
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 7.859595095273107,
    "estimated_duration": 3600.1000881582236,
    "input_throughput": 7468.61485558184,
    "output_throughput": 6639.899562411669,
    "total_throughput": 14108.514417993509,
    "itl": 128.21997862101472,
    "ttft": 1705362.8537217923,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 95,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31440500395372506,
    "arrivals": 372217,
    "finished_requests": 108633,
    "scheduler_time": 67.33825843251776
}
#Debug simulation 
Total elapsed time: 7.859685169998556. Arrivals time: 0.31148357782512903 Scheduler time: 7.424083081074059 Scheduler overhead time: 0.04328447440639138 Adapter cache time: 0.01563643431290984 Engine time: 0.045031335204839706 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-16/adapters_96_slots_96_rate_3.2-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-16/adapters_96_slots_96_rate_3.2-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 34560, 270, 270, 270, 270, 34560, 270, 34560, 270, 33, 34560, 33, 33, 34560, 270, 34560, 270, 34560, 34560, 270, 33, 34560, 270, 33, 33, 270, 34560, 33, 270, 33, 33, 270, 270, 270, 33, 33, 34560, 270, 270, 33, 34560, 34560, 270, 34560, 34560, 270, 34560, 33, 34560, 270, 270, 270, 34560, 34560, 33, 33, 270, 33, 34560, 33, 33, 34560, 33, 270, 270, 33, 270, 34560, 34560, 34560, 270, 34560, 34560, 33, 33, 34560, 270, 34560, 33, 270, 34560, 33, 34560, 270, 33, 34560, 33, 33, 34560, 33, 33, 270]
Prompts retrieved: 1115616 . Total input tokens: 248842694 . Total output tokens: 223201576
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.857012020424008,
    "estimated_duration": 3600.0076745318297,
    "input_throughput": 7485.180154096293,
    "output_throughput": 6652.306929627424,
    "total_throughput": 14137.487083723718,
    "itl": 130.07013836286475,
    "ttft": 1703634.8822789066,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 95,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.284054778015707,
    "arrivals": 372217,
    "finished_requests": 108866,
    "scheduler_time": 67.97630164029327
}
#Debug simulation 
Total elapsed time: 7.857100152410567. Arrivals time: 0.3099245843477547 Scheduler time: 7.425853222142905 Scheduler overhead time: 0.04210782749578357 Adapter cache time: 0.015223070979118347 Engine time: 0.04404627997428179 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-32/adapters_96_slots_96_rate_3.2-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-32/adapters_96_slots_96_rate_3.2-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 34560, 270, 270, 270, 270, 34560, 270, 34560, 270, 33, 34560, 33, 33, 34560, 270, 34560, 270, 34560, 34560, 270, 33, 34560, 270, 33, 33, 270, 34560, 33, 270, 33, 33, 270, 270, 270, 33, 33, 34560, 270, 270, 33, 34560, 34560, 270, 34560, 34560, 270, 34560, 33, 34560, 270, 270, 270, 34560, 34560, 33, 33, 270, 33, 34560, 33, 33, 34560, 33, 270, 270, 33, 270, 34560, 34560, 34560, 270, 34560, 34560, 33, 33, 34560, 270, 34560, 33, 270, 34560, 33, 34560, 270, 33, 34560, 33, 33, 34560, 33, 33, 270]
Prompts retrieved: 1115616 . Total input tokens: 248842694 . Total output tokens: 223201576
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.86117525305599,
    "estimated_duration": 3600.101561654533,
    "input_throughput": 7468.611798730182,
    "output_throughput": 6639.896844747367,
    "total_throughput": 14108.50864347755,
    "itl": 128.21985962499042,
    "ttft": 1705363.8070773804,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 95,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31830337133258546,
    "arrivals": 372217,
    "finished_requests": 108633,
    "scheduler_time": 67.33819122196752
}
#Debug simulation 
Total elapsed time: 7.861259451135993. Arrivals time: 0.30984396720305085 Scheduler time: 7.428656350355595 Scheduler overhead time: 0.042724430561065674 Adapter cache time: 0.015180573798716068 Engine time: 0.04461170732975006 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-8/adapters_96_slots_96_rate_3.2-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-8/adapters_96_slots_96_rate_3.2-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 34560, 135, 135, 135, 135, 34560, 135, 34560, 135, 66, 34560, 66, 66, 34560, 135, 34560, 135, 34560, 34560, 135, 66, 34560, 135, 66, 66, 135, 34560, 66, 135, 66, 66, 135, 135, 135, 66, 66, 34560, 135, 135, 66, 34560, 34560, 135, 34560, 34560, 135, 34560, 66, 34560, 135, 135, 135, 34560, 34560, 66, 66, 135, 66, 34560, 66, 66, 34560, 66, 135, 135, 66, 135, 34560, 34560, 34560, 135, 34560, 34560, 66, 66, 34560, 135, 34560, 66, 135, 34560, 66, 34560, 135, 66, 34560, 66, 66, 34560, 66, 66, 135]
Prompts retrieved: 1112352 . Total input tokens: 248088550 . Total output tokens: 222558435
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 8.012377415783703,
    "estimated_duration": 3600.044274255414,
    "input_throughput": 7614.897460023584,
    "output_throughput": 6748.240062971071,
    "total_throughput": 14363.137522994655,
    "itl": 127.86831715337627,
    "ttft": 1690501.9930140611,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29380682341754405,
    "arrivals": 371082,
    "finished_requests": 110854,
    "scheduler_time": 68.91071975873234
}
#Debug simulation 
Total elapsed time: 8.012458758894354. Arrivals time: 0.34859842993319035 Scheduler time: 7.54267005296424 Scheduler overhead time: 0.04276432329788804 Adapter cache time: 0.013720960356295109 Engine time: 0.04451745701953769 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-16/adapters_96_slots_96_rate_3.2-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-16/adapters_96_slots_96_rate_3.2-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 34560, 135, 135, 135, 135, 34560, 135, 34560, 135, 66, 34560, 66, 66, 34560, 135, 34560, 135, 34560, 34560, 135, 66, 34560, 135, 66, 66, 135, 34560, 66, 135, 66, 66, 135, 135, 135, 66, 66, 34560, 135, 135, 66, 34560, 34560, 135, 34560, 34560, 135, 34560, 66, 34560, 135, 135, 135, 34560, 34560, 66, 66, 135, 66, 34560, 66, 66, 34560, 66, 135, 135, 66, 135, 34560, 34560, 34560, 135, 34560, 34560, 66, 66, 34560, 135, 34560, 66, 135, 34560, 66, 34560, 135, 66, 34560, 66, 66, 34560, 66, 66, 135]
Prompts retrieved: 1112352 . Total input tokens: 248088550 . Total output tokens: 222558435
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 8.000666140113026,
    "estimated_duration": 3600.0861990048415,
    "input_throughput": 7614.808780850287,
    "output_throughput": 6748.161476443394,
    "total_throughput": 14362.970257293682,
    "itl": 127.86923272948283,
    "ttft": 1690522.621246807,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31319492869079113,
    "arrivals": 371082,
    "finished_requests": 110854,
    "scheduler_time": 68.91086414833953
}
#Debug simulation 
Total elapsed time: 8.00076851202175. Arrivals time: 0.3491230048239231 Scheduler time: 7.529667010996491 Scheduler overhead time: 0.04290421213954687 Adapter cache time: 0.01380279241129756 Engine time: 0.04499625414609909 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-32/adapters_96_slots_96_rate_3.2-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-32/adapters_96_slots_96_rate_3.2-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 34560, 135, 135, 135, 135, 34560, 135, 34560, 135, 66, 34560, 66, 66, 34560, 135, 34560, 135, 34560, 34560, 135, 66, 34560, 135, 66, 66, 135, 34560, 66, 135, 66, 66, 135, 135, 135, 66, 66, 34560, 135, 135, 66, 34560, 34560, 135, 34560, 34560, 135, 34560, 66, 34560, 135, 135, 135, 34560, 34560, 66, 66, 135, 66, 34560, 66, 66, 34560, 66, 135, 135, 66, 135, 34560, 34560, 34560, 135, 34560, 34560, 66, 66, 34560, 135, 34560, 66, 135, 34560, 66, 34560, 135, 66, 34560, 66, 66, 34560, 66, 66, 135]
Prompts retrieved: 1112352 . Total input tokens: 248088550 . Total output tokens: 222558435
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 8.207128891721368,
    "estimated_duration": 3600.1200590843923,
    "input_throughput": 7601.10206073506,
    "output_throughput": 6736.665611693001,
    "total_throughput": 14337.76767242806,
    "itl": 126.48856197663224,
    "ttft": 1692064.1105665383,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3137616491317753,
    "arrivals": 371082,
    "finished_requests": 110675,
    "scheduler_time": 68.40834508517347
}
#Debug simulation 
Total elapsed time: 8.207208598963916. Arrivals time: 0.5688372333534062 Scheduler time: 7.516135397367179 Scheduler overhead time: 0.04327965062111616 Adapter cache time: 0.013808224815875292 Engine time: 0.04483193997293711 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-16/adapters_96_slots_96_rate_3.2-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-16/adapters_96_slots_96_rate_3.2-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 34560, 135, 135, 135, 135, 34560, 135, 34560, 135, 66, 34560, 66, 66, 34560, 135, 34560, 135, 34560, 34560, 135, 66, 34560, 135, 66, 66, 135, 34560, 66, 135, 66, 66, 135, 135, 135, 66, 66, 34560, 135, 135, 66, 34560, 34560, 135, 34560, 34560, 135, 34560, 66, 34560, 135, 135, 135, 34560, 34560, 66, 66, 135, 66, 34560, 66, 66, 34560, 66, 135, 135, 66, 135, 34560, 34560, 34560, 135, 34560, 34560, 66, 66, 34560, 135, 34560, 66, 135, 34560, 66, 34560, 135, 66, 34560, 66, 66, 34560, 66, 66, 135]
Prompts retrieved: 1112352 . Total input tokens: 248088550 . Total output tokens: 222558435
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 7.985328521113843,
    "estimated_duration": 3600.056379383341,
    "input_throughput": 7614.871855061275,
    "output_throughput": 6748.217372129418,
    "total_throughput": 14363.089227190694,
    "itl": 127.86850507188929,
    "ttft": 1690507.6826307517,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.30011987850070015,
    "arrivals": 371082,
    "finished_requests": 110854,
    "scheduler_time": 68.91077911962007
}
#Debug simulation 
Total elapsed time: 7.985435516107827. Arrivals time: 0.34618174098432064 Scheduler time: 7.517699079122394 Scheduler overhead time: 0.04276565741747618 Adapter cache time: 0.013645732309669256 Engine time: 0.04494155244901776 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-32/adapters_96_slots_96_rate_3.2-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-32/adapters_96_slots_96_rate_3.2-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 34560, 135, 135, 135, 135, 34560, 135, 34560, 135, 66, 34560, 66, 66, 34560, 135, 34560, 135, 34560, 34560, 135, 66, 34560, 135, 66, 66, 135, 34560, 66, 135, 66, 66, 135, 135, 135, 66, 66, 34560, 135, 135, 66, 34560, 34560, 135, 34560, 34560, 135, 34560, 66, 34560, 135, 135, 135, 34560, 34560, 66, 66, 135, 66, 34560, 66, 66, 34560, 66, 135, 135, 66, 135, 34560, 34560, 34560, 135, 34560, 34560, 66, 66, 34560, 135, 34560, 66, 135, 34560, 66, 34560, 135, 66, 34560, 66, 66, 34560, 66, 66, 135]
Prompts retrieved: 1112352 . Total input tokens: 248088550 . Total output tokens: 222558435
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 7.9897829089313745,
    "estimated_duration": 3600.122006654977,
    "input_throughput": 7601.097948740311,
    "output_throughput": 6736.661967335459,
    "total_throughput": 14337.75991607577,
    "itl": 126.48833932061274,
    "ttft": 1692066.1616814628,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3177857702970505,
    "arrivals": 371082,
    "finished_requests": 110675,
    "scheduler_time": 68.40828768519785
}
#Debug simulation 
Total elapsed time: 7.989871960133314. Arrivals time: 0.3473616624251008 Scheduler time: 7.520106246229261 Scheduler overhead time: 0.04318140121176839 Adapter cache time: 0.013714010827243328 Engine time: 0.04510592995211482 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-16/adapters_96_slots_96_rate_3.2-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-16/adapters_96_slots_96_rate_3.2-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 34560, 135, 135, 135, 135, 34560, 135, 34560, 135, 66, 34560, 66, 66, 34560, 135, 34560, 135, 34560, 34560, 135, 66, 34560, 135, 66, 66, 135, 34560, 66, 135, 66, 66, 135, 135, 135, 66, 66, 34560, 135, 135, 66, 34560, 34560, 135, 34560, 34560, 135, 34560, 66, 34560, 135, 135, 135, 34560, 34560, 66, 66, 135, 66, 34560, 66, 66, 34560, 66, 135, 135, 66, 135, 34560, 34560, 34560, 135, 34560, 34560, 66, 66, 34560, 135, 34560, 66, 135, 34560, 66, 34560, 135, 66, 34560, 66, 66, 34560, 66, 66, 135]
Prompts retrieved: 1112352 . Total input tokens: 248088550 . Total output tokens: 222558435
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 8.000666733365506,
    "estimated_duration": 3600.044549119167,
    "input_throughput": 7614.896878625419,
    "output_throughput": 6748.239547742283,
    "total_throughput": 14363.136426367702,
    "itl": 127.86873517379001,
    "ttft": 1690503.3923826842,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2870448283106092,
    "arrivals": 371082,
    "finished_requests": 110854,
    "scheduler_time": 68.91082401060835
}
#Debug simulation 
Total elapsed time: 8.000752898398787. Arrivals time: 0.3168827877379954 Scheduler time: 7.562533426564187 Scheduler overhead time: 0.042830152437090874 Adapter cache time: 0.013597192242741585 Engine time: 0.04480805667117238 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-32/adapters_96_slots_96_rate_3.2-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-32/adapters_96_slots_96_rate_3.2-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 34560, 135, 135, 135, 135, 34560, 135, 34560, 135, 66, 34560, 66, 66, 34560, 135, 34560, 135, 34560, 34560, 135, 66, 34560, 135, 66, 66, 135, 34560, 66, 135, 66, 66, 135, 135, 135, 66, 66, 34560, 135, 135, 66, 34560, 34560, 135, 34560, 34560, 135, 34560, 66, 34560, 135, 135, 135, 34560, 34560, 66, 66, 135, 66, 34560, 66, 66, 34560, 66, 135, 135, 66, 135, 34560, 34560, 34560, 135, 34560, 34560, 66, 66, 34560, 135, 34560, 66, 135, 34560, 66, 34560, 135, 66, 34560, 66, 66, 34560, 66, 66, 135]
Prompts retrieved: 1112352 . Total input tokens: 248088550 . Total output tokens: 222558435
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 8.02448346093297,
    "estimated_duration": 3600.127174822922,
    "input_throughput": 7601.0870369727945,
    "output_throughput": 6736.652296510307,
    "total_throughput": 14337.739333483101,
    "itl": 126.48823824038253,
    "ttft": 1692069.5267449853,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3218098914623257,
    "arrivals": 371082,
    "finished_requests": 110675,
    "scheduler_time": 68.40830137663286
}
#Debug simulation 
Total elapsed time: 8.024564724881202. Arrivals time: 0.3475916888564825 Scheduler time: 7.55463260691613 Scheduler overhead time: 0.043348658829927444 Adapter cache time: 0.013626013416796923 Engine time: 0.04489004518836737 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-8/adapters_96_slots_96_rate_3.2-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-8/adapters_96_slots_96_rate_3.2-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 34560, 135, 135, 135, 135, 34560, 135, 34560, 135, 33, 34560, 33, 33, 34560, 135, 34560, 135, 34560, 34560, 135, 33, 34560, 135, 33, 33, 135, 34560, 33, 135, 33, 33, 135, 135, 135, 33, 33, 34560, 135, 135, 33, 34560, 34560, 135, 34560, 34560, 135, 34560, 33, 34560, 135, 135, 135, 34560, 34560, 33, 33, 135, 33, 34560, 33, 33, 34560, 33, 135, 135, 33, 135, 34560, 34560, 34560, 135, 34560, 34560, 33, 33, 34560, 135, 34560, 33, 135, 34560, 33, 34560, 135, 33, 34560, 33, 33, 34560, 33, 33, 135]
Prompts retrieved: 1111296 . Total input tokens: 247850982 . Total output tokens: 222339600
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 8.043799815233797,
    "estimated_duration": 3600.1033812734267,
    "input_throughput": 7689.927501528426,
    "output_throughput": 6793.564353518341,
    "total_throughput": 14483.491855046766,
    "itl": 126.83737960123162,
    "ttft": 1685795.8555549502,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 95,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2907463356736113,
    "arrivals": 370740,
    "finished_requests": 111864,
    "scheduler_time": 69.35937516253733
}
#Debug simulation 
Total elapsed time: 8.043902073986828. Arrivals time: 0.3203240232542157 Scheduler time: 7.602583721280098 Scheduler overhead time: 0.04320677602663636 Adapter cache time: 0.012470667250454426 Engine time: 0.04487602366134524 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-16/adapters_96_slots_96_rate_3.2-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-16/adapters_96_slots_96_rate_3.2-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 34560, 135, 135, 135, 135, 34560, 135, 34560, 135, 33, 34560, 33, 33, 34560, 135, 34560, 135, 34560, 34560, 135, 33, 34560, 135, 33, 33, 135, 34560, 33, 135, 33, 33, 135, 135, 135, 33, 33, 34560, 135, 135, 33, 34560, 34560, 135, 34560, 34560, 135, 34560, 33, 34560, 135, 135, 135, 34560, 34560, 33, 33, 135, 33, 34560, 33, 33, 34560, 33, 135, 135, 33, 135, 34560, 34560, 34560, 135, 34560, 34560, 33, 33, 34560, 135, 34560, 33, 135, 34560, 33, 34560, 135, 33, 34560, 33, 33, 34560, 33, 33, 135]
Prompts retrieved: 1111296 . Total input tokens: 247850982 . Total output tokens: 222339600
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 8.014398118946701,
    "estimated_duration": 3600.01597421021,
    "input_throughput": 7690.105043512638,
    "output_throughput": 6793.591521594709,
    "total_throughput": 14483.696565107348,
    "itl": 126.83767147946212,
    "ttft": 1685772.6085737625,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 95,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3097962830774486,
    "arrivals": 370740,
    "finished_requests": 111862,
    "scheduler_time": 69.35766286578196
}
#Debug simulation 
Total elapsed time: 8.0144861349836. Arrivals time: 0.3179957438260317 Scheduler time: 7.5756095997057855 Scheduler overhead time: 0.04319676151499152 Adapter cache time: 0.012367581948637962 Engine time: 0.045044314581900835 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-32/adapters_96_slots_96_rate_3.2-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-32/adapters_96_slots_96_rate_3.2-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 34560, 135, 135, 135, 135, 34560, 135, 34560, 135, 33, 34560, 33, 33, 34560, 135, 34560, 135, 34560, 34560, 135, 33, 34560, 135, 33, 33, 135, 34560, 33, 135, 33, 33, 135, 135, 135, 33, 33, 34560, 135, 135, 33, 34560, 34560, 135, 34560, 34560, 135, 34560, 33, 34560, 135, 135, 135, 34560, 34560, 33, 33, 135, 33, 34560, 33, 33, 34560, 33, 135, 135, 33, 135, 34560, 34560, 34560, 135, 34560, 34560, 33, 33, 34560, 135, 34560, 33, 135, 34560, 33, 34560, 135, 33, 34560, 33, 33, 34560, 33, 33, 135]
Prompts retrieved: 1111296 . Total input tokens: 247850982 . Total output tokens: 222339600
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 8.2148646148853,
    "estimated_duration": 3600.0631950367997,
    "input_throughput": 7677.552726881359,
    "output_throughput": 6781.496511966214,
    "total_throughput": 14459.049238847572,
    "itl": 125.55835790947233,
    "ttft": 1687511.2726556002,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 95,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31038088278844983,
    "arrivals": 370740,
    "finished_requests": 111674,
    "scheduler_time": 68.873270740376
}
#Debug simulation 
Total elapsed time: 8.214953368995339. Arrivals time: 0.5352604323998094 Scheduler time: 7.557700216304511 Scheduler overhead time: 0.043444772716611624 Adapter cache time: 0.012596196494996548 Engine time: 0.045487724244594574 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-16/adapters_96_slots_96_rate_3.2-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-16/adapters_96_slots_96_rate_3.2-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 34560, 135, 135, 135, 135, 34560, 135, 34560, 135, 33, 34560, 33, 33, 34560, 135, 34560, 135, 34560, 34560, 135, 33, 34560, 135, 33, 33, 135, 34560, 33, 135, 33, 33, 135, 135, 135, 33, 33, 34560, 135, 135, 33, 34560, 34560, 135, 34560, 34560, 135, 34560, 33, 34560, 135, 135, 135, 34560, 34560, 33, 33, 135, 33, 34560, 33, 33, 34560, 33, 135, 135, 33, 135, 34560, 34560, 34560, 135, 34560, 34560, 33, 33, 34560, 135, 34560, 33, 135, 34560, 33, 34560, 135, 33, 34560, 33, 33, 34560, 33, 33, 135]
Prompts retrieved: 1111296 . Total input tokens: 247850982 . Total output tokens: 222339600
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 8.021520887967199,
    "estimated_duration": 3600.0038291931705,
    "input_throughput": 7690.1309869452625,
    "output_throughput": 6793.614440538328,
    "total_throughput": 14483.74542748359,
    "itl": 126.83788289039505,
    "ttft": 1685767.547274331,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 95,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29672123288735763,
    "arrivals": 370740,
    "finished_requests": 111862,
    "scheduler_time": 69.3575230184829
}
#Debug simulation 
Total elapsed time: 8.021603200118989. Arrivals time: 0.3161741653457284 Scheduler time: 7.584092980250716 Scheduler overhead time: 0.043041946832090616 Adapter cache time: 0.012567491736263037 Engine time: 0.04513981146737933 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-32/adapters_96_slots_96_rate_3.2-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-32/adapters_96_slots_96_rate_3.2-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 34560, 135, 135, 135, 135, 34560, 135, 34560, 135, 33, 34560, 33, 33, 34560, 135, 34560, 135, 34560, 34560, 135, 33, 34560, 135, 33, 33, 135, 34560, 33, 135, 33, 33, 135, 135, 135, 33, 33, 34560, 135, 135, 33, 34560, 34560, 135, 34560, 34560, 135, 34560, 33, 34560, 135, 135, 135, 34560, 34560, 33, 33, 135, 33, 34560, 33, 33, 34560, 33, 135, 135, 33, 135, 34560, 34560, 34560, 135, 34560, 34560, 33, 33, 34560, 135, 34560, 33, 135, 34560, 33, 34560, 135, 33, 34560, 33, 33, 34560, 33, 33, 135]
Prompts retrieved: 1111296 . Total input tokens: 247850982 . Total output tokens: 222339600
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 7.9891727436333895,
    "estimated_duration": 3600.0670589850215,
    "input_throughput": 7677.54448657202,
    "output_throughput": 6781.489233393077,
    "total_throughput": 14459.033719965097,
    "itl": 125.55837601889894,
    "ttft": 1687513.7905130803,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 95,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31440500395372495,
    "arrivals": 370740,
    "finished_requests": 111674,
    "scheduler_time": 68.87324735540669
}
#Debug simulation 
Total elapsed time: 7.989254935644567. Arrivals time: 0.31303569208830595 Scheduler time: 7.553860171698034 Scheduler overhead time: 0.043572362046688795 Adapter cache time: 0.012749365530908108 Engine time: 0.04536561481654644 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-16/adapters_96_slots_96_rate_3.2-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-16/adapters_96_slots_96_rate_3.2-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 34560, 135, 135, 135, 135, 34560, 135, 34560, 135, 33, 34560, 33, 33, 34560, 135, 34560, 135, 34560, 34560, 135, 33, 34560, 135, 33, 33, 135, 34560, 33, 135, 33, 33, 135, 135, 135, 33, 33, 34560, 135, 135, 33, 34560, 34560, 135, 34560, 34560, 135, 34560, 33, 34560, 135, 135, 135, 34560, 34560, 33, 33, 135, 33, 34560, 33, 33, 34560, 33, 135, 135, 33, 135, 34560, 34560, 34560, 135, 34560, 34560, 33, 33, 34560, 135, 34560, 33, 135, 34560, 33, 34560, 135, 33, 34560, 33, 33, 34560, 33, 33, 135]
Prompts retrieved: 1111296 . Total input tokens: 247850982 . Total output tokens: 222339600
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 8.22847353713587,
    "estimated_duration": 3600.0958907093045,
    "input_throughput": 7689.943501628643,
    "output_throughput": 6793.578488594448,
    "total_throughput": 14483.521990223091,
    "itl": 126.83738607930347,
    "ttft": 1685792.8899036823,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 95,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.284054778015707,
    "arrivals": 370740,
    "finished_requests": 111864,
    "scheduler_time": 69.35954995870992
}
#Debug simulation 
Total elapsed time: 8.228543845936656. Arrivals time: 0.320114950183779 Scheduler time: 7.787176331505179 Scheduler overhead time: 0.0433194818906486 Adapter cache time: 0.012493448331952095 Engine time: 0.04509367886930704 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-32/adapters_96_slots_96_rate_3.2-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-32/adapters_96_slots_96_rate_3.2-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 34560, 135, 135, 135, 135, 34560, 135, 34560, 135, 33, 34560, 33, 33, 34560, 135, 34560, 135, 34560, 34560, 135, 33, 34560, 135, 33, 33, 135, 34560, 33, 135, 33, 33, 135, 135, 135, 33, 33, 34560, 135, 135, 33, 34560, 34560, 135, 34560, 34560, 135, 34560, 33, 34560, 135, 135, 135, 34560, 34560, 33, 33, 135, 33, 34560, 33, 33, 34560, 33, 135, 135, 33, 135, 34560, 34560, 34560, 135, 34560, 34560, 33, 33, 34560, 135, 34560, 33, 135, 34560, 33, 34560, 135, 33, 34560, 33, 33, 34560, 33, 33, 135]
Prompts retrieved: 1111296 . Total input tokens: 247850982 . Total output tokens: 222339600
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 8.011620642617345,
    "estimated_duration": 3600.0681505572734,
    "input_throughput": 7677.542158673165,
    "output_throughput": 6781.487177186037,
    "total_throughput": 14459.029335859203,
    "itl": 125.55830273059817,
    "ttft": 1687513.913321728,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 95,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31830337133258535,
    "arrivals": 370740,
    "finished_requests": 111674,
    "scheduler_time": 68.87295348327105
}
#Debug simulation 
Total elapsed time: 8.011724567972124. Arrivals time: 0.3254919149912894 Scheduler time: 7.564001603983343 Scheduler overhead time: 0.043458244763314724 Adapter cache time: 0.012605254538357258 Engine time: 0.04562397161498666 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-8/adapters_96_slots_96_rate_3.2-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-8/adapters_96_slots_96_rate_3.2-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 34560, 66, 66, 66, 66, 34560, 66, 34560, 66, 33, 34560, 33, 33, 34560, 66, 34560, 66, 34560, 34560, 66, 33, 34560, 66, 33, 33, 66, 34560, 33, 66, 33, 33, 66, 66, 66, 33, 33, 34560, 66, 66, 33, 34560, 34560, 66, 34560, 34560, 66, 34560, 33, 34560, 66, 66, 66, 34560, 34560, 33, 33, 66, 33, 34560, 33, 33, 34560, 33, 66, 66, 33, 66, 34560, 34560, 34560, 66, 34560, 34560, 33, 33, 34560, 66, 34560, 33, 66, 34560, 33, 34560, 66, 33, 34560, 33, 33, 34560, 33, 33, 66]
Prompts retrieved: 1109088 . Total input tokens: 247355226 . Total output tokens: 221887519
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 8.151533744297922,
    "estimated_duration": 3600.0358955324377,
    "input_throughput": 7810.369622951069,
    "output_throughput": 6875.5900547317115,
    "total_throughput": 14685.95967768278,
    "itl": 125.09354943814441,
    "ttft": 1671976.680195206,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29380682341754405,
    "arrivals": 369999,
    "finished_requests": 113700,
    "scheduler_time": 70.11302857567675
}
#Debug simulation 
Total elapsed time: 8.151622998993844. Arrivals time: 0.32683702604845166 Scheduler time: 7.703251540660858 Scheduler overhead time: 0.04412877047434449 Adapter cache time: 0.010899440385401249 Engine time: 0.04585877573117614 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-16/adapters_96_slots_96_rate_3.2-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-16/adapters_96_slots_96_rate_3.2-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 34560, 66, 66, 66, 66, 34560, 66, 34560, 66, 33, 34560, 33, 33, 34560, 66, 34560, 66, 34560, 34560, 66, 33, 34560, 66, 33, 33, 66, 34560, 33, 66, 33, 33, 66, 66, 66, 33, 33, 34560, 66, 66, 33, 34560, 34560, 66, 34560, 34560, 66, 34560, 33, 34560, 66, 66, 66, 34560, 34560, 33, 33, 66, 33, 34560, 33, 33, 34560, 33, 66, 66, 33, 66, 34560, 34560, 34560, 66, 34560, 34560, 33, 33, 34560, 66, 34560, 33, 66, 34560, 33, 34560, 66, 33, 34560, 33, 33, 34560, 33, 33, 66]
Prompts retrieved: 1109088 . Total input tokens: 247355226 . Total output tokens: 221887519
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 8.170232480857521,
    "estimated_duration": 3600.088022881336,
    "input_throughput": 7810.256532976665,
    "output_throughput": 6875.490499865445,
    "total_throughput": 14685.74703284211,
    "itl": 125.09421030002116,
    "ttft": 1671977.3903893726,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31319492869079113,
    "arrivals": 369999,
    "finished_requests": 113700,
    "scheduler_time": 70.11396079242463
}
#Debug simulation 
Total elapsed time: 8.170336430892348. Arrivals time: 0.3290096246637404 Scheduler time: 7.720464876387268 Scheduler overhead time: 0.0437556030228734 Adapter cache time: 0.010930945631116629 Engine time: 0.045544990338385105 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-32/adapters_96_slots_96_rate_3.2-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-32/adapters_96_slots_96_rate_3.2-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 34560, 66, 66, 66, 66, 34560, 66, 34560, 66, 33, 34560, 33, 33, 34560, 66, 34560, 66, 34560, 34560, 66, 33, 34560, 66, 33, 33, 66, 34560, 33, 66, 33, 33, 66, 66, 66, 33, 33, 34560, 66, 66, 33, 34560, 34560, 66, 34560, 34560, 66, 34560, 33, 34560, 66, 66, 66, 34560, 34560, 33, 33, 66, 33, 34560, 33, 33, 34560, 33, 66, 66, 33, 66, 34560, 34560, 34560, 66, 34560, 34560, 33, 33, 34560, 66, 34560, 33, 66, 34560, 33, 34560, 66, 33, 34560, 33, 33, 34560, 33, 33, 66]
Prompts retrieved: 1109088 . Total input tokens: 247355226 . Total output tokens: 221887519
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 8.182287374977022,
    "estimated_duration": 3600.0265227929376,
    "input_throughput": 7798.89754207093,
    "output_throughput": 6866.457189549374,
    "total_throughput": 14665.354731620304,
    "itl": 123.95319901688214,
    "ttft": 1673655.2655423782,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31376164913177523,
    "arrivals": 369999,
    "finished_requests": 113540,
    "scheduler_time": 69.66164285598245
}
#Debug simulation 
Total elapsed time: 8.182376231066883. Arrivals time: 0.3395543326623738 Scheduler time: 7.719861220102757 Scheduler overhead time: 0.04408339923247695 Adapter cache time: 0.011574081610888243 Engine time: 0.04650777019560337 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-16/adapters_96_slots_96_rate_3.2-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-16/adapters_96_slots_96_rate_3.2-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 34560, 66, 66, 66, 66, 34560, 66, 34560, 66, 33, 34560, 33, 33, 34560, 66, 34560, 66, 34560, 34560, 66, 33, 34560, 66, 33, 33, 66, 34560, 33, 66, 33, 33, 66, 66, 66, 33, 33, 34560, 66, 66, 33, 34560, 34560, 66, 34560, 34560, 66, 34560, 33, 34560, 66, 66, 66, 34560, 34560, 33, 33, 66, 33, 34560, 33, 33, 34560, 33, 66, 66, 33, 66, 34560, 34560, 34560, 66, 34560, 34560, 33, 33, 34560, 66, 34560, 33, 66, 34560, 33, 34560, 66, 33, 34560, 33, 33, 34560, 33, 33, 66]
Prompts retrieved: 1109088 . Total input tokens: 247355226 . Total output tokens: 221887519
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 8.200903389137238,
    "estimated_duration": 3600.0719031052095,
    "input_throughput": 7810.291504385623,
    "output_throughput": 6875.521285741562,
    "total_throughput": 14685.812790127186,
    "itl": 125.09408911166953,
    "ttft": 1671972.190694352,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.30011987850070015,
    "arrivals": 369999,
    "finished_requests": 113700,
    "scheduler_time": 70.11393463013914
}
#Debug simulation 
Total elapsed time: 8.200989063363522. Arrivals time: 0.3448693985119462 Scheduler time: 7.733710666652769 Scheduler overhead time: 0.04388223448768258 Adapter cache time: 0.011740837711840868 Engine time: 0.04598813224583864 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-32/adapters_96_slots_96_rate_3.2-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-32/adapters_96_slots_96_rate_3.2-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 34560, 66, 66, 66, 66, 34560, 66, 34560, 66, 33, 34560, 33, 33, 34560, 66, 34560, 66, 34560, 34560, 66, 33, 34560, 66, 33, 33, 66, 34560, 33, 66, 33, 33, 66, 66, 66, 33, 33, 34560, 66, 66, 33, 34560, 34560, 66, 34560, 34560, 66, 34560, 33, 34560, 66, 66, 66, 34560, 34560, 33, 33, 66, 33, 34560, 33, 33, 34560, 33, 66, 66, 33, 66, 34560, 34560, 34560, 66, 34560, 34560, 33, 33, 34560, 66, 34560, 33, 66, 34560, 33, 34560, 66, 33, 34560, 33, 33, 34560, 33, 33, 66]
Prompts retrieved: 1109088 . Total input tokens: 247355226 . Total output tokens: 221887519
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 8.205741654150188,
    "estimated_duration": 3600.0310054946444,
    "input_throughput": 7798.887831006979,
    "output_throughput": 6866.448639545411,
    "total_throughput": 14665.336470552389,
    "itl": 123.95326075356779,
    "ttft": 1673658.395256755,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3177857702970505,
    "arrivals": 369999,
    "finished_requests": 113540,
    "scheduler_time": 69.66161764469909
}
#Debug simulation 
Total elapsed time: 8.205845588818192. Arrivals time: 0.3429067274555564 Scheduler time: 7.740371994674206 Scheduler overhead time: 0.04448351124301553 Adapter cache time: 0.011625115294009447 Engine time: 0.04570312798023224 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-16/adapters_96_slots_96_rate_3.2-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-16/adapters_96_slots_96_rate_3.2-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 34560, 66, 66, 66, 66, 34560, 66, 34560, 66, 33, 34560, 33, 33, 34560, 66, 34560, 66, 34560, 34560, 66, 33, 34560, 66, 33, 33, 66, 34560, 33, 66, 33, 33, 66, 66, 66, 33, 33, 34560, 66, 66, 33, 34560, 34560, 66, 34560, 34560, 66, 34560, 33, 34560, 66, 66, 66, 34560, 34560, 33, 33, 66, 33, 34560, 33, 33, 34560, 33, 66, 66, 33, 66, 34560, 34560, 34560, 66, 34560, 34560, 33, 33, 34560, 66, 34560, 33, 66, 34560, 33, 34560, 66, 33, 34560, 33, 33, 34560, 33, 33, 66]
Prompts retrieved: 1109088 . Total input tokens: 247355226 . Total output tokens: 221887519
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 8.211908391676843,
    "estimated_duration": 3600.0308116077435,
    "input_throughput": 7810.380652670834,
    "output_throughput": 6875.599764365849,
    "total_throughput": 14685.980417036684,
    "itl": 125.09371201832495,
    "ttft": 1671972.121408741,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2870448283106092,
    "arrivals": 369999,
    "finished_requests": 113700,
    "scheduler_time": 70.1131658416159
}
#Debug simulation 
Total elapsed time: 8.212020407896489. Arrivals time: 0.341295741032809 Scheduler time: 7.748573684133589 Scheduler overhead time: 0.04405808448791504 Adapter cache time: 0.01170694176107645 Engine time: 0.04562063980847597 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-32/adapters_96_slots_96_rate_3.2-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-32/adapters_96_slots_96_rate_3.2-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 34560, 66, 66, 66, 66, 34560, 66, 34560, 66, 33, 34560, 33, 33, 34560, 66, 34560, 66, 34560, 34560, 66, 33, 34560, 66, 33, 33, 66, 34560, 33, 66, 33, 33, 66, 66, 66, 33, 33, 34560, 66, 66, 33, 34560, 34560, 66, 34560, 34560, 66, 34560, 33, 34560, 66, 66, 66, 34560, 34560, 33, 33, 66, 33, 34560, 33, 33, 34560, 33, 66, 66, 33, 66, 34560, 34560, 34560, 66, 34560, 34560, 33, 33, 34560, 66, 34560, 33, 66, 34560, 33, 34560, 66, 33, 34560, 33, 33, 34560, 33, 33, 66]
Prompts retrieved: 1109088 . Total input tokens: 247355226 . Total output tokens: 221887519
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 8.18548050429672,
    "estimated_duration": 3600.034969677786,
    "input_throughput": 7798.879243251603,
    "output_throughput": 6866.441078546652,
    "total_throughput": 14665.320321798254,
    "itl": 123.95329595286557,
    "ttft": 1673661.0158360514,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3218098914623257,
    "arrivals": 369999,
    "finished_requests": 113540,
    "scheduler_time": 69.66159200610929
}
#Debug simulation 
Total elapsed time: 8.185567416250706. Arrivals time: 0.3393427333794534 Scheduler time: 7.723435751628131 Scheduler overhead time: 0.04428942780941725 Adapter cache time: 0.011819526087492704 Engine time: 0.04583485657349229 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-8/adapters_96_slots_96_rate_1.6-0.8-0.4_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-8/adapters_96_slots_96_rate_1.6-0.8-0.4_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 8640, 17280, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 17280, 8640, 8640, 4320, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 4320, 17280, 8640, 8640, 8640, 17280, 17280, 4320, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 4320, 4320, 17280, 8640, 17280, 4320, 8640, 17280, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 4320, 8640]
Prompts retrieved: 967680 . Total input tokens: 215756141 . Total output tokens: 193683575
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.847858534194529,
    "estimated_duration": 3600.198136368968,
    "input_throughput": 5445.679170250734,
    "output_throughput": 4822.7515104242475,
    "total_throughput": 10268.430680674981,
    "itl": 178.63756918045434,
    "ttft": 1894646.833501785,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29380682341754405,
    "arrivals": 322758,
    "finished_requests": 79350,
    "scheduler_time": 49.44014922695048
}
#Debug simulation 
Total elapsed time: 5.847949341870844. Arrivals time: 0.27122722286731005 Scheduler time: 5.490002788603306 Scheduler overhead time: 0.030918603762984276 Adapter cache time: 0.008569259196519852 Engine time: 0.03257598401978612 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-16/adapters_96_slots_96_rate_1.6-0.8-0.4_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-16/adapters_96_slots_96_rate_1.6-0.8-0.4_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 8640, 17280, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 17280, 8640, 8640, 4320, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 4320, 17280, 8640, 8640, 8640, 17280, 17280, 4320, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 4320, 4320, 17280, 8640, 17280, 4320, 8640, 17280, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 4320, 8640]
Prompts retrieved: 967680 . Total input tokens: 215756141 . Total output tokens: 193683575
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.864380411803722,
    "estimated_duration": 3600.1664965213945,
    "input_throughput": 5445.7270292758785,
    "output_throughput": 4822.793894886971,
    "total_throughput": 10268.52092416285,
    "itl": 178.6396194102225,
    "ttft": 1894633.2598821355,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31319492869079113,
    "arrivals": 322758,
    "finished_requests": 79350,
    "scheduler_time": 49.43977162885848
}
#Debug simulation 
Total elapsed time: 5.864481691736728. Arrivals time: 0.2699353424832225 Scheduler time: 5.507454552222043 Scheduler overhead time: 0.031145078595727682 Adapter cache time: 0.008461364079266787 Engine time: 0.0327151226811111 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-32/adapters_96_slots_96_rate_1.6-0.8-0.4_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-32/adapters_96_slots_96_rate_1.6-0.8-0.4_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 8640, 17280, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 17280, 8640, 8640, 4320, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 4320, 17280, 8640, 8640, 8640, 17280, 17280, 4320, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 4320, 4320, 17280, 8640, 17280, 4320, 8640, 17280, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 4320, 8640]
Prompts retrieved: 967680 . Total input tokens: 215756141 . Total output tokens: 193683575
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.0577333881519735,
    "estimated_duration": 3600.149373987229,
    "input_throughput": 5433.325389589623,
    "output_throughput": 4811.713681983866,
    "total_throughput": 10245.03907157349,
    "itl": 176.36778622078592,
    "ttft": 1896995.0380435209,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31376164913177523,
    "arrivals": 322758,
    "finished_requests": 79162,
    "scheduler_time": 48.98560578759167
}
#Debug simulation 
Total elapsed time: 6.057829608209431. Arrivals time: 0.2658659480512142 Scheduler time: 5.703853890299797 Scheduler overhead time: 0.03132441872730851 Adapter cache time: 0.008919219486415386 Engine time: 0.03294701734557748 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-16-16/adapters_96_slots_96_rate_1.6-0.8-0.4_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-16-16/adapters_96_slots_96_rate_1.6-0.8-0.4_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 8640, 17280, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 17280, 8640, 8640, 4320, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 4320, 17280, 8640, 8640, 8640, 17280, 17280, 4320, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 4320, 4320, 17280, 8640, 17280, 4320, 8640, 17280, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 4320, 8640]
Prompts retrieved: 967680 . Total input tokens: 215756141 . Total output tokens: 193683575
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 5.832599841989577,
    "estimated_duration": 3600.0307318077407,
    "input_throughput": 5445.9323990701505,
    "output_throughput": 4822.975772565505,
    "total_throughput": 10268.908171635656,
    "itl": 178.6369392157864,
    "ttft": 1894564.9371000968,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3001198785007002,
    "arrivals": 322758,
    "finished_requests": 79350,
    "scheduler_time": 49.4378674376801
}
#Debug simulation 
Total elapsed time: 5.832710449118167. Arrivals time: 0.2706477204337716 Scheduler time: 5.475350058637559 Scheduler overhead time: 0.03102263854816556 Adapter cache time: 0.008483417797833681 Engine time: 0.03251140424981713 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-16-32/adapters_96_slots_96_rate_1.6-0.8-0.4_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-16-32/adapters_96_slots_96_rate_1.6-0.8-0.4_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 8640, 17280, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 17280, 8640, 8640, 4320, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 4320, 17280, 8640, 8640, 8640, 17280, 17280, 4320, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 4320, 4320, 17280, 8640, 17280, 4320, 8640, 17280, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 4320, 8640]
Prompts retrieved: 967680 . Total input tokens: 215756141 . Total output tokens: 193683575
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 5.822793815284967,
    "estimated_duration": 3600.1038857898707,
    "input_throughput": 5433.145159284346,
    "output_throughput": 4811.711425432761,
    "total_throughput": 10244.856584717107,
    "itl": 176.35747200251726,
    "ttft": 1896986.1132313295,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3177857702970504,
    "arrivals": 322758,
    "finished_requests": 79159,
    "scheduler_time": 48.982388153866424
}
#Debug simulation 
Total elapsed time: 5.822881969157606. Arrivals time: 0.2697316645644605 Scheduler time: 5.465331936720759 Scheduler overhead time: 0.031428252812474966 Adapter cache time: 0.008734946604818106 Engine time: 0.032776722218841314 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_16-16-16/adapters_96_slots_96_rate_1.6-0.8-0.4_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_16-16-16/adapters_96_slots_96_rate_1.6-0.8-0.4_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 8640, 17280, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 17280, 8640, 8640, 4320, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 4320, 17280, 8640, 8640, 8640, 17280, 17280, 4320, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 4320, 4320, 17280, 8640, 17280, 4320, 8640, 17280, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 4320, 8640]
Prompts retrieved: 967680 . Total input tokens: 215756141 . Total output tokens: 193683575
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.818971256259829,
    "estimated_duration": 3600.1772746378833,
    "input_throughput": 5445.7107260008415,
    "output_throughput": 4822.779456532848,
    "total_throughput": 10268.49018253369,
    "itl": 178.63757631693514,
    "ttft": 1894625.7629509373,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2870448283106092,
    "arrivals": 322758,
    "finished_requests": 79350,
    "scheduler_time": 49.43994436421397
}
#Debug simulation 
Total elapsed time: 5.819077616091818. Arrivals time: 0.26365454215556383 Scheduler time: 5.468761008698493 Scheduler overhead time: 0.031305994372814894 Adapter cache time: 0.008302403148263693 Engine time: 0.032392683904618025 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_16-16-32/adapters_96_slots_96_rate_1.6-0.8-0.4_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_16-16-32/adapters_96_slots_96_rate_1.6-0.8-0.4_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 8640, 17280, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 17280, 8640, 8640, 4320, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 4320, 17280, 8640, 8640, 8640, 17280, 17280, 4320, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 4320, 4320, 17280, 8640, 17280, 4320, 8640, 17280, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 4320, 8640]
Prompts retrieved: 967680 . Total input tokens: 215756141 . Total output tokens: 193683575
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.837571149691939,
    "estimated_duration": 3600.109203059973,
    "input_throughput": 5433.137134666567,
    "output_throughput": 4811.704318656866,
    "total_throughput": 10244.841453323434,
    "itl": 176.35722513951654,
    "ttft": 1896990.0872447488,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3218098914623257,
    "arrivals": 322758,
    "finished_requests": 79159,
    "scheduler_time": 48.982365079127206
}
#Debug simulation 
Total elapsed time: 5.837680761702359. Arrivals time: 0.2716866424307227 Scheduler time: 5.4781238925643265 Scheduler overhead time: 0.031353702303022146 Adapter cache time: 0.008784469682723284 Engine time: 0.03286574920639396 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-8/adapters_96_slots_96_rate_1.6-0.8-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-8/adapters_96_slots_96_rate_1.6-0.8-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 8640, 17280, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 17280, 8640, 8640, 1080, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 1080, 17280, 8640, 8640, 8640, 17280, 17280, 1080, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 1080, 1080, 17280, 8640, 17280, 1080, 8640, 17280, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 8640]
Prompts retrieved: 864000 . Total input tokens: 192506673 . Total output tokens: 172939330
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.104725158773363,
    "estimated_duration": 3600.0366795483037,
    "input_throughput": 5724.268899000671,
    "output_throughput": 5052.93712793015,
    "total_throughput": 10777.20602693082,
    "itl": 169.877953445194,
    "ttft": 1814962.5421105747,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29380682341754405,
    "arrivals": 287932,
    "finished_requests": 83275,
    "scheduler_time": 51.945521373244866
}
#Debug simulation 
Total elapsed time: 6.104821511078626. Arrivals time: 0.27249470306560397 Scheduler time: 5.73153923638165 Scheduler overhead time: 0.032518291380256414 Adapter cache time: 0.018259319476783276 Engine time: 0.03466597432270646 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-16/adapters_96_slots_96_rate_1.6-0.8-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-16/adapters_96_slots_96_rate_1.6-0.8-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 8640, 17280, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 17280, 8640, 8640, 1080, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 1080, 17280, 8640, 8640, 8640, 17280, 17280, 1080, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 1080, 1080, 17280, 8640, 17280, 1080, 8640, 17280, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 8640]
Prompts retrieved: 864000 . Total input tokens: 192506673 . Total output tokens: 172939330
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.115160969551653,
    "estimated_duration": 3600.1538173819818,
    "input_throughput": 5724.125147237699,
    "output_throughput": 5052.952713345098,
    "total_throughput": 10777.077860582798,
    "itl": 169.88097661292616,
    "ttft": 1814963.7398497136,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31319492869079113,
    "arrivals": 287932,
    "finished_requests": 83277,
    "scheduler_time": 51.94658054495928
}
#Debug simulation 
Total elapsed time: 6.1152990479022264. Arrivals time: 0.27250229800119996 Scheduler time: 5.7424141597002745 Scheduler overhead time: 0.0326559217646718 Adapter cache time: 0.017922168597579002 Engine time: 0.034341156017035246 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-32/adapters_96_slots_96_rate_1.6-0.8-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-32/adapters_96_slots_96_rate_1.6-0.8-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 8640, 17280, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 17280, 8640, 8640, 1080, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 1080, 17280, 8640, 8640, 8640, 17280, 17280, 1080, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 1080, 1080, 17280, 8640, 17280, 1080, 8640, 17280, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 8640]
Prompts retrieved: 864000 . Total input tokens: 192506673 . Total output tokens: 172939330
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.0867974469438195,
    "estimated_duration": 3600.1844531983033,
    "input_throughput": 5713.871127276633,
    "output_throughput": 5043.8026817954815,
    "total_throughput": 10757.673809072114,
    "itl": 167.76415953905845,
    "ttft": 1817066.8737696342,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3137616491317753,
    "arrivals": 287932,
    "finished_requests": 83125,
    "scheduler_time": 51.54402437367119
}
#Debug simulation 
Total elapsed time: 6.086887665092945. Arrivals time: 0.2716502994298935 Scheduler time: 5.714191310573369 Scheduler overhead time: 0.03280959744006395 Adapter cache time: 0.01836970681324601 Engine time: 0.034278870560228825 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-16-16/adapters_96_slots_96_rate_1.6-0.8-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-16-16/adapters_96_slots_96_rate_1.6-0.8-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 8640, 17280, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 17280, 8640, 8640, 1080, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 1080, 17280, 8640, 8640, 8640, 17280, 17280, 1080, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 1080, 1080, 17280, 8640, 17280, 1080, 8640, 17280, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 8640]
Prompts retrieved: 864000 . Total input tokens: 192506673 . Total output tokens: 172939330
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.097000880166888,
    "estimated_duration": 3600.047901398252,
    "input_throughput": 5724.251055658468,
    "output_throughput": 5052.921377222437,
    "total_throughput": 10777.172432880905,
    "itl": 169.87806554051448,
    "ttft": 1814967.6897796574,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3001198785007001,
    "arrivals": 287932,
    "finished_requests": 83275,
    "scheduler_time": 51.945475967175305
}
#Debug simulation 
Total elapsed time: 6.097086812369525. Arrivals time: 0.2750928560271859 Scheduler time: 5.721819945145398 Scheduler overhead time: 0.032594313845038414 Adapter cache time: 0.01808076398447156 Engine time: 0.03412458021193743 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-16-32/adapters_96_slots_96_rate_1.6-0.8-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-16-32/adapters_96_slots_96_rate_1.6-0.8-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 8640, 17280, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 17280, 8640, 8640, 1080, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 1080, 17280, 8640, 8640, 8640, 17280, 17280, 1080, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 1080, 1080, 17280, 8640, 17280, 1080, 8640, 17280, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 8640]
Prompts retrieved: 864000 . Total input tokens: 192506673 . Total output tokens: 172939330
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.094347657170147,
    "estimated_duration": 3600.017647743082,
    "input_throughput": 5714.135321779974,
    "output_throughput": 5043.949440465599,
    "total_throughput": 10758.084762245573,
    "itl": 167.7652550279757,
    "ttft": 1817017.9902163984,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3177857702970505,
    "arrivals": 287932,
    "finished_requests": 83123,
    "scheduler_time": 51.54151860395839
}
#Debug simulation 
Total elapsed time: 6.0944838230498135. Arrivals time: 0.26740599097684026 Scheduler time: 5.725489277392626 Scheduler overhead time: 0.0327721550129354 Adapter cache time: 0.018472691532224417 Engine time: 0.03474658401682973 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_16-16-16/adapters_96_slots_96_rate_1.6-0.8-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_16-16-16/adapters_96_slots_96_rate_1.6-0.8-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 8640, 17280, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 17280, 8640, 8640, 1080, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 1080, 17280, 8640, 8640, 8640, 17280, 17280, 1080, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 1080, 1080, 17280, 8640, 17280, 1080, 8640, 17280, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 8640]
Prompts retrieved: 864000 . Total input tokens: 192506673 . Total output tokens: 172939330
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.118483123835176,
    "estimated_duration": 3600.024074494199,
    "input_throughput": 5724.194775807244,
    "output_throughput": 5052.802321205509,
    "total_throughput": 10776.997097012752,
    "itl": 169.87838798800755,
    "ttft": 1814956.098306854,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2870448283106092,
    "arrivals": 287932,
    "finished_requests": 83274,
    "scheduler_time": 51.94519161314569
}
#Debug simulation 
Total elapsed time: 6.118575178086758. Arrivals time: 0.2755959792993963 Scheduler time: 5.742359803523868 Scheduler overhead time: 0.032701312098652124 Adapter cache time: 0.018329081125557423 Engine time: 0.034168196842074394 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_16-16-32/adapters_96_slots_96_rate_1.6-0.8-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_16-16-32/adapters_96_slots_96_rate_1.6-0.8-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 8640, 17280, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 17280, 8640, 8640, 1080, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 1080, 17280, 8640, 8640, 8640, 17280, 17280, 1080, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 1080, 1080, 17280, 8640, 17280, 1080, 8640, 17280, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 8640]
Prompts retrieved: 864000 . Total input tokens: 192506673 . Total output tokens: 172939330
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.106973755173385,
    "estimated_duration": 3600.0226402916273,
    "input_throughput": 5714.1273973581465,
    "output_throughput": 5043.942445464468,
    "total_throughput": 10758.069842822615,
    "itl": 167.7651563004639,
    "ttft": 1817021.7783290523,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.32180989146232575,
    "arrivals": 287932,
    "finished_requests": 83123,
    "scheduler_time": 51.54147418714736
}
#Debug simulation 
Total elapsed time: 6.10708912787959. Arrivals time: 0.27771469857543707 Scheduler time: 5.727516736835241 Scheduler overhead time: 0.03303269948810339 Adapter cache time: 0.018626163713634014 Engine time: 0.034664486069232225 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-8/adapters_96_slots_96_rate_1.6-0.8-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-8/adapters_96_slots_96_rate_1.6-0.8-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 540, 17280, 540, 540, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 8640, 17280, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 540, 17280, 8640, 8640, 540, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 540, 17280, 8640, 8640, 8640, 17280, 17280, 540, 540, 8640, 540, 17280, 540, 540, 17280, 540, 8640, 8640, 540, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 540, 540, 17280, 8640, 17280, 540, 8640, 17280, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 540, 540, 8640]
Prompts retrieved: 846720 . Total input tokens: 188628101 . Total output tokens: 169501607
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.3857107581570745,
    "estimated_duration": 3600.123658156599,
    "input_throughput": 5881.582970636658,
    "output_throughput": 5248.684154831345,
    "total_throughput": 11130.267125468003,
    "itl": 164.8442899532783,
    "ttft": 1780559.0673463272,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29380682341754405,
    "arrivals": 282072,
    "finished_requests": 85668,
    "scheduler_time": 54.158343869348954
}
#Debug simulation 
Total elapsed time: 6.385821938049048. Arrivals time: 0.2847711225040257 Scheduler time: 5.997673828154802 Scheduler overhead time: 0.03377782041206956 Adapter cache time: 0.018208577297627926 Engine time: 0.03534297551959753 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-16/adapters_96_slots_96_rate_1.6-0.8-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-16/adapters_96_slots_96_rate_1.6-0.8-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 540, 17280, 540, 540, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 8640, 17280, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 540, 17280, 8640, 8640, 540, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 540, 17280, 8640, 8640, 8640, 17280, 17280, 540, 540, 8640, 540, 17280, 540, 540, 17280, 540, 8640, 8640, 540, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 540, 540, 17280, 8640, 17280, 540, 8640, 17280, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 540, 540, 8640]
Prompts retrieved: 846720 . Total input tokens: 188628101 . Total output tokens: 169501607
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.3906379961408675,
    "estimated_duration": 3600.024108393695,
    "input_throughput": 5881.366724915426,
    "output_throughput": 5248.540407255983,
    "total_throughput": 11129.90713217141,
    "itl": 164.84389230601556,
    "ttft": 1780533.0720606744,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31319492869079113,
    "arrivals": 282072,
    "finished_requests": 85664,
    "scheduler_time": 54.156498436166515
}
#Debug simulation 
Total elapsed time: 6.390723914839327. Arrivals time: 0.28358617378398776 Scheduler time: 6.003751454874873 Scheduler overhead time: 0.03360815020278096 Adapter cache time: 0.018264499027282 Engine time: 0.03556743497028947 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-32/adapters_96_slots_96_rate_1.6-0.8-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-32/adapters_96_slots_96_rate_1.6-0.8-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 540, 17280, 540, 540, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 8640, 17280, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 540, 17280, 8640, 8640, 540, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 540, 17280, 8640, 8640, 8640, 17280, 17280, 540, 540, 8640, 540, 17280, 540, 540, 17280, 540, 8640, 8640, 540, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 540, 540, 17280, 8640, 17280, 540, 8640, 17280, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 540, 540, 8640]
Prompts retrieved: 846720 . Total input tokens: 188628101 . Total output tokens: 169501607
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.391831687651575,
    "estimated_duration": 3600.049953517579,
    "input_throughput": 5868.632178105368,
    "output_throughput": 5236.558726519889,
    "total_throughput": 11105.190904625257,
    "itl": 162.20314691429004,
    "ttft": 1782617.0316178103,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3137616491317752,
    "arrivals": 282072,
    "finished_requests": 85481,
    "scheduler_time": 53.6174094888843
}
#Debug simulation 
Total elapsed time: 6.391934190876782. Arrivals time: 0.2842600140720606 Scheduler time: 6.002578089013696 Scheduler overhead time: 0.03427965147420764 Adapter cache time: 0.018843880854547024 Engine time: 0.035826240200549364 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-16-16/adapters_96_slots_96_rate_1.6-0.8-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-16-16/adapters_96_slots_96_rate_1.6-0.8-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 540, 17280, 540, 540, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 8640, 17280, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 540, 17280, 8640, 8640, 540, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 540, 17280, 8640, 8640, 8640, 17280, 17280, 540, 540, 8640, 540, 17280, 540, 540, 17280, 540, 8640, 8640, 540, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 540, 540, 17280, 8640, 17280, 540, 8640, 17280, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 540, 540, 8640]
Prompts retrieved: 846720 . Total input tokens: 188628101 . Total output tokens: 169501607
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.38958995603025,
    "estimated_duration": 3600.164019392741,
    "input_throughput": 5881.517310306213,
    "output_throughput": 5248.758361622467,
    "total_throughput": 11130.27567192868,
    "itl": 164.84495354230276,
    "ttft": 1780562.4049547866,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3001198785007002,
    "arrivals": 282072,
    "finished_requests": 85669,
    "scheduler_time": 54.15908092575301
}
#Debug simulation 
Total elapsed time: 6.389706891961396. Arrivals time: 0.2821870129555464 Scheduler time: 6.003893407527357 Scheduler overhead time: 0.03374582342803478 Adapter cache time: 0.018365257885307074 Engine time: 0.03554782224819064 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-16-32/adapters_96_slots_96_rate_1.6-0.8-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-16-32/adapters_96_slots_96_rate_1.6-0.8-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 540, 17280, 540, 540, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 8640, 17280, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 540, 17280, 8640, 8640, 540, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 540, 17280, 8640, 8640, 8640, 17280, 17280, 540, 540, 8640, 540, 17280, 540, 540, 17280, 540, 8640, 8640, 540, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 540, 540, 17280, 8640, 17280, 540, 8640, 17280, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 540, 540, 8640]
Prompts retrieved: 846720 . Total input tokens: 188628101 . Total output tokens: 169501607
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.362094177398831,
    "estimated_duration": 3600.1621584567474,
    "input_throughput": 5868.870642498267,
    "output_throughput": 5236.664675149382,
    "total_throughput": 11105.53531764765,
    "itl": 162.20086582772885,
    "ttft": 1782611.3104005402,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31778577029705046,
    "arrivals": 282072,
    "finished_requests": 85485,
    "scheduler_time": 53.61914392373252
}
#Debug simulation 
Total elapsed time: 6.362201057374477. Arrivals time: 0.2782882512547076 Scheduler time: 5.979489447083324 Scheduler overhead time: 0.03396758669987321 Adapter cache time: 0.018609233666211367 Engine time: 0.03562828619033098 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_16-16-16/adapters_96_slots_96_rate_1.6-0.8-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_16-16-16/adapters_96_slots_96_rate_1.6-0.8-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 540, 17280, 540, 540, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 8640, 17280, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 540, 17280, 8640, 8640, 540, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 540, 17280, 8640, 8640, 8640, 17280, 17280, 540, 540, 8640, 540, 17280, 540, 540, 17280, 540, 8640, 8640, 540, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 540, 540, 17280, 8640, 17280, 540, 8640, 17280, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 540, 540, 8640]
Prompts retrieved: 846720 . Total input tokens: 188628101 . Total output tokens: 169501607
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.3575431583449244,
    "estimated_duration": 3600.0763605987363,
    "input_throughput": 5881.543300508911,
    "output_throughput": 5248.650336088272,
    "total_throughput": 11130.193636597183,
    "itl": 164.84320383704235,
    "ttft": 1780547.9844690524,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2870448283106092,
    "arrivals": 282072,
    "finished_requests": 85667,
    "scheduler_time": 54.15776892719378
}
#Debug simulation 
Total elapsed time: 6.3576315231621265. Arrivals time: 0.27740764059126377 Scheduler time: 5.977313993033022 Scheduler overhead time: 0.03371041361242533 Adapter cache time: 0.017956980038434267 Engine time: 0.0353429508395493 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_16-16-32/adapters_96_slots_96_rate_1.6-0.8-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_16-16-32/adapters_96_slots_96_rate_1.6-0.8-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 540, 17280, 540, 540, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 8640, 17280, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 540, 17280, 8640, 8640, 540, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 540, 17280, 8640, 8640, 8640, 17280, 17280, 540, 540, 8640, 540, 17280, 540, 540, 17280, 540, 8640, 8640, 540, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 540, 540, 17280, 8640, 17280, 540, 8640, 17280, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 540, 540, 8640]
Prompts retrieved: 846720 . Total input tokens: 188628101 . Total output tokens: 169501607
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.378715708386153,
    "estimated_duration": 3600.0582378164477,
    "input_throughput": 5868.618673461915,
    "output_throughput": 5236.546676376623,
    "total_throughput": 11105.165349838537,
    "itl": 162.2022362168121,
    "ttft": 1782623.3448306047,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.32180989146232564,
    "arrivals": 282072,
    "finished_requests": 85481,
    "scheduler_time": 53.617244178532104
}
#Debug simulation 
Total elapsed time: 6.378824676387012. Arrivals time: 0.2850762982852757 Scheduler time: 5.988485465757549 Scheduler overhead time: 0.0342688849195838 Adapter cache time: 0.0188990724273026 Engine time: 0.03587901592254639 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-8/adapters_96_slots_96_rate_1.6-0.8-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-8/adapters_96_slots_96_rate_1.6-0.8-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 270, 17280, 270, 270, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 8640, 17280, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 270, 17280, 8640, 8640, 270, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 270, 17280, 8640, 8640, 8640, 17280, 17280, 270, 270, 8640, 270, 17280, 270, 270, 17280, 270, 8640, 8640, 270, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 270, 270, 17280, 8640, 17280, 270, 8640, 17280, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 270, 270, 8640]
Prompts retrieved: 838080 . Total input tokens: 186703178 . Total output tokens: 167718589
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.620670082978904,
    "estimated_duration": 3600.0654550111917,
    "input_throughput": 6141.561667781195,
    "output_throughput": 5446.654858095918,
    "total_throughput": 11588.216525877113,
    "itl": 158.3515373608593,
    "ttft": 1741692.0635682002,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29380682341754405,
    "arrivals": 279133,
    "finished_requests": 89107,
    "scheduler_time": 56.15244971841818
}
#Debug simulation 
Total elapsed time: 6.620774909853935. Arrivals time: 0.2959583252668381 Scheduler time: 6.222148982342333 Scheduler overhead time: 0.03485873993486166 Adapter cache time: 0.014571141451597214 Engine time: 0.03672381490468979 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-16/adapters_96_slots_96_rate_1.6-0.8-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-16/adapters_96_slots_96_rate_1.6-0.8-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 270, 17280, 270, 270, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 8640, 17280, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 270, 17280, 8640, 8640, 270, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 270, 17280, 8640, 8640, 8640, 17280, 17280, 270, 270, 8640, 270, 17280, 270, 270, 17280, 270, 8640, 8640, 270, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 270, 270, 17280, 8640, 17280, 270, 8640, 17280, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 270, 270, 8640]
Prompts retrieved: 838080 . Total input tokens: 186703178 . Total output tokens: 167718589
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.583719940390438,
    "estimated_duration": 3600.143709949435,
    "input_throughput": 6141.660939504704,
    "output_throughput": 5446.6795161005975,
    "total_throughput": 11588.340455605303,
    "itl": 158.3519331703695,
    "ttft": 1741694.6460496455,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31319492869079113,
    "arrivals": 279133,
    "finished_requests": 89110,
    "scheduler_time": 56.154012799397115
}
#Debug simulation 
Total elapsed time: 6.583816471975297. Arrivals time: 0.2876263824291527 Scheduler time: 6.193654866423458 Scheduler overhead time: 0.034871555399149656 Adapter cache time: 0.014356419909745455 Engine time: 0.036905976478010416 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-32/adapters_96_slots_96_rate_1.6-0.8-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-32/adapters_96_slots_96_rate_1.6-0.8-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 270, 17280, 270, 270, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 8640, 17280, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 270, 17280, 8640, 8640, 270, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 270, 17280, 8640, 8640, 8640, 17280, 17280, 270, 270, 8640, 270, 17280, 270, 270, 17280, 270, 8640, 8640, 270, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 270, 270, 17280, 8640, 17280, 270, 8640, 17280, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 270, 270, 8640]
Prompts retrieved: 838080 . Total input tokens: 186703178 . Total output tokens: 167718589
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.561851106118411,
    "estimated_duration": 3600.0205526921377,
    "input_throughput": 6126.908354316344,
    "output_throughput": 5435.623967581671,
    "total_throughput": 11562.532321898016,
    "itl": 156.0809581021222,
    "ttft": 1744056.8930565075,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31376164913177523,
    "arrivals": 279133,
    "finished_requests": 88908,
    "scheduler_time": 55.61614049300679
}
#Debug simulation 
Total elapsed time: 6.561963649932295. Arrivals time: 0.293042846955359 Scheduler time: 6.165476834401488 Scheduler overhead time: 0.03526050876826048 Adapter cache time: 0.014844685327261686 Engine time: 0.03652384411543608 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-16-16/adapters_96_slots_96_rate_1.6-0.8-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-16-16/adapters_96_slots_96_rate_1.6-0.8-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 270, 17280, 270, 270, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 8640, 17280, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 270, 17280, 8640, 8640, 270, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 270, 17280, 8640, 8640, 8640, 17280, 17280, 270, 270, 8640, 270, 17280, 270, 270, 17280, 270, 8640, 8640, 270, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 270, 270, 17280, 8640, 17280, 270, 8640, 17280, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 270, 270, 8640]
Prompts retrieved: 838080 . Total input tokens: 186703178 . Total output tokens: 167718589
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.599085528403521,
    "estimated_duration": 3600.0745287562318,
    "input_throughput": 6141.546188389233,
    "output_throughput": 5446.641130169703,
    "total_throughput": 11588.187318558936,
    "itl": 158.35168346433957,
    "ttft": 1741698.663828858,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.30011987850070015,
    "arrivals": 279133,
    "finished_requests": 89107,
    "scheduler_time": 56.152382619071865
}
#Debug simulation 
Total elapsed time: 6.599169539287686. Arrivals time: 0.29302210034802556 Scheduler time: 6.2039921609684825 Scheduler overhead time: 0.034842658787965775 Adapter cache time: 0.01462499238550663 Engine time: 0.03608188172802329 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-16-32/adapters_96_slots_96_rate_1.6-0.8-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-16-32/adapters_96_slots_96_rate_1.6-0.8-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 270, 17280, 270, 270, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 8640, 17280, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 270, 17280, 8640, 8640, 270, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 270, 17280, 8640, 8640, 8640, 17280, 17280, 270, 270, 8640, 270, 17280, 270, 270, 17280, 270, 8640, 8640, 270, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 270, 270, 17280, 8640, 17280, 270, 8640, 17280, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 270, 270, 8640]
Prompts retrieved: 838080 . Total input tokens: 186703178 . Total output tokens: 167718589
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.58993481611833,
    "estimated_duration": 3600.028146457408,
    "input_throughput": 6126.895708219696,
    "output_throughput": 5435.667779224546,
    "total_throughput": 11562.563487444242,
    "itl": 156.0810144968368,
    "ttft": 1744079.767114059,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31778577029705046,
    "arrivals": 279133,
    "finished_requests": 88909,
    "scheduler_time": 55.61677712586669
}
#Debug simulation 
Total elapsed time: 6.590024154167622. Arrivals time: 0.2937203668989241 Scheduler time: 6.1926254141144454 Scheduler overhead time: 0.035387957002967596 Adapter cache time: 0.014547530561685562 Engine time: 0.03698251862078905 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_16-16-16/adapters_96_slots_96_rate_1.6-0.8-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_16-16-16/adapters_96_slots_96_rate_1.6-0.8-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 270, 17280, 270, 270, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 8640, 17280, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 270, 17280, 8640, 8640, 270, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 270, 17280, 8640, 8640, 8640, 17280, 17280, 270, 270, 8640, 270, 17280, 270, 270, 17280, 270, 8640, 8640, 270, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 270, 270, 17280, 8640, 17280, 270, 8640, 17280, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 270, 270, 8640]
Prompts retrieved: 838080 . Total input tokens: 186703178 . Total output tokens: 167718589
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.5943652940914035,
    "estimated_duration": 3600.05016536521,
    "input_throughput": 6141.587751390967,
    "output_throughput": 5446.6779903915085,
    "total_throughput": 11588.265741782476,
    "itl": 158.3514725688907,
    "ttft": 1741684.0531452508,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2870448283106092,
    "arrivals": 279133,
    "finished_requests": 89107,
    "scheduler_time": 56.15243315289061
}
#Debug simulation 
Total elapsed time: 6.59450491797179. Arrivals time: 0.2934216298162937 Scheduler time: 6.198410813231021 Scheduler overhead time: 0.03482353501021862 Adapter cache time: 0.01441985135897994 Engine time: 0.03684427961707115 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_16-16-32/adapters_96_slots_96_rate_1.6-0.8-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_16-16-32/adapters_96_slots_96_rate_1.6-0.8-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 270, 17280, 270, 270, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 8640, 17280, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 270, 17280, 8640, 8640, 270, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 270, 17280, 8640, 8640, 8640, 17280, 17280, 270, 270, 8640, 270, 17280, 270, 270, 17280, 270, 8640, 8640, 270, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 270, 270, 17280, 8640, 17280, 270, 8640, 17280, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 270, 270, 8640]
Prompts retrieved: 838080 . Total input tokens: 186703178 . Total output tokens: 167718589
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.568326711189002,
    "estimated_duration": 3600.095496977115,
    "input_throughput": 6126.999691680739,
    "output_throughput": 5435.632198210101,
    "total_throughput": 11562.63188989084,
    "itl": 156.08262017662838,
    "ttft": 1744063.0238382686,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.32180989146232564,
    "arrivals": 279133,
    "finished_requests": 88913,
    "scheduler_time": 55.618262700098185
}
#Debug simulation 
Total elapsed time: 6.568412428256124. Arrivals time: 0.29077923484146595 Scheduler time: 6.174214125145227 Scheduler overhead time: 0.035268322099000216 Adapter cache time: 0.014545956160873175 Engine time: 0.03686776664108038 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-8/adapters_96_slots_96_rate_1.6-0.8-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-8/adapters_96_slots_96_rate_1.6-0.8-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 8640, 17280, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 135, 17280, 8640, 8640, 135, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 135, 17280, 8640, 8640, 8640, 17280, 17280, 135, 135, 8640, 135, 17280, 135, 135, 17280, 135, 8640, 8640, 135, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 135, 135, 17280, 8640, 17280, 135, 8640, 17280, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 135, 135, 8640]
Prompts retrieved: 833760 . Total input tokens: 185761784 . Total output tokens: 166859550
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.928942226804793,
    "estimated_duration": 3600.070683801569,
    "input_throughput": 6257.755743898537,
    "output_throughput": 5548.615222995165,
    "total_throughput": 11806.370966893703,
    "itl": 155.1571351802471,
    "ttft": 1725067.2363292226,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29380682341754405,
    "arrivals": 277639,
    "finished_requests": 91052,
    "scheduler_time": 57.243578219039556
}
#Debug simulation 
Total elapsed time: 6.929011140950024. Arrivals time: 0.5220314674079418 Scheduler time: 6.3048215778544545 Scheduler overhead time: 0.035630264319479465 Adapter cache time: 0.012361338827759027 Engine time: 0.0374370189383626 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-16/adapters_96_slots_96_rate_1.6-0.8-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-16/adapters_96_slots_96_rate_1.6-0.8-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 8640, 17280, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 135, 17280, 8640, 8640, 135, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 135, 17280, 8640, 8640, 8640, 17280, 17280, 135, 135, 8640, 135, 17280, 135, 135, 17280, 135, 8640, 8640, 135, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 135, 135, 17280, 8640, 17280, 135, 8640, 17280, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 135, 135, 8640]
Prompts retrieved: 833760 . Total input tokens: 185761784 . Total output tokens: 166859550
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.698818588163704,
    "estimated_duration": 3600.1763147710617,
    "input_throughput": 6257.646856785294,
    "output_throughput": 5548.662135807174,
    "total_throughput": 11806.308992592469,
    "itl": 155.15776320091155,
    "ttft": 1725120.9011766317,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31319492869079113,
    "arrivals": 277639,
    "finished_requests": 91055,
    "scheduler_time": 57.24501657246442
}
#Debug simulation 
Total elapsed time: 6.698942854069173. Arrivals time: 0.3220250476151705 Scheduler time: 6.275024119298905 Scheduler overhead time: 0.03548688115552068 Adapter cache time: 0.012121799401938915 Engine time: 0.03741662297397852 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-32/adapters_96_slots_96_rate_1.6-0.8-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-32/adapters_96_slots_96_rate_1.6-0.8-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 8640, 17280, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 135, 17280, 8640, 8640, 135, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 135, 17280, 8640, 8640, 8640, 17280, 17280, 135, 135, 8640, 135, 17280, 135, 135, 17280, 135, 8640, 8640, 135, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 135, 135, 17280, 8640, 17280, 135, 8640, 17280, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 135, 135, 8640]
Prompts retrieved: 833760 . Total input tokens: 185761784 . Total output tokens: 166859550
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.910227763000876,
    "estimated_duration": 3600.0874703323034,
    "input_throughput": 6245.220480135915,
    "output_throughput": 5538.756256430473,
    "total_throughput": 11783.976736566388,
    "itl": 153.18615926050506,
    "ttft": 1725851.3988509213,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3137616491317753,
    "arrivals": 277639,
    "finished_requests": 90864,
    "scheduler_time": 56.73910384417817
}
#Debug simulation 
Total elapsed time: 6.910297449212521. Arrivals time: 0.29988189972937107 Scheduler time: 6.507924577221274 Scheduler overhead time: 0.036031949799507856 Adapter cache time: 0.012095233425498009 Engine time: 0.037391659803688526 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-16/adapters_96_slots_96_rate_1.6-0.8-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-16/adapters_96_slots_96_rate_1.6-0.8-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 8640, 17280, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 135, 17280, 8640, 8640, 135, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 135, 17280, 8640, 8640, 8640, 17280, 17280, 135, 135, 8640, 135, 17280, 135, 135, 17280, 135, 8640, 8640, 135, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 135, 135, 17280, 8640, 17280, 135, 8640, 17280, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 135, 135, 8640]
Prompts retrieved: 833760 . Total input tokens: 185761784 . Total output tokens: 166859550
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.694420221727341,
    "estimated_duration": 3600.082857721486,
    "input_throughput": 6257.734582880777,
    "output_throughput": 5548.5964599833,
    "total_throughput": 11806.331042864078,
    "itl": 155.15726561233922,
    "ttft": 1725073.8556185854,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.30011987850070015,
    "arrivals": 277639,
    "finished_requests": 91052,
    "scheduler_time": 57.24362884643299
}
#Debug simulation 
Total elapsed time: 6.694507501088083. Arrivals time: 0.2961006755940616 Scheduler time: 6.2966872099787 Scheduler overhead time: 0.0355574912391603 Adapter cache time: 0.012104099616408348 Engine time: 0.03727751690894365 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-32/adapters_96_slots_96_rate_1.6-0.8-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-32/adapters_96_slots_96_rate_1.6-0.8-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 8640, 17280, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 135, 17280, 8640, 8640, 135, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 135, 17280, 8640, 8640, 8640, 17280, 17280, 135, 135, 8640, 135, 17280, 135, 135, 17280, 135, 8640, 8640, 135, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 135, 135, 17280, 8640, 17280, 135, 8640, 17280, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 135, 135, 8640]
Prompts retrieved: 833760 . Total input tokens: 185761784 . Total output tokens: 166859550
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.926496904343367,
    "estimated_duration": 3600.090307142507,
    "input_throughput": 6245.215559007924,
    "output_throughput": 5538.751891984328,
    "total_throughput": 11783.967450992252,
    "itl": 153.18598889408173,
    "ttft": 1725853.5638795344,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3177857702970505,
    "arrivals": 277639,
    "finished_requests": 90864,
    "scheduler_time": 56.739077743155434
}
#Debug simulation 
Total elapsed time: 6.926593809388578. Arrivals time: 0.2958181048743427 Scheduler time: 6.528438719920814 Scheduler overhead time: 0.03583760280162096 Adapter cache time: 0.011859494261443615 Engine time: 0.03761557349935174 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-16/adapters_96_slots_96_rate_1.6-0.8-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-16/adapters_96_slots_96_rate_1.6-0.8-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 8640, 17280, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 135, 17280, 8640, 8640, 135, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 135, 17280, 8640, 8640, 8640, 17280, 17280, 135, 135, 8640, 135, 17280, 135, 135, 17280, 135, 8640, 8640, 135, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 135, 135, 17280, 8640, 17280, 135, 8640, 17280, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 135, 135, 8640]
Prompts retrieved: 833760 . Total input tokens: 185761784 . Total output tokens: 166859550
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.704822821076959,
    "estimated_duration": 3600.0244969014216,
    "input_throughput": 6257.832139584157,
    "output_throughput": 5548.563354830685,
    "total_throughput": 11806.39549441484,
    "itl": 155.15670107232683,
    "ttft": 1725047.7294557504,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2870448283106092,
    "arrivals": 277639,
    "finished_requests": 91051,
    "scheduler_time": 57.24262818098119
}
#Debug simulation 
Total elapsed time: 6.7049107728526. Arrivals time: 0.3275317936204374 Scheduler time: 6.276023054961115 Scheduler overhead time: 0.03548065386712551 Adapter cache time: 0.011737545020878315 Engine time: 0.037299023009836674 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-32/adapters_96_slots_96_rate_1.6-0.8-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-32/adapters_96_slots_96_rate_1.6-0.8-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 8640, 17280, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 135, 17280, 8640, 8640, 135, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 135, 17280, 8640, 8640, 8640, 17280, 17280, 135, 135, 8640, 135, 17280, 135, 135, 17280, 135, 8640, 8640, 135, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 135, 135, 17280, 8640, 17280, 135, 8640, 17280, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 135, 135, 8640]
Prompts retrieved: 833760 . Total input tokens: 185761784 . Total output tokens: 166859550
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.892932517919689,
    "estimated_duration": 3600.095806483873,
    "input_throughput": 6245.206019102847,
    "output_throughput": 5538.743431240772,
    "total_throughput": 11783.949450343618,
    "itl": 153.18566860404366,
    "ttft": 1725857.7334037232,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3218098914623257,
    "arrivals": 277639,
    "finished_requests": 90864,
    "scheduler_time": 56.73902494990389
}
#Debug simulation 
Total elapsed time: 6.892996885813773. Arrivals time: 0.5508370688185096 Scheduler time: 6.240093438420445 Scheduler overhead time: 0.0357884974218905 Adapter cache time: 0.01184398215264082 Engine time: 0.03747440502047539 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-8/adapters_96_slots_96_rate_1.6-0.8-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-8/adapters_96_slots_96_rate_1.6-0.8-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 8640, 17280, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 66, 17280, 8640, 8640, 66, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 66, 17280, 8640, 8640, 8640, 17280, 17280, 66, 66, 8640, 66, 17280, 66, 66, 17280, 66, 8640, 8640, 66, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 66, 66, 17280, 8640, 17280, 66, 8640, 17280, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 66, 66, 8640]
Prompts retrieved: 831552 . Total input tokens: 185270176 . Total output tokens: 166411436
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.795754504855722,
    "estimated_duration": 3600.093996048948,
    "input_throughput": 6340.8549957454015,
    "output_throughput": 5640.102181299804,
    "total_throughput": 11980.957177045206,
    "itl": 153.32530534017377,
    "ttft": 1706864.7632555172,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29380682341754405,
    "arrivals": 276898,
    "finished_requests": 92711,
    "scheduler_time": 58.17606954623564
}
#Debug simulation 
Total elapsed time: 6.79588571889326. Arrivals time: 0.3252380187623203 Scheduler time: 6.370001349598169 Scheduler overhead time: 0.035853343084454536 Adapter cache time: 0.009865818545222282 Engine time: 0.03777672071009874 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-16/adapters_96_slots_96_rate_1.6-0.8-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-16/adapters_96_slots_96_rate_1.6-0.8-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 8640, 17280, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 66, 17280, 8640, 8640, 66, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 66, 17280, 8640, 8640, 8640, 17280, 17280, 66, 66, 8640, 66, 17280, 66, 66, 17280, 66, 8640, 8640, 66, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 66, 66, 17280, 8640, 17280, 66, 8640, 17280, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 66, 66, 8640]
Prompts retrieved: 831552 . Total input tokens: 185270176 . Total output tokens: 166411436
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.774758887011558,
    "estimated_duration": 3600.146139005841,
    "input_throughput": 6340.843432067956,
    "output_throughput": 5640.126321540709,
    "total_throughput": 11980.969753608666,
    "itl": 153.32470554959565,
    "ttft": 1706870.5983636384,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3131949286907911,
    "arrivals": 276898,
    "finished_requests": 92712,
    "scheduler_time": 58.1770459018525
}
#Debug simulation 
Total elapsed time: 6.774852394126356. Arrivals time: 0.3017650144174695 Scheduler time: 6.373008684255183 Scheduler overhead time: 0.035857954528182745 Adapter cache time: 0.009725086390972137 Engine time: 0.03744739154353738 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-32/adapters_96_slots_96_rate_1.6-0.8-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-32/adapters_96_slots_96_rate_1.6-0.8-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 8640, 17280, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 66, 17280, 8640, 8640, 66, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 66, 17280, 8640, 8640, 8640, 17280, 17280, 66, 66, 8640, 66, 17280, 66, 66, 17280, 66, 8640, 8640, 66, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 66, 66, 17280, 8640, 17280, 66, 8640, 17280, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 66, 66, 8640]
Prompts retrieved: 831552 . Total input tokens: 185270176 . Total output tokens: 166411436
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.779111131560057,
    "estimated_duration": 3600.09739529587,
    "input_throughput": 6324.4241752322905,
    "output_throughput": 5625.638913675985,
    "total_throughput": 11950.063088908277,
    "itl": 151.47981762597834,
    "ttft": 1708858.2797117357,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31376164913177523,
    "arrivals": 276898,
    "finished_requests": 92485,
    "scheduler_time": 57.67863181118803
}
#Debug simulation 
Total elapsed time: 6.77919819066301. Arrivals time: 0.3011856279335916 Scheduler time: 6.376469950657338 Scheduler overhead time: 0.036252989899367094 Adapter cache time: 0.010148791130632162 Engine time: 0.03790560457855463 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-16/adapters_96_slots_96_rate_1.6-0.8-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-16/adapters_96_slots_96_rate_1.6-0.8-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 8640, 17280, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 66, 17280, 8640, 8640, 66, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 66, 17280, 8640, 8640, 8640, 17280, 17280, 66, 66, 8640, 66, 17280, 66, 66, 17280, 66, 8640, 8640, 66, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 66, 66, 17280, 8640, 17280, 66, 8640, 17280, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 66, 66, 8640]
Prompts retrieved: 831552 . Total input tokens: 185270176 . Total output tokens: 166411436
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.782808851916343,
    "estimated_duration": 3600.0985726610825,
    "input_throughput": 6340.846934956696,
    "output_throughput": 5640.095011340549,
    "total_throughput": 11980.941946297244,
    "itl": 153.32506611507134,
    "ttft": 1706868.1885795072,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.30011987850070015,
    "arrivals": 276898,
    "finished_requests": 92711,
    "scheduler_time": 58.175934410992404
}
#Debug simulation 
Total elapsed time: 6.782932054717094. Arrivals time: 0.2994144959375262 Scheduler time: 6.383325360715389 Scheduler overhead time: 0.03600948676466942 Adapter cache time: 0.009528337512165308 Engine time: 0.037621628027409315 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-32/adapters_96_slots_96_rate_1.6-0.8-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-32/adapters_96_slots_96_rate_1.6-0.8-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 8640, 17280, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 66, 17280, 8640, 8640, 66, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 66, 17280, 8640, 8640, 8640, 17280, 17280, 66, 66, 8640, 66, 17280, 66, 66, 17280, 66, 8640, 8640, 66, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 66, 66, 17280, 8640, 17280, 66, 8640, 17280, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 66, 66, 8640]
Prompts retrieved: 831552 . Total input tokens: 185270176 . Total output tokens: 166411436
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.798281216993928,
    "estimated_duration": 3600.0732777822095,
    "input_throughput": 6324.466543643895,
    "output_throughput": 5625.6766008042405,
    "total_throughput": 11950.143144448135,
    "itl": 151.48465603374976,
    "ttft": 1708839.6598434183,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31778577029705046,
    "arrivals": 276898,
    "finished_requests": 92485,
    "scheduler_time": 57.67919106911971
}
#Debug simulation 
Total elapsed time: 6.798370919190347. Arrivals time: 0.3127171825617552 Scheduler time: 6.383692623581737 Scheduler overhead time: 0.03640888258814812 Adapter cache time: 0.010115135461091995 Engine time: 0.0381797906011343 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-16/adapters_96_slots_96_rate_1.6-0.8-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-16/adapters_96_slots_96_rate_1.6-0.8-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 8640, 17280, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 66, 17280, 8640, 8640, 66, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 66, 17280, 8640, 8640, 8640, 17280, 17280, 66, 66, 8640, 66, 17280, 66, 66, 17280, 66, 8640, 8640, 66, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 66, 66, 17280, 8640, 17280, 66, 8640, 17280, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 66, 66, 8640]
Prompts retrieved: 831552 . Total input tokens: 185270176 . Total output tokens: 166411436
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.797999845817685,
    "estimated_duration": 3600.0404786481427,
    "input_throughput": 6340.787592636137,
    "output_throughput": 5640.1176932390035,
    "total_throughput": 11980.90528587514,
    "itl": 153.3235039984268,
    "ttft": 1706875.379538243,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2870448283106092,
    "arrivals": 276898,
    "finished_requests": 92709,
    "scheduler_time": 58.17538286553932
}
#Debug simulation 
Total elapsed time: 6.798103764653206. Arrivals time: 0.33816968835890293 Scheduler time: 6.359741571359336 Scheduler overhead time: 0.03581583919003606 Adapter cache time: 0.009807114023715258 Engine time: 0.0375527199357748 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-32/adapters_96_slots_96_rate_1.6-0.8-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-32/adapters_96_slots_96_rate_1.6-0.8-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 8640, 17280, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 66, 17280, 8640, 8640, 66, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 66, 17280, 8640, 8640, 8640, 17280, 17280, 66, 66, 8640, 66, 17280, 66, 66, 17280, 66, 8640, 8640, 66, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 66, 66, 17280, 8640, 17280, 66, 8640, 17280, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 66, 66, 8640]
Prompts retrieved: 831552 . Total input tokens: 185270176 . Total output tokens: 166411436
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.766890030819923,
    "estimated_duration": 3600.0859312120283,
    "input_throughput": 6324.199042753096,
    "output_throughput": 5625.355446219005,
    "total_throughput": 11949.5544889721,
    "itl": 151.476417749617,
    "ttft": 1708903.9828036411,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3218098914623256,
    "arrivals": 276898,
    "finished_requests": 92482,
    "scheduler_time": 57.67750010172807
}
#Debug simulation 
Total elapsed time: 6.76701217982918. Arrivals time: 0.32222792180255055 Scheduler time: 6.344210766721517 Scheduler overhead time: 0.036157369147986174 Adapter cache time: 0.009653267450630665 Engine time: 0.03746137861162424 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-8/adapters_96_slots_96_rate_1.6-0.8-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-8/adapters_96_slots_96_rate_1.6-0.8-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 8640, 17280, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 33, 17280, 8640, 8640, 33, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 33, 17280, 8640, 8640, 8640, 17280, 17280, 33, 33, 8640, 33, 17280, 33, 33, 17280, 33, 8640, 8640, 33, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 33, 33, 17280, 8640, 17280, 33, 8640, 17280, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 33, 33, 8640]
Prompts retrieved: 830496 . Total input tokens: 185017985 . Total output tokens: 166201334
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.82754362327978,
    "estimated_duration": 3600.117955953955,
    "input_throughput": 6443.926916792587,
    "output_throughput": 5673.485216288628,
    "total_throughput": 12117.412133081216,
    "itl": 151.49915421491616,
    "ttft": 1700147.2681315902,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 93,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2846253601857458,
    "arrivals": 276581,
    "finished_requests": 93343,
    "scheduler_time": 58.38478239933114
}
#Debug simulation 
Total elapsed time: 6.827630954328924. Arrivals time: 0.32842604722827673 Scheduler time: 6.399445736780763 Scheduler overhead time: 0.03624355187639594 Adapter cache time: 0.007999824360013008 Engine time: 0.03827481810003519 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-16/adapters_96_slots_96_rate_1.6-0.8-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-16/adapters_96_slots_96_rate_1.6-0.8-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 8640, 17280, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 33, 17280, 8640, 8640, 33, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 33, 17280, 8640, 8640, 8640, 17280, 17280, 33, 33, 8640, 33, 17280, 33, 33, 17280, 33, 8640, 8640, 33, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 33, 33, 17280, 8640, 17280, 33, 8640, 17280, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 33, 33, 8640]
Prompts retrieved: 830496 . Total input tokens: 185017985 . Total output tokens: 166201334
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.808386149816215,
    "estimated_duration": 3600.0322649701607,
    "input_throughput": 6443.755859002636,
    "output_throughput": 5673.542762031133,
    "total_throughput": 12117.298621033768,
    "itl": 151.49958355970261,
    "ttft": 1700175.3683358908,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 93,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.30299899185076357,
    "arrivals": 276581,
    "finished_requests": 93340,
    "scheduler_time": 58.383134468263115
}
#Debug simulation 
Total elapsed time: 6.808475782163441. Arrivals time: 0.3019617167301476 Scheduler time: 6.407061136327684 Scheduler overhead time: 0.03616742230951786 Adapter cache time: 0.008242403622716665 Engine time: 0.03785936627537012 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-32/adapters_96_slots_96_rate_1.6-0.8-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-32/adapters_96_slots_96_rate_1.6-0.8-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 8640, 17280, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 33, 17280, 8640, 8640, 33, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 33, 17280, 8640, 8640, 8640, 17280, 17280, 33, 33, 8640, 33, 17280, 33, 33, 17280, 33, 8640, 8640, 33, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 33, 33, 17280, 8640, 17280, 33, 8640, 17280, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 33, 33, 8640]
Prompts retrieved: 830496 . Total input tokens: 185017985 . Total output tokens: 166201334
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.8336639241315424,
    "estimated_duration": 3600.1505505362597,
    "input_throughput": 6430.597186151432,
    "output_throughput": 5659.8496962758545,
    "total_throughput": 12090.446882427286,
    "itl": 149.906431996014,
    "ttft": 1702329.277180311,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 93,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.303619350101799,
    "arrivals": 276581,
    "finished_requests": 93138,
    "scheduler_time": 57.9434614665272
}
#Debug simulation 
Total elapsed time: 6.833777430932969. Arrivals time: 0.30519491573795676 Scheduler time: 6.428191501647234 Scheduler overhead time: 0.03652776591479778 Adapter cache time: 0.008279893547296524 Engine time: 0.03819232899695635 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-16/adapters_96_slots_96_rate_1.6-0.8-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-16/adapters_96_slots_96_rate_1.6-0.8-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 8640, 17280, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 33, 17280, 8640, 8640, 33, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 33, 17280, 8640, 8640, 8640, 17280, 17280, 33, 33, 8640, 33, 17280, 33, 33, 17280, 33, 8640, 8640, 33, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 33, 33, 17280, 8640, 17280, 33, 8640, 17280, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 33, 33, 8640]
Prompts retrieved: 830496 . Total input tokens: 185017985 . Total output tokens: 166201334
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.837001300882548,
    "estimated_duration": 3600.153263570987,
    "input_throughput": 6443.8639973313375,
    "output_throughput": 5673.503460722112,
    "total_throughput": 12117.36745805345,
    "itl": 151.49987357121975,
    "ttft": 1700155.5130137312,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 93,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2907411322975533,
    "arrivals": 276581,
    "finished_requests": 93344,
    "scheduler_time": 58.385232584641585
}
#Debug simulation 
Total elapsed time: 6.837101721670479. Arrivals time: 0.3028370817191899 Scheduler time: 6.434063914231956 Scheduler overhead time: 0.03650088282302022 Adapter cache time: 0.008062362670898438 Engine time: 0.03829619148746133 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-32/adapters_96_slots_96_rate_1.6-0.8-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-32/adapters_96_slots_96_rate_1.6-0.8-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 8640, 17280, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 33, 17280, 8640, 8640, 33, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 33, 17280, 8640, 8640, 8640, 17280, 17280, 33, 33, 8640, 33, 17280, 33, 33, 17280, 33, 8640, 8640, 33, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 33, 33, 17280, 8640, 17280, 33, 8640, 17280, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 33, 33, 8640]
Prompts retrieved: 830496 . Total input tokens: 185017985 . Total output tokens: 166201334
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.812214338220656,
    "estimated_duration": 3600.1567049740765,
    "input_throughput": 6430.586193099254,
    "output_throughput": 5659.840020810073,
    "total_throughput": 12090.426213909326,
    "itl": 149.90575167111794,
    "ttft": 1702334.3378180484,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 93,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.30739196369424454,
    "arrivals": 276581,
    "finished_requests": 93138,
    "scheduler_time": 57.943461285058255
}
#Debug simulation 
Total elapsed time: 6.8123260429129004. Arrivals time: 0.29896075557917356 Scheduler time: 6.413438222836703 Scheduler overhead time: 0.03665656317025423 Adapter cache time: 0.007917564827948809 Engine time: 0.03800212265923619 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-16/adapters_96_slots_96_rate_1.6-0.8-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-16/adapters_96_slots_96_rate_1.6-0.8-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 8640, 17280, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 33, 17280, 8640, 8640, 33, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 33, 17280, 8640, 8640, 8640, 17280, 17280, 33, 33, 8640, 33, 17280, 33, 33, 17280, 33, 8640, 8640, 33, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 33, 33, 17280, 8640, 17280, 33, 8640, 17280, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 33, 33, 8640]
Prompts retrieved: 830496 . Total input tokens: 185017985 . Total output tokens: 166201334
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.819422239903361,
    "estimated_duration": 3600.082641978852,
    "input_throughput": 6443.907906305301,
    "output_throughput": 5673.527535682606,
    "total_throughput": 12117.435441987907,
    "itl": 151.4990722390005,
    "ttft": 1700141.7927330472,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 93,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.27807467742590264,
    "arrivals": 276581,
    "finished_requests": 93342,
    "scheduler_time": 58.38406445479658
}
#Debug simulation 
Total elapsed time: 6.8195458319969475. Arrivals time: 0.2980685052461922 Scheduler time: 6.421969163697213 Scheduler overhead time: 0.03610352333635092 Adapter cache time: 0.007844784762710333 Engine time: 0.03828481351956725 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-32/adapters_96_slots_96_rate_1.6-0.8-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-32/adapters_96_slots_96_rate_1.6-0.8-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 8640, 17280, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 33, 17280, 8640, 8640, 33, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 33, 17280, 8640, 8640, 8640, 17280, 17280, 33, 33, 8640, 33, 17280, 33, 33, 17280, 33, 8640, 8640, 33, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 33, 33, 17280, 8640, 17280, 33, 8640, 17280, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 33, 33, 8640]
Prompts retrieved: 830496 . Total input tokens: 185017985 . Total output tokens: 166201334
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.760920359287411,
    "estimated_duration": 3600.160850511563,
    "input_throughput": 6430.578788364513,
    "output_throughput": 5659.833503579331,
    "total_throughput": 12090.412291943843,
    "itl": 149.90531694862628,
    "ttft": 1702336.621274428,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 93,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3112903310731049,
    "arrivals": 276581,
    "finished_requests": 93138,
    "scheduler_time": 57.94333096141359
}
#Debug simulation 
Total elapsed time: 6.761013777926564. Arrivals time: 0.3254043348133564 Scheduler time: 6.335168271325529 Scheduler overhead time: 0.03657115204259753 Adapter cache time: 0.00809198571369052 Engine time: 0.03845684276893735 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-8/adapters_96_slots_96_rate_1.6-0.4-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-8/adapters_96_slots_96_rate_1.6-0.4-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 1080, 17280, 4320, 1080, 1080, 4320, 17280, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 17280, 4320, 4320, 1080, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 1080, 17280, 4320, 4320, 4320, 17280, 17280, 1080, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 1080, 1080, 17280, 4320, 17280, 1080, 4320, 17280, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 4320]
Prompts retrieved: 725760 . Total input tokens: 161758167 . Total output tokens: 145106966
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.280362878926098,
    "estimated_duration": 3600.110409567364,
    "input_throughput": 5633.7644384738105,
    "output_throughput": 4998.938630374595,
    "total_throughput": 10632.703068848405,
    "itl": 172.10187134251822,
    "ttft": 1745300.669639249,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29380682341754405,
    "arrivals": 241359,
    "finished_requests": 82255,
    "scheduler_time": 51.86080583870894
}
#Debug simulation 
Total elapsed time: 6.280431149061769. Arrivals time: 0.27498714439570904 Scheduler time: 5.905286953784525 Scheduler overhead time: 0.032293207477778196 Adapter cache time: 0.018942926544696093 Engine time: 0.03368694195523858 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-16/adapters_96_slots_96_rate_1.6-0.4-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-16/adapters_96_slots_96_rate_1.6-0.4-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 1080, 17280, 4320, 1080, 1080, 4320, 17280, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 17280, 4320, 4320, 1080, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 1080, 17280, 4320, 4320, 4320, 17280, 17280, 1080, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 1080, 1080, 17280, 4320, 17280, 1080, 4320, 17280, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 4320]
Prompts retrieved: 725760 . Total input tokens: 161758167 . Total output tokens: 145106966
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.087059173267335,
    "estimated_duration": 3600.0003063562526,
    "input_throughput": 5633.683131690541,
    "output_throughput": 4998.990407924453,
    "total_throughput": 10632.673539614994,
    "itl": 172.1023200338219,
    "ttft": 1745279.2000005445,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31319492869079113,
    "arrivals": 241359,
    "finished_requests": 82253,
    "scheduler_time": 51.858862592633095
}
#Debug simulation 
Total elapsed time: 6.087194073945284. Arrivals time: 0.2812825804576278 Scheduler time: 5.704037421382964 Scheduler overhead time: 0.03335684258490801 Adapter cache time: 0.019074957817792892 Engine time: 0.03403076948598027 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-32/adapters_96_slots_96_rate_1.6-0.4-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-32/adapters_96_slots_96_rate_1.6-0.4-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 1080, 17280, 4320, 1080, 1080, 4320, 17280, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 17280, 4320, 4320, 1080, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 1080, 17280, 4320, 4320, 4320, 17280, 17280, 1080, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 1080, 1080, 17280, 4320, 17280, 1080, 4320, 17280, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 4320]
Prompts retrieved: 725760 . Total input tokens: 161758167 . Total output tokens: 145106966
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.046095193363726,
    "estimated_duration": 3600.1282122400953,
    "input_throughput": 5625.963522948341,
    "output_throughput": 4992.055543715573,
    "total_throughput": 10618.019066663914,
    "itl": 169.82617926075807,
    "ttft": 1747061.9454312976,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31376164913177523,
    "arrivals": 241359,
    "finished_requests": 82135,
    "scheduler_time": 51.421439322278445
}
#Debug simulation 
Total elapsed time: 6.046189988031983. Arrivals time: 0.27184767136350274 Scheduler time: 5.672579044941813 Scheduler overhead time: 0.032722583040595055 Adapter cache time: 0.01927762571722269 Engine time: 0.034296523313969374 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-16-16/adapters_96_slots_96_rate_1.6-0.4-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-16-16/adapters_96_slots_96_rate_1.6-0.4-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 1080, 17280, 4320, 1080, 1080, 4320, 17280, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 17280, 4320, 4320, 1080, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 1080, 17280, 4320, 4320, 4320, 17280, 17280, 1080, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 1080, 1080, 17280, 4320, 17280, 1080, 4320, 17280, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 4320]
Prompts retrieved: 725760 . Total input tokens: 161758167 . Total output tokens: 145106966
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.047657779883593,
    "estimated_duration": 3600.131658669088,
    "input_throughput": 5633.731186236117,
    "output_throughput": 4998.909125077139,
    "total_throughput": 10632.640311313255,
    "itl": 172.1024213409843,
    "ttft": 1745309.362908845,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.30011987850070015,
    "arrivals": 241359,
    "finished_requests": 82255,
    "scheduler_time": 51.861089531291285
}
#Debug simulation 
Total elapsed time: 6.047768370248377. Arrivals time: 0.2743432782590389 Scheduler time: 5.673005260527134 Scheduler overhead time: 0.03231858043000102 Adapter cache time: 0.01896211877465248 Engine time: 0.033871762454509735 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-16-32/adapters_96_slots_96_rate_1.6-0.4-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-16-32/adapters_96_slots_96_rate_1.6-0.4-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 1080, 17280, 4320, 1080, 1080, 4320, 17280, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 17280, 4320, 4320, 1080, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 1080, 17280, 4320, 4320, 4320, 17280, 17280, 1080, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 1080, 1080, 17280, 4320, 17280, 1080, 4320, 17280, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 4320]
Prompts retrieved: 725760 . Total input tokens: 161758167 . Total output tokens: 145106966
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.0730487471446395,
    "estimated_duration": 3600.114248302887,
    "input_throughput": 5625.985344645085,
    "output_throughput": 4992.074906642786,
    "total_throughput": 10618.060251287872,
    "itl": 169.83353430210988,
    "ttft": 1747051.455873406,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31778577029705046,
    "arrivals": 241359,
    "finished_requests": 82135,
    "scheduler_time": 51.42218522678579
}
#Debug simulation 
Total elapsed time: 6.073162304237485. Arrivals time: 0.27808206668123603 Scheduler time: 5.692779369652271 Scheduler overhead time: 0.032694883178919554 Adapter cache time: 0.019477441906929016 Engine time: 0.0345789953134954 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_16-16-16/adapters_96_slots_96_rate_1.6-0.4-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_16-16-16/adapters_96_slots_96_rate_1.6-0.4-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 1080, 17280, 4320, 1080, 1080, 4320, 17280, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 17280, 4320, 4320, 1080, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 1080, 17280, 4320, 4320, 4320, 17280, 17280, 1080, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 1080, 1080, 17280, 4320, 17280, 1080, 4320, 17280, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 4320]
Prompts retrieved: 725760 . Total input tokens: 161758167 . Total output tokens: 145106966
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.062853219918907,
    "estimated_duration": 3600.023729101154,
    "input_throughput": 5633.802309704198,
    "output_throughput": 4999.008993891643,
    "total_throughput": 10632.811303595841,
    "itl": 172.1009442437072,
    "ttft": 1745270.3617687854,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2870448283106092,
    "arrivals": 241359,
    "finished_requests": 82254,
    "scheduler_time": 51.85955087721189
}
#Debug simulation 
Total elapsed time: 6.062940584030002. Arrivals time: 0.2751446650363505 Scheduler time: 5.687251100316644 Scheduler overhead time: 0.03231265675276518 Adapter cache time: 0.018775501288473606 Engine time: 0.034205001313239336 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_16-16-32/adapters_96_slots_96_rate_1.6-0.4-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_16-16-32/adapters_96_slots_96_rate_1.6-0.4-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 1080, 17280, 4320, 1080, 1080, 4320, 17280, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 17280, 4320, 4320, 1080, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 1080, 17280, 4320, 4320, 4320, 17280, 17280, 1080, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 1080, 1080, 17280, 4320, 17280, 1080, 4320, 17280, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 4320]
Prompts retrieved: 725760 . Total input tokens: 161758167 . Total output tokens: 145106966
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.062582801096141,
    "estimated_duration": 3600.188452177725,
    "input_throughput": 5626.091597440662,
    "output_throughput": 4992.031455778024,
    "total_throughput": 10618.123053218686,
    "itl": 169.83631418950046,
    "ttft": 1747045.085112775,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.32180989146232564,
    "arrivals": 241359,
    "finished_requests": 82137,
    "scheduler_time": 51.42386381629859
}
#Debug simulation 
Total elapsed time: 6.062668981030583. Arrivals time: 0.27434364752843976 Scheduler time: 5.686527063604444 Scheduler overhead time: 0.03271026210859418 Adapter cache time: 0.01929532317444682 Engine time: 0.03443555114790797 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-8/adapters_96_slots_96_rate_1.6-0.4-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-8/adapters_96_slots_96_rate_1.6-0.4-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 540, 17280, 4320, 540, 540, 4320, 17280, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 540, 17280, 4320, 4320, 540, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 540, 17280, 4320, 4320, 4320, 17280, 17280, 540, 540, 4320, 540, 17280, 540, 540, 17280, 540, 4320, 4320, 540, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 540, 540, 17280, 4320, 17280, 540, 4320, 17280, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 540, 540, 4320]
Prompts retrieved: 708480 . Total input tokens: 157970588 . Total output tokens: 141629128
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.3292590030469,
    "estimated_duration": 3600.1190274431347,
    "input_throughput": 5880.415852537918,
    "output_throughput": 5216.513081051635,
    "total_throughput": 11096.928933589552,
    "itl": 165.08903235470896,
    "ttft": 1691758.1941107744,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29380682341754405,
    "arrivals": 235577,
    "finished_requests": 85918,
    "scheduler_time": 54.19958392449723
}
#Debug simulation 
Total elapsed time: 6.329375277273357. Arrivals time: 0.2846643626689911 Scheduler time: 5.940529318060726 Scheduler overhead time: 0.03370122192427516 Adapter cache time: 0.019174646586179733 Engine time: 0.0353719973936677 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-16/adapters_96_slots_96_rate_1.6-0.4-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-16/adapters_96_slots_96_rate_1.6-0.4-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 540, 17280, 4320, 540, 540, 4320, 17280, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 540, 17280, 4320, 4320, 540, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 540, 17280, 4320, 4320, 4320, 17280, 17280, 540, 540, 4320, 540, 17280, 540, 540, 17280, 540, 4320, 4320, 540, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 540, 540, 17280, 4320, 17280, 540, 4320, 17280, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 540, 540, 4320]
Prompts retrieved: 708480 . Total input tokens: 157970588 . Total output tokens: 141629128
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.562473269179463,
    "estimated_duration": 3600.041671600374,
    "input_throughput": 5880.505541645298,
    "output_throughput": 5216.507394385699,
    "total_throughput": 11097.012936030997,
    "itl": 165.09039311690162,
    "ttft": 1691780.5116643135,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31319492869079113,
    "arrivals": 235577,
    "finished_requests": 85916,
    "scheduler_time": 54.1979740063846
}
#Debug simulation 
Total elapsed time: 6.562567406333983. Arrivals time: 0.28162977704778314 Scheduler time: 6.176846984773874 Scheduler overhead time: 0.033488606568425894 Adapter cache time: 0.018955809995532036 Engine time: 0.03569096140563488 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-32/adapters_96_slots_96_rate_1.6-0.4-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-32/adapters_96_slots_96_rate_1.6-0.4-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 540, 17280, 4320, 540, 540, 4320, 17280, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 540, 17280, 4320, 4320, 540, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 540, 17280, 4320, 4320, 4320, 17280, 17280, 540, 540, 4320, 540, 17280, 540, 540, 17280, 540, 4320, 4320, 540, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 540, 540, 17280, 4320, 17280, 540, 4320, 17280, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 540, 540, 4320]
Prompts retrieved: 708480 . Total input tokens: 157970588 . Total output tokens: 141629128
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.340529385954142,
    "estimated_duration": 3600.0245001438684,
    "input_throughput": 5871.686428566041,
    "output_throughput": 5209.133715409595,
    "total_throughput": 11080.820143975638,
    "itl": 163.46618516230083,
    "ttft": 1692342.3248387715,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3137616491317753,
    "arrivals": 235577,
    "finished_requests": 85790,
    "scheduler_time": 53.87477118297398
}
#Debug simulation 
Total elapsed time: 6.340617877896875. Arrivals time: 0.28189557790756226 Scheduler time: 5.953530624974519 Scheduler overhead time: 0.03384058643132448 Adapter cache time: 0.019580470863729715 Engine time: 0.03567743906751275 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-16-16/adapters_96_slots_96_rate_1.6-0.4-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-16-16/adapters_96_slots_96_rate_1.6-0.4-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 540, 17280, 4320, 540, 540, 4320, 17280, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 540, 17280, 4320, 4320, 540, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 540, 17280, 4320, 4320, 4320, 17280, 17280, 540, 540, 4320, 540, 17280, 540, 540, 17280, 540, 4320, 4320, 540, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 540, 540, 17280, 4320, 17280, 540, 4320, 17280, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 540, 540, 4320]
Prompts retrieved: 708480 . Total input tokens: 157970588 . Total output tokens: 141629128
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.567654489073902,
    "estimated_duration": 3600.160615637296,
    "input_throughput": 5880.3479233807675,
    "output_throughput": 5216.452821140475,
    "total_throughput": 11096.800744521242,
    "itl": 165.0897462387629,
    "ttft": 1691766.3878543566,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.30011987850070015,
    "arrivals": 235577,
    "finished_requests": 85918,
    "scheduler_time": 54.20002548749438
}
#Debug simulation 
Total elapsed time: 6.567745595239103. Arrivals time: 0.2843229155987501 Scheduler time: 6.179310034960508 Scheduler overhead time: 0.03376859566196799 Adapter cache time: 0.019289713352918625 Engine time: 0.035183492582291365 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-16-32/adapters_96_slots_96_rate_1.6-0.4-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-16-32/adapters_96_slots_96_rate_1.6-0.4-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 540, 17280, 4320, 540, 540, 4320, 17280, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 540, 17280, 4320, 4320, 540, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 540, 17280, 4320, 4320, 4320, 17280, 17280, 540, 540, 4320, 540, 17280, 540, 540, 17280, 540, 4320, 4320, 540, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 540, 540, 17280, 4320, 17280, 540, 4320, 17280, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 540, 540, 4320]
Prompts retrieved: 708480 . Total input tokens: 157970588 . Total output tokens: 141629128
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.3407276892103255,
    "estimated_duration": 3600.0293976154167,
    "input_throughput": 5871.678440737597,
    "output_throughput": 5209.126628916308,
    "total_throughput": 11080.805069653905,
    "itl": 163.46599691140423,
    "ttft": 1692346.0734012625,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31778577029705046,
    "arrivals": 235577,
    "finished_requests": 85790,
    "scheduler_time": 53.87473165973543
}
#Debug simulation 
Total elapsed time: 6.340816980227828. Arrivals time: 0.28168202517554164 Scheduler time: 5.954131456092 Scheduler overhead time: 0.03391691902652383 Adapter cache time: 0.019265168346464634 Engine time: 0.03575774189084768 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_16-16-16/adapters_96_slots_96_rate_1.6-0.4-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_16-16-16/adapters_96_slots_96_rate_1.6-0.4-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 540, 17280, 4320, 540, 540, 4320, 17280, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 540, 17280, 4320, 4320, 540, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 540, 17280, 4320, 4320, 4320, 17280, 17280, 540, 540, 4320, 540, 17280, 540, 540, 17280, 540, 4320, 4320, 540, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 540, 540, 17280, 4320, 17280, 540, 4320, 17280, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 540, 540, 4320]
Prompts retrieved: 708480 . Total input tokens: 157970588 . Total output tokens: 141629128
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.566439216025174,
    "estimated_duration": 3600.083260410182,
    "input_throughput": 5880.474274805504,
    "output_throughput": 5216.564907407241,
    "total_throughput": 11097.039182212746,
    "itl": 165.08844026114937,
    "ttft": 1691752.878135489,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2870448283106092,
    "arrivals": 235577,
    "finished_requests": 85918,
    "scheduler_time": 54.19919192939421
}
#Debug simulation 
Total elapsed time: 6.566539105027914. Arrivals time: 0.2863476094789803 Scheduler time: 6.176356416661292 Scheduler overhead time: 0.03355710534378886 Adapter cache time: 0.018760197330266237 Engine time: 0.035642382223159075 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_16-16-32/adapters_96_slots_96_rate_1.6-0.4-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_16-16-32/adapters_96_slots_96_rate_1.6-0.4-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 540, 17280, 4320, 540, 540, 4320, 17280, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 540, 17280, 4320, 4320, 540, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 540, 17280, 4320, 4320, 4320, 17280, 17280, 540, 540, 4320, 540, 17280, 540, 540, 17280, 540, 4320, 4320, 540, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 540, 540, 17280, 4320, 17280, 540, 4320, 17280, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 540, 540, 4320]
Prompts retrieved: 708480 . Total input tokens: 157970588 . Total output tokens: 141629128
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.333076377864927,
    "estimated_duration": 3600.0251038231568,
    "input_throughput": 5871.685443957495,
    "output_throughput": 5209.132841902871,
    "total_throughput": 11080.818285860367,
    "itl": 163.47369553411392,
    "ttft": 1692341.9839556988,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.32180989146232564,
    "arrivals": 235577,
    "finished_requests": 85790,
    "scheduler_time": 53.87557634896939
}
#Debug simulation 
Total elapsed time: 6.33318765508011. Arrivals time: 0.2790393936447799 Scheduler time: 5.9487757505849 Scheduler overhead time: 0.034105897415429354 Adapter cache time: 0.01957977982237935 Engine time: 0.035555881448090076 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-8/adapters_96_slots_96_rate_1.6-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-8/adapters_96_slots_96_rate_1.6-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 4320, 17280, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 17280, 4320, 4320, 270, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 270, 17280, 4320, 4320, 4320, 17280, 17280, 270, 270, 4320, 270, 17280, 270, 270, 17280, 270, 4320, 4320, 270, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 270, 270, 17280, 4320, 17280, 270, 4320, 17280, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 270, 270, 4320]
Prompts retrieved: 699840 . Total input tokens: 156062165 . Total output tokens: 139886480
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.547638517804444,
    "estimated_duration": 3600.0648134933117,
    "input_throughput": 6127.656068112337,
    "output_throughput": 5398.02253758399,
    "total_throughput": 11525.678605696326,
    "itl": 158.99015773154915,
    "ttft": 1656650.0408237956,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29380682341754405,
    "arrivals": 232682,
    "finished_requests": 89064,
    "scheduler_time": 56.03174869410493
}
#Debug simulation 
Total elapsed time: 6.547730043064803. Arrivals time: 0.3116908688098192 Scheduler time: 6.131994462106377 Scheduler overhead time: 0.034883526619523764 Adapter cache time: 0.0164127922616899 Engine time: 0.0362778059206903 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-16/adapters_96_slots_96_rate_1.6-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-16/adapters_96_slots_96_rate_1.6-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 4320, 17280, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 17280, 4320, 4320, 270, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 270, 17280, 4320, 4320, 4320, 17280, 17280, 270, 270, 4320, 270, 17280, 270, 270, 17280, 270, 4320, 4320, 270, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 270, 270, 17280, 4320, 17280, 270, 4320, 17280, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 270, 270, 4320]
Prompts retrieved: 699840 . Total input tokens: 156062165 . Total output tokens: 139886480
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.543713143095374,
    "estimated_duration": 3600.1561628195495,
    "input_throughput": 6127.500586730996,
    "output_throughput": 5397.885569713841,
    "total_throughput": 11525.386156444836,
    "itl": 158.99132511766476,
    "ttft": 1656724.7074216101,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31319492869079113,
    "arrivals": 232682,
    "finished_requests": 89064,
    "scheduler_time": 56.032395740238954
}
#Debug simulation 
Total elapsed time: 6.543803708162159. Arrivals time: 0.321554166264832 Scheduler time: 6.11858213879168 Scheduler overhead time: 0.0346984313800931 Adapter cache time: 0.01639553438872099 Engine time: 0.03606545086950064 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-32/adapters_96_slots_96_rate_1.6-0.4-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-32/adapters_96_slots_96_rate_1.6-0.4-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 4320, 17280, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 17280, 4320, 4320, 270, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 270, 17280, 4320, 4320, 4320, 17280, 17280, 270, 270, 4320, 270, 17280, 270, 270, 17280, 270, 4320, 4320, 270, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 270, 270, 17280, 4320, 17280, 270, 4320, 17280, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 270, 270, 4320]
Prompts retrieved: 699840 . Total input tokens: 156062165 . Total output tokens: 139886480
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.54433629475534,
    "estimated_duration": 3600.0778000287833,
    "input_throughput": 6113.986758792829,
    "output_throughput": 5387.863840010602,
    "total_throughput": 11501.85059880343,
    "itl": 157.00314377786313,
    "ttft": 1659197.6271643338,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3137616491317752,
    "arrivals": 232682,
    "finished_requests": 88887,
    "scheduler_time": 55.5980978599827
}
#Debug simulation 
Total elapsed time: 6.544456836767495. Arrivals time: 0.29616130236536264 Scheduler time: 6.142936592455953 Scheduler overhead time: 0.035212942864745855 Adapter cache time: 0.016765158623456955 Engine time: 0.03667387133464217 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-16-16/adapters_96_slots_96_rate_1.6-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-16-16/adapters_96_slots_96_rate_1.6-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 4320, 17280, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 17280, 4320, 4320, 270, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 270, 17280, 4320, 4320, 4320, 17280, 17280, 270, 270, 4320, 270, 17280, 270, 270, 17280, 270, 4320, 4320, 270, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 270, 270, 17280, 4320, 17280, 270, 4320, 17280, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 270, 270, 4320]
Prompts retrieved: 699840 . Total input tokens: 156062165 . Total output tokens: 139886480
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.548360172193497,
    "estimated_duration": 3600.125956300932,
    "input_throughput": 6127.551998949012,
    "output_throughput": 5397.930860165602,
    "total_throughput": 11525.482859114614,
    "itl": 158.99129131270965,
    "ttft": 1656665.6251409024,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.30011987850070015,
    "arrivals": 232682,
    "finished_requests": 89064,
    "scheduler_time": 56.03215860687217
}
#Debug simulation 
Total elapsed time: 6.54846127005294. Arrivals time: 0.32551379362121224 Scheduler time: 6.118537285830826 Scheduler overhead time: 0.03484806697815657 Adapter cache time: 0.016540194861590862 Engine time: 0.03655743598937988 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-16-32/adapters_96_slots_96_rate_1.6-0.4-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-16-32/adapters_96_slots_96_rate_1.6-0.4-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 4320, 17280, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 17280, 4320, 4320, 270, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 270, 17280, 4320, 4320, 4320, 17280, 17280, 270, 270, 4320, 270, 17280, 270, 270, 17280, 270, 4320, 4320, 270, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 270, 270, 17280, 4320, 17280, 270, 4320, 17280, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 270, 270, 4320]
Prompts retrieved: 699840 . Total input tokens: 156062165 . Total output tokens: 139886480
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.751571709755808,
    "estimated_duration": 3600.0451854349512,
    "input_throughput": 6114.042148429504,
    "output_throughput": 5387.912651339825,
    "total_throughput": 11501.954799769328,
    "itl": 157.00880494243418,
    "ttft": 1659174.1436045414,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31778577029705035,
    "arrivals": 232682,
    "finished_requests": 88887,
    "scheduler_time": 55.59875226761817
}
#Debug simulation 
Total elapsed time: 6.75164172006771. Arrivals time: 0.28943488793447614 Scheduler time: 6.357078866101801 Scheduler overhead time: 0.03517155954614282 Adapter cache time: 0.016523487400263548 Engine time: 0.03672596113756299 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_16-16-16/adapters_96_slots_96_rate_1.6-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_16-16-16/adapters_96_slots_96_rate_1.6-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 4320, 17280, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 17280, 4320, 4320, 270, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 270, 17280, 4320, 4320, 4320, 17280, 17280, 270, 270, 4320, 270, 17280, 270, 270, 17280, 270, 4320, 4320, 270, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 270, 270, 17280, 4320, 17280, 270, 4320, 17280, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 270, 270, 4320]
Prompts retrieved: 699840 . Total input tokens: 156062165 . Total output tokens: 139886480
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.539287946652621,
    "estimated_duration": 3600.042047221871,
    "input_throughput": 6127.694818737888,
    "output_throughput": 5398.056674087042,
    "total_throughput": 11525.751492824931,
    "itl": 158.99017119929266,
    "ttft": 1656627.1284480803,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2870448283106092,
    "arrivals": 232682,
    "finished_requests": 89064,
    "scheduler_time": 56.03149376003043
}
#Debug simulation 
Total elapsed time: 6.539401461835951. Arrivals time: 0.30738570215180516 Scheduler time: 6.127619196195155 Scheduler overhead time: 0.034845867194235325 Adapter cache time: 0.016399510204792023 Engine time: 0.036508691031485796 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_16-16-32/adapters_96_slots_96_rate_1.6-0.4-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_16-16-32/adapters_96_slots_96_rate_1.6-0.4-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 4320, 17280, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 17280, 4320, 4320, 270, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 270, 17280, 4320, 4320, 4320, 17280, 17280, 270, 270, 4320, 270, 17280, 270, 270, 17280, 270, 4320, 4320, 270, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 270, 270, 17280, 4320, 17280, 270, 4320, 17280, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 270, 270, 4320]
Prompts retrieved: 699840 . Total input tokens: 156062165 . Total output tokens: 139886480
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.471451666671783,
    "estimated_duration": 3600.164220845274,
    "input_throughput": 6113.839994452289,
    "output_throughput": 5387.734506023697,
    "total_throughput": 11501.574500475986,
    "itl": 156.99890276723545,
    "ttft": 1659225.7655872346,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3218098914623256,
    "arrivals": 232682,
    "finished_requests": 88887,
    "scheduler_time": 55.597576907391144
}
#Debug simulation 
Total elapsed time: 6.471541109960526. Arrivals time: 0.29404146783053875 Scheduler time: 6.072673316113651 Scheduler overhead time: 0.03500820230692625 Adapter cache time: 0.016674970742315054 Engine time: 0.03670479357242584 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-8/adapters_96_slots_96_rate_1.6-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-8/adapters_96_slots_96_rate_1.6-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 4320, 17280, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 17280, 4320, 4320, 135, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 135, 17280, 4320, 4320, 4320, 17280, 17280, 135, 135, 4320, 135, 17280, 135, 135, 17280, 135, 4320, 4320, 135, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 135, 135, 17280, 4320, 17280, 135, 4320, 17280, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 135, 135, 4320]
Prompts retrieved: 695520 . Total input tokens: 155117441 . Total output tokens: 139015307
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.685897319111973,
    "estimated_duration": 3600.1628484199855,
    "input_throughput": 6250.910846956973,
    "output_throughput": 5532.9949890300695,
    "total_throughput": 11783.905835987041,
    "itl": 155.72722766303116,
    "ttft": 1634619.9601326897,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29380682341754405,
    "arrivals": 231202,
    "finished_requests": 90840,
    "scheduler_time": 57.5646797419341
}
#Debug simulation 
Total elapsed time: 6.685988426208496. Arrivals time: 0.29530119663104415 Scheduler time: 6.287828315980732 Scheduler overhead time: 0.035585543140769005 Adapter cache time: 0.01279515353962779 Engine time: 0.037593923043459654 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-16/adapters_96_slots_96_rate_1.6-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-16/adapters_96_slots_96_rate_1.6-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 4320, 17280, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 17280, 4320, 4320, 135, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 135, 17280, 4320, 4320, 4320, 17280, 17280, 135, 135, 4320, 135, 17280, 135, 135, 17280, 135, 4320, 4320, 135, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 135, 135, 17280, 4320, 17280, 135, 4320, 17280, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 135, 135, 4320]
Prompts retrieved: 695520 . Total input tokens: 155117441 . Total output tokens: 139015307
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.674568976741284,
    "estimated_duration": 3600.069925919167,
    "input_throughput": 6250.71580915322,
    "output_throughput": 5533.010583097004,
    "total_throughput": 11783.726392250224,
    "itl": 155.72759445815024,
    "ttft": 1634626.954752649,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31319492869079113,
    "arrivals": 231202,
    "finished_requests": 90838,
    "scheduler_time": 57.56358725484395
}
#Debug simulation 
Total elapsed time: 6.67469547688961. Arrivals time: 0.29349826695397496 Scheduler time: 6.278729192912579 Scheduler overhead time: 0.03549959836527705 Adapter cache time: 0.012858615256845951 Engine time: 0.03720039827749133 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-32/adapters_96_slots_96_rate_1.6-0.4-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-32/adapters_96_slots_96_rate_1.6-0.4-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 4320, 17280, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 17280, 4320, 4320, 135, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 135, 17280, 4320, 4320, 4320, 17280, 17280, 135, 135, 4320, 135, 17280, 135, 135, 17280, 135, 4320, 4320, 135, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 135, 135, 17280, 4320, 17280, 135, 4320, 17280, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 135, 135, 4320]
Prompts retrieved: 695520 . Total input tokens: 155117441 . Total output tokens: 139015307
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.671173284761608,
    "estimated_duration": 3600.169213123618,
    "input_throughput": 6236.85851158047,
    "output_throughput": 5520.112201269917,
    "total_throughput": 11756.970712850387,
    "itl": 153.56186015549116,
    "ttft": 1637415.4818949648,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31376164913177523,
    "arrivals": 231202,
    "finished_requests": 90627,
    "scheduler_time": 57.02568131807695
}
#Debug simulation 
Total elapsed time: 6.671261882875115. Arrivals time: 0.2974676745943725 Scheduler time: 6.269848841242492 Scheduler overhead time: 0.03603185573592782 Adapter cache time: 0.013225055765360594 Engine time: 0.03764559980481863 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-16/adapters_96_slots_96_rate_1.6-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-16/adapters_96_slots_96_rate_1.6-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 4320, 17280, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 17280, 4320, 4320, 135, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 135, 17280, 4320, 4320, 4320, 17280, 17280, 135, 135, 4320, 135, 17280, 135, 135, 17280, 135, 4320, 4320, 135, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 135, 135, 17280, 4320, 17280, 135, 4320, 17280, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 135, 135, 4320]
Prompts retrieved: 695520 . Total input tokens: 155117441 . Total output tokens: 139015307
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.709516449365765,
    "estimated_duration": 3600.007674499273,
    "input_throughput": 6250.8097300459085,
    "output_throughput": 5532.995982507321,
    "total_throughput": 11783.805712553229,
    "itl": 155.72732869119426,
    "ttft": 1634613.9526146697,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.30011987850070015,
    "arrivals": 231202,
    "finished_requests": 90837,
    "scheduler_time": 57.562048495349785
}
#Debug simulation 
Total elapsed time: 6.709608963225037. Arrivals time: 0.29331120708957314 Scheduler time: 6.3134885327890515 Scheduler overhead time: 0.03537365607917309 Adapter cache time: 0.013088191393762827 Engine time: 0.03745992621406913 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-32/adapters_96_slots_96_rate_1.6-0.4-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-32/adapters_96_slots_96_rate_1.6-0.4-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 4320, 17280, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 17280, 4320, 4320, 135, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 135, 17280, 4320, 4320, 4320, 17280, 17280, 135, 135, 4320, 135, 17280, 135, 135, 17280, 135, 4320, 4320, 135, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 135, 135, 17280, 4320, 17280, 135, 4320, 17280, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 135, 135, 4320]
Prompts retrieved: 695520 . Total input tokens: 155117441 . Total output tokens: 139015307
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.646885565947741,
    "estimated_duration": 3600.009838827453,
    "input_throughput": 6236.912954469333,
    "output_throughput": 5519.961025015535,
    "total_throughput": 11756.873979484868,
    "itl": 153.55524201680632,
    "ttft": 1637387.351286608,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3177857702970504,
    "arrivals": 231202,
    "finished_requests": 90622,
    "scheduler_time": 57.02160843635659
}
#Debug simulation 
Total elapsed time: 6.647000222001225. Arrivals time: 0.3133956203237176 Scheduler time: 6.229979241266847 Scheduler overhead time: 0.03606227319687605 Adapter cache time: 0.01314172288402915 Engine time: 0.03735780017450452 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-16/adapters_96_slots_96_rate_1.6-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-16/adapters_96_slots_96_rate_1.6-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 4320, 17280, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 17280, 4320, 4320, 135, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 135, 17280, 4320, 4320, 4320, 17280, 17280, 135, 135, 4320, 135, 17280, 135, 135, 17280, 135, 4320, 4320, 135, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 135, 135, 17280, 4320, 17280, 135, 4320, 17280, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 135, 135, 4320]
Prompts retrieved: 695520 . Total input tokens: 155117441 . Total output tokens: 139015307
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.680168883409351,
    "estimated_duration": 3600.1019312422654,
    "input_throughput": 6250.859400593353,
    "output_throughput": 5532.989726523259,
    "total_throughput": 11783.849127116613,
    "itl": 155.7257207157675,
    "ttft": 1634621.35539159,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2870448283106092,
    "arrivals": 231202,
    "finished_requests": 90839,
    "scheduler_time": 57.564120633690244
}
#Debug simulation 
Total elapsed time: 6.680255257990211. Arrivals time: 0.2978291427716613 Scheduler time: 6.279542989097536 Scheduler overhead time: 0.03554809279739857 Adapter cache time: 0.013305844739079475 Engine time: 0.03713252209126949 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-32/adapters_96_slots_96_rate_1.6-0.4-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-32/adapters_96_slots_96_rate_1.6-0.4-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 4320, 17280, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 17280, 4320, 4320, 135, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 135, 17280, 4320, 4320, 4320, 17280, 17280, 135, 135, 4320, 135, 17280, 135, 135, 17280, 135, 4320, 4320, 135, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 135, 135, 17280, 4320, 17280, 135, 4320, 17280, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 135, 135, 4320]
Prompts retrieved: 695520 . Total input tokens: 155117441 . Total output tokens: 139015307
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.685327285900712,
    "estimated_duration": 3600.016642651603,
    "input_throughput": 6236.901167062999,
    "output_throughput": 5519.9505926070615,
    "total_throughput": 11756.85175967006,
    "itl": 153.55522925594832,
    "ttft": 1637392.3091158639,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.32180989146232564,
    "arrivals": 231202,
    "finished_requests": 90622,
    "scheduler_time": 57.02160548029009
}
#Debug simulation 
Total elapsed time: 6.685430891811848. Arrivals time: 0.32892483612522483 Scheduler time: 6.2523133447393775 Scheduler overhead time: 0.0358961122110486 Adapter cache time: 0.01351126004010439 Engine time: 0.037776483222842216 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-8/adapters_96_slots_96_rate_1.6-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-8/adapters_96_slots_96_rate_1.6-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 4320, 17280, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 66, 17280, 4320, 4320, 66, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 66, 17280, 4320, 4320, 4320, 17280, 17280, 66, 66, 4320, 66, 17280, 66, 66, 17280, 66, 4320, 4320, 66, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 66, 66, 17280, 4320, 17280, 66, 4320, 17280, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 66, 66, 4320]
Prompts retrieved: 693312 . Total input tokens: 154620069 . Total output tokens: 138577647
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.9937528958544135,
    "estimated_duration": 3600.149822248656,
    "input_throughput": 6315.53744221637,
    "output_throughput": 5614.408287979284,
    "total_throughput": 11929.945730195654,
    "itl": 153.81579637129906,
    "ttft": 1620449.5881216745,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29380682341754405,
    "arrivals": 230450,
    "finished_requests": 91959,
    "scheduler_time": 58.463741915311154
}
#Debug simulation 
Total elapsed time: 6.993871997110546. Arrivals time: 0.522558621596545 Scheduler time: 6.369565284345299 Scheduler overhead time: 0.03573300875723362 Adapter cache time: 0.01129194162786007 Engine time: 0.03758155647665262 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-16/adapters_96_slots_96_rate_1.6-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-16/adapters_96_slots_96_rate_1.6-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 4320, 17280, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 66, 17280, 4320, 4320, 66, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 66, 17280, 4320, 4320, 4320, 17280, 17280, 66, 66, 4320, 66, 17280, 66, 66, 17280, 66, 4320, 4320, 66, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 66, 66, 17280, 4320, 17280, 66, 4320, 17280, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 66, 66, 4320]
Prompts retrieved: 693312 . Total input tokens: 154620069 . Total output tokens: 138577647
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.773820552974939,
    "estimated_duration": 3600.032310922021,
    "input_throughput": 6315.6849817764005,
    "output_throughput": 5614.533219237491,
    "total_throughput": 11930.218201013891,
    "itl": 153.81590107786587,
    "ttft": 1620414.9795039769,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31319492869079113,
    "arrivals": 230450,
    "finished_requests": 91957,
    "scheduler_time": 58.46152935878899
}
#Debug simulation 
Total elapsed time: 6.77390852291137. Arrivals time: 0.3014282835647464 Scheduler time: 6.370736015960574 Scheduler overhead time: 0.03594342619180679 Adapter cache time: 0.010960632935166359 Engine time: 0.037722425535321236 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-32/adapters_96_slots_96_rate_1.6-0.4-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-32/adapters_96_slots_96_rate_1.6-0.4-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 4320, 17280, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 66, 17280, 4320, 4320, 66, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 66, 17280, 4320, 4320, 4320, 17280, 17280, 66, 66, 4320, 66, 17280, 66, 66, 17280, 66, 4320, 4320, 66, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 66, 66, 17280, 4320, 17280, 66, 4320, 17280, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 66, 66, 4320]
Prompts retrieved: 693312 . Total input tokens: 154620069 . Total output tokens: 138577647
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.757397408597171,
    "estimated_duration": 3600.0166075332745,
    "input_throughput": 6297.724002871963,
    "output_throughput": 5598.788616092156,
    "total_throughput": 11896.51261896412,
    "itl": 151.49502353092313,
    "ttft": 1623630.925915603,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31376164913177523,
    "arrivals": 230450,
    "finished_requests": 91690,
    "scheduler_time": 57.85672919923803
}
#Debug simulation 
Total elapsed time: 6.757484208792448. Arrivals time: 0.2992738396860659 Scheduler time: 6.355146196205169 Scheduler overhead time: 0.03645800752565265 Adapter cache time: 0.01108326530084014 Engine time: 0.03818199597299099 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-16/adapters_96_slots_96_rate_1.6-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-16/adapters_96_slots_96_rate_1.6-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 4320, 17280, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 66, 17280, 4320, 4320, 66, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 66, 17280, 4320, 4320, 4320, 17280, 17280, 66, 66, 4320, 66, 17280, 66, 66, 17280, 66, 4320, 4320, 66, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 66, 66, 17280, 4320, 17280, 66, 4320, 17280, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 66, 66, 4320]
Prompts retrieved: 693312 . Total input tokens: 154620069 . Total output tokens: 138577647
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.733230167999864,
    "estimated_duration": 3600.010446228358,
    "input_throughput": 6315.723340142151,
    "output_throughput": 5614.5673191521255,
    "total_throughput": 11930.290659294276,
    "itl": 153.81566346842828,
    "ttft": 1620404.7590737713,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.30011987850070015,
    "arrivals": 230450,
    "finished_requests": 91957,
    "scheduler_time": 58.46162483930188
}
#Debug simulation 
Total elapsed time: 6.73334595002234. Arrivals time: 0.29384454572573304 Scheduler time: 6.338279880117625 Scheduler overhead time: 0.03592409659177065 Adapter cache time: 0.010974002070724964 Engine time: 0.03726163459941745 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-32/adapters_96_slots_96_rate_1.6-0.4-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-32/adapters_96_slots_96_rate_1.6-0.4-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 4320, 17280, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 66, 17280, 4320, 4320, 66, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 66, 17280, 4320, 4320, 4320, 17280, 17280, 66, 66, 4320, 66, 17280, 66, 66, 17280, 66, 4320, 4320, 66, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 66, 66, 17280, 4320, 17280, 66, 4320, 17280, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 66, 66, 4320]
Prompts retrieved: 693312 . Total input tokens: 154620069 . Total output tokens: 138577647
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.7456137291155756,
    "estimated_duration": 3600.0179042450063,
    "input_throughput": 6297.721734457524,
    "output_throughput": 5598.786599431385,
    "total_throughput": 11896.508333888909,
    "itl": 151.49487418501965,
    "ttft": 1623629.1543235763,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3177857702970504,
    "arrivals": 230450,
    "finished_requests": 91690,
    "scheduler_time": 57.85662004791723
}
#Debug simulation 
Total elapsed time: 6.745703968219459. Arrivals time: 0.30028656125068665 Scheduler time: 6.342432808596641 Scheduler overhead time: 0.036464601289480925 Adapter cache time: 0.01146449614316225 Engine time: 0.03781465906649828 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-16/adapters_96_slots_96_rate_1.6-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-16/adapters_96_slots_96_rate_1.6-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 4320, 17280, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 66, 17280, 4320, 4320, 66, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 66, 17280, 4320, 4320, 4320, 17280, 17280, 66, 66, 4320, 66, 17280, 66, 66, 17280, 66, 4320, 4320, 66, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 66, 66, 17280, 4320, 17280, 66, 4320, 17280, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 66, 66, 4320]
Prompts retrieved: 693312 . Total input tokens: 154620069 . Total output tokens: 138577647
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.74062439519912,
    "estimated_duration": 3600.1321795183662,
    "input_throughput": 6315.56839200326,
    "output_throughput": 5614.435801827727,
    "total_throughput": 11930.004193830986,
    "itl": 153.8158471937384,
    "ttft": 1620441.2691139998,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2870448283106092,
    "arrivals": 230450,
    "finished_requests": 91959,
    "scheduler_time": 58.46366880443269
}
#Debug simulation 
Total elapsed time: 6.740711762104183. Arrivals time: 0.30028452118858695 Scheduler time: 6.339263906236738 Scheduler overhead time: 0.03564636176452041 Adapter cache time: 0.011172573547810316 Engine time: 0.037325577810406685 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-32/adapters_96_slots_96_rate_1.6-0.4-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-32/adapters_96_slots_96_rate_1.6-0.4-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 4320, 17280, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 66, 17280, 4320, 4320, 66, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 66, 17280, 4320, 4320, 4320, 17280, 17280, 66, 66, 4320, 66, 17280, 66, 66, 17280, 66, 4320, 4320, 66, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 66, 66, 17280, 4320, 17280, 66, 4320, 17280, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 66, 66, 4320]
Prompts retrieved: 693312 . Total input tokens: 154620069 . Total output tokens: 138577647
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.738595339935273,
    "estimated_duration": 3600.0286522713404,
    "input_throughput": 6297.702932362989,
    "output_throughput": 5598.76988403503,
    "total_throughput": 11896.47281639802,
    "itl": 151.49477069090423,
    "ttft": 1623635.9632122708,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.32180989146232564,
    "arrivals": 230450,
    "finished_requests": 91690,
    "scheduler_time": 57.856615558161494
}
#Debug simulation 
Total elapsed time: 6.738706721924245. Arrivals time: 0.3012188938446343 Scheduler time: 6.334073604550213 Scheduler overhead time: 0.036536023020744324 Adapter cache time: 0.011386493686586618 Engine time: 0.03816607501357794 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-8/adapters_96_slots_96_rate_1.6-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-8/adapters_96_slots_96_rate_1.6-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 4320, 17280, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 33, 17280, 4320, 4320, 33, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 33, 17280, 4320, 4320, 4320, 17280, 17280, 33, 33, 4320, 33, 17280, 33, 33, 17280, 33, 4320, 4320, 33, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 33, 33, 17280, 4320, 17280, 33, 4320, 17280, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 33, 33, 4320]
Prompts retrieved: 692256 . Total input tokens: 154379477 . Total output tokens: 138362450
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.828171375673264,
    "estimated_duration": 3600.1464507689293,
    "input_throughput": 6369.3092249351275,
    "output_throughput": 5665.520355607649,
    "total_throughput": 12034.829580542777,
    "itl": 152.5782367486996,
    "ttft": 1612668.4686080052,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 94,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.28768584792967855,
    "arrivals": 230128,
    "finished_requests": 92606,
    "scheduler_time": 58.98196595303157
}
#Debug simulation 
Total elapsed time: 6.828274497762322. Arrivals time: 0.30355243338271976 Scheduler time: 6.424642079975456 Scheduler overhead time: 0.03601775551214814 Adapter cache time: 0.009011644404381514 Engine time: 0.03790324879810214 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-16/adapters_96_slots_96_rate_1.6-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-16/adapters_96_slots_96_rate_1.6-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 4320, 17280, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 33, 17280, 4320, 4320, 33, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 33, 17280, 4320, 4320, 4320, 17280, 17280, 33, 33, 4320, 33, 17280, 33, 33, 17280, 33, 4320, 4320, 33, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 33, 33, 17280, 4320, 17280, 33, 4320, 17280, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 33, 33, 4320]
Prompts retrieved: 692256 . Total input tokens: 154379477 . Total output tokens: 138362450
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.8094153688289225,
    "estimated_duration": 3600.122469671095,
    "input_throughput": 6369.351652110577,
    "output_throughput": 5665.5580947121025,
    "total_throughput": 12034.90974682268,
    "itl": 152.57997215385376,
    "ttft": 1612665.7756530903,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 94,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.30680623278254643,
    "arrivals": 230128,
    "finished_requests": 92606,
    "scheduler_time": 58.98175650422181
}
#Debug simulation 
Total elapsed time: 6.8095073639415205. Arrivals time: 0.31938520539551973 Scheduler time: 6.390115238726139 Scheduler overhead time: 0.03613680321723223 Adapter cache time: 0.009277336299419403 Engine time: 0.03759046969935298 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-32/adapters_96_slots_96_rate_1.6-0.4-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-32/adapters_96_slots_96_rate_1.6-0.4-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 4320, 17280, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 33, 17280, 4320, 4320, 33, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 33, 17280, 4320, 4320, 4320, 17280, 17280, 33, 33, 4320, 33, 17280, 33, 33, 17280, 33, 4320, 4320, 33, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 33, 33, 17280, 4320, 17280, 33, 4320, 17280, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 33, 33, 4320]
Prompts retrieved: 692256 . Total input tokens: 154379477 . Total output tokens: 138362450
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.747839257121086,
    "estimated_duration": 3600.0733448663964,
    "input_throughput": 6350.142291572785,
    "output_throughput": 5649.57934232165,
    "total_throughput": 11999.721633894436,
    "itl": 150.38871077191328,
    "ttft": 1615629.953443119,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 94,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3073373639397326,
    "arrivals": 230128,
    "finished_requests": 92331,
    "scheduler_time": 58.38095927068535
}
#Debug simulation 
Total elapsed time: 6.747963995207101. Arrivals time: 0.3001368981786072 Scheduler time: 6.3467590836808085 Scheduler overhead time: 0.036378140561282635 Adapter cache time: 0.009449557401239872 Engine time: 0.03793000057339668 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-16/adapters_96_slots_96_rate_1.6-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-16/adapters_96_slots_96_rate_1.6-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 4320, 17280, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 33, 17280, 4320, 4320, 33, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 33, 17280, 4320, 4320, 4320, 17280, 17280, 33, 33, 4320, 33, 17280, 33, 33, 17280, 33, 4320, 4320, 33, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 33, 33, 17280, 4320, 17280, 33, 4320, 17280, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 33, 33, 4320]
Prompts retrieved: 692256 . Total input tokens: 154379477 . Total output tokens: 138362450
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.799430049024522,
    "estimated_duration": 3600.0732419796154,
    "input_throughput": 6369.438747138089,
    "output_throughput": 5665.635566009824,
    "total_throughput": 12035.074313147912,
    "itl": 152.57986310083018,
    "ttft": 1612639.4932154806,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 94,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2941397779108958,
    "arrivals": 230128,
    "finished_requests": 92606,
    "scheduler_time": 58.981206123623636
}
#Debug simulation 
Total elapsed time: 6.799513360951096. Arrivals time: 0.29914887715131044 Scheduler time: 6.400562449358404 Scheduler overhead time: 0.03604975529015064 Adapter cache time: 0.009055892005562782 Engine time: 0.037662896793335676 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-32/adapters_96_slots_96_rate_1.6-0.4-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-32/adapters_96_slots_96_rate_1.6-0.4-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 4320, 17280, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 33, 17280, 4320, 4320, 33, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 33, 17280, 4320, 4320, 4320, 17280, 17280, 33, 33, 4320, 33, 17280, 33, 33, 17280, 33, 4320, 4320, 33, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 33, 33, 17280, 4320, 17280, 33, 4320, 17280, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 33, 33, 4320]
Prompts retrieved: 692256 . Total input tokens: 154379477 . Total output tokens: 138362450
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.797296294942498,
    "estimated_duration": 3600.0527195358345,
    "input_throughput": 6350.178672646643,
    "output_throughput": 5649.61170974806,
    "total_throughput": 11999.790382394702,
    "itl": 150.39350750687075,
    "ttft": 1615631.3355267416,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 94,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31123573131859295,
    "arrivals": 230128,
    "finished_requests": 92331,
    "scheduler_time": 58.382421805856744
}
#Debug simulation 
Total elapsed time: 6.79738665279001. Arrivals time: 0.2968908906914294 Scheduler time: 6.399240039288998 Scheduler overhead time: 0.03650348447263241 Adapter cache time: 0.009294183924794197 Engine time: 0.03819139814004302 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-16/adapters_96_slots_96_rate_1.6-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-16/adapters_96_slots_96_rate_1.6-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 4320, 17280, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 33, 17280, 4320, 4320, 33, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 33, 17280, 4320, 4320, 4320, 17280, 17280, 33, 33, 4320, 33, 17280, 33, 33, 17280, 33, 4320, 4320, 33, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 33, 33, 17280, 4320, 17280, 33, 4320, 17280, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 33, 33, 4320]
Prompts retrieved: 692256 . Total input tokens: 154379477 . Total output tokens: 138362450
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.802546544000506,
    "estimated_duration": 3600.1354138015176,
    "input_throughput": 6369.328751383517,
    "output_throughput": 5665.5377244441925,
    "total_throughput": 12034.866475827708,
    "itl": 152.57835602763876,
    "ttft": 1612662.397939042,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 94,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2810647277208048,
    "arrivals": 230128,
    "finished_requests": 92606,
    "scheduler_time": 58.98191471102672
}
#Debug simulation 
Total elapsed time: 6.802661556750536. Arrivals time: 0.30005049938336015 Scheduler time: 6.402795689646155 Scheduler overhead time: 0.035979599226266146 Adapter cache time: 0.009004917927086353 Engine time: 0.03765004873275757 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-32/adapters_96_slots_96_rate_1.6-0.4-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-32/adapters_96_slots_96_rate_1.6-0.4-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 4320, 17280, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 33, 17280, 4320, 4320, 33, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 33, 17280, 4320, 4320, 4320, 17280, 17280, 33, 33, 4320, 33, 17280, 33, 33, 17280, 33, 4320, 4320, 33, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 33, 33, 17280, 4320, 17280, 33, 4320, 17280, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 33, 33, 4320]
Prompts retrieved: 692256 . Total input tokens: 154379477 . Total output tokens: 138362450
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.8100951430387795,
    "estimated_duration": 3600.048093713381,
    "input_throughput": 6350.186832204049,
    "output_throughput": 5649.618969123496,
    "total_throughput": 11999.805801327544,
    "itl": 150.3933908043322,
    "ttft": 1615627.9523518546,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 94,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3152598524838682,
    "arrivals": 230128,
    "finished_requests": 92331,
    "scheduler_time": 58.38215360164924
}
#Debug simulation 
Total elapsed time: 6.810196025762707. Arrivals time: 0.30013938434422016 Scheduler time: 6.40898149786517 Scheduler overhead time: 0.036227159202098846 Adapter cache time: 0.009218056686222553 Engine time: 0.038316851016134024 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-8/adapters_96_slots_96_rate_1.6-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-8/adapters_96_slots_96_rate_1.6-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 1080, 17280, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 17280, 1080, 1080, 540, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 540, 17280, 1080, 1080, 1080, 17280, 17280, 540, 540, 1080, 540, 17280, 540, 540, 17280, 540, 1080, 1080, 540, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 540, 540, 17280, 1080, 17280, 540, 1080, 17280, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 540, 540, 1080]
Prompts retrieved: 604800 . Total input tokens: 134810828 . Total output tokens: 121020589
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.4191407463513315,
    "estimated_duration": 3600.084600175526,
    "input_throughput": 6053.307191430304,
    "output_throughput": 5295.740549838873,
    "total_throughput": 11349.047741269178,
    "itl": 161.36849477289383,
    "ttft": 1591657.0876265117,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29380682341754405,
    "arrivals": 200953,
    "finished_requests": 87537,
    "scheduler_time": 55.40546298953987
}
#Debug simulation 
Total elapsed time: 6.419231943320483. Arrivals time: 0.2760409447364509 Scheduler time: 6.027421899139881 Scheduler overhead time: 0.03447858477011323 Adapter cache time: 0.02881941804662347 Engine time: 0.03617785358801484 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-16/adapters_96_slots_96_rate_1.6-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-16/adapters_96_slots_96_rate_1.6-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 1080, 17280, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 17280, 1080, 1080, 540, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 540, 17280, 1080, 1080, 1080, 17280, 17280, 540, 540, 1080, 540, 17280, 540, 540, 17280, 540, 1080, 1080, 540, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 540, 540, 17280, 1080, 17280, 540, 1080, 17280, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 540, 540, 1080]
Prompts retrieved: 604800 . Total input tokens: 134810828 . Total output tokens: 121020589
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.420578354969621,
    "estimated_duration": 3600.1291330559707,
    "input_throughput": 6053.232590993618,
    "output_throughput": 5295.733373823842,
    "total_throughput": 11348.96596481746,
    "itl": 161.3687451032099,
    "ttft": 1591668.7473666829,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31319492869079113,
    "arrivals": 200953,
    "finished_requests": 87538,
    "scheduler_time": 55.40601384117396
}
#Debug simulation 
Total elapsed time: 6.420683056116104. Arrivals time: 0.2820485457777977 Scheduler time: 6.022609590552747 Scheduler overhead time: 0.0345028406009078 Adapter cache time: 0.028776640072464943 Engine time: 0.036281506065279245 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-32/adapters_96_slots_96_rate_1.6-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-32/adapters_96_slots_96_rate_1.6-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 1080, 17280, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 17280, 1080, 1080, 540, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 540, 17280, 1080, 1080, 1080, 17280, 17280, 540, 540, 1080, 540, 17280, 540, 540, 17280, 540, 1080, 1080, 540, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 540, 540, 17280, 1080, 17280, 540, 1080, 17280, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 540, 540, 1080]
Prompts retrieved: 604800 . Total input tokens: 134810828 . Total output tokens: 121020589
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.415194009896368,
    "estimated_duration": 3600.0233961431836,
    "input_throughput": 6050.6698437949935,
    "output_throughput": 5292.944490420233,
    "total_throughput": 11343.614334215226,
    "itl": 159.58399009452515,
    "ttft": 1592554.4219046584,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31376164913177523,
    "arrivals": 200953,
    "finished_requests": 87491,
    "scheduler_time": 55.096062049644445
}
#Debug simulation 
Total elapsed time: 6.415284479036927. Arrivals time: 0.2826722199097276 Scheduler time: 6.015024888794869 Scheduler overhead time: 0.03474508924409747 Adapter cache time: 0.029565721284598112 Engine time: 0.03670483082532883 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-16-16/adapters_96_slots_96_rate_1.6-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-16-16/adapters_96_slots_96_rate_1.6-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 1080, 17280, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 17280, 1080, 1080, 540, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 540, 17280, 1080, 1080, 1080, 17280, 17280, 540, 540, 1080, 540, 17280, 540, 540, 17280, 540, 1080, 1080, 540, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 540, 540, 17280, 1080, 17280, 540, 1080, 17280, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 540, 540, 1080]
Prompts retrieved: 604800 . Total input tokens: 134810828 . Total output tokens: 121020589
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.454734841827303,
    "estimated_duration": 3600.094305000689,
    "input_throughput": 6053.290873444447,
    "output_throughput": 5295.726274036133,
    "total_throughput": 11349.01714748058,
    "itl": 161.36859907220426,
    "ttft": 1591659.2912102232,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.30011987850070015,
    "arrivals": 200953,
    "finished_requests": 87537,
    "scheduler_time": 55.40553281073958
}
#Debug simulation 
Total elapsed time: 6.454825781285763. Arrivals time: 0.2819616552442312 Scheduler time: 6.056657047942281 Scheduler overhead time: 0.03446169011294842 Adapter cache time: 0.028999097179621458 Engine time: 0.03634185530245304 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-16-32/adapters_96_slots_96_rate_1.6-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-16-32/adapters_96_slots_96_rate_1.6-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 1080, 17280, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 17280, 1080, 1080, 540, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 540, 17280, 1080, 1080, 1080, 17280, 17280, 540, 540, 1080, 540, 17280, 540, 540, 17280, 540, 1080, 1080, 540, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 540, 540, 17280, 1080, 17280, 540, 1080, 17280, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 540, 540, 1080]
Prompts retrieved: 604800 . Total input tokens: 134810828 . Total output tokens: 121020589
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.426117569673806,
    "estimated_duration": 3600.1821683880016,
    "input_throughput": 6050.79964877274,
    "output_throughput": 5293.14937653073,
    "total_throughput": 11343.94902530347,
    "itl": 159.56782527074114,
    "ttft": 1592533.5777176856,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3177857702970505,
    "arrivals": 200953,
    "finished_requests": 87497,
    "scheduler_time": 55.09519056745931
}
#Debug simulation 
Total elapsed time: 6.426230660639703. Arrivals time: 0.2804516302421689 Scheduler time: 6.0278429430909455 Scheduler overhead time: 0.03508063778281212 Adapter cache time: 0.02952027413994074 Engine time: 0.03667543362826109 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_16-16-16/adapters_96_slots_96_rate_1.6-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_16-16-16/adapters_96_slots_96_rate_1.6-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 1080, 17280, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 17280, 1080, 1080, 540, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 540, 17280, 1080, 1080, 1080, 17280, 17280, 540, 540, 1080, 540, 17280, 540, 540, 17280, 540, 1080, 1080, 540, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 540, 540, 17280, 1080, 17280, 540, 1080, 17280, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 540, 540, 1080]
Prompts retrieved: 604800 . Total input tokens: 134810828 . Total output tokens: 121020589
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.433588811196387,
    "estimated_duration": 3600.0073948232875,
    "input_throughput": 6053.437009973064,
    "output_throughput": 5295.854121692948,
    "total_throughput": 11349.291131666012,
    "itl": 161.36674332970674,
    "ttft": 1591654.2544910249,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2870448283106092,
    "arrivals": 200953,
    "finished_requests": 87537,
    "scheduler_time": 55.404628330929086
}
#Debug simulation 
Total elapsed time: 6.433693843893707. Arrivals time: 0.283866036683321 Scheduler time: 6.033601747825742 Scheduler overhead time: 0.03449696721509099 Adapter cache time: 0.0288845244795084 Engine time: 0.036455659195780754 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_16-16-32/adapters_96_slots_96_rate_1.6-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_16-16-32/adapters_96_slots_96_rate_1.6-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 1080, 17280, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 17280, 1080, 1080, 540, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 540, 17280, 1080, 1080, 1080, 17280, 17280, 540, 540, 1080, 540, 17280, 540, 540, 17280, 540, 1080, 1080, 540, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 540, 540, 17280, 1080, 17280, 540, 1080, 17280, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 540, 540, 1080]
Prompts retrieved: 604800 . Total input tokens: 134810828 . Total output tokens: 121020589
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.424432931933552,
    "estimated_duration": 3600.0030329989013,
    "input_throughput": 6050.703791172791,
    "output_throughput": 5292.765263069104,
    "total_throughput": 11343.469054241896,
    "itl": 159.58194068628268,
    "ttft": 1592547.6822205489,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3218098914623257,
    "arrivals": 200953,
    "finished_requests": 87490,
    "scheduler_time": 55.09540998676117
}
#Debug simulation 
Total elapsed time: 6.42452235519886. Arrivals time: 0.28295296523720026 Scheduler time: 6.024338605813682 Scheduler overhead time: 0.03483673091977835 Adapter cache time: 0.02937168162316084 Engine time: 0.036504663061350584 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-8/adapters_96_slots_96_rate_1.6-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-8/adapters_96_slots_96_rate_1.6-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 270, 17280, 1080, 270, 270, 1080, 17280, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 17280, 1080, 1080, 270, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 270, 17280, 1080, 1080, 1080, 17280, 17280, 270, 270, 1080, 270, 17280, 270, 270, 17280, 270, 1080, 1080, 270, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 270, 270, 17280, 1080, 17280, 270, 1080, 17280, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 270, 270, 1080]
Prompts retrieved: 596160 . Total input tokens: 132911004 . Total output tokens: 119303065
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.666691610123962,
    "estimated_duration": 3600.1158998644087,
    "input_throughput": 6225.584570997877,
    "output_throughput": 5519.658408983005,
    "total_throughput": 11745.242979980882,
    "itl": 155.74611734588999,
    "ttft": 1544000.4581514637,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29380682341754405,
    "arrivals": 198151,
    "finished_requests": 90721,
    "scheduler_time": 58.09097886438744
}
#Debug simulation 
Total elapsed time: 6.666827199049294. Arrivals time: 0.2859797761775553 Scheduler time: 6.264793676324189 Scheduler overhead time: 0.03558317944407463 Adapter cache time: 0.026216234546154737 Engine time: 0.037315523717552423 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-16/adapters_96_slots_96_rate_1.6-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-16/adapters_96_slots_96_rate_1.6-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 270, 17280, 1080, 270, 270, 1080, 17280, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 17280, 1080, 1080, 270, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 270, 17280, 1080, 1080, 1080, 17280, 17280, 270, 270, 1080, 270, 17280, 270, 270, 17280, 270, 1080, 1080, 270, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 270, 270, 17280, 1080, 17280, 270, 1080, 17280, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 270, 270, 1080]
Prompts retrieved: 596160 . Total input tokens: 132911004 . Total output tokens: 119303065
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.666917026042938,
    "estimated_duration": 3600.036002496753,
    "input_throughput": 6225.58996200489,
    "output_throughput": 5519.595911323923,
    "total_throughput": 11745.185873328814,
    "itl": 155.74802917751262,
    "ttft": 1544026.9935638667,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31319492869079113,
    "arrivals": 198151,
    "finished_requests": 90719,
    "scheduler_time": 58.08903290526824
}
#Debug simulation 
Total elapsed time: 6.667004471179098. Arrivals time: 0.28267949214205146 Scheduler time: 6.268678053282201 Scheduler overhead time: 0.03556515881791711 Adapter cache time: 0.026221225038170815 Engine time: 0.03695288486778736 
