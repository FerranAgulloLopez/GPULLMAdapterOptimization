INFO 06-01 00:47:15 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:47:15 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_16-16-32/adapters_320_slots_64_rate_1.6-0.8-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_16-16-32/adapters_320_slots_64_rate_1.6-0.8-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 540, 17280, 17280, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 8640, 8640, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 17280, 17280, 8640, 540, 540, 8640, 17280, 17280, 8640, 8640, 540, 540, 8640, 17280, 17280, 540, 17280, 8640, 540, 8640, 17280, 540, 8640, 17280, 17280, 8640, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 8640, 8640, 8640, 540, 8640, 540, 17280, 540, 17280, 8640, 17280, 17280, 540, 17280, 540, 17280, 8640, 540, 540, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 540, 8640, 8640, 540, 17280, 8640, 17280, 17280, 8640, 540, 8640, 8640, 8640, 540, 17280, 8640, 17280, 540, 17280, 540, 540, 8640, 17280, 17280, 8640, 540, 8640, 540, 8640, 17280, 17280, 8640, 540, 8640, 540, 17280, 540, 540, 540, 540, 17280, 8640, 8640, 17280, 8640, 8640, 540, 8640, 17280, 8640, 540, 540, 8640, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 8640, 17280, 8640, 8640, 8640, 540, 17280, 540, 17280, 8640, 540, 8640, 540, 540, 8640, 540, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 540, 540, 17280, 8640, 17280, 8640, 17280, 8640, 540, 8640, 540, 540, 540, 17280, 17280, 8640, 8640, 540, 540, 8640, 540, 17280, 540, 540, 8640, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 8640, 17280, 8640, 540, 8640, 540, 17280, 8640, 8640, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 8640, 540, 8640, 540, 8640, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 8640, 8640, 17280, 540, 17280, 540, 540, 540, 17280, 8640, 17280, 17280, 540, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 17280, 540, 540, 8640, 540, 8640, 8640, 540, 17280, 17280, 17280, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 17280, 540, 540, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2830680 . Total input tokens: 630386708 . Total output tokens: 566081381
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 82.92601158795878,
    "estimated_duration": 3600.1390269260196,
    "input_throughput": 6181.135737694189,
    "output_throughput": 5480.968888262182,
    "total_throughput": 11662.10462595637,
    "itl": 153.0337386694388,
    "ttft": 2042534.625156737,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 480,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6113644637167444,
    "arrivals": 942321,
    "finished_requests": 90274,
    "scheduler_time": 170.2435503777324
}
#Debug simulation 
Total elapsed time: 82.92623726697639. Arrivals time: 0.4830585699528456 Scheduler time: 82.28325866349041 Scheduler overhead time: 0.06059998972341418 Adapter cache time: 0.01736812386661768 Engine time: 0.05912475287914276 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-8/adapters_320_slots_64_rate_1.6-0.8-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-8/adapters_320_slots_64_rate_1.6-0.8-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 270, 17280, 17280, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 8640, 8640, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 17280, 17280, 8640, 270, 270, 8640, 17280, 17280, 8640, 8640, 270, 270, 8640, 17280, 17280, 270, 17280, 8640, 270, 8640, 17280, 270, 8640, 17280, 17280, 8640, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 8640, 8640, 8640, 270, 8640, 270, 17280, 270, 17280, 8640, 17280, 17280, 270, 17280, 270, 17280, 8640, 270, 270, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 270, 8640, 8640, 270, 17280, 8640, 17280, 17280, 8640, 270, 8640, 8640, 8640, 270, 17280, 8640, 17280, 270, 17280, 270, 270, 8640, 17280, 17280, 8640, 270, 8640, 270, 8640, 17280, 17280, 8640, 270, 8640, 270, 17280, 270, 270, 270, 270, 17280, 8640, 8640, 17280, 8640, 8640, 270, 8640, 17280, 8640, 270, 270, 8640, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 8640, 17280, 8640, 8640, 8640, 270, 17280, 270, 17280, 8640, 270, 8640, 270, 270, 8640, 270, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 270, 270, 17280, 8640, 17280, 8640, 17280, 8640, 270, 8640, 270, 270, 270, 17280, 17280, 8640, 8640, 270, 270, 8640, 270, 17280, 270, 270, 8640, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 8640, 17280, 8640, 270, 8640, 270, 17280, 8640, 8640, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 8640, 270, 8640, 270, 8640, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 8640, 8640, 17280, 270, 17280, 270, 270, 270, 17280, 8640, 17280, 17280, 270, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 17280, 270, 270, 8640, 270, 8640, 8640, 270, 17280, 17280, 17280, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 17280, 270, 270, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2802060 . Total input tokens: 624030052 . Total output tokens: 560316778
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 78.6882020602934,
    "estimated_duration": 3600.1550736444533,
    "input_throughput": 6210.87107155214,
    "output_throughput": 5487.56000668628,
    "total_throughput": 11698.43107823842,
    "itl": 153.154807833976,
    "ttft": 2046863.3079817751,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 514,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.573090700381454,
    "arrivals": 932854,
    "finished_requests": 90365,
    "scheduler_time": 170.03118686646837
}
#Debug simulation 
Total elapsed time: 78.68839116906747. Arrivals time: 0.47111513232812285 Scheduler time: 78.06067016115412 Scheduler overhead time: 0.06014426564797759 Adapter cache time: 0.017235899344086647 Engine time: 0.05733071034774184 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-16/adapters_320_slots_64_rate_1.6-0.8-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-16/adapters_320_slots_64_rate_1.6-0.8-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 270, 17280, 17280, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 8640, 8640, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 17280, 17280, 8640, 270, 270, 8640, 17280, 17280, 8640, 8640, 270, 270, 8640, 17280, 17280, 270, 17280, 8640, 270, 8640, 17280, 270, 8640, 17280, 17280, 8640, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 8640, 8640, 8640, 270, 8640, 270, 17280, 270, 17280, 8640, 17280, 17280, 270, 17280, 270, 17280, 8640, 270, 270, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 270, 8640, 8640, 270, 17280, 8640, 17280, 17280, 8640, 270, 8640, 8640, 8640, 270, 17280, 8640, 17280, 270, 17280, 270, 270, 8640, 17280, 17280, 8640, 270, 8640, 270, 8640, 17280, 17280, 8640, 270, 8640, 270, 17280, 270, 270, 270, 270, 17280, 8640, 8640, 17280, 8640, 8640, 270, 8640, 17280, 8640, 270, 270, 8640, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 8640, 17280, 8640, 8640, 8640, 270, 17280, 270, 17280, 8640, 270, 8640, 270, 270, 8640, 270, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 270, 270, 17280, 8640, 17280, 8640, 17280, 8640, 270, 8640, 270, 270, 270, 17280, 17280, 8640, 8640, 270, 270, 8640, 270, 17280, 270, 270, 8640, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 8640, 17280, 8640, 270, 8640, 270, 17280, 8640, 8640, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 8640, 270, 8640, 270, 8640, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 8640, 8640, 17280, 270, 17280, 270, 270, 270, 17280, 8640, 17280, 17280, 270, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 17280, 270, 270, 8640, 270, 8640, 8640, 270, 17280, 17280, 17280, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 17280, 270, 270, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2802060 . Total input tokens: 624030052 . Total output tokens: 560316778
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 81.91602890426293,
    "estimated_duration": 3600.140722946796,
    "input_throughput": 6201.3037039635565,
    "output_throughput": 5484.201179735879,
    "total_throughput": 11685.504883699436,
    "itl": 153.13570544374696,
    "ttft": 2046058.7763392096,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 503,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6421005159686377,
    "arrivals": 932854,
    "finished_requests": 90212,
    "scheduler_time": 170.04163774413746
}
#Debug simulation 
Total elapsed time: 81.9161914321594. Arrivals time: 0.5047980095259845 Scheduler time: 81.25302855297923 Scheduler overhead time: 0.06085220258682966 Adapter cache time: 0.016919597517699003 Engine time: 0.05844412837177515 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-32/adapters_320_slots_64_rate_1.6-0.8-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-32/adapters_320_slots_64_rate_1.6-0.8-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 270, 17280, 17280, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 8640, 8640, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 17280, 17280, 8640, 270, 270, 8640, 17280, 17280, 8640, 8640, 270, 270, 8640, 17280, 17280, 270, 17280, 8640, 270, 8640, 17280, 270, 8640, 17280, 17280, 8640, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 8640, 8640, 8640, 270, 8640, 270, 17280, 270, 17280, 8640, 17280, 17280, 270, 17280, 270, 17280, 8640, 270, 270, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 270, 8640, 8640, 270, 17280, 8640, 17280, 17280, 8640, 270, 8640, 8640, 8640, 270, 17280, 8640, 17280, 270, 17280, 270, 270, 8640, 17280, 17280, 8640, 270, 8640, 270, 8640, 17280, 17280, 8640, 270, 8640, 270, 17280, 270, 270, 270, 270, 17280, 8640, 8640, 17280, 8640, 8640, 270, 8640, 17280, 8640, 270, 270, 8640, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 8640, 17280, 8640, 8640, 8640, 270, 17280, 270, 17280, 8640, 270, 8640, 270, 270, 8640, 270, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 270, 270, 17280, 8640, 17280, 8640, 17280, 8640, 270, 8640, 270, 270, 270, 17280, 17280, 8640, 8640, 270, 270, 8640, 270, 17280, 270, 270, 8640, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 8640, 17280, 8640, 270, 8640, 270, 17280, 8640, 8640, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 8640, 270, 8640, 270, 8640, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 8640, 8640, 17280, 270, 17280, 270, 270, 270, 17280, 8640, 17280, 17280, 270, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 17280, 270, 270, 8640, 270, 8640, 8640, 270, 17280, 17280, 17280, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 17280, 270, 270, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2802060 . Total input tokens: 624030052 . Total output tokens: 560316778
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 81.52505739731714,
    "estimated_duration": 3600.143522202023,
    "input_throughput": 6201.298882202506,
    "output_throughput": 5484.196915550653,
    "total_throughput": 11685.49579775316,
    "itl": 153.13581752174983,
    "ttft": 2046060.0456109243,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 503,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6448796340823273,
    "arrivals": 932854,
    "finished_requests": 90212,
    "scheduler_time": 170.0416578812213
}
#Debug simulation 
Total elapsed time: 81.52523355698213. Arrivals time: 0.566255496814847 Scheduler time: 80.80164145864546 Scheduler overhead time: 0.06008908525109291 Adapter cache time: 0.016481850296258926 Engine time: 0.05870247958227992 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-16-16/adapters_320_slots_64_rate_1.6-0.8-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-16-16/adapters_320_slots_64_rate_1.6-0.8-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 270, 17280, 17280, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 8640, 8640, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 17280, 17280, 8640, 270, 270, 8640, 17280, 17280, 8640, 8640, 270, 270, 8640, 17280, 17280, 270, 17280, 8640, 270, 8640, 17280, 270, 8640, 17280, 17280, 8640, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 8640, 8640, 8640, 270, 8640, 270, 17280, 270, 17280, 8640, 17280, 17280, 270, 17280, 270, 17280, 8640, 270, 270, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 270, 8640, 8640, 270, 17280, 8640, 17280, 17280, 8640, 270, 8640, 8640, 8640, 270, 17280, 8640, 17280, 270, 17280, 270, 270, 8640, 17280, 17280, 8640, 270, 8640, 270, 8640, 17280, 17280, 8640, 270, 8640, 270, 17280, 270, 270, 270, 270, 17280, 8640, 8640, 17280, 8640, 8640, 270, 8640, 17280, 8640, 270, 270, 8640, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 8640, 17280, 8640, 8640, 8640, 270, 17280, 270, 17280, 8640, 270, 8640, 270, 270, 8640, 270, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 270, 270, 17280, 8640, 17280, 8640, 17280, 8640, 270, 8640, 270, 270, 270, 17280, 17280, 8640, 8640, 270, 270, 8640, 270, 17280, 270, 270, 8640, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 8640, 17280, 8640, 270, 8640, 270, 17280, 8640, 8640, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 8640, 270, 8640, 270, 8640, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 8640, 8640, 17280, 270, 17280, 270, 270, 270, 17280, 8640, 17280, 17280, 270, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 17280, 270, 270, 8640, 270, 8640, 8640, 270, 17280, 17280, 17280, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 17280, 270, 270, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2802060 . Total input tokens: 624030052 . Total output tokens: 560316778
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 82.58450103411451,
    "estimated_duration": 3600.11879783981,
    "input_throughput": 6206.812401137399,
    "output_throughput": 5489.231358658993,
    "total_throughput": 11696.043759796392,
    "itl": 153.07015260774725,
    "ttft": 2045019.1875124662,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 557,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7434997200826101,
    "arrivals": 932854,
    "finished_requests": 90315,
    "scheduler_time": 169.89440627507284
}
#Debug simulation 
Total elapsed time: 82.58466158388183. Arrivals time: 0.5081852409057319 Scheduler time: 81.91943890973926 Scheduler overhead time: 0.059630338568240404 Adapter cache time: 0.017518625129014254 Engine time: 0.057821803260594606 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-16-32/adapters_320_slots_64_rate_1.6-0.8-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-16-32/adapters_320_slots_64_rate_1.6-0.8-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 270, 17280, 17280, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 8640, 8640, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 17280, 17280, 8640, 270, 270, 8640, 17280, 17280, 8640, 8640, 270, 270, 8640, 17280, 17280, 270, 17280, 8640, 270, 8640, 17280, 270, 8640, 17280, 17280, 8640, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 8640, 8640, 8640, 270, 8640, 270, 17280, 270, 17280, 8640, 17280, 17280, 270, 17280, 270, 17280, 8640, 270, 270, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 270, 8640, 8640, 270, 17280, 8640, 17280, 17280, 8640, 270, 8640, 8640, 8640, 270, 17280, 8640, 17280, 270, 17280, 270, 270, 8640, 17280, 17280, 8640, 270, 8640, 270, 8640, 17280, 17280, 8640, 270, 8640, 270, 17280, 270, 270, 270, 270, 17280, 8640, 8640, 17280, 8640, 8640, 270, 8640, 17280, 8640, 270, 270, 8640, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 8640, 17280, 8640, 8640, 8640, 270, 17280, 270, 17280, 8640, 270, 8640, 270, 270, 8640, 270, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 270, 270, 17280, 8640, 17280, 8640, 17280, 8640, 270, 8640, 270, 270, 270, 17280, 17280, 8640, 8640, 270, 270, 8640, 270, 17280, 270, 270, 8640, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 8640, 17280, 8640, 270, 8640, 270, 17280, 8640, 8640, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 8640, 270, 8640, 270, 8640, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 8640, 8640, 17280, 270, 17280, 270, 270, 270, 17280, 8640, 17280, 17280, 270, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 17280, 270, 270, 8640, 270, 8640, 8640, 270, 17280, 17280, 17280, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 17280, 270, 270, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2802060 . Total input tokens: 624030052 . Total output tokens: 560316778
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 81.86396872345358,
    "estimated_duration": 3600.163127682948,
    "input_throughput": 6201.265111664164,
    "output_throughput": 5484.167050148947,
    "total_throughput": 11685.43216181311,
    "itl": 153.13640798968666,
    "ttft": 2046068.3768845145,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 503,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6657547626271891,
    "arrivals": 932854,
    "finished_requests": 90212,
    "scheduler_time": 170.04178061295843
}
#Debug simulation 
Total elapsed time: 81.86413350934163. Arrivals time: 0.5003593345172703 Scheduler time: 81.20591283682734 Scheduler overhead time: 0.06087742280215025 Adapter cache time: 0.01693602092564106 Engine time: 0.058239979669451714 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_16-16-16/adapters_320_slots_64_rate_1.6-0.8-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_16-16-16/adapters_320_slots_64_rate_1.6-0.8-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 270, 17280, 17280, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 8640, 8640, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 17280, 17280, 8640, 270, 270, 8640, 17280, 17280, 8640, 8640, 270, 270, 8640, 17280, 17280, 270, 17280, 8640, 270, 8640, 17280, 270, 8640, 17280, 17280, 8640, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 8640, 8640, 8640, 270, 8640, 270, 17280, 270, 17280, 8640, 17280, 17280, 270, 17280, 270, 17280, 8640, 270, 270, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 270, 8640, 8640, 270, 17280, 8640, 17280, 17280, 8640, 270, 8640, 8640, 8640, 270, 17280, 8640, 17280, 270, 17280, 270, 270, 8640, 17280, 17280, 8640, 270, 8640, 270, 8640, 17280, 17280, 8640, 270, 8640, 270, 17280, 270, 270, 270, 270, 17280, 8640, 8640, 17280, 8640, 8640, 270, 8640, 17280, 8640, 270, 270, 8640, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 8640, 17280, 8640, 8640, 8640, 270, 17280, 270, 17280, 8640, 270, 8640, 270, 270, 8640, 270, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 270, 270, 17280, 8640, 17280, 8640, 17280, 8640, 270, 8640, 270, 270, 270, 17280, 17280, 8640, 8640, 270, 270, 8640, 270, 17280, 270, 270, 8640, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 8640, 17280, 8640, 270, 8640, 270, 17280, 8640, 8640, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 8640, 270, 8640, 270, 8640, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 8640, 8640, 17280, 270, 17280, 270, 270, 270, 17280, 8640, 17280, 17280, 270, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 17280, 270, 270, 8640, 270, 8640, 8640, 270, 17280, 17280, 17280, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 17280, 270, 270, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2802060 . Total input tokens: 624030052 . Total output tokens: 560316778
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 79.03827831195667,
    "estimated_duration": 3600.1167452669165,
    "input_throughput": 6210.937195133153,
    "output_throughput": 5487.618429589362,
    "total_throughput": 11698.555624722516,
    "itl": 153.15287650552617,
    "ttft": 2046849.7923633112,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 514,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5368858515797006,
    "arrivals": 932854,
    "finished_requests": 90365,
    "scheduler_time": 170.03007632362068
}
#Debug simulation 
Total elapsed time: 79.0384414321743. Arrivals time: 0.4989753579720855 Scheduler time: 78.38328346982598 Scheduler overhead time: 0.05978142702952027 Adapter cache time: 0.016747663728892803 Engine time: 0.057616645004600286 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_16-16-32/adapters_320_slots_64_rate_1.6-0.8-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_16-16-32/adapters_320_slots_64_rate_1.6-0.8-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 270, 17280, 17280, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 8640, 8640, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 17280, 17280, 8640, 270, 270, 8640, 17280, 17280, 8640, 8640, 270, 270, 8640, 17280, 17280, 270, 17280, 8640, 270, 8640, 17280, 270, 8640, 17280, 17280, 8640, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 8640, 8640, 8640, 270, 8640, 270, 17280, 270, 17280, 8640, 17280, 17280, 270, 17280, 270, 17280, 8640, 270, 270, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 270, 8640, 8640, 270, 17280, 8640, 17280, 17280, 8640, 270, 8640, 8640, 8640, 270, 17280, 8640, 17280, 270, 17280, 270, 270, 8640, 17280, 17280, 8640, 270, 8640, 270, 8640, 17280, 17280, 8640, 270, 8640, 270, 17280, 270, 270, 270, 270, 17280, 8640, 8640, 17280, 8640, 8640, 270, 8640, 17280, 8640, 270, 270, 8640, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 8640, 17280, 8640, 8640, 8640, 270, 17280, 270, 17280, 8640, 270, 8640, 270, 270, 8640, 270, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 270, 270, 17280, 8640, 17280, 8640, 17280, 8640, 270, 8640, 270, 270, 270, 17280, 17280, 8640, 8640, 270, 270, 8640, 270, 17280, 270, 270, 8640, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 8640, 17280, 8640, 270, 8640, 270, 17280, 8640, 8640, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 8640, 270, 8640, 270, 8640, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 8640, 8640, 17280, 270, 17280, 270, 270, 270, 17280, 8640, 17280, 17280, 270, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 17280, 270, 270, 8640, 270, 8640, 8640, 270, 17280, 17280, 17280, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 17280, 270, 270, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2802060 . Total input tokens: 624030052 . Total output tokens: 560316778
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 81.57221471890807,
    "estimated_duration": 3600.014902482009,
    "input_throughput": 6200.980719443442,
    "output_throughput": 5484.071742699866,
    "total_throughput": 11685.052462143309,
    "itl": 153.13670856229857,
    "ttft": 2046079.9649124222,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 503,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6873844138905387,
    "arrivals": 932854,
    "finished_requests": 90204,
    "scheduler_time": 170.033986629598
}
#Debug simulation 
Total elapsed time: 81.57238220376894. Arrivals time: 0.5610684659332037 Scheduler time: 80.85260329116136 Scheduler overhead time: 0.06149963289499283 Adapter cache time: 0.016592039726674557 Engine time: 0.058482853695750237 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-8/adapters_320_slots_64_rate_1.6-0.8-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-8/adapters_320_slots_64_rate_1.6-0.8-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 135, 17280, 17280, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 8640, 8640, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 17280, 17280, 8640, 135, 135, 8640, 17280, 17280, 8640, 8640, 135, 135, 8640, 17280, 17280, 135, 17280, 8640, 135, 8640, 17280, 135, 8640, 17280, 17280, 8640, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 8640, 8640, 8640, 135, 8640, 135, 17280, 135, 17280, 8640, 17280, 17280, 135, 17280, 135, 17280, 8640, 135, 135, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 135, 8640, 8640, 135, 17280, 8640, 17280, 17280, 8640, 135, 8640, 8640, 8640, 135, 17280, 8640, 17280, 135, 17280, 135, 135, 8640, 17280, 17280, 8640, 135, 8640, 135, 8640, 17280, 17280, 8640, 135, 8640, 135, 17280, 135, 135, 135, 135, 17280, 8640, 8640, 17280, 8640, 8640, 135, 8640, 17280, 8640, 135, 135, 8640, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 8640, 17280, 8640, 8640, 8640, 135, 17280, 135, 17280, 8640, 135, 8640, 135, 135, 8640, 135, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 135, 135, 17280, 8640, 17280, 8640, 17280, 8640, 135, 8640, 135, 135, 135, 17280, 17280, 8640, 8640, 135, 135, 8640, 135, 17280, 135, 135, 8640, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 8640, 17280, 8640, 135, 8640, 135, 17280, 8640, 8640, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 8640, 135, 8640, 135, 8640, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 8640, 8640, 17280, 135, 17280, 135, 135, 135, 17280, 8640, 17280, 17280, 135, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 17280, 135, 135, 8640, 135, 8640, 8640, 135, 17280, 17280, 17280, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2787750 . Total input tokens: 620823562 . Total output tokens: 557458365
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 92.72443026397377,
    "estimated_duration": 3600.1645512037157,
    "input_throughput": 6214.973144080022,
    "output_throughput": 5499.2280820554415,
    "total_throughput": 11714.201226135465,
    "itl": 153.90224961134984,
    "ttft": 2040179.8530504503,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 504,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5424858229421254,
    "arrivals": 928080,
    "finished_requests": 90606,
    "scheduler_time": 169.45874819658965
}
#Debug simulation 
Total elapsed time: 92.72460206318647. Arrivals time: 0.518948882818222 Scheduler time: 92.0429640058428 Scheduler overhead time: 0.06266715750098228 Adapter cache time: 0.017183424904942513 Engine time: 0.05968924146145582 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-16/adapters_320_slots_64_rate_1.6-0.8-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-16/adapters_320_slots_64_rate_1.6-0.8-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 135, 17280, 17280, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 8640, 8640, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 17280, 17280, 8640, 135, 135, 8640, 17280, 17280, 8640, 8640, 135, 135, 8640, 17280, 17280, 135, 17280, 8640, 135, 8640, 17280, 135, 8640, 17280, 17280, 8640, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 8640, 8640, 8640, 135, 8640, 135, 17280, 135, 17280, 8640, 17280, 17280, 135, 17280, 135, 17280, 8640, 135, 135, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 135, 8640, 8640, 135, 17280, 8640, 17280, 17280, 8640, 135, 8640, 8640, 8640, 135, 17280, 8640, 17280, 135, 17280, 135, 135, 8640, 17280, 17280, 8640, 135, 8640, 135, 8640, 17280, 17280, 8640, 135, 8640, 135, 17280, 135, 135, 135, 135, 17280, 8640, 8640, 17280, 8640, 8640, 135, 8640, 17280, 8640, 135, 135, 8640, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 8640, 17280, 8640, 8640, 8640, 135, 17280, 135, 17280, 8640, 135, 8640, 135, 135, 8640, 135, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 135, 135, 17280, 8640, 17280, 8640, 17280, 8640, 135, 8640, 135, 135, 135, 17280, 17280, 8640, 8640, 135, 135, 8640, 135, 17280, 135, 135, 8640, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 8640, 17280, 8640, 135, 8640, 135, 17280, 8640, 8640, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 8640, 135, 8640, 135, 8640, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 8640, 8640, 17280, 135, 17280, 135, 135, 135, 17280, 8640, 17280, 17280, 135, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 17280, 135, 135, 8640, 135, 8640, 8640, 135, 17280, 17280, 17280, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2787750 . Total input tokens: 620823562 . Total output tokens: 557458365
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 80.72151348320767,
    "estimated_duration": 3600.1298119267653,
    "input_throughput": 6199.003137627411,
    "output_throughput": 5479.957676704276,
    "total_throughput": 11678.960814331687,
    "itl": 153.15562595203784,
    "ttft": 2046130.0062904072,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 510,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6630308680329522,
    "arrivals": 928080,
    "finished_requests": 90379,
    "scheduler_time": 170.2420755251226
}
#Debug simulation 
Total elapsed time: 80.72168324515224. Arrivals time: 0.5642735972069204 Scheduler time: 80.00026542786509 Scheduler overhead time: 0.06006715493276715 Adapter cache time: 0.016960544511675835 Engine time: 0.05819777958095074 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-32/adapters_320_slots_64_rate_1.6-0.8-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-32/adapters_320_slots_64_rate_1.6-0.8-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 135, 17280, 17280, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 8640, 8640, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 17280, 17280, 8640, 135, 135, 8640, 17280, 17280, 8640, 8640, 135, 135, 8640, 17280, 17280, 135, 17280, 8640, 135, 8640, 17280, 135, 8640, 17280, 17280, 8640, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 8640, 8640, 8640, 135, 8640, 135, 17280, 135, 17280, 8640, 17280, 17280, 135, 17280, 135, 17280, 8640, 135, 135, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 135, 8640, 8640, 135, 17280, 8640, 17280, 17280, 8640, 135, 8640, 8640, 8640, 135, 17280, 8640, 17280, 135, 17280, 135, 135, 8640, 17280, 17280, 8640, 135, 8640, 135, 8640, 17280, 17280, 8640, 135, 8640, 135, 17280, 135, 135, 135, 135, 17280, 8640, 8640, 17280, 8640, 8640, 135, 8640, 17280, 8640, 135, 135, 8640, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 8640, 17280, 8640, 8640, 8640, 135, 17280, 135, 17280, 8640, 135, 8640, 135, 135, 8640, 135, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 135, 135, 17280, 8640, 17280, 8640, 17280, 8640, 135, 8640, 135, 135, 135, 17280, 17280, 8640, 8640, 135, 135, 8640, 135, 17280, 135, 135, 8640, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 8640, 17280, 8640, 135, 8640, 135, 17280, 8640, 8640, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 8640, 135, 8640, 135, 8640, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 8640, 8640, 17280, 135, 17280, 135, 135, 135, 17280, 8640, 17280, 17280, 135, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 17280, 135, 135, 8640, 135, 8640, 8640, 135, 17280, 17280, 17280, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2787750 . Total input tokens: 620823562 . Total output tokens: 557458365
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 80.4546901579015,
    "estimated_duration": 3600.132848775759,
    "input_throughput": 6198.997908532478,
    "output_throughput": 5479.953054151539,
    "total_throughput": 11678.950962684015,
    "itl": 153.15571553997952,
    "ttft": 2046131.1896163984,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 510,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.666184266023348,
    "arrivals": 928080,
    "finished_requests": 90379,
    "scheduler_time": 170.24209821402934
}
#Debug simulation 
Total elapsed time: 80.45485846279189. Arrivals time: 0.5065016616135836 Scheduler time: 79.79031415609643 Scheduler overhead time: 0.060721819289028645 Adapter cache time: 0.016692238394171 Engine time: 0.058546883054077625 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-16/adapters_320_slots_64_rate_1.6-0.8-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-16/adapters_320_slots_64_rate_1.6-0.8-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 135, 17280, 17280, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 8640, 8640, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 17280, 17280, 8640, 135, 135, 8640, 17280, 17280, 8640, 8640, 135, 135, 8640, 17280, 17280, 135, 17280, 8640, 135, 8640, 17280, 135, 8640, 17280, 17280, 8640, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 8640, 8640, 8640, 135, 8640, 135, 17280, 135, 17280, 8640, 17280, 17280, 135, 17280, 135, 17280, 8640, 135, 135, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 135, 8640, 8640, 135, 17280, 8640, 17280, 17280, 8640, 135, 8640, 8640, 8640, 135, 17280, 8640, 17280, 135, 17280, 135, 135, 8640, 17280, 17280, 8640, 135, 8640, 135, 8640, 17280, 17280, 8640, 135, 8640, 135, 17280, 135, 135, 135, 135, 17280, 8640, 8640, 17280, 8640, 8640, 135, 8640, 17280, 8640, 135, 135, 8640, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 8640, 17280, 8640, 8640, 8640, 135, 17280, 135, 17280, 8640, 135, 8640, 135, 135, 8640, 135, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 135, 135, 17280, 8640, 17280, 8640, 17280, 8640, 135, 8640, 135, 135, 135, 17280, 17280, 8640, 8640, 135, 135, 8640, 135, 17280, 135, 135, 8640, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 8640, 17280, 8640, 135, 8640, 135, 17280, 8640, 8640, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 8640, 135, 8640, 135, 8640, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 8640, 8640, 17280, 135, 17280, 135, 135, 135, 17280, 8640, 17280, 17280, 135, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 17280, 135, 135, 8640, 135, 8640, 8640, 135, 17280, 17280, 17280, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2787750 . Total input tokens: 620823562 . Total output tokens: 557458365
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 92.05460418807343,
    "estimated_duration": 3600.024398418985,
    "input_throughput": 6215.038989687422,
    "output_throughput": 5499.372451112995,
    "total_throughput": 11714.411440800417,
    "itl": 153.90310131502028,
    "ttft": 2040147.8191939185,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 504,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5764465527655491,
    "arrivals": 928080,
    "finished_requests": 90604,
    "scheduler_time": 169.45073345084785
}
#Debug simulation 
Total elapsed time: 92.05478856898844. Arrivals time: 0.5202249921858311 Scheduler time: 91.37133879680187 Scheduler overhead time: 0.0628191102296114 Adapter cache time: 0.017217967193573713 Engine time: 0.060428116004914045 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-32/adapters_320_slots_64_rate_1.6-0.8-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-32/adapters_320_slots_64_rate_1.6-0.8-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 135, 17280, 17280, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 8640, 8640, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 17280, 17280, 8640, 135, 135, 8640, 17280, 17280, 8640, 8640, 135, 135, 8640, 17280, 17280, 135, 17280, 8640, 135, 8640, 17280, 135, 8640, 17280, 17280, 8640, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 8640, 8640, 8640, 135, 8640, 135, 17280, 135, 17280, 8640, 17280, 17280, 135, 17280, 135, 17280, 8640, 135, 135, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 135, 8640, 8640, 135, 17280, 8640, 17280, 17280, 8640, 135, 8640, 8640, 8640, 135, 17280, 8640, 17280, 135, 17280, 135, 135, 8640, 17280, 17280, 8640, 135, 8640, 135, 8640, 17280, 17280, 8640, 135, 8640, 135, 17280, 135, 135, 135, 135, 17280, 8640, 8640, 17280, 8640, 8640, 135, 8640, 17280, 8640, 135, 135, 8640, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 8640, 17280, 8640, 8640, 8640, 135, 17280, 135, 17280, 8640, 135, 8640, 135, 135, 8640, 135, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 135, 135, 17280, 8640, 17280, 8640, 17280, 8640, 135, 8640, 135, 135, 135, 17280, 17280, 8640, 8640, 135, 135, 8640, 135, 17280, 135, 135, 8640, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 8640, 17280, 8640, 135, 8640, 135, 17280, 8640, 8640, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 8640, 135, 8640, 135, 8640, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 8640, 8640, 17280, 135, 17280, 135, 135, 135, 17280, 8640, 17280, 17280, 135, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 17280, 135, 135, 8640, 135, 8640, 8640, 135, 17280, 17280, 17280, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2787750 . Total input tokens: 620823562 . Total output tokens: 557458365
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 80.27541741728783,
    "estimated_duration": 3600.153329390549,
    "input_throughput": 6198.962643565507,
    "output_throughput": 5479.921879699425,
    "total_throughput": 11678.884523264933,
    "itl": 153.15634769038468,
    "ttft": 2046139.7895583047,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 510,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6866821332089654,
    "arrivals": 928080,
    "finished_requests": 90379,
    "scheduler_time": 170.2422201995911
}
#Debug simulation 
Total elapsed time: 80.2755816844292. Arrivals time: 0.5009816391393542 Scheduler time: 79.61653753556311 Scheduler overhead time: 0.060347543098032475 Adapter cache time: 0.016891995444893837 Engine time: 0.05857735825702548 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-16/adapters_320_slots_64_rate_1.6-0.8-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-16/adapters_320_slots_64_rate_1.6-0.8-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 135, 17280, 17280, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 8640, 8640, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 17280, 17280, 8640, 135, 135, 8640, 17280, 17280, 8640, 8640, 135, 135, 8640, 17280, 17280, 135, 17280, 8640, 135, 8640, 17280, 135, 8640, 17280, 17280, 8640, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 8640, 8640, 8640, 135, 8640, 135, 17280, 135, 17280, 8640, 17280, 17280, 135, 17280, 135, 17280, 8640, 135, 135, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 135, 8640, 8640, 135, 17280, 8640, 17280, 17280, 8640, 135, 8640, 8640, 8640, 135, 17280, 8640, 17280, 135, 17280, 135, 135, 8640, 17280, 17280, 8640, 135, 8640, 135, 8640, 17280, 17280, 8640, 135, 8640, 135, 17280, 135, 135, 135, 135, 17280, 8640, 8640, 17280, 8640, 8640, 135, 8640, 17280, 8640, 135, 135, 8640, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 8640, 17280, 8640, 8640, 8640, 135, 17280, 135, 17280, 8640, 135, 8640, 135, 135, 8640, 135, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 135, 135, 17280, 8640, 17280, 8640, 17280, 8640, 135, 8640, 135, 135, 135, 17280, 17280, 8640, 8640, 135, 135, 8640, 135, 17280, 135, 135, 8640, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 8640, 17280, 8640, 135, 8640, 135, 17280, 8640, 8640, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 8640, 135, 8640, 135, 8640, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 8640, 8640, 17280, 135, 17280, 135, 135, 135, 17280, 8640, 17280, 17280, 135, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 17280, 135, 135, 8640, 135, 8640, 8640, 135, 17280, 17280, 17280, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2787750 . Total input tokens: 620823562 . Total output tokens: 557458365
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 81.55279392376542,
    "estimated_duration": 3600.1165658421737,
    "input_throughput": 6209.989757587226,
    "output_throughput": 5490.730546769352,
    "total_throughput": 11700.720304356579,
    "itl": 153.73270828470194,
    "ttft": 2044653.9838562827,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 607,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.814960529005593,
    "arrivals": 928080,
    "finished_requests": 90543,
    "scheduler_time": 169.65702668731527
}
#Debug simulation 
Total elapsed time: 81.55296074878424. Arrivals time: 0.5077248141169548 Scheduler time: 80.88609476294369 Scheduler overhead time: 0.06014753505587578 Adapter cache time: 0.018226204439997673 Engine time: 0.058896321803331375 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-32/adapters_320_slots_64_rate_1.6-0.8-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-32/adapters_320_slots_64_rate_1.6-0.8-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 135, 17280, 17280, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 8640, 8640, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 17280, 17280, 8640, 135, 135, 8640, 17280, 17280, 8640, 8640, 135, 135, 8640, 17280, 17280, 135, 17280, 8640, 135, 8640, 17280, 135, 8640, 17280, 17280, 8640, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 8640, 8640, 8640, 135, 8640, 135, 17280, 135, 17280, 8640, 17280, 17280, 135, 17280, 135, 17280, 8640, 135, 135, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 135, 8640, 8640, 135, 17280, 8640, 17280, 17280, 8640, 135, 8640, 8640, 8640, 135, 17280, 8640, 17280, 135, 17280, 135, 135, 8640, 17280, 17280, 8640, 135, 8640, 135, 8640, 17280, 17280, 8640, 135, 8640, 135, 17280, 135, 135, 135, 135, 17280, 8640, 8640, 17280, 8640, 8640, 135, 8640, 17280, 8640, 135, 135, 8640, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 8640, 17280, 8640, 8640, 8640, 135, 17280, 135, 17280, 8640, 135, 8640, 135, 135, 8640, 135, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 135, 135, 17280, 8640, 17280, 8640, 17280, 8640, 135, 8640, 135, 135, 135, 17280, 17280, 8640, 8640, 135, 135, 8640, 135, 17280, 135, 135, 8640, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 8640, 17280, 8640, 135, 8640, 135, 17280, 8640, 8640, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 8640, 135, 8640, 135, 8640, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 8640, 8640, 17280, 135, 17280, 135, 135, 135, 17280, 8640, 17280, 17280, 135, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 17280, 135, 135, 8640, 135, 8640, 8640, 135, 17280, 17280, 17280, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2787750 . Total input tokens: 620823562 . Total output tokens: 557458365
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 80.583437317051,
    "estimated_duration": 3600.0040825860274,
    "input_throughput": 6198.8340813129425,
    "output_throughput": 5479.883507751156,
    "total_throughput": 11678.717589064097,
    "itl": 153.15679539892025,
    "ttft": 2046117.0153916911,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 510,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7086890458315596,
    "arrivals": 928080,
    "finished_requests": 90375,
    "scheduler_time": 170.2347604560885
}
#Debug simulation 
Total elapsed time: 80.58360374206677. Arrivals time: 0.508002289570868 Scheduler time: 79.91737113287672 Scheduler overhead time: 0.06003127247095108 Adapter cache time: 0.016948081087321043 Engine time: 0.05864743795245886 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-8/adapters_320_slots_64_rate_1.6-0.8-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-8/adapters_320_slots_64_rate_1.6-0.8-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 66, 17280, 17280, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 8640, 8640, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 17280, 8640, 66, 66, 8640, 17280, 17280, 8640, 8640, 66, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 8640, 17280, 17280, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 66, 17280, 8640, 66, 66, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 66, 8640, 8640, 66, 17280, 8640, 17280, 17280, 8640, 66, 8640, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 66, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 17280, 66, 66, 66, 66, 17280, 8640, 8640, 17280, 8640, 8640, 66, 8640, 17280, 8640, 66, 66, 8640, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 8640, 17280, 8640, 8640, 8640, 66, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 66, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 66, 66, 17280, 8640, 17280, 8640, 17280, 8640, 66, 8640, 66, 66, 66, 17280, 17280, 8640, 8640, 66, 66, 8640, 66, 17280, 66, 66, 8640, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 66, 8640, 66, 17280, 8640, 8640, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 8640, 8640, 17280, 66, 17280, 66, 66, 66, 17280, 8640, 17280, 17280, 66, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 17280, 66, 66, 8640, 66, 8640, 8640, 66, 17280, 17280, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2780436 . Total input tokens: 619158227 . Total output tokens: 555999522
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 80.9125949558802,
    "estimated_duration": 3600.0786186385835,
    "input_throughput": 6213.596526527883,
    "output_throughput": 5486.478516813442,
    "total_throughput": 11700.075043341325,
    "itl": 153.33396732322936,
    "ttft": 2040750.5041201035,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 453,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3864009480015496,
    "arrivals": 925677,
    "finished_requests": 90385,
    "scheduler_time": 169.86462553662213
}
#Debug simulation 
Total elapsed time: 80.91277219867334. Arrivals time: 0.4970284253358841 Scheduler time: 80.25919899065048 Scheduler overhead time: 0.05986733874306083 Adapter cache time: 0.016367285512387753 Engine time: 0.05847062123939395 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-16/adapters_320_slots_64_rate_1.6-0.8-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-16/adapters_320_slots_64_rate_1.6-0.8-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 66, 17280, 17280, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 8640, 8640, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 17280, 8640, 66, 66, 8640, 17280, 17280, 8640, 8640, 66, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 8640, 17280, 17280, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 66, 17280, 8640, 66, 66, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 66, 8640, 8640, 66, 17280, 8640, 17280, 17280, 8640, 66, 8640, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 66, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 17280, 66, 66, 66, 66, 17280, 8640, 8640, 17280, 8640, 8640, 66, 8640, 17280, 8640, 66, 66, 8640, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 8640, 17280, 8640, 8640, 8640, 66, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 66, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 66, 66, 17280, 8640, 17280, 8640, 17280, 8640, 66, 8640, 66, 66, 66, 17280, 17280, 8640, 8640, 66, 66, 8640, 66, 17280, 66, 66, 8640, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 66, 8640, 66, 17280, 8640, 8640, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 8640, 8640, 17280, 66, 17280, 66, 66, 66, 17280, 8640, 17280, 17280, 66, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 17280, 66, 66, 8640, 66, 8640, 8640, 66, 17280, 17280, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2780436 . Total input tokens: 619158227 . Total output tokens: 555999522
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 89.08551440713927,
    "estimated_duration": 3600.0652924643646,
    "input_throughput": 6217.351403834728,
    "output_throughput": 5497.545292144422,
    "total_throughput": 11714.89669597915,
    "itl": 153.80865527374024,
    "ttft": 2037870.8302082955,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 444,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4497523311502356,
    "arrivals": 925677,
    "finished_requests": 90606,
    "scheduler_time": 169.49246571215232
}
#Debug simulation 
Total elapsed time: 89.08568543195724. Arrivals time: 0.5046904557384551 Scheduler time: 88.42125027626753 Scheduler overhead time: 0.06182656669989228 Adapter cache time: 0.016101233195513487 Engine time: 0.059746901504695415 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-32/adapters_320_slots_64_rate_1.6-0.8-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-32/adapters_320_slots_64_rate_1.6-0.8-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 66, 17280, 17280, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 8640, 8640, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 17280, 8640, 66, 66, 8640, 17280, 17280, 8640, 8640, 66, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 8640, 17280, 17280, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 66, 17280, 8640, 66, 66, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 66, 8640, 8640, 66, 17280, 8640, 17280, 17280, 8640, 66, 8640, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 66, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 17280, 66, 66, 66, 66, 17280, 8640, 8640, 17280, 8640, 8640, 66, 8640, 17280, 8640, 66, 66, 8640, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 8640, 17280, 8640, 8640, 8640, 66, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 66, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 66, 66, 17280, 8640, 17280, 8640, 17280, 8640, 66, 8640, 66, 66, 66, 17280, 17280, 8640, 8640, 66, 66, 8640, 66, 17280, 66, 66, 8640, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 66, 8640, 66, 17280, 8640, 8640, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 8640, 8640, 17280, 66, 17280, 66, 66, 66, 17280, 8640, 17280, 17280, 66, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 17280, 66, 66, 8640, 66, 8640, 8640, 66, 17280, 17280, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2780436 . Total input tokens: 619158227 . Total output tokens: 555999522
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 88.97483819210902,
    "estimated_duration": 3600.0671520641354,
    "input_throughput": 6217.348192287622,
    "output_throughput": 5497.54245241018,
    "total_throughput": 11714.890644697802,
    "itl": 153.8087058849815,
    "ttft": 2037871.5122212823,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 444,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.452159369718292,
    "arrivals": 925677,
    "finished_requests": 90606,
    "scheduler_time": 169.49247522506167
}
#Debug simulation 
Total elapsed time: 88.97501996112987. Arrivals time: 0.504467514809221 Scheduler time: 88.30927122198045 Scheduler overhead time: 0.06189805408939719 Adapter cache time: 0.01644569355994463 Engine time: 0.060692260041832924 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-16/adapters_320_slots_64_rate_1.6-0.8-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-16/adapters_320_slots_64_rate_1.6-0.8-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 66, 17280, 17280, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 8640, 8640, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 17280, 8640, 66, 66, 8640, 17280, 17280, 8640, 8640, 66, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 8640, 17280, 17280, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 66, 17280, 8640, 66, 66, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 66, 8640, 8640, 66, 17280, 8640, 17280, 17280, 8640, 66, 8640, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 66, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 17280, 66, 66, 66, 66, 17280, 8640, 8640, 17280, 8640, 8640, 66, 8640, 17280, 8640, 66, 66, 8640, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 8640, 17280, 8640, 8640, 8640, 66, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 66, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 66, 66, 17280, 8640, 17280, 8640, 17280, 8640, 66, 8640, 66, 66, 66, 17280, 17280, 8640, 8640, 66, 66, 8640, 66, 17280, 66, 66, 8640, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 66, 8640, 66, 17280, 8640, 8640, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 8640, 8640, 17280, 66, 17280, 66, 66, 66, 17280, 8640, 17280, 17280, 66, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 17280, 66, 66, 8640, 66, 8640, 8640, 66, 17280, 17280, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2780436 . Total input tokens: 619158227 . Total output tokens: 555999522
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 80.50620118901134,
    "estimated_duration": 3600.0622853452405,
    "input_throughput": 6209.928392351712,
    "output_throughput": 5486.878402190118,
    "total_throughput": 11696.80679454183,
    "itl": 153.4243347114892,
    "ttft": 2041265.7649708658,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 453,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4178250579489362,
    "arrivals": 925677,
    "finished_requests": 90379,
    "scheduler_time": 169.80528368695983
}
#Debug simulation 
Total elapsed time: 80.50636612204835. Arrivals time: 0.4979805597104132 Scheduler time: 79.85222469037399 Scheduler overhead time: 0.05992835899814963 Adapter cache time: 0.01649707229807973 Engine time: 0.057805880438536406 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-32/adapters_320_slots_64_rate_1.6-0.8-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-32/adapters_320_slots_64_rate_1.6-0.8-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 66, 17280, 17280, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 8640, 8640, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 17280, 8640, 66, 66, 8640, 17280, 17280, 8640, 8640, 66, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 8640, 17280, 17280, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 66, 17280, 8640, 66, 66, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 66, 8640, 8640, 66, 17280, 8640, 17280, 17280, 8640, 66, 8640, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 66, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 17280, 66, 66, 66, 66, 17280, 8640, 8640, 17280, 8640, 8640, 66, 8640, 17280, 8640, 66, 66, 8640, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 8640, 17280, 8640, 8640, 8640, 66, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 66, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 66, 66, 17280, 8640, 17280, 8640, 17280, 8640, 66, 8640, 66, 66, 66, 17280, 17280, 8640, 8640, 66, 66, 8640, 66, 17280, 66, 66, 8640, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 66, 8640, 66, 17280, 8640, 8640, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 8640, 8640, 17280, 66, 17280, 66, 66, 66, 17280, 8640, 17280, 17280, 66, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 17280, 66, 66, 8640, 66, 8640, 8640, 66, 17280, 17280, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2780436 . Total input tokens: 619158227 . Total output tokens: 555999522
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 88.89175738813356,
    "estimated_duration": 3600.0877665695366,
    "input_throughput": 6217.312591056152,
    "output_throughput": 5497.510972866923,
    "total_throughput": 11714.823563923075,
    "itl": 153.80935590541515,
    "ttft": 2037880.9766095376,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 444,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4708966838941027,
    "arrivals": 925677,
    "finished_requests": 90606,
    "scheduler_time": 169.49268156111367
}
#Debug simulation 
Total elapsed time: 88.891919368878. Arrivals time: 0.5113450731150806 Scheduler time: 88.2178546115756 Scheduler overhead time: 0.061985943000763655 Adapter cache time: 0.01642108801752329 Engine time: 0.06201872602105141 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-16/adapters_320_slots_64_rate_1.6-0.8-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-16/adapters_320_slots_64_rate_1.6-0.8-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 66, 17280, 17280, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 8640, 8640, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 17280, 8640, 66, 66, 8640, 17280, 17280, 8640, 8640, 66, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 8640, 17280, 17280, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 66, 17280, 8640, 66, 66, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 66, 8640, 8640, 66, 17280, 8640, 17280, 17280, 8640, 66, 8640, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 66, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 17280, 66, 66, 66, 66, 17280, 8640, 8640, 17280, 8640, 8640, 66, 8640, 17280, 8640, 66, 66, 8640, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 8640, 17280, 8640, 8640, 8640, 66, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 66, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 66, 66, 17280, 8640, 17280, 8640, 17280, 8640, 66, 8640, 66, 66, 66, 17280, 17280, 8640, 8640, 66, 66, 8640, 66, 17280, 66, 66, 8640, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 66, 8640, 66, 17280, 8640, 8640, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 8640, 8640, 17280, 66, 17280, 66, 66, 66, 17280, 8640, 17280, 17280, 66, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 17280, 66, 66, 8640, 66, 8640, 8640, 66, 17280, 17280, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2780436 . Total input tokens: 619158227 . Total output tokens: 555999522
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 80.93996877176687,
    "estimated_duration": 3600.04945832409,
    "input_throughput": 6213.646856511108,
    "output_throughput": 5486.522957158182,
    "total_throughput": 11700.16981366929,
    "itl": 153.33310340520077,
    "ttft": 2040738.662441337,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 453,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3544927835906744,
    "arrivals": 925677,
    "finished_requests": 90385,
    "scheduler_time": 169.86444938988268
}
#Debug simulation 
Total elapsed time: 80.94013130059466. Arrivals time: 0.5010015284642577 Scheduler time: 80.28243179200217 Scheduler overhead time: 0.06047002552077174 Adapter cache time: 0.01619392167776823 Engine time: 0.058274004608392715 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-32/adapters_320_slots_64_rate_1.6-0.8-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-32/adapters_320_slots_64_rate_1.6-0.8-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 66, 17280, 17280, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 8640, 8640, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 17280, 8640, 66, 66, 8640, 17280, 17280, 8640, 8640, 66, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 8640, 17280, 17280, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 66, 17280, 8640, 66, 66, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 66, 8640, 8640, 66, 17280, 8640, 17280, 17280, 8640, 66, 8640, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 66, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 17280, 66, 66, 66, 66, 17280, 8640, 8640, 17280, 8640, 8640, 66, 8640, 17280, 8640, 66, 66, 8640, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 8640, 17280, 8640, 8640, 8640, 66, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 66, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 66, 66, 17280, 8640, 17280, 8640, 17280, 8640, 66, 8640, 66, 66, 66, 17280, 17280, 8640, 8640, 66, 66, 8640, 66, 17280, 66, 66, 8640, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 66, 8640, 66, 17280, 8640, 8640, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 8640, 8640, 17280, 66, 17280, 66, 66, 66, 17280, 8640, 17280, 17280, 66, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 17280, 66, 66, 8640, 66, 8640, 8640, 66, 17280, 17280, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2780436 . Total input tokens: 619158227 . Total output tokens: 555999522
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 84.25099778361619,
    "estimated_duration": 3600.107241923315,
    "input_throughput": 6213.772395304802,
    "output_throughput": 5493.7474555435165,
    "total_throughput": 11707.519850848319,
    "itl": 153.77001170185167,
    "ttft": 2039271.1507306423,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 440,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4775856764614586,
    "arrivals": 925677,
    "finished_requests": 90452,
    "scheduler_time": 169.54085679544013
}
#Debug simulation 
Total elapsed time: 84.25115922698751. Arrivals time: 0.5645946254953742 Scheduler time: 83.52530272724107 Scheduler overhead time: 0.06194738997146487 Adapter cache time: 0.016547927167266607 Engine time: 0.060498299077153206 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-8/adapters_320_slots_64_rate_1.6-0.8-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-8/adapters_320_slots_64_rate_1.6-0.8-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 33, 17280, 17280, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 8640, 8640, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 17280, 17280, 8640, 33, 33, 8640, 17280, 17280, 8640, 8640, 33, 33, 8640, 17280, 17280, 33, 17280, 8640, 33, 8640, 17280, 33, 8640, 17280, 17280, 8640, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 8640, 8640, 8640, 33, 8640, 33, 17280, 33, 17280, 8640, 17280, 17280, 33, 17280, 33, 17280, 8640, 33, 33, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 33, 8640, 8640, 33, 17280, 8640, 17280, 17280, 8640, 33, 8640, 8640, 8640, 33, 17280, 8640, 17280, 33, 17280, 33, 33, 8640, 17280, 17280, 8640, 33, 8640, 33, 8640, 17280, 17280, 8640, 33, 8640, 33, 17280, 33, 33, 33, 33, 17280, 8640, 8640, 17280, 8640, 8640, 33, 8640, 17280, 8640, 33, 33, 8640, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 8640, 17280, 8640, 8640, 8640, 33, 17280, 33, 17280, 8640, 33, 8640, 33, 33, 8640, 33, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 33, 33, 17280, 8640, 17280, 8640, 17280, 8640, 33, 8640, 33, 33, 33, 17280, 17280, 8640, 8640, 33, 33, 8640, 33, 17280, 33, 33, 8640, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 8640, 17280, 8640, 33, 8640, 33, 17280, 8640, 8640, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 8640, 33, 8640, 33, 8640, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 8640, 8640, 17280, 33, 17280, 33, 33, 33, 17280, 8640, 17280, 17280, 33, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 17280, 33, 33, 8640, 33, 8640, 8640, 33, 17280, 17280, 17280, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2776938 . Total input tokens: 618377608 . Total output tokens: 555301754
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 82.93977504083887,
    "estimated_duration": 3600.1516801480802,
    "input_throughput": 6230.816919101958,
    "output_throughput": 5505.832187377365,
    "total_throughput": 11736.649106479323,
    "itl": 153.86375517706182,
    "ttft": 2043398.7082845822,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 416,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2731629014760337,
    "arrivals": 924451,
    "finished_requests": 90591,
    "scheduler_time": 169.32123523194946
}
#Debug simulation 
Total elapsed time: 82.9399477057159. Arrivals time: 0.5010384703055024 Scheduler time: 82.28135279845446 Scheduler overhead time: 0.06080683646723628 Adapter cache time: 0.015732037369161844 Engine time: 0.05841779662296176 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-16/adapters_320_slots_64_rate_1.6-0.8-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-16/adapters_320_slots_64_rate_1.6-0.8-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 33, 17280, 17280, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 8640, 8640, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 17280, 17280, 8640, 33, 33, 8640, 17280, 17280, 8640, 8640, 33, 33, 8640, 17280, 17280, 33, 17280, 8640, 33, 8640, 17280, 33, 8640, 17280, 17280, 8640, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 8640, 8640, 8640, 33, 8640, 33, 17280, 33, 17280, 8640, 17280, 17280, 33, 17280, 33, 17280, 8640, 33, 33, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 33, 8640, 8640, 33, 17280, 8640, 17280, 17280, 8640, 33, 8640, 8640, 8640, 33, 17280, 8640, 17280, 33, 17280, 33, 33, 8640, 17280, 17280, 8640, 33, 8640, 33, 8640, 17280, 17280, 8640, 33, 8640, 33, 17280, 33, 33, 33, 33, 17280, 8640, 8640, 17280, 8640, 8640, 33, 8640, 17280, 8640, 33, 33, 8640, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 8640, 17280, 8640, 8640, 8640, 33, 17280, 33, 17280, 8640, 33, 8640, 33, 33, 8640, 33, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 33, 33, 17280, 8640, 17280, 8640, 17280, 8640, 33, 8640, 33, 33, 33, 17280, 17280, 8640, 8640, 33, 33, 8640, 33, 17280, 33, 33, 8640, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 8640, 17280, 8640, 33, 8640, 33, 17280, 8640, 8640, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 8640, 33, 8640, 33, 8640, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 8640, 8640, 17280, 33, 17280, 33, 33, 33, 17280, 8640, 17280, 17280, 33, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 17280, 33, 33, 8640, 33, 8640, 8640, 33, 17280, 17280, 17280, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2776938 . Total input tokens: 618377608 . Total output tokens: 555301754
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 81.79632230475545,
    "estimated_duration": 3600.0523003931667,
    "input_throughput": 6224.5162375981945,
    "output_throughput": 5500.81008485273,
    "total_throughput": 11725.326322450925,
    "itl": 153.52344411394552,
    "ttft": 2043820.3962203783,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 417,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3604404715006293,
    "arrivals": 924451,
    "finished_requests": 90507,
    "scheduler_time": 169.5407212467597
}
#Debug simulation 
Total elapsed time: 81.79648091085255. Arrivals time: 0.4986200099810958 Scheduler time: 81.1404379568994 Scheduler overhead time: 0.06067298259586096 Adapter cache time: 0.01574807846918702 Engine time: 0.05885390844196081 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-32/adapters_320_slots_64_rate_1.6-0.8-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-32/adapters_320_slots_64_rate_1.6-0.8-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 33, 17280, 17280, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 8640, 8640, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 17280, 17280, 8640, 33, 33, 8640, 17280, 17280, 8640, 8640, 33, 33, 8640, 17280, 17280, 33, 17280, 8640, 33, 8640, 17280, 33, 8640, 17280, 17280, 8640, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 8640, 8640, 8640, 33, 8640, 33, 17280, 33, 17280, 8640, 17280, 17280, 33, 17280, 33, 17280, 8640, 33, 33, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 33, 8640, 8640, 33, 17280, 8640, 17280, 17280, 8640, 33, 8640, 8640, 8640, 33, 17280, 8640, 17280, 33, 17280, 33, 33, 8640, 17280, 17280, 8640, 33, 8640, 33, 8640, 17280, 17280, 8640, 33, 8640, 33, 17280, 33, 33, 33, 33, 17280, 8640, 8640, 17280, 8640, 8640, 33, 8640, 17280, 8640, 33, 33, 8640, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 8640, 17280, 8640, 8640, 8640, 33, 17280, 33, 17280, 8640, 33, 8640, 33, 33, 8640, 33, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 33, 33, 17280, 8640, 17280, 8640, 17280, 8640, 33, 8640, 33, 33, 33, 17280, 17280, 8640, 8640, 33, 33, 8640, 33, 17280, 33, 33, 8640, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 8640, 17280, 8640, 33, 8640, 33, 17280, 8640, 8640, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 8640, 33, 8640, 33, 8640, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 8640, 8640, 17280, 33, 17280, 33, 33, 33, 17280, 8640, 17280, 17280, 33, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 17280, 33, 33, 8640, 33, 8640, 8640, 33, 17280, 17280, 17280, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2776938 . Total input tokens: 618377608 . Total output tokens: 555301754
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 81.7791324169375,
    "estimated_duration": 3600.0552051265836,
    "input_throughput": 6224.511215297344,
    "output_throughput": 5500.805646479993,
    "total_throughput": 11725.316861777337,
    "itl": 153.5235454948412,
    "ttft": 2043821.7332485272,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 417,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.362902163416155,
    "arrivals": 924451,
    "finished_requests": 90507,
    "scheduler_time": 169.54074657444565
}
#Debug simulation 
Total elapsed time: 81.77929392177612. Arrivals time: 0.49073159461840987 Scheduler time: 81.13241431256756 Scheduler overhead time: 0.06049227202311158 Adapter cache time: 0.015826342161744833 Engine time: 0.05813851486891508 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-16/adapters_320_slots_64_rate_1.6-0.8-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-16/adapters_320_slots_64_rate_1.6-0.8-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 33, 17280, 17280, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 8640, 8640, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 17280, 17280, 8640, 33, 33, 8640, 17280, 17280, 8640, 8640, 33, 33, 8640, 17280, 17280, 33, 17280, 8640, 33, 8640, 17280, 33, 8640, 17280, 17280, 8640, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 8640, 8640, 8640, 33, 8640, 33, 17280, 33, 17280, 8640, 17280, 17280, 33, 17280, 33, 17280, 8640, 33, 33, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 33, 8640, 8640, 33, 17280, 8640, 17280, 17280, 8640, 33, 8640, 8640, 8640, 33, 17280, 8640, 17280, 33, 17280, 33, 33, 8640, 17280, 17280, 8640, 33, 8640, 33, 8640, 17280, 17280, 8640, 33, 8640, 33, 17280, 33, 33, 33, 33, 17280, 8640, 8640, 17280, 8640, 8640, 33, 8640, 17280, 8640, 33, 33, 8640, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 8640, 17280, 8640, 8640, 8640, 33, 17280, 33, 17280, 8640, 33, 8640, 33, 33, 8640, 33, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 33, 33, 17280, 8640, 17280, 8640, 17280, 8640, 33, 8640, 33, 33, 33, 17280, 17280, 8640, 8640, 33, 33, 8640, 33, 17280, 33, 33, 8640, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 8640, 17280, 8640, 33, 8640, 33, 17280, 8640, 8640, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 8640, 33, 8640, 33, 8640, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 8640, 8640, 17280, 33, 17280, 33, 33, 33, 17280, 8640, 17280, 17280, 33, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 17280, 33, 33, 8640, 33, 8640, 8640, 33, 17280, 17280, 17280, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2776938 . Total input tokens: 618377608 . Total output tokens: 555301754
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 83.27684371871874,
    "estimated_duration": 3600.0118170858354,
    "input_throughput": 6230.643714430115,
    "output_throughput": 5505.927759994182,
    "total_throughput": 11736.571474424298,
    "itl": 153.8666960002925,
    "ttft": 2043389.8509824136,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 416,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2986126953503094,
    "arrivals": 924451,
    "finished_requests": 90586,
    "scheduler_time": 169.31352763074977
}
#Debug simulation 
Total elapsed time: 83.27700687386096. Arrivals time: 0.5653881523758173 Scheduler time: 82.55438534077257 Scheduler overhead time: 0.060823348350822926 Adapter cache time: 0.016047399025410414 Engine time: 0.05835095886141062 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-32/adapters_320_slots_64_rate_1.6-0.8-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-32/adapters_320_slots_64_rate_1.6-0.8-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 33, 17280, 17280, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 8640, 8640, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 17280, 17280, 8640, 33, 33, 8640, 17280, 17280, 8640, 8640, 33, 33, 8640, 17280, 17280, 33, 17280, 8640, 33, 8640, 17280, 33, 8640, 17280, 17280, 8640, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 8640, 8640, 8640, 33, 8640, 33, 17280, 33, 17280, 8640, 17280, 17280, 33, 17280, 33, 17280, 8640, 33, 33, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 33, 8640, 8640, 33, 17280, 8640, 17280, 17280, 8640, 33, 8640, 8640, 8640, 33, 17280, 8640, 17280, 33, 17280, 33, 33, 8640, 17280, 17280, 8640, 33, 8640, 33, 8640, 17280, 17280, 8640, 33, 8640, 33, 17280, 33, 33, 33, 33, 17280, 8640, 8640, 17280, 8640, 8640, 33, 8640, 17280, 8640, 33, 33, 8640, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 8640, 17280, 8640, 8640, 8640, 33, 17280, 33, 17280, 8640, 33, 8640, 33, 33, 8640, 33, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 33, 33, 17280, 8640, 17280, 8640, 17280, 8640, 33, 8640, 33, 33, 33, 17280, 17280, 8640, 8640, 33, 33, 8640, 33, 17280, 33, 33, 8640, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 8640, 17280, 8640, 33, 8640, 33, 17280, 8640, 8640, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 8640, 33, 8640, 33, 8640, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 8640, 8640, 17280, 33, 17280, 33, 33, 33, 17280, 8640, 17280, 17280, 33, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 17280, 33, 33, 8640, 33, 8640, 8640, 33, 17280, 17280, 17280, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2776938 . Total input tokens: 618377608 . Total output tokens: 555301754
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 82.20395458722487,
    "estimated_duration": 3600.1373181969616,
    "input_throughput": 6206.559090693425,
    "output_throughput": 5489.409778929659,
    "total_throughput": 11695.968869623084,
    "itl": 153.1911427214682,
    "ttft": 2044342.654729184,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 417,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3819367112219374,
    "arrivals": 924451,
    "finished_requests": 90304,
    "scheduler_time": 170.02450029792467
}
#Debug simulation 
Total elapsed time: 82.2041168063879. Arrivals time: 0.49561233446002007 Scheduler time: 81.55023632571101 Scheduler overhead time: 0.06069742189720273 Adapter cache time: 0.015460952650755644 Engine time: 0.05922378972172737 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-16/adapters_320_slots_64_rate_1.6-0.8-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-16/adapters_320_slots_64_rate_1.6-0.8-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 33, 17280, 17280, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 8640, 8640, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 17280, 17280, 8640, 33, 33, 8640, 17280, 17280, 8640, 8640, 33, 33, 8640, 17280, 17280, 33, 17280, 8640, 33, 8640, 17280, 33, 8640, 17280, 17280, 8640, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 8640, 8640, 8640, 33, 8640, 33, 17280, 33, 17280, 8640, 17280, 17280, 33, 17280, 33, 17280, 8640, 33, 33, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 33, 8640, 8640, 33, 17280, 8640, 17280, 17280, 8640, 33, 8640, 8640, 8640, 33, 17280, 8640, 17280, 33, 17280, 33, 33, 8640, 17280, 17280, 8640, 33, 8640, 33, 8640, 17280, 17280, 8640, 33, 8640, 33, 17280, 33, 33, 33, 33, 17280, 8640, 8640, 17280, 8640, 8640, 33, 8640, 17280, 8640, 33, 33, 8640, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 8640, 17280, 8640, 8640, 8640, 33, 17280, 33, 17280, 8640, 33, 8640, 33, 33, 8640, 33, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 33, 33, 17280, 8640, 17280, 8640, 17280, 8640, 33, 8640, 33, 33, 33, 17280, 17280, 8640, 8640, 33, 33, 8640, 33, 17280, 33, 33, 8640, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 8640, 17280, 8640, 33, 8640, 33, 17280, 8640, 8640, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 8640, 33, 8640, 33, 8640, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 8640, 8640, 17280, 33, 17280, 33, 33, 33, 17280, 8640, 17280, 17280, 33, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 17280, 33, 33, 8640, 33, 8640, 8640, 33, 17280, 17280, 17280, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2776938 . Total input tokens: 618377608 . Total output tokens: 555301754
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 82.93395693972707,
    "estimated_duration": 3600.122537382094,
    "input_throughput": 6230.8673571738545,
    "output_throughput": 5505.876756743361,
    "total_throughput": 11736.744113917215,
    "itl": 153.86290749243005,
    "ttft": 2043385.7764905582,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 416,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2438609226792978,
    "arrivals": 924451,
    "finished_requests": 90591,
    "scheduler_time": 169.3209767309101
}
#Debug simulation 
Total elapsed time: 82.93413430685177. Arrivals time: 0.4987173988483846 Scheduler time: 82.27960123727098 Scheduler overhead time: 0.059222334530204535 Adapter cache time: 0.01580407377332449 Engine time: 0.05883672647178173 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-32/adapters_320_slots_64_rate_1.6-0.8-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-32/adapters_320_slots_64_rate_1.6-0.8-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 33, 17280, 17280, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 8640, 8640, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 17280, 17280, 8640, 33, 33, 8640, 17280, 17280, 8640, 8640, 33, 33, 8640, 17280, 17280, 33, 17280, 8640, 33, 8640, 17280, 33, 8640, 17280, 17280, 8640, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 8640, 8640, 8640, 33, 8640, 33, 17280, 33, 17280, 8640, 17280, 17280, 33, 17280, 33, 17280, 8640, 33, 33, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 33, 8640, 8640, 33, 17280, 8640, 17280, 17280, 8640, 33, 8640, 8640, 8640, 33, 17280, 8640, 17280, 33, 17280, 33, 33, 8640, 17280, 17280, 8640, 33, 8640, 33, 8640, 17280, 17280, 8640, 33, 8640, 33, 17280, 33, 33, 33, 33, 17280, 8640, 8640, 17280, 8640, 8640, 33, 8640, 17280, 8640, 33, 33, 8640, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 8640, 17280, 8640, 8640, 8640, 33, 17280, 33, 17280, 8640, 33, 8640, 33, 33, 8640, 33, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 33, 33, 17280, 8640, 17280, 8640, 17280, 8640, 33, 8640, 33, 33, 33, 17280, 17280, 8640, 8640, 33, 33, 8640, 33, 17280, 33, 33, 8640, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 8640, 17280, 8640, 33, 8640, 33, 17280, 8640, 8640, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 8640, 33, 8640, 33, 8640, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 8640, 8640, 17280, 33, 17280, 33, 33, 33, 17280, 8640, 17280, 17280, 33, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 17280, 33, 33, 8640, 33, 8640, 8640, 33, 17280, 17280, 17280, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2776938 . Total input tokens: 618377608 . Total output tokens: 555301754
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 80.93136926693842,
    "estimated_duration": 3600.0171862706925,
    "input_throughput": 6214.30866644697,
    "output_throughput": 5492.822666350775,
    "total_throughput": 11707.131332797744,
    "itl": 153.28676266913513,
    "ttft": 2044820.002064212,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 421,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4128137991204865,
    "arrivals": 924451,
    "finished_requests": 90387,
    "scheduler_time": 169.9389596691107
}
#Debug simulation 
Total elapsed time: 80.93153535202146. Arrivals time: 0.49445905815809965 Scheduler time: 80.28085209708661 Scheduler overhead time: 0.059847719967365265 Adapter cache time: 0.01577669568359852 Engine time: 0.058271470945328474 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-8/adapters_320_slots_64_rate_1.6-0.4-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-8/adapters_320_slots_64_rate_1.6-0.4-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 1080, 17280, 17280, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 17280, 17280, 4320, 1080, 1080, 4320, 17280, 17280, 4320, 4320, 1080, 1080, 4320, 17280, 17280, 1080, 17280, 4320, 1080, 4320, 17280, 1080, 4320, 17280, 17280, 4320, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 1080, 17280, 4320, 1080, 1080, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 1080, 4320, 4320, 1080, 17280, 4320, 17280, 17280, 4320, 1080, 4320, 4320, 4320, 1080, 17280, 4320, 17280, 1080, 17280, 1080, 1080, 4320, 17280, 17280, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 4320, 4320, 17280, 4320, 4320, 1080, 4320, 17280, 4320, 1080, 1080, 4320, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 4320, 17280, 4320, 4320, 4320, 1080, 17280, 1080, 17280, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 4320, 1080, 4320, 1080, 1080, 1080, 17280, 17280, 4320, 4320, 1080, 1080, 4320, 1080, 17280, 1080, 1080, 4320, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 4320, 1080, 4320, 1080, 17280, 4320, 4320, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 4320, 4320, 17280, 1080, 17280, 1080, 1080, 1080, 17280, 4320, 17280, 17280, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 17280, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 17280, 17280, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 2425680 . Total input tokens: 540332341 . Total output tokens: 485051984
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 83.53071295982227,
    "estimated_duration": 3600.0565561188555,
    "input_throughput": 6229.941294083253,
    "output_throughput": 5484.67633555369,
    "total_throughput": 11714.617629636941,
    "itl": 152.7529722622548,
    "ttft": 2021784.321352175,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 513,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5700302126375212,
    "arrivals": 807771,
    "finished_requests": 90581,
    "scheduler_time": 169.69041534095362
}
#Debug simulation 
Total elapsed time: 83.53087138477713. Arrivals time: 0.48012339882552624 Scheduler time: 82.88900229893625 Scheduler overhead time: 0.06212072120979428 Adapter cache time: 0.01787374122068286 Engine time: 0.05940691288560629 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-16/adapters_320_slots_64_rate_1.6-0.4-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-16/adapters_320_slots_64_rate_1.6-0.4-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 1080, 17280, 17280, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 17280, 17280, 4320, 1080, 1080, 4320, 17280, 17280, 4320, 4320, 1080, 1080, 4320, 17280, 17280, 1080, 17280, 4320, 1080, 4320, 17280, 1080, 4320, 17280, 17280, 4320, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 1080, 17280, 4320, 1080, 1080, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 1080, 4320, 4320, 1080, 17280, 4320, 17280, 17280, 4320, 1080, 4320, 4320, 4320, 1080, 17280, 4320, 17280, 1080, 17280, 1080, 1080, 4320, 17280, 17280, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 4320, 4320, 17280, 4320, 4320, 1080, 4320, 17280, 4320, 1080, 1080, 4320, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 4320, 17280, 4320, 4320, 4320, 1080, 17280, 1080, 17280, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 4320, 1080, 4320, 1080, 1080, 1080, 17280, 17280, 4320, 4320, 1080, 1080, 4320, 1080, 17280, 1080, 1080, 4320, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 4320, 1080, 4320, 1080, 17280, 4320, 4320, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 4320, 4320, 17280, 1080, 17280, 1080, 1080, 1080, 17280, 4320, 17280, 17280, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 17280, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 17280, 17280, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 2425680 . Total input tokens: 540332341 . Total output tokens: 485051984
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 86.7510127928108,
    "estimated_duration": 3600.068096515871,
    "input_throughput": 6240.124741457364,
    "output_throughput": 5499.918465198596,
    "total_throughput": 11740.043206655959,
    "itl": 153.73072857296646,
    "ttft": 2019868.1312117362,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 541,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7622599522699651,
    "arrivals": 807771,
    "finished_requests": 90747,
    "scheduler_time": 169.06174202792567
}
#Debug simulation 
Total elapsed time: 86.75118204578757. Arrivals time: 0.5096230460330844 Scheduler time: 86.07787536317483 Scheduler overhead time: 0.06212255312129855 Adapter cache time: 0.018486078828573227 Engine time: 0.06062705768272281 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-32/adapters_320_slots_64_rate_1.6-0.4-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-32/adapters_320_slots_64_rate_1.6-0.4-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 1080, 17280, 17280, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 17280, 17280, 4320, 1080, 1080, 4320, 17280, 17280, 4320, 4320, 1080, 1080, 4320, 17280, 17280, 1080, 17280, 4320, 1080, 4320, 17280, 1080, 4320, 17280, 17280, 4320, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 1080, 17280, 4320, 1080, 1080, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 1080, 4320, 4320, 1080, 17280, 4320, 17280, 17280, 4320, 1080, 4320, 4320, 4320, 1080, 17280, 4320, 17280, 1080, 17280, 1080, 1080, 4320, 17280, 17280, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 4320, 4320, 17280, 4320, 4320, 1080, 4320, 17280, 4320, 1080, 1080, 4320, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 4320, 17280, 4320, 4320, 4320, 1080, 17280, 1080, 17280, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 4320, 1080, 4320, 1080, 1080, 1080, 17280, 17280, 4320, 4320, 1080, 1080, 4320, 1080, 17280, 1080, 1080, 4320, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 4320, 1080, 4320, 1080, 17280, 4320, 4320, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 4320, 4320, 17280, 1080, 17280, 1080, 1080, 1080, 17280, 4320, 17280, 17280, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 17280, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 17280, 17280, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 2425680 . Total input tokens: 540332341 . Total output tokens: 485051984
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 86.74947788007557,
    "estimated_duration": 3600.0722205462584,
    "input_throughput": 6240.11759313853,
    "output_throughput": 5499.912164816412,
    "total_throughput": 11740.029757954942,
    "itl": 153.73083767860854,
    "ttft": 2019869.848450075,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 541,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7659293102473128,
    "arrivals": 807771,
    "finished_requests": 90747,
    "scheduler_time": 169.06177898651356
}
#Debug simulation 
Total elapsed time: 86.7496393811889. Arrivals time: 0.4996509519405663 Scheduler time: 86.08913585823029 Scheduler overhead time: 0.061028683092445135 Adapter cache time: 0.01847580447793007 Engine time: 0.05919518833979964 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-16-16/adapters_320_slots_64_rate_1.6-0.4-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-16-16/adapters_320_slots_64_rate_1.6-0.4-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 1080, 17280, 17280, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 17280, 17280, 4320, 1080, 1080, 4320, 17280, 17280, 4320, 4320, 1080, 1080, 4320, 17280, 17280, 1080, 17280, 4320, 1080, 4320, 17280, 1080, 4320, 17280, 17280, 4320, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 1080, 17280, 4320, 1080, 1080, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 1080, 4320, 4320, 1080, 17280, 4320, 17280, 17280, 4320, 1080, 4320, 4320, 4320, 1080, 17280, 4320, 17280, 1080, 17280, 1080, 1080, 4320, 17280, 17280, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 4320, 4320, 17280, 4320, 4320, 1080, 4320, 17280, 4320, 1080, 1080, 4320, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 4320, 17280, 4320, 4320, 4320, 1080, 17280, 1080, 17280, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 4320, 1080, 4320, 1080, 1080, 1080, 17280, 17280, 4320, 4320, 1080, 1080, 4320, 1080, 17280, 1080, 1080, 4320, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 4320, 1080, 4320, 1080, 17280, 4320, 4320, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 4320, 4320, 17280, 1080, 17280, 1080, 1080, 1080, 17280, 4320, 17280, 17280, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 17280, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 17280, 17280, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 2425680 . Total input tokens: 540332341 . Total output tokens: 485051984
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 83.32024704990909,
    "estimated_duration": 3600.093342168017,
    "input_throughput": 6229.877636031937,
    "output_throughput": 5484.62029268087,
    "total_throughput": 11714.497928712806,
    "itl": 152.75401966907916,
    "ttft": 2021800.8694857582,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 513,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.605808577330311,
    "arrivals": 807771,
    "finished_requests": 90581,
    "scheduler_time": 169.6907513353005
}
#Debug simulation 
Total elapsed time: 83.32041712198406. Arrivals time: 0.5402434356510639 Scheduler time: 82.61549414461479 Scheduler overhead time: 0.06443640822544694 Adapter cache time: 0.01784900715574622 Engine time: 0.05973377637565136 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-16-32/adapters_320_slots_64_rate_1.6-0.4-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-16-32/adapters_320_slots_64_rate_1.6-0.4-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 1080, 17280, 17280, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 17280, 17280, 4320, 1080, 1080, 4320, 17280, 17280, 4320, 4320, 1080, 1080, 4320, 17280, 17280, 1080, 17280, 4320, 1080, 4320, 17280, 1080, 4320, 17280, 17280, 4320, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 1080, 17280, 4320, 1080, 1080, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 1080, 4320, 4320, 1080, 17280, 4320, 17280, 17280, 4320, 1080, 4320, 4320, 4320, 1080, 17280, 4320, 17280, 1080, 17280, 1080, 1080, 4320, 17280, 17280, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 4320, 4320, 17280, 4320, 4320, 1080, 4320, 17280, 4320, 1080, 1080, 4320, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 4320, 17280, 4320, 4320, 4320, 1080, 17280, 1080, 17280, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 4320, 1080, 4320, 1080, 1080, 1080, 17280, 17280, 4320, 4320, 1080, 1080, 4320, 1080, 17280, 1080, 1080, 4320, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 4320, 1080, 4320, 1080, 17280, 4320, 4320, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 4320, 4320, 17280, 1080, 17280, 1080, 1080, 1080, 17280, 4320, 17280, 17280, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 17280, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 17280, 17280, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 2425680 . Total input tokens: 540332341 . Total output tokens: 485051984
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 86.7022302057594,
    "estimated_duration": 3600.093774876825,
    "input_throughput": 6240.080232568003,
    "output_throughput": 5499.879235972804,
    "total_throughput": 11739.959468540806,
    "itl": 153.73157281545798,
    "ttft": 2019878.562818106,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 541,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7869301925785885,
    "arrivals": 807771,
    "finished_requests": 90747,
    "scheduler_time": 169.06191472096975
}
#Debug simulation 
Total elapsed time: 86.70239327801391. Arrivals time: 0.4890717836096883 Scheduler time: 86.05153247201815 Scheduler overhead time: 0.061327388510107994 Adapter cache time: 0.018737197387963533 Engine time: 0.05952366255223751 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_16-16-16/adapters_320_slots_64_rate_1.6-0.4-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_16-16-16/adapters_320_slots_64_rate_1.6-0.4-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 1080, 17280, 17280, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 17280, 17280, 4320, 1080, 1080, 4320, 17280, 17280, 4320, 4320, 1080, 1080, 4320, 17280, 17280, 1080, 17280, 4320, 1080, 4320, 17280, 1080, 4320, 17280, 17280, 4320, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 1080, 17280, 4320, 1080, 1080, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 1080, 4320, 4320, 1080, 17280, 4320, 17280, 17280, 4320, 1080, 4320, 4320, 4320, 1080, 17280, 4320, 17280, 1080, 17280, 1080, 1080, 4320, 17280, 17280, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 4320, 4320, 17280, 4320, 4320, 1080, 4320, 17280, 4320, 1080, 1080, 4320, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 4320, 17280, 4320, 4320, 4320, 1080, 17280, 1080, 17280, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 4320, 1080, 4320, 1080, 1080, 1080, 17280, 17280, 4320, 4320, 1080, 1080, 4320, 1080, 17280, 1080, 1080, 4320, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 4320, 1080, 4320, 1080, 17280, 4320, 4320, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 4320, 4320, 17280, 1080, 17280, 1080, 1080, 1080, 17280, 4320, 17280, 17280, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 17280, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 17280, 17280, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 2425680 . Total input tokens: 540332341 . Total output tokens: 485051984
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 83.36176777584478,
    "estimated_duration": 3600.021362218003,
    "input_throughput": 6230.002198148579,
    "output_throughput": 5484.729953889732,
    "total_throughput": 11714.732152038312,
    "itl": 152.75201680039882,
    "ttft": 2021769.7259495412,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 513,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5338958012847985,
    "arrivals": 807771,
    "finished_requests": 90581,
    "scheduler_time": 169.68996347205234
}
#Debug simulation 
Total elapsed time: 83.36192815890536. Arrivals time: 0.48791035497561097 Scheduler time: 82.71153668593615 Scheduler overhead time: 0.061398840975016356 Adapter cache time: 0.017955449875444174 Engine time: 0.06002572737634182 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_16-16-32/adapters_320_slots_64_rate_1.6-0.4-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_16-16-32/adapters_320_slots_64_rate_1.6-0.4-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 1080, 17280, 17280, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 17280, 17280, 4320, 1080, 1080, 4320, 17280, 17280, 4320, 4320, 1080, 1080, 4320, 17280, 17280, 1080, 17280, 4320, 1080, 4320, 17280, 1080, 4320, 17280, 17280, 4320, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 1080, 17280, 4320, 1080, 1080, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 1080, 4320, 4320, 1080, 17280, 4320, 17280, 17280, 4320, 1080, 4320, 4320, 4320, 1080, 17280, 4320, 17280, 1080, 17280, 1080, 1080, 4320, 17280, 17280, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 4320, 4320, 17280, 4320, 4320, 1080, 4320, 17280, 4320, 1080, 1080, 4320, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 4320, 17280, 4320, 4320, 4320, 1080, 17280, 1080, 17280, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 4320, 1080, 4320, 1080, 1080, 1080, 17280, 17280, 4320, 4320, 1080, 1080, 4320, 1080, 17280, 1080, 1080, 4320, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 4320, 1080, 4320, 1080, 17280, 4320, 4320, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 4320, 4320, 17280, 1080, 17280, 1080, 1080, 1080, 17280, 4320, 17280, 17280, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 17280, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 17280, 17280, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 2425680 . Total input tokens: 540332341 . Total output tokens: 485051984
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 84.78124979371205,
    "estimated_duration": 3600.1733446900193,
    "input_throughput": 6232.935153829958,
    "output_throughput": 5488.359061694371,
    "total_throughput": 11721.294215524329,
    "itl": 153.10528498188262,
    "ttft": 2021286.9501068115,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 510,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.708226044550536,
    "arrivals": 807771,
    "finished_requests": 90632,
    "scheduler_time": 169.46064858014222
}
#Debug simulation 
Total elapsed time: 84.78141876775771. Arrivals time: 0.4927761540748179 Scheduler time: 84.12621617736295 Scheduler overhead time: 0.06197084952145815 Adapter cache time: 0.018238463439047337 Engine time: 0.06007605046033859 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-8/adapters_320_slots_64_rate_1.6-0.4-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-8/adapters_320_slots_64_rate_1.6-0.4-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 540, 17280, 17280, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 17280, 17280, 4320, 540, 540, 4320, 17280, 17280, 4320, 4320, 540, 540, 4320, 17280, 17280, 540, 17280, 4320, 540, 4320, 17280, 540, 4320, 17280, 17280, 4320, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 17280, 540, 17280, 4320, 17280, 17280, 540, 17280, 540, 17280, 4320, 540, 540, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 540, 4320, 4320, 540, 17280, 4320, 17280, 17280, 4320, 540, 4320, 4320, 4320, 540, 17280, 4320, 17280, 540, 17280, 540, 540, 4320, 17280, 17280, 4320, 540, 4320, 540, 4320, 17280, 17280, 4320, 540, 4320, 540, 17280, 540, 540, 540, 540, 17280, 4320, 4320, 17280, 4320, 4320, 540, 4320, 17280, 4320, 540, 540, 4320, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 4320, 17280, 4320, 4320, 4320, 540, 17280, 540, 17280, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 540, 540, 17280, 4320, 17280, 4320, 17280, 4320, 540, 4320, 540, 540, 540, 17280, 17280, 4320, 4320, 540, 540, 4320, 540, 17280, 540, 540, 4320, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 4320, 17280, 4320, 540, 4320, 540, 17280, 4320, 4320, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 4320, 540, 4320, 540, 4320, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 4320, 4320, 17280, 540, 17280, 540, 540, 540, 17280, 4320, 17280, 17280, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 17280, 540, 540, 4320, 540, 4320, 4320, 540, 17280, 17280, 17280, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2368440 . Total input tokens: 527524345 . Total output tokens: 473668431
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 86.51949921483174,
    "estimated_duration": 3600.054087302458,
    "input_throughput": 6258.480971012998,
    "output_throughput": 5489.730854240798,
    "total_throughput": 11748.211825253797,
    "itl": 152.99438552958478,
    "ttft": 2008890.0460675075,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 456,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3955824112333481,
    "arrivals": 788657,
    "finished_requests": 90791,
    "scheduler_time": 169.4374120064279
}
#Debug simulation 
Total elapsed time: 86.51965831778944. Arrivals time: 0.4837868083268404 Scheduler time: 85.87402027938515 Scheduler overhead time: 0.06119268573820591 Adapter cache time: 0.01714574871584773 Engine time: 0.060415591578930616 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-16/adapters_320_slots_64_rate_1.6-0.4-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-16/adapters_320_slots_64_rate_1.6-0.4-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 540, 17280, 17280, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 17280, 17280, 4320, 540, 540, 4320, 17280, 17280, 4320, 4320, 540, 540, 4320, 17280, 17280, 540, 17280, 4320, 540, 4320, 17280, 540, 4320, 17280, 17280, 4320, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 17280, 540, 17280, 4320, 17280, 17280, 540, 17280, 540, 17280, 4320, 540, 540, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 540, 4320, 4320, 540, 17280, 4320, 17280, 17280, 4320, 540, 4320, 4320, 4320, 540, 17280, 4320, 17280, 540, 17280, 540, 540, 4320, 17280, 17280, 4320, 540, 4320, 540, 4320, 17280, 17280, 4320, 540, 4320, 540, 17280, 540, 540, 540, 540, 17280, 4320, 4320, 17280, 4320, 4320, 540, 4320, 17280, 4320, 540, 540, 4320, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 4320, 17280, 4320, 4320, 4320, 540, 17280, 540, 17280, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 540, 540, 17280, 4320, 17280, 4320, 17280, 4320, 540, 4320, 540, 540, 540, 17280, 17280, 4320, 4320, 540, 540, 4320, 540, 17280, 540, 540, 4320, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 4320, 17280, 4320, 540, 4320, 540, 17280, 4320, 4320, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 4320, 540, 4320, 540, 4320, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 4320, 4320, 17280, 540, 17280, 540, 540, 540, 17280, 4320, 17280, 17280, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 17280, 540, 540, 4320, 540, 4320, 4320, 540, 17280, 17280, 17280, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2368440 . Total input tokens: 527524345 . Total output tokens: 473668431
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 91.533267066814,
    "estimated_duration": 3600.098475341132,
    "input_throughput": 6252.187309367191,
    "output_throughput": 5486.814078919958,
    "total_throughput": 11739.00138828715,
    "itl": 152.89673475232007,
    "ttft": 2008016.3544774593,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 427,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3944269276340546,
    "arrivals": 788657,
    "finished_requests": 90778,
    "scheduler_time": 169.60770427348868
}
#Debug simulation 
Total elapsed time: 91.53344249911606. Arrivals time: 0.5071530234999955 Scheduler time: 90.86301228264347 Scheduler overhead time: 0.06187292095273733 Adapter cache time: 0.01738356053829193 Engine time: 0.06093869125470519 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-32/adapters_320_slots_64_rate_1.6-0.4-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-32/adapters_320_slots_64_rate_1.6-0.4-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 540, 17280, 17280, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 17280, 17280, 4320, 540, 540, 4320, 17280, 17280, 4320, 4320, 540, 540, 4320, 17280, 17280, 540, 17280, 4320, 540, 4320, 17280, 540, 4320, 17280, 17280, 4320, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 17280, 540, 17280, 4320, 17280, 17280, 540, 17280, 540, 17280, 4320, 540, 540, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 540, 4320, 4320, 540, 17280, 4320, 17280, 17280, 4320, 540, 4320, 4320, 4320, 540, 17280, 4320, 17280, 540, 17280, 540, 540, 4320, 17280, 17280, 4320, 540, 4320, 540, 4320, 17280, 17280, 4320, 540, 4320, 540, 17280, 540, 540, 540, 540, 17280, 4320, 4320, 17280, 4320, 4320, 540, 4320, 17280, 4320, 540, 540, 4320, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 4320, 17280, 4320, 4320, 4320, 540, 17280, 540, 17280, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 540, 540, 17280, 4320, 17280, 4320, 17280, 4320, 540, 4320, 540, 540, 540, 17280, 17280, 4320, 4320, 540, 540, 4320, 540, 17280, 540, 540, 4320, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 4320, 17280, 4320, 540, 4320, 540, 17280, 4320, 4320, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 4320, 540, 4320, 540, 4320, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 4320, 4320, 17280, 540, 17280, 540, 540, 540, 17280, 4320, 17280, 17280, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 17280, 540, 540, 4320, 540, 4320, 4320, 540, 17280, 17280, 17280, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2368440 . Total input tokens: 527524345 . Total output tokens: 473668431
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 91.15323392581195,
    "estimated_duration": 3600.100765878571,
    "input_throughput": 6252.183331459339,
    "output_throughput": 5486.810587975153,
    "total_throughput": 11738.993919434492,
    "itl": 152.89681939283773,
    "ttft": 2008017.3653542907,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 427,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3967098268494091,
    "arrivals": 788657,
    "finished_requests": 90778,
    "scheduler_time": 169.60771191169292
}
#Debug simulation 
Total elapsed time: 91.15340631175786. Arrivals time: 0.4932198906317353 Scheduler time: 90.49983845185488 Scheduler overhead time: 0.060730697587132454 Adapter cache time: 0.017122802790254354 Engine time: 0.05997411860153079 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-16-16/adapters_320_slots_64_rate_1.6-0.4-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-16-16/adapters_320_slots_64_rate_1.6-0.4-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 540, 17280, 17280, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 17280, 17280, 4320, 540, 540, 4320, 17280, 17280, 4320, 4320, 540, 540, 4320, 17280, 17280, 540, 17280, 4320, 540, 4320, 17280, 540, 4320, 17280, 17280, 4320, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 17280, 540, 17280, 4320, 17280, 17280, 540, 17280, 540, 17280, 4320, 540, 540, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 540, 4320, 4320, 540, 17280, 4320, 17280, 17280, 4320, 540, 4320, 4320, 4320, 540, 17280, 4320, 17280, 540, 17280, 540, 540, 4320, 17280, 17280, 4320, 540, 4320, 540, 4320, 17280, 17280, 4320, 540, 4320, 540, 17280, 540, 540, 540, 540, 17280, 4320, 4320, 17280, 4320, 4320, 540, 4320, 17280, 4320, 540, 540, 4320, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 4320, 17280, 4320, 4320, 4320, 540, 17280, 540, 17280, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 540, 540, 17280, 4320, 17280, 4320, 17280, 4320, 540, 4320, 540, 540, 540, 17280, 17280, 4320, 4320, 540, 540, 4320, 540, 17280, 540, 540, 4320, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 4320, 17280, 4320, 540, 4320, 540, 17280, 4320, 4320, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 4320, 540, 4320, 540, 4320, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 4320, 4320, 17280, 540, 17280, 540, 540, 540, 17280, 4320, 17280, 17280, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 17280, 540, 540, 4320, 540, 4320, 4320, 540, 17280, 17280, 17280, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2368440 . Total input tokens: 527524345 . Total output tokens: 473668431
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 91.96204308513552,
    "estimated_duration": 3600.0161998693893,
    "input_throughput": 6249.302989474388,
    "output_throughput": 5481.29422326375,
    "total_throughput": 11730.597212738137,
    "itl": 152.55880331939903,
    "ttft": 2008395.5590669946,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 427,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.33804077368928,
    "arrivals": 788657,
    "finished_requests": 90713,
    "scheduler_time": 169.89547105543312
}
#Debug simulation 
Total elapsed time: 91.96221204008907. Arrivals time: 0.4983015120960772 Scheduler time: 91.30111968051642 Scheduler overhead time: 0.062022802885621786 Adapter cache time: 0.016998118720948696 Engine time: 0.06082180701196194 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-16-32/adapters_320_slots_64_rate_1.6-0.4-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-16-32/adapters_320_slots_64_rate_1.6-0.4-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 540, 17280, 17280, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 17280, 17280, 4320, 540, 540, 4320, 17280, 17280, 4320, 4320, 540, 540, 4320, 17280, 17280, 540, 17280, 4320, 540, 4320, 17280, 540, 4320, 17280, 17280, 4320, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 17280, 540, 17280, 4320, 17280, 17280, 540, 17280, 540, 17280, 4320, 540, 540, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 540, 4320, 4320, 540, 17280, 4320, 17280, 17280, 4320, 540, 4320, 4320, 4320, 540, 17280, 4320, 17280, 540, 17280, 540, 540, 4320, 17280, 17280, 4320, 540, 4320, 540, 4320, 17280, 17280, 4320, 540, 4320, 540, 17280, 540, 540, 540, 540, 17280, 4320, 4320, 17280, 4320, 4320, 540, 4320, 17280, 4320, 540, 540, 4320, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 4320, 17280, 4320, 4320, 4320, 540, 17280, 540, 17280, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 540, 540, 17280, 4320, 17280, 4320, 17280, 4320, 540, 4320, 540, 540, 540, 17280, 17280, 4320, 4320, 540, 540, 4320, 540, 17280, 540, 540, 4320, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 4320, 17280, 4320, 540, 4320, 540, 17280, 4320, 4320, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 4320, 540, 4320, 540, 4320, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 4320, 4320, 17280, 540, 17280, 540, 540, 540, 17280, 4320, 17280, 17280, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 17280, 540, 540, 4320, 540, 4320, 4320, 540, 17280, 17280, 17280, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2368440 . Total input tokens: 527524345 . Total output tokens: 473668431
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 91.41164570022374,
    "estimated_duration": 3600.1165237610267,
    "input_throughput": 6252.155965353442,
    "output_throughput": 5486.786571942413,
    "total_throughput": 11738.942537295856,
    "itl": 152.8972920027,
    "ttft": 2008024.7681630407,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 427,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4140638493746573,
    "arrivals": 788657,
    "finished_requests": 90778,
    "scheduler_time": 169.6077866268374
}
#Debug simulation 
Total elapsed time: 91.41181326191872. Arrivals time: 0.5008205720223486 Scheduler time: 90.7482694410719 Scheduler overhead time: 0.06246441835537553 Adapter cache time: 0.01718584168702364 Engine time: 0.06072672689333558 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_16-16-16/adapters_320_slots_64_rate_1.6-0.4-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_16-16-16/adapters_320_slots_64_rate_1.6-0.4-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 540, 17280, 17280, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 17280, 17280, 4320, 540, 540, 4320, 17280, 17280, 4320, 4320, 540, 540, 4320, 17280, 17280, 540, 17280, 4320, 540, 4320, 17280, 540, 4320, 17280, 17280, 4320, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 17280, 540, 17280, 4320, 17280, 17280, 540, 17280, 540, 17280, 4320, 540, 540, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 540, 4320, 4320, 540, 17280, 4320, 17280, 17280, 4320, 540, 4320, 4320, 4320, 540, 17280, 4320, 17280, 540, 17280, 540, 540, 4320, 17280, 17280, 4320, 540, 4320, 540, 4320, 17280, 17280, 4320, 540, 4320, 540, 17280, 540, 540, 540, 540, 17280, 4320, 4320, 17280, 4320, 4320, 540, 4320, 17280, 4320, 540, 540, 4320, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 4320, 17280, 4320, 4320, 4320, 540, 17280, 540, 17280, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 540, 540, 17280, 4320, 17280, 4320, 17280, 4320, 540, 4320, 540, 540, 540, 17280, 17280, 4320, 4320, 540, 540, 4320, 540, 17280, 540, 540, 4320, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 4320, 17280, 4320, 540, 4320, 540, 17280, 4320, 4320, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 4320, 540, 4320, 540, 4320, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 4320, 4320, 17280, 540, 17280, 540, 540, 540, 17280, 4320, 17280, 17280, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 17280, 540, 540, 4320, 540, 4320, 4320, 540, 17280, 17280, 17280, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2368440 . Total input tokens: 527524345 . Total output tokens: 473668431
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 86.12610684102401,
    "estimated_duration": 3600.0014455660407,
    "input_throughput": 6240.445549728843,
    "output_throughput": 5492.485016736161,
    "total_throughput": 11732.930566465004,
    "itl": 153.19643850383503,
    "ttft": 2010214.8424588048,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 526,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5727664551185254,
    "arrivals": 788657,
    "finished_requests": 90807,
    "scheduler_time": 169.3648596009484
}
#Debug simulation 
Total elapsed time: 86.12627986492589. Arrivals time: 0.4986544377170503 Scheduler time: 85.46579480497167 Scheduler overhead time: 0.06136729521676898 Adapter cache time: 0.018560851458460093 Engine time: 0.05920318467542529 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_16-16-32/adapters_320_slots_64_rate_1.6-0.4-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_16-16-32/adapters_320_slots_64_rate_1.6-0.4-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 540, 17280, 17280, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 17280, 17280, 4320, 540, 540, 4320, 17280, 17280, 4320, 4320, 540, 540, 4320, 17280, 17280, 540, 17280, 4320, 540, 4320, 17280, 540, 4320, 17280, 17280, 4320, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 17280, 540, 17280, 4320, 17280, 17280, 540, 17280, 540, 17280, 4320, 540, 540, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 540, 4320, 4320, 540, 17280, 4320, 17280, 17280, 4320, 540, 4320, 4320, 4320, 540, 17280, 4320, 17280, 540, 17280, 540, 540, 4320, 17280, 17280, 4320, 540, 4320, 540, 4320, 17280, 17280, 4320, 540, 4320, 540, 17280, 540, 540, 540, 540, 17280, 4320, 4320, 17280, 4320, 4320, 540, 4320, 17280, 4320, 540, 540, 4320, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 4320, 17280, 4320, 4320, 4320, 540, 17280, 540, 17280, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 540, 540, 17280, 4320, 17280, 4320, 17280, 4320, 540, 4320, 540, 540, 540, 17280, 17280, 4320, 4320, 540, 540, 4320, 540, 17280, 540, 540, 4320, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 4320, 17280, 4320, 540, 4320, 540, 17280, 4320, 4320, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 4320, 540, 4320, 540, 4320, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 4320, 4320, 17280, 540, 17280, 540, 540, 540, 17280, 4320, 17280, 17280, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 17280, 540, 540, 4320, 540, 4320, 4320, 540, 17280, 17280, 17280, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2368440 . Total input tokens: 527524345 . Total output tokens: 473668431
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 91.16290044691414,
    "estimated_duration": 3600.056083664792,
    "input_throughput": 6258.106950674319,
    "output_throughput": 5491.58805878226,
    "total_throughput": 11749.695009456578,
    "itl": 153.0385928831302,
    "ttft": 2008170.9628293107,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 428,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4359704361855996,
    "arrivals": 788657,
    "finished_requests": 90858,
    "scheduler_time": 169.45659607040986
}
#Debug simulation 
Total elapsed time: 91.16306698368862. Arrivals time: 0.503260713070631 Scheduler time: 90.49773087864742 Scheduler overhead time: 0.061084688641130924 Adapter cache time: 0.016852219123393297 Engine time: 0.06093703489750624 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-8/adapters_320_slots_64_rate_1.6-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-8/adapters_320_slots_64_rate_1.6-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 270, 17280, 17280, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 17280, 17280, 4320, 270, 270, 4320, 17280, 17280, 4320, 4320, 270, 270, 4320, 17280, 17280, 270, 17280, 4320, 270, 4320, 17280, 270, 4320, 17280, 17280, 4320, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 17280, 270, 17280, 4320, 17280, 17280, 270, 17280, 270, 17280, 4320, 270, 270, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 270, 4320, 4320, 270, 17280, 4320, 17280, 17280, 4320, 270, 4320, 4320, 4320, 270, 17280, 4320, 17280, 270, 17280, 270, 270, 4320, 17280, 17280, 4320, 270, 4320, 270, 4320, 17280, 17280, 4320, 270, 4320, 270, 17280, 270, 270, 270, 270, 17280, 4320, 4320, 17280, 4320, 4320, 270, 4320, 17280, 4320, 270, 270, 4320, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 4320, 17280, 4320, 4320, 4320, 270, 17280, 270, 17280, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 270, 270, 17280, 4320, 17280, 4320, 17280, 4320, 270, 4320, 270, 270, 270, 17280, 17280, 4320, 4320, 270, 270, 4320, 270, 17280, 270, 270, 4320, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 4320, 17280, 4320, 270, 4320, 270, 17280, 4320, 4320, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 4320, 270, 4320, 270, 4320, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 4320, 4320, 17280, 270, 17280, 270, 270, 270, 17280, 4320, 17280, 17280, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 17280, 270, 270, 4320, 270, 4320, 4320, 270, 17280, 17280, 17280, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2339820 . Total input tokens: 521146796 . Total output tokens: 467944613
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 88.85653048800305,
    "estimated_duration": 3600.002201098105,
    "input_throughput": 6201.140930744568,
    "output_throughput": 5494.004696432409,
    "total_throughput": 11695.145627176978,
    "itl": 153.79774658124862,
    "ttft": 2012703.0783863997,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 480,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4690341170877368,
    "arrivals": 779141,
    "finished_requests": 90526,
    "scheduler_time": 169.18265921300366
}
#Debug simulation 
Total elapsed time: 88.85670456197113. Arrivals time: 0.49585285456851125 Scheduler time: 88.2003007363528 Scheduler overhead time: 0.06078593013808131 Adapter cache time: 0.017463316675275564 Engine time: 0.059395847376435995 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-16/adapters_320_slots_64_rate_1.6-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-16/adapters_320_slots_64_rate_1.6-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 270, 17280, 17280, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 17280, 17280, 4320, 270, 270, 4320, 17280, 17280, 4320, 4320, 270, 270, 4320, 17280, 17280, 270, 17280, 4320, 270, 4320, 17280, 270, 4320, 17280, 17280, 4320, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 17280, 270, 17280, 4320, 17280, 17280, 270, 17280, 270, 17280, 4320, 270, 270, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 270, 4320, 4320, 270, 17280, 4320, 17280, 17280, 4320, 270, 4320, 4320, 4320, 270, 17280, 4320, 17280, 270, 17280, 270, 270, 4320, 17280, 17280, 4320, 270, 4320, 270, 4320, 17280, 17280, 4320, 270, 4320, 270, 17280, 270, 270, 270, 270, 17280, 4320, 4320, 17280, 4320, 4320, 270, 4320, 17280, 4320, 270, 270, 4320, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 4320, 17280, 4320, 4320, 4320, 270, 17280, 270, 17280, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 270, 270, 17280, 4320, 17280, 4320, 17280, 4320, 270, 4320, 270, 270, 270, 17280, 17280, 4320, 4320, 270, 270, 4320, 270, 17280, 270, 270, 4320, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 4320, 17280, 4320, 270, 4320, 270, 17280, 4320, 4320, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 4320, 270, 4320, 270, 4320, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 4320, 4320, 17280, 270, 17280, 270, 270, 270, 17280, 4320, 17280, 17280, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 17280, 270, 270, 4320, 270, 4320, 4320, 270, 17280, 17280, 17280, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2339820 . Total input tokens: 521146796 . Total output tokens: 467944613
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 89.83598097786307,
    "estimated_duration": 3600.0503989414906,
    "input_throughput": 6200.572360476776,
    "output_throughput": 5494.690853721432,
    "total_throughput": 11695.263214198209,
    "itl": 153.82549591880587,
    "ttft": 2012079.656903634,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 477,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5553701112954927,
    "arrivals": 779141,
    "finished_requests": 90522,
    "scheduler_time": 169.14082618898763
}
#Debug simulation 
Total elapsed time: 89.83614846179262. Arrivals time: 0.5005492474883795 Scheduler time: 89.17355400556698 Scheduler overhead time: 0.06149792345240712 Adapter cache time: 0.017882701475173235 Engine time: 0.06019742740318179 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-32/adapters_320_slots_64_rate_1.6-0.4-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-32/adapters_320_slots_64_rate_1.6-0.4-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 270, 17280, 17280, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 17280, 17280, 4320, 270, 270, 4320, 17280, 17280, 4320, 4320, 270, 270, 4320, 17280, 17280, 270, 17280, 4320, 270, 4320, 17280, 270, 4320, 17280, 17280, 4320, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 17280, 270, 17280, 4320, 17280, 17280, 270, 17280, 270, 17280, 4320, 270, 270, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 270, 4320, 4320, 270, 17280, 4320, 17280, 17280, 4320, 270, 4320, 4320, 4320, 270, 17280, 4320, 17280, 270, 17280, 270, 270, 4320, 17280, 17280, 4320, 270, 4320, 270, 4320, 17280, 17280, 4320, 270, 4320, 270, 17280, 270, 270, 270, 270, 17280, 4320, 4320, 17280, 4320, 4320, 270, 4320, 17280, 4320, 270, 270, 4320, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 4320, 17280, 4320, 4320, 4320, 270, 17280, 270, 17280, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 270, 270, 17280, 4320, 17280, 4320, 17280, 4320, 270, 4320, 270, 270, 270, 17280, 17280, 4320, 4320, 270, 270, 4320, 270, 17280, 270, 270, 4320, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 4320, 17280, 4320, 270, 4320, 270, 17280, 4320, 4320, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 4320, 270, 4320, 270, 4320, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 4320, 4320, 17280, 270, 17280, 270, 270, 270, 17280, 4320, 17280, 17280, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 17280, 270, 270, 4320, 270, 4320, 4320, 270, 17280, 17280, 17280, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2339820 . Total input tokens: 521146796 . Total output tokens: 467944613
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 90.39412736194208,
    "estimated_duration": 3600.05368593136,
    "input_throughput": 6200.56669911161,
    "output_throughput": 5494.6858368537,
    "total_throughput": 11695.25253596531,
    "itl": 153.82558281476116,
    "ttft": 2012081.2105850133,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 477,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5583286991342995,
    "arrivals": 779141,
    "finished_requests": 90522,
    "scheduler_time": 169.1408761151314
}
#Debug simulation 
Total elapsed time: 90.39430189225823. Arrivals time: 0.5508653349243104 Scheduler time: 89.68083572108299 Scheduler overhead time: 0.06205633748322725 Adapter cache time: 0.017918191850185394 Engine time: 0.06048076134175062 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-16-16/adapters_320_slots_64_rate_1.6-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-16-16/adapters_320_slots_64_rate_1.6-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 270, 17280, 17280, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 17280, 17280, 4320, 270, 270, 4320, 17280, 17280, 4320, 4320, 270, 270, 4320, 17280, 17280, 270, 17280, 4320, 270, 4320, 17280, 270, 4320, 17280, 17280, 4320, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 17280, 270, 17280, 4320, 17280, 17280, 270, 17280, 270, 17280, 4320, 270, 270, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 270, 4320, 4320, 270, 17280, 4320, 17280, 17280, 4320, 270, 4320, 4320, 4320, 270, 17280, 4320, 17280, 270, 17280, 270, 270, 4320, 17280, 17280, 4320, 270, 4320, 270, 4320, 17280, 17280, 4320, 270, 4320, 270, 17280, 270, 270, 270, 270, 17280, 4320, 4320, 17280, 4320, 4320, 270, 4320, 17280, 4320, 270, 270, 4320, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 4320, 17280, 4320, 4320, 4320, 270, 17280, 270, 17280, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 270, 270, 17280, 4320, 17280, 4320, 17280, 4320, 270, 4320, 270, 270, 270, 17280, 17280, 4320, 4320, 270, 270, 4320, 270, 17280, 270, 270, 4320, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 4320, 17280, 4320, 270, 4320, 270, 17280, 4320, 4320, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 4320, 270, 4320, 270, 4320, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 4320, 4320, 17280, 270, 17280, 270, 270, 270, 17280, 4320, 17280, 17280, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 17280, 270, 270, 4320, 270, 4320, 4320, 270, 17280, 17280, 17280, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2339820 . Total input tokens: 521146796 . Total output tokens: 467944613
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 90.67036532238126,
    "estimated_duration": 3600.1533807537744,
    "input_throughput": 6200.66303823036,
    "output_throughput": 5494.636174600507,
    "total_throughput": 11695.299212830867,
    "itl": 153.82438378892064,
    "ttft": 2012075.6860104268,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 477,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.490812050981908,
    "arrivals": 779141,
    "finished_requests": 90525,
    "scheduler_time": 169.1479735979802
}
#Debug simulation 
Total elapsed time: 90.67053793324158. Arrivals time: 0.4999530469067395 Scheduler time: 90.00813106214628 Scheduler overhead time: 0.06175707234069705 Adapter cache time: 0.01771519659087062 Engine time: 0.06061186967417598 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-16-32/adapters_320_slots_64_rate_1.6-0.4-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-16-32/adapters_320_slots_64_rate_1.6-0.4-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 270, 17280, 17280, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 17280, 17280, 4320, 270, 270, 4320, 17280, 17280, 4320, 4320, 270, 270, 4320, 17280, 17280, 270, 17280, 4320, 270, 4320, 17280, 270, 4320, 17280, 17280, 4320, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 17280, 270, 17280, 4320, 17280, 17280, 270, 17280, 270, 17280, 4320, 270, 270, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 270, 4320, 4320, 270, 17280, 4320, 17280, 17280, 4320, 270, 4320, 4320, 4320, 270, 17280, 4320, 17280, 270, 17280, 270, 270, 4320, 17280, 17280, 4320, 270, 4320, 270, 4320, 17280, 17280, 4320, 270, 4320, 270, 17280, 270, 270, 270, 270, 17280, 4320, 4320, 17280, 4320, 4320, 270, 4320, 17280, 4320, 270, 270, 4320, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 4320, 17280, 4320, 4320, 4320, 270, 17280, 270, 17280, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 270, 270, 17280, 4320, 17280, 4320, 17280, 4320, 270, 4320, 270, 270, 270, 17280, 17280, 4320, 4320, 270, 270, 4320, 270, 17280, 270, 270, 4320, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 4320, 17280, 4320, 270, 4320, 270, 17280, 4320, 4320, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 4320, 270, 4320, 270, 4320, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 4320, 4320, 17280, 270, 17280, 270, 270, 270, 17280, 4320, 17280, 17280, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 17280, 270, 270, 4320, 270, 4320, 4320, 270, 17280, 17280, 17280, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2339820 . Total input tokens: 521146796 . Total output tokens: 467944613
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 89.92297958489507,
    "estimated_duration": 3600.072849659594,
    "input_throughput": 6200.533692564221,
    "output_throughput": 5494.656587816109,
    "total_throughput": 11695.19028038033,
    "itl": 153.82608857752678,
    "ttft": 2012089.2601923323,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 477,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5781977973878434,
    "arrivals": 779141,
    "finished_requests": 90522,
    "scheduler_time": 169.1410061727277
}
#Debug simulation 
Total elapsed time: 89.92315360996872. Arrivals time: 0.5008433130569756 Scheduler time: 89.26153310900554 Scheduler overhead time: 0.06063097668811679 Adapter cache time: 0.017752855084836483 Engine time: 0.060105782467871904 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_16-16-16/adapters_320_slots_64_rate_1.6-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_16-16-16/adapters_320_slots_64_rate_1.6-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 270, 17280, 17280, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 17280, 17280, 4320, 270, 270, 4320, 17280, 17280, 4320, 4320, 270, 270, 4320, 17280, 17280, 270, 17280, 4320, 270, 4320, 17280, 270, 4320, 17280, 17280, 4320, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 17280, 270, 17280, 4320, 17280, 17280, 270, 17280, 270, 17280, 4320, 270, 270, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 270, 4320, 4320, 270, 17280, 4320, 17280, 17280, 4320, 270, 4320, 4320, 4320, 270, 17280, 4320, 17280, 270, 17280, 270, 270, 4320, 17280, 17280, 4320, 270, 4320, 270, 4320, 17280, 17280, 4320, 270, 4320, 270, 17280, 270, 270, 270, 270, 17280, 4320, 4320, 17280, 4320, 4320, 270, 4320, 17280, 4320, 270, 270, 4320, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 4320, 17280, 4320, 4320, 4320, 270, 17280, 270, 17280, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 270, 270, 17280, 4320, 17280, 4320, 17280, 4320, 270, 4320, 270, 270, 270, 17280, 17280, 4320, 4320, 270, 270, 4320, 270, 17280, 270, 270, 4320, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 4320, 17280, 4320, 270, 4320, 270, 17280, 4320, 4320, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 4320, 270, 4320, 270, 4320, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 4320, 4320, 17280, 270, 17280, 270, 270, 270, 17280, 4320, 17280, 17280, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 17280, 270, 270, 4320, 270, 4320, 4320, 270, 17280, 17280, 17280, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2339820 . Total input tokens: 521146796 . Total output tokens: 467944613
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 90.74874510383233,
    "estimated_duration": 3600.143338039212,
    "input_throughput": 6201.11837329207,
    "output_throughput": 5494.035137715556,
    "total_throughput": 11695.153511007626,
    "itl": 153.7965581885141,
    "ttft": 2012765.1620040257,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 480,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4352241415530302,
    "arrivals": 779141,
    "finished_requests": 90530,
    "scheduler_time": 169.19011498138968
}
#Debug simulation 
Total elapsed time: 90.7489068210125. Arrivals time: 0.48765469063073397 Scheduler time: 90.10108276642859 Scheduler overhead time: 0.0604386767372489 Adapter cache time: 0.01769453240558505 Engine time: 0.05950818303972483 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_16-16-32/adapters_320_slots_64_rate_1.6-0.4-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_16-16-32/adapters_320_slots_64_rate_1.6-0.4-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 270, 17280, 17280, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 17280, 17280, 4320, 270, 270, 4320, 17280, 17280, 4320, 4320, 270, 270, 4320, 17280, 17280, 270, 17280, 4320, 270, 4320, 17280, 270, 4320, 17280, 17280, 4320, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 17280, 270, 17280, 4320, 17280, 17280, 270, 17280, 270, 17280, 4320, 270, 270, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 270, 4320, 4320, 270, 17280, 4320, 17280, 17280, 4320, 270, 4320, 4320, 4320, 270, 17280, 4320, 17280, 270, 17280, 270, 270, 4320, 17280, 17280, 4320, 270, 4320, 270, 4320, 17280, 17280, 4320, 270, 4320, 270, 17280, 270, 270, 270, 270, 17280, 4320, 4320, 17280, 4320, 4320, 270, 4320, 17280, 4320, 270, 270, 4320, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 4320, 17280, 4320, 4320, 4320, 270, 17280, 270, 17280, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 270, 270, 17280, 4320, 17280, 4320, 17280, 4320, 270, 4320, 270, 270, 270, 17280, 17280, 4320, 4320, 270, 270, 4320, 270, 17280, 270, 270, 4320, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 4320, 17280, 4320, 270, 4320, 270, 17280, 4320, 4320, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 4320, 270, 4320, 270, 4320, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 4320, 4320, 17280, 270, 17280, 270, 270, 270, 17280, 4320, 17280, 17280, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 17280, 270, 270, 4320, 270, 4320, 4320, 270, 17280, 17280, 17280, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2339820 . Total input tokens: 521146796 . Total output tokens: 467944613
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 90.41412631375715,
    "estimated_duration": 3600.094318063368,
    "input_throughput": 6200.496716988259,
    "output_throughput": 5494.623821589504,
    "total_throughput": 11695.120538577763,
    "itl": 153.82664324140615,
    "ttft": 2012098.8138605077,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 477,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.598066895641386,
    "arrivals": 779141,
    "finished_requests": 90522,
    "scheduler_time": 169.14121309894125
}
#Debug simulation 
Total elapsed time: 90.41429730691016. Arrivals time: 0.5487534711137414 Scheduler time: 89.70286444667727 Scheduler overhead time: 0.06178849143907428 Adapter cache time: 0.017707749735563993 Engine time: 0.060413156636059284 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-8/adapters_320_slots_64_rate_1.6-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-8/adapters_320_slots_64_rate_1.6-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 135, 17280, 17280, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 17280, 17280, 4320, 135, 135, 4320, 17280, 17280, 4320, 4320, 135, 135, 4320, 17280, 17280, 135, 17280, 4320, 135, 4320, 17280, 135, 4320, 17280, 17280, 4320, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 17280, 135, 17280, 4320, 17280, 17280, 135, 17280, 135, 17280, 4320, 135, 135, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 135, 4320, 4320, 135, 17280, 4320, 17280, 17280, 4320, 135, 4320, 4320, 4320, 135, 17280, 4320, 17280, 135, 17280, 135, 135, 4320, 17280, 17280, 4320, 135, 4320, 135, 4320, 17280, 17280, 4320, 135, 4320, 135, 17280, 135, 135, 135, 135, 17280, 4320, 4320, 17280, 4320, 4320, 135, 4320, 17280, 4320, 135, 135, 4320, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 4320, 17280, 4320, 4320, 4320, 135, 17280, 135, 17280, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 135, 135, 17280, 4320, 17280, 4320, 17280, 4320, 135, 4320, 135, 135, 135, 17280, 17280, 4320, 4320, 135, 135, 4320, 135, 17280, 135, 135, 4320, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 4320, 17280, 4320, 135, 4320, 135, 17280, 4320, 4320, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 4320, 135, 4320, 135, 4320, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 4320, 4320, 17280, 135, 17280, 135, 135, 135, 17280, 4320, 17280, 17280, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 17280, 135, 135, 4320, 135, 4320, 4320, 135, 17280, 17280, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2325510 . Total input tokens: 517947587 . Total output tokens: 465135213
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 84.9588064798154,
    "estimated_duration": 3600.033165569759,
    "input_throughput": 6231.921476325984,
    "output_throughput": 5518.311939455672,
    "total_throughput": 11750.233415781657,
    "itl": 155.25544370243537,
    "ttft": 2006938.3556797348,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 441,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3496750950743552,
    "arrivals": 774377,
    "finished_requests": 90762,
    "scheduler_time": 167.9411724002587
}
#Debug simulation 
Total elapsed time: 84.9589778939262. Arrivals time: 0.4787594950757921 Scheduler time: 84.32052777055651 Scheduler overhead time: 0.060839592944830656 Adapter cache time: 0.016908833757042885 Engine time: 0.05918691027909517 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-16/adapters_320_slots_64_rate_1.6-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-16/adapters_320_slots_64_rate_1.6-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 135, 17280, 17280, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 17280, 17280, 4320, 135, 135, 4320, 17280, 17280, 4320, 4320, 135, 135, 4320, 17280, 17280, 135, 17280, 4320, 135, 4320, 17280, 135, 4320, 17280, 17280, 4320, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 17280, 135, 17280, 4320, 17280, 17280, 135, 17280, 135, 17280, 4320, 135, 135, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 135, 4320, 4320, 135, 17280, 4320, 17280, 17280, 4320, 135, 4320, 4320, 4320, 135, 17280, 4320, 17280, 135, 17280, 135, 135, 4320, 17280, 17280, 4320, 135, 4320, 135, 4320, 17280, 17280, 4320, 135, 4320, 135, 17280, 135, 135, 135, 135, 17280, 4320, 4320, 17280, 4320, 4320, 135, 4320, 17280, 4320, 135, 135, 4320, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 4320, 17280, 4320, 4320, 4320, 135, 17280, 135, 17280, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 135, 135, 17280, 4320, 17280, 4320, 17280, 4320, 135, 4320, 135, 135, 135, 17280, 17280, 4320, 4320, 135, 135, 4320, 135, 17280, 135, 135, 4320, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 4320, 17280, 4320, 135, 4320, 135, 17280, 4320, 4320, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 4320, 135, 4320, 135, 4320, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 4320, 4320, 17280, 135, 17280, 135, 135, 135, 17280, 4320, 17280, 17280, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 17280, 135, 135, 4320, 135, 4320, 4320, 135, 17280, 17280, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2325510 . Total input tokens: 517947587 . Total output tokens: 465135213
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 87.41513547999784,
    "estimated_duration": 3600.136481480607,
    "input_throughput": 6231.968458810457,
    "output_throughput": 5509.425018198951,
    "total_throughput": 11741.393477009407,
    "itl": 154.6354247619013,
    "ttft": 2007344.9368328864,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 425,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3880382317258106,
    "arrivals": 774377,
    "finished_requests": 90780,
    "scheduler_time": 168.35421111497257
}
#Debug simulation 
Total elapsed time: 87.41530749201775. Arrivals time: 0.49922695755958557 Scheduler time: 86.7554068705067 Scheduler overhead time: 0.06139597948640585 Adapter cache time: 0.016937625128775835 Engine time: 0.060052795335650444 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-32/adapters_320_slots_64_rate_1.6-0.4-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-32/adapters_320_slots_64_rate_1.6-0.4-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 135, 17280, 17280, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 17280, 17280, 4320, 135, 135, 4320, 17280, 17280, 4320, 4320, 135, 135, 4320, 17280, 17280, 135, 17280, 4320, 135, 4320, 17280, 135, 4320, 17280, 17280, 4320, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 17280, 135, 17280, 4320, 17280, 17280, 135, 17280, 135, 17280, 4320, 135, 135, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 135, 4320, 4320, 135, 17280, 4320, 17280, 17280, 4320, 135, 4320, 4320, 4320, 135, 17280, 4320, 17280, 135, 17280, 135, 135, 4320, 17280, 17280, 4320, 135, 4320, 135, 4320, 17280, 17280, 4320, 135, 4320, 135, 17280, 135, 135, 135, 135, 17280, 4320, 4320, 17280, 4320, 4320, 135, 4320, 17280, 4320, 135, 135, 4320, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 4320, 17280, 4320, 4320, 4320, 135, 17280, 135, 17280, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 135, 135, 17280, 4320, 17280, 4320, 17280, 4320, 135, 4320, 135, 135, 135, 17280, 17280, 4320, 4320, 135, 135, 4320, 135, 17280, 135, 135, 4320, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 4320, 17280, 4320, 135, 4320, 135, 17280, 4320, 4320, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 4320, 135, 4320, 135, 4320, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 4320, 4320, 17280, 135, 17280, 135, 135, 135, 17280, 4320, 17280, 17280, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 17280, 135, 135, 4320, 135, 4320, 4320, 135, 17280, 17280, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2325510 . Total input tokens: 517947587 . Total output tokens: 465135213
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 87.12929376401007,
    "estimated_duration": 3600.138735907977,
    "input_throughput": 6231.964556316333,
    "output_throughput": 5509.421568165642,
    "total_throughput": 11741.386124481975,
    "itl": 154.63552000649946,
    "ttft": 2007345.910014641,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 425,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3902855416573663,
    "arrivals": 774377,
    "finished_requests": 90780,
    "scheduler_time": 168.35421823239017
}
#Debug simulation 
Total elapsed time: 87.12946283072233. Arrivals time: 0.47803213307633996 Scheduler time: 86.49098678166047 Scheduler overhead time: 0.060775432735681534 Adapter cache time: 0.016708311624825 Engine time: 0.06068640947341919 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-16/adapters_320_slots_64_rate_1.6-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-16/adapters_320_slots_64_rate_1.6-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 135, 17280, 17280, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 17280, 17280, 4320, 135, 135, 4320, 17280, 17280, 4320, 4320, 135, 135, 4320, 17280, 17280, 135, 17280, 4320, 135, 4320, 17280, 135, 4320, 17280, 17280, 4320, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 17280, 135, 17280, 4320, 17280, 17280, 135, 17280, 135, 17280, 4320, 135, 135, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 135, 4320, 4320, 135, 17280, 4320, 17280, 17280, 4320, 135, 4320, 4320, 4320, 135, 17280, 4320, 17280, 135, 17280, 135, 135, 4320, 17280, 17280, 4320, 135, 4320, 135, 4320, 17280, 17280, 4320, 135, 4320, 135, 17280, 135, 135, 135, 135, 17280, 4320, 4320, 17280, 4320, 4320, 135, 4320, 17280, 4320, 135, 135, 4320, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 4320, 17280, 4320, 4320, 4320, 135, 17280, 135, 17280, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 135, 135, 17280, 4320, 17280, 4320, 17280, 4320, 135, 4320, 135, 135, 135, 17280, 17280, 4320, 4320, 135, 135, 4320, 135, 17280, 135, 135, 4320, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 4320, 17280, 4320, 135, 4320, 135, 17280, 4320, 4320, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 4320, 135, 4320, 135, 4320, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 4320, 4320, 17280, 135, 17280, 135, 135, 135, 17280, 4320, 17280, 17280, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 17280, 135, 135, 4320, 135, 4320, 4320, 135, 17280, 17280, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2325510 . Total input tokens: 517947587 . Total output tokens: 465135213
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 85.08834847109392,
    "estimated_duration": 3600.062400694184,
    "input_throughput": 6231.870868592148,
    "output_throughput": 5518.267126750166,
    "total_throughput": 11750.137995342315,
    "itl": 155.2561920597983,
    "ttft": 2006951.8799098583,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 441,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3786756918625873,
    "arrivals": 774377,
    "finished_requests": 90762,
    "scheduler_time": 167.94140692784757
}
#Debug simulation 
Total elapsed time: 85.08853023638949. Arrivals time: 0.4825883824378252 Scheduler time: 84.44537742016837 Scheduler overhead time: 0.061354128178209066 Adapter cache time: 0.01717935362830758 Engine time: 0.05944472877308726 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-32/adapters_320_slots_64_rate_1.6-0.4-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-32/adapters_320_slots_64_rate_1.6-0.4-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 135, 17280, 17280, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 17280, 17280, 4320, 135, 135, 4320, 17280, 17280, 4320, 4320, 135, 135, 4320, 17280, 17280, 135, 17280, 4320, 135, 4320, 17280, 135, 4320, 17280, 17280, 4320, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 17280, 135, 17280, 4320, 17280, 17280, 135, 17280, 135, 17280, 4320, 135, 135, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 135, 4320, 4320, 135, 17280, 4320, 17280, 17280, 4320, 135, 4320, 4320, 4320, 135, 17280, 4320, 17280, 135, 17280, 135, 135, 4320, 17280, 17280, 4320, 135, 4320, 135, 4320, 17280, 17280, 4320, 135, 4320, 135, 17280, 135, 135, 135, 135, 17280, 4320, 4320, 17280, 4320, 4320, 135, 4320, 17280, 4320, 135, 135, 4320, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 4320, 17280, 4320, 4320, 4320, 135, 17280, 135, 17280, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 135, 135, 17280, 4320, 17280, 4320, 17280, 4320, 135, 4320, 135, 135, 135, 17280, 17280, 4320, 4320, 135, 135, 4320, 135, 17280, 135, 135, 4320, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 4320, 17280, 4320, 135, 4320, 135, 17280, 4320, 4320, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 4320, 135, 4320, 135, 4320, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 4320, 4320, 17280, 135, 17280, 135, 135, 135, 17280, 4320, 17280, 17280, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 17280, 135, 135, 4320, 135, 4320, 4320, 135, 17280, 17280, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2325510 . Total input tokens: 517947587 . Total output tokens: 465135213
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 87.13701415993273,
    "estimated_duration": 3600.157058831125,
    "input_throughput": 6231.932838864633,
    "output_throughput": 5509.393528081187,
    "total_throughput": 11741.32636694582,
    "itl": 154.63605103042988,
    "ttft": 2007353.8688589232,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 425,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4080168255418586,
    "arrivals": 774377,
    "finished_requests": 90780,
    "scheduler_time": 168.35439215786735
}
#Debug simulation 
Total elapsed time: 87.1371835093014. Arrivals time: 0.4835153594613075 Scheduler time: 86.49165279697627 Scheduler overhead time: 0.062130256090313196 Adapter cache time: 0.01715334551408887 Engine time: 0.0601444817148149 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-16/adapters_320_slots_64_rate_1.6-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-16/adapters_320_slots_64_rate_1.6-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 135, 17280, 17280, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 17280, 17280, 4320, 135, 135, 4320, 17280, 17280, 4320, 4320, 135, 135, 4320, 17280, 17280, 135, 17280, 4320, 135, 4320, 17280, 135, 4320, 17280, 17280, 4320, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 17280, 135, 17280, 4320, 17280, 17280, 135, 17280, 135, 17280, 4320, 135, 135, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 135, 4320, 4320, 135, 17280, 4320, 17280, 17280, 4320, 135, 4320, 4320, 4320, 135, 17280, 4320, 17280, 135, 17280, 135, 135, 4320, 17280, 17280, 4320, 135, 4320, 135, 4320, 17280, 17280, 4320, 135, 4320, 135, 17280, 135, 135, 135, 135, 17280, 4320, 4320, 17280, 4320, 4320, 135, 4320, 17280, 4320, 135, 135, 4320, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 4320, 17280, 4320, 4320, 4320, 135, 17280, 135, 17280, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 135, 135, 17280, 4320, 17280, 4320, 17280, 4320, 135, 4320, 135, 135, 135, 17280, 17280, 4320, 4320, 135, 135, 4320, 135, 17280, 135, 135, 4320, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 4320, 17280, 4320, 135, 4320, 135, 17280, 4320, 4320, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 4320, 135, 4320, 135, 4320, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 4320, 4320, 17280, 135, 17280, 135, 135, 135, 17280, 4320, 17280, 17280, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 17280, 135, 135, 4320, 135, 4320, 4320, 135, 17280, 17280, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2325510 . Total input tokens: 517947587 . Total output tokens: 465135213
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 90.07845491403714,
    "estimated_duration": 3600.0135919524805,
    "input_throughput": 6226.892323437622,
    "output_throughput": 5512.3730766908575,
    "total_throughput": 11739.265400128479,
    "itl": 154.3483335961893,
    "ttft": 2004076.1124666515,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 508,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5189455498102882,
    "arrivals": 774377,
    "finished_requests": 90667,
    "scheduler_time": 168.6551723767303
}
#Debug simulation 
Total elapsed time: 90.0786218540743. Arrivals time: 0.5389363165013492 Scheduler time: 89.37769160186872 Scheduler overhead time: 0.06203414686024189 Adapter cache time: 0.017668667249381542 Engine time: 0.05977980885654688 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-32/adapters_320_slots_64_rate_1.6-0.4-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-32/adapters_320_slots_64_rate_1.6-0.4-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 135, 17280, 17280, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 17280, 17280, 4320, 135, 135, 4320, 17280, 17280, 4320, 4320, 135, 135, 4320, 17280, 17280, 135, 17280, 4320, 135, 4320, 17280, 135, 4320, 17280, 17280, 4320, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 17280, 135, 17280, 4320, 17280, 17280, 135, 17280, 135, 17280, 4320, 135, 135, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 135, 4320, 4320, 135, 17280, 4320, 17280, 17280, 4320, 135, 4320, 4320, 4320, 135, 17280, 4320, 17280, 135, 17280, 135, 135, 4320, 17280, 17280, 4320, 135, 4320, 135, 4320, 17280, 17280, 4320, 135, 4320, 135, 17280, 135, 135, 135, 135, 17280, 4320, 4320, 17280, 4320, 4320, 135, 4320, 17280, 4320, 135, 135, 4320, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 4320, 17280, 4320, 4320, 4320, 135, 17280, 135, 17280, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 135, 135, 17280, 4320, 17280, 4320, 17280, 4320, 135, 4320, 135, 135, 135, 17280, 17280, 4320, 4320, 135, 135, 4320, 135, 17280, 135, 135, 4320, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 4320, 17280, 4320, 135, 4320, 135, 17280, 4320, 4320, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 4320, 135, 4320, 135, 4320, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 4320, 4320, 17280, 135, 17280, 135, 135, 135, 17280, 4320, 17280, 17280, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 17280, 135, 135, 4320, 135, 4320, 4320, 135, 17280, 17280, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2325510 . Total input tokens: 517947587 . Total output tokens: 465135213
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 72.71433101128787,
    "estimated_duration": 3600.0617078243868,
    "input_throughput": 6234.101474211395,
    "output_throughput": 5507.690870105281,
    "total_throughput": 11741.792344316675,
    "itl": 154.79720290625994,
    "ttft": 2010556.2581308535,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 542,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8181196822971069,
    "arrivals": 774377,
    "finished_requests": 90807,
    "scheduler_time": 168.41889639124955
}
#Debug simulation 
Total elapsed time: 72.71450588200241. Arrivals time: 0.4763651629909873 Scheduler time: 72.07915641088039 Scheduler overhead time: 0.060468815732747316 Adapter cache time: 0.01803083997219801 Engine time: 0.05875501735135913 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-8/adapters_320_slots_64_rate_1.6-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-8/adapters_320_slots_64_rate_1.6-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 66, 17280, 17280, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 17280, 17280, 4320, 66, 66, 4320, 17280, 17280, 4320, 4320, 66, 66, 4320, 17280, 17280, 66, 17280, 4320, 66, 4320, 17280, 66, 4320, 17280, 17280, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 17280, 4320, 17280, 17280, 66, 17280, 66, 17280, 4320, 66, 66, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 66, 4320, 4320, 66, 17280, 4320, 17280, 17280, 4320, 66, 4320, 4320, 4320, 66, 17280, 4320, 17280, 66, 17280, 66, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 17280, 66, 66, 66, 66, 17280, 4320, 4320, 17280, 4320, 4320, 66, 4320, 17280, 4320, 66, 66, 4320, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 4320, 17280, 4320, 4320, 4320, 66, 17280, 66, 17280, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 66, 66, 17280, 4320, 17280, 4320, 17280, 4320, 66, 4320, 66, 66, 66, 17280, 17280, 4320, 4320, 66, 66, 4320, 66, 17280, 66, 66, 4320, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 4320, 17280, 4320, 66, 4320, 66, 17280, 4320, 4320, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 4320, 4320, 17280, 66, 17280, 66, 66, 66, 17280, 4320, 17280, 17280, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 17280, 66, 66, 4320, 66, 4320, 4320, 66, 17280, 17280, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2318196 . Total input tokens: 516259933 . Total output tokens: 463669613
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 78.49724424770102,
    "estimated_duration": 3600.087858008412,
    "input_throughput": 6227.653847426635,
    "output_throughput": 5516.1078793743145,
    "total_throughput": 11743.76172680095,
    "itl": 154.96980878517232,
    "ttft": 2013326.7797271474,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 500,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.530243871966394,
    "arrivals": 771975,
    "finished_requests": 90785,
    "scheduler_time": 168.29170981739688
}
#Debug simulation 
Total elapsed time: 78.49741387600079. Arrivals time: 0.48972479114308953 Scheduler time: 77.85088980337605 Scheduler overhead time: 0.05882575735449791 Adapter cache time: 0.01752982335165143 Engine time: 0.05852869572117925 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-16/adapters_320_slots_64_rate_1.6-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-16/adapters_320_slots_64_rate_1.6-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 66, 17280, 17280, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 17280, 17280, 4320, 66, 66, 4320, 17280, 17280, 4320, 4320, 66, 66, 4320, 17280, 17280, 66, 17280, 4320, 66, 4320, 17280, 66, 4320, 17280, 17280, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 17280, 4320, 17280, 17280, 66, 17280, 66, 17280, 4320, 66, 66, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 66, 4320, 4320, 66, 17280, 4320, 17280, 17280, 4320, 66, 4320, 4320, 4320, 66, 17280, 4320, 17280, 66, 17280, 66, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 17280, 66, 66, 66, 66, 17280, 4320, 4320, 17280, 4320, 4320, 66, 4320, 17280, 4320, 66, 66, 4320, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 4320, 17280, 4320, 4320, 4320, 66, 17280, 66, 17280, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 66, 66, 17280, 4320, 17280, 4320, 17280, 4320, 66, 4320, 66, 66, 66, 17280, 17280, 4320, 4320, 66, 66, 4320, 66, 17280, 66, 66, 4320, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 4320, 17280, 4320, 66, 4320, 66, 17280, 4320, 4320, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 4320, 4320, 17280, 66, 17280, 66, 66, 66, 17280, 4320, 17280, 17280, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 17280, 66, 66, 4320, 66, 4320, 4320, 66, 17280, 17280, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2318196 . Total input tokens: 516259933 . Total output tokens: 463669613
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 80.75502273906022,
    "estimated_duration": 3600.106262997288,
    "input_throughput": 6218.519222641308,
    "output_throughput": 5507.877421232368,
    "total_throughput": 11726.396643873675,
    "itl": 154.9234466319666,
    "ttft": 2013671.9144437097,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 478,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5604031381825971,
    "arrivals": 771975,
    "finished_requests": 90679,
    "scheduler_time": 168.48921738414194
}
#Debug simulation 
Total elapsed time: 80.75518905231729. Arrivals time: 0.4799207132309675 Scheduler time: 80.11711458396167 Scheduler overhead time: 0.060022433288395405 Adapter cache time: 0.017258908599615097 Engine time: 0.058090724516659975 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-32/adapters_320_slots_64_rate_1.6-0.4-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-32/adapters_320_slots_64_rate_1.6-0.4-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 66, 17280, 17280, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 17280, 17280, 4320, 66, 66, 4320, 17280, 17280, 4320, 4320, 66, 66, 4320, 17280, 17280, 66, 17280, 4320, 66, 4320, 17280, 66, 4320, 17280, 17280, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 17280, 4320, 17280, 17280, 66, 17280, 66, 17280, 4320, 66, 66, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 66, 4320, 4320, 66, 17280, 4320, 17280, 17280, 4320, 66, 4320, 4320, 4320, 66, 17280, 4320, 17280, 66, 17280, 66, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 17280, 66, 66, 66, 66, 17280, 4320, 4320, 17280, 4320, 4320, 66, 4320, 17280, 4320, 66, 66, 4320, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 4320, 17280, 4320, 4320, 4320, 66, 17280, 66, 17280, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 66, 66, 17280, 4320, 17280, 4320, 17280, 4320, 66, 4320, 66, 66, 66, 17280, 17280, 4320, 4320, 66, 66, 4320, 66, 17280, 66, 66, 4320, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 4320, 17280, 4320, 66, 4320, 66, 17280, 4320, 4320, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 4320, 4320, 17280, 66, 17280, 66, 66, 66, 17280, 4320, 17280, 17280, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 17280, 66, 66, 4320, 66, 4320, 4320, 66, 17280, 17280, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2318196 . Total input tokens: 516259933 . Total output tokens: 463669613
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 81.07061251997948,
    "estimated_duration": 3600.109224843543,
    "input_throughput": 6218.514106602677,
    "output_throughput": 5507.872889845931,
    "total_throughput": 11726.386996448608,
    "itl": 154.9235421298786,
    "ttft": 2013673.3121442911,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 478,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5630584554560576,
    "arrivals": 771975,
    "finished_requests": 90679,
    "scheduler_time": 168.48924543724635
}
#Debug simulation 
Total elapsed time: 81.07077975803986. Arrivals time: 0.5413492820225656 Scheduler time: 80.36995963333175 Scheduler overhead time: 0.06024598050862551 Adapter cache time: 0.017379598692059517 Engine time: 0.05916172731667757 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-16/adapters_320_slots_64_rate_1.6-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-16/adapters_320_slots_64_rate_1.6-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 66, 17280, 17280, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 17280, 17280, 4320, 66, 66, 4320, 17280, 17280, 4320, 4320, 66, 66, 4320, 17280, 17280, 66, 17280, 4320, 66, 4320, 17280, 66, 4320, 17280, 17280, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 17280, 4320, 17280, 17280, 66, 17280, 66, 17280, 4320, 66, 66, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 66, 4320, 4320, 66, 17280, 4320, 17280, 17280, 4320, 66, 4320, 4320, 4320, 66, 17280, 4320, 17280, 66, 17280, 66, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 17280, 66, 66, 66, 66, 17280, 4320, 4320, 17280, 4320, 4320, 66, 4320, 17280, 4320, 66, 66, 4320, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 4320, 17280, 4320, 4320, 4320, 66, 17280, 66, 17280, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 66, 66, 17280, 4320, 17280, 4320, 17280, 4320, 66, 4320, 66, 66, 66, 17280, 17280, 4320, 4320, 66, 66, 4320, 66, 17280, 66, 66, 4320, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 4320, 17280, 4320, 66, 4320, 66, 17280, 4320, 4320, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 4320, 4320, 17280, 66, 17280, 66, 66, 66, 17280, 4320, 17280, 17280, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 17280, 66, 66, 4320, 66, 4320, 4320, 66, 17280, 17280, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2318196 . Total input tokens: 516259933 . Total output tokens: 463669613
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 80.60194861004129,
    "estimated_duration": 3600.067565846427,
    "input_throughput": 6207.226556523262,
    "output_throughput": 5503.573096229273,
    "total_throughput": 11710.799652752534,
    "itl": 154.37210161464597,
    "ttft": 2012551.4836166417,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 471,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.471645963257174,
    "arrivals": 771975,
    "finished_requests": 90524,
    "scheduler_time": 168.80936905058383
}
#Debug simulation 
Total elapsed time: 80.60211176471785. Arrivals time: 0.5235044434666634 Scheduler time: 79.92209052015096 Scheduler overhead time: 0.0593403484672308 Adapter cache time: 0.016772440169006586 Engine time: 0.05808413913473487 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-32/adapters_320_slots_64_rate_1.6-0.4-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-32/adapters_320_slots_64_rate_1.6-0.4-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 66, 17280, 17280, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 17280, 17280, 4320, 66, 66, 4320, 17280, 17280, 4320, 4320, 66, 66, 4320, 17280, 17280, 66, 17280, 4320, 66, 4320, 17280, 66, 4320, 17280, 17280, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 17280, 4320, 17280, 17280, 66, 17280, 66, 17280, 4320, 66, 66, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 66, 4320, 4320, 66, 17280, 4320, 17280, 17280, 4320, 66, 4320, 4320, 4320, 66, 17280, 4320, 17280, 66, 17280, 66, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 17280, 66, 66, 66, 66, 17280, 4320, 4320, 17280, 4320, 4320, 66, 4320, 17280, 4320, 66, 66, 4320, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 4320, 17280, 4320, 4320, 4320, 66, 17280, 66, 17280, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 66, 66, 17280, 4320, 17280, 4320, 17280, 4320, 66, 4320, 66, 66, 66, 17280, 17280, 4320, 4320, 66, 66, 4320, 66, 17280, 66, 66, 4320, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 4320, 17280, 4320, 66, 4320, 66, 17280, 4320, 4320, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 4320, 4320, 17280, 66, 17280, 66, 66, 66, 17280, 4320, 17280, 17280, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 17280, 66, 66, 4320, 66, 4320, 4320, 66, 17280, 17280, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2318196 . Total input tokens: 516259933 . Total output tokens: 463669613
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 76.9055683137849,
    "estimated_duration": 3600.0795433053167,
    "input_throughput": 6214.81573694843,
    "output_throughput": 5504.6578170340545,
    "total_throughput": 11719.473553982485,
    "itl": 154.61796675155023,
    "ttft": 2012482.0656097727,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 471,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5585019543953282,
    "arrivals": 771975,
    "finished_requests": 90563,
    "scheduler_time": 168.85058404970394
}
#Debug simulation 
Total elapsed time: 76.90572351682931. Arrivals time: 0.47731720795854926 Scheduler time: 76.27169990492985 Scheduler overhead time: 0.05944189801812172 Adapter cache time: 0.01691099861636758 Engine time: 0.05819374043494463 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-16/adapters_320_slots_64_rate_1.6-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-16/adapters_320_slots_64_rate_1.6-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 66, 17280, 17280, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 17280, 17280, 4320, 66, 66, 4320, 17280, 17280, 4320, 4320, 66, 66, 4320, 17280, 17280, 66, 17280, 4320, 66, 4320, 17280, 66, 4320, 17280, 17280, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 17280, 4320, 17280, 17280, 66, 17280, 66, 17280, 4320, 66, 66, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 66, 4320, 4320, 66, 17280, 4320, 17280, 17280, 4320, 66, 4320, 4320, 4320, 66, 17280, 4320, 17280, 66, 17280, 66, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 17280, 66, 66, 66, 66, 17280, 4320, 4320, 17280, 4320, 4320, 66, 4320, 17280, 4320, 66, 66, 4320, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 4320, 17280, 4320, 4320, 4320, 66, 17280, 66, 17280, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 66, 66, 17280, 4320, 17280, 4320, 17280, 4320, 66, 4320, 66, 66, 66, 17280, 17280, 4320, 4320, 66, 66, 4320, 66, 17280, 66, 66, 4320, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 4320, 17280, 4320, 66, 4320, 66, 17280, 4320, 4320, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 4320, 4320, 17280, 66, 17280, 66, 66, 66, 17280, 4320, 17280, 17280, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 17280, 66, 66, 4320, 66, 4320, 4320, 66, 17280, 17280, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2318196 . Total input tokens: 516259933 . Total output tokens: 463669613
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 77.47673985129222,
    "estimated_duration": 3600.168231067249,
    "input_throughput": 6206.381914929638,
    "output_throughput": 5494.61573192536,
    "total_throughput": 11700.997646854998,
    "itl": 154.4872271471089,
    "ttft": 2013197.9496888225,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 465,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3903733871294992,
    "arrivals": 771975,
    "finished_requests": 90441,
    "scheduler_time": 169.1895256687024
}
#Debug simulation 
Total elapsed time: 77.47698066895828. Arrivals time: 0.5193530693650246 Scheduler time: 76.80012817075476 Scheduler overhead time: 0.05959043651819229 Adapter cache time: 0.016813162248581648 Engine time: 0.058430696837604046 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-32/adapters_320_slots_64_rate_1.6-0.4-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-32/adapters_320_slots_64_rate_1.6-0.4-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 66, 17280, 17280, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 17280, 17280, 4320, 66, 66, 4320, 17280, 17280, 4320, 4320, 66, 66, 4320, 17280, 17280, 66, 17280, 4320, 66, 4320, 17280, 66, 4320, 17280, 17280, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 17280, 4320, 17280, 17280, 66, 17280, 66, 17280, 4320, 66, 66, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 66, 4320, 4320, 66, 17280, 4320, 17280, 17280, 4320, 66, 4320, 4320, 4320, 66, 17280, 4320, 17280, 66, 17280, 66, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 4320, 66, 4320, 66, 17280, 66, 66, 66, 66, 17280, 4320, 4320, 17280, 4320, 4320, 66, 4320, 17280, 4320, 66, 66, 4320, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 4320, 17280, 4320, 4320, 4320, 66, 17280, 66, 17280, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 66, 66, 17280, 4320, 17280, 4320, 17280, 4320, 66, 4320, 66, 66, 66, 17280, 17280, 4320, 4320, 66, 66, 4320, 66, 17280, 66, 66, 4320, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 4320, 17280, 4320, 66, 4320, 66, 17280, 4320, 4320, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 4320, 66, 4320, 66, 4320, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 4320, 4320, 17280, 66, 17280, 66, 66, 66, 17280, 4320, 17280, 17280, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 17280, 66, 66, 4320, 66, 4320, 4320, 66, 17280, 17280, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2318196 . Total input tokens: 516259933 . Total output tokens: 463669613
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 76.6670605787076,
    "estimated_duration": 3600.0200702945835,
    "input_throughput": 6214.344243411219,
    "output_throughput": 5504.6098669051125,
    "total_throughput": 11718.954110316332,
    "itl": 154.61677212672714,
    "ttft": 2012512.6452559726,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 470,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5744472572952506,
    "arrivals": 771975,
    "finished_requests": 90559,
    "scheduler_time": 168.84536188777312
}
#Debug simulation 
Total elapsed time: 76.66723097069189. Arrivals time: 0.4816830297932029 Scheduler time: 76.02817278029397 Scheduler overhead time: 0.05972679425030947 Adapter cache time: 0.016859210561960936 Engine time: 0.05860258638858795 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-8/adapters_320_slots_64_rate_1.6-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-8/adapters_320_slots_64_rate_1.6-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 33, 17280, 17280, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 17280, 17280, 4320, 33, 33, 4320, 17280, 17280, 4320, 4320, 33, 33, 4320, 17280, 17280, 33, 17280, 4320, 33, 4320, 17280, 33, 4320, 17280, 17280, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 17280, 4320, 17280, 17280, 33, 17280, 33, 17280, 4320, 33, 33, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 33, 4320, 4320, 33, 17280, 4320, 17280, 17280, 4320, 33, 4320, 4320, 4320, 33, 17280, 4320, 17280, 33, 17280, 33, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 17280, 33, 33, 33, 33, 17280, 4320, 4320, 17280, 4320, 4320, 33, 4320, 17280, 4320, 33, 33, 4320, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 4320, 17280, 4320, 4320, 4320, 33, 17280, 33, 17280, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 33, 33, 17280, 4320, 17280, 4320, 17280, 4320, 33, 4320, 33, 33, 33, 17280, 17280, 4320, 4320, 33, 33, 4320, 33, 17280, 33, 33, 4320, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 4320, 17280, 4320, 33, 4320, 33, 17280, 4320, 4320, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 4320, 4320, 17280, 33, 17280, 33, 33, 33, 17280, 4320, 17280, 17280, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 17280, 33, 33, 4320, 33, 4320, 4320, 33, 17280, 17280, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2314698 . Total input tokens: 515493855 . Total output tokens: 462974761
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 72.52989101689309,
    "estimated_duration": 3600.076428437627,
    "input_throughput": 6231.671589743498,
    "output_throughput": 5513.159899389584,
    "total_throughput": 11744.831489133081,
    "itl": 154.73240854022595,
    "ttft": 2006868.7383616373,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 566,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7322360630659628,
    "arrivals": 770785,
    "finished_requests": 90901,
    "scheduler_time": 168.21072478854572
}
#Debug simulation 
Total elapsed time: 72.53005298459902. Arrivals time: 0.5650214212946594 Scheduler time: 71.81005292013288 Scheduler overhead time: 0.05812648357823491 Adapter cache time: 0.017914132680743933 Engine time: 0.05729840183630586 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-16/adapters_320_slots_64_rate_1.6-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-16/adapters_320_slots_64_rate_1.6-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 33, 17280, 17280, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 17280, 17280, 4320, 33, 33, 4320, 17280, 17280, 4320, 4320, 33, 33, 4320, 17280, 17280, 33, 17280, 4320, 33, 4320, 17280, 33, 4320, 17280, 17280, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 17280, 4320, 17280, 17280, 33, 17280, 33, 17280, 4320, 33, 33, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 33, 4320, 4320, 33, 17280, 4320, 17280, 17280, 4320, 33, 4320, 4320, 4320, 33, 17280, 4320, 17280, 33, 17280, 33, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 17280, 33, 33, 33, 33, 17280, 4320, 4320, 17280, 4320, 4320, 33, 4320, 17280, 4320, 33, 33, 4320, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 4320, 17280, 4320, 4320, 4320, 33, 17280, 33, 17280, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 33, 33, 17280, 4320, 17280, 4320, 17280, 4320, 33, 4320, 33, 33, 33, 17280, 17280, 4320, 4320, 33, 33, 4320, 33, 17280, 33, 33, 4320, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 4320, 17280, 4320, 33, 4320, 33, 17280, 4320, 4320, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 4320, 4320, 17280, 33, 17280, 33, 33, 33, 17280, 4320, 17280, 17280, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 17280, 33, 33, 4320, 33, 4320, 4320, 33, 17280, 17280, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2314698 . Total input tokens: 515493855 . Total output tokens: 462974761
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 77.96115808514878,
    "estimated_duration": 3600.0210095536145,
    "input_throughput": 6233.880563597798,
    "output_throughput": 5516.380028699453,
    "total_throughput": 11750.26059229725,
    "itl": 154.7717642691897,
    "ttft": 2007959.24412521,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 434,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4198518282012151,
    "arrivals": 770785,
    "finished_requests": 90995,
    "scheduler_time": 168.06986424894842
}
#Debug simulation 
Total elapsed time: 77.96132652042434. Arrivals time: 0.4897042838856578 Scheduler time: 77.31125894607976 Scheduler overhead time: 0.0629462068900466 Adapter cache time: 0.016193523537367582 Engine time: 0.05891041969880462 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-32/adapters_320_slots_64_rate_1.6-0.4-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-32/adapters_320_slots_64_rate_1.6-0.4-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 33, 17280, 17280, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 17280, 17280, 4320, 33, 33, 4320, 17280, 17280, 4320, 4320, 33, 33, 4320, 17280, 17280, 33, 17280, 4320, 33, 4320, 17280, 33, 4320, 17280, 17280, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 17280, 4320, 17280, 17280, 33, 17280, 33, 17280, 4320, 33, 33, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 33, 4320, 4320, 33, 17280, 4320, 17280, 17280, 4320, 33, 4320, 4320, 4320, 33, 17280, 4320, 17280, 33, 17280, 33, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 17280, 33, 33, 33, 33, 17280, 4320, 4320, 17280, 4320, 4320, 33, 4320, 17280, 4320, 33, 33, 4320, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 4320, 17280, 4320, 4320, 4320, 33, 17280, 33, 17280, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 33, 33, 17280, 4320, 17280, 4320, 17280, 4320, 33, 4320, 33, 33, 33, 17280, 17280, 4320, 4320, 33, 33, 4320, 33, 17280, 33, 33, 4320, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 4320, 17280, 4320, 33, 4320, 33, 17280, 4320, 4320, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 4320, 4320, 17280, 33, 17280, 33, 33, 33, 17280, 4320, 17280, 17280, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 17280, 33, 33, 4320, 33, 4320, 4320, 33, 17280, 17280, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2314698 . Total input tokens: 515493855 . Total output tokens: 462974761
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 78.05035481508821,
    "estimated_duration": 3600.0228935375553,
    "input_throughput": 6233.877301248858,
    "output_throughput": 5516.377141836871,
    "total_throughput": 11750.254443085729,
    "itl": 154.77183338773037,
    "ttft": 2007960.227111942,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 434,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4217241812311197,
    "arrivals": 770785,
    "finished_requests": 90995,
    "scheduler_time": 168.06987587985031
}
#Debug simulation 
Total elapsed time: 78.05052238889039. Arrivals time: 0.48759484803304076 Scheduler time: 77.40671291388571 Scheduler overhead time: 0.05948714027181268 Adapter cache time: 0.01660432806238532 Engine time: 0.05848053051158786 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-16/adapters_320_slots_64_rate_1.6-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-16/adapters_320_slots_64_rate_1.6-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 33, 17280, 17280, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 17280, 17280, 4320, 33, 33, 4320, 17280, 17280, 4320, 4320, 33, 33, 4320, 17280, 17280, 33, 17280, 4320, 33, 4320, 17280, 33, 4320, 17280, 17280, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 17280, 4320, 17280, 17280, 33, 17280, 33, 17280, 4320, 33, 33, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 33, 4320, 4320, 33, 17280, 4320, 17280, 17280, 4320, 33, 4320, 4320, 4320, 33, 17280, 4320, 17280, 33, 17280, 33, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 17280, 33, 33, 33, 33, 17280, 4320, 4320, 17280, 4320, 4320, 33, 4320, 17280, 4320, 33, 33, 4320, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 4320, 17280, 4320, 4320, 4320, 33, 17280, 33, 17280, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 33, 33, 17280, 4320, 17280, 4320, 17280, 4320, 33, 4320, 33, 33, 33, 17280, 17280, 4320, 4320, 33, 33, 4320, 33, 17280, 33, 33, 4320, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 4320, 17280, 4320, 33, 4320, 33, 17280, 4320, 4320, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 4320, 4320, 17280, 33, 17280, 33, 33, 33, 17280, 4320, 17280, 17280, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 17280, 33, 33, 4320, 33, 4320, 4320, 33, 17280, 17280, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2314698 . Total input tokens: 515493855 . Total output tokens: 462974761
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 72.98348494106904,
    "estimated_duration": 3600.1121670602,
    "input_throughput": 6231.609727404601,
    "output_throughput": 5513.105169777926,
    "total_throughput": 11744.714897182526,
    "itl": 154.73369371914654,
    "ttft": 2006883.5986738338,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 566,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7646898382785625,
    "arrivals": 770785,
    "finished_requests": 90901,
    "scheduler_time": 168.21094640132327
}
#Debug simulation 
Total elapsed time: 72.9836454000324. Arrivals time: 0.7981465291231871 Scheduler time: 72.03046994609758 Scheduler overhead time: 0.058109795674681664 Adapter cache time: 0.017976430244743824 Engine time: 0.057269826997071505 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-32/adapters_320_slots_64_rate_1.6-0.4-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-32/adapters_320_slots_64_rate_1.6-0.4-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 33, 17280, 17280, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 17280, 17280, 4320, 33, 33, 4320, 17280, 17280, 4320, 4320, 33, 33, 4320, 17280, 17280, 33, 17280, 4320, 33, 4320, 17280, 33, 4320, 17280, 17280, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 17280, 4320, 17280, 17280, 33, 17280, 33, 17280, 4320, 33, 33, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 33, 4320, 4320, 33, 17280, 4320, 17280, 17280, 4320, 33, 4320, 4320, 4320, 33, 17280, 4320, 17280, 33, 17280, 33, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 17280, 33, 33, 33, 33, 17280, 4320, 4320, 17280, 4320, 4320, 33, 4320, 17280, 4320, 33, 33, 4320, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 4320, 17280, 4320, 4320, 4320, 33, 17280, 33, 17280, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 33, 33, 17280, 4320, 17280, 4320, 17280, 4320, 33, 4320, 33, 33, 33, 17280, 17280, 4320, 4320, 33, 33, 4320, 33, 17280, 33, 33, 4320, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 4320, 17280, 4320, 33, 4320, 33, 17280, 4320, 4320, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 4320, 4320, 17280, 33, 17280, 33, 33, 33, 17280, 4320, 17280, 17280, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 17280, 33, 33, 4320, 33, 4320, 4320, 33, 17280, 17280, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2314698 . Total input tokens: 515493855 . Total output tokens: 462974761
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 78.33195483824238,
    "estimated_duration": 3600.046253615824,
    "input_throughput": 6233.836850695889,
    "output_throughput": 5516.341347018495,
    "total_throughput": 11750.178197714384,
    "itl": 154.77263877704146,
    "ttft": 2007972.2005908757,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 434,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4418447870574929,
    "arrivals": 770785,
    "finished_requests": 90995,
    "scheduler_time": 168.07019135571045
}
#Debug simulation 
Total elapsed time: 78.3321172920987. Arrivals time: 0.47663032449781895 Scheduler time: 77.69811742193997 Scheduler overhead time: 0.05963567038998008 Adapter cache time: 0.016695021651685238 Engine time: 0.059047346003353596 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-16/adapters_320_slots_64_rate_1.6-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-16/adapters_320_slots_64_rate_1.6-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 33, 17280, 17280, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 17280, 17280, 4320, 33, 33, 4320, 17280, 17280, 4320, 4320, 33, 33, 4320, 17280, 17280, 33, 17280, 4320, 33, 4320, 17280, 33, 4320, 17280, 17280, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 17280, 4320, 17280, 17280, 33, 17280, 33, 17280, 4320, 33, 33, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 33, 4320, 4320, 33, 17280, 4320, 17280, 17280, 4320, 33, 4320, 4320, 4320, 33, 17280, 4320, 17280, 33, 17280, 33, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 17280, 33, 33, 33, 33, 17280, 4320, 4320, 17280, 4320, 4320, 33, 4320, 17280, 4320, 33, 33, 4320, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 4320, 17280, 4320, 4320, 4320, 33, 17280, 33, 17280, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 33, 33, 17280, 4320, 17280, 4320, 17280, 4320, 33, 4320, 33, 33, 33, 17280, 17280, 4320, 4320, 33, 33, 4320, 33, 17280, 33, 33, 4320, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 4320, 17280, 4320, 33, 4320, 33, 17280, 4320, 4320, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 4320, 4320, 17280, 33, 17280, 33, 33, 33, 17280, 4320, 17280, 17280, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 17280, 33, 33, 4320, 33, 4320, 4320, 33, 17280, 17280, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2314698 . Total input tokens: 515493855 . Total output tokens: 462974761
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 72.98358759889379,
    "estimated_duration": 3600.128800688211,
    "input_throughput": 6239.288437598691,
    "output_throughput": 5519.956673828199,
    "total_throughput": 11759.245111426892,
    "itl": 155.01626638231903,
    "ttft": 2007370.9619708199,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 567,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6953585172095103,
    "arrivals": 770785,
    "finished_requests": 91009,
    "scheduler_time": 167.9393909684508
}
#Debug simulation 
Total elapsed time: 72.98375571984798. Arrivals time: 0.48671198543161154 Scheduler time: 72.34170594159514 Scheduler overhead time: 0.05861296923831105 Adapter cache time: 0.01787468185648322 Engine time: 0.056965313851833344 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-32/adapters_320_slots_64_rate_1.6-0.4-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-32/adapters_320_slots_64_rate_1.6-0.4-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [106 107 107]
Adapter prompts. [4320, 17280, 17280, 33, 17280, 17280, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 17280, 17280, 4320, 33, 33, 4320, 17280, 17280, 4320, 4320, 33, 33, 4320, 17280, 17280, 33, 17280, 4320, 33, 4320, 17280, 33, 4320, 17280, 17280, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 17280, 4320, 17280, 17280, 33, 17280, 33, 17280, 4320, 33, 33, 4320, 4320, 17280, 4320, 17280, 17280, 17280, 33, 4320, 4320, 33, 17280, 4320, 17280, 17280, 4320, 33, 4320, 4320, 4320, 33, 17280, 4320, 17280, 33, 17280, 33, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 4320, 33, 4320, 33, 17280, 33, 33, 33, 33, 17280, 4320, 4320, 17280, 4320, 4320, 33, 4320, 17280, 4320, 33, 33, 4320, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 4320, 17280, 4320, 4320, 4320, 33, 17280, 33, 17280, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 33, 33, 17280, 4320, 17280, 4320, 17280, 4320, 33, 4320, 33, 33, 33, 17280, 17280, 4320, 4320, 33, 33, 4320, 33, 17280, 33, 33, 4320, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 4320, 17280, 4320, 33, 4320, 33, 17280, 4320, 4320, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 4320, 33, 4320, 33, 4320, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 4320, 4320, 17280, 33, 17280, 33, 33, 33, 17280, 4320, 17280, 17280, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 17280, 33, 33, 4320, 33, 4320, 4320, 33, 17280, 17280, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2314698 . Total input tokens: 515493855 . Total output tokens: 462974761
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 78.05114482017234,
    "estimated_duration": 3600.061098859393,
    "input_throughput": 6233.811144791495,
    "output_throughput": 5516.318599784862,
    "total_throughput": 11750.129744576358,
    "itl": 154.7730918533204,
    "ttft": 2007978.8875349162,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 434,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.459324563369155,
    "arrivals": 770785,
    "finished_requests": 90995,
    "scheduler_time": 168.07020234370617
}
#Debug simulation 
Total elapsed time: 78.05131531180814. Arrivals time: 0.49153190525248647 Scheduler time: 77.40241539804265 Scheduler overhead time: 0.05994622269645333 Adapter cache time: 0.016482624225318432 Engine time: 0.05947629502043128 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-8/adapters_320_slots_64_rate_1.6-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-8/adapters_320_slots_64_rate_1.6-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 540, 17280, 17280, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 17280, 17280, 1080, 540, 540, 1080, 17280, 17280, 1080, 1080, 540, 540, 1080, 17280, 17280, 540, 17280, 1080, 540, 1080, 17280, 540, 1080, 17280, 17280, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 17280, 1080, 17280, 17280, 540, 17280, 540, 17280, 1080, 540, 540, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 540, 1080, 1080, 540, 17280, 1080, 17280, 17280, 1080, 540, 1080, 1080, 1080, 540, 17280, 1080, 17280, 540, 17280, 540, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 17280, 540, 540, 540, 540, 17280, 1080, 1080, 17280, 1080, 1080, 540, 1080, 17280, 1080, 540, 540, 1080, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 1080, 17280, 1080, 1080, 1080, 540, 17280, 540, 17280, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 540, 540, 17280, 1080, 17280, 1080, 17280, 1080, 540, 1080, 540, 540, 540, 17280, 17280, 1080, 1080, 540, 540, 1080, 540, 17280, 540, 540, 1080, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 1080, 17280, 1080, 540, 1080, 540, 17280, 1080, 1080, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 1080, 1080, 17280, 540, 17280, 540, 540, 540, 17280, 1080, 17280, 17280, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 17280, 540, 540, 1080, 540, 1080, 1080, 540, 17280, 17280, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2021760 . Total input tokens: 450245744 . Total output tokens: 404618148
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 78.04660299001262,
    "estimated_duration": 3600.100148483538,
    "input_throughput": 6217.143711801479,
    "output_throughput": 5485.662116460509,
    "total_throughput": 11702.80582826199,
    "itl": 153.26304118812175,
    "ttft": 1990469.7501911004,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 562,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7199941120902313,
    "arrivals": 673640,
    "finished_requests": 90533,
    "scheduler_time": 169.44024281388576
}
#Debug simulation 
Total elapsed time: 78.04676158167422. Arrivals time: 0.47134249098598957 Scheduler time: 77.42061826121062 Scheduler overhead time: 0.057517258916050196 Adapter cache time: 0.018325576558709145 Engine time: 0.05686008417978883 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-16/adapters_320_slots_64_rate_1.6-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-16/adapters_320_slots_64_rate_1.6-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 540, 17280, 17280, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 17280, 17280, 1080, 540, 540, 1080, 17280, 17280, 1080, 1080, 540, 540, 1080, 17280, 17280, 540, 17280, 1080, 540, 1080, 17280, 540, 1080, 17280, 17280, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 17280, 1080, 17280, 17280, 540, 17280, 540, 17280, 1080, 540, 540, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 540, 1080, 1080, 540, 17280, 1080, 17280, 17280, 1080, 540, 1080, 1080, 1080, 540, 17280, 1080, 17280, 540, 17280, 540, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 17280, 540, 540, 540, 540, 17280, 1080, 1080, 17280, 1080, 1080, 540, 1080, 17280, 1080, 540, 540, 1080, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 1080, 17280, 1080, 1080, 1080, 540, 17280, 540, 17280, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 540, 540, 17280, 1080, 17280, 1080, 17280, 1080, 540, 1080, 540, 540, 540, 17280, 17280, 1080, 1080, 540, 540, 1080, 540, 17280, 540, 540, 1080, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 1080, 17280, 1080, 540, 1080, 540, 17280, 1080, 1080, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 1080, 1080, 17280, 540, 17280, 540, 540, 540, 17280, 1080, 17280, 17280, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 17280, 540, 540, 1080, 540, 1080, 1080, 540, 17280, 17280, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2021760 . Total input tokens: 450245744 . Total output tokens: 404618148
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 77.91301826899871,
    "estimated_duration": 3600.021871984455,
    "input_throughput": 6216.113900348167,
    "output_throughput": 5484.964175819114,
    "total_throughput": 11701.07807616728,
    "itl": 153.1847057777293,
    "ttft": 1989804.0499623506,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 557,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.819089853994089,
    "arrivals": 673640,
    "finished_requests": 90505,
    "scheduler_time": 169.56724830771586
}
#Debug simulation 
Total elapsed time: 77.91317657520995. Arrivals time: 0.4602069309912622 Scheduler time: 77.29663880495355 Scheduler overhead time: 0.05876247491687536 Adapter cache time: 0.01855245605111122 Engine time: 0.056920696049928665 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-32/adapters_320_slots_64_rate_1.6-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-32/adapters_320_slots_64_rate_1.6-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 540, 17280, 17280, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 17280, 17280, 1080, 540, 540, 1080, 17280, 17280, 1080, 1080, 540, 540, 1080, 17280, 17280, 540, 17280, 1080, 540, 1080, 17280, 540, 1080, 17280, 17280, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 17280, 1080, 17280, 17280, 540, 17280, 540, 17280, 1080, 540, 540, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 540, 1080, 1080, 540, 17280, 1080, 17280, 17280, 1080, 540, 1080, 1080, 1080, 540, 17280, 1080, 17280, 540, 17280, 540, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 17280, 540, 540, 540, 540, 17280, 1080, 1080, 17280, 1080, 1080, 540, 1080, 17280, 1080, 540, 540, 1080, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 1080, 17280, 1080, 1080, 1080, 540, 17280, 540, 17280, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 540, 540, 17280, 1080, 17280, 1080, 17280, 1080, 540, 1080, 540, 540, 540, 17280, 17280, 1080, 1080, 540, 540, 1080, 540, 17280, 540, 540, 1080, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 1080, 17280, 1080, 540, 1080, 540, 17280, 1080, 1080, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 1080, 1080, 17280, 540, 17280, 540, 540, 540, 17280, 1080, 17280, 17280, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 17280, 540, 540, 1080, 540, 1080, 1080, 540, 17280, 17280, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2021760 . Total input tokens: 450245744 . Total output tokens: 404618148
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 78.3652704320848,
    "estimated_duration": 3600.025859330435,
    "input_throughput": 6216.107015454074,
    "output_throughput": 5484.958100737792,
    "total_throughput": 11701.065116191865,
    "itl": 153.18478576570152,
    "ttft": 1989805.8285610368,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 557,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8220450567081683,
    "arrivals": 673640,
    "finished_requests": 90505,
    "scheduler_time": 169.56730578542468
}
#Debug simulation 
Total elapsed time: 78.36543378187343. Arrivals time: 0.4638107721693814 Scheduler time: 77.7432675040327 Scheduler overhead time: 0.05946232192218304 Adapter cache time: 0.018430239986628294 Engine time: 0.05807875748723745 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-16-16/adapters_320_slots_64_rate_1.6-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-16-16/adapters_320_slots_64_rate_1.6-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 540, 17280, 17280, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 17280, 17280, 1080, 540, 540, 1080, 17280, 17280, 1080, 1080, 540, 540, 1080, 17280, 17280, 540, 17280, 1080, 540, 1080, 17280, 540, 1080, 17280, 17280, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 17280, 1080, 17280, 17280, 540, 17280, 540, 17280, 1080, 540, 540, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 540, 1080, 1080, 540, 17280, 1080, 17280, 17280, 1080, 540, 1080, 1080, 1080, 540, 17280, 1080, 17280, 540, 17280, 540, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 17280, 540, 540, 540, 540, 17280, 1080, 1080, 17280, 1080, 1080, 540, 1080, 17280, 1080, 540, 540, 1080, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 1080, 17280, 1080, 1080, 1080, 540, 17280, 540, 17280, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 540, 540, 17280, 1080, 17280, 1080, 17280, 1080, 540, 1080, 540, 540, 540, 17280, 17280, 1080, 1080, 540, 540, 1080, 540, 17280, 540, 540, 1080, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 1080, 17280, 1080, 540, 1080, 540, 17280, 1080, 1080, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 1080, 1080, 17280, 540, 17280, 540, 540, 540, 17280, 1080, 17280, 17280, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 17280, 540, 540, 1080, 540, 1080, 1080, 540, 17280, 17280, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2021760 . Total input tokens: 450245744 . Total output tokens: 404618148
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 68.86603328119963,
    "estimated_duration": 3600.0785314614986,
    "input_throughput": 6232.310990974824,
    "output_throughput": 5499.116151769903,
    "total_throughput": 11731.427142744726,
    "itl": 153.75577816233087,
    "ttft": 1990126.8358647989,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 580,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8143138534575598,
    "arrivals": 673640,
    "finished_requests": 90721,
    "scheduler_time": 168.80869139247366
}
#Debug simulation 
Total elapsed time: 68.86620245780796. Arrivals time: 0.47312127612531185 Scheduler time: 68.23719002725556 Scheduler overhead time: 0.058239635080099106 Adapter cache time: 0.018740773666650057 Engine time: 0.057097600772976875 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-16-32/adapters_320_slots_64_rate_1.6-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-16-32/adapters_320_slots_64_rate_1.6-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 540, 17280, 17280, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 17280, 17280, 1080, 540, 540, 1080, 17280, 17280, 1080, 1080, 540, 540, 1080, 17280, 17280, 540, 17280, 1080, 540, 1080, 17280, 540, 1080, 17280, 17280, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 17280, 1080, 17280, 17280, 540, 17280, 540, 17280, 1080, 540, 540, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 540, 1080, 1080, 540, 17280, 1080, 17280, 17280, 1080, 540, 1080, 1080, 1080, 540, 17280, 1080, 17280, 540, 17280, 540, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 17280, 540, 540, 540, 540, 17280, 1080, 1080, 17280, 1080, 1080, 540, 1080, 17280, 1080, 540, 540, 1080, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 1080, 17280, 1080, 1080, 1080, 540, 17280, 540, 17280, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 540, 540, 17280, 1080, 17280, 1080, 17280, 1080, 540, 1080, 540, 540, 540, 17280, 17280, 1080, 1080, 540, 540, 1080, 540, 17280, 540, 540, 1080, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 1080, 17280, 1080, 540, 1080, 540, 17280, 1080, 1080, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 1080, 1080, 17280, 540, 17280, 540, 540, 540, 17280, 1080, 17280, 17280, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 17280, 540, 540, 1080, 540, 1080, 1080, 540, 17280, 17280, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2021760 . Total input tokens: 450245744 . Total output tokens: 404618148
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 78.2573105529882,
    "estimated_duration": 3600.049206242983,
    "input_throughput": 6216.066702975393,
    "output_throughput": 5484.922529880348,
    "total_throughput": 11700.98923285574,
    "itl": 153.18559260704666,
    "ttft": 1989814.044342185,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 557,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8454352609813254,
    "arrivals": 673640,
    "finished_requests": 90505,
    "scheduler_time": 169.56740173165377
}
#Debug simulation 
Total elapsed time: 78.25746751576662. Arrivals time: 0.4729089611209929 Scheduler time: 77.62739409366623 Scheduler overhead time: 0.059364395681768656 Adapter cache time: 0.01828696858137846 Engine time: 0.05768326669931412 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_16-16-16/adapters_320_slots_64_rate_1.6-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_16-16-16/adapters_320_slots_64_rate_1.6-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 540, 17280, 17280, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 17280, 17280, 1080, 540, 540, 1080, 17280, 17280, 1080, 1080, 540, 540, 1080, 17280, 17280, 540, 17280, 1080, 540, 1080, 17280, 540, 1080, 17280, 17280, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 17280, 1080, 17280, 17280, 540, 17280, 540, 17280, 1080, 540, 540, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 540, 1080, 1080, 540, 17280, 1080, 17280, 17280, 1080, 540, 1080, 1080, 1080, 540, 17280, 1080, 17280, 540, 17280, 540, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 17280, 540, 540, 540, 540, 17280, 1080, 1080, 17280, 1080, 1080, 540, 1080, 17280, 1080, 540, 540, 1080, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 1080, 17280, 1080, 1080, 1080, 540, 17280, 540, 17280, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 540, 540, 17280, 1080, 17280, 1080, 17280, 1080, 540, 1080, 540, 540, 540, 17280, 17280, 1080, 1080, 540, 540, 1080, 540, 17280, 540, 540, 1080, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 1080, 17280, 1080, 540, 1080, 540, 17280, 1080, 1080, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 1080, 1080, 17280, 540, 17280, 540, 540, 540, 17280, 1080, 17280, 17280, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 17280, 540, 540, 1080, 540, 1080, 1080, 540, 17280, 17280, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2021760 . Total input tokens: 450245744 . Total output tokens: 404618148
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 74.95507873315364,
    "estimated_duration": 3600.1165586060383,
    "input_throughput": 6224.749292194323,
    "output_throughput": 5489.5553180789875,
    "total_throughput": 11714.304610273311,
    "itl": 153.5403055733232,
    "ttft": 1991184.5739944282,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 562,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.680408265735,
    "arrivals": 673640,
    "finished_requests": 90602,
    "scheduler_time": 169.17404118193375
}
#Debug simulation 
Total elapsed time: 74.95523746497929. Arrivals time: 0.4526484957896173 Scheduler time: 74.34845313476399 Scheduler overhead time: 0.05759907839819789 Adapter cache time: 0.018410346005111933 Engine time: 0.056387598626315594 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_16-16-32/adapters_320_slots_64_rate_1.6-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_16-16-32/adapters_320_slots_64_rate_1.6-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 540, 17280, 17280, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 17280, 17280, 1080, 540, 540, 1080, 17280, 17280, 1080, 1080, 540, 540, 1080, 17280, 17280, 540, 17280, 1080, 540, 1080, 17280, 540, 1080, 17280, 17280, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 17280, 1080, 17280, 17280, 540, 17280, 540, 17280, 1080, 540, 540, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 540, 1080, 1080, 540, 17280, 1080, 17280, 17280, 1080, 540, 1080, 1080, 1080, 540, 17280, 1080, 17280, 540, 17280, 540, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 1080, 540, 1080, 540, 17280, 540, 540, 540, 540, 17280, 1080, 1080, 17280, 1080, 1080, 540, 1080, 17280, 1080, 540, 540, 1080, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 1080, 17280, 1080, 1080, 1080, 540, 17280, 540, 17280, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 540, 540, 17280, 1080, 17280, 1080, 17280, 1080, 540, 1080, 540, 540, 540, 17280, 17280, 1080, 1080, 540, 540, 1080, 540, 17280, 540, 540, 1080, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 1080, 17280, 1080, 540, 1080, 540, 17280, 1080, 1080, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 1080, 540, 1080, 540, 1080, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 1080, 1080, 17280, 540, 17280, 540, 540, 540, 17280, 1080, 17280, 17280, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 17280, 540, 540, 1080, 540, 1080, 1080, 540, 17280, 17280, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2021760 . Total input tokens: 450245744 . Total output tokens: 404618148
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 78.3430021898821,
    "estimated_duration": 3600.074683144323,
    "input_throughput": 6216.022713299608,
    "output_throughput": 5484.88371434388,
    "total_throughput": 11700.906427643487,
    "itl": 153.186435009261,
    "ttft": 1989824.0524570378,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 557,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8693284804001413,
    "arrivals": 673640,
    "finished_requests": 90505,
    "scheduler_time": 169.56759303426765
}
#Debug simulation 
Total elapsed time: 78.34316834574565. Arrivals time: 0.7767917816527188 Scheduler time: 77.4100202806294 Scheduler overhead time: 0.05855382513254881 Adapter cache time: 0.01865673018619418 Engine time: 0.05735407583415508 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-8/adapters_320_slots_64_rate_1.6-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-8/adapters_320_slots_64_rate_1.6-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 270, 17280, 17280, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 17280, 17280, 1080, 270, 270, 1080, 17280, 17280, 1080, 1080, 270, 270, 1080, 17280, 17280, 270, 17280, 1080, 270, 1080, 17280, 270, 1080, 17280, 17280, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 17280, 1080, 17280, 17280, 270, 17280, 270, 17280, 1080, 270, 270, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 270, 1080, 1080, 270, 17280, 1080, 17280, 17280, 1080, 270, 1080, 1080, 1080, 270, 17280, 1080, 17280, 270, 17280, 270, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 17280, 270, 270, 270, 270, 17280, 1080, 1080, 17280, 1080, 1080, 270, 1080, 17280, 1080, 270, 270, 1080, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 1080, 17280, 1080, 1080, 1080, 270, 17280, 270, 17280, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 270, 270, 17280, 1080, 17280, 1080, 17280, 1080, 270, 1080, 270, 270, 270, 17280, 17280, 1080, 1080, 270, 270, 1080, 270, 17280, 270, 270, 1080, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 1080, 17280, 1080, 270, 1080, 270, 17280, 1080, 1080, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 1080, 1080, 17280, 270, 17280, 270, 270, 270, 17280, 1080, 17280, 17280, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 17280, 270, 270, 1080, 270, 1080, 1080, 270, 17280, 17280, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1993140 . Total input tokens: 443958301 . Total output tokens: 398929590
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 76.98209335608408,
    "estimated_duration": 3600.0500811566976,
    "input_throughput": 6173.278287522985,
    "output_throughput": 5496.414092562377,
    "total_throughput": 11669.692380085362,
    "itl": 154.33370882690423,
    "ttft": 1982983.7856998944,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 579,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.77202240373709,
    "arrivals": 664253,
    "finished_requests": 90596,
    "scheduler_time": 168.96947853674945
}
#Debug simulation 
Total elapsed time: 76.98225050838664. Arrivals time: 0.45705230720341206 Scheduler time: 76.37269354751334 Scheduler overhead time: 0.05640169000253081 Adapter cache time: 0.018474485725164413 Engine time: 0.056170746218413115 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-16/adapters_320_slots_64_rate_1.6-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-16/adapters_320_slots_64_rate_1.6-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 270, 17280, 17280, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 17280, 17280, 1080, 270, 270, 1080, 17280, 17280, 1080, 1080, 270, 270, 1080, 17280, 17280, 270, 17280, 1080, 270, 1080, 17280, 270, 1080, 17280, 17280, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 17280, 1080, 17280, 17280, 270, 17280, 270, 17280, 1080, 270, 270, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 270, 1080, 1080, 270, 17280, 1080, 17280, 17280, 1080, 270, 1080, 1080, 1080, 270, 17280, 1080, 17280, 270, 17280, 270, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 17280, 270, 270, 270, 270, 17280, 1080, 1080, 17280, 1080, 1080, 270, 1080, 17280, 1080, 270, 270, 1080, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 1080, 17280, 1080, 1080, 1080, 270, 17280, 270, 17280, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 270, 270, 17280, 1080, 17280, 1080, 17280, 1080, 270, 1080, 270, 270, 270, 17280, 17280, 1080, 1080, 270, 270, 1080, 270, 17280, 270, 270, 1080, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 1080, 17280, 1080, 270, 1080, 270, 17280, 1080, 1080, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 1080, 1080, 17280, 270, 17280, 270, 270, 270, 17280, 1080, 17280, 17280, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 17280, 270, 270, 1080, 270, 1080, 1080, 270, 17280, 17280, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1993140 . Total input tokens: 443958301 . Total output tokens: 398929590
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 76.78755228407681,
    "estimated_duration": 3600.136777975714,
    "input_throughput": 6173.129625507223,
    "output_throughput": 5496.281730475264,
    "total_throughput": 11669.411355982487,
    "itl": 154.33890380221465,
    "ttft": 1983001.6346730941,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 579,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.890999890258542,
    "arrivals": 664253,
    "finished_requests": 90596,
    "scheduler_time": 168.96821427529744
}
#Debug simulation 
Total elapsed time: 76.78771171811968. Arrivals time: 0.4698722236789763 Scheduler time: 76.16404754295945 Scheduler overhead time: 0.05721281422302127 Adapter cache time: 0.01841798797249794 Engine time: 0.05659050028771162 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-32/adapters_320_slots_64_rate_1.6-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-32/adapters_320_slots_64_rate_1.6-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 270, 17280, 17280, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 17280, 17280, 1080, 270, 270, 1080, 17280, 17280, 1080, 1080, 270, 270, 1080, 17280, 17280, 270, 17280, 1080, 270, 1080, 17280, 270, 1080, 17280, 17280, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 17280, 1080, 17280, 17280, 270, 17280, 270, 17280, 1080, 270, 270, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 270, 1080, 1080, 270, 17280, 1080, 17280, 17280, 1080, 270, 1080, 1080, 1080, 270, 17280, 1080, 17280, 270, 17280, 270, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 17280, 270, 270, 270, 270, 17280, 1080, 1080, 17280, 1080, 1080, 270, 1080, 17280, 1080, 270, 270, 1080, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 1080, 17280, 1080, 1080, 1080, 270, 17280, 270, 17280, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 270, 270, 17280, 1080, 17280, 1080, 17280, 1080, 270, 1080, 270, 270, 270, 17280, 17280, 1080, 1080, 270, 270, 1080, 270, 17280, 270, 270, 1080, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 1080, 17280, 1080, 270, 1080, 270, 17280, 1080, 1080, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 1080, 1080, 17280, 270, 17280, 270, 270, 270, 17280, 1080, 17280, 17280, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 17280, 270, 270, 1080, 270, 1080, 1080, 270, 17280, 17280, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1993140 . Total input tokens: 443958301 . Total output tokens: 398929590
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 76.6603980557993,
    "estimated_duration": 3600.139850205807,
    "input_throughput": 6173.124357580034,
    "output_throughput": 5496.277040145767,
    "total_throughput": 11669.401397725802,
    "itl": 154.33901136862,
    "ttft": 1983002.7361293735,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 579,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.89406118379907,
    "arrivals": 664253,
    "finished_requests": 90596,
    "scheduler_time": 168.96822521181713
}
#Debug simulation 
Total elapsed time: 76.66056879376993. Arrivals time: 0.4554718593135476 Scheduler time: 76.05098480824381 Scheduler overhead time: 0.057239999528974295 Adapter cache time: 0.018487929832190275 Engine time: 0.05628881836310029 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-16-16/adapters_320_slots_64_rate_1.6-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-16-16/adapters_320_slots_64_rate_1.6-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 270, 17280, 17280, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 17280, 17280, 1080, 270, 270, 1080, 17280, 17280, 1080, 1080, 270, 270, 1080, 17280, 17280, 270, 17280, 1080, 270, 1080, 17280, 270, 1080, 17280, 17280, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 17280, 1080, 17280, 17280, 270, 17280, 270, 17280, 1080, 270, 270, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 270, 1080, 1080, 270, 17280, 1080, 17280, 17280, 1080, 270, 1080, 1080, 1080, 270, 17280, 1080, 17280, 270, 17280, 270, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 17280, 270, 270, 270, 270, 17280, 1080, 1080, 17280, 1080, 1080, 270, 1080, 17280, 1080, 270, 270, 1080, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 1080, 17280, 1080, 1080, 1080, 270, 17280, 270, 17280, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 270, 270, 17280, 1080, 17280, 1080, 17280, 1080, 270, 1080, 270, 270, 270, 17280, 17280, 1080, 1080, 270, 270, 1080, 270, 17280, 270, 270, 1080, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 1080, 17280, 1080, 270, 1080, 270, 17280, 1080, 1080, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 1080, 1080, 17280, 270, 17280, 270, 270, 270, 17280, 1080, 17280, 17280, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 17280, 270, 270, 1080, 270, 1080, 1080, 270, 17280, 17280, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1993140 . Total input tokens: 443958301 . Total output tokens: 398929590
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 77.77869865763932,
    "estimated_duration": 3600.1336182712867,
    "input_throughput": 6173.148376273768,
    "output_throughput": 5496.605709179777,
    "total_throughput": 11669.754085453545,
    "itl": 154.33745479412568,
    "ttft": 1983050.7137649786,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 577,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8028921306622114,
    "arrivals": 664253,
    "finished_requests": 90598,
    "scheduler_time": 168.97258790471162
}
#Debug simulation 
Total elapsed time: 77.77885890798643. Arrivals time: 0.4779463605955243 Scheduler time: 77.14672564947978 Scheduler overhead time: 0.05745397647842765 Adapter cache time: 0.01814439846202731 Engine time: 0.05642886599525809 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-16-32/adapters_320_slots_64_rate_1.6-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-16-32/adapters_320_slots_64_rate_1.6-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 270, 17280, 17280, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 17280, 17280, 1080, 270, 270, 1080, 17280, 17280, 1080, 1080, 270, 270, 1080, 17280, 17280, 270, 17280, 1080, 270, 1080, 17280, 270, 1080, 17280, 17280, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 17280, 1080, 17280, 17280, 270, 17280, 270, 17280, 1080, 270, 270, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 270, 1080, 1080, 270, 17280, 1080, 17280, 17280, 1080, 270, 1080, 1080, 1080, 270, 17280, 1080, 17280, 270, 17280, 270, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 17280, 270, 270, 270, 270, 17280, 1080, 1080, 17280, 1080, 1080, 270, 1080, 17280, 1080, 270, 270, 1080, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 1080, 17280, 1080, 1080, 1080, 270, 17280, 270, 17280, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 270, 270, 17280, 1080, 17280, 1080, 17280, 1080, 270, 1080, 270, 270, 270, 17280, 17280, 1080, 1080, 270, 270, 1080, 270, 17280, 270, 270, 1080, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 1080, 17280, 1080, 270, 1080, 270, 17280, 1080, 1080, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 1080, 1080, 17280, 270, 17280, 270, 270, 270, 17280, 1080, 17280, 17280, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 17280, 270, 270, 1080, 270, 1080, 1080, 270, 17280, 17280, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1993140 . Total input tokens: 443958301 . Total output tokens: 398929590
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 76.49787471489981,
    "estimated_duration": 3600.1701717477986,
    "input_throughput": 6173.072365968388,
    "output_throughput": 5496.230749113089,
    "total_throughput": 11669.303115081477,
    "itl": 154.33997240871022,
    "ttft": 1983014.076817212,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 579,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.919211941082034,
    "arrivals": 664253,
    "finished_requests": 90596,
    "scheduler_time": 168.96852266890303
}
#Debug simulation 
Total elapsed time: 76.49803591193631. Arrivals time: 0.46742798388004303 Scheduler time: 75.87642640154809 Scheduler overhead time: 0.056937289889901876 Adapter cache time: 0.018430931959301233 Engine time: 0.05609933892264962 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_16-16-16/adapters_320_slots_64_rate_1.6-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_16-16-16/adapters_320_slots_64_rate_1.6-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 270, 17280, 17280, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 17280, 17280, 1080, 270, 270, 1080, 17280, 17280, 1080, 1080, 270, 270, 1080, 17280, 17280, 270, 17280, 1080, 270, 1080, 17280, 270, 1080, 17280, 17280, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 17280, 1080, 17280, 17280, 270, 17280, 270, 17280, 1080, 270, 270, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 270, 1080, 1080, 270, 17280, 1080, 17280, 17280, 1080, 270, 1080, 1080, 1080, 270, 17280, 1080, 17280, 270, 17280, 270, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 17280, 270, 270, 270, 270, 17280, 1080, 1080, 17280, 1080, 1080, 270, 1080, 17280, 1080, 270, 270, 1080, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 1080, 17280, 1080, 1080, 1080, 270, 17280, 270, 17280, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 270, 270, 17280, 1080, 17280, 1080, 17280, 1080, 270, 1080, 270, 270, 270, 17280, 17280, 1080, 1080, 270, 270, 1080, 270, 17280, 270, 270, 1080, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 1080, 17280, 1080, 270, 1080, 270, 17280, 1080, 1080, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 1080, 1080, 17280, 270, 17280, 270, 270, 270, 17280, 1080, 17280, 17280, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 17280, 270, 270, 1080, 270, 1080, 1080, 270, 17280, 17280, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1993140 . Total input tokens: 443958301 . Total output tokens: 398929590
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 76.96457713097334,
    "estimated_duration": 3600.009313953038,
    "input_throughput": 6173.348194923562,
    "output_throughput": 5496.476335021539,
    "total_throughput": 11669.824529945101,
    "itl": 154.33266285959346,
    "ttft": 1982971.4382295175,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 579,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.731239120748335,
    "arrivals": 664253,
    "finished_requests": 90596,
    "scheduler_time": 168.96863026256722
}
#Debug simulation 
Total elapsed time: 76.96473326114938. Arrivals time: 0.45562670147046447 Scheduler time: 76.35648941388354 Scheduler overhead time: 0.05721090966835618 Adapter cache time: 0.018037478905171156 Engine time: 0.0559648722410202 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_16-16-32/adapters_320_slots_64_rate_1.6-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_16-16-32/adapters_320_slots_64_rate_1.6-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 270, 17280, 17280, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 17280, 17280, 1080, 270, 270, 1080, 17280, 17280, 1080, 1080, 270, 270, 1080, 17280, 17280, 270, 17280, 1080, 270, 1080, 17280, 270, 1080, 17280, 17280, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 17280, 1080, 17280, 17280, 270, 17280, 270, 17280, 1080, 270, 270, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 270, 1080, 1080, 270, 17280, 1080, 17280, 17280, 1080, 270, 1080, 1080, 1080, 270, 17280, 1080, 17280, 270, 17280, 270, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 1080, 270, 1080, 270, 17280, 270, 270, 270, 270, 17280, 1080, 1080, 17280, 1080, 1080, 270, 1080, 17280, 1080, 270, 270, 1080, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 1080, 17280, 1080, 1080, 1080, 270, 17280, 270, 17280, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 270, 270, 17280, 1080, 17280, 1080, 17280, 1080, 270, 1080, 270, 270, 270, 17280, 17280, 1080, 1080, 270, 270, 1080, 270, 17280, 270, 270, 1080, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 1080, 17280, 1080, 270, 1080, 270, 17280, 1080, 1080, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 1080, 270, 1080, 270, 1080, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 1080, 1080, 17280, 270, 17280, 270, 270, 270, 17280, 1080, 17280, 17280, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 17280, 270, 270, 1080, 270, 1080, 1080, 270, 17280, 17280, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1993140 . Total input tokens: 443958301 . Total output tokens: 398929590
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 76.4649462159723,
    "estimated_duration": 3600.023206415113,
    "input_throughput": 6173.179095178709,
    "output_throughput": 5496.162903822813,
    "total_throughput": 11669.34199900152,
    "itl": 154.34102855633034,
    "ttft": 1982970.066327897,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 579,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9432309142872646,
    "arrivals": 664253,
    "finished_requests": 90592,
    "scheduler_time": 168.9605785944489
}
#Debug simulation 
Total elapsed time: 76.46511350572109. Arrivals time: 0.45141166914254427 Scheduler time: 75.86047573154792 Scheduler overhead time: 0.05691315745934844 Adapter cache time: 0.01829133229330182 Engine time: 0.056336583103984594 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-8/adapters_320_slots_64_rate_1.6-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-8/adapters_320_slots_64_rate_1.6-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 135, 17280, 17280, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 17280, 17280, 1080, 135, 135, 1080, 17280, 17280, 1080, 1080, 135, 135, 1080, 17280, 17280, 135, 17280, 1080, 135, 1080, 17280, 135, 1080, 17280, 17280, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 17280, 1080, 17280, 17280, 135, 17280, 135, 17280, 1080, 135, 135, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 135, 1080, 1080, 135, 17280, 1080, 17280, 17280, 1080, 135, 1080, 1080, 1080, 135, 17280, 1080, 17280, 135, 17280, 135, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 17280, 135, 135, 135, 135, 17280, 1080, 1080, 17280, 1080, 1080, 135, 1080, 17280, 1080, 135, 135, 1080, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 1080, 17280, 1080, 1080, 1080, 135, 17280, 135, 17280, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 135, 135, 17280, 1080, 17280, 1080, 17280, 1080, 135, 1080, 135, 135, 135, 17280, 17280, 1080, 1080, 135, 135, 1080, 135, 17280, 135, 135, 1080, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 1080, 17280, 1080, 135, 1080, 135, 17280, 1080, 1080, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 1080, 1080, 17280, 135, 17280, 135, 135, 135, 17280, 1080, 17280, 17280, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 17280, 135, 135, 1080, 135, 1080, 1080, 135, 17280, 17280, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1978830 . Total input tokens: 440734472 . Total output tokens: 396088724
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 78.0241389288567,
    "estimated_duration": 3600.091742947118,
    "input_throughput": 6222.691419986146,
    "output_throughput": 5492.381420206059,
    "total_throughput": 11715.072840192206,
    "itl": 153.95834530695663,
    "ttft": 1987566.2889088434,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 573,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7536594772734928,
    "arrivals": 659440,
    "finished_requests": 90380,
    "scheduler_time": 169.00204487354188
}
#Debug simulation 
Total elapsed time: 78.0243043731898. Arrivals time: 0.4697042624466121 Scheduler time: 77.40053285844624 Scheduler overhead time: 0.057921068742871284 Adapter cache time: 0.01815440459176898 Engine time: 0.05621261149644852 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-16/adapters_320_slots_64_rate_1.6-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-16/adapters_320_slots_64_rate_1.6-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 135, 17280, 17280, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 17280, 17280, 1080, 135, 135, 1080, 17280, 17280, 1080, 1080, 135, 135, 1080, 17280, 17280, 135, 17280, 1080, 135, 1080, 17280, 135, 1080, 17280, 17280, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 17280, 1080, 17280, 17280, 135, 17280, 135, 17280, 1080, 135, 135, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 135, 1080, 1080, 135, 17280, 1080, 17280, 17280, 1080, 135, 1080, 1080, 1080, 135, 17280, 1080, 17280, 135, 17280, 135, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 17280, 135, 135, 135, 135, 17280, 1080, 1080, 17280, 1080, 1080, 135, 1080, 17280, 1080, 135, 135, 1080, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 1080, 17280, 1080, 1080, 1080, 135, 17280, 135, 17280, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 135, 135, 17280, 1080, 17280, 1080, 17280, 1080, 135, 1080, 135, 135, 135, 17280, 17280, 1080, 1080, 135, 135, 1080, 135, 17280, 135, 135, 1080, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 1080, 17280, 1080, 135, 1080, 135, 17280, 1080, 1080, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 1080, 1080, 17280, 135, 17280, 135, 135, 135, 17280, 1080, 17280, 17280, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 17280, 135, 135, 1080, 135, 1080, 1080, 135, 17280, 17280, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1978830 . Total input tokens: 440734472 . Total output tokens: 396088724
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 76.0335328602232,
    "estimated_duration": 3600.0878064079116,
    "input_throughput": 6229.866382725323,
    "output_throughput": 5502.661897506897,
    "total_throughput": 11732.52828023222,
    "itl": 154.50627040022187,
    "ttft": 1988633.8853396587,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 582,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8987442551879268,
    "arrivals": 659440,
    "finished_requests": 90538,
    "scheduler_time": 168.48198226157578
}
#Debug simulation 
Total elapsed time: 76.03369597299024. Arrivals time: 0.4959949245676398 Scheduler time: 75.38597594946623 Scheduler overhead time: 0.05651161540299654 Adapter cache time: 0.0181439109146595 Engine time: 0.05560634005814791 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-32/adapters_320_slots_64_rate_1.6-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-32/adapters_320_slots_64_rate_1.6-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 135, 17280, 17280, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 17280, 17280, 1080, 135, 135, 1080, 17280, 17280, 1080, 1080, 135, 135, 1080, 17280, 17280, 135, 17280, 1080, 135, 1080, 17280, 135, 1080, 17280, 17280, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 17280, 1080, 17280, 17280, 135, 17280, 135, 17280, 1080, 135, 135, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 135, 1080, 1080, 135, 17280, 1080, 17280, 17280, 1080, 135, 1080, 1080, 1080, 135, 17280, 1080, 17280, 135, 17280, 135, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 17280, 135, 135, 135, 135, 17280, 1080, 1080, 17280, 1080, 1080, 135, 1080, 17280, 1080, 135, 135, 1080, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 1080, 17280, 1080, 1080, 1080, 135, 17280, 135, 17280, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 135, 135, 17280, 1080, 17280, 1080, 17280, 1080, 135, 1080, 135, 135, 135, 17280, 17280, 1080, 1080, 135, 135, 1080, 135, 17280, 135, 135, 1080, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 1080, 17280, 1080, 135, 1080, 135, 17280, 1080, 1080, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 1080, 1080, 17280, 135, 17280, 135, 135, 135, 17280, 1080, 17280, 17280, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 17280, 135, 135, 1080, 135, 1080, 1080, 135, 17280, 17280, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1978830 . Total input tokens: 440734472 . Total output tokens: 396088724
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 76.72007493581623,
    "estimated_duration": 3600.091249962416,
    "input_throughput": 6229.860423741799,
    "output_throughput": 5502.6566341080415,
    "total_throughput": 11732.51705784984,
    "itl": 154.50641577862473,
    "ttft": 1988635.1052174391,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 582,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9021799978613971,
    "arrivals": 659440,
    "finished_requests": 90538,
    "scheduler_time": 168.48199007337556
}
#Debug simulation 
Total elapsed time: 76.72023170394823. Arrivals time: 0.45293937623500824 Scheduler time: 76.1163305840455 Scheduler overhead time: 0.05655892426148057 Adapter cache time: 0.01827486092224717 Engine time: 0.05511013697832823 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-16/adapters_320_slots_64_rate_1.6-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-16/adapters_320_slots_64_rate_1.6-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 135, 17280, 17280, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 17280, 17280, 1080, 135, 135, 1080, 17280, 17280, 1080, 1080, 135, 135, 1080, 17280, 17280, 135, 17280, 1080, 135, 1080, 17280, 135, 1080, 17280, 17280, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 17280, 1080, 17280, 17280, 135, 17280, 135, 17280, 1080, 135, 135, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 135, 1080, 1080, 135, 17280, 1080, 17280, 17280, 1080, 135, 1080, 1080, 1080, 135, 17280, 1080, 17280, 135, 17280, 135, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 17280, 135, 135, 135, 135, 17280, 1080, 1080, 17280, 1080, 1080, 135, 1080, 17280, 1080, 135, 135, 1080, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 1080, 17280, 1080, 1080, 1080, 135, 17280, 135, 17280, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 135, 135, 17280, 1080, 17280, 1080, 17280, 1080, 135, 1080, 135, 135, 135, 17280, 17280, 1080, 1080, 135, 135, 1080, 135, 17280, 135, 135, 1080, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 1080, 17280, 1080, 135, 1080, 135, 17280, 1080, 1080, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 1080, 1080, 17280, 135, 17280, 135, 135, 135, 17280, 1080, 17280, 17280, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 17280, 135, 135, 1080, 135, 1080, 1080, 135, 17280, 17280, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1978830 . Total input tokens: 440734472 . Total output tokens: 396088724
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 77.87904565082863,
    "estimated_duration": 3600.129555141448,
    "input_throughput": 6222.626063000064,
    "output_throughput": 5492.323733672724,
    "total_throughput": 11714.949796672789,
    "itl": 153.95960163381386,
    "ttft": 1987580.1940991723,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 573,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.790523334164162,
    "arrivals": 659440,
    "finished_requests": 90380,
    "scheduler_time": 169.00229702123772
}
#Debug simulation 
Total elapsed time: 77.87920662062243. Arrivals time: 0.4507112461142242 Scheduler time: 77.27555674826726 Scheduler overhead time: 0.0568529749289155 Adapter cache time: 0.018212548457086086 Engine time: 0.05598936788737774 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-32/adapters_320_slots_64_rate_1.6-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-32/adapters_320_slots_64_rate_1.6-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 135, 17280, 17280, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 17280, 17280, 1080, 135, 135, 1080, 17280, 17280, 1080, 1080, 135, 135, 1080, 17280, 17280, 135, 17280, 1080, 135, 1080, 17280, 135, 1080, 17280, 17280, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 17280, 1080, 17280, 17280, 135, 17280, 135, 17280, 1080, 135, 135, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 135, 1080, 1080, 135, 17280, 1080, 17280, 17280, 1080, 135, 1080, 1080, 1080, 135, 17280, 1080, 17280, 135, 17280, 135, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 17280, 135, 135, 135, 135, 17280, 1080, 1080, 17280, 1080, 1080, 135, 1080, 17280, 1080, 135, 135, 1080, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 1080, 17280, 1080, 1080, 1080, 135, 17280, 135, 17280, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 135, 135, 17280, 1080, 17280, 1080, 17280, 1080, 135, 1080, 135, 135, 135, 17280, 17280, 1080, 1080, 135, 135, 1080, 135, 17280, 135, 135, 1080, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 1080, 17280, 1080, 135, 1080, 135, 17280, 1080, 1080, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 1080, 1080, 17280, 135, 17280, 135, 135, 135, 17280, 1080, 17280, 17280, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 17280, 135, 135, 1080, 135, 1080, 1080, 135, 17280, 17280, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1978830 . Total input tokens: 440734472 . Total output tokens: 396088724
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 76.26299561187625,
    "estimated_duration": 3600.1153383864025,
    "input_throughput": 6229.818739655275,
    "output_throughput": 5502.619815752629,
    "total_throughput": 11732.438555407904,
    "itl": 154.5072947662991,
    "ttft": 1988643.1242419188,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 582,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9265762324258726,
    "arrivals": 659440,
    "finished_requests": 90538,
    "scheduler_time": 168.4820999766235
}
#Debug simulation 
Total elapsed time: 76.26315765501931. Arrivals time: 0.4866398712620139 Scheduler time: 75.62478752341121 Scheduler overhead time: 0.055966432206332684 Adapter cache time: 0.018388955388218164 Engine time: 0.05577000929042697 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-16/adapters_320_slots_64_rate_1.6-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-16/adapters_320_slots_64_rate_1.6-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 135, 17280, 17280, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 17280, 17280, 1080, 135, 135, 1080, 17280, 17280, 1080, 1080, 135, 135, 1080, 17280, 17280, 135, 17280, 1080, 135, 1080, 17280, 135, 1080, 17280, 17280, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 17280, 1080, 17280, 17280, 135, 17280, 135, 17280, 1080, 135, 135, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 135, 1080, 1080, 135, 17280, 1080, 17280, 17280, 1080, 135, 1080, 1080, 1080, 135, 17280, 1080, 17280, 135, 17280, 135, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 17280, 135, 135, 135, 135, 17280, 1080, 1080, 17280, 1080, 1080, 135, 1080, 17280, 1080, 135, 135, 1080, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 1080, 17280, 1080, 1080, 1080, 135, 17280, 135, 17280, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 135, 135, 17280, 1080, 17280, 1080, 17280, 1080, 135, 1080, 135, 135, 135, 17280, 17280, 1080, 1080, 135, 135, 1080, 135, 17280, 135, 135, 1080, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 1080, 17280, 1080, 135, 1080, 135, 17280, 1080, 1080, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 1080, 1080, 17280, 135, 17280, 135, 135, 135, 17280, 1080, 17280, 17280, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 17280, 135, 135, 1080, 135, 1080, 1080, 135, 17280, 17280, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1978830 . Total input tokens: 440734472 . Total output tokens: 396088724
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 76.7085077650845,
    "estimated_duration": 3600.161465717467,
    "input_throughput": 6220.48350143568,
    "output_throughput": 5492.242830853004,
    "total_throughput": 11712.726332288685,
    "itl": 154.0412954242466,
    "ttft": 1987695.4661669692,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 583,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7431993219279434,
    "arrivals": 659440,
    "finished_requests": 90379,
    "scheduler_time": 169.08182165238375
}
#Debug simulation 
Total elapsed time: 76.70866954792291. Arrivals time: 0.46231019450351596 Scheduler time: 76.09504850022495 Scheduler overhead time: 0.05626250058412552 Adapter cache time: 0.017998058814555407 Engine time: 0.05542887467890978 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-32/adapters_320_slots_64_rate_1.6-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-32/adapters_320_slots_64_rate_1.6-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 135, 17280, 17280, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 17280, 17280, 1080, 135, 135, 1080, 17280, 17280, 1080, 1080, 135, 135, 1080, 17280, 17280, 135, 17280, 1080, 135, 1080, 17280, 135, 1080, 17280, 17280, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 17280, 1080, 17280, 17280, 135, 17280, 135, 17280, 1080, 135, 135, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 135, 1080, 1080, 135, 17280, 1080, 17280, 17280, 1080, 135, 1080, 1080, 1080, 135, 17280, 1080, 17280, 135, 17280, 135, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 1080, 135, 1080, 135, 17280, 135, 135, 135, 135, 17280, 1080, 1080, 17280, 1080, 1080, 135, 1080, 17280, 1080, 135, 135, 1080, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 1080, 17280, 1080, 1080, 1080, 135, 17280, 135, 17280, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 135, 135, 17280, 1080, 17280, 1080, 17280, 1080, 135, 1080, 135, 135, 135, 17280, 17280, 1080, 1080, 135, 135, 1080, 135, 17280, 135, 135, 1080, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 1080, 17280, 1080, 135, 1080, 135, 17280, 1080, 1080, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 1080, 135, 1080, 135, 1080, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 1080, 1080, 17280, 135, 17280, 135, 135, 135, 17280, 1080, 17280, 17280, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 17280, 135, 135, 1080, 135, 1080, 1080, 135, 17280, 17280, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1978830 . Total input tokens: 440734472 . Total output tokens: 396088724
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 76.15502529405057,
    "estimated_duration": 3600.141651672736,
    "input_throughput": 6229.773206167939,
    "output_throughput": 5502.579597332132,
    "total_throughput": 11732.35280350007,
    "itl": 154.50830924632095,
    "ttft": 1988653.2702194,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 582,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.950972466990347,
    "arrivals": 659440,
    "finished_requests": 90538,
    "scheduler_time": 168.48248541117363
}
#Debug simulation 
Total elapsed time: 76.155187190976. Arrivals time: 0.4584686397574842 Scheduler time: 75.5439647459425 Scheduler overhead time: 0.05679508578032255 Adapter cache time: 0.01831775764003396 Engine time: 0.055889510083943605 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-8/adapters_320_slots_64_rate_1.6-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-8/adapters_320_slots_64_rate_1.6-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 66, 17280, 17280, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 17280, 17280, 1080, 66, 66, 1080, 17280, 17280, 1080, 1080, 66, 66, 1080, 17280, 17280, 66, 17280, 1080, 66, 1080, 17280, 66, 1080, 17280, 17280, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 17280, 1080, 17280, 17280, 66, 17280, 66, 17280, 1080, 66, 66, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 66, 1080, 1080, 66, 17280, 1080, 17280, 17280, 1080, 66, 1080, 1080, 1080, 66, 17280, 1080, 17280, 66, 17280, 66, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 17280, 66, 66, 66, 66, 17280, 1080, 1080, 17280, 1080, 1080, 66, 1080, 17280, 1080, 66, 66, 1080, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 1080, 17280, 1080, 1080, 1080, 66, 17280, 66, 17280, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 66, 66, 17280, 1080, 17280, 1080, 17280, 1080, 66, 1080, 66, 66, 66, 17280, 17280, 1080, 1080, 66, 66, 1080, 66, 17280, 66, 66, 1080, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 1080, 1080, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 1080, 1080, 17280, 66, 17280, 66, 66, 66, 17280, 1080, 17280, 17280, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 17280, 66, 66, 1080, 66, 1080, 1080, 66, 17280, 17280, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1971516 . Total input tokens: 439087091 . Total output tokens: 394634127
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 80.95354293799028,
    "estimated_duration": 3600.082589246496,
    "input_throughput": 6211.846935622844,
    "output_throughput": 5489.1437932639465,
    "total_throughput": 11700.99072888679,
    "itl": 153.73332512197243,
    "ttft": 1980903.7623143997,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 520,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5914536268450512,
    "arrivals": 657053,
    "finished_requests": 90432,
    "scheduler_time": 169.19297473580085
}
#Debug simulation 
Total elapsed time: 80.95370956882834. Arrivals time: 0.4615564038977027 Scheduler time: 80.3379235281609 Scheduler overhead time: 0.057773951441049576 Adapter cache time: 0.017846707720309496 Engine time: 0.05694785714149475 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-16/adapters_320_slots_64_rate_1.6-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-16/adapters_320_slots_64_rate_1.6-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 66, 17280, 17280, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 17280, 17280, 1080, 66, 66, 1080, 17280, 17280, 1080, 1080, 66, 66, 1080, 17280, 17280, 66, 17280, 1080, 66, 1080, 17280, 66, 1080, 17280, 17280, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 17280, 1080, 17280, 17280, 66, 17280, 66, 17280, 1080, 66, 66, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 66, 1080, 1080, 66, 17280, 1080, 17280, 17280, 1080, 66, 1080, 1080, 1080, 66, 17280, 1080, 17280, 66, 17280, 66, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 17280, 66, 66, 66, 66, 17280, 1080, 1080, 17280, 1080, 1080, 66, 1080, 17280, 1080, 66, 66, 1080, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 1080, 17280, 1080, 1080, 1080, 66, 17280, 66, 17280, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 66, 66, 17280, 1080, 17280, 1080, 17280, 1080, 66, 1080, 66, 66, 66, 17280, 17280, 1080, 1080, 66, 66, 1080, 66, 17280, 66, 66, 1080, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 1080, 1080, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 1080, 1080, 17280, 66, 17280, 66, 66, 66, 17280, 1080, 17280, 17280, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 17280, 66, 66, 1080, 66, 1080, 1080, 66, 17280, 17280, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1971516 . Total input tokens: 439087091 . Total output tokens: 394634127
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 82.34159592119977,
    "estimated_duration": 3600.0478397213446,
    "input_throughput": 6209.546093623668,
    "output_throughput": 5486.815142303479,
    "total_throughput": 11696.361235927146,
    "itl": 153.6150613668127,
    "ttft": 1980437.5215764826,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 496,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.619944377949002,
    "arrivals": 657053,
    "finished_requests": 90386,
    "scheduler_time": 169.22911472148022
}
#Debug simulation 
Total elapsed time: 82.34175747120753. Arrivals time: 0.4508696380071342 Scheduler time: 81.73545369692147 Scheduler overhead time: 0.05871307710185647 Adapter cache time: 0.017552481032907963 Engine time: 0.05695358943194151 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-32/adapters_320_slots_64_rate_1.6-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-32/adapters_320_slots_64_rate_1.6-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 66, 17280, 17280, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 17280, 17280, 1080, 66, 66, 1080, 17280, 17280, 1080, 1080, 66, 66, 1080, 17280, 17280, 66, 17280, 1080, 66, 1080, 17280, 66, 1080, 17280, 17280, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 17280, 1080, 17280, 17280, 66, 17280, 66, 17280, 1080, 66, 66, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 66, 1080, 1080, 66, 17280, 1080, 17280, 17280, 1080, 66, 1080, 1080, 1080, 66, 17280, 1080, 17280, 66, 17280, 66, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 17280, 66, 66, 66, 66, 17280, 1080, 1080, 17280, 1080, 1080, 66, 1080, 17280, 1080, 66, 66, 1080, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 1080, 17280, 1080, 1080, 1080, 66, 17280, 66, 17280, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 66, 66, 17280, 1080, 17280, 1080, 17280, 1080, 66, 1080, 66, 66, 66, 17280, 17280, 1080, 1080, 66, 66, 1080, 66, 17280, 66, 66, 1080, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 1080, 1080, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 1080, 1080, 17280, 66, 17280, 66, 66, 66, 17280, 1080, 17280, 17280, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 17280, 66, 66, 1080, 66, 1080, 1080, 66, 17280, 17280, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1971516 . Total input tokens: 439087091 . Total output tokens: 394634127
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 82.60146237816662,
    "estimated_duration": 3600.0522090695795,
    "input_throughput": 6209.53855715817,
    "output_throughput": 5486.808483009484,
    "total_throughput": 11696.347040167653,
    "itl": 153.61519798446642,
    "ttft": 1980439.682200628,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 496,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6225632596574822,
    "arrivals": 657053,
    "finished_requests": 90386,
    "scheduler_time": 169.22919433278028
}
#Debug simulation 
Total elapsed time: 82.6016283039935. Arrivals time: 0.48859993321821094 Scheduler time: 81.95796659542248 Scheduler overhead time: 0.05831891531124711 Adapter cache time: 0.01726000616326928 Engine time: 0.057566927280277014 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-16/adapters_320_slots_64_rate_1.6-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-16/adapters_320_slots_64_rate_1.6-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 66, 17280, 17280, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 17280, 17280, 1080, 66, 66, 1080, 17280, 17280, 1080, 1080, 66, 66, 1080, 17280, 17280, 66, 17280, 1080, 66, 1080, 17280, 66, 1080, 17280, 17280, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 17280, 1080, 17280, 17280, 66, 17280, 66, 17280, 1080, 66, 66, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 66, 1080, 1080, 66, 17280, 1080, 17280, 17280, 1080, 66, 1080, 1080, 1080, 66, 17280, 1080, 17280, 66, 17280, 66, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 17280, 66, 66, 66, 66, 17280, 1080, 1080, 17280, 1080, 1080, 66, 1080, 17280, 1080, 66, 66, 1080, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 1080, 17280, 1080, 1080, 1080, 66, 17280, 66, 17280, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 66, 66, 17280, 1080, 17280, 1080, 17280, 1080, 66, 1080, 66, 66, 66, 17280, 17280, 1080, 1080, 66, 66, 1080, 66, 17280, 66, 66, 1080, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 1080, 1080, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 1080, 1080, 17280, 66, 17280, 66, 66, 66, 17280, 1080, 17280, 17280, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 17280, 66, 66, 1080, 66, 1080, 1080, 66, 17280, 17280, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1971516 . Total input tokens: 439087091 . Total output tokens: 394634127
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 82.62613037368283,
    "estimated_duration": 3600.150245613656,
    "input_throughput": 6209.488069904013,
    "output_throughput": 5487.025444026393,
    "total_throughput": 11696.513513930407,
    "itl": 153.614049614906,
    "ttft": 1980449.0234786004,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 496,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5525261504063335,
    "arrivals": 657053,
    "finished_requests": 90391,
    "scheduler_time": 169.23655722659498
}
#Debug simulation 
Total elapsed time: 82.62629518378526. Arrivals time: 0.47154138004407287 Scheduler time: 81.99948924360797 Scheduler overhead time: 0.05931722233071923 Adapter cache time: 0.017016939353197813 Engine time: 0.05720722349360585 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-32/adapters_320_slots_64_rate_1.6-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-32/adapters_320_slots_64_rate_1.6-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 66, 17280, 17280, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 17280, 17280, 1080, 66, 66, 1080, 17280, 17280, 1080, 1080, 66, 66, 1080, 17280, 17280, 66, 17280, 1080, 66, 1080, 17280, 66, 1080, 17280, 17280, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 17280, 1080, 17280, 17280, 66, 17280, 66, 17280, 1080, 66, 66, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 66, 1080, 1080, 66, 17280, 1080, 17280, 17280, 1080, 66, 1080, 1080, 1080, 66, 17280, 1080, 17280, 66, 17280, 66, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 17280, 66, 66, 66, 66, 17280, 1080, 1080, 17280, 1080, 1080, 66, 1080, 17280, 1080, 66, 66, 1080, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 1080, 17280, 1080, 1080, 1080, 66, 17280, 66, 17280, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 66, 66, 17280, 1080, 17280, 1080, 17280, 1080, 66, 1080, 66, 66, 66, 17280, 17280, 1080, 1080, 66, 66, 1080, 66, 17280, 66, 66, 1080, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 1080, 1080, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 1080, 1080, 17280, 66, 17280, 66, 66, 66, 17280, 1080, 17280, 17280, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 17280, 66, 66, 1080, 66, 1080, 1080, 66, 17280, 17280, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1971516 . Total input tokens: 439087091 . Total output tokens: 394634127
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 79.63145158812404,
    "estimated_duration": 3600.127144206367,
    "input_throughput": 6222.869943927682,
    "output_throughput": 5496.223663056762,
    "total_throughput": 11719.093606984445,
    "itl": 153.82864728076416,
    "ttft": 1982869.4085134566,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 530,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7554692580178426,
    "arrivals": 657053,
    "finished_requests": 90611,
    "scheduler_time": 168.99030660994043
}
#Debug simulation 
Total elapsed time: 79.63161422125995. Arrivals time: 0.4645667439326644 Scheduler time: 79.01471498934552 Scheduler overhead time: 0.057106921914964914 Adapter cache time: 0.017639716155827045 Engine time: 0.05602036835625768 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-16/adapters_320_slots_64_rate_1.6-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-16/adapters_320_slots_64_rate_1.6-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 66, 17280, 17280, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 17280, 17280, 1080, 66, 66, 1080, 17280, 17280, 1080, 1080, 66, 66, 1080, 17280, 17280, 66, 17280, 1080, 66, 1080, 17280, 66, 1080, 17280, 17280, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 17280, 1080, 17280, 17280, 66, 17280, 66, 17280, 1080, 66, 66, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 66, 1080, 1080, 66, 17280, 1080, 17280, 17280, 1080, 66, 1080, 1080, 1080, 66, 17280, 1080, 17280, 66, 17280, 66, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 17280, 66, 66, 66, 66, 17280, 1080, 1080, 17280, 1080, 1080, 66, 1080, 17280, 1080, 66, 66, 1080, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 1080, 17280, 1080, 1080, 1080, 66, 17280, 66, 17280, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 66, 66, 17280, 1080, 17280, 1080, 17280, 1080, 66, 1080, 66, 66, 66, 17280, 17280, 1080, 1080, 66, 66, 1080, 66, 17280, 66, 66, 1080, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 1080, 1080, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 1080, 1080, 17280, 66, 17280, 66, 66, 66, 17280, 1080, 17280, 17280, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 17280, 66, 66, 1080, 66, 1080, 1080, 66, 17280, 17280, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1971516 . Total input tokens: 439087091 . Total output tokens: 394634127
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 81.17472355626523,
    "estimated_duration": 3600.047228528524,
    "input_throughput": 6211.907950202273,
    "output_throughput": 5489.197709241504,
    "total_throughput": 11701.105659443778,
    "itl": 153.73225638282838,
    "ttft": 1980892.4219902412,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 520,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.554826153349113,
    "arrivals": 657053,
    "finished_requests": 90432,
    "scheduler_time": 169.1927837116375
}
#Debug simulation 
Total elapsed time: 81.17488054698333. Arrivals time: 0.4659510157071054 Scheduler time: 80.5543894758448 Scheduler overhead time: 0.057879111263900995 Adapter cache time: 0.017598489299416542 Engine time: 0.05708889337256551 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-32/adapters_320_slots_64_rate_1.6-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-32/adapters_320_slots_64_rate_1.6-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 66, 17280, 17280, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 17280, 17280, 1080, 66, 66, 1080, 17280, 17280, 1080, 1080, 66, 66, 1080, 17280, 17280, 66, 17280, 1080, 66, 1080, 17280, 66, 1080, 17280, 17280, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 17280, 1080, 17280, 17280, 66, 17280, 66, 17280, 1080, 66, 66, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 66, 1080, 1080, 66, 17280, 1080, 17280, 17280, 1080, 66, 1080, 1080, 1080, 66, 17280, 1080, 17280, 66, 17280, 66, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 1080, 66, 1080, 66, 17280, 66, 66, 66, 66, 17280, 1080, 1080, 17280, 1080, 1080, 66, 1080, 17280, 1080, 66, 66, 1080, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 1080, 17280, 1080, 1080, 1080, 66, 17280, 66, 17280, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 66, 66, 17280, 1080, 17280, 1080, 17280, 1080, 66, 1080, 66, 66, 66, 17280, 17280, 1080, 1080, 66, 66, 1080, 66, 17280, 66, 66, 1080, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 1080, 1080, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 1080, 66, 1080, 66, 1080, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 1080, 1080, 17280, 66, 17280, 66, 66, 66, 17280, 1080, 17280, 17280, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 17280, 66, 66, 1080, 66, 1080, 1080, 66, 17280, 17280, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1971516 . Total input tokens: 439087091 . Total output tokens: 394634127
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 81.0857056081295,
    "estimated_duration": 3600.097625190803,
    "input_throughput": 6205.8044880979905,
    "output_throughput": 5487.092867086639,
    "total_throughput": 11692.897355184628,
    "itl": 153.65341057166003,
    "ttft": 1980914.6395478402,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 506,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6965149704366902,
    "arrivals": 657053,
    "finished_requests": 90393,
    "scheduler_time": 169.2357708726528
}
#Debug simulation 
Total elapsed time: 81.08587051136419. Arrivals time: 0.505150608252734 Scheduler time: 80.42639526678249 Scheduler overhead time: 0.05808868259191513 Adapter cache time: 0.017723657190799713 Engine time: 0.05668878508731723 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-8/adapters_320_slots_64_rate_1.6-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-8/adapters_320_slots_64_rate_1.6-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 33, 17280, 17280, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 17280, 17280, 1080, 33, 33, 1080, 17280, 17280, 1080, 1080, 33, 33, 1080, 17280, 17280, 33, 17280, 1080, 33, 1080, 17280, 33, 1080, 17280, 17280, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 17280, 1080, 17280, 17280, 33, 17280, 33, 17280, 1080, 33, 33, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 33, 1080, 1080, 33, 17280, 1080, 17280, 17280, 1080, 33, 1080, 1080, 1080, 33, 17280, 1080, 17280, 33, 17280, 33, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 17280, 33, 33, 33, 33, 17280, 1080, 1080, 17280, 1080, 1080, 33, 1080, 17280, 1080, 33, 33, 1080, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 1080, 17280, 1080, 1080, 1080, 33, 17280, 33, 17280, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 33, 33, 17280, 1080, 17280, 1080, 17280, 1080, 33, 1080, 33, 33, 33, 17280, 17280, 1080, 1080, 33, 33, 1080, 33, 17280, 33, 33, 1080, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 1080, 1080, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 1080, 1080, 17280, 33, 17280, 33, 33, 33, 17280, 1080, 17280, 17280, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 17280, 33, 33, 1080, 33, 1080, 1080, 33, 17280, 17280, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1968018 . Total input tokens: 438292478 . Total output tokens: 393947046
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 73.7455921350047,
    "estimated_duration": 3600.015590745209,
    "input_throughput": 6246.453781425176,
    "output_throughput": 5519.449985461551,
    "total_throughput": 11765.903766886728,
    "itl": 155.49986630364208,
    "ttft": 1985899.7962679225,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 516,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5792116758693198,
    "arrivals": 655825,
    "finished_requests": 90681,
    "scheduler_time": 167.6939132551944
}
#Debug simulation 
Total elapsed time: 73.74575391691178. Arrivals time: 0.4455808945931494 Scheduler time: 73.15228269482031 Scheduler overhead time: 0.05493352469056845 Adapter cache time: 0.016579156275838614 Engine time: 0.05466884979978204 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-16/adapters_320_slots_64_rate_1.6-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-16/adapters_320_slots_64_rate_1.6-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 33, 17280, 17280, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 17280, 17280, 1080, 33, 33, 1080, 17280, 17280, 1080, 1080, 33, 33, 1080, 17280, 17280, 33, 17280, 1080, 33, 1080, 17280, 33, 1080, 17280, 17280, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 17280, 1080, 17280, 17280, 33, 17280, 33, 17280, 1080, 33, 33, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 33, 1080, 1080, 33, 17280, 1080, 17280, 17280, 1080, 33, 1080, 1080, 1080, 33, 17280, 1080, 17280, 33, 17280, 33, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 17280, 33, 33, 33, 33, 17280, 1080, 1080, 17280, 1080, 1080, 33, 1080, 17280, 1080, 33, 33, 1080, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 1080, 17280, 1080, 1080, 1080, 33, 17280, 33, 17280, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 33, 33, 17280, 1080, 17280, 1080, 17280, 1080, 33, 1080, 33, 33, 33, 17280, 17280, 1080, 1080, 33, 33, 1080, 33, 17280, 33, 33, 1080, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 1080, 1080, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 1080, 1080, 17280, 33, 17280, 33, 33, 33, 17280, 1080, 17280, 17280, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 17280, 33, 33, 1080, 33, 1080, 1080, 33, 17280, 17280, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1968018 . Total input tokens: 438292478 . Total output tokens: 393947046
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 73.85861382307485,
    "estimated_duration": 3600.0827591718,
    "input_throughput": 6250.502420443431,
    "output_throughput": 5515.653202530284,
    "total_throughput": 11766.155622973716,
    "itl": 155.3848681808718,
    "ttft": 1986263.3517163987,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 532,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7337151183420834,
    "arrivals": 655825,
    "finished_requests": 90713,
    "scheduler_time": 167.7193184080052
}
#Debug simulation 
Total elapsed time: 73.85878107277676. Arrivals time: 0.49610637314617634 Scheduler time: 73.21285491855815 Scheduler overhead time: 0.055485821794718504 Adapter cache time: 0.017389755230396986 Engine time: 0.05558797065168619 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-32/adapters_320_slots_64_rate_1.6-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-32/adapters_320_slots_64_rate_1.6-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 33, 17280, 17280, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 17280, 17280, 1080, 33, 33, 1080, 17280, 17280, 1080, 1080, 33, 33, 1080, 17280, 17280, 33, 17280, 1080, 33, 1080, 17280, 33, 1080, 17280, 17280, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 17280, 1080, 17280, 17280, 33, 17280, 33, 17280, 1080, 33, 33, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 33, 1080, 1080, 33, 17280, 1080, 17280, 17280, 1080, 33, 1080, 1080, 1080, 33, 17280, 1080, 17280, 33, 17280, 33, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 17280, 33, 33, 33, 33, 17280, 1080, 1080, 17280, 1080, 1080, 33, 1080, 17280, 1080, 33, 33, 1080, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 1080, 17280, 1080, 1080, 1080, 33, 17280, 33, 17280, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 33, 33, 17280, 1080, 17280, 1080, 17280, 1080, 33, 1080, 33, 33, 33, 17280, 17280, 1080, 1080, 33, 33, 1080, 33, 17280, 33, 33, 1080, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 1080, 1080, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 1080, 1080, 17280, 33, 17280, 33, 33, 33, 17280, 1080, 17280, 17280, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 17280, 33, 33, 1080, 33, 1080, 1080, 33, 17280, 17280, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1968018 . Total input tokens: 438292478 . Total output tokens: 393947046
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 73.99335128813982,
    "estimated_duration": 3600.086256313108,
    "input_throughput": 6250.496348674963,
    "output_throughput": 5515.647844597923,
    "total_throughput": 11766.144193272887,
    "itl": 155.3849984774878,
    "ttft": 1986264.5030412385,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 532,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.737188650630425,
    "arrivals": 655825,
    "finished_requests": 90713,
    "scheduler_time": 167.7193420170001
}
#Debug simulation 
Total elapsed time: 73.99351144907996. Arrivals time: 0.4522142903879285 Scheduler time: 73.392379084602 Scheduler overhead time: 0.055687465239316225 Adapter cache time: 0.01700370153412223 Engine time: 0.05504225846379995 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-16/adapters_320_slots_64_rate_1.6-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-16/adapters_320_slots_64_rate_1.6-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 33, 17280, 17280, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 17280, 17280, 1080, 33, 33, 1080, 17280, 17280, 1080, 1080, 33, 33, 1080, 17280, 17280, 33, 17280, 1080, 33, 1080, 17280, 33, 1080, 17280, 17280, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 17280, 1080, 17280, 17280, 33, 17280, 33, 17280, 1080, 33, 33, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 33, 1080, 1080, 33, 17280, 1080, 17280, 17280, 1080, 33, 1080, 1080, 1080, 33, 17280, 1080, 17280, 33, 17280, 33, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 17280, 33, 33, 33, 33, 17280, 1080, 1080, 17280, 1080, 1080, 33, 1080, 17280, 1080, 33, 33, 1080, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 1080, 17280, 1080, 1080, 1080, 33, 17280, 33, 17280, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 33, 33, 17280, 1080, 17280, 1080, 17280, 1080, 33, 1080, 33, 33, 33, 17280, 17280, 1080, 1080, 33, 33, 1080, 33, 17280, 33, 33, 1080, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 1080, 1080, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 1080, 1080, 17280, 33, 17280, 33, 33, 33, 17280, 1080, 17280, 17280, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 17280, 33, 33, 1080, 33, 1080, 1080, 33, 17280, 17280, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1968018 . Total input tokens: 438292478 . Total output tokens: 393947046
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 73.78170310892165,
    "estimated_duration": 3600.023666197576,
    "input_throughput": 6249.75335891728,
    "output_throughput": 5515.607351818517,
    "total_throughput": 11765.360710735797,
    "itl": 155.37982521432968,
    "ttft": 1986497.806017822,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 543,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.699187444043337,
    "arrivals": 655825,
    "finished_requests": 90711,
    "scheduler_time": 167.7149305231798
}
#Debug simulation 
Total elapsed time: 73.78187243361026. Arrivals time: 0.48605579044669867 Scheduler time: 73.1468534944579 Scheduler overhead time: 0.055145115591585636 Adapter cache time: 0.01736224675551057 Engine time: 0.05493866605684161 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-32/adapters_320_slots_64_rate_1.6-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-32/adapters_320_slots_64_rate_1.6-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 33, 17280, 17280, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 17280, 17280, 1080, 33, 33, 1080, 17280, 17280, 1080, 1080, 33, 33, 1080, 17280, 17280, 33, 17280, 1080, 33, 1080, 17280, 33, 1080, 17280, 17280, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 17280, 1080, 17280, 17280, 33, 17280, 33, 17280, 1080, 33, 33, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 33, 1080, 1080, 33, 17280, 1080, 17280, 17280, 1080, 33, 1080, 1080, 1080, 33, 17280, 1080, 17280, 33, 17280, 33, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 17280, 33, 33, 33, 33, 17280, 1080, 1080, 17280, 1080, 1080, 33, 1080, 17280, 1080, 33, 33, 1080, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 1080, 17280, 1080, 1080, 1080, 33, 17280, 33, 17280, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 33, 33, 17280, 1080, 17280, 1080, 17280, 1080, 33, 1080, 33, 33, 33, 17280, 17280, 1080, 1080, 33, 33, 1080, 33, 17280, 33, 33, 1080, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 1080, 1080, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 1080, 1080, 17280, 33, 17280, 33, 33, 33, 17280, 1080, 17280, 17280, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 17280, 33, 33, 1080, 33, 1080, 1080, 33, 17280, 17280, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1968018 . Total input tokens: 438292478 . Total output tokens: 393947046
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 71.96563433716074,
    "estimated_duration": 3600.0417537956164,
    "input_throughput": 6246.909768835078,
    "output_throughput": 5519.209042242691,
    "total_throughput": 11766.118811077768,
    "itl": 155.49436957302348,
    "ttft": 1986712.7794901235,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 539,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.783409668859099,
    "arrivals": 655825,
    "finished_requests": 90682,
    "scheduler_time": 167.68796431250132
}
#Debug simulation 
Total elapsed time: 71.96586833195761. Arrivals time: 0.45833462895825505 Scheduler time: 71.35799687774852 Scheduler overhead time: 0.05580882355570793 Adapter cache time: 0.017106507904827595 Engine time: 0.054886740166693926 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-16/adapters_320_slots_64_rate_1.6-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-16/adapters_320_slots_64_rate_1.6-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 33, 17280, 17280, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 17280, 17280, 1080, 33, 33, 1080, 17280, 17280, 1080, 1080, 33, 33, 1080, 17280, 17280, 33, 17280, 1080, 33, 1080, 17280, 33, 1080, 17280, 17280, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 17280, 1080, 17280, 17280, 33, 17280, 33, 17280, 1080, 33, 33, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 33, 1080, 1080, 33, 17280, 1080, 17280, 17280, 1080, 33, 1080, 1080, 1080, 33, 17280, 1080, 17280, 33, 17280, 33, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 17280, 33, 33, 33, 33, 17280, 1080, 1080, 17280, 1080, 1080, 33, 1080, 17280, 1080, 33, 33, 1080, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 1080, 17280, 1080, 1080, 1080, 33, 17280, 33, 17280, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 33, 33, 17280, 1080, 17280, 1080, 17280, 1080, 33, 1080, 33, 33, 33, 17280, 17280, 1080, 1080, 33, 33, 1080, 33, 17280, 33, 33, 1080, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 1080, 1080, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 1080, 1080, 17280, 33, 17280, 33, 33, 33, 17280, 1080, 17280, 17280, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 17280, 33, 33, 1080, 33, 1080, 1080, 33, 17280, 17280, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1968018 . Total input tokens: 438292478 . Total output tokens: 393947046
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 73.94337747199461,
    "estimated_duration": 3600.0822951178106,
    "input_throughput": 6246.139159233897,
    "output_throughput": 5519.4916035522865,
    "total_throughput": 11765.630762786182,
    "itl": 155.50441131326755,
    "ttft": 1985901.7709438438,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 516,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5428659521695047,
    "arrivals": 655825,
    "finished_requests": 90680,
    "scheduler_time": 167.69658656318407
}
#Debug simulation 
Total elapsed time: 73.94353814283386. Arrivals time: 0.4977510957978666 Scheduler time: 73.29771308461204 Scheduler overhead time: 0.05561854178085923 Adapter cache time: 0.016630114521831274 Engine time: 0.05484703555703163 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-32/adapters_320_slots_64_rate_1.6-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-32/adapters_320_slots_64_rate_1.6-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [106 107 107]
Adapter prompts. [1080, 17280, 17280, 33, 17280, 17280, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 17280, 17280, 1080, 33, 33, 1080, 17280, 17280, 1080, 1080, 33, 33, 1080, 17280, 17280, 33, 17280, 1080, 33, 1080, 17280, 33, 1080, 17280, 17280, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 17280, 1080, 17280, 17280, 33, 17280, 33, 17280, 1080, 33, 33, 1080, 1080, 17280, 1080, 17280, 17280, 17280, 33, 1080, 1080, 33, 17280, 1080, 17280, 17280, 1080, 33, 1080, 1080, 1080, 33, 17280, 1080, 17280, 33, 17280, 33, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 1080, 33, 1080, 33, 17280, 33, 33, 33, 33, 17280, 1080, 1080, 17280, 1080, 1080, 33, 1080, 17280, 1080, 33, 33, 1080, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 1080, 17280, 1080, 1080, 1080, 33, 17280, 33, 17280, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 33, 33, 17280, 1080, 17280, 1080, 17280, 1080, 33, 1080, 33, 33, 33, 17280, 17280, 1080, 1080, 33, 33, 1080, 33, 17280, 33, 33, 1080, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 1080, 1080, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 1080, 33, 1080, 33, 1080, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 1080, 1080, 17280, 33, 17280, 33, 33, 33, 17280, 1080, 17280, 17280, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 17280, 33, 33, 1080, 33, 1080, 1080, 33, 17280, 17280, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1968018 . Total input tokens: 438292478 . Total output tokens: 393947046
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 72.0391227370128,
    "estimated_duration": 3600.0663356841756,
    "input_throughput": 6246.867113832236,
    "output_throughput": 5519.171356108892,
    "total_throughput": 11766.038469941128,
    "itl": 155.49503014875773,
    "ttft": 1986721.8177655833,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 539,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8066741193458409,
    "arrivals": 655825,
    "finished_requests": 90682,
    "scheduler_time": 167.68816689850883
}
#Debug simulation 
Total elapsed time: 72.03935071779415. Arrivals time: 0.4493367774412036 Scheduler time: 71.44078033044934 Scheduler overhead time: 0.05603382084518671 Adapter cache time: 0.016946523915976286 Engine time: 0.054912710562348366 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-8/adapters_320_slots_64_rate_1.6-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-8/adapters_320_slots_64_rate_1.6-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 270, 17280, 17280, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 17280, 17280, 540, 270, 270, 540, 17280, 17280, 540, 540, 270, 270, 540, 17280, 17280, 270, 17280, 540, 270, 540, 17280, 270, 540, 17280, 17280, 540, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 540, 540, 540, 270, 540, 270, 17280, 270, 17280, 540, 17280, 17280, 270, 17280, 270, 17280, 540, 270, 270, 540, 540, 17280, 540, 17280, 17280, 17280, 270, 540, 540, 270, 17280, 540, 17280, 17280, 540, 270, 540, 540, 540, 270, 17280, 540, 17280, 270, 17280, 270, 270, 540, 17280, 17280, 540, 270, 540, 270, 540, 17280, 17280, 540, 270, 540, 270, 17280, 270, 270, 270, 270, 17280, 540, 540, 17280, 540, 540, 270, 540, 17280, 540, 270, 270, 540, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 540, 17280, 540, 540, 540, 270, 17280, 270, 17280, 540, 270, 540, 270, 270, 540, 270, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 270, 270, 17280, 540, 17280, 540, 17280, 540, 270, 540, 270, 270, 270, 17280, 17280, 540, 540, 270, 270, 540, 270, 17280, 270, 270, 540, 270, 17280, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 270, 540, 17280, 540, 540, 17280, 540, 270, 540, 270, 17280, 540, 540, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 540, 270, 540, 270, 540, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 540, 540, 17280, 270, 17280, 270, 270, 270, 17280, 540, 17280, 17280, 270, 540, 540, 540, 270, 540, 270, 540, 540, 17280, 270, 270, 540, 270, 540, 540, 270, 17280, 17280, 17280, 270, 540, 540, 540, 540, 270, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 540, 540, 540, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1935360 . Total input tokens: 431032019 . Total output tokens: 387484439
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 74.93930985080078,
    "estimated_duration": 3600.125646593091,
    "input_throughput": 6275.2554265374665,
    "output_throughput": 5509.789364927125,
    "total_throughput": 11785.04479146459,
    "itl": 154.3159439567044,
    "ttft": 1982931.3765170192,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 625,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9128048399580015,
    "arrivals": 644956,
    "finished_requests": 91098,
    "scheduler_time": 167.9171805789538
}
#Debug simulation 
Total elapsed time: 74.93946540914476. Arrivals time: 0.46542290737852454 Scheduler time: 74.31960897054523 Scheduler overhead time: 0.05804271204397082 Adapter cache time: 0.01885451190173626 Engine time: 0.055955376010388136 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-16/adapters_320_slots_64_rate_1.6-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-16/adapters_320_slots_64_rate_1.6-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 270, 17280, 17280, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 17280, 17280, 540, 270, 270, 540, 17280, 17280, 540, 540, 270, 270, 540, 17280, 17280, 270, 17280, 540, 270, 540, 17280, 270, 540, 17280, 17280, 540, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 540, 540, 540, 270, 540, 270, 17280, 270, 17280, 540, 17280, 17280, 270, 17280, 270, 17280, 540, 270, 270, 540, 540, 17280, 540, 17280, 17280, 17280, 270, 540, 540, 270, 17280, 540, 17280, 17280, 540, 270, 540, 540, 540, 270, 17280, 540, 17280, 270, 17280, 270, 270, 540, 17280, 17280, 540, 270, 540, 270, 540, 17280, 17280, 540, 270, 540, 270, 17280, 270, 270, 270, 270, 17280, 540, 540, 17280, 540, 540, 270, 540, 17280, 540, 270, 270, 540, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 540, 17280, 540, 540, 540, 270, 17280, 270, 17280, 540, 270, 540, 270, 270, 540, 270, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 270, 270, 17280, 540, 17280, 540, 17280, 540, 270, 540, 270, 270, 270, 17280, 17280, 540, 540, 270, 270, 540, 270, 17280, 270, 270, 540, 270, 17280, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 270, 540, 17280, 540, 540, 17280, 540, 270, 540, 270, 17280, 540, 540, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 540, 270, 540, 270, 540, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 540, 540, 17280, 270, 17280, 270, 270, 270, 17280, 540, 17280, 17280, 270, 540, 540, 540, 270, 540, 270, 540, 540, 17280, 270, 270, 540, 270, 540, 540, 270, 17280, 17280, 17280, 270, 540, 540, 540, 540, 270, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 540, 540, 540, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1935360 . Total input tokens: 431032019 . Total output tokens: 387484439
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 77.30255015706643,
    "estimated_duration": 3600.111306271501,
    "input_throughput": 6263.042467804072,
    "output_throughput": 5499.111642885129,
    "total_throughput": 11762.1541106892,
    "itl": 153.73927901896127,
    "ttft": 1980810.9680677047,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 643,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0982983265514545,
    "arrivals": 644956,
    "finished_requests": 90890,
    "scheduler_time": 168.59363978235103
}
#Debug simulation 
Total elapsed time: 77.30270951520652. Arrivals time: 0.46972331404685974 Scheduler time: 76.67873935261741 Scheduler overhead time: 0.05721571994945407 Adapter cache time: 0.01922359224408865 Engine time: 0.05632189940661192 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-32/adapters_320_slots_64_rate_1.6-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-32/adapters_320_slots_64_rate_1.6-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 270, 17280, 17280, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 17280, 17280, 540, 270, 270, 540, 17280, 17280, 540, 540, 270, 270, 540, 17280, 17280, 270, 17280, 540, 270, 540, 17280, 270, 540, 17280, 17280, 540, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 540, 540, 540, 270, 540, 270, 17280, 270, 17280, 540, 17280, 17280, 270, 17280, 270, 17280, 540, 270, 270, 540, 540, 17280, 540, 17280, 17280, 17280, 270, 540, 540, 270, 17280, 540, 17280, 17280, 540, 270, 540, 540, 540, 270, 17280, 540, 17280, 270, 17280, 270, 270, 540, 17280, 17280, 540, 270, 540, 270, 540, 17280, 17280, 540, 270, 540, 270, 17280, 270, 270, 270, 270, 17280, 540, 540, 17280, 540, 540, 270, 540, 17280, 540, 270, 270, 540, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 540, 17280, 540, 540, 540, 270, 17280, 270, 17280, 540, 270, 540, 270, 270, 540, 270, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 270, 270, 17280, 540, 17280, 540, 17280, 540, 270, 540, 270, 270, 270, 17280, 17280, 540, 540, 270, 270, 540, 270, 17280, 270, 270, 540, 270, 17280, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 270, 540, 17280, 540, 540, 17280, 540, 270, 540, 270, 17280, 540, 540, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 540, 270, 540, 270, 540, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 540, 540, 17280, 270, 17280, 270, 270, 270, 17280, 540, 17280, 17280, 270, 540, 540, 540, 270, 540, 270, 540, 540, 17280, 270, 270, 540, 270, 540, 540, 270, 17280, 17280, 17280, 270, 540, 540, 540, 540, 270, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 540, 540, 540, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1935360 . Total input tokens: 431032019 . Total output tokens: 387484439
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 77.5556080872193,
    "estimated_duration": 3600.114321647288,
    "input_throughput": 6263.03722201882,
    "output_throughput": 5499.107036951367,
    "total_throughput": 11762.144258970187,
    "itl": 153.73942568886633,
    "ttft": 1980811.6758262522,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 643,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.101999042406687,
    "arrivals": 644956,
    "finished_requests": 90890,
    "scheduler_time": 168.59365063191444
}
#Debug simulation 
Total elapsed time: 77.5557687790133. Arrivals time: 0.46496374206617475 Scheduler time: 76.93656879337505 Scheduler overhead time: 0.05727344937622547 Adapter cache time: 0.01923154341056943 Engine time: 0.0560019314289093 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-16-16/adapters_320_slots_64_rate_1.6-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-16-16/adapters_320_slots_64_rate_1.6-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 270, 17280, 17280, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 17280, 17280, 540, 270, 270, 540, 17280, 17280, 540, 540, 270, 270, 540, 17280, 17280, 270, 17280, 540, 270, 540, 17280, 270, 540, 17280, 17280, 540, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 540, 540, 540, 270, 540, 270, 17280, 270, 17280, 540, 17280, 17280, 270, 17280, 270, 17280, 540, 270, 270, 540, 540, 17280, 540, 17280, 17280, 17280, 270, 540, 540, 270, 17280, 540, 17280, 17280, 540, 270, 540, 540, 540, 270, 17280, 540, 17280, 270, 17280, 270, 270, 540, 17280, 17280, 540, 270, 540, 270, 540, 17280, 17280, 540, 270, 540, 270, 17280, 270, 270, 270, 270, 17280, 540, 540, 17280, 540, 540, 270, 540, 17280, 540, 270, 270, 540, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 540, 17280, 540, 540, 540, 270, 17280, 270, 17280, 540, 270, 540, 270, 270, 540, 270, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 270, 270, 17280, 540, 17280, 540, 17280, 540, 270, 540, 270, 270, 270, 17280, 17280, 540, 540, 270, 270, 540, 270, 17280, 270, 270, 540, 270, 17280, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 270, 540, 17280, 540, 540, 17280, 540, 270, 540, 270, 17280, 540, 540, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 540, 270, 540, 270, 540, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 540, 540, 17280, 270, 17280, 270, 270, 270, 17280, 540, 17280, 17280, 270, 540, 540, 540, 270, 540, 270, 540, 540, 17280, 270, 270, 540, 270, 540, 540, 270, 17280, 17280, 17280, 270, 540, 540, 540, 540, 270, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 540, 540, 540, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1935360 . Total input tokens: 431032019 . Total output tokens: 387484439
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 75.23133342619985,
    "estimated_duration": 3600.171305842358,
    "input_throughput": 6275.175840476862,
    "output_throughput": 5509.7194869061495,
    "total_throughput": 11784.895327383012,
    "itl": 154.31765081606608,
    "ttft": 1982946.3353748047,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 625,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9574466184154031,
    "arrivals": 644956,
    "finished_requests": 91098,
    "scheduler_time": 167.9174071905217
}
#Debug simulation 
Total elapsed time: 75.23150022141635. Arrivals time: 0.7671050769276917 Scheduler time: 74.30927441641688 Scheduler overhead time: 0.057984471786767244 Adapter cache time: 0.018958815839141607 Engine time: 0.056585478130728006 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-16-32/adapters_320_slots_64_rate_1.6-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-16-32/adapters_320_slots_64_rate_1.6-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 270, 17280, 17280, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 17280, 17280, 540, 270, 270, 540, 17280, 17280, 540, 540, 270, 270, 540, 17280, 17280, 270, 17280, 540, 270, 540, 17280, 270, 540, 17280, 17280, 540, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 540, 540, 540, 270, 540, 270, 17280, 270, 17280, 540, 17280, 17280, 270, 17280, 270, 17280, 540, 270, 270, 540, 540, 17280, 540, 17280, 17280, 17280, 270, 540, 540, 270, 17280, 540, 17280, 17280, 540, 270, 540, 540, 540, 270, 17280, 540, 17280, 270, 17280, 270, 270, 540, 17280, 17280, 540, 270, 540, 270, 540, 17280, 17280, 540, 270, 540, 270, 17280, 270, 270, 270, 270, 17280, 540, 540, 17280, 540, 540, 270, 540, 17280, 540, 270, 270, 540, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 540, 17280, 540, 540, 540, 270, 17280, 270, 17280, 540, 270, 540, 270, 270, 540, 270, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 270, 270, 17280, 540, 17280, 540, 17280, 540, 270, 540, 270, 270, 270, 17280, 17280, 540, 540, 270, 270, 540, 270, 17280, 270, 270, 540, 270, 17280, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 270, 540, 17280, 540, 540, 17280, 540, 270, 540, 270, 17280, 540, 540, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 540, 270, 540, 270, 540, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 540, 540, 17280, 270, 17280, 270, 270, 270, 17280, 540, 17280, 17280, 270, 540, 540, 540, 270, 540, 270, 540, 540, 17280, 270, 270, 540, 270, 540, 540, 270, 17280, 17280, 17280, 270, 540, 540, 540, 540, 270, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 540, 540, 540, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1935360 . Total input tokens: 431032019 . Total output tokens: 387484439
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 77.11818348709494,
    "estimated_duration": 3600.121265682844,
    "input_throughput": 6255.085686878593,
    "output_throughput": 5496.20180537084,
    "total_throughput": 11751.287492249432,
    "itl": 153.7061703082537,
    "ttft": 1980665.7801867193,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 600,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.984354785289619,
    "arrivals": 644956,
    "finished_requests": 90797,
    "scheduler_time": 168.7554174369348
}
#Debug simulation 
Total elapsed time: 77.11833415972069. Arrivals time: 0.4503091461956501 Scheduler time: 76.51630462985486 Scheduler overhead time: 0.05651027197018266 Adapter cache time: 0.018429502844810486 Engine time: 0.055602673441171646 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_16-16-16/adapters_320_slots_64_rate_1.6-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_16-16-16/adapters_320_slots_64_rate_1.6-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 270, 17280, 17280, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 17280, 17280, 540, 270, 270, 540, 17280, 17280, 540, 540, 270, 270, 540, 17280, 17280, 270, 17280, 540, 270, 540, 17280, 270, 540, 17280, 17280, 540, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 540, 540, 540, 270, 540, 270, 17280, 270, 17280, 540, 17280, 17280, 270, 17280, 270, 17280, 540, 270, 270, 540, 540, 17280, 540, 17280, 17280, 17280, 270, 540, 540, 270, 17280, 540, 17280, 17280, 540, 270, 540, 540, 540, 270, 17280, 540, 17280, 270, 17280, 270, 270, 540, 17280, 17280, 540, 270, 540, 270, 540, 17280, 17280, 540, 270, 540, 270, 17280, 270, 270, 270, 270, 17280, 540, 540, 17280, 540, 540, 270, 540, 17280, 540, 270, 270, 540, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 540, 17280, 540, 540, 540, 270, 17280, 270, 17280, 540, 270, 540, 270, 270, 540, 270, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 270, 270, 17280, 540, 17280, 540, 17280, 540, 270, 540, 270, 270, 270, 17280, 17280, 540, 540, 270, 270, 540, 270, 17280, 270, 270, 540, 270, 17280, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 270, 540, 17280, 540, 540, 17280, 540, 270, 540, 270, 17280, 540, 540, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 540, 270, 540, 270, 540, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 540, 540, 17280, 270, 17280, 270, 270, 270, 17280, 540, 17280, 17280, 270, 540, 540, 540, 270, 540, 270, 540, 540, 17280, 270, 270, 540, 270, 540, 540, 270, 17280, 17280, 17280, 270, 540, 540, 540, 540, 270, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 540, 540, 540, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1935360 . Total input tokens: 431032019 . Total output tokens: 387484439
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 75.09159694705158,
    "estimated_duration": 3600.0211218485947,
    "input_throughput": 6272.437642922719,
    "output_throughput": 5509.05156629081,
    "total_throughput": 11781.489209213529,
    "itl": 154.3154184599529,
    "ttft": 1983034.1179571615,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 625,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8687814343138303,
    "arrivals": 644956,
    "finished_requests": 91076,
    "scheduler_time": 167.9087206637108
}
#Debug simulation 
Total elapsed time: 75.09176095295697. Arrivals time: 0.459509652107954 Scheduler time: 74.47866200981662 Scheduler overhead time: 0.057514789048582315 Adapter cache time: 0.018841122277081013 Engine time: 0.05561325792223215 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_16-16-32/adapters_320_slots_64_rate_1.6-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_16-16-32/adapters_320_slots_64_rate_1.6-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 270, 17280, 17280, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 17280, 17280, 540, 270, 270, 540, 17280, 17280, 540, 540, 270, 270, 540, 17280, 17280, 270, 17280, 540, 270, 540, 17280, 270, 540, 17280, 17280, 540, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 540, 540, 540, 270, 540, 270, 17280, 270, 17280, 540, 17280, 17280, 270, 17280, 270, 17280, 540, 270, 270, 540, 540, 17280, 540, 17280, 17280, 17280, 270, 540, 540, 270, 17280, 540, 17280, 17280, 540, 270, 540, 540, 540, 270, 17280, 540, 17280, 270, 17280, 270, 270, 540, 17280, 17280, 540, 270, 540, 270, 540, 17280, 17280, 540, 270, 540, 270, 17280, 270, 270, 270, 270, 17280, 540, 540, 17280, 540, 540, 270, 540, 17280, 540, 270, 270, 540, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 540, 17280, 540, 540, 540, 270, 17280, 270, 17280, 540, 270, 540, 270, 270, 540, 270, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 270, 270, 17280, 540, 17280, 540, 17280, 540, 270, 540, 270, 270, 270, 17280, 17280, 540, 540, 270, 270, 540, 270, 17280, 270, 270, 540, 270, 17280, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 270, 540, 17280, 540, 540, 17280, 540, 270, 540, 270, 17280, 540, 540, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 540, 270, 540, 270, 540, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 540, 540, 17280, 270, 17280, 270, 270, 270, 17280, 540, 17280, 17280, 270, 540, 540, 540, 270, 540, 270, 540, 540, 17280, 270, 270, 540, 270, 540, 540, 270, 17280, 17280, 17280, 270, 540, 540, 540, 540, 270, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 540, 540, 540, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 1935360 . Total input tokens: 431032019 . Total output tokens: 387484439
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 76.77192361932248,
    "estimated_duration": 3600.1490685571634,
    "input_throughput": 6255.037380722959,
    "output_throughput": 5496.159359848413,
    "total_throughput": 11751.196740571371,
    "itl": 153.70692087413158,
    "ttft": 1980675.4435958525,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 600,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.010385819077487,
    "arrivals": 644956,
    "finished_requests": 90797,
    "scheduler_time": 168.755646704864
}
#Debug simulation 
Total elapsed time: 76.77208243217319. Arrivals time: 0.4545018789358437 Scheduler time: 76.16512783011422 Scheduler overhead time: 0.05715475743636489 Adapter cache time: 0.01854453654959798 Engine time: 0.05518493102863431 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-8/adapters_320_slots_64_rate_1.6-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-8/adapters_320_slots_64_rate_1.6-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 135, 17280, 17280, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 17280, 17280, 540, 135, 135, 540, 17280, 17280, 540, 540, 135, 135, 540, 17280, 17280, 135, 17280, 540, 135, 540, 17280, 135, 540, 17280, 17280, 540, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 540, 540, 540, 135, 540, 135, 17280, 135, 17280, 540, 17280, 17280, 135, 17280, 135, 17280, 540, 135, 135, 540, 540, 17280, 540, 17280, 17280, 17280, 135, 540, 540, 135, 17280, 540, 17280, 17280, 540, 135, 540, 540, 540, 135, 17280, 540, 17280, 135, 17280, 135, 135, 540, 17280, 17280, 540, 135, 540, 135, 540, 17280, 17280, 540, 135, 540, 135, 17280, 135, 135, 135, 135, 17280, 540, 540, 17280, 540, 540, 135, 540, 17280, 540, 135, 135, 540, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 540, 17280, 540, 540, 540, 135, 17280, 135, 17280, 540, 135, 540, 135, 135, 540, 135, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 135, 135, 17280, 540, 17280, 540, 17280, 540, 135, 540, 135, 135, 135, 17280, 17280, 540, 540, 135, 135, 540, 135, 17280, 135, 135, 540, 135, 17280, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 135, 540, 17280, 540, 540, 17280, 540, 135, 540, 135, 17280, 540, 540, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 540, 135, 540, 135, 540, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 540, 540, 17280, 135, 17280, 135, 135, 135, 17280, 540, 17280, 17280, 135, 540, 540, 540, 135, 540, 135, 540, 540, 17280, 135, 135, 540, 135, 540, 540, 135, 17280, 17280, 17280, 135, 540, 540, 540, 540, 135, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 540, 540, 540, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1921050 . Total input tokens: 427835857 . Total output tokens: 384618743
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 76.25608794530854,
    "estimated_duration": 3600.026422224885,
    "input_throughput": 6246.578042086169,
    "output_throughput": 5500.78323807451,
    "total_throughput": 11747.36128016068,
    "itl": 154.36889544170867,
    "ttft": 1978101.7893497804,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 605,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8515950850793443,
    "arrivals": 640132,
    "finished_requests": 90856,
    "scheduler_time": 168.396683236448
}
#Debug simulation 
Total elapsed time: 76.25624815095216. Arrivals time: 0.45660249702632427 Scheduler time: 75.64931677188724 Scheduler overhead time: 0.05571321118623018 Adapter cache time: 0.018340930342674255 Engine time: 0.05489312997087836 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-16/adapters_320_slots_64_rate_1.6-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-16/adapters_320_slots_64_rate_1.6-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 135, 17280, 17280, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 17280, 17280, 540, 135, 135, 540, 17280, 17280, 540, 540, 135, 135, 540, 17280, 17280, 135, 17280, 540, 135, 540, 17280, 135, 540, 17280, 17280, 540, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 540, 540, 540, 135, 540, 135, 17280, 135, 17280, 540, 17280, 17280, 135, 17280, 135, 17280, 540, 135, 135, 540, 540, 17280, 540, 17280, 17280, 17280, 135, 540, 540, 135, 17280, 540, 17280, 17280, 540, 135, 540, 540, 540, 135, 17280, 540, 17280, 135, 17280, 135, 135, 540, 17280, 17280, 540, 135, 540, 135, 540, 17280, 17280, 540, 135, 540, 135, 17280, 135, 135, 135, 135, 17280, 540, 540, 17280, 540, 540, 135, 540, 17280, 540, 135, 135, 540, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 540, 17280, 540, 540, 540, 135, 17280, 135, 17280, 540, 135, 540, 135, 135, 540, 135, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 135, 135, 17280, 540, 17280, 540, 17280, 540, 135, 540, 135, 135, 135, 17280, 17280, 540, 540, 135, 135, 540, 135, 17280, 135, 135, 540, 135, 17280, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 135, 540, 17280, 540, 540, 17280, 540, 135, 540, 135, 17280, 540, 540, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 540, 135, 540, 135, 540, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 540, 540, 17280, 135, 17280, 135, 135, 135, 17280, 540, 17280, 17280, 135, 540, 540, 540, 135, 540, 135, 540, 540, 17280, 135, 135, 540, 135, 540, 540, 135, 17280, 17280, 17280, 135, 540, 540, 540, 540, 135, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 540, 540, 540, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1921050 . Total input tokens: 427835857 . Total output tokens: 384618743
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 76.25015396717936,
    "estimated_duration": 3600.1619656125986,
    "input_throughput": 6250.312962286703,
    "output_throughput": 5501.966352958097,
    "total_throughput": 11752.2793152448,
    "itl": 154.3810866969916,
    "ttft": 1978328.3675739127,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 615,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0108995604282307,
    "arrivals": 640132,
    "finished_requests": 90919,
    "scheduler_time": 168.33117499207094
}
#Debug simulation 
Total elapsed time: 76.25030707009137. Arrivals time: 0.44776247907429934 Scheduler time: 75.65369449742138 Scheduler overhead time: 0.055009253323078156 Adapter cache time: 0.017849461641162634 Engine time: 0.05454894667491317 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-32/adapters_320_slots_64_rate_1.6-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-32/adapters_320_slots_64_rate_1.6-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 135, 17280, 17280, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 17280, 17280, 540, 135, 135, 540, 17280, 17280, 540, 540, 135, 135, 540, 17280, 17280, 135, 17280, 540, 135, 540, 17280, 135, 540, 17280, 17280, 540, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 540, 540, 540, 135, 540, 135, 17280, 135, 17280, 540, 17280, 17280, 135, 17280, 135, 17280, 540, 135, 135, 540, 540, 17280, 540, 17280, 17280, 17280, 135, 540, 540, 135, 17280, 540, 17280, 17280, 540, 135, 540, 540, 540, 135, 17280, 540, 17280, 135, 17280, 135, 135, 540, 17280, 17280, 540, 135, 540, 135, 540, 17280, 17280, 540, 135, 540, 135, 17280, 135, 135, 135, 135, 17280, 540, 540, 17280, 540, 540, 135, 540, 17280, 540, 135, 135, 540, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 540, 17280, 540, 540, 540, 135, 17280, 135, 17280, 540, 135, 540, 135, 135, 540, 135, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 135, 135, 17280, 540, 17280, 540, 17280, 540, 135, 540, 135, 135, 135, 17280, 17280, 540, 540, 135, 135, 540, 135, 17280, 135, 135, 540, 135, 17280, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 135, 540, 17280, 540, 540, 17280, 540, 135, 540, 135, 17280, 540, 540, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 540, 135, 540, 135, 540, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 540, 540, 17280, 135, 17280, 135, 135, 135, 17280, 540, 17280, 17280, 135, 540, 540, 540, 135, 540, 135, 540, 540, 17280, 135, 135, 540, 135, 540, 540, 135, 17280, 17280, 17280, 135, 540, 540, 540, 540, 135, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 540, 540, 540, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1921050 . Total input tokens: 427835857 . Total output tokens: 384618743
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 76.1698727873154,
    "estimated_duration": 3600.1646729173262,
    "input_throughput": 6250.308262084526,
    "output_throughput": 5501.962215508598,
    "total_throughput": 11752.270477593125,
    "itl": 154.38117342457355,
    "ttft": 1978329.1601771514,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 615,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0137452871911345,
    "arrivals": 640132,
    "finished_requests": 90919,
    "scheduler_time": 168.33117580793828
}
#Debug simulation 
Total elapsed time: 76.17003374407068. Arrivals time: 0.4618940092623234 Scheduler time: 75.5568931279704 Scheduler overhead time: 0.056151792872697115 Adapter cache time: 0.018563190940767527 Engine time: 0.05523425480350852 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-16/adapters_320_slots_64_rate_1.6-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-16/adapters_320_slots_64_rate_1.6-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 135, 17280, 17280, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 17280, 17280, 540, 135, 135, 540, 17280, 17280, 540, 540, 135, 135, 540, 17280, 17280, 135, 17280, 540, 135, 540, 17280, 135, 540, 17280, 17280, 540, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 540, 540, 540, 135, 540, 135, 17280, 135, 17280, 540, 17280, 17280, 135, 17280, 135, 17280, 540, 135, 135, 540, 540, 17280, 540, 17280, 17280, 17280, 135, 540, 540, 135, 17280, 540, 17280, 17280, 540, 135, 540, 540, 540, 135, 17280, 540, 17280, 135, 17280, 135, 135, 540, 17280, 17280, 540, 135, 540, 135, 540, 17280, 17280, 540, 135, 540, 135, 17280, 135, 135, 135, 135, 17280, 540, 540, 17280, 540, 540, 135, 540, 17280, 540, 135, 135, 540, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 540, 17280, 540, 540, 540, 135, 17280, 135, 17280, 540, 135, 540, 135, 135, 540, 135, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 135, 135, 17280, 540, 17280, 540, 17280, 540, 135, 540, 135, 135, 135, 17280, 17280, 540, 540, 135, 135, 540, 135, 17280, 135, 135, 540, 135, 17280, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 135, 540, 17280, 540, 540, 17280, 540, 135, 540, 135, 17280, 540, 540, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 540, 135, 540, 135, 540, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 540, 540, 17280, 135, 17280, 135, 135, 135, 17280, 540, 17280, 17280, 135, 540, 540, 540, 135, 540, 135, 540, 540, 17280, 135, 135, 540, 135, 540, 540, 135, 17280, 17280, 17280, 135, 540, 540, 540, 540, 135, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 540, 540, 540, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1921050 . Total input tokens: 427835857 . Total output tokens: 384618743
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 75.69884438300505,
    "estimated_duration": 3600.073324825904,
    "input_throughput": 6269.477581013295,
    "output_throughput": 5519.153696948899,
    "total_throughput": 11788.631277962193,
    "itl": 155.03239846756887,
    "ttft": 1978904.7749118872,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 659,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0611513050342762,
    "arrivals": 640132,
    "finished_requests": 91175,
    "scheduler_time": 167.6550045160067
}
#Debug simulation 
Total elapsed time: 75.69900780217722. Arrivals time: 0.4537719003856182 Scheduler time: 75.09523796383291 Scheduler overhead time: 0.05514242313802242 Adapter cache time: 0.01907503930851817 Engine time: 0.05475630844011903 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-32/adapters_320_slots_64_rate_1.6-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-32/adapters_320_slots_64_rate_1.6-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 135, 17280, 17280, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 17280, 17280, 540, 135, 135, 540, 17280, 17280, 540, 540, 135, 135, 540, 17280, 17280, 135, 17280, 540, 135, 540, 17280, 135, 540, 17280, 17280, 540, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 540, 540, 540, 135, 540, 135, 17280, 135, 17280, 540, 17280, 17280, 135, 17280, 135, 17280, 540, 135, 135, 540, 540, 17280, 540, 17280, 17280, 17280, 135, 540, 540, 135, 17280, 540, 17280, 17280, 540, 135, 540, 540, 540, 135, 17280, 540, 17280, 135, 17280, 135, 135, 540, 17280, 17280, 540, 135, 540, 135, 540, 17280, 17280, 540, 135, 540, 135, 17280, 135, 135, 135, 135, 17280, 540, 540, 17280, 540, 540, 135, 540, 17280, 540, 135, 135, 540, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 540, 17280, 540, 540, 540, 135, 17280, 135, 17280, 540, 135, 540, 135, 135, 540, 135, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 135, 135, 17280, 540, 17280, 540, 17280, 540, 135, 540, 135, 135, 135, 17280, 17280, 540, 540, 135, 135, 540, 135, 17280, 135, 135, 540, 135, 17280, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 135, 540, 17280, 540, 540, 17280, 540, 135, 540, 135, 17280, 540, 540, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 540, 135, 540, 135, 540, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 540, 540, 17280, 135, 17280, 135, 135, 135, 17280, 540, 17280, 17280, 135, 540, 540, 540, 135, 540, 135, 540, 540, 17280, 135, 135, 540, 135, 540, 540, 135, 17280, 17280, 17280, 135, 540, 540, 540, 540, 135, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 540, 540, 540, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1921050 . Total input tokens: 427835857 . Total output tokens: 384618743
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 76.4922106647864,
    "estimated_duration": 3600.0274453009006,
    "input_throughput": 6253.352881902366,
    "output_throughput": 5502.083887125594,
    "total_throughput": 11755.43676902796,
    "itl": 154.33646605230996,
    "ttft": 1978591.568321071,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 631,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0934398828633154,
    "arrivals": 640132,
    "finished_requests": 90942,
    "scheduler_time": 168.33822103209894
}
#Debug simulation 
Total elapsed time: 76.4923668880947. Arrivals time: 0.7564972578547895 Scheduler time: 75.58540530828759 Scheduler overhead time: 0.05572220776230097 Adapter cache time: 0.018323348835110664 Engine time: 0.055015032179653645 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-16/adapters_320_slots_64_rate_1.6-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-16/adapters_320_slots_64_rate_1.6-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 135, 17280, 17280, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 17280, 17280, 540, 135, 135, 540, 17280, 17280, 540, 540, 135, 135, 540, 17280, 17280, 135, 17280, 540, 135, 540, 17280, 135, 540, 17280, 17280, 540, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 540, 540, 540, 135, 540, 135, 17280, 135, 17280, 540, 17280, 17280, 135, 17280, 135, 17280, 540, 135, 135, 540, 540, 17280, 540, 17280, 17280, 17280, 135, 540, 540, 135, 17280, 540, 17280, 17280, 540, 135, 540, 540, 540, 135, 17280, 540, 17280, 135, 17280, 135, 135, 540, 17280, 17280, 540, 135, 540, 135, 540, 17280, 17280, 540, 135, 540, 135, 17280, 135, 135, 135, 135, 17280, 540, 540, 17280, 540, 540, 135, 540, 17280, 540, 135, 135, 540, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 540, 17280, 540, 540, 540, 135, 17280, 135, 17280, 540, 135, 540, 135, 135, 540, 135, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 135, 135, 17280, 540, 17280, 540, 17280, 540, 135, 540, 135, 135, 135, 17280, 17280, 540, 540, 135, 135, 540, 135, 17280, 135, 135, 540, 135, 17280, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 135, 540, 17280, 540, 540, 17280, 540, 135, 540, 135, 17280, 540, 540, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 540, 135, 540, 135, 540, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 540, 540, 17280, 135, 17280, 135, 135, 135, 17280, 540, 17280, 17280, 135, 540, 540, 540, 135, 540, 135, 540, 540, 17280, 135, 135, 540, 135, 540, 540, 135, 17280, 17280, 17280, 135, 540, 540, 540, 540, 135, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 540, 540, 540, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1921050 . Total input tokens: 427835857 . Total output tokens: 384618743
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 76.04861755436286,
    "estimated_duration": 3600.1595614607777,
    "input_throughput": 6246.613689220787,
    "output_throughput": 5501.049512362221,
    "total_throughput": 11747.66320158301,
    "itl": 154.36790363975842,
    "ttft": 1978099.8156107755,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 605,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8089804284157889,
    "arrivals": 640132,
    "finished_requests": 90862,
    "scheduler_time": 168.40464892465795
}
#Debug simulation 
Total elapsed time: 76.04878045292571. Arrivals time: 0.440514356829226 Scheduler time: 75.45821882039309 Scheduler overhead time: 0.055699339136481285 Adapter cache time: 0.017941561061888933 Engine time: 0.05522889783605933 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-32/adapters_320_slots_64_rate_1.6-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-32/adapters_320_slots_64_rate_1.6-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 135, 17280, 17280, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 17280, 17280, 540, 135, 135, 540, 17280, 17280, 540, 540, 135, 135, 540, 17280, 17280, 135, 17280, 540, 135, 540, 17280, 135, 540, 17280, 17280, 540, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 540, 540, 540, 135, 540, 135, 17280, 135, 17280, 540, 17280, 17280, 135, 17280, 135, 17280, 540, 135, 135, 540, 540, 17280, 540, 17280, 17280, 17280, 135, 540, 540, 135, 17280, 540, 17280, 17280, 540, 135, 540, 540, 540, 135, 17280, 540, 17280, 135, 17280, 135, 135, 540, 17280, 17280, 540, 135, 540, 135, 540, 17280, 17280, 540, 135, 540, 135, 17280, 135, 135, 135, 135, 17280, 540, 540, 17280, 540, 540, 135, 540, 17280, 540, 135, 135, 540, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 540, 17280, 540, 540, 540, 135, 17280, 135, 17280, 540, 135, 540, 135, 135, 540, 135, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 135, 135, 17280, 540, 17280, 540, 17280, 540, 135, 540, 135, 135, 135, 17280, 17280, 540, 540, 135, 135, 540, 135, 17280, 135, 135, 540, 135, 17280, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 135, 540, 17280, 540, 540, 17280, 540, 135, 540, 135, 17280, 540, 540, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 540, 135, 540, 135, 540, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 540, 540, 17280, 135, 17280, 135, 135, 135, 17280, 540, 17280, 17280, 135, 540, 540, 540, 135, 540, 135, 540, 540, 17280, 135, 135, 540, 135, 540, 540, 135, 17280, 17280, 17280, 135, 540, 540, 540, 540, 135, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 540, 540, 540, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1921050 . Total input tokens: 427835857 . Total output tokens: 384618743
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 75.94329995382577,
    "estimated_duration": 3600.0563706663143,
    "input_throughput": 6253.302638101007,
    "output_throughput": 5502.03967954366,
    "total_throughput": 11755.342317644667,
    "itl": 154.3373882843978,
    "ttft": 1978602.2064384697,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 631,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1204769469425067,
    "arrivals": 640132,
    "finished_requests": 90942,
    "scheduler_time": 168.33843847826608
}
#Debug simulation 
Total elapsed time: 75.94345914386213. Arrivals time: 0.4530500816181302 Scheduler time: 75.34040597453713 Scheduler overhead time: 0.05551643203943968 Adapter cache time: 0.01808900712057948 Engine time: 0.054884783923625946 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-8/adapters_320_slots_64_rate_1.6-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-8/adapters_320_slots_64_rate_1.6-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 66, 17280, 17280, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 17280, 17280, 540, 66, 66, 540, 17280, 17280, 540, 540, 66, 66, 540, 17280, 17280, 66, 17280, 540, 66, 540, 17280, 66, 540, 17280, 17280, 540, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 540, 540, 540, 66, 540, 66, 17280, 66, 17280, 540, 17280, 17280, 66, 17280, 66, 17280, 540, 66, 66, 540, 540, 17280, 540, 17280, 17280, 17280, 66, 540, 540, 66, 17280, 540, 17280, 17280, 540, 66, 540, 540, 540, 66, 17280, 540, 17280, 66, 17280, 66, 66, 540, 17280, 17280, 540, 66, 540, 66, 540, 17280, 17280, 540, 66, 540, 66, 17280, 66, 66, 66, 66, 17280, 540, 540, 17280, 540, 540, 66, 540, 17280, 540, 66, 66, 540, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 540, 17280, 540, 540, 540, 66, 17280, 66, 17280, 540, 66, 540, 66, 66, 540, 66, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 66, 66, 17280, 540, 17280, 540, 17280, 540, 66, 540, 66, 66, 66, 17280, 17280, 540, 540, 66, 66, 540, 66, 17280, 66, 66, 540, 66, 17280, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 66, 540, 17280, 540, 540, 17280, 540, 66, 540, 66, 17280, 540, 540, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 540, 66, 540, 66, 540, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 540, 540, 17280, 66, 17280, 66, 66, 66, 17280, 540, 17280, 17280, 66, 540, 540, 540, 66, 540, 66, 540, 540, 17280, 66, 66, 540, 66, 540, 540, 66, 17280, 17280, 17280, 66, 540, 540, 540, 540, 66, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 540, 540, 540, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1913736 . Total input tokens: 426202907 . Total output tokens: 383168847
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 68.54222970502451,
    "estimated_duration": 3600.1562786408176,
    "input_throughput": 6222.373493313279,
    "output_throughput": 5526.792855645677,
    "total_throughput": 11749.166348958957,
    "itl": 155.79737370165859,
    "ttft": 1980615.6890454288,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 625,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9128048399580015,
    "arrivals": 637737,
    "finished_requests": 90574,
    "scheduler_time": 167.24773688454013
}
#Debug simulation 
Total elapsed time: 68.54246834525838. Arrivals time: 0.44777623657137156 Scheduler time: 67.94709844980389 Scheduler overhead time: 0.05440473882481456 Adapter cache time: 0.01826530322432518 Engine time: 0.053702912759035826 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-16/adapters_320_slots_64_rate_1.6-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-16/adapters_320_slots_64_rate_1.6-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 66, 17280, 17280, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 17280, 17280, 540, 66, 66, 540, 17280, 17280, 540, 540, 66, 66, 540, 17280, 17280, 66, 17280, 540, 66, 540, 17280, 66, 540, 17280, 17280, 540, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 540, 540, 540, 66, 540, 66, 17280, 66, 17280, 540, 17280, 17280, 66, 17280, 66, 17280, 540, 66, 66, 540, 540, 17280, 540, 17280, 17280, 17280, 66, 540, 540, 66, 17280, 540, 17280, 17280, 540, 66, 540, 540, 540, 66, 17280, 540, 17280, 66, 17280, 66, 66, 540, 17280, 17280, 540, 66, 540, 66, 540, 17280, 17280, 540, 66, 540, 66, 17280, 66, 66, 66, 66, 17280, 540, 540, 17280, 540, 540, 66, 540, 17280, 540, 66, 66, 540, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 540, 17280, 540, 540, 540, 66, 17280, 66, 17280, 540, 66, 540, 66, 66, 540, 66, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 66, 66, 17280, 540, 17280, 540, 17280, 540, 66, 540, 66, 66, 66, 17280, 17280, 540, 540, 66, 66, 540, 66, 17280, 66, 66, 540, 66, 17280, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 66, 540, 17280, 540, 540, 17280, 540, 66, 540, 66, 17280, 540, 540, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 540, 66, 540, 66, 540, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 540, 540, 17280, 66, 17280, 66, 66, 66, 17280, 540, 17280, 17280, 66, 540, 540, 540, 66, 540, 66, 540, 540, 17280, 66, 66, 540, 66, 540, 540, 66, 17280, 17280, 17280, 66, 540, 540, 540, 540, 66, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 540, 540, 540, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1913736 . Total input tokens: 426202907 . Total output tokens: 383168847
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 70.45817070221528,
    "estimated_duration": 3600.032415241493,
    "input_throughput": 6222.9734113372415,
    "output_throughput": 5524.2091476184505,
    "total_throughput": 11747.182558955692,
    "itl": 155.7699034247025,
    "ttft": 1981158.3316825132,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 634,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.070570683260454,
    "arrivals": 637737,
    "finished_requests": 90592,
    "scheduler_time": 167.23099980535835
}
#Debug simulation 
Total elapsed time: 70.45833121007308. Arrivals time: 0.44199594389647245 Scheduler time: 69.86802831245586 Scheduler overhead time: 0.054770839400589466 Adapter cache time: 0.01833371538668871 Engine time: 0.053975720424205065 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-32/adapters_320_slots_64_rate_1.6-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-32/adapters_320_slots_64_rate_1.6-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 66, 17280, 17280, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 17280, 17280, 540, 66, 66, 540, 17280, 17280, 540, 540, 66, 66, 540, 17280, 17280, 66, 17280, 540, 66, 540, 17280, 66, 540, 17280, 17280, 540, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 540, 540, 540, 66, 540, 66, 17280, 66, 17280, 540, 17280, 17280, 66, 17280, 66, 17280, 540, 66, 66, 540, 540, 17280, 540, 17280, 17280, 17280, 66, 540, 540, 66, 17280, 540, 17280, 17280, 540, 66, 540, 540, 540, 66, 17280, 540, 17280, 66, 17280, 66, 66, 540, 17280, 17280, 540, 66, 540, 66, 540, 17280, 17280, 540, 66, 540, 66, 17280, 66, 66, 66, 66, 17280, 540, 540, 17280, 540, 540, 66, 540, 17280, 540, 66, 66, 540, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 540, 17280, 540, 540, 540, 66, 17280, 66, 17280, 540, 66, 540, 66, 66, 540, 66, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 66, 66, 17280, 540, 17280, 540, 17280, 540, 66, 540, 66, 66, 66, 17280, 17280, 540, 540, 66, 66, 540, 66, 17280, 66, 66, 540, 66, 17280, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 66, 540, 17280, 540, 540, 17280, 540, 66, 540, 66, 17280, 540, 540, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 540, 66, 540, 66, 540, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 540, 540, 17280, 66, 17280, 66, 66, 66, 17280, 540, 17280, 17280, 66, 540, 540, 540, 66, 540, 66, 540, 540, 17280, 66, 66, 540, 66, 540, 540, 66, 17280, 17280, 17280, 66, 540, 540, 540, 540, 66, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 540, 540, 540, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1913736 . Total input tokens: 426202907 . Total output tokens: 383168847
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 69.68627270078287,
    "estimated_duration": 3600.0333624609134,
    "input_throughput": 6222.971773985396,
    "output_throughput": 5524.207694121314,
    "total_throughput": 11747.17946810671,
    "itl": 155.76993395192252,
    "ttft": 1981157.9840587697,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 634,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.073932877779017,
    "arrivals": 637737,
    "finished_requests": 90592,
    "scheduler_time": 167.23095187508773
}
#Debug simulation 
Total elapsed time: 69.68643664103001. Arrivals time: 0.4361856644973159 Scheduler time: 69.10187924327329 Scheduler overhead time: 0.055038133170455694 Adapter cache time: 0.018481430131942034 Engine time: 0.05391333531588316 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-16/adapters_320_slots_64_rate_1.6-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-16/adapters_320_slots_64_rate_1.6-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 66, 17280, 17280, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 17280, 17280, 540, 66, 66, 540, 17280, 17280, 540, 540, 66, 66, 540, 17280, 17280, 66, 17280, 540, 66, 540, 17280, 66, 540, 17280, 17280, 540, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 540, 540, 540, 66, 540, 66, 17280, 66, 17280, 540, 17280, 17280, 66, 17280, 66, 17280, 540, 66, 66, 540, 540, 17280, 540, 17280, 17280, 17280, 66, 540, 540, 66, 17280, 540, 17280, 17280, 540, 66, 540, 540, 540, 66, 17280, 540, 17280, 66, 17280, 66, 66, 540, 17280, 17280, 540, 66, 540, 66, 540, 17280, 17280, 540, 66, 540, 66, 17280, 66, 66, 66, 66, 17280, 540, 540, 17280, 540, 540, 66, 540, 17280, 540, 66, 66, 540, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 540, 17280, 540, 540, 540, 66, 17280, 66, 17280, 540, 66, 540, 66, 66, 540, 66, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 66, 66, 17280, 540, 17280, 540, 17280, 540, 66, 540, 66, 66, 66, 17280, 17280, 540, 540, 66, 66, 540, 66, 17280, 66, 66, 540, 66, 17280, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 66, 540, 17280, 540, 540, 17280, 540, 66, 540, 66, 17280, 540, 540, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 540, 66, 540, 66, 540, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 540, 540, 17280, 66, 17280, 66, 66, 66, 17280, 540, 17280, 17280, 66, 540, 540, 540, 66, 540, 66, 540, 540, 17280, 66, 66, 540, 66, 540, 540, 66, 17280, 17280, 17280, 66, 540, 540, 540, 540, 66, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 540, 540, 540, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1913736 . Total input tokens: 426202907 . Total output tokens: 383168847
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 72.40297673922032,
    "estimated_duration": 3600.0152829822455,
    "input_throughput": 6216.7147194609215,
    "output_throughput": 5517.826019767474,
    "total_throughput": 11734.540739228396,
    "itl": 155.28308434824126,
    "ttft": 1981694.2719576196,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 636,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9874770044302432,
    "arrivals": 637737,
    "finished_requests": 90512,
    "scheduler_time": 167.60581611166694
}
#Debug simulation 
Total elapsed time: 72.40313726104796. Arrivals time: 0.4511650479398668 Scheduler time: 71.8022770662792 Scheduler overhead time: 0.055549383629113436 Adapter cache time: 0.018770769704133272 Engine time: 0.05424485728144646 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-32/adapters_320_slots_64_rate_1.6-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-32/adapters_320_slots_64_rate_1.6-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 66, 17280, 17280, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 17280, 17280, 540, 66, 66, 540, 17280, 17280, 540, 540, 66, 66, 540, 17280, 17280, 66, 17280, 540, 66, 540, 17280, 66, 540, 17280, 17280, 540, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 540, 540, 540, 66, 540, 66, 17280, 66, 17280, 540, 17280, 17280, 66, 17280, 66, 17280, 540, 66, 66, 540, 540, 17280, 540, 17280, 17280, 17280, 66, 540, 540, 66, 17280, 540, 17280, 17280, 540, 66, 540, 540, 540, 66, 17280, 540, 17280, 66, 17280, 66, 66, 540, 17280, 17280, 540, 66, 540, 66, 540, 17280, 17280, 540, 66, 540, 66, 17280, 66, 66, 66, 66, 17280, 540, 540, 17280, 540, 540, 66, 540, 17280, 540, 66, 66, 540, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 540, 17280, 540, 540, 540, 66, 17280, 66, 17280, 540, 66, 540, 66, 66, 540, 66, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 66, 66, 17280, 540, 17280, 540, 17280, 540, 66, 540, 66, 66, 66, 17280, 17280, 540, 540, 66, 66, 540, 66, 17280, 66, 66, 540, 66, 17280, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 66, 540, 17280, 540, 540, 17280, 540, 66, 540, 66, 17280, 540, 540, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 540, 66, 540, 66, 540, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 540, 540, 17280, 66, 17280, 66, 66, 66, 17280, 540, 17280, 17280, 66, 540, 540, 540, 66, 540, 66, 540, 540, 17280, 66, 66, 540, 66, 540, 540, 66, 17280, 17280, 17280, 66, 540, 540, 540, 540, 66, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 540, 540, 540, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1913736 . Total input tokens: 426202907 . Total output tokens: 383168847
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 69.5047370614484,
    "estimated_duration": 3600.061573424395,
    "input_throughput": 6222.9230092557145,
    "output_throughput": 5524.1644050779605,
    "total_throughput": 11747.087414333675,
    "itl": 155.77102793462413,
    "ttft": 1981167.250609547,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 634,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.101347203217449,
    "arrivals": 637737,
    "finished_requests": 90592,
    "scheduler_time": 167.23106471219566
}
#Debug simulation 
Total elapsed time: 69.50489298440516. Arrivals time: 0.4373397040180862 Scheduler time: 68.92019766801968 Scheduler overhead time: 0.05428023962303996 Adapter cache time: 0.018428143113851547 Engine time: 0.053386063780635595 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-16/adapters_320_slots_64_rate_1.6-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-16/adapters_320_slots_64_rate_1.6-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 66, 17280, 17280, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 17280, 17280, 540, 66, 66, 540, 17280, 17280, 540, 540, 66, 66, 540, 17280, 17280, 66, 17280, 540, 66, 540, 17280, 66, 540, 17280, 17280, 540, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 540, 540, 540, 66, 540, 66, 17280, 66, 17280, 540, 17280, 17280, 66, 17280, 66, 17280, 540, 66, 66, 540, 540, 17280, 540, 17280, 17280, 17280, 66, 540, 540, 66, 17280, 540, 17280, 17280, 540, 66, 540, 540, 540, 66, 17280, 540, 17280, 66, 17280, 66, 66, 540, 17280, 17280, 540, 66, 540, 66, 540, 17280, 17280, 540, 66, 540, 66, 17280, 66, 66, 66, 66, 17280, 540, 540, 17280, 540, 540, 66, 540, 17280, 540, 66, 66, 540, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 540, 17280, 540, 540, 540, 66, 17280, 66, 17280, 540, 66, 540, 66, 66, 540, 66, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 66, 66, 17280, 540, 17280, 540, 17280, 540, 66, 540, 66, 66, 66, 17280, 17280, 540, 540, 66, 66, 540, 66, 17280, 66, 66, 540, 66, 17280, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 66, 540, 17280, 540, 540, 17280, 540, 66, 540, 66, 17280, 540, 540, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 540, 66, 540, 66, 540, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 540, 540, 17280, 66, 17280, 66, 66, 66, 17280, 540, 17280, 17280, 66, 540, 540, 540, 66, 540, 66, 540, 540, 17280, 66, 66, 540, 66, 540, 540, 66, 17280, 17280, 17280, 66, 540, 540, 540, 540, 66, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 540, 540, 540, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1913736 . Total input tokens: 426202907 . Total output tokens: 383168847
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 69.3275212738663,
    "estimated_duration": 3600.017081494961,
    "input_throughput": 6226.0293472530775,
    "output_throughput": 5524.566842260922,
    "total_throughput": 11750.596189513999,
    "itl": 155.75240677827924,
    "ttft": 1981284.484069034,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 631,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8867217360832427,
    "arrivals": 637737,
    "finished_requests": 90621,
    "scheduler_time": 167.2441281212869
}
#Debug simulation 
Total elapsed time: 69.32769278483465. Arrivals time: 0.44870090018957853 Scheduler time: 68.72999667562544 Scheduler overhead time: 0.05502464575693011 Adapter cache time: 0.01844289619475603 Engine time: 0.054135116282850504 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-32/adapters_320_slots_64_rate_1.6-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-32/adapters_320_slots_64_rate_1.6-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 66, 17280, 17280, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 17280, 17280, 540, 66, 66, 540, 17280, 17280, 540, 540, 66, 66, 540, 17280, 17280, 66, 17280, 540, 66, 540, 17280, 66, 540, 17280, 17280, 540, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 540, 540, 540, 66, 540, 66, 17280, 66, 17280, 540, 17280, 17280, 66, 17280, 66, 17280, 540, 66, 66, 540, 540, 17280, 540, 17280, 17280, 17280, 66, 540, 540, 66, 17280, 540, 17280, 17280, 540, 66, 540, 540, 540, 66, 17280, 540, 17280, 66, 17280, 66, 66, 540, 17280, 17280, 540, 66, 540, 66, 540, 17280, 17280, 540, 66, 540, 66, 17280, 66, 66, 66, 66, 17280, 540, 540, 17280, 540, 540, 66, 540, 17280, 540, 66, 66, 540, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 540, 17280, 540, 540, 540, 66, 17280, 66, 17280, 540, 66, 540, 66, 66, 540, 66, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 66, 66, 17280, 540, 17280, 540, 17280, 540, 66, 540, 66, 66, 66, 17280, 17280, 540, 540, 66, 66, 540, 66, 17280, 66, 66, 540, 66, 17280, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 66, 540, 17280, 540, 540, 17280, 540, 66, 540, 66, 17280, 540, 540, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 540, 66, 540, 66, 540, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 540, 540, 17280, 66, 17280, 66, 66, 66, 17280, 540, 17280, 17280, 66, 540, 540, 540, 66, 540, 66, 540, 540, 17280, 66, 66, 540, 66, 540, 540, 66, 17280, 17280, 17280, 66, 540, 540, 540, 540, 66, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 540, 540, 540, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1913736 . Total input tokens: 426202907 . Total output tokens: 383168847
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 70.06772423302755,
    "estimated_duration": 3600.040914516629,
    "input_throughput": 6220.752355812304,
    "output_throughput": 5526.358025481297,
    "total_throughput": 11747.1103812936,
    "itl": 155.8064538414934,
    "ttft": 1980534.479966033,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 637,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1368860549107187,
    "arrivals": 637737,
    "finished_requests": 90575,
    "scheduler_time": 167.22031537633077
}
#Debug simulation 
Total elapsed time: 70.06788793997839. Arrivals time: 0.43858654564246535 Scheduler time: 69.48042615270242 Scheduler overhead time: 0.055551701691001654 Adapter cache time: 0.01854971330612898 Engine time: 0.053862061351537704 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-8/adapters_320_slots_64_rate_1.6-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-8/adapters_320_slots_64_rate_1.6-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 33, 17280, 17280, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 17280, 17280, 540, 33, 33, 540, 17280, 17280, 540, 540, 33, 33, 540, 17280, 17280, 33, 17280, 540, 33, 540, 17280, 33, 540, 17280, 17280, 540, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 540, 540, 540, 33, 540, 33, 17280, 33, 17280, 540, 17280, 17280, 33, 17280, 33, 17280, 540, 33, 33, 540, 540, 17280, 540, 17280, 17280, 17280, 33, 540, 540, 33, 17280, 540, 17280, 17280, 540, 33, 540, 540, 540, 33, 17280, 540, 17280, 33, 17280, 33, 33, 540, 17280, 17280, 540, 33, 540, 33, 540, 17280, 17280, 540, 33, 540, 33, 17280, 33, 33, 33, 33, 17280, 540, 540, 17280, 540, 540, 33, 540, 17280, 540, 33, 33, 540, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 540, 17280, 540, 540, 540, 33, 17280, 33, 17280, 540, 33, 540, 33, 33, 540, 33, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 33, 33, 17280, 540, 17280, 540, 17280, 540, 33, 540, 33, 33, 33, 17280, 17280, 540, 540, 33, 33, 540, 33, 17280, 33, 33, 540, 33, 17280, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 33, 540, 17280, 540, 540, 17280, 540, 33, 540, 33, 17280, 540, 540, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 540, 33, 540, 33, 540, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 540, 540, 17280, 33, 17280, 33, 33, 33, 17280, 540, 17280, 17280, 33, 540, 540, 540, 33, 540, 33, 540, 540, 17280, 33, 33, 540, 33, 540, 540, 33, 17280, 17280, 17280, 33, 540, 540, 540, 540, 33, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 540, 540, 540, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1910238 . Total input tokens: 425397056 . Total output tokens: 382469408
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 64.47015369869769,
    "estimated_duration": 3600.1436789100685,
    "input_throughput": 6256.39863540642,
    "output_throughput": 5517.746171178914,
    "total_throughput": 11774.144806585333,
    "itl": 155.02079042577103,
    "ttft": 1977089.8194839873,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 607,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.85771606056721,
    "arrivals": 636613,
    "finished_requests": 91120,
    "scheduler_time": 167.66385323263717
}
#Debug simulation 
Total elapsed time: 64.47031545592472. Arrivals time: 0.4346164343878627 Scheduler time: 63.88998644705862 Scheduler overhead time: 0.05413853796198964 Adapter cache time: 0.017492919694632292 Engine time: 0.05318556074053049 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-16/adapters_320_slots_64_rate_1.6-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-16/adapters_320_slots_64_rate_1.6-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 33, 17280, 17280, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 17280, 17280, 540, 33, 33, 540, 17280, 17280, 540, 540, 33, 33, 540, 17280, 17280, 33, 17280, 540, 33, 540, 17280, 33, 540, 17280, 17280, 540, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 540, 540, 540, 33, 540, 33, 17280, 33, 17280, 540, 17280, 17280, 33, 17280, 33, 17280, 540, 33, 33, 540, 540, 17280, 540, 17280, 17280, 17280, 33, 540, 540, 33, 17280, 540, 17280, 17280, 540, 33, 540, 540, 540, 33, 17280, 540, 17280, 33, 17280, 33, 33, 540, 17280, 17280, 540, 33, 540, 33, 540, 17280, 17280, 540, 33, 540, 33, 17280, 33, 33, 33, 33, 17280, 540, 540, 17280, 540, 540, 33, 540, 17280, 540, 33, 33, 540, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 540, 17280, 540, 540, 540, 33, 17280, 33, 17280, 540, 33, 540, 33, 33, 540, 33, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 33, 33, 17280, 540, 17280, 540, 17280, 540, 33, 540, 33, 33, 33, 17280, 17280, 540, 540, 33, 33, 540, 33, 17280, 33, 33, 540, 33, 17280, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 33, 540, 17280, 540, 540, 17280, 540, 33, 540, 33, 17280, 540, 540, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 540, 33, 540, 33, 540, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 540, 540, 17280, 33, 17280, 33, 33, 33, 17280, 540, 17280, 17280, 33, 540, 540, 540, 33, 540, 33, 540, 540, 17280, 33, 33, 540, 33, 540, 540, 33, 17280, 17280, 17280, 33, 540, 540, 540, 540, 33, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 540, 540, 540, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1910238 . Total input tokens: 425397056 . Total output tokens: 382469408
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 67.92244740389287,
    "estimated_duration": 3600.1034938007892,
    "input_throughput": 6263.540767322109,
    "output_throughput": 5516.014201868067,
    "total_throughput": 11779.554969190176,
    "itl": 154.9378070380487,
    "ttft": 1976701.2619135894,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 577,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8842025990318578,
    "arrivals": 636613,
    "finished_requests": 91170,
    "scheduler_time": 167.67924591710562
}
#Debug simulation 
Total elapsed time: 67.92261404264718. Arrivals time: 0.45361954905092716 Scheduler time: 67.32326430873945 Scheduler overhead time: 0.05413480708375573 Adapter cache time: 0.017511608079075813 Engine time: 0.05308109661564231 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-32/adapters_320_slots_64_rate_1.6-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-32/adapters_320_slots_64_rate_1.6-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 33, 17280, 17280, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 17280, 17280, 540, 33, 33, 540, 17280, 17280, 540, 540, 33, 33, 540, 17280, 17280, 33, 17280, 540, 33, 540, 17280, 33, 540, 17280, 17280, 540, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 540, 540, 540, 33, 540, 33, 17280, 33, 17280, 540, 17280, 17280, 33, 17280, 33, 17280, 540, 33, 33, 540, 540, 17280, 540, 17280, 17280, 17280, 33, 540, 540, 33, 17280, 540, 17280, 17280, 540, 33, 540, 540, 540, 33, 17280, 540, 17280, 33, 17280, 33, 33, 540, 17280, 17280, 540, 33, 540, 33, 540, 17280, 17280, 540, 33, 540, 33, 17280, 33, 33, 33, 33, 17280, 540, 540, 17280, 540, 540, 33, 540, 17280, 540, 33, 33, 540, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 540, 17280, 540, 540, 540, 33, 17280, 33, 17280, 540, 33, 540, 33, 33, 540, 33, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 33, 33, 17280, 540, 17280, 540, 17280, 540, 33, 540, 33, 33, 33, 17280, 17280, 540, 540, 33, 33, 540, 33, 17280, 33, 33, 540, 33, 17280, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 33, 540, 17280, 540, 540, 17280, 540, 33, 540, 33, 17280, 540, 540, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 540, 33, 540, 33, 540, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 540, 540, 17280, 33, 17280, 33, 33, 33, 17280, 540, 17280, 17280, 33, 540, 540, 540, 33, 540, 33, 540, 540, 17280, 33, 33, 540, 33, 540, 540, 33, 17280, 17280, 17280, 33, 540, 540, 540, 540, 33, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 540, 540, 540, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1910238 . Total input tokens: 425397056 . Total output tokens: 382469408
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 68.0565414908342,
    "estimated_duration": 3600.1065892905435,
    "input_throughput": 6263.5353817242685,
    "output_throughput": 5516.0094590180925,
    "total_throughput": 11779.544840742361,
    "itl": 154.9379490710849,
    "ttft": 1976702.2709040684,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 577,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8872996511124192,
    "arrivals": 636613,
    "finished_requests": 91170,
    "scheduler_time": 167.67924435474566
}
#Debug simulation 
Total elapsed time: 68.05678272387013. Arrivals time: 0.4400337291881442 Scheduler time: 67.46991738909855 Scheduler overhead time: 0.05434843245893717 Adapter cache time: 0.017495928332209587 Engine time: 0.053852387238293886 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-16/adapters_320_slots_64_rate_1.6-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-16/adapters_320_slots_64_rate_1.6-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 33, 17280, 17280, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 17280, 17280, 540, 33, 33, 540, 17280, 17280, 540, 540, 33, 33, 540, 17280, 17280, 33, 17280, 540, 33, 540, 17280, 33, 540, 17280, 17280, 540, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 540, 540, 540, 33, 540, 33, 17280, 33, 17280, 540, 17280, 17280, 33, 17280, 33, 17280, 540, 33, 33, 540, 540, 17280, 540, 17280, 17280, 17280, 33, 540, 540, 33, 17280, 540, 17280, 17280, 540, 33, 540, 540, 540, 33, 17280, 540, 17280, 33, 17280, 33, 33, 540, 17280, 17280, 540, 33, 540, 33, 540, 17280, 17280, 540, 33, 540, 33, 17280, 33, 33, 33, 33, 17280, 540, 540, 17280, 540, 540, 33, 540, 17280, 540, 33, 33, 540, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 540, 17280, 540, 540, 540, 33, 17280, 33, 17280, 540, 33, 540, 33, 33, 540, 33, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 33, 33, 17280, 540, 17280, 540, 17280, 540, 33, 540, 33, 33, 33, 17280, 17280, 540, 540, 33, 33, 540, 33, 17280, 33, 33, 540, 33, 17280, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 33, 540, 17280, 540, 540, 17280, 540, 33, 540, 33, 17280, 540, 540, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 540, 33, 540, 33, 540, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 540, 540, 17280, 33, 17280, 33, 33, 33, 17280, 540, 17280, 17280, 33, 540, 540, 540, 33, 540, 33, 540, 540, 17280, 33, 33, 540, 33, 540, 540, 33, 17280, 17280, 17280, 33, 540, 540, 540, 540, 33, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 540, 540, 540, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1910238 . Total input tokens: 425397056 . Total output tokens: 382469408
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 69.97744362987578,
    "estimated_duration": 3600.0179175341977,
    "input_throughput": 6267.151863358935,
    "output_throughput": 5517.456705772442,
    "total_throughput": 11784.608569131376,
    "itl": 154.9587875611226,
    "ttft": 1976046.2886049764,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 581,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8160781177971415,
    "arrivals": 636613,
    "finished_requests": 91131,
    "scheduler_time": 167.68113334000455
}
#Debug simulation 
Total elapsed time: 69.97760570282117. Arrivals time: 0.44118264969438314 Scheduler time: 69.38766179699451 Scheduler overhead time: 0.055398741737008095 Adapter cache time: 0.017832814250141382 Engine time: 0.054277155082672834 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-32/adapters_320_slots_64_rate_1.6-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-32/adapters_320_slots_64_rate_1.6-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 33, 17280, 17280, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 17280, 17280, 540, 33, 33, 540, 17280, 17280, 540, 540, 33, 33, 540, 17280, 17280, 33, 17280, 540, 33, 540, 17280, 33, 540, 17280, 17280, 540, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 540, 540, 540, 33, 540, 33, 17280, 33, 17280, 540, 17280, 17280, 33, 17280, 33, 17280, 540, 33, 33, 540, 540, 17280, 540, 17280, 17280, 17280, 33, 540, 540, 33, 17280, 540, 17280, 17280, 540, 33, 540, 540, 540, 33, 17280, 540, 17280, 33, 17280, 33, 33, 540, 17280, 17280, 540, 33, 540, 33, 540, 17280, 17280, 540, 33, 540, 33, 17280, 33, 33, 33, 33, 17280, 540, 540, 17280, 540, 540, 33, 540, 17280, 540, 33, 33, 540, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 540, 17280, 540, 540, 540, 33, 17280, 33, 17280, 540, 33, 540, 33, 33, 540, 33, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 33, 33, 17280, 540, 17280, 540, 17280, 540, 33, 540, 33, 33, 33, 17280, 17280, 540, 540, 33, 33, 540, 33, 17280, 33, 33, 540, 33, 17280, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 33, 540, 17280, 540, 540, 17280, 540, 33, 540, 33, 17280, 540, 540, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 540, 33, 540, 33, 540, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 540, 540, 17280, 33, 17280, 33, 33, 33, 17280, 540, 17280, 17280, 33, 540, 540, 540, 33, 540, 33, 540, 540, 17280, 33, 33, 540, 33, 540, 540, 33, 17280, 17280, 17280, 33, 540, 540, 540, 540, 33, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 540, 540, 540, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1910238 . Total input tokens: 425397056 . Total output tokens: 382469408
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 68.1182113289833,
    "estimated_duration": 3600.131909295068,
    "input_throughput": 6263.491329798339,
    "output_throughput": 5515.970664499453,
    "total_throughput": 11779.461994297792,
    "itl": 154.93882449172094,
    "ttft": 1976710.8477826738,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 577,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9121989008225533,
    "arrivals": 636613,
    "finished_requests": 91170,
    "scheduler_time": 167.67938663372234
}
#Debug simulation 
Total elapsed time: 68.11837598728016. Arrivals time: 0.7508787573315203 Scheduler time: 67.22032312909141 Scheduler overhead time: 0.05424549849703908 Adapter cache time: 0.01748228445649147 Engine time: 0.05474682943895459 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-16/adapters_320_slots_64_rate_1.6-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-16/adapters_320_slots_64_rate_1.6-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 33, 17280, 17280, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 17280, 17280, 540, 33, 33, 540, 17280, 17280, 540, 540, 33, 33, 540, 17280, 17280, 33, 17280, 540, 33, 540, 17280, 33, 540, 17280, 17280, 540, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 540, 540, 540, 33, 540, 33, 17280, 33, 17280, 540, 17280, 17280, 33, 17280, 33, 17280, 540, 33, 33, 540, 540, 17280, 540, 17280, 17280, 17280, 33, 540, 540, 33, 17280, 540, 17280, 17280, 540, 33, 540, 540, 540, 33, 17280, 540, 17280, 33, 17280, 33, 33, 540, 17280, 17280, 540, 33, 540, 33, 540, 17280, 17280, 540, 33, 540, 33, 17280, 33, 33, 33, 33, 17280, 540, 540, 17280, 540, 540, 33, 540, 17280, 540, 33, 33, 540, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 540, 17280, 540, 540, 540, 33, 17280, 33, 17280, 540, 33, 540, 33, 33, 540, 33, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 33, 33, 17280, 540, 17280, 540, 17280, 540, 33, 540, 33, 33, 33, 17280, 17280, 540, 540, 33, 33, 540, 33, 17280, 33, 33, 540, 33, 17280, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 33, 540, 17280, 540, 540, 17280, 540, 33, 540, 33, 17280, 540, 540, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 540, 33, 540, 33, 540, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 540, 540, 17280, 33, 17280, 33, 33, 33, 17280, 540, 17280, 17280, 33, 540, 540, 540, 33, 540, 33, 540, 540, 17280, 33, 33, 540, 33, 540, 540, 33, 17280, 17280, 17280, 33, 540, 540, 540, 540, 33, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 540, 540, 540, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1910238 . Total input tokens: 425397056 . Total output tokens: 382469408
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 64.55206653382629,
    "estimated_duration": 3600.147673989027,
    "input_throughput": 6256.7127906288915,
    "output_throughput": 5516.840640593271,
    "total_throughput": 11773.553431222163,
    "itl": 155.00437554952637,
    "ttft": 1976944.4335069947,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 604,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8059903781208868,
    "arrivals": 636613,
    "finished_requests": 91117,
    "scheduler_time": 167.66768428202337
}
#Debug simulation 
Total elapsed time: 64.55221806792542. Arrivals time: 0.4311572830192745 Scheduler time: 63.97559539973736 Scheduler overhead time: 0.05369547102600336 Adapter cache time: 0.017518099397420883 Engine time: 0.053300999104976654 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-32/adapters_320_slots_64_rate_1.6-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-32/adapters_320_slots_64_rate_1.6-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [106 107 107]
Adapter prompts. [540, 17280, 17280, 33, 17280, 17280, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 17280, 17280, 540, 33, 33, 540, 17280, 17280, 540, 540, 33, 33, 540, 17280, 17280, 33, 17280, 540, 33, 540, 17280, 33, 540, 17280, 17280, 540, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 540, 540, 540, 33, 540, 33, 17280, 33, 17280, 540, 17280, 17280, 33, 17280, 33, 17280, 540, 33, 33, 540, 540, 17280, 540, 17280, 17280, 17280, 33, 540, 540, 33, 17280, 540, 17280, 17280, 540, 33, 540, 540, 540, 33, 17280, 540, 17280, 33, 17280, 33, 33, 540, 17280, 17280, 540, 33, 540, 33, 540, 17280, 17280, 540, 33, 540, 33, 17280, 33, 33, 33, 33, 17280, 540, 540, 17280, 540, 540, 33, 540, 17280, 540, 33, 33, 540, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 540, 17280, 540, 540, 540, 33, 17280, 33, 17280, 540, 33, 540, 33, 33, 540, 33, 540, 17280, 17280, 17280, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 33, 33, 17280, 540, 17280, 540, 17280, 540, 33, 540, 33, 33, 33, 17280, 17280, 540, 540, 33, 33, 540, 33, 17280, 33, 33, 540, 33, 17280, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 33, 540, 17280, 540, 540, 17280, 540, 33, 540, 33, 17280, 540, 540, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 540, 33, 540, 33, 540, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 540, 540, 17280, 33, 17280, 33, 33, 33, 17280, 540, 17280, 17280, 33, 540, 540, 540, 33, 540, 33, 540, 540, 17280, 33, 33, 540, 33, 540, 540, 33, 17280, 17280, 17280, 33, 540, 540, 540, 540, 33, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 540, 540, 540, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1910238 . Total input tokens: 425397056 . Total output tokens: 382469408
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 67.85329798515886,
    "estimated_duration": 3600.1236496555416,
    "input_throughput": 6262.493512453987,
    "output_throughput": 5516.073316509575,
    "total_throughput": 11778.566828963563,
    "itl": 154.95077761750096,
    "ttft": 1976900.0333563825,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 586,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9659245500713531,
    "arrivals": 636613,
    "finished_requests": 91144,
    "scheduler_time": 167.67487336981685
}
#Debug simulation 
Total elapsed time: 67.85346511611715. Arrivals time: 0.4519281415268779 Scheduler time: 67.25463531259447 Scheduler overhead time: 0.05435341317206621 Adapter cache time: 0.0175454868003726 Engine time: 0.05386829376220703 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-8/adapters_320_slots_64_rate_1.6-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-8/adapters_320_slots_64_rate_1.6-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [106 107 107]
Adapter prompts. [270, 17280, 17280, 135, 17280, 17280, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 17280, 17280, 270, 135, 135, 270, 17280, 17280, 270, 270, 135, 135, 270, 17280, 17280, 135, 17280, 270, 135, 270, 17280, 135, 270, 17280, 17280, 270, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 270, 270, 270, 135, 270, 135, 17280, 135, 17280, 270, 17280, 17280, 135, 17280, 135, 17280, 270, 135, 135, 270, 270, 17280, 270, 17280, 17280, 17280, 135, 270, 270, 135, 17280, 270, 17280, 17280, 270, 135, 270, 270, 270, 135, 17280, 270, 17280, 135, 17280, 135, 135, 270, 17280, 17280, 270, 135, 270, 135, 270, 17280, 17280, 270, 135, 270, 135, 17280, 135, 135, 135, 135, 17280, 270, 270, 17280, 270, 270, 135, 270, 17280, 270, 135, 135, 270, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 270, 17280, 270, 270, 270, 135, 17280, 135, 17280, 270, 135, 270, 135, 135, 270, 135, 270, 17280, 17280, 17280, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 135, 135, 17280, 270, 17280, 270, 17280, 270, 135, 270, 135, 135, 135, 17280, 17280, 270, 270, 135, 135, 270, 135, 17280, 135, 135, 270, 135, 17280, 270, 135, 17280, 135, 135, 17280, 270, 17280, 270, 135, 270, 17280, 270, 270, 17280, 270, 135, 270, 135, 17280, 270, 270, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 270, 135, 270, 135, 270, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 270, 270, 17280, 135, 17280, 135, 135, 135, 17280, 270, 17280, 17280, 135, 270, 270, 270, 135, 270, 135, 270, 270, 17280, 135, 135, 270, 135, 270, 270, 135, 17280, 17280, 17280, 135, 270, 270, 270, 270, 135, 270, 135, 17280, 135, 135, 17280, 270, 17280, 270, 270, 270, 270, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 270, 17280, 270, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1892160 . Total input tokens: 421336932 . Total output tokens: 378846953
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 67.6191877219826,
    "estimated_duration": 3600.1450865635775,
    "input_throughput": 6241.161247600515,
    "output_throughput": 5520.511402214295,
    "total_throughput": 11761.67264981481,
    "itl": 155.27246806934,
    "ttft": 1972539.7369546343,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 707,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.163764834960496,
    "arrivals": 630527,
    "finished_requests": 91061,
    "scheduler_time": 167.43024635924573
}
#Debug simulation 
Total elapsed time: 67.61936168000102. Arrivals time: 0.441967248916626 Scheduler time: 67.02971641719341 Scheduler overhead time: 0.054317268542945385 Adapter cache time: 0.019099948462098837 Engine time: 0.053282920736819506 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-16/adapters_320_slots_64_rate_1.6-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-16/adapters_320_slots_64_rate_1.6-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [106 107 107]
Adapter prompts. [270, 17280, 17280, 135, 17280, 17280, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 17280, 17280, 270, 135, 135, 270, 17280, 17280, 270, 270, 135, 135, 270, 17280, 17280, 135, 17280, 270, 135, 270, 17280, 135, 270, 17280, 17280, 270, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 270, 270, 270, 135, 270, 135, 17280, 135, 17280, 270, 17280, 17280, 135, 17280, 135, 17280, 270, 135, 135, 270, 270, 17280, 270, 17280, 17280, 17280, 135, 270, 270, 135, 17280, 270, 17280, 17280, 270, 135, 270, 270, 270, 135, 17280, 270, 17280, 135, 17280, 135, 135, 270, 17280, 17280, 270, 135, 270, 135, 270, 17280, 17280, 270, 135, 270, 135, 17280, 135, 135, 135, 135, 17280, 270, 270, 17280, 270, 270, 135, 270, 17280, 270, 135, 135, 270, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 270, 17280, 270, 270, 270, 135, 17280, 135, 17280, 270, 135, 270, 135, 135, 270, 135, 270, 17280, 17280, 17280, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 135, 135, 17280, 270, 17280, 270, 17280, 270, 135, 270, 135, 135, 135, 17280, 17280, 270, 270, 135, 135, 270, 135, 17280, 135, 135, 270, 135, 17280, 270, 135, 17280, 135, 135, 17280, 270, 17280, 270, 135, 270, 17280, 270, 270, 17280, 270, 135, 270, 135, 17280, 270, 270, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 270, 135, 270, 135, 270, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 270, 270, 17280, 135, 17280, 135, 135, 135, 17280, 270, 17280, 17280, 135, 270, 270, 270, 135, 270, 135, 270, 270, 17280, 135, 135, 270, 135, 270, 270, 135, 17280, 17280, 17280, 135, 270, 270, 270, 270, 135, 270, 135, 17280, 135, 135, 17280, 270, 17280, 270, 270, 270, 270, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 270, 17280, 270, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1892160 . Total input tokens: 421336932 . Total output tokens: 378846953
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 68.511834140867,
    "estimated_duration": 3600.0304018396546,
    "input_throughput": 6239.899248773216,
    "output_throughput": 5519.304500830433,
    "total_throughput": 11759.20374960365,
    "itl": 155.21145860040514,
    "ttft": 1973050.568504965,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 724,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.359696380405225,
    "arrivals": 630527,
    "finished_requests": 91028,
    "scheduler_time": 167.42046804217276
}
#Debug simulation 
Total elapsed time: 68.51199960289523. Arrivals time: 0.44675757782533765 Scheduler time: 67.91614528093487 Scheduler overhead time: 0.054988106712698936 Adapter cache time: 0.019268892239779234 Engine time: 0.053645757026970387 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-32/adapters_320_slots_64_rate_1.6-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-32/adapters_320_slots_64_rate_1.6-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [106 107 107]
Adapter prompts. [270, 17280, 17280, 135, 17280, 17280, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 17280, 17280, 270, 135, 135, 270, 17280, 17280, 270, 270, 135, 135, 270, 17280, 17280, 135, 17280, 270, 135, 270, 17280, 135, 270, 17280, 17280, 270, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 270, 270, 270, 135, 270, 135, 17280, 135, 17280, 270, 17280, 17280, 135, 17280, 135, 17280, 270, 135, 135, 270, 270, 17280, 270, 17280, 17280, 17280, 135, 270, 270, 135, 17280, 270, 17280, 17280, 270, 135, 270, 270, 270, 135, 17280, 270, 17280, 135, 17280, 135, 135, 270, 17280, 17280, 270, 135, 270, 135, 270, 17280, 17280, 270, 135, 270, 135, 17280, 135, 135, 135, 135, 17280, 270, 270, 17280, 270, 270, 135, 270, 17280, 270, 135, 135, 270, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 270, 17280, 270, 270, 270, 135, 17280, 135, 17280, 270, 135, 270, 135, 135, 270, 135, 270, 17280, 17280, 17280, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 135, 135, 17280, 270, 17280, 270, 17280, 270, 135, 270, 135, 135, 135, 17280, 17280, 270, 270, 135, 135, 270, 135, 17280, 135, 135, 270, 135, 17280, 270, 135, 17280, 135, 135, 17280, 270, 17280, 270, 135, 270, 17280, 270, 270, 17280, 270, 135, 270, 135, 17280, 270, 270, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 270, 135, 270, 135, 270, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 270, 270, 17280, 135, 17280, 135, 135, 135, 17280, 270, 17280, 17280, 135, 270, 270, 270, 135, 270, 135, 270, 270, 17280, 135, 135, 270, 135, 270, 270, 135, 17280, 17280, 17280, 135, 270, 270, 270, 270, 135, 270, 135, 17280, 135, 135, 17280, 270, 17280, 270, 270, 270, 270, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 270, 17280, 270, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1892160 . Total input tokens: 421336932 . Total output tokens: 378846953
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 68.44136991677806,
    "estimated_duration": 3600.039048526112,
    "input_throughput": 6239.88426158791,
    "output_throughput": 5519.291244392146,
    "total_throughput": 11759.175505980056,
    "itl": 155.21182806739884,
    "ttft": 1973052.6764221727,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 724,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.364374701399357,
    "arrivals": 630527,
    "finished_requests": 91028,
    "scheduler_time": 167.42081867129025
}
#Debug simulation 
Total elapsed time: 68.44153647404164. Arrivals time: 0.44376259204000235 Scheduler time: 67.8491291385144 Scheduler overhead time: 0.055075402837246656 Adapter cache time: 0.018880778457969427 Engine time: 0.05330044636502862 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-16/adapters_320_slots_64_rate_1.6-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-16/adapters_320_slots_64_rate_1.6-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [106 107 107]
Adapter prompts. [270, 17280, 17280, 135, 17280, 17280, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 17280, 17280, 270, 135, 135, 270, 17280, 17280, 270, 270, 135, 135, 270, 17280, 17280, 135, 17280, 270, 135, 270, 17280, 135, 270, 17280, 17280, 270, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 270, 270, 270, 135, 270, 135, 17280, 135, 17280, 270, 17280, 17280, 135, 17280, 135, 17280, 270, 135, 135, 270, 270, 17280, 270, 17280, 17280, 17280, 135, 270, 270, 135, 17280, 270, 17280, 17280, 270, 135, 270, 270, 270, 135, 17280, 270, 17280, 135, 17280, 135, 135, 270, 17280, 17280, 270, 135, 270, 135, 270, 17280, 17280, 270, 135, 270, 135, 17280, 135, 135, 135, 135, 17280, 270, 270, 17280, 270, 270, 135, 270, 17280, 270, 135, 135, 270, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 270, 17280, 270, 270, 270, 135, 17280, 135, 17280, 270, 135, 270, 135, 135, 270, 135, 270, 17280, 17280, 17280, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 135, 135, 17280, 270, 17280, 270, 17280, 270, 135, 270, 135, 135, 135, 17280, 17280, 270, 270, 135, 135, 270, 135, 17280, 135, 135, 270, 135, 17280, 270, 135, 17280, 135, 135, 17280, 270, 17280, 270, 135, 270, 17280, 270, 270, 17280, 270, 135, 270, 135, 17280, 270, 270, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 270, 135, 270, 135, 270, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 270, 270, 17280, 135, 17280, 135, 135, 135, 17280, 270, 17280, 17280, 135, 270, 270, 270, 135, 270, 135, 270, 270, 17280, 135, 135, 270, 135, 270, 270, 135, 17280, 17280, 17280, 135, 270, 270, 270, 270, 135, 270, 135, 17280, 135, 135, 17280, 270, 17280, 270, 270, 270, 270, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 270, 17280, 270, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1892160 . Total input tokens: 421336932 . Total output tokens: 378846953
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 67.63453997625038,
    "estimated_duration": 3600.1551026622124,
    "input_throughput": 6238.524552287128,
    "output_throughput": 5520.252720585265,
    "total_throughput": 11758.777272872394,
    "itl": 155.24167435223038,
    "ttft": 1973301.3119271386,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 725,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2605376010900162,
    "arrivals": 630527,
    "finished_requests": 91050,
    "scheduler_time": 167.418184789737
}
#Debug simulation 
Total elapsed time: 67.63470346992835. Arrivals time: 0.43959243781864643 Scheduler time: 67.04793275566772 Scheduler overhead time: 0.0541396290063858 Adapter cache time: 0.019103293772786856 Engine time: 0.053112360648810863 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-32/adapters_320_slots_64_rate_1.6-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-32/adapters_320_slots_64_rate_1.6-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [106 107 107]
Adapter prompts. [270, 17280, 17280, 135, 17280, 17280, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 17280, 17280, 270, 135, 135, 270, 17280, 17280, 270, 270, 135, 135, 270, 17280, 17280, 135, 17280, 270, 135, 270, 17280, 135, 270, 17280, 17280, 270, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 270, 270, 270, 135, 270, 135, 17280, 135, 17280, 270, 17280, 17280, 135, 17280, 135, 17280, 270, 135, 135, 270, 270, 17280, 270, 17280, 17280, 17280, 135, 270, 270, 135, 17280, 270, 17280, 17280, 270, 135, 270, 270, 270, 135, 17280, 270, 17280, 135, 17280, 135, 135, 270, 17280, 17280, 270, 135, 270, 135, 270, 17280, 17280, 270, 135, 270, 135, 17280, 135, 135, 135, 135, 17280, 270, 270, 17280, 270, 270, 135, 270, 17280, 270, 135, 135, 270, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 270, 17280, 270, 270, 270, 135, 17280, 135, 17280, 270, 135, 270, 135, 135, 270, 135, 270, 17280, 17280, 17280, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 135, 135, 17280, 270, 17280, 270, 17280, 270, 135, 270, 135, 135, 135, 17280, 17280, 270, 270, 135, 135, 270, 135, 17280, 135, 135, 270, 135, 17280, 270, 135, 17280, 135, 135, 17280, 270, 17280, 270, 135, 270, 17280, 270, 270, 17280, 270, 135, 270, 135, 17280, 270, 270, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 270, 135, 270, 135, 270, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 270, 270, 17280, 135, 17280, 135, 135, 135, 17280, 270, 17280, 17280, 135, 270, 270, 270, 135, 270, 135, 270, 270, 17280, 135, 135, 270, 135, 270, 270, 135, 17280, 17280, 17280, 135, 270, 270, 270, 270, 135, 270, 135, 17280, 135, 135, 17280, 270, 17280, 270, 270, 270, 270, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 270, 17280, 270, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1892160 . Total input tokens: 421336932 . Total output tokens: 378846953
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 67.50810677697882,
    "estimated_duration": 3600.0947462987197,
    "input_throughput": 6239.979662506359,
    "output_throughput": 5518.948916671478,
    "total_throughput": 11758.928579177837,
    "itl": 155.22954673737428,
    "ttft": 1973142.386384215,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 719,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.378194807432595,
    "arrivals": 630527,
    "finished_requests": 91037,
    "scheduler_time": 167.419327554842
}
#Debug simulation 
Total elapsed time: 67.50826812488958. Arrivals time: 0.45229706261307 Scheduler time: 66.90823718113825 Scheduler overhead time: 0.0540455156005919 Adapter cache time: 0.019269925076514482 Engine time: 0.05322995921596885 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-16/adapters_320_slots_64_rate_1.6-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-16/adapters_320_slots_64_rate_1.6-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [106 107 107]
Adapter prompts. [270, 17280, 17280, 135, 17280, 17280, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 17280, 17280, 270, 135, 135, 270, 17280, 17280, 270, 270, 135, 135, 270, 17280, 17280, 135, 17280, 270, 135, 270, 17280, 135, 270, 17280, 17280, 270, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 270, 270, 270, 135, 270, 135, 17280, 135, 17280, 270, 17280, 17280, 135, 17280, 135, 17280, 270, 135, 135, 270, 270, 17280, 270, 17280, 17280, 17280, 135, 270, 270, 135, 17280, 270, 17280, 17280, 270, 135, 270, 270, 270, 135, 17280, 270, 17280, 135, 17280, 135, 135, 270, 17280, 17280, 270, 135, 270, 135, 270, 17280, 17280, 270, 135, 270, 135, 17280, 135, 135, 135, 135, 17280, 270, 270, 17280, 270, 270, 135, 270, 17280, 270, 135, 135, 270, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 270, 17280, 270, 270, 270, 135, 17280, 135, 17280, 270, 135, 270, 135, 135, 270, 135, 270, 17280, 17280, 17280, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 135, 135, 17280, 270, 17280, 270, 17280, 270, 135, 270, 135, 135, 135, 17280, 17280, 270, 270, 135, 135, 270, 135, 17280, 135, 135, 270, 135, 17280, 270, 135, 17280, 135, 135, 17280, 270, 17280, 270, 135, 270, 17280, 270, 270, 17280, 270, 135, 270, 135, 17280, 270, 270, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 270, 135, 270, 135, 270, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 270, 270, 17280, 135, 17280, 135, 135, 135, 17280, 270, 17280, 17280, 135, 270, 270, 270, 135, 270, 135, 270, 270, 17280, 135, 135, 270, 135, 270, 270, 135, 17280, 17280, 17280, 135, 270, 270, 270, 270, 135, 270, 135, 17280, 135, 135, 17280, 270, 17280, 270, 270, 270, 270, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 270, 17280, 270, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1892160 . Total input tokens: 421336932 . Total output tokens: 378846953
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 70.53974175686017,
    "estimated_duration": 3600.0017069965756,
    "input_throughput": 6239.396485936546,
    "output_throughput": 5519.683771644084,
    "total_throughput": 11759.08025758063,
    "itl": 155.24634298848878,
    "ttft": 1972215.610704977,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 694,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0750949046620732,
    "arrivals": 630527,
    "finished_requests": 91070,
    "scheduler_time": 167.42132011528975
}
#Debug simulation 
Total elapsed time: 70.53989800997078. Arrivals time: 0.4378360523842275 Scheduler time: 69.95362185314298 Scheduler overhead time: 0.05506238341331482 Adapter cache time: 0.018737405072897673 Engine time: 0.05360582144930959 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-32/adapters_320_slots_64_rate_1.6-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-32/adapters_320_slots_64_rate_1.6-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [106 107 107]
Adapter prompts. [270, 17280, 17280, 135, 17280, 17280, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 17280, 17280, 270, 135, 135, 270, 17280, 17280, 270, 270, 135, 135, 270, 17280, 17280, 135, 17280, 270, 135, 270, 17280, 135, 270, 17280, 17280, 270, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 270, 270, 270, 135, 270, 135, 17280, 135, 17280, 270, 17280, 17280, 135, 17280, 135, 17280, 270, 135, 135, 270, 270, 17280, 270, 17280, 17280, 17280, 135, 270, 270, 135, 17280, 270, 17280, 17280, 270, 135, 270, 270, 270, 135, 17280, 270, 17280, 135, 17280, 135, 135, 270, 17280, 17280, 270, 135, 270, 135, 270, 17280, 17280, 270, 135, 270, 135, 17280, 135, 135, 135, 135, 17280, 270, 270, 17280, 270, 270, 135, 270, 17280, 270, 135, 135, 270, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 270, 17280, 270, 270, 270, 135, 17280, 135, 17280, 270, 135, 270, 135, 135, 270, 135, 270, 17280, 17280, 17280, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 135, 135, 17280, 270, 17280, 270, 17280, 270, 135, 270, 135, 135, 135, 17280, 17280, 270, 270, 135, 135, 270, 135, 17280, 135, 135, 270, 135, 17280, 270, 135, 17280, 135, 135, 17280, 270, 17280, 270, 135, 270, 17280, 270, 270, 17280, 270, 135, 270, 135, 17280, 270, 270, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 270, 135, 270, 135, 270, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 270, 270, 17280, 135, 17280, 135, 135, 135, 17280, 270, 17280, 17280, 135, 270, 270, 270, 135, 270, 135, 270, 270, 17280, 135, 135, 270, 135, 270, 270, 135, 17280, 17280, 17280, 135, 270, 270, 270, 270, 135, 270, 135, 17280, 135, 135, 17280, 270, 17280, 270, 270, 270, 270, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 270, 17280, 270, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 1892160 . Total input tokens: 421336932 . Total output tokens: 378846953
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 67.2984486236237,
    "estimated_duration": 3600.1258930077975,
    "input_throughput": 6239.925676941139,
    "output_throughput": 5518.9011691478,
    "total_throughput": 11758.826846088938,
    "itl": 155.23074431125605,
    "ttft": 1973153.8156271502,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 719,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4063636555895274,
    "arrivals": 630527,
    "finished_requests": 91037,
    "scheduler_time": 167.41952719035953
}
#Debug simulation 
Total elapsed time: 67.29860918503255. Arrivals time: 0.43202257715165615 Scheduler time: 66.71875413972884 Scheduler overhead time: 0.054229164496064186 Adapter cache time: 0.01900748861953616 Engine time: 0.053618671372532845 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-8/adapters_320_slots_64_rate_1.6-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-8/adapters_320_slots_64_rate_1.6-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [106 107 107]
Adapter prompts. [270, 17280, 17280, 66, 17280, 17280, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 17280, 17280, 270, 66, 66, 270, 17280, 17280, 270, 270, 66, 66, 270, 17280, 17280, 66, 17280, 270, 66, 270, 17280, 66, 270, 17280, 17280, 270, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 270, 270, 270, 66, 270, 66, 17280, 66, 17280, 270, 17280, 17280, 66, 17280, 66, 17280, 270, 66, 66, 270, 270, 17280, 270, 17280, 17280, 17280, 66, 270, 270, 66, 17280, 270, 17280, 17280, 270, 66, 270, 270, 270, 66, 17280, 270, 17280, 66, 17280, 66, 66, 270, 17280, 17280, 270, 66, 270, 66, 270, 17280, 17280, 270, 66, 270, 66, 17280, 66, 66, 66, 66, 17280, 270, 270, 17280, 270, 270, 66, 270, 17280, 270, 66, 66, 270, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 270, 17280, 270, 270, 270, 66, 17280, 66, 17280, 270, 66, 270, 66, 66, 270, 66, 270, 17280, 17280, 17280, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 66, 66, 17280, 270, 17280, 270, 17280, 270, 66, 270, 66, 66, 66, 17280, 17280, 270, 270, 66, 66, 270, 66, 17280, 66, 66, 270, 66, 17280, 270, 66, 17280, 66, 66, 17280, 270, 17280, 270, 66, 270, 17280, 270, 270, 17280, 270, 66, 270, 66, 17280, 270, 270, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 270, 66, 270, 66, 270, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 270, 270, 17280, 66, 17280, 66, 66, 66, 17280, 270, 17280, 17280, 66, 270, 270, 270, 66, 270, 66, 270, 270, 17280, 66, 66, 270, 66, 270, 270, 66, 17280, 17280, 17280, 66, 270, 270, 270, 270, 66, 270, 66, 17280, 66, 66, 17280, 270, 17280, 270, 270, 270, 270, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 270, 17280, 270, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1884846 . Total input tokens: 419763905 . Total output tokens: 377378292
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 64.14523607306182,
    "estimated_duration": 3600.080009903493,
    "input_throughput": 6255.05264828924,
    "output_throughput": 5517.697647095487,
    "total_throughput": 11772.750295384727,
    "itl": 154.90279727545735,
    "ttft": 1974495.6939152803,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 713,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.182127761424093,
    "arrivals": 628242,
    "finished_requests": 91192,
    "scheduler_time": 167.57832062941156
}
#Debug simulation 
Total elapsed time: 64.14539577392861. Arrivals time: 0.74055997421965 Scheduler time: 63.258030608296394 Scheduler overhead time: 0.05377727374434471 Adapter cache time: 0.01858354452997446 Engine time: 0.05344829289242625 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-16/adapters_320_slots_64_rate_1.6-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-16/adapters_320_slots_64_rate_1.6-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [106 107 107]
Adapter prompts. [270, 17280, 17280, 66, 17280, 17280, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 17280, 17280, 270, 66, 66, 270, 17280, 17280, 270, 270, 66, 66, 270, 17280, 17280, 66, 17280, 270, 66, 270, 17280, 66, 270, 17280, 17280, 270, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 270, 270, 270, 66, 270, 66, 17280, 66, 17280, 270, 17280, 17280, 66, 17280, 66, 17280, 270, 66, 66, 270, 270, 17280, 270, 17280, 17280, 17280, 66, 270, 270, 66, 17280, 270, 17280, 17280, 270, 66, 270, 270, 270, 66, 17280, 270, 17280, 66, 17280, 66, 66, 270, 17280, 17280, 270, 66, 270, 66, 270, 17280, 17280, 270, 66, 270, 66, 17280, 66, 66, 66, 66, 17280, 270, 270, 17280, 270, 270, 66, 270, 17280, 270, 66, 66, 270, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 270, 17280, 270, 270, 270, 66, 17280, 66, 17280, 270, 66, 270, 66, 66, 270, 66, 270, 17280, 17280, 17280, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 66, 66, 17280, 270, 17280, 270, 17280, 270, 66, 270, 66, 66, 66, 17280, 17280, 270, 270, 66, 66, 270, 66, 17280, 66, 66, 270, 66, 17280, 270, 66, 17280, 66, 66, 17280, 270, 17280, 270, 66, 270, 17280, 270, 270, 17280, 270, 66, 270, 66, 17280, 270, 270, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 270, 66, 270, 66, 270, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 270, 270, 17280, 66, 17280, 66, 66, 66, 17280, 270, 17280, 17280, 66, 270, 270, 270, 66, 270, 66, 270, 270, 17280, 66, 66, 270, 66, 270, 270, 66, 17280, 17280, 17280, 66, 270, 270, 270, 270, 66, 270, 66, 17280, 66, 66, 17280, 270, 17280, 270, 270, 270, 270, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 270, 17280, 270, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1884846 . Total input tokens: 419763905 . Total output tokens: 377378292
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 64.66785495262593,
    "estimated_duration": 3600.0153307177407,
    "input_throughput": 6256.730022177237,
    "output_throughput": 5517.715113740838,
    "total_throughput": 11774.445135918075,
    "itl": 154.9009950468106,
    "ttft": 1974465.9059502522,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 713,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3280316131166234,
    "arrivals": 628242,
    "finished_requests": 91201,
    "scheduler_time": 167.57442929819365
}
#Debug simulation 
Total elapsed time: 64.66810143506154. Arrivals time: 0.4339945097453892 Scheduler time: 64.08707283390686 Scheduler overhead time: 0.05372187728062272 Adapter cache time: 0.018870015162974596 Engine time: 0.053743809927254915 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-32/adapters_320_slots_64_rate_1.6-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-32/adapters_320_slots_64_rate_1.6-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [106 107 107]
Adapter prompts. [270, 17280, 17280, 66, 17280, 17280, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 17280, 17280, 270, 66, 66, 270, 17280, 17280, 270, 270, 66, 66, 270, 17280, 17280, 66, 17280, 270, 66, 270, 17280, 66, 270, 17280, 17280, 270, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 270, 270, 270, 66, 270, 66, 17280, 66, 17280, 270, 17280, 17280, 66, 17280, 66, 17280, 270, 66, 66, 270, 270, 17280, 270, 17280, 17280, 17280, 66, 270, 270, 66, 17280, 270, 17280, 17280, 270, 66, 270, 270, 270, 66, 17280, 270, 17280, 66, 17280, 66, 66, 270, 17280, 17280, 270, 66, 270, 66, 270, 17280, 17280, 270, 66, 270, 66, 17280, 66, 66, 66, 66, 17280, 270, 270, 17280, 270, 270, 66, 270, 17280, 270, 66, 66, 270, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 270, 17280, 270, 270, 270, 66, 17280, 66, 17280, 270, 66, 270, 66, 66, 270, 66, 270, 17280, 17280, 17280, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 66, 66, 17280, 270, 17280, 270, 17280, 270, 66, 270, 66, 66, 66, 17280, 17280, 270, 270, 66, 66, 270, 66, 17280, 66, 66, 270, 66, 17280, 270, 66, 17280, 66, 66, 17280, 270, 17280, 270, 66, 270, 17280, 270, 270, 17280, 270, 66, 270, 66, 17280, 270, 270, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 270, 66, 270, 66, 270, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 270, 270, 17280, 66, 17280, 66, 66, 66, 17280, 270, 17280, 17280, 66, 270, 270, 270, 66, 270, 66, 270, 270, 17280, 66, 66, 270, 66, 270, 270, 66, 17280, 17280, 17280, 66, 270, 270, 270, 270, 66, 270, 66, 17280, 66, 66, 17280, 270, 17280, 270, 270, 270, 270, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 270, 17280, 270, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1884846 . Total input tokens: 419763905 . Total output tokens: 377378292
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 63.9486397318542,
    "estimated_duration": 3600.0193815447465,
    "input_throughput": 6256.722981956545,
    "output_throughput": 5517.708905077211,
    "total_throughput": 11774.431887033756,
    "itl": 154.9011358869897,
    "ttft": 1974467.3110997947,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 713,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3319077365472927,
    "arrivals": 628242,
    "finished_requests": 91201,
    "scheduler_time": 167.57446476379636
}
#Debug simulation 
Total elapsed time: 63.94879937497899. Arrivals time: 0.447809393517673 Scheduler time: 63.353722552768886 Scheduler overhead time: 0.054181650280952454 Adapter cache time: 0.018876547925174236 Engine time: 0.05344152683392167 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-16/adapters_320_slots_64_rate_1.6-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-16/adapters_320_slots_64_rate_1.6-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [106 107 107]
Adapter prompts. [270, 17280, 17280, 66, 17280, 17280, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 17280, 17280, 270, 66, 66, 270, 17280, 17280, 270, 270, 66, 66, 270, 17280, 17280, 66, 17280, 270, 66, 270, 17280, 66, 270, 17280, 17280, 270, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 270, 270, 270, 66, 270, 66, 17280, 66, 17280, 270, 17280, 17280, 66, 17280, 66, 17280, 270, 66, 66, 270, 270, 17280, 270, 17280, 17280, 17280, 66, 270, 270, 66, 17280, 270, 17280, 17280, 270, 66, 270, 270, 270, 66, 17280, 270, 17280, 66, 17280, 66, 66, 270, 17280, 17280, 270, 66, 270, 66, 270, 17280, 17280, 270, 66, 270, 66, 17280, 66, 66, 66, 66, 17280, 270, 270, 17280, 270, 270, 66, 270, 17280, 270, 66, 66, 270, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 270, 17280, 270, 270, 270, 66, 17280, 66, 17280, 270, 66, 270, 66, 66, 270, 66, 270, 17280, 17280, 17280, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 66, 66, 17280, 270, 17280, 270, 17280, 270, 66, 270, 66, 66, 66, 17280, 17280, 270, 270, 66, 66, 270, 66, 17280, 66, 66, 270, 66, 17280, 270, 66, 17280, 66, 66, 17280, 270, 17280, 270, 66, 270, 17280, 270, 270, 17280, 270, 66, 270, 66, 17280, 270, 270, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 270, 66, 270, 66, 270, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 270, 270, 17280, 66, 17280, 66, 66, 66, 17280, 270, 17280, 17280, 66, 270, 270, 270, 66, 270, 66, 270, 270, 17280, 66, 66, 270, 66, 270, 270, 66, 17280, 17280, 17280, 66, 270, 270, 270, 270, 66, 270, 66, 17280, 66, 66, 17280, 270, 17280, 270, 270, 270, 270, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 270, 17280, 270, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1884846 . Total input tokens: 419763905 . Total output tokens: 377378292
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 64.12768787518144,
    "estimated_duration": 3600.117424030918,
    "input_throughput": 6256.360653586995,
    "output_throughput": 5518.532775454654,
    "total_throughput": 11774.89342904165,
    "itl": 154.90017970807827,
    "ttft": 1974287.0226486071,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 711,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2280745892855176,
    "arrivals": 628242,
    "finished_requests": 91207,
    "scheduler_time": 167.5786159992295
}
#Debug simulation 
Total elapsed time: 64.12786424905062. Arrivals time: 0.4367779637686908 Scheduler time: 63.54476149054244 Scheduler overhead time: 0.05388948833569884 Adapter cache time: 0.018635366577655077 Engine time: 0.053274755366146564 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-32/adapters_320_slots_64_rate_1.6-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-32/adapters_320_slots_64_rate_1.6-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [106 107 107]
Adapter prompts. [270, 17280, 17280, 66, 17280, 17280, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 17280, 17280, 270, 66, 66, 270, 17280, 17280, 270, 270, 66, 66, 270, 17280, 17280, 66, 17280, 270, 66, 270, 17280, 66, 270, 17280, 17280, 270, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 270, 270, 270, 66, 270, 66, 17280, 66, 17280, 270, 17280, 17280, 66, 17280, 66, 17280, 270, 66, 66, 270, 270, 17280, 270, 17280, 17280, 17280, 66, 270, 270, 66, 17280, 270, 17280, 17280, 270, 66, 270, 270, 270, 66, 17280, 270, 17280, 66, 17280, 66, 66, 270, 17280, 17280, 270, 66, 270, 66, 270, 17280, 17280, 270, 66, 270, 66, 17280, 66, 66, 66, 66, 17280, 270, 270, 17280, 270, 270, 66, 270, 17280, 270, 66, 66, 270, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 270, 17280, 270, 270, 270, 66, 17280, 66, 17280, 270, 66, 270, 66, 66, 270, 66, 270, 17280, 17280, 17280, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 66, 66, 17280, 270, 17280, 270, 17280, 270, 66, 270, 66, 66, 66, 17280, 17280, 270, 270, 66, 66, 270, 66, 17280, 66, 66, 270, 66, 17280, 270, 66, 17280, 66, 66, 17280, 270, 17280, 270, 66, 270, 17280, 270, 270, 17280, 270, 66, 270, 66, 17280, 270, 270, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 270, 66, 270, 66, 270, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 270, 270, 17280, 66, 17280, 66, 66, 66, 17280, 270, 17280, 17280, 66, 270, 270, 270, 66, 270, 66, 270, 270, 17280, 66, 66, 270, 66, 270, 270, 66, 17280, 17280, 17280, 66, 270, 270, 270, 270, 66, 270, 66, 17280, 66, 66, 17280, 270, 17280, 270, 270, 270, 270, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 270, 17280, 270, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1884846 . Total input tokens: 419763905 . Total output tokens: 377378292
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 64.0009392737411,
    "estimated_duration": 3600.0482442601347,
    "input_throughput": 6256.672819846917,
    "output_throughput": 5517.6646678751185,
    "total_throughput": 11774.337487722036,
    "itl": 154.9022829090053,
    "ttft": 1974476.9566955334,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 713,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3607053536362956,
    "arrivals": 628242,
    "finished_requests": 91201,
    "scheduler_time": 167.57452986212786
}
#Debug simulation 
Total elapsed time: 64.00111695285887. Arrivals time: 0.44578657764941454 Scheduler time: 63.407704623416066 Scheduler overhead time: 0.05448287073522806 Adapter cache time: 0.018532152753323317 Engine time: 0.0535742761567235 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-16/adapters_320_slots_64_rate_1.6-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-16/adapters_320_slots_64_rate_1.6-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [106 107 107]
Adapter prompts. [270, 17280, 17280, 66, 17280, 17280, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 17280, 17280, 270, 66, 66, 270, 17280, 17280, 270, 270, 66, 66, 270, 17280, 17280, 66, 17280, 270, 66, 270, 17280, 66, 270, 17280, 17280, 270, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 270, 270, 270, 66, 270, 66, 17280, 66, 17280, 270, 17280, 17280, 66, 17280, 66, 17280, 270, 66, 66, 270, 270, 17280, 270, 17280, 17280, 17280, 66, 270, 270, 66, 17280, 270, 17280, 17280, 270, 66, 270, 270, 270, 66, 17280, 270, 17280, 66, 17280, 66, 66, 270, 17280, 17280, 270, 66, 270, 66, 270, 17280, 17280, 270, 66, 270, 66, 17280, 66, 66, 66, 66, 17280, 270, 270, 17280, 270, 270, 66, 270, 17280, 270, 66, 66, 270, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 270, 17280, 270, 270, 270, 66, 17280, 66, 17280, 270, 66, 270, 66, 66, 270, 66, 270, 17280, 17280, 17280, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 66, 66, 17280, 270, 17280, 270, 17280, 270, 66, 270, 66, 66, 66, 17280, 17280, 270, 270, 66, 66, 270, 66, 17280, 66, 66, 270, 66, 17280, 270, 66, 17280, 66, 66, 17280, 270, 17280, 270, 66, 270, 17280, 270, 270, 17280, 270, 66, 270, 66, 17280, 270, 270, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 270, 66, 270, 66, 270, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 270, 270, 17280, 66, 17280, 66, 66, 66, 17280, 270, 17280, 17280, 66, 270, 270, 270, 66, 270, 66, 270, 270, 17280, 66, 66, 270, 66, 270, 270, 66, 17280, 17280, 17280, 66, 270, 270, 270, 270, 66, 270, 66, 17280, 66, 66, 17280, 270, 17280, 270, 270, 270, 270, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 270, 17280, 270, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1884846 . Total input tokens: 419763905 . Total output tokens: 377378292
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 63.79016398778185,
    "estimated_duration": 3600.0291416806062,
    "input_throughput": 6255.141031854973,
    "output_throughput": 5517.77561187374,
    "total_throughput": 11772.916643728713,
    "itl": 154.90064022987949,
    "ttft": 1974465.5538359303,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 713,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1319058602652126,
    "arrivals": 628242,
    "finished_requests": 91192,
    "scheduler_time": 167.5780920213356
}
#Debug simulation 
Total elapsed time: 63.790334458928555. Arrivals time: 0.4406819068826735 Scheduler time: 63.203190085012466 Scheduler overhead time: 0.05338768847286701 Adapter cache time: 0.018823214806616306 Engine time: 0.05320118507370353 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-32/adapters_320_slots_64_rate_1.6-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-32/adapters_320_slots_64_rate_1.6-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [106 107 107]
Adapter prompts. [270, 17280, 17280, 66, 17280, 17280, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 17280, 17280, 270, 66, 66, 270, 17280, 17280, 270, 270, 66, 66, 270, 17280, 17280, 66, 17280, 270, 66, 270, 17280, 66, 270, 17280, 17280, 270, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 270, 270, 270, 66, 270, 66, 17280, 66, 17280, 270, 17280, 17280, 66, 17280, 66, 17280, 270, 66, 66, 270, 270, 17280, 270, 17280, 17280, 17280, 66, 270, 270, 66, 17280, 270, 17280, 17280, 270, 66, 270, 270, 270, 66, 17280, 270, 17280, 66, 17280, 66, 66, 270, 17280, 17280, 270, 66, 270, 66, 270, 17280, 17280, 270, 66, 270, 66, 17280, 66, 66, 66, 66, 17280, 270, 270, 17280, 270, 270, 66, 270, 17280, 270, 66, 66, 270, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 270, 17280, 270, 270, 270, 66, 17280, 66, 17280, 270, 66, 270, 66, 66, 270, 66, 270, 17280, 17280, 17280, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 66, 66, 17280, 270, 17280, 270, 17280, 270, 66, 270, 66, 66, 66, 17280, 17280, 270, 270, 66, 66, 270, 66, 17280, 66, 66, 270, 66, 17280, 270, 66, 17280, 66, 66, 17280, 270, 17280, 270, 66, 270, 17280, 270, 270, 17280, 270, 66, 270, 66, 17280, 270, 270, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 270, 66, 270, 66, 270, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 270, 270, 17280, 66, 17280, 66, 66, 66, 17280, 270, 17280, 17280, 66, 270, 270, 270, 66, 270, 66, 270, 270, 17280, 66, 66, 270, 66, 270, 270, 66, 17280, 17280, 17280, 66, 270, 270, 270, 270, 66, 270, 66, 17280, 66, 66, 17280, 270, 17280, 270, 270, 270, 270, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 270, 17280, 270, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1884846 . Total input tokens: 419763905 . Total output tokens: 377378292
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 63.41897841496393,
    "estimated_duration": 3600.0492616289307,
    "input_throughput": 6254.770244396993,
    "output_throughput": 5517.502277458384,
    "total_throughput": 11772.272521855377,
    "itl": 154.92195741860388,
    "ttft": 1974520.8001995336,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 716,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4023261131346296,
    "arrivals": 628242,
    "finished_requests": 91185,
    "scheduler_time": 167.5673194051406
}
#Debug simulation 
Total elapsed time: 63.41915515484288. Arrivals time: 0.441407036036253 Scheduler time: 62.83136001601815 Scheduler overhead time: 0.05357995117083192 Adapter cache time: 0.018607059493660927 Engine time: 0.05326498951762915 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-8/adapters_320_slots_64_rate_1.6-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-8/adapters_320_slots_64_rate_1.6-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [106 107 107]
Adapter prompts. [270, 17280, 17280, 33, 17280, 17280, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 17280, 17280, 270, 33, 33, 270, 17280, 17280, 270, 270, 33, 33, 270, 17280, 17280, 33, 17280, 270, 33, 270, 17280, 33, 270, 17280, 17280, 270, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 270, 270, 270, 33, 270, 33, 17280, 33, 17280, 270, 17280, 17280, 33, 17280, 33, 17280, 270, 33, 33, 270, 270, 17280, 270, 17280, 17280, 17280, 33, 270, 270, 33, 17280, 270, 17280, 17280, 270, 33, 270, 270, 270, 33, 17280, 270, 17280, 33, 17280, 33, 33, 270, 17280, 17280, 270, 33, 270, 33, 270, 17280, 17280, 270, 33, 270, 33, 17280, 33, 33, 33, 33, 17280, 270, 270, 17280, 270, 270, 33, 270, 17280, 270, 33, 33, 270, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 270, 17280, 270, 270, 270, 33, 17280, 33, 17280, 270, 33, 270, 33, 33, 270, 33, 270, 17280, 17280, 17280, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 33, 33, 17280, 270, 17280, 270, 17280, 270, 33, 270, 33, 33, 33, 17280, 17280, 270, 270, 33, 33, 270, 33, 17280, 33, 33, 270, 33, 17280, 270, 33, 17280, 33, 33, 17280, 270, 17280, 270, 33, 270, 17280, 270, 270, 17280, 270, 33, 270, 33, 17280, 270, 270, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 270, 33, 270, 33, 270, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 270, 270, 17280, 33, 17280, 33, 33, 33, 17280, 270, 17280, 17280, 33, 270, 270, 270, 33, 270, 33, 270, 270, 17280, 33, 33, 270, 33, 270, 270, 33, 17280, 17280, 17280, 33, 270, 270, 270, 270, 33, 270, 33, 17280, 33, 33, 17280, 270, 17280, 270, 270, 270, 270, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 270, 17280, 270, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1881348 . Total input tokens: 418999621 . Total output tokens: 376682735
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 61.64299148414284,
    "estimated_duration": 3600.0695854455466,
    "input_throughput": 6231.775655309578,
    "output_throughput": 5520.282463523676,
    "total_throughput": 11752.058118833253,
    "itl": 155.47428112897833,
    "ttft": 1980448.3266770965,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 687,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1025550800818387,
    "arrivals": 627073,
    "finished_requests": 90680,
    "scheduler_time": 167.53332832837606
}
#Debug simulation 
Total elapsed time: 61.64316290197894. Arrivals time: 0.4626577524468303 Scheduler time: 61.03558305604383 Scheduler overhead time: 0.05333223473280668 Adapter cache time: 0.017930911388248205 Engine time: 0.052700305823236704 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-16/adapters_320_slots_64_rate_1.6-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-16/adapters_320_slots_64_rate_1.6-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [106 107 107]
Adapter prompts. [270, 17280, 17280, 33, 17280, 17280, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 17280, 17280, 270, 33, 33, 270, 17280, 17280, 270, 270, 33, 33, 270, 17280, 17280, 33, 17280, 270, 33, 270, 17280, 33, 270, 17280, 17280, 270, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 270, 270, 270, 33, 270, 33, 17280, 33, 17280, 270, 17280, 17280, 33, 17280, 33, 17280, 270, 33, 33, 270, 270, 17280, 270, 17280, 17280, 17280, 33, 270, 270, 33, 17280, 270, 17280, 17280, 270, 33, 270, 270, 270, 33, 17280, 270, 17280, 33, 17280, 33, 33, 270, 17280, 17280, 270, 33, 270, 33, 270, 17280, 17280, 270, 33, 270, 33, 17280, 33, 33, 33, 33, 17280, 270, 270, 17280, 270, 270, 33, 270, 17280, 270, 33, 33, 270, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 270, 17280, 270, 270, 270, 33, 17280, 33, 17280, 270, 33, 270, 33, 33, 270, 33, 270, 17280, 17280, 17280, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 33, 33, 17280, 270, 17280, 270, 17280, 270, 33, 270, 33, 33, 33, 17280, 17280, 270, 270, 33, 33, 270, 33, 17280, 33, 33, 270, 33, 17280, 270, 33, 17280, 33, 33, 17280, 270, 17280, 270, 33, 270, 17280, 270, 270, 17280, 270, 33, 270, 33, 17280, 270, 270, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 270, 33, 270, 33, 270, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 270, 270, 17280, 33, 17280, 33, 33, 33, 17280, 270, 17280, 17280, 33, 270, 270, 270, 33, 270, 33, 270, 270, 17280, 33, 33, 270, 33, 270, 270, 33, 17280, 17280, 17280, 33, 270, 270, 270, 270, 33, 270, 33, 17280, 33, 33, 17280, 270, 17280, 270, 270, 270, 270, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 270, 17280, 270, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1881348 . Total input tokens: 418999621 . Total output tokens: 376682735
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 61.94547100691125,
    "estimated_duration": 3600.040786327454,
    "input_throughput": 6230.496355815398,
    "output_throughput": 5520.196347628932,
    "total_throughput": 11750.692703444329,
    "itl": 155.47905196802563,
    "ttft": 1980321.8489494682,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 688,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2471514259674645,
    "arrivals": 627073,
    "finished_requests": 90672,
    "scheduler_time": 167.52654334919288
}
#Debug simulation 
Total elapsed time: 61.945640734862536. Arrivals time: 0.4365154239349067 Scheduler time: 61.36175962910056 Scheduler overhead time: 0.05453666904941201 Adapter cache time: 0.018162252381443977 Engine time: 0.053908262867480516 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-32/adapters_320_slots_64_rate_1.6-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-32/adapters_320_slots_64_rate_1.6-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [106 107 107]
Adapter prompts. [270, 17280, 17280, 33, 17280, 17280, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 17280, 17280, 270, 33, 33, 270, 17280, 17280, 270, 270, 33, 33, 270, 17280, 17280, 33, 17280, 270, 33, 270, 17280, 33, 270, 17280, 17280, 270, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 270, 270, 270, 33, 270, 33, 17280, 33, 17280, 270, 17280, 17280, 33, 17280, 33, 17280, 270, 33, 33, 270, 270, 17280, 270, 17280, 17280, 17280, 33, 270, 270, 33, 17280, 270, 17280, 17280, 270, 33, 270, 270, 270, 33, 17280, 270, 17280, 33, 17280, 33, 33, 270, 17280, 17280, 270, 33, 270, 33, 270, 17280, 17280, 270, 33, 270, 33, 17280, 33, 33, 33, 33, 17280, 270, 270, 17280, 270, 270, 33, 270, 17280, 270, 33, 33, 270, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 270, 17280, 270, 270, 270, 33, 17280, 33, 17280, 270, 33, 270, 33, 33, 270, 33, 270, 17280, 17280, 17280, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 33, 33, 17280, 270, 17280, 270, 17280, 270, 33, 270, 33, 33, 33, 17280, 17280, 270, 270, 33, 33, 270, 33, 17280, 33, 33, 270, 33, 17280, 270, 33, 17280, 33, 33, 17280, 270, 17280, 270, 33, 270, 17280, 270, 270, 17280, 270, 33, 270, 33, 17280, 270, 270, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 270, 33, 270, 33, 270, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 270, 270, 17280, 33, 17280, 33, 33, 33, 17280, 270, 17280, 17280, 33, 270, 270, 270, 33, 270, 33, 270, 270, 17280, 33, 33, 270, 33, 270, 270, 33, 17280, 17280, 17280, 33, 270, 270, 270, 270, 33, 270, 33, 17280, 33, 33, 17280, 270, 17280, 270, 270, 270, 270, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 270, 17280, 270, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1881348 . Total input tokens: 418999621 . Total output tokens: 376682735
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 61.840198741760105,
    "estimated_duration": 3600.0444171330905,
    "input_throughput": 6230.4900720814585,
    "output_throughput": 5520.190780264285,
    "total_throughput": 11750.680852345744,
    "itl": 155.4791741712615,
    "ttft": 1980323.1527260158,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 688,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2507610529102418,
    "arrivals": 627073,
    "finished_requests": 90672,
    "scheduler_time": 167.52656452785007
}
#Debug simulation 
Total elapsed time: 61.84036432998255. Arrivals time: 0.43052536994218826 Scheduler time: 61.263269453309476 Scheduler overhead time: 0.05394653882831335 Adapter cache time: 0.018180981278419495 Engine time: 0.05354305217042565 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-16/adapters_320_slots_64_rate_1.6-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-16/adapters_320_slots_64_rate_1.6-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [106 107 107]
Adapter prompts. [270, 17280, 17280, 33, 17280, 17280, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 17280, 17280, 270, 33, 33, 270, 17280, 17280, 270, 270, 33, 33, 270, 17280, 17280, 33, 17280, 270, 33, 270, 17280, 33, 270, 17280, 17280, 270, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 270, 270, 270, 33, 270, 33, 17280, 33, 17280, 270, 17280, 17280, 33, 17280, 33, 17280, 270, 33, 33, 270, 270, 17280, 270, 17280, 17280, 17280, 33, 270, 270, 33, 17280, 270, 17280, 17280, 270, 33, 270, 270, 270, 33, 17280, 270, 17280, 33, 17280, 33, 33, 270, 17280, 17280, 270, 33, 270, 33, 270, 17280, 17280, 270, 33, 270, 33, 17280, 33, 33, 33, 33, 17280, 270, 270, 17280, 270, 270, 33, 270, 17280, 270, 33, 33, 270, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 270, 17280, 270, 270, 270, 33, 17280, 33, 17280, 270, 33, 270, 33, 33, 270, 33, 270, 17280, 17280, 17280, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 33, 33, 17280, 270, 17280, 270, 17280, 270, 33, 270, 33, 33, 33, 17280, 17280, 270, 270, 33, 33, 270, 33, 17280, 33, 33, 270, 33, 17280, 270, 33, 17280, 33, 33, 17280, 270, 17280, 270, 33, 270, 17280, 270, 270, 17280, 270, 33, 270, 33, 17280, 270, 270, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 270, 33, 270, 33, 270, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 270, 270, 17280, 33, 17280, 33, 33, 33, 17280, 270, 17280, 17280, 33, 270, 270, 270, 33, 270, 33, 270, 270, 17280, 33, 33, 270, 33, 270, 270, 33, 17280, 17280, 17280, 33, 270, 270, 270, 270, 33, 270, 33, 17280, 33, 33, 17280, 270, 17280, 270, 270, 270, 270, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 270, 17280, 270, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1881348 . Total input tokens: 418999621 . Total output tokens: 376682735
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 62.01027639117092,
    "estimated_duration": 3600.105731037187,
    "input_throughput": 6230.8406129887335,
    "output_throughput": 5520.722857846172,
    "total_throughput": 11751.563470834904,
    "itl": 155.47801611762068,
    "ttft": 1980273.8217076277,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 688,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1499057401786397,
    "arrivals": 627073,
    "finished_requests": 90679,
    "scheduler_time": 167.53367728742396
}
#Debug simulation 
Total elapsed time: 62.01052301330492. Arrivals time: 0.439353808760643 Scheduler time: 61.42466460587457 Scheduler overhead time: 0.054039116483181715 Adapter cache time: 0.018089048098772764 Engine time: 0.05356309562921524 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-32/adapters_320_slots_64_rate_1.6-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-32/adapters_320_slots_64_rate_1.6-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [106 107 107]
Adapter prompts. [270, 17280, 17280, 33, 17280, 17280, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 17280, 17280, 270, 33, 33, 270, 17280, 17280, 270, 270, 33, 33, 270, 17280, 17280, 33, 17280, 270, 33, 270, 17280, 33, 270, 17280, 17280, 270, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 270, 270, 270, 33, 270, 33, 17280, 33, 17280, 270, 17280, 17280, 33, 17280, 33, 17280, 270, 33, 33, 270, 270, 17280, 270, 17280, 17280, 17280, 33, 270, 270, 33, 17280, 270, 17280, 17280, 270, 33, 270, 270, 270, 33, 17280, 270, 17280, 33, 17280, 33, 33, 270, 17280, 17280, 270, 33, 270, 33, 270, 17280, 17280, 270, 33, 270, 33, 17280, 33, 33, 33, 33, 17280, 270, 270, 17280, 270, 270, 33, 270, 17280, 270, 33, 33, 270, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 270, 17280, 270, 270, 270, 33, 17280, 33, 17280, 270, 33, 270, 33, 33, 270, 33, 270, 17280, 17280, 17280, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 33, 33, 17280, 270, 17280, 270, 17280, 270, 33, 270, 33, 33, 33, 17280, 17280, 270, 270, 33, 33, 270, 33, 17280, 33, 33, 270, 33, 17280, 270, 33, 17280, 33, 33, 17280, 270, 17280, 270, 33, 270, 17280, 270, 270, 17280, 270, 33, 270, 33, 17280, 270, 270, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 270, 33, 270, 33, 270, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 270, 270, 17280, 33, 17280, 33, 33, 33, 17280, 270, 17280, 17280, 33, 270, 270, 270, 33, 270, 33, 270, 270, 17280, 33, 33, 270, 33, 270, 270, 33, 17280, 17280, 17280, 33, 270, 270, 270, 270, 33, 270, 33, 17280, 33, 33, 17280, 270, 17280, 270, 270, 270, 270, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 270, 17280, 270, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1881348 . Total input tokens: 418999621 . Total output tokens: 376682735
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 61.85353957908228,
    "estimated_duration": 3600.075360545875,
    "input_throughput": 6230.436519695232,
    "output_throughput": 5520.14333305142,
    "total_throughput": 11750.579852746652,
    "itl": 155.4805979809354,
    "ttft": 1980327.644864143,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 688,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.280690454076979,
    "arrivals": 627073,
    "finished_requests": 90672,
    "scheduler_time": 167.52728746636242
}
#Debug simulation 
Total elapsed time: 61.853707394097. Arrivals time: 0.43182612443342805 Scheduler time: 61.27503442345187 Scheduler overhead time: 0.05430912226438522 Adapter cache time: 0.018459205981343985 Engine time: 0.052870430052280426 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-16/adapters_320_slots_64_rate_1.6-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-16/adapters_320_slots_64_rate_1.6-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [106 107 107]
Adapter prompts. [270, 17280, 17280, 33, 17280, 17280, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 17280, 17280, 270, 33, 33, 270, 17280, 17280, 270, 270, 33, 33, 270, 17280, 17280, 33, 17280, 270, 33, 270, 17280, 33, 270, 17280, 17280, 270, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 270, 270, 270, 33, 270, 33, 17280, 33, 17280, 270, 17280, 17280, 33, 17280, 33, 17280, 270, 33, 33, 270, 270, 17280, 270, 17280, 17280, 17280, 33, 270, 270, 33, 17280, 270, 17280, 17280, 270, 33, 270, 270, 270, 33, 17280, 270, 17280, 33, 17280, 33, 33, 270, 17280, 17280, 270, 33, 270, 33, 270, 17280, 17280, 270, 33, 270, 33, 17280, 33, 33, 33, 33, 17280, 270, 270, 17280, 270, 270, 33, 270, 17280, 270, 33, 33, 270, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 270, 17280, 270, 270, 270, 33, 17280, 33, 17280, 270, 33, 270, 33, 33, 270, 33, 270, 17280, 17280, 17280, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 33, 33, 17280, 270, 17280, 270, 17280, 270, 33, 270, 33, 33, 33, 17280, 17280, 270, 270, 33, 33, 270, 33, 17280, 33, 33, 270, 33, 17280, 270, 33, 17280, 33, 33, 17280, 270, 17280, 270, 33, 270, 17280, 270, 270, 17280, 270, 33, 270, 33, 17280, 270, 270, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 270, 33, 270, 33, 270, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 270, 270, 17280, 33, 17280, 33, 33, 33, 17280, 270, 17280, 17280, 33, 270, 270, 270, 33, 270, 33, 270, 270, 17280, 33, 33, 270, 33, 270, 270, 33, 17280, 17280, 17280, 33, 270, 270, 270, 270, 33, 270, 33, 17280, 33, 33, 17280, 270, 17280, 270, 270, 270, 270, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 270, 17280, 270, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1881348 . Total input tokens: 418999621 . Total output tokens: 376682735
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 62.246282261330634,
    "estimated_duration": 3600.159547446653,
    "input_throughput": 6231.338001647946,
    "output_throughput": 5521.329746093578,
    "total_throughput": 11752.667747741523,
    "itl": 155.49667665952407,
    "ttft": 1979487.5604810207,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 691,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.066124753777367,
    "arrivals": 627073,
    "finished_requests": 90666,
    "scheduler_time": 167.53553640504649
}
#Debug simulation 
Total elapsed time: 62.246450113132596. Arrivals time: 0.4356722100637853 Scheduler time: 61.663932183757424 Scheduler overhead time: 0.053788257762789726 Adapter cache time: 0.018506913911551237 Engine time: 0.05335932457819581 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-32/adapters_320_slots_64_rate_1.6-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-32/adapters_320_slots_64_rate_1.6-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [106 107 107]
Adapter prompts. [270, 17280, 17280, 33, 17280, 17280, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 17280, 17280, 270, 33, 33, 270, 17280, 17280, 270, 270, 33, 33, 270, 17280, 17280, 33, 17280, 270, 33, 270, 17280, 33, 270, 17280, 17280, 270, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 270, 270, 270, 33, 270, 33, 17280, 33, 17280, 270, 17280, 17280, 33, 17280, 33, 17280, 270, 33, 33, 270, 270, 17280, 270, 17280, 17280, 17280, 33, 270, 270, 33, 17280, 270, 17280, 17280, 270, 33, 270, 270, 270, 33, 17280, 270, 17280, 33, 17280, 33, 33, 270, 17280, 17280, 270, 33, 270, 33, 270, 17280, 17280, 270, 33, 270, 33, 17280, 33, 33, 33, 33, 17280, 270, 270, 17280, 270, 270, 33, 270, 17280, 270, 33, 33, 270, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 270, 17280, 270, 270, 270, 33, 17280, 33, 17280, 270, 33, 270, 33, 33, 270, 33, 270, 17280, 17280, 17280, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 33, 33, 17280, 270, 17280, 270, 17280, 270, 33, 270, 33, 33, 33, 17280, 17280, 270, 270, 33, 33, 270, 33, 17280, 33, 33, 270, 33, 17280, 270, 33, 17280, 33, 33, 17280, 270, 17280, 270, 33, 270, 17280, 270, 270, 17280, 270, 33, 270, 33, 17280, 270, 270, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 270, 33, 270, 33, 270, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 270, 270, 17280, 33, 17280, 33, 33, 33, 17280, 270, 17280, 17280, 33, 270, 270, 270, 33, 270, 33, 270, 270, 17280, 33, 33, 270, 33, 270, 270, 33, 17280, 17280, 17280, 33, 270, 270, 270, 270, 33, 270, 33, 17280, 33, 33, 17280, 270, 17280, 270, 270, 270, 270, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 270, 17280, 270, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1881348 . Total input tokens: 418999621 . Total output tokens: 376682735
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 62.443881856277585,
    "estimated_duration": 3600.118795857479,
    "input_throughput": 6228.581130656585,
    "output_throughput": 5519.678690288049,
    "total_throughput": 11748.259820944633,
    "itl": 155.51641502857976,
    "ttft": 1980800.6506515734,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 650,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1806188114732508,
    "arrivals": 627073,
    "finished_requests": 90671,
    "scheduler_time": 167.51563200607623
}
#Debug simulation 
Total elapsed time: 62.444042227230966. Arrivals time: 0.46208467660471797 Scheduler time: 61.83723664889112 Scheduler overhead time: 0.05354508804157376 Adapter cache time: 0.017603260464966297 Engine time: 0.052895200438797474 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-8/adapters_320_slots_64_rate_1.6-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-8/adapters_320_slots_64_rate_1.6-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [106 107 107]
Adapter prompts. [135, 17280, 17280, 66, 17280, 17280, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 17280, 17280, 135, 66, 66, 135, 17280, 17280, 135, 135, 66, 66, 135, 17280, 17280, 66, 17280, 135, 66, 135, 17280, 66, 135, 17280, 17280, 135, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 135, 135, 135, 66, 135, 66, 17280, 66, 17280, 135, 17280, 17280, 66, 17280, 66, 17280, 135, 66, 66, 135, 135, 17280, 135, 17280, 17280, 17280, 66, 135, 135, 66, 17280, 135, 17280, 17280, 135, 66, 135, 135, 135, 66, 17280, 135, 17280, 66, 17280, 66, 66, 135, 17280, 17280, 135, 66, 135, 66, 135, 17280, 17280, 135, 66, 135, 66, 17280, 66, 66, 66, 66, 17280, 135, 135, 17280, 135, 135, 66, 135, 17280, 135, 66, 66, 135, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 135, 17280, 135, 135, 135, 66, 17280, 66, 17280, 135, 66, 135, 66, 66, 135, 66, 135, 17280, 17280, 17280, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 66, 66, 17280, 135, 17280, 135, 17280, 135, 66, 135, 66, 66, 66, 17280, 17280, 135, 135, 66, 66, 135, 66, 17280, 66, 66, 135, 66, 17280, 135, 66, 17280, 66, 66, 17280, 135, 17280, 135, 66, 135, 17280, 135, 135, 17280, 135, 66, 135, 66, 17280, 135, 135, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 135, 66, 135, 66, 135, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 135, 135, 17280, 66, 17280, 66, 66, 66, 17280, 135, 17280, 17280, 66, 135, 135, 135, 66, 135, 66, 135, 135, 17280, 66, 66, 135, 66, 135, 135, 66, 17280, 17280, 17280, 66, 135, 135, 135, 135, 66, 135, 66, 17280, 66, 66, 17280, 135, 17280, 135, 135, 135, 135, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 135, 17280, 135, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1870401 . Total input tokens: 416565998 . Total output tokens: 374464939
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 84.32982609793544,
    "estimated_duration": 3600.1195319052686,
    "input_throughput": 6230.725897072865,
    "output_throughput": 5524.95044226309,
    "total_throughput": 11755.676339335956,
    "itl": 155.50937207147572,
    "ttft": 1961637.6006473494,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 647,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9801355703245245,
    "arrivals": 623634,
    "finished_requests": 91021,
    "scheduler_time": 167.3075493758196
}
#Debug simulation 
Total elapsed time: 84.3299961797893. Arrivals time: 0.45562616595998406 Scheduler time: 83.71952448459342 Scheduler overhead time: 0.05809034314006567 Adapter cache time: 0.018108217511326075 Engine time: 0.056949676014482975 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-16/adapters_320_slots_64_rate_1.6-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-16/adapters_320_slots_64_rate_1.6-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [106 107 107]
Adapter prompts. [135, 17280, 17280, 66, 17280, 17280, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 17280, 17280, 135, 66, 66, 135, 17280, 17280, 135, 135, 66, 66, 135, 17280, 17280, 66, 17280, 135, 66, 135, 17280, 66, 135, 17280, 17280, 135, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 135, 135, 135, 66, 135, 66, 17280, 66, 17280, 135, 17280, 17280, 66, 17280, 66, 17280, 135, 66, 66, 135, 135, 17280, 135, 17280, 17280, 17280, 66, 135, 135, 66, 17280, 135, 17280, 17280, 135, 66, 135, 135, 135, 66, 17280, 135, 17280, 66, 17280, 66, 66, 135, 17280, 17280, 135, 66, 135, 66, 135, 17280, 17280, 135, 66, 135, 66, 17280, 66, 66, 66, 66, 17280, 135, 135, 17280, 135, 135, 66, 135, 17280, 135, 66, 66, 135, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 135, 17280, 135, 135, 135, 66, 17280, 66, 17280, 135, 66, 135, 66, 66, 135, 66, 135, 17280, 17280, 17280, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 66, 66, 17280, 135, 17280, 135, 17280, 135, 66, 135, 66, 66, 66, 17280, 17280, 135, 135, 66, 66, 135, 66, 17280, 66, 66, 135, 66, 17280, 135, 66, 17280, 66, 66, 17280, 135, 17280, 135, 66, 135, 17280, 135, 135, 17280, 135, 66, 135, 66, 17280, 135, 135, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 135, 66, 135, 66, 135, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 135, 135, 17280, 66, 17280, 66, 66, 66, 17280, 135, 17280, 17280, 66, 135, 135, 135, 66, 135, 66, 135, 135, 17280, 66, 66, 135, 66, 135, 135, 66, 17280, 17280, 17280, 66, 135, 135, 135, 135, 66, 135, 66, 17280, 66, 66, 17280, 135, 17280, 135, 135, 135, 135, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 135, 17280, 135, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1870401 . Total input tokens: 416565998 . Total output tokens: 374464939
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 84.33399849198759,
    "estimated_duration": 3600.0960316205674,
    "input_throughput": 6230.766569274715,
    "output_throughput": 5524.9865073866895,
    "total_throughput": 11755.753076661405,
    "itl": 155.51457154423304,
    "ttft": 1961671.7466008898,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 647,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1118929090048253,
    "arrivals": 623634,
    "finished_requests": 91021,
    "scheduler_time": 167.3015297496487
}
#Debug simulation 
Total elapsed time: 84.33416488021612. Arrivals time: 0.4591128691099584 Scheduler time: 83.71868653781712 Scheduler overhead time: 0.058505862951278687 Adapter cache time: 0.018144508823752403 Engine time: 0.057543289847671986 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-32/adapters_320_slots_64_rate_1.6-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-32/adapters_320_slots_64_rate_1.6-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [106 107 107]
Adapter prompts. [135, 17280, 17280, 66, 17280, 17280, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 17280, 17280, 135, 66, 66, 135, 17280, 17280, 135, 135, 66, 66, 135, 17280, 17280, 66, 17280, 135, 66, 135, 17280, 66, 135, 17280, 17280, 135, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 135, 135, 135, 66, 135, 66, 17280, 66, 17280, 135, 17280, 17280, 66, 17280, 66, 17280, 135, 66, 66, 135, 135, 17280, 135, 17280, 17280, 17280, 66, 135, 135, 66, 17280, 135, 17280, 17280, 135, 66, 135, 135, 135, 66, 17280, 135, 17280, 66, 17280, 66, 66, 135, 17280, 17280, 135, 66, 135, 66, 135, 17280, 17280, 135, 66, 135, 66, 17280, 66, 66, 66, 66, 17280, 135, 135, 17280, 135, 135, 66, 135, 17280, 135, 66, 66, 135, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 135, 17280, 135, 135, 135, 66, 17280, 66, 17280, 135, 66, 135, 66, 66, 135, 66, 135, 17280, 17280, 17280, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 66, 66, 17280, 135, 17280, 135, 17280, 135, 66, 135, 66, 66, 66, 17280, 17280, 135, 135, 66, 66, 135, 66, 17280, 66, 66, 135, 66, 17280, 135, 66, 17280, 66, 66, 17280, 135, 17280, 135, 66, 135, 17280, 135, 135, 17280, 135, 66, 135, 66, 17280, 135, 135, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 135, 66, 135, 66, 135, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 135, 135, 17280, 66, 17280, 66, 66, 66, 17280, 135, 17280, 17280, 66, 135, 135, 135, 66, 135, 66, 135, 135, 17280, 66, 66, 135, 66, 135, 135, 66, 17280, 17280, 17280, 66, 135, 135, 135, 135, 66, 135, 66, 17280, 66, 66, 17280, 135, 17280, 135, 135, 135, 135, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 135, 17280, 135, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1870401 . Total input tokens: 416565998 . Total output tokens: 374464939
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 84.2585673010908,
    "estimated_duration": 3600.099833786949,
    "input_throughput": 6230.75998878743,
    "output_throughput": 5524.980672293518,
    "total_throughput": 11755.740661080948,
    "itl": 155.51469242666872,
    "ttft": 1961673.3790050778,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 647,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.115522107779988,
    "arrivals": 623634,
    "finished_requests": 91021,
    "scheduler_time": 167.3015634792959
}
#Debug simulation 
Total elapsed time: 84.258751551155. Arrivals time: 0.465302134398371 Scheduler time: 83.6360423322767 Scheduler overhead time: 0.05918494425714016 Adapter cache time: 0.017880165483802557 Engine time: 0.05792537843808532 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-16/adapters_320_slots_64_rate_1.6-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-16/adapters_320_slots_64_rate_1.6-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [106 107 107]
Adapter prompts. [135, 17280, 17280, 66, 17280, 17280, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 17280, 17280, 135, 66, 66, 135, 17280, 17280, 135, 135, 66, 66, 135, 17280, 17280, 66, 17280, 135, 66, 135, 17280, 66, 135, 17280, 17280, 135, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 135, 135, 135, 66, 135, 66, 17280, 66, 17280, 135, 17280, 17280, 66, 17280, 66, 17280, 135, 66, 66, 135, 135, 17280, 135, 17280, 17280, 17280, 66, 135, 135, 66, 17280, 135, 17280, 17280, 135, 66, 135, 135, 135, 66, 17280, 135, 17280, 66, 17280, 66, 66, 135, 17280, 17280, 135, 66, 135, 66, 135, 17280, 17280, 135, 66, 135, 66, 17280, 66, 66, 66, 66, 17280, 135, 135, 17280, 135, 135, 66, 135, 17280, 135, 66, 66, 135, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 135, 17280, 135, 135, 135, 66, 17280, 66, 17280, 135, 66, 135, 66, 66, 135, 66, 135, 17280, 17280, 17280, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 66, 66, 17280, 135, 17280, 135, 17280, 135, 66, 135, 66, 66, 66, 17280, 17280, 135, 135, 66, 66, 135, 66, 17280, 66, 66, 135, 66, 17280, 135, 66, 17280, 66, 66, 17280, 135, 17280, 135, 66, 135, 17280, 135, 135, 17280, 135, 66, 135, 66, 17280, 135, 135, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 135, 66, 135, 66, 135, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 135, 135, 17280, 66, 17280, 66, 66, 66, 17280, 135, 17280, 17280, 66, 135, 135, 135, 66, 135, 66, 135, 135, 17280, 66, 66, 135, 66, 135, 135, 66, 17280, 17280, 17280, 66, 135, 135, 135, 135, 66, 135, 66, 17280, 66, 66, 17280, 135, 17280, 135, 135, 135, 135, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 135, 17280, 135, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1870401 . Total input tokens: 416565998 . Total output tokens: 374464939
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 84.57804043684155,
    "estimated_duration": 3600.010314695794,
    "input_throughput": 6230.914925002231,
    "output_throughput": 5525.118058357778,
    "total_throughput": 11756.032983360008,
    "itl": 155.51183364747666,
    "ttft": 1961637.1571446117,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 647,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.026905082769214,
    "arrivals": 623634,
    "finished_requests": 91021,
    "scheduler_time": 167.30114669364306
}
#Debug simulation 
Total elapsed time: 84.57820719992742. Arrivals time: 0.4674535384401679 Scheduler time: 83.95392580097541 Scheduler overhead time: 0.059448959305882454 Adapter cache time: 0.01802031509578228 Engine time: 0.05759858572855592 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-32/adapters_320_slots_64_rate_1.6-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-32/adapters_320_slots_64_rate_1.6-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [106 107 107]
Adapter prompts. [135, 17280, 17280, 66, 17280, 17280, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 17280, 17280, 135, 66, 66, 135, 17280, 17280, 135, 135, 66, 66, 135, 17280, 17280, 66, 17280, 135, 66, 135, 17280, 66, 135, 17280, 17280, 135, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 135, 135, 135, 66, 135, 66, 17280, 66, 17280, 135, 17280, 17280, 66, 17280, 66, 17280, 135, 66, 66, 135, 135, 17280, 135, 17280, 17280, 17280, 66, 135, 135, 66, 17280, 135, 17280, 17280, 135, 66, 135, 135, 135, 66, 17280, 135, 17280, 66, 17280, 66, 66, 135, 17280, 17280, 135, 66, 135, 66, 135, 17280, 17280, 135, 66, 135, 66, 17280, 66, 66, 66, 66, 17280, 135, 135, 17280, 135, 135, 66, 135, 17280, 135, 66, 66, 135, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 135, 17280, 135, 135, 135, 66, 17280, 66, 17280, 135, 66, 135, 66, 66, 135, 66, 135, 17280, 17280, 17280, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 66, 66, 17280, 135, 17280, 135, 17280, 135, 66, 135, 66, 66, 66, 17280, 17280, 135, 135, 66, 66, 135, 66, 17280, 66, 66, 135, 66, 17280, 135, 66, 17280, 66, 66, 17280, 135, 17280, 135, 66, 135, 17280, 135, 135, 17280, 135, 66, 135, 66, 17280, 135, 135, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 135, 66, 135, 66, 135, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 135, 135, 17280, 66, 17280, 66, 66, 66, 17280, 135, 17280, 17280, 66, 135, 135, 135, 66, 135, 66, 135, 135, 17280, 66, 66, 135, 66, 135, 135, 66, 17280, 17280, 17280, 66, 135, 135, 135, 135, 66, 135, 66, 17280, 66, 66, 17280, 135, 17280, 135, 135, 135, 135, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 135, 17280, 135, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1870401 . Total input tokens: 416565998 . Total output tokens: 374464939
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 83.92512886459008,
    "estimated_duration": 3600.126511035815,
    "input_throughput": 6230.713818316938,
    "output_throughput": 5524.939731708813,
    "total_throughput": 11755.65355002575,
    "itl": 155.51569403822754,
    "ttft": 1961683.6242080238,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 647,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1416788953542727,
    "arrivals": 623634,
    "finished_requests": 91021,
    "scheduler_time": 167.3016890930998
}
#Debug simulation 
Total elapsed time: 83.92529903585091. Arrivals time: 0.44789472315460443 Scheduler time: 83.32110753189772 Scheduler overhead time: 0.058800277300179005 Adapter cache time: 0.01801661541685462 Engine time: 0.05766893830150366 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-16/adapters_320_slots_64_rate_1.6-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-16/adapters_320_slots_64_rate_1.6-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [106 107 107]
Adapter prompts. [135, 17280, 17280, 66, 17280, 17280, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 17280, 17280, 135, 66, 66, 135, 17280, 17280, 135, 135, 66, 66, 135, 17280, 17280, 66, 17280, 135, 66, 135, 17280, 66, 135, 17280, 17280, 135, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 135, 135, 135, 66, 135, 66, 17280, 66, 17280, 135, 17280, 17280, 66, 17280, 66, 17280, 135, 66, 66, 135, 135, 17280, 135, 17280, 17280, 17280, 66, 135, 135, 66, 17280, 135, 17280, 17280, 135, 66, 135, 135, 135, 66, 17280, 135, 17280, 66, 17280, 66, 66, 135, 17280, 17280, 135, 66, 135, 66, 135, 17280, 17280, 135, 66, 135, 66, 17280, 66, 66, 66, 66, 17280, 135, 135, 17280, 135, 135, 66, 135, 17280, 135, 66, 66, 135, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 135, 17280, 135, 135, 135, 66, 17280, 66, 17280, 135, 66, 135, 66, 66, 135, 66, 135, 17280, 17280, 17280, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 66, 66, 17280, 135, 17280, 135, 17280, 135, 66, 135, 66, 66, 66, 17280, 17280, 135, 135, 66, 66, 135, 66, 17280, 66, 66, 135, 66, 17280, 135, 66, 17280, 66, 66, 17280, 135, 17280, 135, 66, 135, 17280, 135, 135, 17280, 135, 66, 135, 66, 17280, 135, 135, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 135, 66, 135, 66, 135, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 135, 135, 17280, 66, 17280, 66, 66, 66, 17280, 135, 17280, 17280, 66, 135, 135, 135, 66, 135, 66, 135, 135, 17280, 66, 66, 135, 66, 135, 135, 66, 17280, 17280, 17280, 66, 135, 135, 135, 135, 66, 135, 66, 17280, 66, 66, 17280, 135, 17280, 135, 135, 135, 135, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 135, 17280, 135, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1870401 . Total input tokens: 416565998 . Total output tokens: 374464939
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 84.30639682663605,
    "estimated_duration": 3600.0701389508877,
    "input_throughput": 6230.811382618457,
    "output_throughput": 5525.026244570994,
    "total_throughput": 11755.83762718945,
    "itl": 155.50792944727047,
    "ttft": 1961617.7031359854,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 647,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9345625408016758,
    "arrivals": 623634,
    "finished_requests": 91021,
    "scheduler_time": 167.30717623170793
}
#Debug simulation 
Total elapsed time: 84.30656334804371. Arrivals time: 0.44669109443202615 Scheduler time: 83.70289500104263 Scheduler overhead time: 0.05899912631139159 Adapter cache time: 0.018308980856090784 Engine time: 0.057474952191114426 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-32/adapters_320_slots_64_rate_1.6-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-32/adapters_320_slots_64_rate_1.6-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [106 107 107]
Adapter prompts. [135, 17280, 17280, 66, 17280, 17280, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 17280, 17280, 135, 66, 66, 135, 17280, 17280, 135, 135, 66, 66, 135, 17280, 17280, 66, 17280, 135, 66, 135, 17280, 66, 135, 17280, 17280, 135, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 135, 135, 135, 66, 135, 66, 17280, 66, 17280, 135, 17280, 17280, 66, 17280, 66, 17280, 135, 66, 66, 135, 135, 17280, 135, 17280, 17280, 17280, 66, 135, 135, 66, 17280, 135, 17280, 17280, 135, 66, 135, 135, 135, 66, 17280, 135, 17280, 66, 17280, 66, 66, 135, 17280, 17280, 135, 66, 135, 66, 135, 17280, 17280, 135, 66, 135, 66, 17280, 66, 66, 66, 66, 17280, 135, 135, 17280, 135, 135, 66, 135, 17280, 135, 66, 66, 135, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 135, 17280, 135, 135, 135, 66, 17280, 66, 17280, 135, 66, 135, 66, 66, 135, 66, 135, 17280, 17280, 17280, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 66, 66, 17280, 135, 17280, 135, 17280, 135, 66, 135, 66, 66, 66, 17280, 17280, 135, 135, 66, 66, 135, 66, 17280, 66, 66, 135, 66, 17280, 135, 66, 17280, 66, 66, 17280, 135, 17280, 135, 66, 135, 17280, 135, 135, 17280, 135, 66, 135, 66, 17280, 135, 135, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 135, 66, 135, 66, 135, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 135, 135, 17280, 66, 17280, 66, 66, 66, 17280, 135, 17280, 17280, 66, 135, 135, 135, 66, 135, 66, 135, 135, 17280, 66, 66, 135, 66, 135, 135, 66, 17280, 17280, 17280, 66, 135, 135, 135, 135, 66, 135, 66, 17280, 66, 66, 17280, 135, 17280, 135, 135, 135, 135, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 135, 17280, 135, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 1870401 . Total input tokens: 416565998 . Total output tokens: 374464939
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 83.89042753633112,
    "estimated_duration": 3600.108695664866,
    "input_throughput": 6230.739929327993,
    "output_throughput": 5524.8973521136095,
    "total_throughput": 11755.637281441603,
    "itl": 155.51757105466265,
    "ttft": 1961653.3192790502,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 647,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1700992510840287,
    "arrivals": 623634,
    "finished_requests": 91020,
    "scheduler_time": 167.29837249555445
}
#Debug simulation 
Total elapsed time: 83.89059331221506. Arrivals time: 0.4479530891403556 Scheduler time: 83.28628267953172 Scheduler overhead time: 0.05827079759910703 Adapter cache time: 0.018062591552734375 Engine time: 0.058217707090079784 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-8/adapters_320_slots_64_rate_1.6-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-8/adapters_320_slots_64_rate_1.6-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [106 107 107]
Adapter prompts. [135, 17280, 17280, 33, 17280, 17280, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 17280, 17280, 135, 33, 33, 135, 17280, 17280, 135, 135, 33, 33, 135, 17280, 17280, 33, 17280, 135, 33, 135, 17280, 33, 135, 17280, 17280, 135, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 135, 135, 135, 33, 135, 33, 17280, 33, 17280, 135, 17280, 17280, 33, 17280, 33, 17280, 135, 33, 33, 135, 135, 17280, 135, 17280, 17280, 17280, 33, 135, 135, 33, 17280, 135, 17280, 17280, 135, 33, 135, 135, 135, 33, 17280, 135, 17280, 33, 17280, 33, 33, 135, 17280, 17280, 135, 33, 135, 33, 135, 17280, 17280, 135, 33, 135, 33, 17280, 33, 33, 33, 33, 17280, 135, 135, 17280, 135, 135, 33, 135, 17280, 135, 33, 33, 135, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 135, 17280, 135, 135, 135, 33, 17280, 33, 17280, 135, 33, 135, 33, 33, 135, 33, 135, 17280, 17280, 17280, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 33, 33, 17280, 135, 17280, 135, 17280, 135, 33, 135, 33, 33, 33, 17280, 17280, 135, 135, 33, 33, 135, 33, 17280, 33, 33, 135, 33, 17280, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 33, 135, 17280, 135, 135, 17280, 135, 33, 135, 33, 17280, 135, 135, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 135, 33, 135, 33, 135, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 135, 135, 17280, 33, 17280, 33, 33, 33, 17280, 135, 17280, 17280, 33, 135, 135, 135, 33, 135, 33, 135, 135, 17280, 33, 33, 135, 33, 135, 135, 33, 17280, 17280, 17280, 33, 135, 135, 135, 135, 33, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 135, 135, 135, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 135, 17280, 135, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1866903 . Total input tokens: 415769561 . Total output tokens: 373751715
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 84.47171464469284,
    "estimated_duration": 3600.0646492179435,
    "input_throughput": 6257.801232790071,
    "output_throughput": 5527.876285311463,
    "total_throughput": 11785.677518101533,
    "itl": 155.06948850663616,
    "ttft": 1964201.8327115176,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 626,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9158653277019344,
    "arrivals": 622407,
    "finished_requests": 91162,
    "scheduler_time": 167.78862101246247
}
#Debug simulation 
Total elapsed time: 84.47195821488276. Arrivals time: 0.4420412089675665 Scheduler time: 83.87324233492836 Scheduler overhead time: 0.05894005997106433 Adapter cache time: 0.017590865958482027 Engine time: 0.05777909094467759 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-16/adapters_320_slots_64_rate_1.6-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-16/adapters_320_slots_64_rate_1.6-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [106 107 107]
Adapter prompts. [135, 17280, 17280, 33, 17280, 17280, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 17280, 17280, 135, 33, 33, 135, 17280, 17280, 135, 135, 33, 33, 135, 17280, 17280, 33, 17280, 135, 33, 135, 17280, 33, 135, 17280, 17280, 135, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 135, 135, 135, 33, 135, 33, 17280, 33, 17280, 135, 17280, 17280, 33, 17280, 33, 17280, 135, 33, 33, 135, 135, 17280, 135, 17280, 17280, 17280, 33, 135, 135, 33, 17280, 135, 17280, 17280, 135, 33, 135, 135, 135, 33, 17280, 135, 17280, 33, 17280, 33, 33, 135, 17280, 17280, 135, 33, 135, 33, 135, 17280, 17280, 135, 33, 135, 33, 17280, 33, 33, 33, 33, 17280, 135, 135, 17280, 135, 135, 33, 135, 17280, 135, 33, 33, 135, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 135, 17280, 135, 135, 135, 33, 17280, 33, 17280, 135, 33, 135, 33, 33, 135, 33, 135, 17280, 17280, 17280, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 33, 33, 17280, 135, 17280, 135, 17280, 135, 33, 135, 33, 33, 33, 17280, 17280, 135, 135, 33, 33, 135, 33, 17280, 33, 33, 135, 33, 17280, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 33, 135, 17280, 135, 135, 17280, 135, 33, 135, 33, 17280, 135, 135, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 135, 33, 135, 33, 135, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 135, 135, 17280, 33, 17280, 33, 33, 33, 17280, 135, 17280, 17280, 33, 135, 135, 135, 33, 135, 33, 135, 135, 17280, 33, 33, 135, 33, 135, 135, 33, 17280, 17280, 17280, 33, 135, 135, 135, 135, 33, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 135, 135, 135, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 135, 17280, 135, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1866903 . Total input tokens: 415769561 . Total output tokens: 373751715
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 84.0153541942127,
    "estimated_duration": 3600.029638886877,
    "input_throughput": 6257.750702009677,
    "output_throughput": 5527.638379708713,
    "total_throughput": 11785.389081718391,
    "itl": 155.07403779668712,
    "ttft": 1964245.3360014635,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 626,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0429729230352733,
    "arrivals": 622407,
    "finished_requests": 91156,
    "scheduler_time": 167.78143973507414
}
#Debug simulation 
Total elapsed time: 84.01552271330729. Arrivals time: 0.465554631780833 Scheduler time: 83.39538031909615 Scheduler overhead time: 0.058301490265876055 Adapter cache time: 0.01706640375778079 Engine time: 0.05724121443927288 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-32/adapters_320_slots_64_rate_1.6-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-32/adapters_320_slots_64_rate_1.6-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [106 107 107]
Adapter prompts. [135, 17280, 17280, 33, 17280, 17280, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 17280, 17280, 135, 33, 33, 135, 17280, 17280, 135, 135, 33, 33, 135, 17280, 17280, 33, 17280, 135, 33, 135, 17280, 33, 135, 17280, 17280, 135, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 135, 135, 135, 33, 135, 33, 17280, 33, 17280, 135, 17280, 17280, 33, 17280, 33, 17280, 135, 33, 33, 135, 135, 17280, 135, 17280, 17280, 17280, 33, 135, 135, 33, 17280, 135, 17280, 17280, 135, 33, 135, 135, 135, 33, 17280, 135, 17280, 33, 17280, 33, 33, 135, 17280, 17280, 135, 33, 135, 33, 135, 17280, 17280, 135, 33, 135, 33, 17280, 33, 33, 33, 33, 17280, 135, 135, 17280, 135, 135, 33, 135, 17280, 135, 33, 33, 135, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 135, 17280, 135, 135, 135, 33, 17280, 33, 17280, 135, 33, 135, 33, 33, 135, 33, 135, 17280, 17280, 17280, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 33, 33, 17280, 135, 17280, 135, 17280, 135, 33, 135, 33, 33, 33, 17280, 17280, 135, 135, 33, 33, 135, 33, 17280, 33, 33, 135, 33, 17280, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 33, 135, 17280, 135, 135, 17280, 135, 33, 135, 33, 17280, 135, 135, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 135, 33, 135, 33, 135, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 135, 135, 17280, 33, 17280, 33, 33, 33, 17280, 135, 17280, 17280, 33, 135, 135, 135, 33, 135, 33, 135, 135, 17280, 33, 33, 135, 33, 135, 135, 33, 17280, 17280, 17280, 33, 135, 135, 135, 135, 33, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 135, 135, 135, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 135, 17280, 135, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1866903 . Total input tokens: 415769561 . Total output tokens: 373751715
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 84.36887827701867,
    "estimated_duration": 3600.032747527047,
    "input_throughput": 6257.745298421274,
    "output_throughput": 5527.633606574712,
    "total_throughput": 11785.378904995987,
    "itl": 155.07416737222707,
    "ttft": 1964246.52519629,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 626,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0465494995378064,
    "arrivals": 622407,
    "finished_requests": 91156,
    "scheduler_time": 167.7814566780633
}
#Debug simulation 
Total elapsed time: 84.3690464203246. Arrivals time: 0.4514367966912687 Scheduler time: 83.76189226843417 Scheduler overhead time: 0.05805289000272751 Adapter cache time: 0.017872624564915895 Engine time: 0.05797813832759857 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-16/adapters_320_slots_64_rate_1.6-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-16/adapters_320_slots_64_rate_1.6-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [106 107 107]
Adapter prompts. [135, 17280, 17280, 33, 17280, 17280, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 17280, 17280, 135, 33, 33, 135, 17280, 17280, 135, 135, 33, 33, 135, 17280, 17280, 33, 17280, 135, 33, 135, 17280, 33, 135, 17280, 17280, 135, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 135, 135, 135, 33, 135, 33, 17280, 33, 17280, 135, 17280, 17280, 33, 17280, 33, 17280, 135, 33, 33, 135, 135, 17280, 135, 17280, 17280, 17280, 33, 135, 135, 33, 17280, 135, 17280, 17280, 135, 33, 135, 135, 135, 33, 17280, 135, 17280, 33, 17280, 33, 33, 135, 17280, 17280, 135, 33, 135, 33, 135, 17280, 17280, 135, 33, 135, 33, 17280, 33, 33, 33, 33, 17280, 135, 135, 17280, 135, 135, 33, 135, 17280, 135, 33, 33, 135, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 135, 17280, 135, 135, 135, 33, 17280, 33, 17280, 135, 33, 135, 33, 33, 135, 33, 135, 17280, 17280, 17280, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 33, 33, 17280, 135, 17280, 135, 17280, 135, 33, 135, 33, 33, 33, 17280, 17280, 135, 135, 33, 33, 135, 33, 17280, 33, 33, 135, 33, 17280, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 33, 135, 17280, 135, 135, 17280, 135, 33, 135, 33, 17280, 135, 135, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 135, 33, 135, 33, 135, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 135, 135, 17280, 33, 17280, 33, 33, 33, 17280, 135, 17280, 17280, 33, 135, 135, 135, 33, 135, 33, 135, 135, 17280, 33, 33, 135, 33, 135, 135, 33, 17280, 17280, 17280, 33, 135, 135, 135, 135, 33, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 135, 135, 135, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 135, 17280, 135, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1866903 . Total input tokens: 415769561 . Total output tokens: 373751715
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 84.10835339687765,
    "estimated_duration": 3600.099934146845,
    "input_throughput": 6257.739899472769,
    "output_throughput": 5527.822106059422,
    "total_throughput": 11785.56200553219,
    "itl": 155.07039593101968,
    "ttft": 1964215.7523618513,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 626,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9506303810677346,
    "arrivals": 622407,
    "finished_requests": 91162,
    "scheduler_time": 167.788789521315
}
#Debug simulation 
Total elapsed time: 84.1085169557482. Arrivals time: 0.4501676536165178 Scheduler time: 83.5023222710006 Scheduler overhead time: 0.05810820125043392 Adapter cache time: 0.017913490999490023 Engine time: 0.058180191088467836 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-32/adapters_320_slots_64_rate_1.6-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-32/adapters_320_slots_64_rate_1.6-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [106 107 107]
Adapter prompts. [135, 17280, 17280, 33, 17280, 17280, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 17280, 17280, 135, 33, 33, 135, 17280, 17280, 135, 135, 33, 33, 135, 17280, 17280, 33, 17280, 135, 33, 135, 17280, 33, 135, 17280, 17280, 135, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 135, 135, 135, 33, 135, 33, 17280, 33, 17280, 135, 17280, 17280, 33, 17280, 33, 17280, 135, 33, 33, 135, 135, 17280, 135, 17280, 17280, 17280, 33, 135, 135, 33, 17280, 135, 17280, 17280, 135, 33, 135, 135, 135, 33, 17280, 135, 17280, 33, 17280, 33, 33, 135, 17280, 17280, 135, 33, 135, 33, 135, 17280, 17280, 135, 33, 135, 33, 17280, 33, 33, 33, 33, 17280, 135, 135, 17280, 135, 135, 33, 135, 17280, 135, 33, 33, 135, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 135, 17280, 135, 135, 135, 33, 17280, 33, 17280, 135, 33, 135, 33, 33, 135, 33, 135, 17280, 17280, 17280, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 33, 33, 17280, 135, 17280, 135, 17280, 135, 33, 135, 33, 33, 33, 17280, 17280, 135, 135, 33, 33, 135, 33, 17280, 33, 33, 135, 33, 17280, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 33, 135, 17280, 135, 135, 17280, 135, 33, 135, 33, 17280, 135, 135, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 135, 33, 135, 33, 135, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 135, 135, 17280, 33, 17280, 33, 33, 33, 17280, 135, 17280, 17280, 33, 135, 135, 135, 33, 135, 33, 135, 135, 17280, 33, 33, 135, 33, 135, 135, 33, 17280, 17280, 17280, 33, 135, 135, 135, 135, 33, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 135, 135, 135, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 135, 17280, 135, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1866903 . Total input tokens: 415769561 . Total output tokens: 373751715
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 84.18392796581611,
    "estimated_duration": 3600.060761239182,
    "input_throughput": 6257.696604055532,
    "output_throughput": 5527.590593540513,
    "total_throughput": 11785.287197596044,
    "itl": 155.07547851297952,
    "ttft": 1964255.2975590033,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 626,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0749698552675584,
    "arrivals": 622407,
    "finished_requests": 91156,
    "scheduler_time": 167.78212238247127
}
#Debug simulation 
Total elapsed time: 84.18408964807168. Arrivals time: 0.44756195042282343 Scheduler time: 83.56917302124202 Scheduler overhead time: 0.057453307788819075 Adapter cache time: 0.0174093134701252 Engine time: 0.07074647955596447 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-16/adapters_320_slots_64_rate_1.6-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-16/adapters_320_slots_64_rate_1.6-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [106 107 107]
Adapter prompts. [135, 17280, 17280, 33, 17280, 17280, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 17280, 17280, 135, 33, 33, 135, 17280, 17280, 135, 135, 33, 33, 135, 17280, 17280, 33, 17280, 135, 33, 135, 17280, 33, 135, 17280, 17280, 135, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 135, 135, 135, 33, 135, 33, 17280, 33, 17280, 135, 17280, 17280, 33, 17280, 33, 17280, 135, 33, 33, 135, 135, 17280, 135, 17280, 17280, 17280, 33, 135, 135, 33, 17280, 135, 17280, 17280, 135, 33, 135, 135, 135, 33, 17280, 135, 17280, 33, 17280, 33, 33, 135, 17280, 17280, 135, 33, 135, 33, 135, 17280, 17280, 135, 33, 135, 33, 17280, 33, 33, 33, 33, 17280, 135, 135, 17280, 135, 135, 33, 135, 17280, 135, 33, 33, 135, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 135, 17280, 135, 135, 135, 33, 17280, 33, 17280, 135, 33, 135, 33, 33, 135, 33, 135, 17280, 17280, 17280, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 33, 33, 17280, 135, 17280, 135, 17280, 135, 33, 135, 33, 33, 33, 17280, 17280, 135, 135, 33, 33, 135, 33, 17280, 33, 33, 135, 33, 17280, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 33, 135, 17280, 135, 135, 17280, 135, 33, 135, 33, 17280, 135, 135, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 135, 33, 135, 33, 135, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 135, 135, 17280, 33, 17280, 33, 33, 33, 17280, 135, 17280, 17280, 33, 135, 135, 135, 33, 135, 33, 135, 135, 17280, 33, 33, 135, 33, 135, 135, 33, 17280, 17280, 17280, 33, 135, 135, 135, 135, 33, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 135, 135, 135, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 135, 17280, 135, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1866903 . Total input tokens: 415769561 . Total output tokens: 373751715
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 84.26661044033244,
    "estimated_duration": 3600.017106435442,
    "input_throughput": 6257.883874975969,
    "output_throughput": 5527.94928791455,
    "total_throughput": 11785.833162890518,
    "itl": 155.06809623924772,
    "ttft": 1964184.5565018544,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 626,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8717714846087323,
    "arrivals": 622407,
    "finished_requests": 91162,
    "scheduler_time": 167.78762578799981
}
#Debug simulation 
Total elapsed time: 84.26677307905629. Arrivals time: 0.44440328562632203 Scheduler time: 83.66715941717848 Scheduler overhead time: 0.05848800344392657 Adapter cache time: 0.017637294251471758 Engine time: 0.05672271177172661 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-32/adapters_320_slots_64_rate_1.6-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-32/adapters_320_slots_64_rate_1.6-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [106 107 107]
Adapter prompts. [135, 17280, 17280, 33, 17280, 17280, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 17280, 17280, 135, 33, 33, 135, 17280, 17280, 135, 135, 33, 33, 135, 17280, 17280, 33, 17280, 135, 33, 135, 17280, 33, 135, 17280, 17280, 135, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 135, 135, 135, 33, 135, 33, 17280, 33, 17280, 135, 17280, 17280, 33, 17280, 33, 17280, 135, 33, 33, 135, 135, 17280, 135, 17280, 17280, 17280, 33, 135, 135, 33, 17280, 135, 17280, 17280, 135, 33, 135, 135, 135, 33, 17280, 135, 17280, 33, 17280, 33, 33, 135, 17280, 17280, 135, 33, 135, 33, 135, 17280, 17280, 135, 33, 135, 33, 17280, 33, 33, 33, 33, 17280, 135, 135, 17280, 135, 135, 33, 135, 17280, 135, 33, 33, 135, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 135, 17280, 135, 135, 135, 33, 17280, 33, 17280, 135, 33, 135, 33, 33, 135, 33, 135, 17280, 17280, 17280, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 33, 33, 17280, 135, 17280, 135, 17280, 135, 33, 135, 33, 33, 33, 17280, 17280, 135, 135, 33, 33, 135, 33, 17280, 33, 33, 135, 33, 17280, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 33, 135, 17280, 135, 135, 17280, 135, 33, 135, 33, 17280, 135, 135, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 135, 33, 135, 33, 135, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 135, 135, 17280, 33, 17280, 33, 33, 33, 17280, 135, 17280, 17280, 33, 135, 135, 135, 33, 135, 33, 135, 135, 17280, 33, 33, 135, 33, 135, 135, 33, 17280, 17280, 17280, 33, 135, 135, 135, 135, 33, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 135, 135, 135, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 135, 17280, 135, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1866903 . Total input tokens: 415769561 . Total output tokens: 373751715
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 84.18628829624504,
    "estimated_duration": 3600.0932582978294,
    "input_throughput": 6257.64011753728,
    "output_throughput": 5527.540697489825,
    "total_throughput": 11785.180815027104,
    "itl": 155.07626957332806,
    "ttft": 1964264.2599265848,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 626,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.099240336045621,
    "arrivals": 622407,
    "finished_requests": 91156,
    "scheduler_time": 167.78254942784307
}
#Debug simulation 
Total elapsed time: 84.1864624270238. Arrivals time: 0.4860798395238817 Scheduler time: 83.54352860432118 Scheduler overhead time: 0.059338337276130915 Adapter cache time: 0.017711274325847626 Engine time: 0.05745019484311342 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-8/adapters_320_slots_64_rate_1.6-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-8/adapters_320_slots_64_rate_1.6-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [106 107 107]
Adapter prompts. [66, 17280, 17280, 33, 17280, 17280, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 17280, 17280, 66, 33, 33, 66, 17280, 17280, 66, 66, 33, 33, 66, 17280, 17280, 33, 17280, 66, 33, 66, 17280, 33, 66, 17280, 17280, 66, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 66, 66, 66, 33, 66, 33, 17280, 33, 17280, 66, 17280, 17280, 33, 17280, 33, 17280, 66, 33, 33, 66, 66, 17280, 66, 17280, 17280, 17280, 33, 66, 66, 33, 17280, 66, 17280, 17280, 66, 33, 66, 66, 66, 33, 17280, 66, 17280, 33, 17280, 33, 33, 66, 17280, 17280, 66, 33, 66, 33, 66, 17280, 17280, 66, 33, 66, 33, 17280, 33, 33, 33, 33, 17280, 66, 66, 17280, 66, 66, 33, 66, 17280, 66, 33, 33, 66, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 66, 17280, 66, 66, 66, 33, 17280, 33, 17280, 66, 33, 66, 33, 33, 66, 33, 66, 17280, 17280, 17280, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 33, 33, 17280, 66, 17280, 66, 17280, 66, 33, 66, 33, 33, 33, 17280, 17280, 66, 66, 33, 33, 66, 33, 17280, 33, 33, 66, 33, 17280, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 33, 66, 17280, 66, 66, 17280, 66, 33, 66, 33, 17280, 66, 66, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 66, 33, 66, 33, 66, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 66, 66, 17280, 33, 17280, 33, 33, 33, 17280, 66, 17280, 17280, 33, 66, 66, 66, 33, 66, 33, 66, 66, 17280, 33, 33, 66, 33, 66, 66, 33, 17280, 17280, 17280, 33, 66, 66, 66, 66, 33, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 66, 66, 66, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 66, 17280, 66, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1859520 . Total input tokens: 414091379 . Total output tokens: 372292778
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 85.50246067298576,
    "estimated_duration": 3600.1259576947186,
    "input_throughput": 6301.876730592948,
    "output_throughput": 5570.9736924989875,
    "total_throughput": 11872.850423091935,
    "itl": 153.8572495678496,
    "ttft": 1956328.485582829,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 465,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4231268009287439,
    "arrivals": 619978,
    "finished_requests": 91666,
    "scheduler_time": 169.00508830493558
}
#Debug simulation 
Total elapsed time: 85.50262619741261. Arrivals time: 0.4918138924986124 Scheduler time: 84.85688787465915 Scheduler overhead time: 0.05815506959334016 Adapter cache time: 0.015872361604124308 Engine time: 0.05757849384099245 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-16/adapters_320_slots_64_rate_1.6-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-16/adapters_320_slots_64_rate_1.6-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [106 107 107]
Adapter prompts. [66, 17280, 17280, 33, 17280, 17280, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 17280, 17280, 66, 33, 33, 66, 17280, 17280, 66, 66, 33, 33, 66, 17280, 17280, 33, 17280, 66, 33, 66, 17280, 33, 66, 17280, 17280, 66, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 66, 66, 66, 33, 66, 33, 17280, 33, 17280, 66, 17280, 17280, 33, 17280, 33, 17280, 66, 33, 33, 66, 66, 17280, 66, 17280, 17280, 17280, 33, 66, 66, 33, 17280, 66, 17280, 17280, 66, 33, 66, 66, 66, 33, 17280, 66, 17280, 33, 17280, 33, 33, 66, 17280, 17280, 66, 33, 66, 33, 66, 17280, 17280, 66, 33, 66, 33, 17280, 33, 33, 33, 33, 17280, 66, 66, 17280, 66, 66, 33, 66, 17280, 66, 33, 33, 66, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 66, 17280, 66, 66, 66, 33, 17280, 33, 17280, 66, 33, 66, 33, 33, 66, 33, 66, 17280, 17280, 17280, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 33, 33, 17280, 66, 17280, 66, 17280, 66, 33, 66, 33, 33, 33, 17280, 17280, 66, 66, 33, 33, 66, 33, 17280, 33, 33, 66, 33, 17280, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 33, 66, 17280, 66, 66, 17280, 66, 33, 66, 33, 17280, 66, 66, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 66, 33, 66, 33, 66, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 66, 66, 17280, 33, 17280, 33, 33, 33, 17280, 66, 17280, 17280, 33, 66, 66, 66, 33, 66, 33, 66, 66, 17280, 33, 33, 66, 33, 66, 66, 33, 17280, 17280, 17280, 33, 66, 66, 66, 66, 33, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 66, 66, 66, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 66, 17280, 66, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1859520 . Total input tokens: 414091379 . Total output tokens: 372292778
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 85.31504058791324,
    "estimated_duration": 3600.1418225002762,
    "input_throughput": 6299.315448703621,
    "output_throughput": 5561.027033678328,
    "total_throughput": 11860.34248238195,
    "itl": 153.88368733657256,
    "ttft": 1957145.723136424,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 467,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5271039896202334,
    "arrivals": 619978,
    "finished_requests": 91662,
    "scheduler_time": 168.79959340418438
}
#Debug simulation 
Total elapsed time: 85.31520571699366. Arrivals time: 0.48610873240977526 Scheduler time: 84.67565307626501 Scheduler overhead time: 0.058669301215559244 Adapter cache time: 0.015890781302005053 Engine time: 0.056938284542411566 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-32/adapters_320_slots_64_rate_1.6-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-32/adapters_320_slots_64_rate_1.6-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [106 107 107]
Adapter prompts. [66, 17280, 17280, 33, 17280, 17280, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 17280, 17280, 66, 33, 33, 66, 17280, 17280, 66, 66, 33, 33, 66, 17280, 17280, 33, 17280, 66, 33, 66, 17280, 33, 66, 17280, 17280, 66, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 66, 66, 66, 33, 66, 33, 17280, 33, 17280, 66, 17280, 17280, 33, 17280, 33, 17280, 66, 33, 33, 66, 66, 17280, 66, 17280, 17280, 17280, 33, 66, 66, 33, 17280, 66, 17280, 17280, 66, 33, 66, 66, 66, 33, 17280, 66, 17280, 33, 17280, 33, 33, 66, 17280, 17280, 66, 33, 66, 33, 66, 17280, 17280, 66, 33, 66, 33, 17280, 33, 33, 33, 33, 17280, 66, 66, 17280, 66, 66, 33, 66, 17280, 66, 33, 33, 66, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 66, 17280, 66, 66, 66, 33, 17280, 33, 17280, 66, 33, 66, 33, 33, 66, 33, 66, 17280, 17280, 17280, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 33, 33, 17280, 66, 17280, 66, 17280, 66, 33, 66, 33, 33, 33, 17280, 17280, 66, 66, 33, 33, 66, 33, 17280, 33, 33, 66, 33, 17280, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 33, 66, 17280, 66, 66, 17280, 66, 33, 66, 33, 17280, 66, 66, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 66, 33, 66, 33, 66, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 66, 66, 17280, 33, 17280, 33, 33, 33, 17280, 66, 17280, 17280, 33, 66, 66, 66, 33, 66, 33, 66, 66, 17280, 33, 33, 66, 33, 66, 66, 33, 17280, 17280, 17280, 33, 66, 66, 66, 66, 33, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 66, 66, 66, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 66, 17280, 66, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1859520 . Total input tokens: 414091379 . Total output tokens: 372292778
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 84.90945317968726,
    "estimated_duration": 3600.1439820163564,
    "input_throughput": 6299.311670112244,
    "output_throughput": 5561.023697943046,
    "total_throughput": 11860.33536805529,
    "itl": 153.88375989819835,
    "ttft": 1957146.7098391652,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 467,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5292425006255599,
    "arrivals": 619978,
    "finished_requests": 91662,
    "scheduler_time": 168.799614409246
}
#Debug simulation 
Total elapsed time: 84.90962410671636. Arrivals time: 0.4897083812393248 Scheduler time: 84.26574365794659 Scheduler overhead time: 0.0585555350407958 Adapter cache time: 0.015833052806556225 Engine time: 0.057608168106526136 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-16/adapters_320_slots_64_rate_1.6-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-16/adapters_320_slots_64_rate_1.6-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [106 107 107]
Adapter prompts. [66, 17280, 17280, 33, 17280, 17280, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 17280, 17280, 66, 33, 33, 66, 17280, 17280, 66, 66, 33, 33, 66, 17280, 17280, 33, 17280, 66, 33, 66, 17280, 33, 66, 17280, 17280, 66, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 66, 66, 66, 33, 66, 33, 17280, 33, 17280, 66, 17280, 17280, 33, 17280, 33, 17280, 66, 33, 33, 66, 66, 17280, 66, 17280, 17280, 17280, 33, 66, 66, 33, 17280, 66, 17280, 17280, 66, 33, 66, 66, 66, 33, 17280, 66, 17280, 33, 17280, 33, 33, 66, 17280, 17280, 66, 33, 66, 33, 66, 17280, 17280, 66, 33, 66, 33, 17280, 33, 33, 33, 33, 17280, 66, 66, 17280, 66, 66, 33, 66, 17280, 66, 33, 33, 66, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 66, 17280, 66, 66, 66, 33, 17280, 33, 17280, 66, 33, 66, 33, 33, 66, 33, 66, 17280, 17280, 17280, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 33, 33, 17280, 66, 17280, 66, 17280, 66, 33, 66, 33, 33, 33, 17280, 17280, 66, 66, 33, 33, 66, 33, 17280, 33, 33, 66, 33, 17280, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 33, 66, 17280, 66, 66, 17280, 66, 33, 66, 33, 17280, 66, 66, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 66, 33, 66, 33, 66, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 66, 66, 17280, 33, 17280, 33, 33, 33, 17280, 66, 17280, 17280, 33, 66, 66, 66, 33, 66, 33, 66, 66, 17280, 33, 33, 66, 33, 66, 66, 33, 17280, 17280, 17280, 33, 66, 66, 66, 66, 33, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 66, 66, 66, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 66, 17280, 66, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1859520 . Total input tokens: 414091379 . Total output tokens: 372292778
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 85.21921347407624,
    "estimated_duration": 3600.1563760453246,
    "input_throughput": 6301.823484934748,
    "output_throughput": 5570.9266223683335,
    "total_throughput": 11872.750107303082,
    "itl": 153.85835318923807,
    "ttft": 1956341.094289338,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 465,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4545228521246418,
    "arrivals": 619978,
    "finished_requests": 91666,
    "scheduler_time": 169.00522450775088
}
#Debug simulation 
Total elapsed time: 85.2193770557642. Arrivals time: 0.47974941739812493 Scheduler time: 84.58469089865685 Scheduler overhead time: 0.05888862023130059 Adapter cache time: 0.01588326459750533 Engine time: 0.057848737109452486 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-32/adapters_320_slots_64_rate_1.6-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-32/adapters_320_slots_64_rate_1.6-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [106 107 107]
Adapter prompts. [66, 17280, 17280, 33, 17280, 17280, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 17280, 17280, 66, 33, 33, 66, 17280, 17280, 66, 66, 33, 33, 66, 17280, 17280, 33, 17280, 66, 33, 66, 17280, 33, 66, 17280, 17280, 66, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 66, 66, 66, 33, 66, 33, 17280, 33, 17280, 66, 17280, 17280, 33, 17280, 33, 17280, 66, 33, 33, 66, 66, 17280, 66, 17280, 17280, 17280, 33, 66, 66, 33, 17280, 66, 17280, 17280, 66, 33, 66, 66, 66, 33, 17280, 66, 17280, 33, 17280, 33, 33, 66, 17280, 17280, 66, 33, 66, 33, 66, 17280, 17280, 66, 33, 66, 33, 17280, 33, 33, 33, 33, 17280, 66, 66, 17280, 66, 66, 33, 66, 17280, 66, 33, 33, 66, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 66, 17280, 66, 66, 66, 33, 17280, 33, 17280, 66, 33, 66, 33, 33, 66, 33, 66, 17280, 17280, 17280, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 33, 33, 17280, 66, 17280, 66, 17280, 66, 33, 66, 33, 33, 33, 17280, 17280, 66, 66, 33, 33, 66, 33, 17280, 33, 33, 66, 33, 17280, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 33, 66, 17280, 66, 66, 17280, 66, 33, 66, 33, 17280, 66, 66, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 66, 33, 66, 33, 66, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 66, 66, 17280, 33, 17280, 33, 33, 33, 17280, 66, 17280, 17280, 33, 66, 66, 66, 33, 66, 33, 66, 66, 17280, 33, 33, 66, 33, 66, 66, 33, 17280, 17280, 17280, 33, 66, 66, 66, 66, 33, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 66, 66, 66, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 66, 17280, 66, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1859520 . Total input tokens: 414091379 . Total output tokens: 372292778
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 84.96953339502215,
    "estimated_duration": 3600.0541893915547,
    "input_throughput": 6298.981572783655,
    "output_throughput": 5560.751296186298,
    "total_throughput": 11859.732868969953,
    "itl": 153.88634268437968,
    "ttft": 1957157.8899133166,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 467,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5502433829568372,
    "arrivals": 619978,
    "finished_requests": 91656,
    "scheduler_time": 168.7919094279753
}
#Debug simulation 
Total elapsed time: 84.96979848202318. Arrivals time: 0.45342528726905584 Scheduler time: 84.36170487850904 Scheduler overhead time: 0.05877149663865566 Adapter cache time: 0.01594346994534135 Engine time: 0.057954808697104454 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-16/adapters_320_slots_64_rate_1.6-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-16/adapters_320_slots_64_rate_1.6-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [106 107 107]
Adapter prompts. [66, 17280, 17280, 33, 17280, 17280, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 17280, 17280, 66, 33, 33, 66, 17280, 17280, 66, 66, 33, 33, 66, 17280, 17280, 33, 17280, 66, 33, 66, 17280, 33, 66, 17280, 17280, 66, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 66, 66, 66, 33, 66, 33, 17280, 33, 17280, 66, 17280, 17280, 33, 17280, 33, 17280, 66, 33, 33, 66, 66, 17280, 66, 17280, 17280, 17280, 33, 66, 66, 33, 17280, 66, 17280, 17280, 66, 33, 66, 66, 66, 33, 17280, 66, 17280, 33, 17280, 33, 33, 66, 17280, 17280, 66, 33, 66, 33, 66, 17280, 17280, 66, 33, 66, 33, 17280, 33, 33, 33, 33, 17280, 66, 66, 17280, 66, 66, 33, 66, 17280, 66, 33, 33, 66, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 66, 17280, 66, 66, 66, 33, 17280, 33, 17280, 66, 33, 66, 33, 33, 66, 33, 66, 17280, 17280, 17280, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 33, 33, 17280, 66, 17280, 66, 17280, 66, 33, 66, 33, 33, 33, 17280, 17280, 66, 66, 33, 33, 66, 33, 17280, 33, 33, 66, 33, 17280, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 33, 66, 17280, 66, 66, 17280, 66, 33, 66, 33, 17280, 66, 66, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 66, 33, 66, 33, 66, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 66, 66, 17280, 33, 17280, 33, 33, 33, 17280, 66, 17280, 17280, 33, 66, 66, 66, 33, 66, 33, 66, 66, 17280, 33, 33, 66, 33, 66, 66, 33, 17280, 17280, 17280, 33, 66, 66, 66, 66, 33, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 66, 66, 66, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 66, 17280, 66, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1859520 . Total input tokens: 414091379 . Total output tokens: 372292778
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 85.24085695808753,
    "estimated_duration": 3600.0656680514016,
    "input_throughput": 6301.685605718258,
    "output_throughput": 5570.79282691397,
    "total_throughput": 11872.478432632228,
    "itl": 153.8631180814752,
    "ttft": 1956347.234397744,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 465,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3903733871294992,
    "arrivals": 619978,
    "finished_requests": 91662,
    "scheduler_time": 168.99621955508957
}
#Debug simulation 
Total elapsed time: 85.24101378535852. Arrivals time: 0.4647818086668849 Scheduler time: 84.62423654226586 Scheduler overhead time: 0.05804897518828511 Adapter cache time: 0.015068524982780218 Engine time: 0.05682479543611407 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-32/adapters_320_slots_64_rate_1.6-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-32/adapters_320_slots_64_rate_1.6-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [106 107 107]
Adapter prompts. [66, 17280, 17280, 33, 17280, 17280, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 17280, 17280, 66, 33, 33, 66, 17280, 17280, 66, 66, 33, 33, 66, 17280, 17280, 33, 17280, 66, 33, 66, 17280, 33, 66, 17280, 17280, 66, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 66, 66, 66, 33, 66, 33, 17280, 33, 17280, 66, 17280, 17280, 33, 17280, 33, 17280, 66, 33, 33, 66, 66, 17280, 66, 17280, 17280, 17280, 33, 66, 66, 33, 17280, 66, 17280, 17280, 66, 33, 66, 66, 66, 33, 17280, 66, 17280, 33, 17280, 33, 33, 66, 17280, 17280, 66, 33, 66, 33, 66, 17280, 17280, 66, 33, 66, 33, 17280, 33, 33, 33, 33, 17280, 66, 66, 17280, 66, 66, 33, 66, 17280, 66, 33, 33, 66, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 66, 17280, 66, 66, 66, 33, 17280, 33, 17280, 66, 33, 66, 33, 33, 66, 33, 66, 17280, 17280, 17280, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 33, 33, 17280, 66, 17280, 66, 17280, 66, 33, 66, 33, 33, 33, 17280, 17280, 66, 66, 33, 33, 66, 33, 17280, 33, 33, 66, 33, 17280, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 33, 66, 17280, 66, 66, 17280, 66, 33, 66, 33, 17280, 66, 66, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 66, 33, 66, 33, 66, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 66, 66, 17280, 33, 17280, 33, 33, 33, 17280, 66, 17280, 17280, 33, 66, 66, 66, 33, 66, 33, 66, 66, 17280, 33, 33, 66, 33, 66, 66, 33, 17280, 17280, 17280, 33, 66, 66, 66, 66, 33, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 66, 66, 66, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 66, 17280, 66, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 1859520 . Total input tokens: 414091379 . Total output tokens: 372292778
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 84.53340899571776,
    "estimated_duration": 3600.0738254779512,
    "input_throughput": 6298.947215891999,
    "output_throughput": 5560.720965865817,
    "total_throughput": 11859.668181757816,
    "itl": 153.88707724996314,
    "ttft": 1957166.2361882718,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 467,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5694837122783059,
    "arrivals": 619978,
    "finished_requests": 91656,
    "scheduler_time": 168.79202670919275
}
#Debug simulation 
Total elapsed time: 84.53356836689636. Arrivals time: 0.42856035847216845 Scheduler time: 83.95261985855177 Scheduler overhead time: 0.05871296767145395 Adapter cache time: 0.01471117464825511 Engine time: 0.056785126216709614 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-8/adapters_320_slots_64_rate_0.8-0.4-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-8/adapters_320_slots_64_rate_0.8-0.4-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 1080, 8640, 8640, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 8640, 8640, 4320, 1080, 1080, 4320, 8640, 8640, 4320, 4320, 1080, 1080, 4320, 8640, 8640, 1080, 8640, 4320, 1080, 4320, 8640, 1080, 4320, 8640, 8640, 4320, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 1080, 8640, 4320, 1080, 1080, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 1080, 4320, 4320, 1080, 8640, 4320, 8640, 8640, 4320, 1080, 4320, 4320, 4320, 1080, 8640, 4320, 8640, 1080, 8640, 1080, 1080, 4320, 8640, 8640, 4320, 1080, 4320, 1080, 4320, 8640, 8640, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 4320, 4320, 8640, 4320, 4320, 1080, 4320, 8640, 4320, 1080, 1080, 4320, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 4320, 8640, 4320, 4320, 4320, 1080, 8640, 1080, 8640, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 4320, 1080, 4320, 1080, 1080, 1080, 8640, 8640, 4320, 4320, 1080, 1080, 4320, 1080, 8640, 1080, 1080, 4320, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 4320, 1080, 4320, 1080, 8640, 4320, 4320, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 4320, 1080, 4320, 1080, 4320, 8640, 8640, 8640, 1080, 8640, 8640, 8640, 8640, 1080, 4320, 4320, 8640, 1080, 8640, 1080, 1080, 1080, 8640, 4320, 8640, 8640, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 8640, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 1080]
Prompts retrieved: 1501200 . Total input tokens: 334488518 . Total output tokens: 300632801
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 88.18876323802397,
    "estimated_duration": 3600.1162553007484,
    "input_throughput": 6206.079308439869,
    "output_throughput": 5473.921840991695,
    "total_throughput": 11680.001149431564,
    "itl": 152.6111729435254,
    "ttft": 1920392.1315412403,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 526,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6098165533086484,
    "arrivals": 500641,
    "finished_requests": 90294,
    "scheduler_time": 168.7322889323705
}
#Debug simulation 
Total elapsed time: 88.18891461705789. Arrivals time: 0.4351414078846574 Scheduler time: 87.59295376203954 Scheduler overhead time: 0.061412493232637644 Adapter cache time: 0.017272696364670992 Engine time: 0.059400799218565226 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-16/adapters_320_slots_64_rate_0.8-0.4-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-16/adapters_320_slots_64_rate_0.8-0.4-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 1080, 8640, 8640, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 8640, 8640, 4320, 1080, 1080, 4320, 8640, 8640, 4320, 4320, 1080, 1080, 4320, 8640, 8640, 1080, 8640, 4320, 1080, 4320, 8640, 1080, 4320, 8640, 8640, 4320, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 1080, 8640, 4320, 1080, 1080, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 1080, 4320, 4320, 1080, 8640, 4320, 8640, 8640, 4320, 1080, 4320, 4320, 4320, 1080, 8640, 4320, 8640, 1080, 8640, 1080, 1080, 4320, 8640, 8640, 4320, 1080, 4320, 1080, 4320, 8640, 8640, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 4320, 4320, 8640, 4320, 4320, 1080, 4320, 8640, 4320, 1080, 1080, 4320, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 4320, 8640, 4320, 4320, 4320, 1080, 8640, 1080, 8640, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 4320, 1080, 4320, 1080, 1080, 1080, 8640, 8640, 4320, 4320, 1080, 1080, 4320, 1080, 8640, 1080, 1080, 4320, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 4320, 1080, 4320, 1080, 8640, 4320, 4320, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 4320, 1080, 4320, 1080, 4320, 8640, 8640, 8640, 1080, 8640, 8640, 8640, 8640, 1080, 4320, 4320, 8640, 1080, 8640, 1080, 1080, 1080, 8640, 4320, 8640, 8640, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 8640, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 1080]
Prompts retrieved: 1501200 . Total input tokens: 334488518 . Total output tokens: 300632801
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 83.85688601620495,
    "estimated_duration": 3600.1025263525435,
    "input_throughput": 6211.839478543245,
    "output_throughput": 5478.180372818833,
    "total_throughput": 11690.019851362078,
    "itl": 152.74512223480616,
    "ttft": 1921613.3951127313,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 534,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7433725767978527,
    "arrivals": 500641,
    "finished_requests": 90411,
    "scheduler_time": 168.51593464759748
}
#Debug simulation 
Total elapsed time: 83.85703829629347. Arrivals time: 0.39012420596554875 Scheduler time: 83.31504688505083 Scheduler overhead time: 0.05845813546329737 Adapter cache time: 0.015641817823052406 Engine time: 0.05643590074032545 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-32/adapters_320_slots_64_rate_0.8-0.4-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-32/adapters_320_slots_64_rate_0.8-0.4-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 1080, 8640, 8640, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 8640, 8640, 4320, 1080, 1080, 4320, 8640, 8640, 4320, 4320, 1080, 1080, 4320, 8640, 8640, 1080, 8640, 4320, 1080, 4320, 8640, 1080, 4320, 8640, 8640, 4320, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 1080, 8640, 4320, 1080, 1080, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 1080, 4320, 4320, 1080, 8640, 4320, 8640, 8640, 4320, 1080, 4320, 4320, 4320, 1080, 8640, 4320, 8640, 1080, 8640, 1080, 1080, 4320, 8640, 8640, 4320, 1080, 4320, 1080, 4320, 8640, 8640, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 4320, 4320, 8640, 4320, 4320, 1080, 4320, 8640, 4320, 1080, 1080, 4320, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 4320, 8640, 4320, 4320, 4320, 1080, 8640, 1080, 8640, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 4320, 1080, 4320, 1080, 1080, 1080, 8640, 8640, 4320, 4320, 1080, 1080, 4320, 1080, 8640, 1080, 1080, 4320, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 4320, 1080, 4320, 1080, 8640, 4320, 4320, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 4320, 1080, 4320, 1080, 4320, 8640, 8640, 8640, 1080, 8640, 8640, 8640, 8640, 1080, 4320, 4320, 8640, 1080, 8640, 1080, 1080, 1080, 8640, 4320, 8640, 8640, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 8640, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 1080]
Prompts retrieved: 1501200 . Total input tokens: 334488518 . Total output tokens: 300632801
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 83.58498524129391,
    "estimated_duration": 3600.1056189108062,
    "input_throughput": 6211.8341424566015,
    "output_throughput": 5478.175666959125,
    "total_throughput": 11690.009809415726,
    "itl": 152.74523768121705,
    "ttft": 1921614.8122492684,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 534,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.746310915779333,
    "arrivals": 500641,
    "finished_requests": 90411,
    "scheduler_time": 168.5159496289252
}
#Debug simulation 
Total elapsed time: 83.58512924890965. Arrivals time: 0.3562344014644623 Scheduler time: 83.08096559625119 Scheduler overhead time: 0.056958023458719254 Adapter cache time: 0.015193598810583353 Engine time: 0.05468613700941205 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-16-16/adapters_320_slots_64_rate_0.8-0.4-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-16-16/adapters_320_slots_64_rate_0.8-0.4-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 1080, 8640, 8640, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 8640, 8640, 4320, 1080, 1080, 4320, 8640, 8640, 4320, 4320, 1080, 1080, 4320, 8640, 8640, 1080, 8640, 4320, 1080, 4320, 8640, 1080, 4320, 8640, 8640, 4320, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 1080, 8640, 4320, 1080, 1080, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 1080, 4320, 4320, 1080, 8640, 4320, 8640, 8640, 4320, 1080, 4320, 4320, 4320, 1080, 8640, 4320, 8640, 1080, 8640, 1080, 1080, 4320, 8640, 8640, 4320, 1080, 4320, 1080, 4320, 8640, 8640, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 4320, 4320, 8640, 4320, 4320, 1080, 4320, 8640, 4320, 1080, 1080, 4320, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 4320, 8640, 4320, 4320, 4320, 1080, 8640, 1080, 8640, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 4320, 1080, 4320, 1080, 1080, 1080, 8640, 8640, 4320, 4320, 1080, 1080, 4320, 1080, 8640, 1080, 1080, 4320, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 4320, 1080, 4320, 1080, 8640, 4320, 4320, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 4320, 1080, 4320, 1080, 4320, 8640, 8640, 8640, 1080, 8640, 8640, 8640, 8640, 1080, 4320, 4320, 8640, 1080, 8640, 1080, 1080, 1080, 8640, 4320, 8640, 8640, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 8640, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 1080]
Prompts retrieved: 1501200 . Total input tokens: 334488518 . Total output tokens: 300632801
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 83.28841521311551,
    "estimated_duration": 3600.0807896980264,
    "input_throughput": 6211.393106507389,
    "output_throughput": 5481.06199629346,
    "total_throughput": 11692.45510280085,
    "itl": 152.80074435186006,
    "ttft": 1922296.8815822948,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 536,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6762141153868204,
    "arrivals": 500641,
    "finished_requests": 90413,
    "scheduler_time": 168.39170774734973
}
#Debug simulation 
Total elapsed time: 83.28856051713228. Arrivals time: 0.361704318318516 Scheduler time: 82.77862827014178 Scheduler overhead time: 0.057071460876613855 Adapter cache time: 0.015185810625553131 Engine time: 0.054804250597953796 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-16-32/adapters_320_slots_64_rate_0.8-0.4-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-16-32/adapters_320_slots_64_rate_0.8-0.4-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 1080, 8640, 8640, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 8640, 8640, 4320, 1080, 1080, 4320, 8640, 8640, 4320, 4320, 1080, 1080, 4320, 8640, 8640, 1080, 8640, 4320, 1080, 4320, 8640, 1080, 4320, 8640, 8640, 4320, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 1080, 8640, 4320, 1080, 1080, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 1080, 4320, 4320, 1080, 8640, 4320, 8640, 8640, 4320, 1080, 4320, 4320, 4320, 1080, 8640, 4320, 8640, 1080, 8640, 1080, 1080, 4320, 8640, 8640, 4320, 1080, 4320, 1080, 4320, 8640, 8640, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 4320, 4320, 8640, 4320, 4320, 1080, 4320, 8640, 4320, 1080, 1080, 4320, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 4320, 8640, 4320, 4320, 4320, 1080, 8640, 1080, 8640, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 4320, 1080, 4320, 1080, 1080, 1080, 8640, 8640, 4320, 4320, 1080, 1080, 4320, 1080, 8640, 1080, 1080, 4320, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 4320, 1080, 4320, 1080, 8640, 4320, 4320, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 4320, 1080, 4320, 1080, 4320, 8640, 8640, 8640, 1080, 8640, 8640, 8640, 8640, 1080, 4320, 4320, 8640, 1080, 8640, 1080, 1080, 1080, 8640, 4320, 8640, 8640, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 8640, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 1080]
Prompts retrieved: 1501200 . Total input tokens: 334488518 . Total output tokens: 300632801
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 84.78453741781414,
    "estimated_duration": 3600.051768405701,
    "input_throughput": 6206.019645627,
    "output_throughput": 5473.7537868036825,
    "total_throughput": 11679.773432430682,
    "itl": 152.61659148249583,
    "ttft": 1920375.5102547782,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 526,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7419461926445408,
    "arrivals": 500641,
    "finished_requests": 90290,
    "scheduler_time": 168.72354758671105
}
#Debug simulation 
Total elapsed time: 84.78468378679827. Arrivals time: 0.3579063415527344 Scheduler time: 84.2784418114461 Scheduler overhead time: 0.056961544789373875 Adapter cache time: 0.015142039861530066 Engine time: 0.05501927109435201 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_16-16-16/adapters_320_slots_64_rate_0.8-0.4-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_16-16-16/adapters_320_slots_64_rate_0.8-0.4-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 1080, 8640, 8640, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 8640, 8640, 4320, 1080, 1080, 4320, 8640, 8640, 4320, 4320, 1080, 1080, 4320, 8640, 8640, 1080, 8640, 4320, 1080, 4320, 8640, 1080, 4320, 8640, 8640, 4320, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 1080, 8640, 4320, 1080, 1080, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 1080, 4320, 4320, 1080, 8640, 4320, 8640, 8640, 4320, 1080, 4320, 4320, 4320, 1080, 8640, 4320, 8640, 1080, 8640, 1080, 1080, 4320, 8640, 8640, 4320, 1080, 4320, 1080, 4320, 8640, 8640, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 4320, 4320, 8640, 4320, 4320, 1080, 4320, 8640, 4320, 1080, 1080, 4320, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 4320, 8640, 4320, 4320, 4320, 1080, 8640, 1080, 8640, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 4320, 1080, 4320, 1080, 1080, 1080, 8640, 8640, 4320, 4320, 1080, 1080, 4320, 1080, 8640, 1080, 1080, 4320, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 4320, 1080, 4320, 1080, 8640, 4320, 4320, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 4320, 1080, 4320, 1080, 4320, 8640, 8640, 8640, 1080, 8640, 8640, 8640, 8640, 1080, 4320, 4320, 8640, 1080, 8640, 1080, 1080, 1080, 8640, 4320, 8640, 8640, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 8640, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 1080]
Prompts retrieved: 1501200 . Total input tokens: 334488518 . Total output tokens: 300632801
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 82.32956622540951,
    "estimated_duration": 3600.105686153853,
    "input_throughput": 6212.202071182261,
    "output_throughput": 5481.487411855013,
    "total_throughput": 11693.689483037273,
    "itl": 153.01209180569862,
    "ttft": 1922402.773919907,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 551,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6475177124910771,
    "arrivals": 500641,
    "finished_requests": 90440,
    "scheduler_time": 168.31754959086115
}
#Debug simulation 
Total elapsed time: 82.32971113128588. Arrivals time: 0.38360437704250216 Scheduler time: 81.79834876814857 Scheduler overhead time: 0.05641820887103677 Adapter cache time: 0.015081945806741714 Engine time: 0.055192091036587954 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_16-16-32/adapters_320_slots_64_rate_0.8-0.4-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_16-16-32/adapters_320_slots_64_rate_0.8-0.4-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 1080, 8640, 8640, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 8640, 8640, 4320, 1080, 1080, 4320, 8640, 8640, 4320, 4320, 1080, 1080, 4320, 8640, 8640, 1080, 8640, 4320, 1080, 4320, 8640, 1080, 4320, 8640, 8640, 4320, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 1080, 8640, 4320, 1080, 1080, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 1080, 4320, 4320, 1080, 8640, 4320, 8640, 8640, 4320, 1080, 4320, 4320, 4320, 1080, 8640, 4320, 8640, 1080, 8640, 1080, 1080, 4320, 8640, 8640, 4320, 1080, 4320, 1080, 4320, 8640, 8640, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 4320, 4320, 8640, 4320, 4320, 1080, 4320, 8640, 4320, 1080, 1080, 4320, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 4320, 8640, 4320, 4320, 4320, 1080, 8640, 1080, 8640, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 4320, 1080, 4320, 1080, 1080, 1080, 8640, 8640, 4320, 4320, 1080, 1080, 4320, 1080, 8640, 1080, 1080, 4320, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 4320, 1080, 4320, 1080, 8640, 4320, 4320, 8640, 8640, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 4320, 1080, 4320, 1080, 4320, 8640, 8640, 8640, 1080, 8640, 8640, 8640, 8640, 1080, 4320, 4320, 8640, 1080, 8640, 1080, 1080, 1080, 8640, 4320, 8640, 8640, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 8640, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 1080]
Prompts retrieved: 1501200 . Total input tokens: 334488518 . Total output tokens: 300632801
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 85.05556012084708,
    "estimated_duration": 3600.0705489328698,
    "input_throughput": 6205.987270616849,
    "output_throughput": 5473.7252318127985,
    "total_throughput": 11679.712502429647,
    "itl": 152.6172338759515,
    "ttft": 1920383.2721793163,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 526,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7643303666263788,
    "arrivals": 500641,
    "finished_requests": 90290,
    "scheduler_time": 168.72392243120103
}
#Debug simulation 
Total elapsed time: 85.05570293217897. Arrivals time: 0.3656642106361687 Scheduler time: 84.54056261526421 Scheduler overhead time: 0.05775373103097081 Adapter cache time: 0.015088748186826706 Engine time: 0.0551246702671051 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-8/adapters_320_slots_64_rate_0.8-0.4-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-8/adapters_320_slots_64_rate_0.8-0.4-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [106 107 107]
Adapter prompts. [4320, 8640, 8640, 540, 8640, 8640, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 8640, 8640, 4320, 540, 540, 4320, 8640, 8640, 4320, 4320, 540, 540, 4320, 8640, 8640, 540, 8640, 4320, 540, 4320, 8640, 540, 4320, 8640, 8640, 4320, 540, 540, 8640, 540, 540, 8640, 8640, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 8640, 540, 8640, 4320, 8640, 8640, 540, 8640, 540, 8640, 4320, 540, 540, 4320, 4320, 8640, 4320, 8640, 8640, 8640, 540, 4320, 4320, 540, 8640, 4320, 8640, 8640, 4320, 540, 4320, 4320, 4320, 540, 8640, 4320, 8640, 540, 8640, 540, 540, 4320, 8640, 8640, 4320, 540, 4320, 540, 4320, 8640, 8640, 4320, 540, 4320, 540, 8640, 540, 540, 540, 540, 8640, 4320, 4320, 8640, 4320, 4320, 540, 4320, 8640, 4320, 540, 540, 4320, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 4320, 8640, 4320, 4320, 4320, 540, 8640, 540, 8640, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 540, 540, 8640, 4320, 8640, 4320, 8640, 4320, 540, 4320, 540, 540, 540, 8640, 8640, 4320, 4320, 540, 540, 4320, 540, 8640, 540, 540, 4320, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 540, 4320, 8640, 4320, 4320, 8640, 4320, 540, 4320, 540, 8640, 4320, 4320, 8640, 8640, 540, 540, 540, 8640, 8640, 540, 540, 8640, 4320, 540, 4320, 540, 4320, 8640, 8640, 8640, 540, 8640, 8640, 8640, 8640, 540, 4320, 4320, 8640, 540, 8640, 540, 540, 540, 8640, 4320, 8640, 8640, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 8640, 540, 540, 4320, 540, 4320, 4320, 540, 8640, 8640, 8640, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 4320, 4320, 4320, 540, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 8640, 4320, 8640, 4320, 540, 8640, 540, 8640, 8640, 540, 540, 540]
Prompts retrieved: 1443960 . Total input tokens: 321804801 . Total output tokens: 289105213
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 83.57037997478619,
    "estimated_duration": 3600.0397642146922,
    "input_throughput": 6160.768617187233,
    "output_throughput": 5484.259700755509,
    "total_throughput": 11645.02831794274,
    "itl": 152.97189904709796,
    "ttft": 1920849.5715404085,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 528,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.615937528796514,
    "arrivals": 481654,
    "finished_requests": 90012,
    "scheduler_time": 168.31778043073004
}
#Debug simulation 
Total elapsed time: 83.57053097710013. Arrivals time: 0.36728935688734055 Scheduler time: 83.05671043833718 Scheduler overhead time: 0.055974419228732586 Adapter cache time: 0.01497356640174985 Engine time: 0.05376418028026819 
