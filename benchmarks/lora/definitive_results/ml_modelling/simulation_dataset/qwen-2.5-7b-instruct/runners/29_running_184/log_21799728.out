INFO 06-01 00:46:59 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:47:00 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-32/adapters_96_slots_16_rate_1.6-0.8-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-32/adapters_96_slots_16_rate_1.6-0.8-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 8640, 17280, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 33, 17280, 8640, 8640, 33, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 33, 17280, 8640, 8640, 8640, 17280, 17280, 33, 33, 8640, 33, 17280, 33, 33, 17280, 33, 8640, 8640, 33, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 33, 33, 17280, 8640, 17280, 33, 8640, 17280, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 33, 33, 8640]
Prompts retrieved: 830496 . Total input tokens: 185017985 . Total output tokens: 166201334
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 140.17107732594013,
    "estimated_duration": 3600.0095474967957,
    "input_throughput": 7979.2221717783,
    "output_throughput": 7064.165709694589,
    "total_throughput": 15043.38788147289,
    "itl": 105.55626763477514,
    "ttft": 1541968.596661669,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 163,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5311673117801565,
    "arrivals": 276581,
    "finished_requests": 115610,
    "scheduler_time": 244.04034731026476
}
#Debug simulation 
Total elapsed time: 140.17128861602396. Arrivals time: 0.7019900078885257 Scheduler time: 139.2022626027465 Scheduler overhead time: 0.10538987535983324 Adapter cache time: 0.02088209753856063 Engine time: 0.10527644027024508 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-16/adapters_96_slots_16_rate_1.6-0.8-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-16/adapters_96_slots_16_rate_1.6-0.8-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 8640, 17280, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 33, 17280, 8640, 8640, 33, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 33, 17280, 8640, 8640, 8640, 17280, 17280, 33, 33, 8640, 33, 17280, 33, 33, 17280, 33, 8640, 8640, 33, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 33, 33, 17280, 8640, 17280, 33, 8640, 17280, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 33, 33, 8640]
Prompts retrieved: 830496 . Total input tokens: 185017985 . Total output tokens: 166201334
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 130.3780206865631,
    "estimated_duration": 3600.054434801812,
    "input_throughput": 7960.544074822492,
    "output_throughput": 7014.769209007875,
    "total_throughput": 14975.313283830366,
    "itl": 105.44395199345325,
    "ttft": 1563196.412127546,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 163,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5078079639910724,
    "arrivals": 276581,
    "finished_requests": 115309,
    "scheduler_time": 244.24548467677903
}
#Debug simulation 
Total elapsed time: 130.37822772469372. Arrivals time: 0.6804366302676499 Scheduler time: 129.43754824716598 Scheduler overhead time: 0.1025642235763371 Adapter cache time: 0.020443564746528864 Engine time: 0.10190331656485796 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-32/adapters_96_slots_16_rate_1.6-0.8-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-32/adapters_96_slots_16_rate_1.6-0.8-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 8640, 17280, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 33, 17280, 8640, 8640, 33, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 33, 17280, 8640, 8640, 8640, 17280, 17280, 33, 33, 8640, 33, 17280, 33, 33, 17280, 33, 8640, 8640, 33, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 33, 33, 17280, 8640, 17280, 33, 8640, 17280, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 33, 33, 8640]
Prompts retrieved: 830496 . Total input tokens: 185017985 . Total output tokens: 166201334
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 141.74975382024422,
    "estimated_duration": 3600.0156586427975,
    "input_throughput": 7979.208626783974,
    "output_throughput": 7064.153718038962,
    "total_throughput": 15043.362344822935,
    "itl": 105.55644038315765,
    "ttft": 1541971.2619326334,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 163,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5372034935280692,
    "arrivals": 276581,
    "finished_requests": 115610,
    "scheduler_time": 244.04042227452265
}
#Debug simulation 
Total elapsed time: 141.7499224911444. Arrivals time: 0.7499422687105834 Scheduler time: 140.72624445566908 Scheduler overhead time: 0.10803379956632853 Adapter cache time: 0.021748648956418037 Engine time: 0.10818344680592418 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-16/adapters_96_slots_16_rate_1.6-0.8-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-16/adapters_96_slots_16_rate_1.6-0.8-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 8640, 17280, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 33, 17280, 8640, 8640, 33, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 33, 17280, 8640, 8640, 8640, 17280, 17280, 33, 33, 8640, 33, 17280, 33, 33, 17280, 33, 8640, 8640, 33, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 33, 33, 17280, 8640, 17280, 33, 8640, 17280, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 33, 33, 8640]
Prompts retrieved: 830496 . Total input tokens: 185017985 . Total output tokens: 166201334
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 126.78272408386692,
    "estimated_duration": 3600.099117236107,
    "input_throughput": 7954.002117026159,
    "output_throughput": 7006.812084486741,
    "total_throughput": 14960.8142015129,
    "itl": 105.48791882382784,
    "ttft": 1560900.4396664668,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 187,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5591394051467076,
    "arrivals": 276581,
    "finished_requests": 115192,
    "scheduler_time": 244.60237853737334
}
#Debug simulation 
Total elapsed time: 126.78289715386927. Arrivals time: 0.6765941716730595 Scheduler time: 125.85234298137948 Scheduler overhead time: 0.09980007354170084 Adapter cache time: 0.01979523804038763 Engine time: 0.09996916120871902 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-32/adapters_96_slots_16_rate_1.6-0.8-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-32/adapters_96_slots_16_rate_1.6-0.8-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 8640, 17280, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 33, 17280, 8640, 8640, 33, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 33, 17280, 8640, 8640, 8640, 17280, 17280, 33, 33, 8640, 33, 17280, 33, 33, 17280, 33, 8640, 8640, 33, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 33, 33, 17280, 8640, 17280, 33, 8640, 17280, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 33, 33, 8640]
Prompts retrieved: 830496 . Total input tokens: 185017985 . Total output tokens: 166201334
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 145.28279626509175,
    "estimated_duration": 3600.0299951282873,
    "input_throughput": 7939.873567353823,
    "output_throughput": 7004.6391374862405,
    "total_throughput": 14944.512704840063,
    "itl": 104.98496490191553,
    "ttft": 1556168.7111505594,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 168,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5608523036539558,
    "arrivals": 276581,
    "finished_requests": 115139,
    "scheduler_time": 244.77813702116168
}
#Debug simulation 
Total elapsed time: 145.28297401033342. Arrivals time: 0.7437859964556992 Scheduler time: 144.26423569815233 Scheduler overhead time: 0.10905325831845403 Adapter cache time: 0.02138695679605007 Engine time: 0.10849407501518726 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-8/adapters_96_slots_16_rate_1.6-0.4-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-8/adapters_96_slots_16_rate_1.6-0.4-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 1080, 17280, 4320, 1080, 1080, 4320, 17280, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 17280, 4320, 4320, 1080, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 1080, 17280, 4320, 4320, 4320, 17280, 17280, 1080, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 1080, 1080, 17280, 4320, 17280, 1080, 4320, 17280, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 4320]
Prompts retrieved: 725760 . Total input tokens: 161758167 . Total output tokens: 145106966
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 148.50727722560987,
    "estimated_duration": 3600.020908671498,
    "input_throughput": 7830.566742570093,
    "output_throughput": 6970.55395971586,
    "total_throughput": 14801.120702285953,
    "itl": 101.09191743889133,
    "ttft": 1460830.549760012,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 161,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.49273852677317276,
    "arrivals": 241359,
    "finished_requests": 114125,
    "scheduler_time": 244.77129539840286
}
#Debug simulation 
Total elapsed time: 148.5074518788606. Arrivals time: 0.6811577854678035 Scheduler time: 147.54638564400375 Scheduler overhead time: 0.11150738270953298 Adapter cache time: 0.02126761805266142 Engine time: 0.10985462507233024 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-16/adapters_96_slots_16_rate_1.6-0.4-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-16/adapters_96_slots_16_rate_1.6-0.4-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 1080, 17280, 4320, 1080, 1080, 4320, 17280, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 17280, 4320, 4320, 1080, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 1080, 17280, 4320, 4320, 4320, 17280, 17280, 1080, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 1080, 1080, 17280, 4320, 17280, 1080, 4320, 17280, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 4320]
Prompts retrieved: 725760 . Total input tokens: 161758167 . Total output tokens: 145106966
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 140.27652501314878,
    "estimated_duration": 3600.034316559589,
    "input_throughput": 7828.057602220785,
    "output_throughput": 6952.2851170815275,
    "total_throughput": 14780.342719302313,
    "itl": 101.86054464881836,
    "ttft": 1472946.2673339404,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 169,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5486296035931452,
    "arrivals": 241359,
    "finished_requests": 114226,
    "scheduler_time": 244.22026331458426
}
#Debug simulation 
Total elapsed time: 140.2766962070018. Arrivals time: 0.6773182465694845 Scheduler time: 139.33356357226148 Scheduler overhead time: 0.10390986874699593 Adapter cache time: 0.02081987913697958 Engine time: 0.10442121280357242 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-32/adapters_96_slots_16_rate_1.6-0.4-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-32/adapters_96_slots_16_rate_1.6-0.4-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 1080, 17280, 4320, 1080, 1080, 4320, 17280, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 17280, 4320, 4320, 1080, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 1080, 17280, 4320, 4320, 4320, 17280, 17280, 1080, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 1080, 1080, 17280, 4320, 17280, 1080, 4320, 17280, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 4320]
Prompts retrieved: 725760 . Total input tokens: 161758167 . Total output tokens: 145106966
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 141.6725362869911,
    "estimated_duration": 3600.0361170561005,
    "input_throughput": 7828.053687151618,
    "output_throughput": 6952.281640014995,
    "total_throughput": 14780.335327166613,
    "itl": 101.86057110748108,
    "ttft": 1472947.2000544944,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 169,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5501029198616763,
    "arrivals": 241359,
    "finished_requests": 114226,
    "scheduler_time": 244.22039041766368
}
#Debug simulation 
Total elapsed time: 141.67270460911095. Arrivals time: 0.674096517264843 Scheduler time: 140.7314287647605 Scheduler overhead time: 0.10558522399514914 Adapter cache time: 0.020408714655786753 Engine time: 0.10390260489657521 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-16-16/adapters_96_slots_16_rate_1.6-0.4-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-16-16/adapters_96_slots_16_rate_1.6-0.4-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 1080, 17280, 4320, 1080, 1080, 4320, 17280, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 17280, 4320, 4320, 1080, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 1080, 17280, 4320, 4320, 4320, 17280, 17280, 1080, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 1080, 1080, 17280, 4320, 17280, 1080, 4320, 17280, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 4320]
Prompts retrieved: 725760 . Total input tokens: 161758167 . Total output tokens: 145106966
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 146.14360431581736,
    "estimated_duration": 3600.0321401654446,
    "input_throughput": 7830.54231252071,
    "output_throughput": 6970.532212761513,
    "total_throughput": 14801.074525282222,
    "itl": 101.09216735808513,
    "ttft": 1460836.1607652768,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 161,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5026450540381486,
    "arrivals": 241359,
    "finished_requests": 114125,
    "scheduler_time": 244.7718200564237
}
#Debug simulation 
Total elapsed time: 146.14385625580326. Arrivals time: 0.6923054866492748 Scheduler time: 145.17285928921774 Scheduler overhead time: 0.1111870021559298 Adapter cache time: 0.021226401440799236 Engine time: 0.10915534477680922 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-16-32/adapters_96_slots_16_rate_1.6-0.4-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-16-32/adapters_96_slots_16_rate_1.6-0.4-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 1080, 17280, 4320, 1080, 1080, 4320, 17280, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 17280, 4320, 4320, 1080, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 1080, 17280, 4320, 4320, 4320, 17280, 17280, 1080, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 1080, 1080, 17280, 4320, 17280, 1080, 4320, 17280, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 4320]
Prompts retrieved: 725760 . Total input tokens: 161758167 . Total output tokens: 145106966
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 140.93645226303488,
    "estimated_duration": 3600.0433257504496,
    "input_throughput": 7828.03801232738,
    "output_throughput": 6952.267718828821,
    "total_throughput": 14780.3057311562,
    "itl": 101.86076420193648,
    "ttft": 1472950.3447337344,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 169,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5567678705416634,
    "arrivals": 241359,
    "finished_requests": 114226,
    "scheduler_time": 244.2205340070146
}
#Debug simulation 
Total elapsed time: 140.9366305009462. Arrivals time: 0.6815064423717558 Scheduler time: 139.9824463641271 Scheduler overhead time: 0.10790250590071082 Adapter cache time: 0.020903408993035555 Engine time: 0.10672267992049456 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_16-16-16/adapters_96_slots_16_rate_1.6-0.4-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_16-16-16/adapters_96_slots_16_rate_1.6-0.4-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 1080, 17280, 4320, 1080, 1080, 4320, 17280, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 17280, 4320, 4320, 1080, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 1080, 17280, 4320, 4320, 4320, 17280, 17280, 1080, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 1080, 1080, 17280, 4320, 17280, 1080, 4320, 17280, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 4320]
Prompts retrieved: 725760 . Total input tokens: 161758167 . Total output tokens: 145106966
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 145.59444552380592,
    "estimated_duration": 3600.0100475108034,
    "input_throughput": 7830.590367238525,
    "output_throughput": 6970.574989742357,
    "total_throughput": 14801.165356980882,
    "itl": 101.09164812285881,
    "ttft": 1460825.7400533953,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 161,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4813980974792509,
    "arrivals": 241359,
    "finished_requests": 114125,
    "scheduler_time": 244.77107439691744
}
#Debug simulation 
Total elapsed time: 145.59461793256924. Arrivals time: 0.723241787403822 Scheduler time: 144.59804391860962 Scheduler overhead time: 0.10791701264679432 Adapter cache time: 0.021669738925993443 Engine time: 0.10683155339211226 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_16-16-32/adapters_96_slots_16_rate_1.6-0.4-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_16-16-32/adapters_96_slots_16_rate_1.6-0.4-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 1080, 17280, 4320, 1080, 1080, 4320, 17280, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 17280, 4320, 4320, 1080, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 1080, 17280, 4320, 4320, 4320, 17280, 17280, 1080, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 1080, 1080, 17280, 4320, 17280, 1080, 4320, 17280, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 4320]
Prompts retrieved: 725760 . Total input tokens: 161758167 . Total output tokens: 145106966
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 143.91796451993287,
    "estimated_duration": 3600.0503242032337,
    "input_throughput": 7828.0227947194335,
    "output_throughput": 6952.254203707367,
    "total_throughput": 14780.2769984268,
    "itl": 101.86087784875106,
    "ttft": 1472953.5996760994,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 169,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5634328212216503,
    "arrivals": 241359,
    "finished_requests": 114226,
    "scheduler_time": 244.22076747054183
}
#Debug simulation 
Total elapsed time: 143.91825215518475. Arrivals time: 0.7473404286429286 Scheduler time: 142.89138822397217 Scheduler overhead time: 0.1110570072196424 Adapter cache time: 0.022094132378697395 Engine time: 0.10836650291457772 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-8/adapters_96_slots_16_rate_1.6-0.4-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-8/adapters_96_slots_16_rate_1.6-0.4-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 540, 17280, 4320, 540, 540, 4320, 17280, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 540, 17280, 4320, 4320, 540, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 540, 17280, 4320, 4320, 4320, 17280, 17280, 540, 540, 4320, 540, 17280, 540, 540, 17280, 540, 4320, 4320, 540, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 540, 540, 17280, 4320, 17280, 540, 4320, 17280, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 540, 540, 4320]
Prompts retrieved: 708480 . Total input tokens: 157970588 . Total output tokens: 141629128
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 157.22410996770486,
    "estimated_duration": 3600.0585441398803,
    "input_throughput": 7790.791359672461,
    "output_throughput": 6911.506769939133,
    "total_throughput": 14702.298129611594,
    "itl": 101.02768354050849,
    "ttft": 1455372.336423086,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 143,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.43764974738238327,
    "arrivals": 235577,
    "finished_requests": 113458,
    "scheduler_time": 246.32342595703338
}
#Debug simulation 
Total elapsed time: 157.22428072011098. Arrivals time: 0.7134836250916123 Scheduler time: 156.2239847886376 Scheduler overhead time: 0.11310023022815585 Adapter cache time: 0.022248791065067053 Engine time: 0.11355595802888274 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-16/adapters_96_slots_16_rate_1.6-0.4-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-16/adapters_96_slots_16_rate_1.6-0.4-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 540, 17280, 4320, 540, 540, 4320, 17280, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 540, 17280, 4320, 4320, 540, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 540, 17280, 4320, 4320, 4320, 17280, 17280, 540, 540, 4320, 540, 17280, 540, 540, 17280, 540, 4320, 4320, 540, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 540, 540, 17280, 4320, 17280, 540, 4320, 17280, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 540, 540, 4320]
Prompts retrieved: 708480 . Total input tokens: 157970588 . Total output tokens: 141629128
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 150.0540232709609,
    "estimated_duration": 3600.0083037858526,
    "input_throughput": 7790.387308414467,
    "output_throughput": 6911.011281233971,
    "total_throughput": 14701.39858964844,
    "itl": 101.02757463027356,
    "ttft": 1455490.9283419088,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 143,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4627163895568811,
    "arrivals": 235577,
    "finished_requests": 113451,
    "scheduler_time": 246.31763709133634
}
#Debug simulation 
Total elapsed time: 150.0541972699575. Arrivals time: 0.6697708838619292 Scheduler time: 149.1158528435044 Scheduler overhead time: 0.10575868003070354 Adapter cache time: 0.02034163335338235 Engine time: 0.10561352269724011 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-32/adapters_96_slots_16_rate_1.6-0.4-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-32/adapters_96_slots_16_rate_1.6-0.4-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 540, 17280, 4320, 540, 540, 4320, 17280, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 540, 17280, 4320, 4320, 540, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 540, 17280, 4320, 4320, 4320, 17280, 17280, 540, 540, 4320, 540, 17280, 540, 540, 17280, 540, 4320, 4320, 540, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 540, 540, 17280, 4320, 17280, 540, 4320, 17280, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 540, 540, 4320]
Prompts retrieved: 708480 . Total input tokens: 157970588 . Total output tokens: 141629128
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 157.3999923397787,
    "estimated_duration": 3600.009880684372,
    "input_throughput": 7790.383896020996,
    "output_throughput": 6911.008254030208,
    "total_throughput": 14701.392150051204,
    "itl": 101.02762807730676,
    "ttft": 1455491.64862567,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 143,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4642264799028649,
    "arrivals": 235577,
    "finished_requests": 113451,
    "scheduler_time": 246.3177038995075
}
#Debug simulation 
Total elapsed time: 157.40027050673962. Arrivals time: 0.7264811503700912 Scheduler time: 156.3795679458417 Scheduler overhead time: 0.11709546344354749 Adapter cache time: 0.022550075314939022 Engine time: 0.11566510424017906 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-16-16/adapters_96_slots_16_rate_1.6-0.4-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-16-16/adapters_96_slots_16_rate_1.6-0.4-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 540, 17280, 4320, 540, 540, 4320, 17280, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 540, 17280, 4320, 4320, 540, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 540, 17280, 4320, 4320, 4320, 17280, 17280, 540, 540, 4320, 540, 17280, 540, 540, 17280, 540, 4320, 4320, 540, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 540, 540, 17280, 4320, 17280, 540, 4320, 17280, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 540, 540, 4320]
Prompts retrieved: 708480 . Total input tokens: 157970588 . Total output tokens: 141629128
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 156.36208200268447,
    "estimated_duration": 3600.0671264565153,
    "input_throughput": 7790.7727869525825,
    "output_throughput": 6911.490293374268,
    "total_throughput": 14702.263080326851,
    "itl": 101.02780849970985,
    "ttft": 1455376.0229220716,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 143,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4463725768192674,
    "arrivals": 235577,
    "finished_requests": 113458,
    "scheduler_time": 246.3235855599565
}
#Debug simulation 
Total elapsed time: 156.36225585872307. Arrivals time: 0.6960244099609554 Scheduler time: 155.38158334372565 Scheduler overhead time: 0.11171748070046306 Adapter cache time: 0.022485309280455112 Engine time: 0.11178209539502859 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-16-32/adapters_96_slots_16_rate_1.6-0.4-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-16-32/adapters_96_slots_16_rate_1.6-0.4-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 540, 17280, 4320, 540, 540, 4320, 17280, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 540, 17280, 4320, 4320, 540, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 540, 17280, 4320, 4320, 4320, 17280, 17280, 540, 540, 4320, 540, 17280, 540, 540, 17280, 540, 4320, 4320, 540, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 540, 540, 17280, 4320, 17280, 540, 4320, 17280, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 540, 540, 4320]
Prompts retrieved: 708480 . Total input tokens: 157970588 . Total output tokens: 141629128
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 161.30207559792325,
    "estimated_duration": 3600.0153351630893,
    "input_throughput": 7790.372092603731,
    "output_throughput": 6910.997782978302,
    "total_throughput": 14701.369875582033,
    "itl": 101.02773693500764,
    "ttft": 1455494.3035345813,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 143,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4692566313594587,
    "arrivals": 235577,
    "finished_requests": 113451,
    "scheduler_time": 246.31782811102747
}
#Debug simulation 
Total elapsed time: 161.30224242573604. Arrivals time: 0.7230016891844571 Scheduler time: 160.28331436263397 Scheduler overhead time: 0.11850476916879416 Adapter cache time: 0.022830128204077482 Engine time: 0.11540651926770806 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_16-16-16/adapters_96_slots_16_rate_1.6-0.4-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_16-16-16/adapters_96_slots_16_rate_1.6-0.4-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 540, 17280, 4320, 540, 540, 4320, 17280, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 540, 17280, 4320, 4320, 540, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 540, 17280, 4320, 4320, 4320, 17280, 17280, 540, 540, 4320, 540, 17280, 540, 540, 17280, 540, 4320, 4320, 540, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 540, 540, 17280, 4320, 17280, 540, 4320, 17280, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 540, 540, 4320]
Prompts retrieved: 708480 . Total input tokens: 157970588 . Total output tokens: 141629128
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 155.0107175358571,
    "estimated_duration": 3600.0480953691654,
    "input_throughput": 7790.813971646093,
    "output_throughput": 6911.526829879339,
    "total_throughput": 14702.340801525432,
    "itl": 101.02744933989901,
    "ttft": 1455367.5007637104,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 143,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42757719217101164,
    "arrivals": 235577,
    "finished_requests": 113458,
    "scheduler_time": 246.32314978008537
}
#Debug simulation 
Total elapsed time: 155.0109881698154. Arrivals time: 0.687759826425463 Scheduler time: 154.04498813860118 Scheduler overhead time: 0.1107372073456645 Adapter cache time: 0.02126141544431448 Engine time: 0.10888055665418506 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_16-16-32/adapters_96_slots_16_rate_1.6-0.4-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_16-16-32/adapters_96_slots_16_rate_1.6-0.4-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 540, 17280, 4320, 540, 540, 4320, 17280, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 540, 17280, 4320, 4320, 540, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 540, 17280, 4320, 4320, 4320, 17280, 17280, 540, 540, 4320, 540, 17280, 540, 540, 17280, 540, 4320, 4320, 540, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 540, 540, 17280, 4320, 17280, 540, 4320, 17280, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 540, 540, 4320]
Prompts retrieved: 708480 . Total input tokens: 157970588 . Total output tokens: 141629128
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 153.8983432939276,
    "estimated_duration": 3600.021269734985,
    "input_throughput": 7790.359250312031,
    "output_throughput": 6910.986390319721,
    "total_throughput": 14701.345640631751,
    "itl": 101.0278427076356,
    "ttft": 1455496.9685978368,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 143,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.47504130553454144,
    "arrivals": 235577,
    "finished_requests": 113451,
    "scheduler_time": 246.31800012639772
}
#Debug simulation 
Total elapsed time: 153.89851507218555. Arrivals time: 0.713056773878634 Scheduler time: 152.9062387975864 Scheduler overhead time: 0.10935031296685338 Adapter cache time: 0.021305500529706478 Engine time: 0.11026985477656126 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-8/adapters_96_slots_16_rate_1.6-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-8/adapters_96_slots_16_rate_1.6-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 4320, 17280, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 17280, 4320, 4320, 270, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 270, 17280, 4320, 4320, 4320, 17280, 17280, 270, 270, 4320, 270, 17280, 270, 270, 17280, 270, 4320, 4320, 270, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 270, 270, 17280, 4320, 17280, 270, 4320, 17280, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 270, 270, 4320]
Prompts retrieved: 699840 . Total input tokens: 156062165 . Total output tokens: 139886480
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 136.591097692959,
    "estimated_duration": 3600.0888138807773,
    "input_throughput": 7953.471283708234,
    "output_throughput": 7038.022757190538,
    "total_throughput": 14991.494040898771,
    "itl": 102.73012066562508,
    "ttft": 1436532.0000345716,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 157,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.48049657579744176,
    "arrivals": 232682,
    "finished_requests": 115700,
    "scheduler_time": 240.25583245083965
}
#Debug simulation 
Total elapsed time: 136.5912725920789. Arrivals time: 0.6751419836655259 Scheduler time: 135.65701568871737 Scheduler overhead time: 0.10066369827836752 Adapter cache time: 0.019422344863414764 Engine time: 0.10322449775412679 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-16/adapters_96_slots_16_rate_1.6-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-16/adapters_96_slots_16_rate_1.6-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 4320, 17280, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 17280, 4320, 4320, 270, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 270, 17280, 4320, 4320, 4320, 17280, 17280, 270, 270, 4320, 270, 17280, 270, 270, 17280, 270, 4320, 4320, 270, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 270, 270, 17280, 4320, 17280, 270, 4320, 17280, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 270, 270, 4320]
Prompts retrieved: 699840 . Total input tokens: 156062165 . Total output tokens: 139886480
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 143.55797366518527,
    "estimated_duration": 3600.120086009367,
    "input_throughput": 7953.4021965748125,
    "output_throughput": 7037.96162202076,
    "total_throughput": 14991.363818595572,
    "itl": 102.73081820592044,
    "ttft": 1436545.6623489943,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 157,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5107060234621168,
    "arrivals": 232682,
    "finished_requests": 115700,
    "scheduler_time": 240.25640725666221
}
#Debug simulation 
Total elapsed time: 143.55824371706694. Arrivals time: 0.7279754281044006 Scheduler time: 142.5494686011225 Scheduler overhead time: 0.11112722242251039 Adapter cache time: 0.021307144779711962 Engine time: 0.11061428161337972 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-32/adapters_96_slots_16_rate_1.6-0.4-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-32/adapters_96_slots_16_rate_1.6-0.4-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 4320, 17280, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 17280, 4320, 4320, 270, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 270, 17280, 4320, 4320, 4320, 17280, 17280, 270, 270, 4320, 270, 17280, 270, 270, 17280, 270, 4320, 4320, 270, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 270, 270, 17280, 4320, 17280, 270, 4320, 17280, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 270, 270, 4320]
Prompts retrieved: 699840 . Total input tokens: 156062165 . Total output tokens: 139886480
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 138.00789137696847,
    "estimated_duration": 3600.121090341068,
    "input_throughput": 7953.399977801122,
    "output_throughput": 7037.959658629032,
    "total_throughput": 14991.359636430154,
    "itl": 102.73083810549743,
    "ttft": 1436546.020652252,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 157,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5118944562040286,
    "arrivals": 232682,
    "finished_requests": 115700,
    "scheduler_time": 240.2564232327801
}
#Debug simulation 
Total elapsed time: 138.0080681988038. Arrivals time: 0.6807450046762824 Scheduler time: 137.06545465253294 Scheduler overhead time: 0.10314431181177497 Adapter cache time: 0.02032929565757513 Engine time: 0.10258953040465713 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-16-16/adapters_96_slots_16_rate_1.6-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-16-16/adapters_96_slots_16_rate_1.6-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 4320, 17280, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 17280, 4320, 4320, 270, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 270, 17280, 4320, 4320, 4320, 17280, 17280, 270, 270, 4320, 270, 17280, 270, 270, 17280, 270, 4320, 4320, 270, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 270, 270, 17280, 4320, 17280, 270, 4320, 17280, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 270, 270, 4320]
Prompts retrieved: 699840 . Total input tokens: 156062165 . Total output tokens: 139886480
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 141.12355209421366,
    "estimated_duration": 3600.09806464652,
    "input_throughput": 7953.450846570588,
    "output_throughput": 7038.004672377666,
    "total_throughput": 14991.455518948254,
    "itl": 102.73029940003826,
    "ttft": 1436536.5646894006,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 157,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4890504715847786,
    "arrivals": 232682,
    "finished_requests": 115700,
    "scheduler_time": 240.25614148426536
}
#Debug simulation 
Total elapsed time: 141.12372320936993. Arrivals time: 0.6840641391463578 Scheduler time: 140.16819241130725 Scheduler overhead time: 0.10623670183122158 Adapter cache time: 0.021109933499246836 Engine time: 0.10716686537489295 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-16-32/adapters_96_slots_16_rate_1.6-0.4-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-16-32/adapters_96_slots_16_rate_1.6-0.4-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 4320, 17280, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 17280, 4320, 4320, 270, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 270, 17280, 4320, 4320, 4320, 17280, 17280, 270, 270, 4320, 270, 17280, 270, 270, 17280, 270, 4320, 4320, 270, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 270, 270, 17280, 4320, 17280, 270, 4320, 17280, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 270, 270, 4320]
Prompts retrieved: 699840 . Total input tokens: 156062165 . Total output tokens: 139886480
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 138.85762214567512,
    "estimated_duration": 3600.127480058507,
    "input_throughput": 7953.385861640286,
    "output_throughput": 7037.947167245376,
    "total_throughput": 14991.333028885661,
    "itl": 102.73096961016563,
    "ttft": 1436548.556306573,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 157,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5185594068840153,
    "arrivals": 232682,
    "finished_requests": 115700,
    "scheduler_time": 240.25654815386585
}
#Debug simulation 
Total elapsed time: 138.85790959885344. Arrivals time: 0.6898171082139015 Scheduler time: 137.90226987889037 Scheduler overhead time: 0.10473633650690317 Adapter cache time: 0.020389764104038477 Engine time: 0.10456641064956784 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_16-16-16/adapters_96_slots_16_rate_1.6-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_16-16-16/adapters_96_slots_16_rate_1.6-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 4320, 17280, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 17280, 4320, 4320, 270, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 270, 17280, 4320, 4320, 4320, 17280, 17280, 270, 270, 4320, 270, 17280, 270, 270, 17280, 270, 4320, 4320, 270, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 270, 270, 17280, 4320, 17280, 270, 4320, 17280, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 270, 270, 4320]
Prompts retrieved: 699840 . Total input tokens: 156062165 . Total output tokens: 139886480
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 142.37033332604915,
    "estimated_duration": 3600.0775348037264,
    "input_throughput": 7953.496202009177,
    "output_throughput": 7038.044807382567,
    "total_throughput": 14991.541009391745,
    "itl": 102.7297126804355,
    "ttft": 1436527.1812821818,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 157,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.46943789629964217,
    "arrivals": 232682,
    "finished_requests": 115700,
    "scheduler_time": 240.2555087480643
}
#Debug simulation 
Total elapsed time: 142.3705052579753. Arrivals time: 0.7082975786179304 Scheduler time: 141.38740010326728 Scheduler overhead time: 0.10808689054101706 Adapter cache time: 0.02069280855357647 Engine time: 0.10839865636080503 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_16-16-32/adapters_96_slots_16_rate_1.6-0.4-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_16-16-32/adapters_96_slots_16_rate_1.6-0.4-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 4320, 17280, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 17280, 4320, 4320, 270, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 270, 17280, 4320, 4320, 4320, 17280, 17280, 270, 270, 4320, 270, 17280, 270, 270, 17280, 270, 4320, 4320, 270, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 270, 270, 17280, 4320, 17280, 270, 4320, 17280, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 270, 270, 4320]
Prompts retrieved: 699840 . Total input tokens: 156062165 . Total output tokens: 139886480
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 134.5709165208973,
    "estimated_duration": 3600.0044528334124,
    "input_throughput": 7953.364051387447,
    "output_throughput": 7037.957405874475,
    "total_throughput": 14991.321457261922,
    "itl": 102.73100006352215,
    "ttft": 1436545.8311506868,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 157,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5245955886319278,
    "arrivals": 232682,
    "finished_requests": 115697,
    "scheduler_time": 240.24822263067853
}
#Debug simulation 
Total elapsed time: 134.57109877979383. Arrivals time: 0.6388370040804148 Scheduler time: 133.67572477599606 Scheduler overhead time: 0.10028040269389749 Adapter cache time: 0.018977918662130833 Engine time: 0.10104340687394142 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-8/adapters_96_slots_16_rate_1.6-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-8/adapters_96_slots_16_rate_1.6-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 4320, 17280, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 17280, 4320, 4320, 135, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 135, 17280, 4320, 4320, 4320, 17280, 17280, 135, 135, 4320, 135, 17280, 135, 135, 17280, 135, 4320, 4320, 135, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 135, 135, 17280, 4320, 17280, 135, 4320, 17280, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 135, 135, 4320]
Prompts retrieved: 695520 . Total input tokens: 155117441 . Total output tokens: 139015307
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 139.3199007329531,
    "estimated_duration": 3600.008457027254,
    "input_throughput": 7938.997183245681,
    "output_throughput": 7033.637087872071,
    "total_throughput": 14972.634271117751,
    "itl": 103.09428852260797,
    "ttft": 1439979.769704486,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 163,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.49885950226103826,
    "arrivals": 231202,
    "finished_requests": 115461,
    "scheduler_time": 239.35078322139879
}
#Debug simulation 
Total elapsed time: 139.3201627349481. Arrivals time: 0.6781575470231473 Scheduler time: 138.37533748196438 Scheduler overhead time: 0.10532458079978824 Adapter cache time: 0.02109986636787653 Engine time: 0.10422566533088684 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-16/adapters_96_slots_16_rate_1.6-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-16/adapters_96_slots_16_rate_1.6-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 4320, 17280, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 17280, 4320, 4320, 135, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 135, 17280, 4320, 4320, 4320, 17280, 17280, 135, 135, 4320, 135, 17280, 135, 135, 17280, 135, 4320, 4320, 135, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 135, 135, 17280, 4320, 17280, 135, 4320, 17280, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 135, 135, 4320]
Prompts retrieved: 695520 . Total input tokens: 155117441 . Total output tokens: 139015307
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 148.3084050542675,
    "estimated_duration": 3600.047507245993,
    "input_throughput": 7910.528942376555,
    "output_throughput": 7016.041301999991,
    "total_throughput": 14926.570244376546,
    "itl": 102.82219620837239,
    "ttft": 1438544.5788520738,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 157,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5115232140989976,
    "arrivals": 231202,
    "finished_requests": 115094,
    "scheduler_time": 240.2989378411329
}
#Debug simulation 
Total elapsed time: 148.30856944294646. Arrivals time: 0.6711845966055989 Scheduler time: 147.370355383493 Scheduler overhead time: 0.10394451254978776 Adapter cache time: 0.020870483480393887 Engine time: 0.10564848920330405 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-32/adapters_96_slots_16_rate_1.6-0.4-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-32/adapters_96_slots_16_rate_1.6-0.4-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 4320, 17280, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 17280, 4320, 4320, 135, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 135, 17280, 4320, 4320, 4320, 17280, 17280, 135, 135, 4320, 135, 17280, 135, 135, 17280, 135, 4320, 4320, 135, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 135, 135, 17280, 4320, 17280, 135, 4320, 17280, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 135, 135, 4320]
Prompts retrieved: 695520 . Total input tokens: 155117441 . Total output tokens: 139015307
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 148.3316040020436,
    "estimated_duration": 3600.0482930917374,
    "input_throughput": 7910.527215606524,
    "output_throughput": 7016.03977048548,
    "total_throughput": 14926.566986092004,
    "itl": 102.82221607247676,
    "ttft": 1438544.9924240836,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 157,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.512568951193245,
    "arrivals": 231202,
    "finished_requests": 115094,
    "scheduler_time": 240.29897806552069
}
#Debug simulation 
Total elapsed time: 148.33177966671064. Arrivals time: 0.6951563809998333 Scheduler time: 147.3599375928752 Scheduler overhead time: 0.1092697149142623 Adapter cache time: 0.02165848994627595 Engine time: 0.10856415424495935 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-16/adapters_96_slots_16_rate_1.6-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-16/adapters_96_slots_16_rate_1.6-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 4320, 17280, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 17280, 4320, 4320, 135, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 135, 17280, 4320, 4320, 4320, 17280, 17280, 135, 135, 4320, 135, 17280, 135, 135, 17280, 135, 4320, 4320, 135, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 135, 135, 17280, 4320, 17280, 135, 4320, 17280, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 135, 135, 4320]
Prompts retrieved: 695520 . Total input tokens: 155117441 . Total output tokens: 139015307
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 145.43189236614853,
    "estimated_duration": 3600.06085574839,
    "input_throughput": 7881.466768733716,
    "output_throughput": 6988.346866367066,
    "total_throughput": 14869.813635100782,
    "itl": 102.01299177396483,
    "ttft": 1445839.7313054402,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 143,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.44678117213770774,
    "arrivals": 231202,
    "finished_requests": 114651,
    "scheduler_time": 241.80925886360794
}
#Debug simulation 
Total elapsed time: 145.43216775218025. Arrivals time: 0.6811501639895141 Scheduler time: 144.48261070018634 Scheduler overhead time: 0.10577211575582623 Adapter cache time: 0.02007199078798294 Engine time: 0.10588762070983648 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-32/adapters_96_slots_16_rate_1.6-0.4-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-32/adapters_96_slots_16_rate_1.6-0.4-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 4320, 17280, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 17280, 4320, 4320, 135, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 135, 17280, 4320, 4320, 4320, 17280, 17280, 135, 135, 4320, 135, 17280, 135, 135, 17280, 135, 4320, 4320, 135, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 135, 135, 17280, 4320, 17280, 135, 4320, 17280, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 135, 135, 4320]
Prompts retrieved: 695520 . Total input tokens: 155117441 . Total output tokens: 139015307
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 148.70740637090057,
    "estimated_duration": 3600.0545115755513,
    "input_throughput": 7910.513551511914,
    "output_throughput": 7016.02765146628,
    "total_throughput": 14926.541202978193,
    "itl": 102.82252691269703,
    "ttft": 1438547.718278327,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 157,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5187308867275725,
    "arrivals": 231202,
    "finished_requests": 115094,
    "scheduler_time": 240.299134652381
}
#Debug simulation 
Total elapsed time: 148.70759139908478. Arrivals time: 0.7090513007715344 Scheduler time: 147.72122755087912 Scheduler overhead time: 0.10961410356685519 Adapter cache time: 0.02098723128437996 Engine time: 0.10980613250285387 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-16/adapters_96_slots_16_rate_1.6-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-16/adapters_96_slots_16_rate_1.6-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 4320, 17280, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 17280, 4320, 4320, 135, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 135, 17280, 4320, 4320, 4320, 17280, 17280, 135, 135, 4320, 135, 17280, 135, 135, 17280, 135, 4320, 4320, 135, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 135, 135, 17280, 4320, 17280, 135, 4320, 17280, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 135, 135, 4320]
Prompts retrieved: 695520 . Total input tokens: 155117441 . Total output tokens: 139015307
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 141.6408949806355,
    "estimated_duration": 3600.124199377817,
    "input_throughput": 7938.9730512462575,
    "output_throughput": 7033.549843745989,
    "total_throughput": 14972.522894992248,
    "itl": 103.09443910943497,
    "ttft": 1440007.9964236598,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 163,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.48737819806905525,
    "arrivals": 231202,
    "finished_requests": 115463,
    "scheduler_time": 239.35886879311002
}
#Debug simulation 
Total elapsed time: 141.64105913601816. Arrivals time: 0.7236503446474671 Scheduler time: 140.64579032873735 Scheduler overhead time: 0.1066633970476687 Adapter cache time: 0.02036413410678506 Engine time: 0.10831517959013581 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-32/adapters_96_slots_16_rate_1.6-0.4-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-32/adapters_96_slots_16_rate_1.6-0.4-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 4320, 17280, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 17280, 4320, 4320, 135, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 135, 17280, 4320, 4320, 4320, 17280, 17280, 135, 135, 4320, 135, 17280, 135, 135, 17280, 135, 4320, 4320, 135, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 135, 135, 17280, 4320, 17280, 135, 4320, 17280, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 135, 135, 4320]
Prompts retrieved: 695520 . Total input tokens: 155117441 . Total output tokens: 139015307
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 148.8524871058762,
    "estimated_duration": 3600.0608442525036,
    "input_throughput": 7910.49963654519,
    "output_throughput": 7016.015309942476,
    "total_throughput": 14926.514946487667,
    "itl": 102.82263926406294,
    "ttft": 1438550.2843808713,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 157,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.525521591193974,
    "arrivals": 231202,
    "finished_requests": 115094,
    "scheduler_time": 240.29927685635283
}
#Debug simulation 
Total elapsed time: 148.85274221887812. Arrivals time: 0.6785109960474074 Scheduler time: 147.90005057910457 Scheduler overhead time: 0.10845413245260715 Adapter cache time: 0.021017514169216156 Engine time: 0.10808608634397388 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-8/adapters_96_slots_16_rate_1.6-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-8/adapters_96_slots_16_rate_1.6-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 4320, 17280, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 66, 17280, 4320, 4320, 66, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 66, 17280, 4320, 4320, 4320, 17280, 17280, 66, 66, 4320, 66, 17280, 66, 66, 17280, 66, 4320, 4320, 66, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 66, 66, 17280, 4320, 17280, 66, 4320, 17280, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 66, 66, 4320]
Prompts retrieved: 693312 . Total input tokens: 154620069 . Total output tokens: 138577647
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 146.74653749587014,
    "estimated_duration": 3600.0077632341486,
    "input_throughput": 7817.028142938939,
    "output_throughput": 6969.037193814576,
    "total_throughput": 14786.065336753516,
    "itl": 102.42013836143326,
    "ttft": 1447017.1139907432,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 141,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.43152877189451777,
    "arrivals": 230450,
    "finished_requests": 114037,
    "scheduler_time": 242.4645684206628
}
#Debug simulation 
Total elapsed time: 146.74671166669577. Arrivals time: 0.6269663204438984 Scheduler time: 145.86278034374118 Scheduler overhead time: 0.09964103670790792 Adapter cache time: 0.019462777767330408 Engine time: 0.10269020777195692 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-16/adapters_96_slots_16_rate_1.6-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-16/adapters_96_slots_16_rate_1.6-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 4320, 17280, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 66, 17280, 4320, 4320, 66, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 66, 17280, 4320, 4320, 4320, 17280, 17280, 66, 66, 4320, 66, 17280, 66, 66, 17280, 66, 4320, 4320, 66, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 66, 66, 17280, 4320, 17280, 66, 4320, 17280, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 66, 66, 4320]
Prompts retrieved: 693312 . Total input tokens: 154620069 . Total output tokens: 138577647
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 147.9348615258932,
    "estimated_duration": 3600.033374439803,
    "input_throughput": 7816.972531366891,
    "output_throughput": 6968.987614983987,
    "total_throughput": 14785.960146350879,
    "itl": 102.42053435596775,
    "ttft": 1447029.0484699798,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 141,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4571448842855171,
    "arrivals": 230450,
    "finished_requests": 114037,
    "scheduler_time": 242.46547372898473
}
#Debug simulation 
Total elapsed time: 147.93504461366683. Arrivals time: 0.5933364755474031 Scheduler time: 147.08252844307572 Scheduler overhead time: 0.1018163338303566 Adapter cache time: 0.01987383235245943 Engine time: 0.101283248513937 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-32/adapters_96_slots_16_rate_1.6-0.4-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-32/adapters_96_slots_16_rate_1.6-0.4-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 4320, 17280, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 66, 17280, 4320, 4320, 66, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 66, 17280, 4320, 4320, 4320, 17280, 17280, 66, 66, 4320, 66, 17280, 66, 66, 17280, 66, 4320, 4320, 66, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 66, 66, 17280, 4320, 17280, 66, 4320, 17280, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 66, 66, 4320]
Prompts retrieved: 693312 . Total input tokens: 154620069 . Total output tokens: 138577647
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 149.2761489697732,
    "estimated_duration": 3600.034960564582,
    "input_throughput": 7816.969087318719,
    "output_throughput": 6968.984544546044,
    "total_throughput": 14785.953631864762,
    "itl": 102.42058863562185,
    "ttft": 1447029.755617625,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 141,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4584766897000386,
    "arrivals": 230450,
    "finished_requests": 114037,
    "scheduler_time": 242.46552797118912
}
#Debug simulation 
Total elapsed time: 149.2763786460273. Arrivals time: 0.6662858398631215 Scheduler time: 148.34387276228517 Scheduler overhead time: 0.10483608162030578 Adapter cache time: 0.019673718139529228 Engine time: 0.10615280922502279 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-16/adapters_96_slots_16_rate_1.6-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-16/adapters_96_slots_16_rate_1.6-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 4320, 17280, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 66, 17280, 4320, 4320, 66, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 66, 17280, 4320, 4320, 4320, 17280, 17280, 66, 66, 4320, 66, 17280, 66, 66, 17280, 66, 4320, 4320, 66, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 66, 66, 17280, 4320, 17280, 66, 4320, 17280, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 66, 66, 4320]
Prompts retrieved: 693312 . Total input tokens: 154620069 . Total output tokens: 138577647
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 145.487473085057,
    "estimated_duration": 3600.0166346360434,
    "input_throughput": 7817.008879695094,
    "output_throughput": 6969.020020246773,
    "total_throughput": 14786.028899941868,
    "itl": 102.42026913436845,
    "ttft": 1447021.5418501757,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 141,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.44039247622946304,
    "arrivals": 230450,
    "finished_requests": 114037,
    "scheduler_time": 242.46497627252833
}
#Debug simulation 
Total elapsed time: 145.48764198971912. Arrivals time: 0.6193114956840873 Scheduler time: 144.60959252063185 Scheduler overhead time: 0.10235805669799447 Adapter cache time: 0.019098408054560423 Engine time: 0.1019912539049983 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-32/adapters_96_slots_16_rate_1.6-0.4-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-32/adapters_96_slots_16_rate_1.6-0.4-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 4320, 17280, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 66, 17280, 4320, 4320, 66, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 66, 17280, 4320, 4320, 4320, 17280, 17280, 66, 66, 4320, 66, 17280, 66, 66, 17280, 66, 4320, 4320, 66, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 66, 66, 17280, 4320, 17280, 66, 4320, 17280, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 66, 66, 4320]
Prompts retrieved: 693312 . Total input tokens: 154620069 . Total output tokens: 138577647
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 150.51484229788184,
    "estimated_duration": 3600.0400215998625,
    "input_throughput": 7816.958098008572,
    "output_throughput": 6968.974747355892,
    "total_throughput": 14785.932845364463,
    "itl": 102.4206780366026,
    "ttft": 1447032.0522307504,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 141,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4636325949430472,
    "arrivals": 230450,
    "finished_requests": 114037,
    "scheduler_time": 242.4656331783882
}
#Debug simulation 
Total elapsed time: 150.51500815991312. Arrivals time: 0.66333276219666 Scheduler time: 149.58253178047016 Scheduler overhead time: 0.10590831423178315 Adapter cache time: 0.019970932509750128 Engine time: 0.10717521607875824 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-16/adapters_96_slots_16_rate_1.6-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-16/adapters_96_slots_16_rate_1.6-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 4320, 17280, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 66, 17280, 4320, 4320, 66, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 66, 17280, 4320, 4320, 4320, 17280, 17280, 66, 66, 4320, 66, 17280, 66, 66, 17280, 66, 4320, 4320, 66, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 66, 66, 17280, 4320, 17280, 66, 4320, 17280, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 66, 66, 4320]
Prompts retrieved: 693312 . Total input tokens: 154620069 . Total output tokens: 138577647
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 142.45398380002007,
    "estimated_duration": 3600.122791216505,
    "input_throughput": 7816.992261669661,
    "output_throughput": 6969.07868287517,
    "total_throughput": 14786.07094454483,
    "itl": 102.42064148900283,
    "ttft": 1446986.1219146578,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 141,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4215970915812073,
    "arrivals": 230450,
    "finished_requests": 114042,
    "scheduler_time": 242.47249162713055
}
#Debug simulation 
Total elapsed time: 142.4542395672761. Arrivals time: 0.5998597797006369 Scheduler time: 141.60368552198634 Scheduler overhead time: 0.09767397167161107 Adapter cache time: 0.019212921150028706 Engine time: 0.09941692277789116 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-32/adapters_96_slots_16_rate_1.6-0.4-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-32/adapters_96_slots_16_rate_1.6-0.4-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 4320, 17280, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 66, 17280, 4320, 4320, 66, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 66, 17280, 4320, 4320, 4320, 17280, 17280, 66, 66, 4320, 66, 17280, 66, 66, 17280, 66, 4320, 4320, 66, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 66, 66, 17280, 4320, 17280, 66, 4320, 17280, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 66, 66, 4320]
Prompts retrieved: 693312 . Total input tokens: 154620069 . Total output tokens: 138577647
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 148.76397738792002,
    "estimated_duration": 3600.045944963511,
    "input_throughput": 7816.945236315653,
    "output_throughput": 6968.963280898986,
    "total_throughput": 14785.908517214639,
    "itl": 102.42081030181146,
    "ttft": 1447034.8882615627,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 141,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.46941726911813,
    "arrivals": 230450,
    "finished_requests": 114037,
    "scheduler_time": 242.4658719064425
}
#Debug simulation 
Total elapsed time: 148.76416176883504. Arrivals time: 0.6692149960435927 Scheduler time: 147.82867883797735 Scheduler overhead time: 0.10338094411417842 Adapter cache time: 0.020187019370496273 Engine time: 0.10669191973283887 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-8/adapters_96_slots_16_rate_1.6-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-8/adapters_96_slots_16_rate_1.6-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 4320, 17280, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 33, 17280, 4320, 4320, 33, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 33, 17280, 4320, 4320, 4320, 17280, 17280, 33, 33, 4320, 33, 17280, 33, 33, 17280, 33, 4320, 4320, 33, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 33, 33, 17280, 4320, 17280, 33, 4320, 17280, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 33, 33, 4320]
Prompts retrieved: 692256 . Total input tokens: 154379477 . Total output tokens: 138362450
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 125.13182745222002,
    "estimated_duration": 3600.0415461185335,
    "input_throughput": 7866.627825596639,
    "output_throughput": 7006.204699830298,
    "total_throughput": 14872.832525426937,
    "itl": 103.92122312602628,
    "ttft": 1451557.5444201608,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 165,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5049804777489038,
    "arrivals": 230128,
    "finished_requests": 114456,
    "scheduler_time": 240.54475188816852
}
#Debug simulation 
Total elapsed time: 125.13197796279564. Arrivals time: 0.5533643113449216 Scheduler time: 124.34789343131706 Scheduler overhead time: 0.09043853729963303 Adapter cache time: 0.016821798402816057 Engine time: 0.09059211704879999 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-16/adapters_96_slots_16_rate_1.6-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-16/adapters_96_slots_16_rate_1.6-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 4320, 17280, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 33, 17280, 4320, 4320, 33, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 33, 17280, 4320, 4320, 4320, 17280, 17280, 33, 33, 4320, 33, 17280, 33, 33, 17280, 33, 4320, 4320, 33, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 33, 33, 17280, 4320, 17280, 33, 4320, 17280, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 33, 33, 4320]
Prompts retrieved: 692256 . Total input tokens: 154379477 . Total output tokens: 138362450
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 138.2511555450037,
    "estimated_duration": 3600.0367702245253,
    "input_throughput": 7829.360864623089,
    "output_throughput": 6971.451293936293,
    "total_throughput": 14800.812158559382,
    "itl": 103.4041664850338,
    "ttft": 1459729.2368032257,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 144,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.46815801176242533,
    "arrivals": 230128,
    "finished_requests": 113858,
    "scheduler_time": 242.20544285140937
}
#Debug simulation 
Total elapsed time: 138.25136669026688. Arrivals time: 0.6515985149890184 Scheduler time: 137.33752492209896 Scheduler overhead time: 0.10161925805732608 Adapter cache time: 0.01976761966943741 Engine time: 0.10525717306882143 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-32/adapters_96_slots_16_rate_1.6-0.4-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-32/adapters_96_slots_16_rate_1.6-0.4-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 4320, 17280, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 33, 17280, 4320, 4320, 33, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 33, 17280, 4320, 4320, 4320, 17280, 17280, 33, 33, 4320, 33, 17280, 33, 33, 17280, 33, 4320, 4320, 33, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 33, 33, 17280, 4320, 17280, 33, 4320, 17280, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 33, 33, 4320]
Prompts retrieved: 692256 . Total input tokens: 154379477 . Total output tokens: 138362450
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 136.311746514868,
    "estimated_duration": 3600.038298992629,
    "input_throughput": 7829.3575398592475,
    "output_throughput": 6971.448333486574,
    "total_throughput": 14800.805873345822,
    "itl": 103.404193874437,
    "ttft": 1459730.0302944244,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 144,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.46929348371923113,
    "arrivals": 230128,
    "finished_requests": 113858,
    "scheduler_time": 242.2055360318116
}
#Debug simulation 
Total elapsed time: 136.31189890718088. Arrivals time: 0.6446526884101331 Scheduler time: 135.41210453491658 Scheduler overhead time: 0.10010678553953767 Adapter cache time: 0.018650651443749666 Engine time: 0.10119135351851583 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-16/adapters_96_slots_16_rate_1.6-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-16/adapters_96_slots_16_rate_1.6-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 4320, 17280, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 33, 17280, 4320, 4320, 33, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 33, 17280, 4320, 4320, 4320, 17280, 17280, 33, 33, 4320, 33, 17280, 33, 33, 17280, 33, 4320, 4320, 33, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 33, 33, 17280, 4320, 17280, 33, 4320, 17280, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 33, 33, 4320]
Prompts retrieved: 692256 . Total input tokens: 154379477 . Total output tokens: 138362450
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 131.0939576230012,
    "estimated_duration": 3600.0070658404666,
    "input_throughput": 7859.722073460477,
    "output_throughput": 7002.690422251844,
    "total_throughput": 14862.412495712322,
    "itl": 104.19824722157355,
    "ttft": 1452399.984714254,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 163,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5090337499463934,
    "arrivals": 230128,
    "finished_requests": 114351,
    "scheduler_time": 240.66047292912333
}
#Debug simulation 
Total elapsed time: 131.09412160143256. Arrivals time: 0.6111040087416768 Scheduler time: 130.2392063140869 Scheduler overhead time: 0.09485616628080606 Adapter cache time: 0.01779715158045292 Engine time: 0.09651930397376418 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-32/adapters_96_slots_16_rate_1.6-0.4-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-32/adapters_96_slots_16_rate_1.6-0.4-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 4320, 17280, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 33, 17280, 4320, 4320, 33, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 33, 17280, 4320, 4320, 4320, 17280, 17280, 33, 33, 4320, 33, 17280, 33, 33, 17280, 33, 4320, 4320, 33, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 33, 33, 17280, 4320, 17280, 33, 4320, 17280, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 33, 33, 4320]
Prompts retrieved: 692256 . Total input tokens: 154379477 . Total output tokens: 138362450
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 137.56661938130856,
    "estimated_duration": 3600.044475836898,
    "input_throughput": 7829.34410649125,
    "output_throughput": 6971.436372092491,
    "total_throughput": 14800.780478583742,
    "itl": 103.40428652349152,
    "ttft": 1459732.9220030417,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 144,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4750781578943139,
    "arrivals": 230128,
    "finished_requests": 113858,
    "scheduler_time": 242.20573962590768
}
#Debug simulation 
Total elapsed time: 137.56682836124673. Arrivals time: 0.6665066829882562 Scheduler time: 136.63053494272754 Scheduler overhead time: 0.10495890583842993 Adapter cache time: 0.020586004480719566 Engine time: 0.10698481136932969 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-16/adapters_96_slots_16_rate_1.6-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-16/adapters_96_slots_16_rate_1.6-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 4320, 17280, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 33, 17280, 4320, 4320, 33, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 33, 17280, 4320, 4320, 4320, 17280, 17280, 33, 33, 4320, 33, 17280, 33, 33, 17280, 33, 4320, 4320, 33, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 33, 33, 17280, 4320, 17280, 33, 4320, 17280, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 33, 33, 4320]
Prompts retrieved: 692256 . Total input tokens: 154379477 . Total output tokens: 138362450
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 132.7075087740086,
    "estimated_duration": 3600.0297658435748,
    "input_throughput": 7866.653567339016,
    "output_throughput": 7006.227626034565,
    "total_throughput": 14872.881193373581,
    "itl": 103.92102534898251,
    "ttft": 1451552.3694490744,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 165,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4933582986588596,
    "arrivals": 230128,
    "finished_requests": 114456,
    "scheduler_time": 240.54439371510804
}
#Debug simulation 
Total elapsed time: 132.70764492359012. Arrivals time: 0.591452345252037 Scheduler time: 131.86848793644458 Scheduler overhead time: 0.09733119048178196 Adapter cache time: 0.018721826374530792 Engine time: 0.09761211695149541 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-32/adapters_96_slots_16_rate_1.6-0.4-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-32/adapters_96_slots_16_rate_1.6-0.4-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 4320, 17280, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 33, 17280, 4320, 4320, 33, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 33, 17280, 4320, 4320, 4320, 17280, 17280, 33, 33, 4320, 33, 17280, 33, 33, 17280, 33, 4320, 4320, 33, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 33, 33, 17280, 4320, 17280, 33, 4320, 17280, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 33, 33, 4320]
Prompts retrieved: 692256 . Total input tokens: 154379477 . Total output tokens: 138362450
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 135.69044557213783,
    "estimated_duration": 3600.051541898369,
    "input_throughput": 7829.32873931495,
    "output_throughput": 6971.422688788968,
    "total_throughput": 14800.751428103918,
    "itl": 103.40425831361475,
    "ttft": 1459736.10040322,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 144,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4808628320693967,
    "arrivals": 230128,
    "finished_requests": 113858,
    "scheduler_time": 242.20602062740267
}
#Debug simulation 
Total elapsed time: 135.69062636001036. Arrivals time: 0.6339705283753574 Scheduler time: 134.7980584767647 Scheduler overhead time: 0.10105795972049236 Adapter cache time: 0.01941779488697648 Engine time: 0.10173166822642088 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-8/adapters_96_slots_16_rate_1.6-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-8/adapters_96_slots_16_rate_1.6-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 1080, 17280, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 17280, 1080, 1080, 540, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 540, 17280, 1080, 1080, 1080, 17280, 17280, 540, 540, 1080, 540, 17280, 540, 540, 17280, 540, 1080, 1080, 540, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 540, 540, 17280, 1080, 17280, 540, 1080, 17280, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 540, 540, 1080]
Prompts retrieved: 604800 . Total input tokens: 134810828 . Total output tokens: 121020589
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 133.66857909224927,
    "estimated_duration": 3600.0250592041903,
    "input_throughput": 7861.018335871217,
    "output_throughput": 6902.705284360782,
    "total_throughput": 14763.723620231998,
    "itl": 98.93150341177622,
    "ttft": 1352028.969727348,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 141,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.43152877189451777,
    "arrivals": 200953,
    "finished_requests": 113866,
    "scheduler_time": 239.4550106312992
}
#Debug simulation 
Total elapsed time: 133.66877535823733. Arrivals time: 0.5998048488982022 Scheduler time: 132.8143486105837 Scheduler overhead time: 0.09863114496693015 Adapter cache time: 0.018794091884046793 Engine time: 0.100887983571738 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-16/adapters_96_slots_16_rate_1.6-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-16/adapters_96_slots_16_rate_1.6-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 1080, 17280, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 17280, 1080, 1080, 540, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 540, 17280, 1080, 1080, 1080, 17280, 17280, 540, 540, 1080, 540, 17280, 540, 540, 17280, 540, 1080, 1080, 540, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 540, 540, 17280, 1080, 17280, 540, 1080, 17280, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 540, 540, 1080]
Prompts retrieved: 604800 . Total input tokens: 134810828 . Total output tokens: 121020589
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 135.37374462932348,
    "estimated_duration": 3600.039541439238,
    "input_throughput": 7849.112120780557,
    "output_throughput": 6892.9640117451,
    "total_throughput": 14742.076132525657,
    "itl": 98.7836465863133,
    "ttft": 1354387.5853004486,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 141,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4575534796039574,
    "arrivals": 200953,
    "finished_requests": 113684,
    "scheduler_time": 239.9523477734985
}
#Debug simulation 
Total elapsed time: 135.37390164332464. Arrivals time: 0.6544332755729556 Scheduler time: 134.45526046445593 Scheduler overhead time: 0.10309453401714563 Adapter cache time: 0.019594591576606035 Engine time: 0.10536385467275977 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-32/adapters_96_slots_16_rate_1.6-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-32/adapters_96_slots_16_rate_1.6-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 1080, 17280, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 17280, 1080, 1080, 540, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 540, 17280, 1080, 1080, 1080, 17280, 17280, 540, 540, 1080, 540, 17280, 540, 540, 17280, 540, 1080, 1080, 540, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 540, 540, 17280, 1080, 17280, 540, 1080, 17280, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 540, 540, 1080]
Prompts retrieved: 604800 . Total input tokens: 134810828 . Total output tokens: 121020589
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 135.7692786050029,
    "estimated_duration": 3600.040685766064,
    "input_throughput": 7849.109625822764,
    "output_throughput": 6892.961820713298,
    "total_throughput": 14742.071446536063,
    "itl": 98.78367142012699,
    "ttft": 1354388.0509001047,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 141,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.45881393719464675,
    "arrivals": 200953,
    "finished_requests": 113684,
    "scheduler_time": 239.95233168131537
}
#Debug simulation 
Total elapsed time: 135.76944086514413. Arrivals time: 0.6442077634856105 Scheduler time: 134.86198189714924 Scheduler overhead time: 0.10277609433978796 Adapter cache time: 0.019362553022801876 Engine time: 0.10488141421228647 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-16-16/adapters_96_slots_16_rate_1.6-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-16-16/adapters_96_slots_16_rate_1.6-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 1080, 17280, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 17280, 1080, 1080, 540, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 540, 17280, 1080, 1080, 1080, 17280, 17280, 540, 540, 1080, 540, 17280, 540, 540, 17280, 540, 1080, 1080, 540, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 540, 540, 17280, 1080, 17280, 540, 1080, 17280, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 540, 540, 1080]
Prompts retrieved: 604800 . Total input tokens: 134810828 . Total output tokens: 121020589
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 132.79070724220946,
    "estimated_duration": 3600.034781138216,
    "input_throughput": 7860.997107103639,
    "output_throughput": 6902.6866435282745,
    "total_throughput": 14763.683750631913,
    "itl": 98.93156638331523,
    "ttft": 1352033.925246238,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 141,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4399838809110227,
    "arrivals": 200953,
    "finished_requests": 113866,
    "scheduler_time": 239.45552478557963
}
#Debug simulation 
Total elapsed time: 132.7909117899835. Arrivals time: 0.6453003906644881 Scheduler time: 131.87956590438262 Scheduler overhead time: 0.10348027106374502 Adapter cache time: 0.020376531407237053 Engine time: 0.10533839091658592 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-16-32/adapters_96_slots_16_rate_1.6-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-16-32/adapters_96_slots_16_rate_1.6-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 1080, 17280, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 17280, 1080, 1080, 540, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 540, 17280, 1080, 1080, 1080, 17280, 17280, 540, 540, 1080, 540, 17280, 540, 540, 17280, 540, 1080, 1080, 540, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 540, 540, 17280, 1080, 17280, 540, 1080, 17280, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 540, 540, 1080]
Prompts retrieved: 604800 . Total input tokens: 134810828 . Total output tokens: 121020589
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 135.404084560927,
    "estimated_duration": 3600.045922496243,
    "input_throughput": 7849.098208282506,
    "output_throughput": 6892.951794013094,
    "total_throughput": 14742.0500022956,
    "itl": 98.78376742536372,
    "ttft": 1354390.4029750936,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 141,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.46434710379689986,
    "arrivals": 200953,
    "finished_requests": 113684,
    "scheduler_time": 239.95243539921023
}
#Debug simulation 
Total elapsed time: 135.40424889791757. Arrivals time: 0.652824507560581 Scheduler time: 134.48476780811325 Scheduler overhead time: 0.1052605570293963 Adapter cache time: 0.019576387014240026 Engine time: 0.10547849209979177 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_16-16-16/adapters_96_slots_16_rate_1.6-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_16-16-16/adapters_96_slots_16_rate_1.6-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 1080, 17280, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 17280, 1080, 1080, 540, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 540, 17280, 1080, 1080, 1080, 17280, 17280, 540, 540, 1080, 540, 17280, 540, 540, 17280, 540, 1080, 1080, 540, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 540, 540, 17280, 1080, 17280, 540, 1080, 17280, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 540, 540, 1080]
Prompts retrieved: 604800 . Total input tokens: 134810828 . Total output tokens: 121020589
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 134.64260423369706,
    "estimated_duration": 3600.0151709107763,
    "input_throughput": 7861.039928017956,
    "output_throughput": 6902.7242442739935,
    "total_throughput": 14763.76417229195,
    "itl": 98.93131727018245,
    "ttft": 1352024.393534821,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 141,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4215970915812073,
    "arrivals": 200953,
    "finished_requests": 113866,
    "scheduler_time": 239.45475390243809
}
#Debug simulation 
Total elapsed time: 134.64276315504685. Arrivals time: 0.617591452319175 Scheduler time: 133.76356630260125 Scheduler overhead time: 0.10215462930500507 Adapter cache time: 0.019681305158883333 Engine time: 0.10398699948564172 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_16-16-32/adapters_96_slots_16_rate_1.6-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_16-16-32/adapters_96_slots_16_rate_1.6-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 1080, 17280, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 17280, 1080, 1080, 540, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 540, 17280, 1080, 1080, 1080, 17280, 17280, 540, 540, 1080, 540, 17280, 540, 540, 17280, 540, 1080, 1080, 540, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 540, 540, 17280, 1080, 17280, 540, 1080, 17280, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 540, 540, 1080]
Prompts retrieved: 604800 . Total input tokens: 134810828 . Total output tokens: 121020589
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 135.83345831604674,
    "estimated_duration": 3600.0510043891654,
    "input_throughput": 7849.087128362642,
    "output_throughput": 6892.94206380569,
    "total_throughput": 14742.029192168331,
    "itl": 98.78383595300593,
    "ttft": 1354392.7615833217,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 141,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.469880270399153,
    "arrivals": 200953,
    "finished_requests": 113684,
    "scheduler_time": 239.95258435701356
}
#Debug simulation 
Total elapsed time: 135.83366619609296. Arrivals time: 0.6374476701021194 Scheduler time: 134.93006147723645 Scheduler overhead time: 0.10495589626953006 Adapter cache time: 0.019783942494541407 Engine time: 0.10477212117984891 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-8/adapters_96_slots_16_rate_1.6-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-8/adapters_96_slots_16_rate_1.6-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 270, 17280, 1080, 270, 270, 1080, 17280, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 17280, 1080, 1080, 270, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 270, 17280, 1080, 1080, 1080, 17280, 17280, 270, 270, 1080, 270, 17280, 270, 270, 17280, 270, 1080, 1080, 270, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 270, 270, 17280, 1080, 17280, 270, 1080, 17280, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 270, 270, 1080]
Prompts retrieved: 596160 . Total input tokens: 132911004 . Total output tokens: 119303065
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 142.73522463906556,
    "estimated_duration": 3600.1159831106124,
    "input_throughput": 7823.200733567771,
    "output_throughput": 6941.331645212221,
    "total_throughput": 14764.532378779992,
    "itl": 99.02010434012675,
    "ttft": 1343990.8018779068,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 136,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.416226333174854,
    "arrivals": 198151,
    "finished_requests": 113826,
    "scheduler_time": 238.10267043691894
}
#Debug simulation 
Total elapsed time: 142.7353775058873. Arrivals time: 0.6513607674278319 Scheduler time: 141.81541113741696 Scheduler overhead time: 0.10639296565204859 Adapter cache time: 0.020011055748909712 Engine time: 0.10563273215666413 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-16/adapters_96_slots_16_rate_1.6-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-16/adapters_96_slots_16_rate_1.6-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 270, 17280, 1080, 270, 270, 1080, 17280, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 17280, 1080, 1080, 270, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 270, 17280, 1080, 1080, 1080, 17280, 17280, 270, 270, 1080, 270, 17280, 270, 270, 17280, 270, 1080, 1080, 270, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 270, 270, 17280, 1080, 17280, 270, 1080, 17280, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 270, 270, 1080]
Prompts retrieved: 596160 . Total input tokens: 132911004 . Total output tokens: 119303065
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 139.13167412625626,
    "estimated_duration": 3600.0205763845493,
    "input_throughput": 7822.895842524126,
    "output_throughput": 6941.203381980549,
    "total_throughput": 14764.099224504676,
    "itl": 99.01978863773016,
    "ttft": 1344069.3474731387,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 136,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4426032281294465,
    "arrivals": 198151,
    "finished_requests": 113818,
    "scheduler_time": 238.0952304649436
}
#Debug simulation 
Total elapsed time: 139.13182719610631. Arrivals time: 0.5929663488641381 Scheduler time: 138.27957703359425 Scheduler overhead time: 0.10210950300097466 Adapter cache time: 0.019858200568705797 Engine time: 0.10142618045210838 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-32/adapters_96_slots_16_rate_1.6-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-32/adapters_96_slots_16_rate_1.6-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 270, 17280, 1080, 270, 270, 1080, 17280, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 17280, 1080, 1080, 270, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 270, 17280, 1080, 1080, 1080, 17280, 17280, 270, 270, 1080, 270, 17280, 270, 270, 17280, 270, 1080, 1080, 270, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 270, 270, 17280, 1080, 17280, 270, 1080, 17280, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 270, 270, 1080]
Prompts retrieved: 596160 . Total input tokens: 132911004 . Total output tokens: 119303065
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 141.7186424206011,
    "estimated_duration": 3600.0213994536043,
    "input_throughput": 7822.894053983789,
    "output_throughput": 6941.201795020619,
    "total_throughput": 14764.095849004409,
    "itl": 99.0198083413526,
    "ttft": 1344069.6698841567,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 136,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4435963429510606,
    "arrivals": 198151,
    "finished_requests": 113818,
    "scheduler_time": 238.0952604963324
}
#Debug simulation 
Total elapsed time: 141.718852405902. Arrivals time: 0.6636448535136878 Scheduler time: 140.7895706873387 Scheduler overhead time: 0.10412528272718191 Adapter cache time: 0.020345771685242653 Engine time: 0.10499361529946327 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-16-16/adapters_96_slots_16_rate_1.6-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-16-16/adapters_96_slots_16_rate_1.6-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 270, 17280, 1080, 270, 270, 1080, 17280, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 17280, 1080, 1080, 270, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 270, 17280, 1080, 1080, 1080, 17280, 17280, 270, 270, 1080, 270, 17280, 270, 270, 17280, 270, 1080, 1080, 270, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 270, 270, 17280, 1080, 17280, 270, 1080, 17280, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 270, 270, 1080]
Prompts retrieved: 596160 . Total input tokens: 132911004 . Total output tokens: 119303065
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 141.62394856801257,
    "estimated_duration": 3600.0022732378025,
    "input_throughput": 7822.9356157241755,
    "output_throughput": 6941.238672476071,
    "total_throughput": 14764.174288200245,
    "itl": 99.01948653131187,
    "ttft": 1344061.4019964056,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 136,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42544222475495214,
    "arrivals": 198151,
    "finished_requests": 113818,
    "scheduler_time": 238.0946885530528
}
#Debug simulation 
Total elapsed time: 141.6241049100645. Arrivals time: 0.6597769749350846 Scheduler time: 140.69966244371608 Scheduler overhead time: 0.1032620845362544 Adapter cache time: 0.01986009068787098 Engine time: 0.10543894674628973 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-16-32/adapters_96_slots_16_rate_1.6-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-16-32/adapters_96_slots_16_rate_1.6-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 270, 17280, 1080, 270, 270, 1080, 17280, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 17280, 1080, 1080, 270, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 270, 17280, 1080, 1080, 1080, 17280, 17280, 270, 270, 1080, 270, 17280, 270, 270, 17280, 270, 1080, 1080, 270, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 270, 270, 17280, 1080, 17280, 270, 1080, 17280, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 270, 270, 1080]
Prompts retrieved: 596160 . Total input tokens: 132911004 . Total output tokens: 119303065
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 144.45126438327134,
    "estimated_duration": 3600.026471447688,
    "input_throughput": 7822.883032489177,
    "output_throughput": 6941.192015721851,
    "total_throughput": 14764.075048211027,
    "itl": 99.01993598036663,
    "ttft": 1344071.7439420505,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 136,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4488780019804841,
    "arrivals": 198151,
    "finished_requests": 113818,
    "scheduler_time": 238.09535094713294
}
#Debug simulation 
Total elapsed time: 144.45141737628728. Arrivals time: 0.6491088471375406 Scheduler time: 143.53365791682154 Scheduler overhead time: 0.10603449819609523 Adapter cache time: 0.020115843042731285 Engine time: 0.10584308672696352 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_16-16-16/adapters_96_slots_16_rate_1.6-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_16-16-16/adapters_96_slots_16_rate_1.6-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 270, 17280, 1080, 270, 270, 1080, 17280, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 17280, 1080, 1080, 270, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 270, 17280, 1080, 1080, 1080, 17280, 17280, 270, 270, 1080, 270, 17280, 270, 270, 17280, 270, 1080, 1080, 270, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 270, 270, 17280, 1080, 17280, 270, 1080, 17280, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 270, 270, 1080]
Prompts retrieved: 596160 . Total input tokens: 132911004 . Total output tokens: 119303065
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 138.03180504543707,
    "estimated_duration": 3600.1065748362344,
    "input_throughput": 7823.2211781900305,
    "output_throughput": 6941.34978521761,
    "total_throughput": 14764.57096340764,
    "itl": 99.0199270332841,
    "ttft": 1343986.9440676626,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 136,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4066468401066964,
    "arrivals": 198151,
    "finished_requests": 113826,
    "scheduler_time": 238.10243081676282
}
#Debug simulation 
Total elapsed time: 138.03201894834638. Arrivals time: 0.5903358994983137 Scheduler time: 137.18575173104182 Scheduler overhead time: 0.09953050129115582 Adapter cache time: 0.018947774078696966 Engine time: 0.10163132939487696 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_16-16-32/adapters_96_slots_16_rate_1.6-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_16-16-32/adapters_96_slots_16_rate_1.6-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 270, 17280, 1080, 270, 270, 1080, 17280, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 17280, 1080, 1080, 270, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 270, 17280, 1080, 1080, 1080, 17280, 17280, 270, 270, 1080, 270, 17280, 270, 270, 17280, 270, 1080, 1080, 270, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 270, 270, 17280, 1080, 17280, 270, 1080, 17280, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 270, 270, 1080]
Prompts retrieved: 596160 . Total input tokens: 132911004 . Total output tokens: 119303065
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 144.48575236694887,
    "estimated_duration": 3600.033275625157,
    "input_throughput": 7822.868246991267,
    "output_throughput": 6941.178896648024,
    "total_throughput": 14764.04714363929,
    "itl": 99.0200461644302,
    "ttft": 1344074.8651800973,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 136,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4546626761555669,
    "arrivals": 198151,
    "finished_requests": 113818,
    "scheduler_time": 238.0957005325641
}
#Debug simulation 
Total elapsed time: 144.48591114906594. Arrivals time: 0.6610842254012823 Scheduler time: 143.556145505514 Scheduler overhead time: 0.10485208733007312 Adapter cache time: 0.02016458474099636 Engine time: 0.10652755573391914 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-8/adapters_96_slots_16_rate_1.6-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-8/adapters_96_slots_16_rate_1.6-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 135, 17280, 1080, 135, 135, 1080, 17280, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 17280, 1080, 1080, 135, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 135, 17280, 1080, 1080, 1080, 17280, 17280, 135, 135, 1080, 135, 17280, 135, 135, 17280, 135, 1080, 1080, 135, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 135, 135, 17280, 1080, 17280, 135, 1080, 17280, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 135, 135, 1080]
Prompts retrieved: 591840 . Total input tokens: 131946218 . Total output tokens: 118450311
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 130.4767470760271,
    "estimated_duration": 3600.0242476097787,
    "input_throughput": 7801.664952297948,
    "output_throughput": 6916.8767450754995,
    "total_throughput": 14718.541697373446,
    "itl": 99.43045175048071,
    "ttft": 1347677.6116169142,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 136,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.416226333174854,
    "arrivals": 196793,
    "finished_requests": 113667,
    "scheduler_time": 238.88490155442784
}
#Debug simulation 
Total elapsed time: 130.47690369188786. Arrivals time: 0.5909454091452062 Scheduler time: 129.63183694938198 Scheduler overhead time: 0.09964280482381582 Adapter cache time: 0.01884535141289234 Engine time: 0.10052188020199537 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-16/adapters_96_slots_16_rate_1.6-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-16/adapters_96_slots_16_rate_1.6-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 135, 17280, 1080, 135, 135, 1080, 17280, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 17280, 1080, 1080, 135, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 135, 17280, 1080, 1080, 1080, 17280, 17280, 135, 135, 1080, 135, 17280, 135, 135, 17280, 135, 1080, 1080, 135, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 135, 135, 17280, 1080, 17280, 135, 1080, 17280, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 135, 135, 1080]
Prompts retrieved: 591840 . Total input tokens: 131946218 . Total output tokens: 118450311
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 145.34588148910552,
    "estimated_duration": 3600.0961252809093,
    "input_throughput": 7625.142786391024,
    "output_throughput": 6764.361881614988,
    "total_throughput": 14389.504668006011,
    "itl": 97.10897403465432,
    "ttft": 1344518.4468853697,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 140,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4549720246274956,
    "arrivals": 196793,
    "finished_requests": 111010,
    "scheduler_time": 246.57144004396858
}
#Debug simulation 
Total elapsed time: 145.34609426790848. Arrivals time: 0.620368632953614 Scheduler time: 144.45330199878663 Scheduler overhead time: 0.10687748435884714 Adapter cache time: 0.019955243915319443 Engine time: 0.10802041040733457 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-32/adapters_96_slots_16_rate_1.6-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-32/adapters_96_slots_16_rate_1.6-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 135, 17280, 1080, 135, 135, 1080, 17280, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 17280, 1080, 1080, 135, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 135, 17280, 1080, 1080, 1080, 17280, 17280, 135, 135, 1080, 135, 17280, 135, 135, 17280, 135, 1080, 1080, 135, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 135, 135, 17280, 1080, 17280, 135, 1080, 17280, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 135, 135, 1080]
Prompts retrieved: 591840 . Total input tokens: 131946218 . Total output tokens: 118450311
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 140.28199462406337,
    "estimated_duration": 3600.0976167984027,
    "input_throughput": 7625.139627300614,
    "output_throughput": 6764.359079145403,
    "total_throughput": 14389.498706446017,
    "itl": 97.10906334104531,
    "ttft": 1344519.159831563,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 140,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.45610766584053775,
    "arrivals": 196793,
    "finished_requests": 111010,
    "scheduler_time": 246.57149580449342
}
#Debug simulation 
Total elapsed time: 140.2821331359446. Arrivals time: 0.601364828646183 Scheduler time: 139.4163909512572 Scheduler overhead time: 0.10349503578618169 Adapter cache time: 0.019300879444926977 Engine time: 0.1048829173669219 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-16/adapters_96_slots_16_rate_1.6-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-16/adapters_96_slots_16_rate_1.6-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 135, 17280, 1080, 135, 135, 1080, 17280, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 17280, 1080, 1080, 135, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 135, 17280, 1080, 1080, 1080, 17280, 17280, 135, 135, 1080, 135, 17280, 135, 135, 17280, 135, 1080, 1080, 135, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 135, 135, 17280, 1080, 17280, 135, 1080, 17280, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 135, 135, 1080]
Prompts retrieved: 591840 . Total input tokens: 131946218 . Total output tokens: 118450311
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 141.22131868405268,
    "estimated_duration": 3600.085321602924,
    "input_throughput": 7767.473129650531,
    "output_throughput": 6886.437621695467,
    "total_throughput": 14653.910751345997,
    "itl": 98.85855908073172,
    "ttft": 1352497.4366144503,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 134,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.41823633820982675,
    "arrivals": 196793,
    "finished_requests": 113167,
    "scheduler_time": 240.60566730850746
}
#Debug simulation 
Total elapsed time: 141.22147369012237. Arrivals time: 0.6493172412738204 Scheduler time: 140.2936297398992 Scheduler overhead time: 0.11025419505313039 Adapter cache time: 0.02053563017398119 Engine time: 0.1107979160733521 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-32/adapters_96_slots_16_rate_1.6-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-32/adapters_96_slots_16_rate_1.6-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 135, 17280, 1080, 135, 135, 1080, 17280, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 17280, 1080, 1080, 135, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 135, 17280, 1080, 1080, 1080, 17280, 17280, 135, 135, 1080, 135, 17280, 135, 135, 17280, 135, 1080, 1080, 135, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 135, 135, 17280, 1080, 17280, 135, 1080, 17280, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 135, 135, 1080]
Prompts retrieved: 591840 . Total input tokens: 131946218 . Total output tokens: 118450311
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 140.82325361203402,
    "estimated_duration": 3600.1024488644416,
    "input_throughput": 7625.129392820135,
    "output_throughput": 6764.350000006615,
    "total_throughput": 14389.47939282675,
    "itl": 97.10912067434714,
    "ttft": 1344520.8117245291,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 140,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4613893248699612,
    "arrivals": 196793,
    "finished_requests": 111010,
    "scheduler_time": 246.57154640441618
}
#Debug simulation 
Total elapsed time: 140.82344380300492. Arrivals time: 0.5816426333039999 Scheduler time: 139.97490415954962 Scheduler overhead time: 0.10395359573885798 Adapter cache time: 0.020312922541052103 Engine time: 0.10472225490957499 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-16/adapters_96_slots_16_rate_1.6-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-16/adapters_96_slots_16_rate_1.6-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 135, 17280, 1080, 135, 135, 1080, 17280, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 17280, 1080, 1080, 135, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 135, 17280, 1080, 1080, 1080, 17280, 17280, 135, 135, 1080, 135, 17280, 135, 135, 17280, 135, 1080, 1080, 135, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 135, 135, 17280, 1080, 17280, 135, 1080, 17280, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 135, 135, 1080]
Prompts retrieved: 591840 . Total input tokens: 131946218 . Total output tokens: 118450311
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 135.9082016069442,
    "estimated_duration": 3600.014524585835,
    "input_throughput": 7801.686023261583,
    "output_throughput": 6916.8954263774085,
    "total_throughput": 14718.58144963899,
    "itl": 99.43028064585361,
    "ttft": 1347673.471505072,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 136,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4066468401066964,
    "arrivals": 196793,
    "finished_requests": 113667,
    "scheduler_time": 238.88465798495076
}
#Debug simulation 
Total elapsed time: 135.90835416223854. Arrivals time: 0.6844195071607828 Scheduler time: 134.9499096334912 Scheduler overhead time: 0.10701834643259645 Adapter cache time: 0.021232572849839926 Engine time: 0.10804152674973011 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-32/adapters_96_slots_16_rate_1.6-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-32/adapters_96_slots_16_rate_1.6-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 135, 17280, 1080, 135, 135, 1080, 17280, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 17280, 1080, 1080, 135, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 135, 17280, 1080, 1080, 1080, 17280, 17280, 135, 135, 1080, 135, 17280, 135, 135, 17280, 135, 1080, 1080, 135, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 135, 135, 17280, 1080, 17280, 135, 1080, 17280, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 135, 135, 1080]
Prompts retrieved: 591840 . Total input tokens: 131946218 . Total output tokens: 118450311
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 143.31737957615405,
    "estimated_duration": 3600.108753828413,
    "input_throughput": 7625.116038732971,
    "output_throughput": 6764.33815342476,
    "total_throughput": 14389.454192157731,
    "itl": 97.10919721347543,
    "ttft": 1344523.1983400155,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 140,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4672997528314588,
    "arrivals": 196793,
    "finished_requests": 111010,
    "scheduler_time": 246.57174086327487
}
#Debug simulation 
Total elapsed time: 143.3175298590213. Arrivals time: 0.64355852548033 Scheduler time: 142.4002268211916 Scheduler overhead time: 0.10705354902893305 Adapter cache time: 0.020750725641846657 Engine time: 0.10875401645898819 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-8/adapters_96_slots_16_rate_1.6-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-8/adapters_96_slots_16_rate_1.6-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 66, 17280, 1080, 66, 66, 1080, 17280, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 17280, 1080, 1080, 66, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 66, 17280, 1080, 1080, 1080, 17280, 17280, 66, 66, 1080, 66, 17280, 66, 66, 17280, 66, 1080, 1080, 66, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 66, 66, 17280, 1080, 17280, 66, 1080, 17280, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 66, 66, 1080]
Prompts retrieved: 589632 . Total input tokens: 131460243 . Total output tokens: 118014727
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 153.80855378881097,
    "estimated_duration": 3600.082996661335,
    "input_throughput": 7809.525232077535,
    "output_throughput": 6905.458019455387,
    "total_throughput": 14714.983251532922,
    "itl": 99.03532466127504,
    "ttft": 1329052.8606719305,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 131,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4009238944551903,
    "arrivals": 196113,
    "finished_requests": 113579,
    "scheduler_time": 238.19135677090003
}
#Debug simulation 
Total elapsed time: 153.8087966516614. Arrivals time: 0.6729097058996558 Scheduler time: 152.8505841284059 Scheduler overhead time: 0.11146573815494776 Adapter cache time: 0.021999039221554995 Engine time: 0.11296982318162918 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-16/adapters_96_slots_16_rate_1.6-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-16/adapters_96_slots_16_rate_1.6-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 66, 17280, 1080, 66, 66, 1080, 17280, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 17280, 1080, 1080, 66, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 66, 17280, 1080, 1080, 1080, 17280, 17280, 66, 66, 1080, 66, 17280, 66, 66, 17280, 66, 1080, 1080, 66, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 66, 66, 17280, 1080, 17280, 66, 1080, 17280, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 66, 66, 1080]
Prompts retrieved: 589632 . Total input tokens: 131460243 . Total output tokens: 118014727
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 149.6301623438485,
    "estimated_duration": 3600.110278319714,
    "input_throughput": 7809.466051446107,
    "output_throughput": 6905.405689850994,
    "total_throughput": 14714.871741297102,
    "itl": 99.03572864921003,
    "ttft": 1329063.3305311552,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 131,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4272443813364953,
    "arrivals": 196113,
    "finished_requests": 113579,
    "scheduler_time": 238.19224253943335
}
#Debug simulation 
Total elapsed time: 149.63031777879223. Arrivals time: 0.6123278862796724 Scheduler time: 148.7454750519246 Scheduler overhead time: 0.10677200136706233 Adapter cache time: 0.020414001308381557 Engine time: 0.10775773180648685 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-32/adapters_96_slots_16_rate_1.6-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-32/adapters_96_slots_16_rate_1.6-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 66, 17280, 1080, 66, 66, 1080, 17280, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 17280, 1080, 1080, 66, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 66, 17280, 1080, 1080, 1080, 17280, 17280, 66, 66, 1080, 66, 17280, 66, 66, 17280, 66, 1080, 1080, 66, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 66, 66, 17280, 1080, 17280, 66, 1080, 17280, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 66, 66, 1080]
Prompts retrieved: 589632 . Total input tokens: 131460243 . Total output tokens: 118014727
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 154.5256816712208,
    "estimated_duration": 3600.1109669753496,
    "input_throughput": 7809.464557594151,
    "output_throughput": 6905.404368934337,
    "total_throughput": 14714.868926528488,
    "itl": 99.03575227994205,
    "ttft": 1329063.5958634813,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 131,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4280415012128662,
    "arrivals": 196113,
    "finished_requests": 113579,
    "scheduler_time": 238.19223411376163
}
#Debug simulation 
Total elapsed time: 154.52583002718166. Arrivals time: 0.6548081794753671 Scheduler time: 153.5869099884294 Scheduler overhead time: 0.11115378187969327 Adapter cache time: 0.02211740519851446 Engine time: 0.11259829206392169 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-16/adapters_96_slots_16_rate_1.6-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-16/adapters_96_slots_16_rate_1.6-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 66, 17280, 1080, 66, 66, 1080, 17280, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 17280, 1080, 1080, 66, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 66, 17280, 1080, 1080, 1080, 17280, 17280, 66, 66, 1080, 66, 17280, 66, 66, 17280, 66, 1080, 1080, 66, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 66, 66, 17280, 1080, 17280, 66, 1080, 17280, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 66, 66, 1080]
Prompts retrieved: 589632 . Total input tokens: 131460243 . Total output tokens: 118014727
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 152.01586501207203,
    "estimated_duration": 3600.0904747548198,
    "input_throughput": 7809.509010163068,
    "output_throughput": 6905.443675465705,
    "total_throughput": 14714.952685628774,
    "itl": 99.03541388851137,
    "ttft": 1329055.56035219,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 131,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4092661873251202,
    "arrivals": 196113,
    "finished_requests": 113579,
    "scheduler_time": 238.1915142583001
}
#Debug simulation 
Total elapsed time: 152.01608005492017. Arrivals time: 0.6815121863037348 Scheduler time: 151.05653955135494 Scheduler overhead time: 0.10945516964420676 Adapter cache time: 0.021415806375443935 Engine time: 0.10996517864987254 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-32/adapters_96_slots_16_rate_1.6-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-32/adapters_96_slots_16_rate_1.6-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 66, 17280, 1080, 66, 66, 1080, 17280, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 17280, 1080, 1080, 66, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 66, 17280, 1080, 1080, 1080, 17280, 17280, 66, 66, 1080, 66, 17280, 66, 66, 17280, 66, 1080, 1080, 66, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 66, 66, 17280, 1080, 17280, 66, 1080, 17280, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 66, 66, 1080]
Prompts retrieved: 589632 . Total input tokens: 131460243 . Total output tokens: 118014727
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 151.804232488852,
    "estimated_duration": 3600.116286614729,
    "input_throughput": 7809.453018096012,
    "output_throughput": 6905.394165302541,
    "total_throughput": 14714.847183398553,
    "itl": 99.03584562829502,
    "ttft": 1329065.5430512475,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 131,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4335746678151194,
    "arrivals": 196113,
    "finished_requests": 113579,
    "scheduler_time": 238.19232070229012
}
#Debug simulation 
Total elapsed time: 151.80438730400056. Arrivals time: 0.6519071105867624 Scheduler time: 150.87328178342432 Scheduler overhead time: 0.10989269940182567 Adapter cache time: 0.0211627334356308 Engine time: 0.11075980309396982 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-16/adapters_96_slots_16_rate_1.6-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-16/adapters_96_slots_16_rate_1.6-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 66, 17280, 1080, 66, 66, 1080, 17280, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 17280, 1080, 1080, 66, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 66, 17280, 1080, 1080, 1080, 17280, 17280, 66, 66, 1080, 66, 17280, 66, 66, 17280, 66, 1080, 1080, 66, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 66, 66, 17280, 1080, 17280, 66, 1080, 17280, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 66, 66, 1080]
Prompts retrieved: 589632 . Total input tokens: 131460243 . Total output tokens: 118014727
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 151.04445620579645,
    "estimated_duration": 3600.069687784805,
    "input_throughput": 7809.554102631742,
    "output_throughput": 6905.483547819041,
    "total_throughput": 14715.037650450782,
    "itl": 99.0351027090216,
    "ttft": 1329046.87547008,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 131,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3916965886321855,
    "arrivals": 196113,
    "finished_requests": 113579,
    "scheduler_time": 238.19067154397976
}
#Debug simulation 
Total elapsed time: 151.04460247373208. Arrivals time: 0.6303038224577904 Scheduler time: 150.14115580823272 Scheduler overhead time: 0.10725297685712576 Adapter cache time: 0.020708130206912756 Engine time: 0.10759437596425414 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-32/adapters_96_slots_16_rate_1.6-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-32/adapters_96_slots_16_rate_1.6-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 66, 17280, 1080, 66, 66, 1080, 17280, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 17280, 1080, 1080, 66, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 66, 17280, 1080, 1080, 1080, 17280, 17280, 66, 66, 1080, 66, 17280, 66, 66, 17280, 66, 1080, 1080, 66, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 66, 66, 17280, 1080, 17280, 66, 1080, 17280, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 66, 66, 1080]
Prompts retrieved: 589632 . Total input tokens: 131460243 . Total output tokens: 118014727
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 154.90929968794808,
    "estimated_duration": 3600.1220545058572,
    "input_throughput": 7809.4405062772175,
    "output_throughput": 6905.383101910484,
    "total_throughput": 14714.823608187702,
    "itl": 99.03596151472445,
    "ttft": 1329067.7976342358,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 131,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.43898208063095767,
    "arrivals": 196113,
    "finished_requests": 113579,
    "scheduler_time": 238.19248355340665
}
#Debug simulation 
Total elapsed time: 154.90950470976532. Arrivals time: 0.6716601466760039 Scheduler time: 153.9512687213719 Scheduler overhead time: 0.11048477981239557 Adapter cache time: 0.022476357873529196 Engine time: 0.11400161823257804 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-8/adapters_96_slots_16_rate_1.6-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-8/adapters_96_slots_16_rate_1.6-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 33, 17280, 1080, 33, 33, 1080, 17280, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 17280, 1080, 1080, 33, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 33, 17280, 1080, 1080, 1080, 17280, 17280, 33, 33, 1080, 33, 17280, 33, 33, 17280, 33, 1080, 1080, 33, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 33, 33, 17280, 1080, 17280, 33, 1080, 17280, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 33, 33, 1080]
Prompts retrieved: 588576 . Total input tokens: 131231793 . Total output tokens: 117798990
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 142.6358687891625,
    "estimated_duration": 3600.056834492439,
    "input_throughput": 7826.741991969843,
    "output_throughput": 6917.614955795861,
    "total_throughput": 14744.356947765704,
    "itl": 99.66795675656242,
    "ttft": 1326358.3891202554,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 143,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.43764974738238327,
    "arrivals": 195753,
    "finished_requests": 114053,
    "scheduler_time": 237.6022133279938
}
#Debug simulation 
Total elapsed time: 142.6360101280734. Arrivals time: 0.6203536069951952 Scheduler time: 141.747101476416 Scheduler overhead time: 0.10530835017561913 Adapter cache time: 0.020384738221764565 Engine time: 0.10535004502162337 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-16/adapters_96_slots_16_rate_1.6-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-16/adapters_96_slots_16_rate_1.6-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 33, 17280, 1080, 33, 33, 1080, 17280, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 17280, 1080, 1080, 33, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 33, 17280, 1080, 1080, 1080, 17280, 17280, 33, 33, 1080, 33, 17280, 33, 33, 17280, 33, 1080, 1080, 33, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 33, 33, 17280, 1080, 17280, 33, 1080, 17280, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 33, 33, 1080]
Prompts retrieved: 588576 . Total input tokens: 131231793 . Total output tokens: 117798990
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 140.64704391313717,
    "estimated_duration": 3600.121945331164,
    "input_throughput": 7827.058479656016,
    "output_throughput": 6918.4575906661,
    "total_throughput": 14745.516070322115,
    "itl": 99.6571432319589,
    "ttft": 1326261.7370243685,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 142,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.46095212521729995,
    "arrivals": 195753,
    "finished_requests": 114060,
    "scheduler_time": 237.6350768337939
}
#Debug simulation 
Total elapsed time: 140.64719621790573. Arrivals time: 0.5967090232297778 Scheduler time: 139.78725511673838 Scheduler overhead time: 0.10243731271475554 Adapter cache time: 0.01975658116862178 Engine time: 0.1045992593280971 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-32/adapters_96_slots_16_rate_1.6-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-32/adapters_96_slots_16_rate_1.6-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 33, 17280, 1080, 33, 33, 1080, 17280, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 17280, 1080, 1080, 33, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 33, 17280, 1080, 1080, 1080, 17280, 17280, 33, 33, 1080, 33, 17280, 33, 33, 17280, 33, 1080, 1080, 33, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 33, 33, 17280, 1080, 17280, 33, 1080, 17280, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 33, 33, 1080]
Prompts retrieved: 588576 . Total input tokens: 131231793 . Total output tokens: 117798990
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 140.81556345429271,
    "estimated_duration": 3600.1230038084514,
    "input_throughput": 7827.056178411414,
    "output_throughput": 6918.45555656054,
    "total_throughput": 14745.511734971955,
    "itl": 99.65716397687554,
    "ttft": 1326262.158508705,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 142,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.46219470353797215,
    "arrivals": 195753,
    "finished_requests": 114060,
    "scheduler_time": 237.6350928099117
}
#Debug simulation 
Total elapsed time: 140.81575178913772. Arrivals time: 0.5961624486371875 Scheduler time: 139.95335001125932 Scheduler overhead time: 0.10405631829053164 Adapter cache time: 0.01977915596216917 Engine time: 0.1059009418822825 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-16/adapters_96_slots_16_rate_1.6-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-16/adapters_96_slots_16_rate_1.6-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 33, 17280, 1080, 33, 33, 1080, 17280, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 17280, 1080, 1080, 33, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 33, 17280, 1080, 1080, 1080, 17280, 17280, 33, 33, 1080, 33, 17280, 33, 33, 17280, 33, 1080, 1080, 33, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 33, 33, 17280, 1080, 17280, 33, 1080, 17280, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 33, 33, 1080]
Prompts retrieved: 588576 . Total input tokens: 131231793 . Total output tokens: 117798990
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 144.62886926485226,
    "estimated_duration": 3600.0650948554867,
    "input_throughput": 7826.724033480585,
    "output_throughput": 6917.599083302044,
    "total_throughput": 14744.323116782629,
    "itl": 99.6682040828254,
    "ttft": 1326361.372015536,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 143,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.44637257681926734,
    "arrivals": 195753,
    "finished_requests": 114053,
    "scheduler_time": 237.60235109306913
}
#Debug simulation 
Total elapsed time: 144.62902542203665. Arrivals time: 0.6585786398500204 Scheduler time: 143.69704154133797 Scheduler overhead time: 0.10626583965495229 Adapter cache time: 0.021196466870605946 Engine time: 0.10785061772912741 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-32/adapters_96_slots_16_rate_1.6-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-32/adapters_96_slots_16_rate_1.6-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 33, 17280, 1080, 33, 33, 1080, 17280, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 17280, 1080, 1080, 33, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 33, 17280, 1080, 1080, 1080, 17280, 17280, 33, 33, 1080, 33, 17280, 33, 33, 17280, 33, 1080, 1080, 33, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 33, 33, 17280, 1080, 17280, 33, 1080, 17280, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 33, 33, 1080]
Prompts retrieved: 588576 . Total input tokens: 131231793 . Total output tokens: 117798990
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 144.05251298099756,
    "estimated_duration": 3600.0032188252258,
    "input_throughput": 7826.948557339039,
    "output_throughput": 6918.153258798271,
    "total_throughput": 14745.10181613731,
    "itl": 99.65591393822513,
    "ttft": 1326297.335406728,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 142,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4676021163538105,
    "arrivals": 195753,
    "finished_requests": 114054,
    "scheduler_time": 237.6269368700607
}
#Debug simulation 
Total elapsed time: 144.05266554187983. Arrivals time: 0.672088679857552 Scheduler time: 143.10929886996746 Scheduler overhead time: 0.10531902872025967 Adapter cache time: 0.02070256555452943 Engine time: 0.10824121534824371 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-16/adapters_96_slots_16_rate_1.6-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-16/adapters_96_slots_16_rate_1.6-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 33, 17280, 1080, 33, 33, 1080, 17280, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 17280, 1080, 1080, 33, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 33, 17280, 1080, 1080, 1080, 17280, 17280, 33, 33, 1080, 33, 17280, 33, 33, 17280, 33, 1080, 1080, 33, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 33, 33, 17280, 1080, 17280, 33, 1080, 17280, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 33, 33, 1080]
Prompts retrieved: 588576 . Total input tokens: 131231793 . Total output tokens: 117798990
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 141.82464001793414,
    "estimated_duration": 3600.111761715177,
    "input_throughput": 7827.080620012522,
    "output_throughput": 6918.477160868358,
    "total_throughput": 14745.55778088088,
    "itl": 99.65711782965356,
    "ttft": 1326264.38586653,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 142,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42458714187610946,
    "arrivals": 195753,
    "finished_requests": 114060,
    "scheduler_time": 237.63864911360133
}
#Debug simulation 
Total elapsed time: 141.8248501997441. Arrivals time: 0.6310376590117812 Scheduler time: 140.921808690764 Scheduler overhead time: 0.10594190238043666 Adapter cache time: 0.020929742604494095 Engine time: 0.10751068172976375 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-32/adapters_96_slots_16_rate_1.6-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-32/adapters_96_slots_16_rate_1.6-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 33, 17280, 1080, 33, 33, 1080, 17280, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 17280, 1080, 1080, 33, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 33, 17280, 1080, 1080, 1080, 17280, 17280, 33, 33, 1080, 33, 17280, 33, 33, 17280, 33, 1080, 1080, 33, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 33, 33, 17280, 1080, 17280, 33, 1080, 17280, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 33, 33, 1080]
Prompts retrieved: 588576 . Total input tokens: 131231793 . Total output tokens: 117798990
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 142.58000594610348,
    "estimated_duration": 3600.009570144178,
    "input_throughput": 7826.934748640551,
    "output_throughput": 6918.14105344241,
    "total_throughput": 14745.075802082962,
    "itl": 99.65611976170514,
    "ttft": 1326299.9275457065,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 142,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4733867905288932,
    "arrivals": 195753,
    "finished_requests": 114054,
    "scheduler_time": 237.62711812829554
}
#Debug simulation 
Total elapsed time: 142.58015209017321. Arrivals time: 0.6052165101282299 Scheduler time: 141.70648921793327 Scheduler overhead time: 0.10486406413838267 Adapter cache time: 0.020071789156645536 Engine time: 0.10699712531641126 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-8/adapters_96_slots_16_rate_1.6-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-8/adapters_96_slots_16_rate_1.6-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 540, 270, 17280, 540, 270, 270, 540, 17280, 270, 540, 270, 270, 540, 540, 540, 270, 270, 17280, 540, 540, 270, 17280, 17280, 540, 17280, 17280, 540, 17280, 270, 17280, 540, 540, 540, 17280, 17280, 270, 270, 540, 270, 17280, 270, 270, 17280, 270, 540, 540, 270, 540, 17280, 17280, 17280, 540, 17280, 17280, 270, 270, 17280, 540, 17280, 270, 540, 17280, 270, 17280, 540, 270, 17280, 270, 270, 17280, 270, 270, 540]
Prompts retrieved: 578880 . Total input tokens: 129047310 . Total output tokens: 115859917
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 137.96195761440322,
    "estimated_duration": 3600.017094827256,
    "input_throughput": 7597.206424185708,
    "output_throughput": 6704.618162697414,
    "total_throughput": 14301.824586883122,
    "itl": 96.8411963578431,
    "ttft": 1341384.2806179444,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 121,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3703190170158628,
    "arrivals": 192543,
    "finished_requests": 110119,
    "scheduler_time": 247.41929066975686
}
#Debug simulation 
Total elapsed time: 137.96210235031322. Arrivals time: 0.610233913641423 Scheduler time: 137.08100509876385 Scheduler overhead time: 0.10640663933008909 Adapter cache time: 0.020284023135900497 Engine time: 0.10681122168898582 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-16/adapters_96_slots_16_rate_1.6-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-16/adapters_96_slots_16_rate_1.6-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 540, 270, 17280, 540, 270, 270, 540, 17280, 270, 540, 270, 270, 540, 540, 540, 270, 270, 17280, 540, 540, 270, 17280, 17280, 540, 17280, 17280, 540, 17280, 270, 17280, 540, 540, 540, 17280, 17280, 270, 270, 540, 270, 17280, 270, 270, 17280, 270, 540, 540, 270, 540, 17280, 17280, 17280, 540, 17280, 17280, 270, 270, 17280, 540, 17280, 270, 540, 17280, 270, 17280, 540, 270, 17280, 270, 270, 17280, 270, 270, 540]
Prompts retrieved: 578880 . Total input tokens: 129047310 . Total output tokens: 115859917
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 128.6248374702409,
    "estimated_duration": 3600.0431663225118,
    "input_throughput": 7597.1514052534085,
    "output_throughput": 6704.569607885001,
    "total_throughput": 14301.721013138409,
    "itl": 96.84157904721042,
    "ttft": 1341394.0160545171,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 121,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3936665205215104,
    "arrivals": 192543,
    "finished_requests": 110119,
    "scheduler_time": 247.41991385131763
}
#Debug simulation 
Total elapsed time: 128.62505816295743. Arrivals time: 0.5287500293925405 Scheduler time: 127.85019763978198 Scheduler overhead time: 0.09651306457817554 Adapter cache time: 0.01809097360819578 Engine time: 0.09602357121184468 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-32/adapters_96_slots_16_rate_1.6-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-32/adapters_96_slots_16_rate_1.6-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 540, 270, 17280, 540, 270, 270, 540, 17280, 270, 540, 270, 270, 540, 540, 540, 270, 270, 17280, 540, 540, 270, 17280, 17280, 540, 17280, 17280, 540, 17280, 270, 17280, 540, 540, 540, 17280, 17280, 270, 270, 540, 270, 17280, 270, 270, 17280, 270, 540, 540, 270, 540, 17280, 17280, 17280, 540, 17280, 17280, 270, 270, 17280, 540, 17280, 270, 540, 17280, 270, 17280, 540, 270, 17280, 270, 270, 17280, 270, 270, 540]
Prompts retrieved: 578880 . Total input tokens: 129047310 . Total output tokens: 115859917
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 124.95265838876367,
    "estimated_duration": 3600.0444433743164,
    "input_throughput": 7597.148710298925,
    "output_throughput": 6704.567229558052,
    "total_throughput": 14301.715939856977,
    "itl": 96.84161471517476,
    "ttft": 1341394.7262021299,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 121,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3945710852742204,
    "arrivals": 192543,
    "finished_requests": 110119,
    "scheduler_time": 247.41998622261735
}
#Debug simulation 
Total elapsed time: 124.95279252482578. Arrivals time: 0.42910443944856524 Scheduler time: 124.28456498635933 Scheduler overhead time: 0.09258795063942671 Adapter cache time: 0.01686734613031149 Engine time: 0.09435709426179528 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-16-16/adapters_96_slots_16_rate_1.6-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-16-16/adapters_96_slots_16_rate_1.6-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 540, 270, 17280, 540, 270, 270, 540, 17280, 270, 540, 270, 270, 540, 540, 540, 270, 270, 17280, 540, 540, 270, 17280, 17280, 540, 17280, 17280, 540, 17280, 270, 17280, 540, 540, 540, 17280, 17280, 270, 270, 540, 270, 17280, 270, 270, 17280, 270, 540, 540, 270, 540, 17280, 17280, 17280, 540, 17280, 17280, 270, 270, 17280, 540, 17280, 270, 540, 17280, 270, 17280, 540, 270, 17280, 270, 270, 17280, 270, 270, 540]
Prompts retrieved: 578880 . Total input tokens: 129047310 . Total output tokens: 115859917
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 125.93741756305099,
    "estimated_duration": 3600.0248147332313,
    "input_throughput": 7597.190132709319,
    "output_throughput": 6704.603785290457,
    "total_throughput": 14301.793917999776,
    "itl": 96.84132935692834,
    "ttft": 1341387.0779873643,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 121,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.37773130310233705,
    "arrivals": 192543,
    "finished_requests": 110119,
    "scheduler_time": 247.41939821246956
}
#Debug simulation 
Total elapsed time: 125.93755642697215. Arrivals time: 0.4317274186760187 Scheduler time: 125.2663485892117 Scheduler overhead time: 0.09271567640826106 Adapter cache time: 0.016804006416350603 Engine time: 0.09449356561526656 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-16-32/adapters_96_slots_16_rate_1.6-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-16-32/adapters_96_slots_16_rate_1.6-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 540, 270, 17280, 540, 270, 270, 540, 17280, 270, 540, 270, 270, 540, 540, 540, 270, 270, 17280, 540, 540, 270, 17280, 17280, 540, 17280, 17280, 540, 17280, 270, 17280, 540, 540, 540, 17280, 17280, 270, 270, 540, 270, 17280, 270, 270, 17280, 270, 540, 540, 270, 540, 17280, 17280, 17280, 540, 17280, 17280, 270, 270, 17280, 540, 17280, 270, 540, 17280, 270, 17280, 540, 270, 17280, 270, 270, 17280, 270, 270, 540]
Prompts retrieved: 578880 . Total input tokens: 129047310 . Total output tokens: 115859917
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 125.42703923210502,
    "estimated_duration": 3600.047207222859,
    "input_throughput": 7597.142877773077,
    "output_throughput": 6704.562082289892,
    "total_throughput": 14301.704960062969,
    "itl": 96.84161993797231,
    "ttft": 1341395.5107755417,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 121,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.39947548294439944,
    "arrivals": 192543,
    "finished_requests": 110119,
    "scheduler_time": 247.42004652226166
}
#Debug simulation 
Total elapsed time: 125.42724280478433. Arrivals time: 0.4259164868853986 Scheduler time: 124.76277057873085 Scheduler overhead time: 0.09269601386040449 Adapter cache time: 0.016594499815255404 Engine time: 0.09370298404246569 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_16-16-16/adapters_96_slots_16_rate_1.6-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_16-16-16/adapters_96_slots_16_rate_1.6-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 540, 270, 17280, 540, 270, 270, 540, 17280, 270, 540, 270, 270, 540, 540, 540, 270, 270, 17280, 540, 540, 270, 17280, 17280, 540, 17280, 17280, 540, 17280, 270, 17280, 540, 540, 540, 17280, 17280, 270, 270, 540, 270, 17280, 270, 270, 17280, 270, 540, 540, 270, 540, 17280, 17280, 17280, 540, 17280, 17280, 270, 270, 17280, 540, 17280, 270, 540, 17280, 270, 17280, 540, 270, 17280, 270, 270, 17280, 270, 270, 540]
Prompts retrieved: 578880 . Total input tokens: 129047310 . Total output tokens: 115859917
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 125.53630636865273,
    "estimated_duration": 3600.0074709589667,
    "input_throughput": 7597.226733730781,
    "output_throughput": 6704.636086094143,
    "total_throughput": 14301.862819824924,
    "itl": 96.84108466936758,
    "ttft": 1341380.2027051158,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 121,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3617960856831637,
    "arrivals": 192543,
    "finished_requests": 110119,
    "scheduler_time": 247.41899004142448
}
#Debug simulation 
Total elapsed time: 125.53644293174148. Arrivals time: 0.4408115642145276 Scheduler time: 124.85849119583145 Scheduler overhead time: 0.09128972515463829 Adapter cache time: 0.016836528200656176 Engine time: 0.09351374674588442 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_16-16-32/adapters_96_slots_16_rate_1.6-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_16-16-32/adapters_96_slots_16_rate_1.6-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 540, 270, 17280, 540, 270, 270, 540, 17280, 270, 540, 270, 270, 540, 540, 540, 270, 270, 17280, 540, 540, 270, 17280, 17280, 540, 17280, 17280, 540, 17280, 270, 17280, 540, 540, 540, 17280, 17280, 270, 270, 540, 270, 17280, 270, 270, 17280, 270, 540, 540, 270, 540, 17280, 17280, 17280, 540, 17280, 17280, 270, 270, 17280, 540, 17280, 270, 540, 17280, 270, 17280, 540, 270, 17280, 270, 270, 17280, 270, 270, 540]
Prompts retrieved: 578880 . Total input tokens: 129047310 . Total output tokens: 115859917
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 124.8818009053357,
    "estimated_duration": 3600.0500125070594,
    "input_throughput": 7597.136957815074,
    "output_throughput": 6704.556857861893,
    "total_throughput": 14301.693815676967,
    "itl": 96.8416346030682,
    "ttft": 1341396.5058908747,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 121,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.40437988061457836,
    "arrivals": 192543,
    "finished_requests": 110119,
    "scheduler_time": 247.42014825757457
}
#Debug simulation 
Total elapsed time: 124.88193905493245. Arrivals time: 0.43069279845803976 Scheduler time: 124.21392566245049 Scheduler overhead time: 0.09172629518434405 Adapter cache time: 0.016844442579895258 Engine time: 0.09377134125679731 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-8/adapters_96_slots_16_rate_1.6-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-8/adapters_96_slots_16_rate_1.6-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 540, 135, 17280, 540, 135, 135, 540, 17280, 135, 540, 135, 135, 540, 540, 540, 135, 135, 17280, 540, 540, 135, 17280, 17280, 540, 17280, 17280, 540, 17280, 135, 17280, 540, 540, 540, 17280, 17280, 135, 135, 540, 135, 17280, 135, 135, 17280, 135, 540, 540, 135, 540, 17280, 17280, 17280, 540, 17280, 17280, 135, 135, 17280, 540, 17280, 135, 540, 17280, 135, 17280, 540, 135, 17280, 135, 135, 17280, 135, 135, 540]
Prompts retrieved: 574560 . Total input tokens: 128078117 . Total output tokens: 114993343
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 132.84816267387941,
    "estimated_duration": 3600.0310273334744,
    "input_throughput": 7677.049111565865,
    "output_throughput": 6775.661880355369,
    "total_throughput": 14452.710991921234,
    "itl": 97.9537080184334,
    "ttft": 1335630.8638411213,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 135,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4131658454309213,
    "arrivals": 191076,
    "finished_requests": 111106,
    "scheduler_time": 243.85897048070865
}
#Debug simulation 
Total elapsed time: 132.84835582086816. Arrivals time: 0.4901839285157621 Scheduler time: 132.11359563330188 Scheduler overhead time: 0.09551172144711018 Adapter cache time: 0.017230162397027016 Engine time: 0.09575122268870473 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-16/adapters_96_slots_16_rate_1.6-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-16/adapters_96_slots_16_rate_1.6-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 540, 135, 17280, 540, 135, 135, 540, 17280, 135, 540, 135, 135, 540, 540, 540, 135, 135, 17280, 540, 540, 135, 17280, 17280, 540, 17280, 17280, 540, 17280, 135, 17280, 540, 540, 540, 17280, 17280, 135, 135, 540, 135, 17280, 135, 135, 17280, 135, 540, 540, 135, 540, 17280, 17280, 17280, 540, 17280, 17280, 135, 135, 17280, 540, 17280, 135, 540, 17280, 135, 17280, 540, 135, 17280, 135, 135, 17280, 135, 135, 540]
Prompts retrieved: 574560 . Total input tokens: 128078117 . Total output tokens: 114993343
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 133.91082200501114,
    "estimated_duration": 3600.0648528506276,
    "input_throughput": 7713.51298797066,
    "output_throughput": 6817.151357861468,
    "total_throughput": 14530.664345832127,
    "itl": 98.16557121993897,
    "ttft": 1313508.7421583615,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 134,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4358059369027615,
    "arrivals": 191076,
    "finished_requests": 111655,
    "scheduler_time": 241.7930383347236
}
#Debug simulation 
Total elapsed time: 133.91095178807154. Arrivals time: 0.47742878925055265 Scheduler time: 133.19040555134416 Scheduler overhead time: 0.09412591438740492 Adapter cache time: 0.017707091756165028 Engine time: 0.09575007017701864 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-32/adapters_96_slots_16_rate_1.6-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-32/adapters_96_slots_16_rate_1.6-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 540, 135, 17280, 540, 135, 135, 540, 17280, 135, 540, 135, 135, 540, 540, 540, 135, 135, 17280, 540, 540, 135, 17280, 17280, 540, 17280, 17280, 540, 17280, 135, 17280, 540, 540, 540, 17280, 17280, 135, 135, 540, 135, 17280, 135, 135, 17280, 135, 540, 540, 135, 540, 17280, 17280, 17280, 540, 17280, 17280, 135, 135, 17280, 540, 17280, 135, 540, 17280, 135, 17280, 540, 135, 17280, 135, 135, 17280, 135, 135, 540]
Prompts retrieved: 574560 . Total input tokens: 128078117 . Total output tokens: 114993343
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 133.45094933593646,
    "estimated_duration": 3600.065702945516,
    "input_throughput": 7713.511166554468,
    "output_throughput": 6817.14974810598,
    "total_throughput": 14530.660914660448,
    "itl": 98.16559879707435,
    "ttft": 1313509.0930000765,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 134,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4368348102644098,
    "arrivals": 191076,
    "finished_requests": 111655,
    "scheduler_time": 241.79305963340133
}
#Debug simulation 
Total elapsed time: 133.451083089225. Arrivals time: 0.4359373520128429 Scheduler time: 132.77456421405077 Scheduler overhead time: 0.0928382514975965 Adapter cache time: 0.01720040710642934 Engine time: 0.09511422226205468 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-16/adapters_96_slots_16_rate_1.6-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-16/adapters_96_slots_16_rate_1.6-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 540, 135, 17280, 540, 135, 135, 540, 17280, 135, 540, 135, 135, 540, 540, 540, 135, 135, 17280, 540, 540, 135, 17280, 17280, 540, 17280, 17280, 540, 17280, 135, 17280, 540, 540, 540, 17280, 17280, 135, 135, 540, 135, 17280, 135, 135, 17280, 135, 540, 540, 135, 540, 17280, 17280, 17280, 540, 17280, 17280, 135, 135, 17280, 540, 17280, 135, 540, 17280, 135, 17280, 540, 135, 17280, 135, 135, 17280, 135, 135, 540]
Prompts retrieved: 574560 . Total input tokens: 128078117 . Total output tokens: 114993343
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 138.09074615500867,
    "estimated_duration": 3600.1046040843507,
    "input_throughput": 7647.806113401171,
    "output_throughput": 6758.293626356512,
    "total_throughput": 14406.099739757683,
    "itl": 97.62602684449875,
    "ttft": 1338269.340236367,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 130,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4066847323486584,
    "arrivals": 191076,
    "finished_requests": 110769,
    "scheduler_time": 244.78850154884572
}
#Debug simulation 
Total elapsed time: 138.0909259710461. Arrivals time: 0.43097824277356267 Scheduler time: 137.41568917781115 Scheduler overhead time: 0.09400045266374946 Adapter cache time: 0.01754469657316804 Engine time: 0.09665784053504467 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-32/adapters_96_slots_16_rate_1.6-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-32/adapters_96_slots_16_rate_1.6-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 540, 135, 17280, 540, 135, 135, 540, 17280, 135, 540, 135, 135, 540, 540, 540, 135, 135, 17280, 540, 540, 135, 17280, 17280, 540, 17280, 17280, 540, 17280, 135, 17280, 540, 540, 540, 17280, 17280, 135, 135, 540, 135, 17280, 135, 135, 17280, 135, 540, 540, 135, 540, 17280, 17280, 17280, 540, 17280, 17280, 135, 135, 17280, 540, 17280, 135, 540, 17280, 135, 17280, 540, 135, 17280, 135, 135, 17280, 135, 135, 540]
Prompts retrieved: 574560 . Total input tokens: 128078117 . Total output tokens: 114993343
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 132.64284142619,
    "estimated_duration": 3600.0702795524553,
    "input_throughput": 7713.501360715696,
    "output_throughput": 6817.141081771041,
    "total_throughput": 14530.642442486736,
    "itl": 98.16562843050008,
    "ttft": 1313510.7776666216,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 134,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.44199071550741836,
    "arrivals": 191076,
    "finished_requests": 111655,
    "scheduler_time": 241.79318060516593
}
#Debug simulation 
Total elapsed time: 132.64297599997371. Arrivals time: 0.43953536497429013 Scheduler time: 131.96287849592045 Scheduler overhead time: 0.09382023802027106 Adapter cache time: 0.017158252652734518 Engine time: 0.09491517534479499 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-16/adapters_96_slots_16_rate_1.6-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-16/adapters_96_slots_16_rate_1.6-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 540, 135, 17280, 540, 135, 135, 540, 17280, 135, 540, 135, 135, 540, 540, 540, 135, 135, 17280, 540, 540, 135, 17280, 17280, 540, 17280, 17280, 540, 17280, 135, 17280, 540, 540, 540, 17280, 17280, 135, 135, 540, 135, 17280, 135, 135, 17280, 135, 540, 540, 135, 540, 17280, 17280, 17280, 540, 17280, 17280, 135, 135, 17280, 540, 17280, 135, 540, 17280, 135, 17280, 540, 135, 17280, 135, 135, 17280, 135, 135, 540]
Prompts retrieved: 574560 . Total input tokens: 128078117 . Total output tokens: 114993343
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 131.54759991681203,
    "estimated_duration": 3600.05935292096,
    "input_throughput": 7693.533435088368,
    "output_throughput": 6790.015831313069,
    "total_throughput": 14483.549266401436,
    "itl": 98.02728768611671,
    "ttft": 1324305.9654624385,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 137,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.40963689040159856,
    "arrivals": 191076,
    "finished_requests": 111279,
    "scheduler_time": 243.25133952918463
}
#Debug simulation 
Total elapsed time: 131.5477319099009. Arrivals time: 0.43466862849891186 Scheduler time: 130.8739900663495 Scheduler overhead time: 0.09256085800006986 Adapter cache time: 0.017268960364162922 Engine time: 0.09430692251771688 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-32/adapters_96_slots_16_rate_1.6-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-32/adapters_96_slots_16_rate_1.6-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 540, 135, 17280, 540, 135, 135, 540, 17280, 135, 540, 135, 135, 540, 540, 540, 135, 135, 17280, 540, 540, 135, 17280, 17280, 540, 17280, 17280, 540, 17280, 135, 17280, 540, 540, 540, 17280, 17280, 135, 135, 540, 135, 17280, 135, 135, 17280, 135, 540, 540, 135, 540, 17280, 17280, 17280, 540, 17280, 17280, 135, 135, 17280, 540, 17280, 135, 540, 17280, 135, 17280, 540, 135, 17280, 135, 135, 17280, 135, 135, 540]
Prompts retrieved: 574560 . Total input tokens: 128078117 . Total output tokens: 114993343
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 133.71706456504762,
    "estimated_duration": 3600.0754632869393,
    "input_throughput": 7713.490254075459,
    "output_throughput": 6817.131265796441,
    "total_throughput": 14530.6215198719,
    "itl": 98.16579982521,
    "ttft": 1313512.6109264812,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 134,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4476496358960864,
    "arrivals": 191076,
    "finished_requests": 111655,
    "scheduler_time": 241.79330565075492
}
#Debug simulation 
Total elapsed time: 133.7172453980893. Arrivals time: 0.43710744800046086 Scheduler time: 133.03841131180525 Scheduler overhead time: 0.09255492826923728 Adapter cache time: 0.017276807222515345 Engine time: 0.0960749676451087 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-8/adapters_96_slots_16_rate_1.6-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-8/adapters_96_slots_16_rate_1.6-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 540, 66, 17280, 540, 66, 66, 540, 17280, 66, 540, 66, 66, 540, 540, 540, 66, 66, 17280, 540, 540, 66, 17280, 17280, 540, 17280, 17280, 540, 17280, 66, 17280, 540, 540, 540, 17280, 17280, 66, 66, 540, 66, 17280, 66, 66, 17280, 66, 540, 540, 66, 540, 17280, 17280, 17280, 540, 17280, 17280, 66, 66, 17280, 540, 17280, 66, 540, 17280, 66, 17280, 540, 66, 17280, 66, 66, 17280, 66, 66, 540]
Prompts retrieved: 572352 . Total input tokens: 127568280 . Total output tokens: 114562164
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 121.3941487185657,
    "estimated_duration": 3600.055472783692,
    "input_throughput": 7591.842738708315,
    "output_throughput": 6747.031589826682,
    "total_throughput": 14338.874328534996,
    "itl": 97.77107037755383,
    "ttft": 1332717.847534902,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 121,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3703190170158628,
    "arrivals": 190312,
    "finished_requests": 110612,
    "scheduler_time": 244.83672970037983
}
#Debug simulation 
Total elapsed time: 121.39427709579468. Arrivals time: 0.4287370527163148 Scheduler time: 120.73094720393419 Scheduler overhead time: 0.09082409460097551 Adapter cache time: 0.016481107100844383 Engine time: 0.09221567446365952 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-16/adapters_96_slots_16_rate_1.6-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-16/adapters_96_slots_16_rate_1.6-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 540, 66, 17280, 540, 66, 66, 540, 17280, 66, 540, 66, 66, 540, 540, 540, 66, 66, 17280, 540, 540, 66, 17280, 17280, 540, 17280, 17280, 540, 17280, 66, 17280, 540, 540, 540, 17280, 17280, 66, 66, 540, 66, 17280, 66, 66, 17280, 66, 540, 540, 66, 540, 17280, 17280, 17280, 540, 17280, 17280, 66, 66, 17280, 540, 17280, 66, 540, 17280, 66, 17280, 540, 66, 17280, 66, 66, 17280, 66, 66, 540]
Prompts retrieved: 572352 . Total input tokens: 127568280 . Total output tokens: 114562164
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 136.25791395409033,
    "estimated_duration": 3600.0332743601125,
    "input_throughput": 7735.073227885533,
    "output_throughput": 6871.648708412864,
    "total_throughput": 14606.721936298396,
    "itl": 99.12876214604283,
    "ttft": 1301595.252667039,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 117,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.380889128705021,
    "arrivals": 190312,
    "finished_requests": 112742,
    "scheduler_time": 238.41152135788434
}
#Debug simulation 
Total elapsed time: 136.25804983638227. Arrivals time: 0.4407646362669766 Scheduler time: 135.5763258561492 Scheduler overhead time: 0.09358277637511492 Adapter cache time: 0.01740590762346983 Engine time: 0.09523920062929392 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-32/adapters_96_slots_16_rate_1.6-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-32/adapters_96_slots_16_rate_1.6-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 540, 66, 17280, 540, 66, 66, 540, 17280, 66, 540, 66, 66, 540, 540, 540, 66, 66, 17280, 540, 540, 66, 17280, 17280, 540, 17280, 17280, 540, 17280, 66, 17280, 540, 540, 540, 17280, 17280, 66, 66, 540, 66, 17280, 66, 66, 17280, 66, 540, 540, 66, 540, 17280, 17280, 17280, 540, 17280, 17280, 66, 66, 17280, 540, 17280, 66, 540, 17280, 66, 17280, 540, 66, 17280, 66, 66, 17280, 66, 66, 540]
Prompts retrieved: 572352 . Total input tokens: 127568280 . Total output tokens: 114562164
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 136.4046463239938,
    "estimated_duration": 3600.0339073510463,
    "input_throughput": 7735.071867834114,
    "output_throughput": 6871.647500176651,
    "total_throughput": 14606.719368010765,
    "itl": 99.12877250506415,
    "ttft": 1301595.5070453493,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 117,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.38172251489013515,
    "arrivals": 190312,
    "finished_requests": 112742,
    "scheduler_time": 238.41152267309056
}
#Debug simulation 
Total elapsed time: 136.4048318299465. Arrivals time: 0.43648400669917464 Scheduler time: 135.7291848133318 Scheduler overhead time: 0.09199263993650675 Adapter cache time: 0.01745143113657832 Engine time: 0.09419615287333727 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-16/adapters_96_slots_16_rate_1.6-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-16/adapters_96_slots_16_rate_1.6-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 540, 66, 17280, 540, 66, 66, 540, 17280, 66, 540, 66, 66, 540, 540, 540, 66, 66, 17280, 540, 540, 66, 17280, 17280, 540, 17280, 17280, 540, 17280, 66, 17280, 540, 540, 540, 17280, 17280, 66, 66, 540, 66, 17280, 66, 66, 17280, 66, 540, 540, 66, 540, 17280, 17280, 17280, 540, 17280, 17280, 66, 66, 17280, 540, 17280, 66, 540, 17280, 66, 17280, 540, 66, 17280, 66, 66, 17280, 66, 66, 540]
Prompts retrieved: 572352 . Total input tokens: 127568280 . Total output tokens: 114562164
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 132.79745373129845,
    "estimated_duration": 3600.061364263779,
    "input_throughput": 7591.830314700556,
    "output_throughput": 6747.020548347597,
    "total_throughput": 14338.850863048154,
    "itl": 97.7711396812176,
    "ttft": 1332719.9506806566,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 121,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3760969218285756,
    "arrivals": 190312,
    "finished_requests": 110612,
    "scheduler_time": 244.83674323705918
}
#Debug simulation 
Total elapsed time: 132.79761503543705. Arrivals time: 0.5615425924770534 Scheduler time: 131.97848468646407 Scheduler overhead time: 0.1000374243594706 Adapter cache time: 0.018857250455766916 Engine time: 0.10228025913238525 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-32/adapters_96_slots_16_rate_1.6-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-32/adapters_96_slots_16_rate_1.6-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 540, 66, 17280, 540, 66, 66, 540, 17280, 66, 540, 66, 66, 540, 540, 540, 66, 66, 17280, 540, 540, 66, 17280, 17280, 540, 17280, 17280, 540, 17280, 66, 17280, 540, 540, 540, 17280, 17280, 66, 66, 540, 66, 17280, 66, 66, 17280, 66, 540, 540, 66, 540, 17280, 17280, 17280, 540, 17280, 17280, 66, 66, 17280, 540, 17280, 66, 540, 17280, 66, 17280, 540, 66, 17280, 66, 66, 17280, 66, 66, 540]
Prompts retrieved: 572352 . Total input tokens: 127568280 . Total output tokens: 114562164
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 136.25065228994936,
    "estimated_duration": 3600.0400556423706,
    "input_throughput": 7735.058657571305,
    "output_throughput": 6871.635764504254,
    "total_throughput": 14606.69442207556,
    "itl": 99.12882487491933,
    "ttft": 1301597.9067678305,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 117,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.38687842013314383,
    "arrivals": 190312,
    "finished_requests": 112742,
    "scheduler_time": 238.4117147505434
}
#Debug simulation 
Total elapsed time: 136.25081042060629. Arrivals time: 0.47649248177185655 Scheduler time: 135.53085085051134 Scheduler overhead time: 0.0947062149643898 Adapter cache time: 0.017394480295479298 Engine time: 0.09665973577648401 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-16/adapters_96_slots_16_rate_1.6-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-16/adapters_96_slots_16_rate_1.6-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 540, 66, 17280, 540, 66, 66, 540, 17280, 66, 540, 66, 66, 540, 540, 540, 66, 66, 17280, 540, 540, 66, 17280, 17280, 540, 17280, 17280, 540, 17280, 66, 17280, 540, 540, 540, 17280, 17280, 66, 66, 540, 66, 17280, 66, 66, 17280, 66, 540, 540, 66, 540, 17280, 17280, 17280, 540, 17280, 17280, 66, 66, 17280, 540, 17280, 66, 540, 17280, 66, 17280, 540, 66, 17280, 66, 66, 17280, 66, 66, 540]
Prompts retrieved: 572352 . Total input tokens: 127568280 . Total output tokens: 114562164
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 121.69718502508476,
    "estimated_duration": 3600.046253733012,
    "input_throughput": 7591.862180009351,
    "output_throughput": 6747.0488677230705,
    "total_throughput": 14338.911047732421,
    "itl": 97.77096413706434,
    "ttft": 1332714.1858462468,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 121,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3617960856831637,
    "arrivals": 190312,
    "finished_requests": 110612,
    "scheduler_time": 244.83640998437983
}
#Debug simulation 
Total elapsed time: 121.6973737301305. Arrivals time: 0.42173312325030565 Scheduler time: 121.03838761989027 Scheduler overhead time: 0.09236664231866598 Adapter cache time: 0.016263585072010756 Engine time: 0.09285880019888282 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-32/adapters_96_slots_16_rate_1.6-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-32/adapters_96_slots_16_rate_1.6-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 540, 66, 17280, 540, 66, 66, 540, 17280, 66, 540, 66, 66, 540, 540, 540, 66, 66, 17280, 540, 540, 66, 17280, 17280, 540, 17280, 17280, 540, 17280, 66, 17280, 540, 540, 540, 17280, 17280, 66, 66, 540, 66, 17280, 66, 66, 17280, 66, 540, 540, 66, 540, 17280, 17280, 17280, 540, 17280, 17280, 66, 66, 17280, 540, 17280, 66, 540, 17280, 66, 17280, 540, 66, 17280, 66, 66, 17280, 66, 66, 540]
Prompts retrieved: 572352 . Total input tokens: 127568280 . Total output tokens: 114562164
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 136.91890157479793,
    "estimated_duration": 3600.0445694670602,
    "input_throughput": 7735.048959163946,
    "output_throughput": 6871.627148677819,
    "total_throughput": 14606.676107841764,
    "itl": 99.12881101123854,
    "ttft": 1301599.8697003894,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 117,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.39127980265766354,
    "arrivals": 190312,
    "finished_requests": 112742,
    "scheduler_time": 238.41182719271126
}
#Debug simulation 
Total elapsed time: 136.9190518418327. Arrivals time: 0.4529381301254034 Scheduler time: 136.22469903714955 Scheduler overhead time: 0.093329849652946 Adapter cache time: 0.017397115007042885 Engine time: 0.09484971966594458 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-8/adapters_96_slots_16_rate_1.6-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-8/adapters_96_slots_16_rate_1.6-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 540, 33, 17280, 540, 33, 33, 540, 17280, 33, 540, 33, 33, 540, 540, 540, 33, 33, 17280, 540, 540, 33, 17280, 17280, 540, 17280, 17280, 540, 17280, 33, 17280, 540, 540, 540, 17280, 17280, 33, 33, 540, 33, 17280, 33, 33, 17280, 33, 540, 540, 33, 540, 17280, 17280, 17280, 540, 17280, 17280, 33, 33, 17280, 540, 17280, 33, 540, 17280, 33, 17280, 540, 33, 17280, 33, 33, 17280, 33, 33, 540]
Prompts retrieved: 571296 . Total input tokens: 127344419 . Total output tokens: 114344834
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 125.02520930068567,
    "estimated_duration": 3600.0678286492603,
    "input_throughput": 7596.636869550616,
    "output_throughput": 6763.012853881442,
    "total_throughput": 14359.649723432058,
    "itl": 97.95874550863823,
    "ttft": 1324299.8089462116,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 117,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3580770660401318,
    "arrivals": 189952,
    "finished_requests": 110841,
    "scheduler_time": 244.5040625561542
}
#Debug simulation 
Total elapsed time: 125.02533738873899. Arrivals time: 0.4309181086719036 Scheduler time: 124.3543197195977 Scheduler overhead time: 0.09297065902501345 Adapter cache time: 0.017231648322194815 Engine time: 0.09492387110367417 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-16/adapters_96_slots_16_rate_1.6-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-16/adapters_96_slots_16_rate_1.6-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 540, 33, 17280, 540, 33, 33, 540, 17280, 33, 540, 33, 33, 540, 540, 540, 33, 33, 17280, 540, 540, 33, 17280, 17280, 540, 17280, 17280, 540, 17280, 33, 17280, 540, 540, 540, 17280, 17280, 33, 33, 540, 33, 17280, 33, 33, 17280, 33, 540, 540, 33, 540, 17280, 17280, 17280, 540, 17280, 17280, 33, 33, 17280, 540, 17280, 33, 540, 17280, 33, 17280, 540, 33, 17280, 33, 33, 17280, 33, 33, 540]
Prompts retrieved: 571296 . Total input tokens: 127344419 . Total output tokens: 114344834
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 144.3399138180539,
    "estimated_duration": 3600.002864768119,
    "input_throughput": 7566.429256648526,
    "output_throughput": 6752.255182320729,
    "total_throughput": 14318.684438969254,
    "itl": 97.75147030909721,
    "ttft": 1279571.6554845632,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 114,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.37191897782031447,
    "arrivals": 189952,
    "finished_requests": 110399,
    "scheduler_time": 246.51529273849533
}
#Debug simulation 
Total elapsed time: 144.34009752096608. Arrivals time: 0.4467253810726106 Scheduler time: 143.64282846823335 Scheduler overhead time: 0.09665667917579412 Adapter cache time: 0.017928034998476505 Engine time: 0.09957825252786279 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-32/adapters_96_slots_16_rate_1.6-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-32/adapters_96_slots_16_rate_1.6-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 540, 33, 17280, 540, 33, 33, 540, 17280, 33, 540, 33, 33, 540, 540, 540, 33, 33, 17280, 540, 540, 33, 17280, 17280, 540, 17280, 17280, 540, 17280, 33, 17280, 540, 540, 540, 17280, 17280, 33, 33, 540, 33, 17280, 33, 33, 17280, 33, 540, 540, 33, 540, 17280, 17280, 17280, 540, 17280, 17280, 33, 33, 17280, 540, 17280, 33, 540, 17280, 33, 17280, 540, 33, 17280, 33, 33, 17280, 33, 33, 540]
Prompts retrieved: 571296 . Total input tokens: 127344419 . Total output tokens: 114344834
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 151.80432718992233,
    "estimated_duration": 3600.003659143944,
    "input_throughput": 7566.427587042311,
    "output_throughput": 6752.253692369943,
    "total_throughput": 14318.681279412252,
    "itl": 97.75147150665738,
    "ttft": 1279572.0350605494,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 114,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.37259195834398345,
    "arrivals": 189952,
    "finished_requests": 110399,
    "scheduler_time": 246.51531409520578
}
#Debug simulation 
Total elapsed time: 151.80446243518963. Arrivals time: 0.556993612088263 Scheduler time: 150.9729895191267 Scheduler overhead time: 0.1078933859243989 Adapter cache time: 0.019634940661489964 Engine time: 0.10940262954682112 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-16/adapters_96_slots_16_rate_1.6-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-16/adapters_96_slots_16_rate_1.6-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 540, 33, 17280, 540, 33, 33, 540, 17280, 33, 540, 33, 33, 540, 540, 540, 33, 33, 17280, 540, 540, 33, 17280, 17280, 540, 17280, 17280, 540, 17280, 33, 17280, 540, 540, 540, 17280, 17280, 33, 33, 540, 33, 17280, 33, 33, 17280, 33, 540, 540, 33, 540, 17280, 17280, 17280, 540, 17280, 17280, 33, 33, 17280, 540, 17280, 33, 540, 17280, 33, 17280, 540, 33, 17280, 33, 33, 17280, 33, 33, 540]
Prompts retrieved: 571296 . Total input tokens: 127344419 . Total output tokens: 114344834
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 145.14718643715605,
    "estimated_duration": 3600.10098529583,
    "input_throughput": 7556.405809478866,
    "output_throughput": 6714.055827523899,
    "total_throughput": 14270.461637002765,
    "itl": 97.20980394489361,
    "ttft": 1308492.3357654524,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 119,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.37338558378629405,
    "arrivals": 189952,
    "finished_requests": 110106,
    "scheduler_time": 247.31617487505542
}
#Debug simulation 
Total elapsed time: 145.1473231362179. Arrivals time: 0.4926291583105922 Scheduler time: 144.40093188453466 Scheduler overhead time: 0.09808466350659728 Adapter cache time: 0.01859252853319049 Engine time: 0.10050602350383997 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-32/adapters_96_slots_16_rate_1.6-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-32/adapters_96_slots_16_rate_1.6-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 540, 33, 17280, 540, 33, 33, 540, 17280, 33, 540, 33, 33, 540, 540, 540, 33, 33, 17280, 540, 540, 33, 17280, 17280, 540, 17280, 17280, 540, 17280, 33, 17280, 540, 540, 540, 17280, 17280, 33, 33, 540, 33, 17280, 33, 33, 17280, 33, 540, 540, 33, 540, 17280, 17280, 17280, 540, 17280, 17280, 33, 33, 17280, 540, 17280, 33, 540, 17280, 33, 17280, 540, 33, 17280, 33, 33, 17280, 33, 33, 540]
Prompts retrieved: 571296 . Total input tokens: 127344419 . Total output tokens: 114344834
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 144.72907383786514,
    "estimated_duration": 3600.008578808371,
    "input_throughput": 7566.417246987884,
    "output_throughput": 6752.244464941295,
    "total_throughput": 14318.661711929179,
    "itl": 97.75154669986463,
    "ttft": 1279573.9768041496,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 114,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.377119094654918,
    "arrivals": 189952,
    "finished_requests": 110399,
    "scheduler_time": 246.51550654616855
}
#Debug simulation 
Total elapsed time: 144.72925781086087. Arrivals time: 0.4430233109742403 Scheduler time: 144.03501703450456 Scheduler overhead time: 0.09786378359422088 Adapter cache time: 0.01849994994699955 Engine time: 0.09884652821347117 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-16/adapters_96_slots_16_rate_1.6-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-16/adapters_96_slots_16_rate_1.6-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 540, 33, 17280, 540, 33, 33, 540, 17280, 33, 540, 33, 33, 540, 540, 540, 33, 33, 17280, 540, 540, 33, 17280, 17280, 540, 17280, 17280, 540, 17280, 33, 17280, 540, 540, 540, 17280, 17280, 33, 33, 540, 33, 17280, 33, 33, 17280, 33, 540, 540, 33, 540, 17280, 17280, 17280, 540, 17280, 17280, 33, 33, 17280, 540, 17280, 33, 540, 17280, 33, 17280, 540, 33, 17280, 33, 33, 17280, 33, 33, 540]
Prompts retrieved: 571296 . Total input tokens: 127344419 . Total output tokens: 114344834
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 124.78781065810472,
    "estimated_duration": 3600.0605223441244,
    "input_throughput": 7596.6522868878055,
    "output_throughput": 6763.026579382789,
    "total_throughput": 14359.678866270595,
    "itl": 97.9586915212704,
    "ttft": 1324297.2002477702,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 117,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.34983588450355496,
    "arrivals": 189952,
    "finished_requests": 110841,
    "scheduler_time": 244.50389700815438
}
#Debug simulation 
Total elapsed time: 124.78793533332646. Arrivals time: 0.4202897506766021 Scheduler time: 124.13016544329002 Scheduler overhead time: 0.09140213066712022 Adapter cache time: 0.01689582923427224 Engine time: 0.09430186916142702 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-32/adapters_96_slots_16_rate_1.6-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-32/adapters_96_slots_16_rate_1.6-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 540, 33, 17280, 540, 33, 33, 540, 17280, 33, 540, 33, 33, 540, 540, 540, 33, 33, 17280, 540, 540, 33, 17280, 17280, 540, 17280, 17280, 540, 17280, 33, 17280, 540, 540, 540, 17280, 17280, 33, 33, 540, 33, 17280, 33, 33, 17280, 33, 540, 540, 33, 540, 17280, 17280, 17280, 540, 17280, 17280, 33, 33, 17280, 540, 17280, 33, 540, 17280, 33, 17280, 540, 33, 17280, 33, 33, 17280, 33, 33, 540]
Prompts retrieved: 571296 . Total input tokens: 127344419 . Total output tokens: 114344834
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 144.68812738684937,
    "estimated_duration": 3600.006247422381,
    "input_throughput": 7557.983272801707,
    "output_throughput": 6716.429455452306,
    "total_throughput": 14274.412728254012,
    "itl": 97.22162857027493,
    "ttft": 1307960.6430804974,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 119,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.39921884547919,
    "arrivals": 189952,
    "finished_requests": 110186,
    "scheduler_time": 247.20182716015208
}
#Debug simulation 
Total elapsed time: 144.68825817201287. Arrivals time: 0.44233612064272165 Scheduler time: 143.99532710202038 Scheduler overhead time: 0.09645998338237405 Adapter cache time: 0.018191122449934483 Engine time: 0.09957109577953815 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-8/adapters_96_slots_16_rate_1.6-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-8/adapters_96_slots_16_rate_1.6-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 135, 17280, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 270, 135, 17280, 270, 135, 135, 270, 17280, 135, 270, 135, 135, 270, 270, 270, 135, 135, 17280, 270, 270, 135, 17280, 17280, 270, 17280, 17280, 270, 17280, 135, 17280, 270, 270, 270, 17280, 17280, 135, 135, 270, 135, 17280, 135, 135, 17280, 135, 270, 270, 135, 270, 17280, 17280, 17280, 270, 17280, 17280, 135, 135, 17280, 270, 17280, 135, 270, 17280, 135, 17280, 270, 135, 17280, 135, 135, 17280, 135, 135, 270]
Prompts retrieved: 565920 . Total input tokens: 126139240 . Total output tokens: 113278943
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 143.7842060700059,
    "estimated_duration": 3600.11678608065,
    "input_throughput": 7699.802158412261,
    "output_throughput": 6772.57223828677,
    "total_throughput": 14472.374396699031,
    "itl": 97.46992593620752,
    "ttft": 1298137.2296981667,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 117,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3580770660401318,
    "arrivals": 188134,
    "finished_requests": 111526,
    "scheduler_time": 242.86885071689966
}
#Debug simulation 
Total elapsed time: 143.78439002111554. Arrivals time: 0.4429723075591028 Scheduler time: 143.09395262040198 Scheduler overhead time: 0.09557699412107468 Adapter cache time: 0.017336620017886162 Engine time: 0.0983237293548882 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-16/adapters_96_slots_16_rate_1.6-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-16/adapters_96_slots_16_rate_1.6-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 135, 17280, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 270, 135, 17280, 270, 135, 135, 270, 17280, 135, 270, 135, 135, 270, 270, 270, 135, 135, 17280, 270, 270, 135, 17280, 17280, 270, 17280, 17280, 270, 17280, 135, 17280, 270, 270, 270, 17280, 17280, 135, 135, 270, 135, 17280, 135, 135, 17280, 135, 270, 270, 135, 270, 17280, 17280, 17280, 270, 17280, 17280, 135, 135, 17280, 270, 17280, 135, 270, 17280, 135, 17280, 270, 135, 17280, 135, 135, 17280, 135, 135, 270]
Prompts retrieved: 565920 . Total input tokens: 126139240 . Total output tokens: 113278943
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 144.07519953977317,
    "estimated_duration": 3600.023251738674,
    "input_throughput": 7699.55054779521,
    "output_throughput": 6772.387647281174,
    "total_throughput": 14471.938195076384,
    "itl": 97.46970692901455,
    "ttft": 1298114.1459518278,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 117,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.38170631934190163,
    "arrivals": 188134,
    "finished_requests": 111521,
    "scheduler_time": 242.86150690867058
}
#Debug simulation 
Total elapsed time: 144.07532485108823. Arrivals time: 0.44113021111115813 Scheduler time: 143.38905030861497 Scheduler overhead time: 0.09480666043236852 Adapter cache time: 0.017393107060343027 Engine time: 0.09679865790531039 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-32/adapters_96_slots_16_rate_1.6-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-32/adapters_96_slots_16_rate_1.6-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 135, 17280, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 270, 135, 17280, 270, 135, 135, 270, 17280, 135, 270, 135, 135, 270, 270, 270, 135, 135, 17280, 270, 270, 135, 17280, 17280, 270, 17280, 17280, 270, 17280, 135, 17280, 270, 270, 270, 17280, 17280, 135, 135, 270, 135, 17280, 135, 135, 17280, 135, 270, 270, 135, 270, 17280, 17280, 17280, 270, 17280, 17280, 135, 135, 17280, 270, 17280, 135, 270, 17280, 135, 17280, 270, 135, 17280, 135, 135, 17280, 135, 135, 270]
Prompts retrieved: 565920 . Total input tokens: 126139240 . Total output tokens: 113278943
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 143.79364985926077,
    "estimated_duration": 3600.0239747380924,
    "input_throughput": 7699.54900148035,
    "output_throughput": 6772.38628717014,
    "total_throughput": 14471.93528865049,
    "itl": 97.46971301573598,
    "ttft": 1298114.456357729,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 117,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3823970098793515,
    "arrivals": 188134,
    "finished_requests": 111521,
    "scheduler_time": 242.8615392175403
}
#Debug simulation 
Total elapsed time: 143.79377805488184. Arrivals time: 0.4378449465148151 Scheduler time: 143.10863752663136 Scheduler overhead time: 0.09670274658128619 Adapter cache time: 0.017516239546239376 Engine time: 0.09723218064755201 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-16/adapters_96_slots_16_rate_1.6-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-16/adapters_96_slots_16_rate_1.6-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 135, 17280, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 270, 135, 17280, 270, 135, 135, 270, 17280, 135, 270, 135, 135, 270, 270, 270, 135, 135, 17280, 270, 270, 135, 17280, 17280, 270, 17280, 17280, 270, 17280, 135, 17280, 270, 270, 270, 17280, 17280, 135, 135, 270, 135, 17280, 135, 135, 17280, 135, 270, 270, 135, 270, 17280, 17280, 17280, 270, 17280, 17280, 135, 135, 17280, 270, 17280, 135, 270, 17280, 135, 17280, 270, 135, 17280, 135, 135, 17280, 135, 135, 270]
Prompts retrieved: 565920 . Total input tokens: 126139240 . Total output tokens: 113278943
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 144.1641847603023,
    "estimated_duration": 3600.0048528516236,
    "input_throughput": 7699.589898620183,
    "output_throughput": 6772.422259566567,
    "total_throughput": 14472.01215818675,
    "itl": 97.46955316441033,
    "ttft": 1298106.9013967847,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 117,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3649539112858476,
    "arrivals": 188134,
    "finished_requests": 111521,
    "scheduler_time": 242.86066073830636
}
#Debug simulation 
Total elapsed time: 144.1643756981939. Arrivals time: 0.44440061738714576 Scheduler time: 143.47127549396828 Scheduler overhead time: 0.09645142639055848 Adapter cache time: 0.01772206276655197 Engine time: 0.09813867742195725 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-32/adapters_96_slots_16_rate_1.6-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-32/adapters_96_slots_16_rate_1.6-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 135, 17280, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 270, 135, 17280, 270, 135, 135, 270, 17280, 135, 270, 135, 135, 270, 270, 270, 135, 135, 17280, 270, 270, 135, 17280, 17280, 270, 17280, 17280, 270, 17280, 135, 17280, 270, 270, 270, 17280, 17280, 135, 135, 270, 135, 17280, 135, 135, 17280, 135, 270, 270, 135, 270, 17280, 17280, 17280, 270, 17280, 17280, 135, 135, 17280, 270, 17280, 135, 270, 17280, 135, 17280, 270, 135, 17280, 135, 135, 17280, 135, 135, 270]
Prompts retrieved: 565920 . Total input tokens: 126139240 . Total output tokens: 113278943
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 143.49799749115482,
    "estimated_duration": 3600.0295644910507,
    "input_throughput": 7699.537046418304,
    "output_throughput": 6772.375771710307,
    "total_throughput": 14471.912818128612,
    "itl": 97.46975290727978,
    "ttft": 1298116.6152138354,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 117,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.38755291512236023,
    "arrivals": 188134,
    "finished_requests": 111521,
    "scheduler_time": 242.8617729881068
}
#Debug simulation 
Total elapsed time: 143.49812183203176. Arrivals time: 0.44704029941931367 Scheduler time: 142.8003602689132 Scheduler overhead time: 0.0968731353059411 Adapter cache time: 0.017999985720962286 Engine time: 0.09927377291023731 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-16/adapters_96_slots_16_rate_1.6-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-16/adapters_96_slots_16_rate_1.6-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 135, 17280, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 270, 135, 17280, 270, 135, 135, 270, 17280, 135, 270, 135, 135, 270, 270, 270, 135, 135, 17280, 270, 270, 135, 17280, 17280, 270, 17280, 17280, 270, 17280, 135, 17280, 270, 270, 270, 17280, 17280, 135, 135, 270, 135, 17280, 135, 135, 17280, 135, 270, 270, 135, 270, 17280, 17280, 17280, 270, 17280, 17280, 135, 135, 17280, 270, 17280, 135, 270, 17280, 135, 17280, 270, 135, 17280, 135, 135, 17280, 135, 135, 270]
Prompts retrieved: 565920 . Total input tokens: 126139240 . Total output tokens: 113278943
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 143.85606407094747,
    "estimated_duration": 3600.1091481475214,
    "input_throughput": 7699.81849418753,
    "output_throughput": 6772.586606866093,
    "total_throughput": 14472.405101053622,
    "itl": 97.46986387513643,
    "ttft": 1298134.5228873952,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 117,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.34983588450355496,
    "arrivals": 188134,
    "finished_requests": 111526,
    "scheduler_time": 242.8686536566448
}
#Debug simulation 
Total elapsed time: 143.85619675228372. Arrivals time: 0.441172210033983 Scheduler time: 143.16819153307006 Scheduler overhead time: 0.09626469435170293 Adapter cache time: 0.01736923772841692 Engine time: 0.09725535614416003 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-32/adapters_96_slots_16_rate_1.6-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-32/adapters_96_slots_16_rate_1.6-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 135, 17280, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 270, 135, 17280, 270, 135, 135, 270, 17280, 135, 270, 135, 135, 270, 270, 270, 135, 135, 17280, 270, 270, 135, 17280, 17280, 270, 17280, 17280, 270, 17280, 135, 17280, 270, 270, 270, 17280, 17280, 135, 135, 270, 135, 17280, 135, 135, 17280, 135, 270, 270, 135, 270, 17280, 17280, 17280, 270, 17280, 17280, 135, 135, 17280, 270, 17280, 135, 270, 17280, 135, 17280, 270, 135, 17280, 135, 135, 17280, 135, 135, 270]
Prompts retrieved: 565920 . Total input tokens: 126139240 . Total output tokens: 113278943
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 144.45856340415776,
    "estimated_duration": 3600.0344085341917,
    "input_throughput": 7699.52668627021,
    "output_throughput": 6772.366659108403,
    "total_throughput": 14471.893345378612,
    "itl": 97.46980049880003,
    "ttft": 1298118.5070726203,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 117,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.39220580521970955,
    "arrivals": 188134,
    "finished_requests": 111521,
    "scheduler_time": 242.86186410258063
}
#Debug simulation 
Total elapsed time: 144.45874453196302. Arrivals time: 0.43822539784014225 Scheduler time: 143.77186221024022 Scheduler overhead time: 0.09703476820141077 Adapter cache time: 0.017900030128657818 Engine time: 0.09770087664946914 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-8/adapters_96_slots_16_rate_1.6-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-8/adapters_96_slots_16_rate_1.6-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 66, 17280, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 270, 66, 17280, 270, 66, 66, 270, 17280, 66, 270, 66, 66, 270, 270, 270, 66, 66, 17280, 270, 270, 66, 17280, 17280, 270, 17280, 17280, 270, 17280, 66, 17280, 270, 270, 270, 17280, 17280, 66, 66, 270, 66, 17280, 66, 66, 17280, 66, 270, 270, 66, 270, 17280, 17280, 17280, 270, 17280, 17280, 66, 66, 17280, 270, 17280, 66, 270, 17280, 66, 17280, 270, 66, 17280, 66, 66, 17280, 66, 66, 270]
Prompts retrieved: 563712 . Total input tokens: 125628176 . Total output tokens: 112839488
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 119.40050167264417,
    "estimated_duration": 3600.0140921133675,
    "input_throughput": 7709.880097637671,
    "output_throughput": 6834.6663014187925,
    "total_throughput": 14544.546399056462,
    "itl": 98.95861298753796,
    "ttft": 1308044.2533439628,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 120,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.36725852927193003,
    "arrivals": 187468,
    "finished_requests": 112140,
    "scheduler_time": 239.28132631860083
}
#Debug simulation 
Total elapsed time: 119.40063616679981. Arrivals time: 0.4195028468966484 Scheduler time: 118.74715648405254 Scheduler overhead time: 0.09062865283340216 Adapter cache time: 0.016113908495754004 Engine time: 0.0922951977699995 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-16/adapters_96_slots_16_rate_1.6-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-16/adapters_96_slots_16_rate_1.6-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 66, 17280, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 270, 66, 17280, 270, 66, 66, 270, 17280, 66, 270, 66, 66, 270, 270, 270, 66, 66, 17280, 270, 270, 66, 17280, 17280, 270, 17280, 17280, 270, 17280, 66, 17280, 270, 270, 270, 17280, 17280, 66, 66, 270, 66, 17280, 66, 66, 17280, 66, 270, 270, 66, 270, 17280, 17280, 17280, 270, 17280, 17280, 66, 66, 17280, 270, 17280, 66, 270, 17280, 66, 17280, 270, 66, 17280, 66, 66, 17280, 66, 66, 270]
Prompts retrieved: 563712 . Total input tokens: 125628176 . Total output tokens: 112839488
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 136.754036817234,
    "estimated_duration": 3600.073175608661,
    "input_throughput": 7669.779099790577,
    "output_throughput": 6799.908725705599,
    "total_throughput": 14469.687825496176,
    "itl": 98.37693143234468,
    "ttft": 1284576.2020468474,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 127,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4111982269724831,
    "arrivals": 187468,
    "finished_requests": 111511,
    "scheduler_time": 241.5051739421545
}
#Debug simulation 
Total elapsed time: 136.75416526012123. Arrivals time: 0.42909345822408795 Scheduler time: 136.0837486810051 Scheduler overhead time: 0.09353112196549773 Adapter cache time: 0.01756738405674696 Engine time: 0.09511832054704428 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-32/adapters_96_slots_16_rate_1.6-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-32/adapters_96_slots_16_rate_1.6-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 66, 17280, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 270, 66, 17280, 270, 66, 66, 270, 17280, 66, 270, 66, 66, 270, 270, 270, 66, 66, 17280, 270, 270, 66, 17280, 17280, 270, 17280, 17280, 270, 17280, 66, 17280, 270, 270, 270, 17280, 17280, 66, 66, 270, 66, 17280, 66, 66, 17280, 66, 270, 270, 66, 270, 17280, 17280, 17280, 270, 17280, 17280, 66, 66, 17280, 270, 17280, 66, 270, 17280, 66, 17280, 270, 66, 17280, 66, 66, 17280, 66, 66, 270]
Prompts retrieved: 563712 . Total input tokens: 125628176 . Total output tokens: 112839488
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 136.90555909881368,
    "estimated_duration": 3600.0746319068985,
    "input_throughput": 7669.7759972199565,
    "output_throughput": 6799.905975013988,
    "total_throughput": 14469.681972233944,
    "itl": 98.37696278683273,
    "ttft": 1284576.6523959723,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 127,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4124949508719156,
    "arrivals": 187468,
    "finished_requests": 111511,
    "scheduler_time": 241.50523347790255
}
#Debug simulation 
Total elapsed time: 136.9057409237139. Arrivals time: 0.43488498870283365 Scheduler time: 136.2257348727435 Scheduler overhead time: 0.09486547438427806 Adapter cache time: 0.017521830275654793 Engine time: 0.0970609299838543 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-16/adapters_96_slots_16_rate_1.6-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-16/adapters_96_slots_16_rate_1.6-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 66, 17280, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 270, 66, 17280, 270, 66, 66, 270, 17280, 66, 270, 66, 66, 270, 270, 270, 66, 66, 17280, 270, 270, 66, 17280, 17280, 270, 17280, 17280, 270, 17280, 66, 17280, 270, 270, 270, 17280, 17280, 66, 66, 270, 66, 17280, 66, 66, 17280, 66, 270, 270, 66, 270, 17280, 17280, 17280, 270, 17280, 17280, 66, 66, 17280, 270, 17280, 66, 270, 17280, 66, 17280, 270, 66, 17280, 66, 66, 17280, 66, 66, 270]
Prompts retrieved: 563712 . Total input tokens: 125628176 . Total output tokens: 112839488
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 119.5514290719293,
    "estimated_duration": 3600.02027837287,
    "input_throughput": 7709.866849012571,
    "output_throughput": 6834.65455675735,
    "total_throughput": 14544.521405769921,
    "itl": 98.95869731505967,
    "ttft": 1308046.2572575016,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 120,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3743326574889945,
    "arrivals": 187468,
    "finished_requests": 112140,
    "scheduler_time": 239.28143883567722
}
#Debug simulation 
Total elapsed time: 119.5515631227754. Arrivals time: 0.41859764652326703 Scheduler time: 118.89823534945026 Scheduler overhead time: 0.09102508658543229 Adapter cache time: 0.01671888818964362 Engine time: 0.09157054917886853 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-32/adapters_96_slots_16_rate_1.6-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-32/adapters_96_slots_16_rate_1.6-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 66, 17280, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 270, 66, 17280, 270, 66, 66, 270, 17280, 66, 270, 66, 66, 270, 270, 270, 66, 66, 17280, 270, 270, 66, 17280, 17280, 270, 17280, 17280, 270, 17280, 66, 17280, 270, 270, 270, 17280, 17280, 66, 66, 270, 66, 17280, 66, 66, 17280, 66, 270, 270, 66, 270, 17280, 17280, 17280, 270, 17280, 17280, 66, 66, 17280, 270, 17280, 66, 270, 17280, 66, 17280, 270, 66, 17280, 66, 66, 17280, 66, 66, 270]
Prompts retrieved: 563712 . Total input tokens: 125628176 . Total output tokens: 112839488
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 137.29885520925745,
    "estimated_duration": 3600.079249106564,
    "input_throughput": 7669.766160523395,
    "output_throughput": 6799.897253949416,
    "total_throughput": 14469.66341447281,
    "itl": 98.37702068611411,
    "ttft": 1284578.512711519,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 127,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.417147840969265,
    "arrivals": 187468,
    "finished_requests": 111511,
    "scheduler_time": 241.50529782605693
}
#Debug simulation 
Total elapsed time: 137.29898884193972. Arrivals time: 0.44648447167128325 Scheduler time: 136.607390133664 Scheduler overhead time: 0.09554446907714009 Adapter cache time: 0.017459070775657892 Engine time: 0.09611385222524405 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-16/adapters_96_slots_16_rate_1.6-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-16/adapters_96_slots_16_rate_1.6-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 66, 17280, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 270, 66, 17280, 270, 66, 66, 270, 17280, 66, 270, 66, 66, 270, 270, 270, 66, 66, 17280, 270, 270, 66, 17280, 17280, 270, 17280, 17280, 270, 17280, 66, 17280, 270, 270, 270, 17280, 17280, 66, 66, 270, 66, 17280, 66, 66, 17280, 66, 270, 270, 66, 270, 17280, 17280, 17280, 270, 17280, 17280, 66, 66, 17280, 270, 17280, 66, 270, 17280, 66, 17280, 270, 66, 17280, 66, 66, 17280, 66, 66, 270]
Prompts retrieved: 563712 . Total input tokens: 125628176 . Total output tokens: 112839488
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 119.3848535772413,
    "estimated_duration": 3600.004043609411,
    "input_throughput": 7709.901617824795,
    "output_throughput": 6834.685378667189,
    "total_throughput": 14544.586996491984,
    "itl": 98.95838284379953,
    "ttft": 1308040.1049745905,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 120,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3588060353882615,
    "arrivals": 187468,
    "finished_requests": 112140,
    "scheduler_time": 239.28092505490676
}
#Debug simulation 
Total elapsed time: 119.38503205636516. Arrivals time: 0.4161094226874411 Scheduler time: 118.73773158434778 Scheduler overhead time: 0.08949398761615157 Adapter cache time: 0.016537406016141176 Engine time: 0.09046311676502228 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-32/adapters_96_slots_16_rate_1.6-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-32/adapters_96_slots_16_rate_1.6-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 66, 17280, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 270, 66, 17280, 270, 66, 66, 270, 17280, 66, 270, 66, 66, 270, 270, 270, 66, 66, 17280, 270, 270, 66, 17280, 17280, 270, 17280, 17280, 270, 17280, 66, 17280, 270, 270, 270, 17280, 17280, 66, 66, 270, 66, 17280, 66, 66, 17280, 66, 270, 270, 66, 270, 17280, 17280, 17280, 270, 17280, 17280, 66, 66, 17280, 270, 17280, 66, 270, 17280, 66, 17280, 270, 66, 17280, 66, 66, 17280, 66, 66, 270]
Prompts retrieved: 563712 . Total input tokens: 125628176 . Total output tokens: 112839488
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 136.71448940597475,
    "estimated_duration": 3600.0842323163206,
    "input_throughput": 7669.755544090252,
    "output_throughput": 6799.887841582328,
    "total_throughput": 14469.643385672582,
    "itl": 98.37706447722677,
    "ttft": 1284580.2776750713,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 127,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4221779924258588,
    "arrivals": 187468,
    "finished_requests": 111511,
    "scheduler_time": 241.50545096152644
}
#Debug simulation 
Total elapsed time: 136.71461202017963. Arrivals time: 0.43408019840717316 Scheduler time: 136.0373308993876 Scheduler overhead time: 0.09370547160506248 Adapter cache time: 0.01758725894615054 Engine time: 0.09604427265003324 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-8/adapters_96_slots_16_rate_1.6-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-8/adapters_96_slots_16_rate_1.6-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 33, 17280, 33, 33, 17280, 270, 17280, 270, 17280, 17280, 270, 33, 17280, 270, 33, 33, 270, 17280, 33, 270, 33, 33, 270, 270, 270, 33, 33, 17280, 270, 270, 33, 17280, 17280, 270, 17280, 17280, 270, 17280, 33, 17280, 270, 270, 270, 17280, 17280, 33, 33, 270, 33, 17280, 33, 33, 17280, 33, 270, 270, 33, 270, 17280, 17280, 17280, 270, 17280, 17280, 33, 33, 17280, 270, 17280, 33, 270, 17280, 33, 17280, 270, 33, 17280, 33, 33, 17280, 33, 33, 270]
Prompts retrieved: 562656 . Total input tokens: 125378570 . Total output tokens: 112631294
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 121.84307623328641,
    "estimated_duration": 3600.0549036387247,
    "input_throughput": 7708.304940558434,
    "output_throughput": 6857.147921563287,
    "total_throughput": 14565.452862121721,
    "itl": 99.32008244219965,
    "ttft": 1307076.4122404435,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 127,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3886819434794593,
    "arrivals": 186986,
    "finished_requests": 112148,
    "scheduler_time": 238.02206113512332
}
#Debug simulation 
Total elapsed time: 121.84320438327268. Arrivals time: 0.4195486125536263 Scheduler time: 121.1889798832126 Scheduler overhead time: 0.09096446493640542 Adapter cache time: 0.017076879274100065 Engine time: 0.09169423347339034 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-16/adapters_96_slots_16_rate_1.6-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-16/adapters_96_slots_16_rate_1.6-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 33, 17280, 33, 33, 17280, 270, 17280, 270, 17280, 17280, 270, 33, 17280, 270, 33, 33, 270, 17280, 33, 270, 33, 33, 270, 270, 270, 33, 33, 17280, 270, 270, 33, 17280, 17280, 270, 17280, 17280, 270, 17280, 33, 17280, 270, 270, 270, 17280, 17280, 33, 33, 270, 33, 17280, 33, 33, 17280, 33, 270, 270, 33, 270, 17280, 17280, 17280, 270, 17280, 17280, 33, 33, 17280, 270, 17280, 33, 270, 17280, 33, 17280, 270, 33, 17280, 33, 33, 17280, 33, 33, 270]
Prompts retrieved: 562656 . Total input tokens: 125378570 . Total output tokens: 112631294
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 121.25477024680004,
    "estimated_duration": 3600.1146947637503,
    "input_throughput": 7702.261553036342,
    "output_throughput": 6851.305330876026,
    "total_throughput": 14553.566883912368,
    "itl": 99.30235914134494,
    "ttft": 1308862.4202637272,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 124,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.40263667140621695,
    "arrivals": 186986,
    "finished_requests": 112052,
    "scheduler_time": 238.23449122786846
}
#Debug simulation 
Total elapsed time: 121.25496097374707. Arrivals time: 0.4168104543350637 Scheduler time: 120.60490510985255 Scheduler overhead time: 0.0910891923122108 Adapter cache time: 0.016535145696252584 Engine time: 0.09132007416337729 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-32/adapters_96_slots_16_rate_1.6-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-32/adapters_96_slots_16_rate_1.6-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 33, 17280, 33, 33, 17280, 270, 17280, 270, 17280, 17280, 270, 33, 17280, 270, 33, 33, 270, 17280, 33, 270, 33, 33, 270, 270, 270, 33, 33, 17280, 270, 270, 33, 17280, 17280, 270, 17280, 17280, 270, 17280, 33, 17280, 270, 270, 270, 17280, 17280, 33, 33, 270, 33, 17280, 33, 33, 17280, 33, 270, 270, 33, 270, 17280, 17280, 17280, 270, 17280, 17280, 33, 33, 17280, 270, 17280, 33, 270, 17280, 33, 17280, 270, 33, 17280, 33, 33, 17280, 33, 33, 270]
Prompts retrieved: 562656 . Total input tokens: 125378570 . Total output tokens: 112631294
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 126.19250340294093,
    "estimated_duration": 3600.116018468611,
    "input_throughput": 7702.258721038428,
    "output_throughput": 6851.302811761053,
    "total_throughput": 14553.56153279948,
    "itl": 99.30237610519485,
    "ttft": 1308863.1034408393,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 124,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4037016418203721,
    "arrivals": 186986,
    "finished_requests": 112052,
    "scheduler_time": 238.23457778738054
}
#Debug simulation 
Total elapsed time: 126.19265030091628. Arrivals time: 0.5526164164766669 Scheduler time: 125.39138311846182 Scheduler overhead time: 0.09741798089817166 Adapter cache time: 0.018163200933486223 Engine time: 0.09748409874737263 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-16/adapters_96_slots_16_rate_1.6-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-16/adapters_96_slots_16_rate_1.6-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 33, 17280, 33, 33, 17280, 270, 17280, 270, 17280, 17280, 270, 33, 17280, 270, 33, 33, 270, 17280, 33, 270, 33, 33, 270, 270, 270, 33, 33, 17280, 270, 270, 33, 17280, 17280, 270, 17280, 17280, 270, 17280, 33, 17280, 270, 270, 270, 17280, 17280, 33, 33, 270, 33, 17280, 33, 33, 17280, 33, 270, 270, 33, 270, 17280, 17280, 17280, 270, 17280, 17280, 33, 33, 17280, 270, 17280, 33, 270, 17280, 33, 17280, 270, 33, 17280, 33, 33, 17280, 33, 33, 270]
Prompts retrieved: 562656 . Total input tokens: 125378570 . Total output tokens: 112631294
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 120.78442462766543,
    "estimated_duration": 3600.098611167551,
    "input_throughput": 7702.295963222845,
    "output_throughput": 6851.335939378815,
    "total_throughput": 14553.631902601659,
    "itl": 99.30222186339907,
    "ttft": 1308856.0831078936,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 124,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.38629285866860325,
    "arrivals": 186986,
    "finished_requests": 112052,
    "scheduler_time": 238.23415121291964
}
#Debug simulation 
Total elapsed time: 120.78457451192662. Arrivals time: 0.4571902183815837 Scheduler time: 120.09485434740782 Scheduler overhead time: 0.09088591020554304 Adapter cache time: 0.016532093286514282 Engine time: 0.09101564669981599 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-32/adapters_96_slots_16_rate_1.6-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-32/adapters_96_slots_16_rate_1.6-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 33, 17280, 33, 33, 17280, 270, 17280, 270, 17280, 17280, 270, 33, 17280, 270, 33, 33, 270, 17280, 33, 270, 33, 33, 270, 270, 270, 33, 33, 17280, 270, 270, 33, 17280, 17280, 270, 17280, 17280, 270, 17280, 33, 17280, 270, 270, 270, 17280, 17280, 33, 33, 270, 33, 17280, 33, 33, 17280, 33, 270, 270, 33, 270, 17280, 17280, 17280, 270, 17280, 17280, 33, 33, 17280, 270, 17280, 33, 270, 17280, 33, 17280, 270, 33, 17280, 33, 33, 17280, 33, 33, 270]
Prompts retrieved: 562656 . Total input tokens: 125378570 . Total output tokens: 112631294
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 121.37551145767793,
    "estimated_duration": 3600.1209864820717,
    "input_throughput": 7702.248092249799,
    "output_throughput": 6851.293357255296,
    "total_throughput": 14553.541449505095,
    "itl": 99.30244989941406,
    "ttft": 1308865.0706823766,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 124,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.40873179327696585,
    "arrivals": 186986,
    "finished_requests": 112052,
    "scheduler_time": 238.23471572655396
}
#Debug simulation 
Total elapsed time: 121.37571595190093. Arrivals time: 0.42911724792793393 Scheduler time: 120.71008492494002 Scheduler overhead time: 0.09248246485367417 Adapter cache time: 0.017249338794499636 Engine time: 0.09259967086836696 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-16/adapters_96_slots_16_rate_1.6-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-16/adapters_96_slots_16_rate_1.6-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 33, 17280, 33, 33, 17280, 270, 17280, 270, 17280, 17280, 270, 33, 17280, 270, 33, 33, 270, 17280, 33, 270, 33, 33, 270, 270, 270, 33, 33, 17280, 270, 270, 33, 17280, 17280, 270, 17280, 17280, 270, 17280, 33, 17280, 270, 270, 270, 17280, 17280, 33, 33, 270, 33, 17280, 33, 33, 17280, 33, 270, 270, 33, 270, 17280, 17280, 17280, 270, 17280, 17280, 33, 33, 17280, 270, 17280, 33, 270, 17280, 33, 17280, 270, 33, 17280, 33, 33, 17280, 33, 33, 270]
Prompts retrieved: 562656 . Total input tokens: 125378570 . Total output tokens: 112631294
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 122.37040776899084,
    "estimated_duration": 3600.047242081533,
    "input_throughput": 7708.321345237368,
    "output_throughput": 6857.16251482483,
    "total_throughput": 14565.483860062199,
    "itl": 99.31993421485171,
    "ttft": 1307073.551949332,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 127,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.37973638745257676,
    "arrivals": 186986,
    "finished_requests": 112148,
    "scheduler_time": 238.021944593817
}
#Debug simulation 
Total elapsed time: 122.37054461799562. Arrivals time: 0.4220759505406022 Scheduler time: 121.70881089102477 Scheduler overhead time: 0.09369057137519121 Adapter cache time: 0.016703434754163027 Engine time: 0.09386954130604863 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-32/adapters_96_slots_16_rate_1.6-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-32/adapters_96_slots_16_rate_1.6-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 33, 17280, 33, 33, 17280, 270, 17280, 270, 17280, 17280, 270, 33, 17280, 270, 33, 33, 270, 17280, 33, 270, 33, 33, 270, 270, 270, 33, 33, 17280, 270, 270, 33, 17280, 17280, 270, 17280, 17280, 270, 17280, 33, 17280, 270, 270, 270, 17280, 17280, 33, 33, 270, 33, 17280, 33, 33, 17280, 33, 270, 270, 33, 270, 17280, 17280, 17280, 270, 17280, 17280, 33, 33, 17280, 270, 17280, 33, 270, 17280, 33, 17280, 270, 33, 17280, 33, 33, 17280, 33, 33, 270]
Prompts retrieved: 562656 . Total input tokens: 125378570 . Total output tokens: 112631294
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 122.08947728155181,
    "estimated_duration": 3600.0030069569657,
    "input_throughput": 7702.064400062167,
    "output_throughput": 6851.1592774608025,
    "total_throughput": 14553.223677522969,
    "itl": 99.30162192839346,
    "ttft": 1308890.3726852052,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 124,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.41351043716073005,
    "arrivals": 186986,
    "finished_requests": 112048,
    "scheduler_time": 238.22671442740247
}
#Debug simulation 
Total elapsed time: 122.08960884995759. Arrivals time: 0.4296555621549487 Scheduler time: 121.42380691552535 Scheduler overhead time: 0.09246604703366756 Adapter cache time: 0.016743723303079605 Engine time: 0.09231508383527398 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-8/adapters_96_slots_16_rate_1.6-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-8/adapters_96_slots_16_rate_1.6-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 17280, 135, 135, 135, 135, 17280, 135, 17280, 135, 66, 17280, 66, 66, 17280, 135, 17280, 135, 17280, 17280, 135, 66, 17280, 135, 66, 66, 135, 17280, 66, 135, 66, 66, 135, 135, 135, 66, 66, 17280, 135, 135, 66, 17280, 17280, 135, 17280, 17280, 135, 17280, 66, 17280, 135, 135, 135, 17280, 17280, 66, 66, 135, 66, 17280, 66, 66, 17280, 66, 135, 135, 66, 135, 17280, 17280, 17280, 135, 17280, 17280, 66, 66, 17280, 135, 17280, 66, 135, 17280, 66, 17280, 135, 66, 17280, 66, 66, 17280, 66, 66, 135]
Prompts retrieved: 559392 . Total input tokens: 124640771 . Total output tokens: 111969357
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 125.36920633306727,
    "estimated_duration": 3600.107501054139,
    "input_throughput": 7748.962216220353,
    "output_throughput": 6860.745128518473,
    "total_throughput": 14609.707344738827,
    "itl": 99.07586687179219,
    "ttft": 1304122.5814248156,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 129,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3948029189673248,
    "arrivals": 186004,
    "finished_requests": 112707,
    "scheduler_time": 237.59192548880242
}
#Debug simulation 
Total elapsed time: 125.36939849983901. Arrivals time: 0.43652541982010007 Scheduler time: 124.69506797613576 Scheduler overhead time: 0.09275527484714985 Adapter cache time: 0.01712483074516058 Engine time: 0.09348043520003557 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-16/adapters_96_slots_16_rate_1.6-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-16/adapters_96_slots_16_rate_1.6-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 17280, 135, 135, 135, 135, 17280, 135, 17280, 135, 66, 17280, 66, 66, 17280, 135, 17280, 135, 17280, 17280, 135, 66, 17280, 135, 66, 66, 135, 17280, 66, 135, 66, 66, 135, 135, 135, 66, 66, 17280, 135, 135, 66, 17280, 17280, 135, 17280, 17280, 135, 17280, 66, 17280, 135, 135, 135, 17280, 17280, 66, 66, 135, 66, 17280, 66, 66, 17280, 66, 135, 135, 66, 135, 17280, 17280, 17280, 135, 17280, 17280, 66, 66, 17280, 135, 17280, 66, 135, 17280, 66, 17280, 135, 66, 17280, 66, 66, 17280, 66, 66, 135]
Prompts retrieved: 559392 . Total input tokens: 124640771 . Total output tokens: 111969357
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 124.77023527678102,
    "estimated_duration": 3600.046948186157,
    "input_throughput": 7745.727042268028,
    "output_throughput": 6856.14919895308,
    "total_throughput": 14601.876241221107,
    "itl": 99.04036195287699,
    "ttft": 1304894.9640246513,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 129,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4208556854282506,
    "arrivals": 186004,
    "finished_requests": 112643,
    "scheduler_time": 237.75465391885362
}
#Debug simulation 
Total elapsed time: 124.77037052577361. Arrivals time: 0.4242781954817474 Scheduler time: 124.10731436265633 Scheduler overhead time: 0.09321687463670969 Adapter cache time: 0.01696373289451003 Engine time: 0.09345615282654762 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-32/adapters_96_slots_16_rate_1.6-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-32/adapters_96_slots_16_rate_1.6-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 17280, 135, 135, 135, 135, 17280, 135, 17280, 135, 66, 17280, 66, 66, 17280, 135, 17280, 135, 17280, 17280, 135, 66, 17280, 135, 66, 66, 135, 17280, 66, 135, 66, 66, 135, 135, 135, 66, 66, 17280, 135, 135, 66, 17280, 17280, 135, 17280, 17280, 135, 17280, 66, 17280, 135, 135, 135, 17280, 17280, 66, 66, 135, 66, 17280, 66, 66, 17280, 66, 135, 135, 66, 135, 17280, 17280, 17280, 135, 17280, 17280, 66, 66, 17280, 135, 17280, 66, 135, 17280, 66, 17280, 135, 66, 17280, 66, 66, 17280, 66, 66, 135]
Prompts retrieved: 559392 . Total input tokens: 124640771 . Total output tokens: 111969357
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 125.12780188582838,
    "estimated_duration": 3600.047584430181,
    "input_throughput": 7745.725673349304,
    "output_throughput": 6856.147987251331,
    "total_throughput": 14601.873660600635,
    "itl": 99.04037445494042,
    "ttft": 1304895.2620274615,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 129,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42161721602082364,
    "arrivals": 186004,
    "finished_requests": 112643,
    "scheduler_time": 237.7546286708548
}
#Debug simulation 
Total elapsed time: 125.12794157490134. Arrivals time: 0.4328790199942887 Scheduler time: 124.4564129137434 Scheduler overhead time: 0.09279266418889165 Adapter cache time: 0.01696301205083728 Engine time: 0.09382571885362267 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-16/adapters_96_slots_16_rate_1.6-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-16/adapters_96_slots_16_rate_1.6-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 17280, 135, 135, 135, 135, 17280, 135, 17280, 135, 66, 17280, 66, 66, 17280, 135, 17280, 135, 17280, 17280, 135, 66, 17280, 135, 66, 66, 135, 17280, 66, 135, 66, 66, 135, 135, 135, 66, 66, 17280, 135, 135, 66, 17280, 17280, 135, 17280, 17280, 135, 17280, 66, 17280, 135, 135, 135, 17280, 17280, 66, 66, 135, 66, 17280, 66, 66, 17280, 66, 135, 135, 66, 135, 17280, 17280, 17280, 135, 17280, 17280, 66, 66, 17280, 135, 17280, 66, 135, 17280, 66, 17280, 135, 66, 17280, 66, 66, 17280, 66, 66, 135]
Prompts retrieved: 559392 . Total input tokens: 124640771 . Total output tokens: 111969357
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 125.1601002663374,
    "estimated_duration": 3600.11699139465,
    "input_throughput": 7748.941789025845,
    "output_throughput": 6860.72704277082,
    "total_throughput": 14609.668831796664,
    "itl": 99.07597784934676,
    "ttft": 1304126.714487404,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 129,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.40410327737219653,
    "arrivals": 186004,
    "finished_requests": 112707,
    "scheduler_time": 237.5922155094689
}
#Debug simulation 
Total elapsed time: 125.16029137931764. Arrivals time: 0.4257030072622001 Scheduler time: 124.496567344293 Scheduler overhead time: 0.09380813268944621 Adapter cache time: 0.016931534744799137 Engine time: 0.09276958694681525 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-32/adapters_96_slots_16_rate_1.6-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-32/adapters_96_slots_16_rate_1.6-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 17280, 135, 135, 135, 135, 17280, 135, 17280, 135, 66, 17280, 66, 66, 17280, 135, 17280, 135, 17280, 17280, 135, 66, 17280, 135, 66, 66, 135, 17280, 66, 135, 66, 66, 135, 135, 135, 66, 66, 17280, 135, 135, 66, 17280, 17280, 135, 17280, 17280, 135, 17280, 66, 17280, 135, 135, 135, 17280, 17280, 66, 66, 135, 66, 17280, 66, 66, 17280, 66, 135, 135, 66, 135, 17280, 17280, 17280, 135, 17280, 17280, 66, 66, 17280, 135, 17280, 66, 135, 17280, 66, 17280, 135, 66, 17280, 66, 66, 17280, 66, 66, 135]
Prompts retrieved: 559392 . Total input tokens: 124640771 . Total output tokens: 111969357
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 124.03465665085241,
    "estimated_duration": 3600.0528127643242,
    "input_throughput": 7745.714424280441,
    "output_throughput": 6856.138030110567,
    "total_throughput": 14601.852454391008,
    "itl": 99.04047156630364,
    "ttft": 1304897.3382614213,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 129,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42677312126383227,
    "arrivals": 186004,
    "finished_requests": 112643,
    "scheduler_time": 237.754801138346
}
#Debug simulation 
Total elapsed time: 124.03479334479198. Arrivals time: 0.4326475509442389 Scheduler time: 123.36519223824143 Scheduler overhead time: 0.09204776585102081 Adapter cache time: 0.016778016462922096 Engine time: 0.09306063363328576 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-16/adapters_96_slots_16_rate_1.6-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-16/adapters_96_slots_16_rate_1.6-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 17280, 135, 135, 135, 135, 17280, 135, 17280, 135, 66, 17280, 66, 66, 17280, 135, 17280, 135, 17280, 17280, 135, 66, 17280, 135, 66, 66, 135, 17280, 66, 135, 66, 66, 135, 135, 135, 66, 66, 17280, 135, 135, 66, 17280, 17280, 135, 17280, 17280, 135, 17280, 66, 17280, 135, 135, 135, 17280, 17280, 66, 66, 135, 66, 17280, 66, 66, 17280, 66, 135, 135, 66, 135, 17280, 17280, 17280, 135, 17280, 17280, 66, 66, 17280, 135, 17280, 66, 135, 17280, 66, 17280, 135, 66, 17280, 66, 66, 17280, 66, 66, 135]
Prompts retrieved: 559392 . Total input tokens: 124640771 . Total output tokens: 111969357
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 131.54747054167092,
    "estimated_duration": 3600.109611179341,
    "input_throughput": 7743.4172874719425,
    "output_throughput": 6856.793171892759,
    "total_throughput": 14600.210459364702,
    "itl": 99.05539669158553,
    "ttft": 1293277.1632113417,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.38272643774747894,
    "arrivals": 186004,
    "finished_requests": 112621,
    "scheduler_time": 237.8020170949406
}
#Debug simulation 
Total elapsed time: 131.54762141080573. Arrivals time: 0.43801728170365095 Scheduler time: 130.86567276064306 Scheduler overhead time: 0.09505410445854068 Adapter cache time: 0.017312955111265182 Engine time: 0.09604853112250566 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-32/adapters_96_slots_16_rate_1.6-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-32/adapters_96_slots_16_rate_1.6-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 17280, 135, 135, 135, 135, 17280, 135, 17280, 135, 66, 17280, 66, 66, 17280, 135, 17280, 135, 17280, 17280, 135, 66, 17280, 135, 66, 66, 135, 17280, 66, 135, 66, 66, 135, 135, 135, 66, 66, 17280, 135, 135, 66, 17280, 17280, 135, 17280, 17280, 135, 17280, 66, 17280, 135, 135, 135, 17280, 17280, 66, 66, 135, 66, 17280, 66, 66, 17280, 66, 135, 135, 66, 135, 17280, 17280, 17280, 135, 17280, 17280, 66, 66, 17280, 135, 17280, 66, 135, 17280, 66, 17280, 135, 66, 17280, 66, 66, 17280, 66, 66, 135]
Prompts retrieved: 559392 . Total input tokens: 124640771 . Total output tokens: 111969357
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 125.42591962544248,
    "estimated_duration": 3600.058033371076,
    "input_throughput": 7745.703191870118,
    "output_throughput": 6856.12808771515,
    "total_throughput": 14601.831279585267,
    "itl": 99.04058979572281,
    "ttft": 1304899.5854517142,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 129,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4324320416525003,
    "arrivals": 186004,
    "finished_requests": 112643,
    "scheduler_time": 237.7549630562044
}
#Debug simulation 
Total elapsed time: 125.42611233936623. Arrivals time: 0.4318997282534838 Scheduler time: 124.75374730397016 Scheduler overhead time: 0.0938643952831626 Adapter cache time: 0.017256527673453093 Engine time: 0.0935595566406846 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-8/adapters_96_slots_16_rate_1.6-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-8/adapters_96_slots_16_rate_1.6-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 17280, 135, 135, 135, 135, 17280, 135, 17280, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 17280, 17280, 135, 33, 17280, 135, 33, 33, 135, 17280, 33, 135, 33, 33, 135, 135, 135, 33, 33, 17280, 135, 135, 33, 17280, 17280, 135, 17280, 17280, 135, 17280, 33, 17280, 135, 135, 135, 17280, 17280, 33, 33, 135, 33, 17280, 33, 33, 17280, 33, 135, 135, 33, 135, 17280, 17280, 17280, 135, 17280, 17280, 33, 33, 17280, 135, 17280, 33, 135, 17280, 33, 17280, 135, 33, 17280, 33, 33, 17280, 33, 33, 135]
Prompts retrieved: 558336 . Total input tokens: 124411758 . Total output tokens: 111757417
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 140.79591160919517,
    "estimated_duration": 3600.0504676880278,
    "input_throughput": 7720.164828091648,
    "output_throughput": 6848.172885707568,
    "total_throughput": 14568.337713799216,
    "itl": 98.99922345972602,
    "ttft": 1268959.5907938522,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 132,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.403984382199123,
    "arrivals": 185665,
    "finished_requests": 112404,
    "scheduler_time": 239.45286530950682
}
#Debug simulation 
Total elapsed time: 140.79604644700885. Arrivals time: 0.45485989190638065 Scheduler time: 140.08948568068445 Scheduler overhead time: 0.09761607646942139 Adapter cache time: 0.01794059993699193 Engine time: 0.10034474264830351 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-16/adapters_96_slots_16_rate_1.6-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-16/adapters_96_slots_16_rate_1.6-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 17280, 135, 135, 135, 135, 17280, 135, 17280, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 17280, 17280, 135, 33, 17280, 135, 33, 33, 135, 17280, 33, 135, 33, 33, 135, 135, 135, 33, 33, 17280, 135, 135, 33, 17280, 17280, 135, 17280, 17280, 135, 17280, 33, 17280, 135, 135, 135, 17280, 17280, 33, 33, 135, 33, 17280, 33, 33, 17280, 33, 135, 135, 33, 135, 17280, 17280, 17280, 135, 17280, 17280, 33, 33, 17280, 135, 17280, 33, 135, 17280, 33, 17280, 135, 33, 17280, 33, 33, 17280, 33, 33, 135]
Prompts retrieved: 558336 . Total input tokens: 124411758 . Total output tokens: 111757417
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 146.3057239567861,
    "estimated_duration": 3600.011963717186,
    "input_throughput": 7651.900126341931,
    "output_throughput": 6794.144365771746,
    "total_throughput": 14446.044492113677,
    "itl": 98.55373164414218,
    "ttft": 1263841.7429875801,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 118,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.38428777431836353,
    "arrivals": 185665,
    "finished_requests": 111393,
    "scheduler_time": 242.35062586055514
}
#Debug simulation 
Total elapsed time: 146.30585546093062. Arrivals time: 0.45004446618258953 Scheduler time: 145.60273464862257 Scheduler overhead time: 0.09915677830576897 Adapter cache time: 0.01828328100964427 Engine time: 0.09931414620950818 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-32/adapters_96_slots_16_rate_1.6-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-32/adapters_96_slots_16_rate_1.6-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 17280, 135, 135, 135, 135, 17280, 135, 17280, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 17280, 17280, 135, 33, 17280, 135, 33, 33, 135, 17280, 33, 135, 33, 33, 135, 135, 135, 33, 33, 17280, 135, 135, 33, 17280, 17280, 135, 17280, 17280, 135, 17280, 33, 17280, 135, 135, 135, 17280, 17280, 33, 33, 135, 33, 17280, 33, 33, 17280, 33, 135, 135, 33, 135, 17280, 17280, 17280, 135, 17280, 17280, 33, 33, 17280, 135, 17280, 33, 135, 17280, 33, 17280, 135, 33, 17280, 33, 33, 17280, 33, 33, 135]
Prompts retrieved: 558336 . Total input tokens: 124411758 . Total output tokens: 111757417
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 146.61537283705547,
    "estimated_duration": 3600.0131304695046,
    "input_throughput": 7651.897646386473,
    "output_throughput": 6794.1421638120855,
    "total_throughput": 14446.039810198557,
    "itl": 98.55371869036053,
    "ttft": 1263842.2374760094,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 118,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.38510328123346055,
    "arrivals": 185665,
    "finished_requests": 111393,
    "scheduler_time": 242.35068107347215
}
#Debug simulation 
Total elapsed time: 146.61556797567755. Arrivals time: 0.47361300233751535 Scheduler time: 145.88590114703402 Scheduler overhead time: 0.10058477567508817 Adapter cache time: 0.01868327846750617 Engine time: 0.10008196206763387 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-16/adapters_96_slots_16_rate_1.6-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-16/adapters_96_slots_16_rate_1.6-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 17280, 135, 135, 135, 135, 17280, 135, 17280, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 17280, 17280, 135, 33, 17280, 135, 33, 33, 135, 17280, 33, 135, 33, 33, 135, 135, 135, 33, 33, 17280, 135, 135, 33, 17280, 17280, 135, 17280, 17280, 135, 17280, 33, 17280, 135, 135, 135, 17280, 17280, 33, 33, 135, 33, 17280, 33, 33, 17280, 33, 135, 135, 33, 135, 17280, 17280, 17280, 135, 17280, 17280, 33, 33, 17280, 135, 17280, 33, 135, 17280, 33, 17280, 135, 33, 17280, 33, 33, 17280, 33, 33, 135]
Prompts retrieved: 558336 . Total input tokens: 124411758 . Total output tokens: 111757417
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 143.8905905680731,
    "estimated_duration": 3600.057270899859,
    "input_throughput": 7686.3474433236925,
    "output_throughput": 6817.744872671148,
    "total_throughput": 14504.092315994842,
    "itl": 99.00687927175687,
    "ttft": 1265009.335438974,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 114,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3568009510380218,
    "arrivals": 185665,
    "finished_requests": 111863,
    "scheduler_time": 240.6024116571657
}
#Debug simulation 
Total elapsed time: 143.89073877828196. Arrivals time: 0.4765972150489688 Scheduler time: 143.1615384616889 Scheduler overhead time: 0.09862494934350252 Adapter cache time: 0.017930008936673403 Engine time: 0.09970647096633911 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-32/adapters_96_slots_16_rate_1.6-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-32/adapters_96_slots_16_rate_1.6-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 17280, 135, 135, 135, 135, 17280, 135, 17280, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 17280, 17280, 135, 33, 17280, 135, 33, 33, 135, 17280, 33, 135, 33, 33, 135, 135, 135, 33, 33, 17280, 135, 135, 33, 17280, 17280, 135, 17280, 17280, 135, 17280, 33, 17280, 135, 135, 135, 17280, 17280, 33, 33, 135, 33, 17280, 33, 33, 17280, 33, 135, 135, 33, 135, 17280, 17280, 17280, 135, 17280, 17280, 33, 33, 17280, 135, 17280, 33, 135, 17280, 33, 17280, 135, 33, 17280, 33, 33, 17280, 33, 33, 135]
Prompts retrieved: 558336 . Total input tokens: 124411758 . Total output tokens: 111757417
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 145.88563517807052,
    "estimated_duration": 3600.0172046185385,
    "input_throughput": 7651.8889867135795,
    "output_throughput": 6794.13447486335,
    "total_throughput": 14446.02346157693,
    "itl": 98.55376101515465,
    "ttft": 1263843.5268462219,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 118,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3897561713308098,
    "arrivals": 185665,
    "finished_requests": 111393,
    "scheduler_time": 242.35071161509757
}
#Debug simulation 
Total elapsed time: 145.8857705197297. Arrivals time: 0.4803760228678584 Scheduler time: 145.14942458365113 Scheduler overhead time: 0.10074284439906478 Adapter cache time: 0.01822443027049303 Engine time: 0.09960448183119297 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-16/adapters_96_slots_16_rate_1.6-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-16/adapters_96_slots_16_rate_1.6-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 17280, 135, 135, 135, 135, 17280, 135, 17280, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 17280, 17280, 135, 33, 17280, 135, 33, 33, 135, 17280, 33, 135, 33, 33, 135, 135, 135, 33, 33, 17280, 135, 135, 33, 17280, 17280, 135, 17280, 17280, 135, 17280, 33, 17280, 135, 135, 135, 17280, 17280, 33, 33, 135, 33, 17280, 33, 33, 17280, 33, 135, 135, 33, 135, 17280, 17280, 17280, 135, 17280, 17280, 33, 33, 17280, 135, 17280, 33, 135, 17280, 33, 17280, 135, 33, 17280, 33, 33, 17280, 33, 33, 135]
Prompts retrieved: 558336 . Total input tokens: 124411758 . Total output tokens: 111757417
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 141.30051488708705,
    "estimated_duration": 3600.0409427578084,
    "input_throughput": 7720.185253979142,
    "output_throughput": 6848.1910044928545,
    "total_throughput": 14568.376258471997,
    "itl": 98.99907587639755,
    "ttft": 1268955.913138114,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 132,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.39468663892708766,
    "arrivals": 185665,
    "finished_requests": 112404,
    "scheduler_time": 239.4526135549265
}
#Debug simulation 
Total elapsed time: 141.3007028871216. Arrivals time: 0.47461248375475407 Scheduler time: 140.57699491642416 Scheduler overhead time: 0.09783156123012304 Adapter cache time: 0.01782106189057231 Engine time: 0.09744377201423049 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-32/adapters_96_slots_16_rate_1.6-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-32/adapters_96_slots_16_rate_1.6-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 17280, 135, 135, 135, 135, 17280, 135, 17280, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 17280, 17280, 135, 33, 17280, 135, 33, 33, 135, 17280, 33, 135, 33, 33, 135, 135, 135, 33, 33, 17280, 135, 135, 33, 17280, 17280, 135, 17280, 17280, 135, 17280, 33, 17280, 135, 135, 135, 17280, 17280, 33, 33, 135, 33, 17280, 33, 33, 17280, 33, 135, 135, 33, 135, 17280, 17280, 17280, 135, 17280, 17280, 33, 33, 17280, 135, 17280, 33, 135, 17280, 33, 17280, 135, 33, 17280, 33, 33, 17280, 33, 33, 135]
Prompts retrieved: 558336 . Total input tokens: 124411758 . Total output tokens: 111757417
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 146.14502756204456,
    "estimated_duration": 3600.0194487579133,
    "input_throughput": 7651.884216765636,
    "output_throughput": 6794.130239612705,
    "total_throughput": 14446.01445637834,
    "itl": 98.55372583558325,
    "ttft": 1263843.9825240546,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 118,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.39478632278740367,
    "arrivals": 185665,
    "finished_requests": 111393,
    "scheduler_time": 242.35072668327118
}
#Debug simulation 
Total elapsed time: 146.14516454190016. Arrivals time: 0.47603794978931546 Scheduler time: 145.4141739476472 Scheduler overhead time: 0.10048421286046505 Adapter cache time: 0.018313655629754066 Engine time: 0.09986974857747555 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-8/adapters_96_slots_16_rate_1.6-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-8/adapters_96_slots_16_rate_1.6-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 17280, 66, 66, 66, 66, 17280, 66, 17280, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 17280, 17280, 66, 33, 17280, 66, 33, 33, 66, 17280, 33, 66, 33, 33, 66, 66, 66, 33, 33, 17280, 66, 66, 33, 17280, 17280, 66, 17280, 17280, 66, 17280, 33, 17280, 66, 66, 66, 17280, 17280, 33, 33, 66, 33, 17280, 33, 33, 17280, 33, 66, 66, 33, 66, 17280, 17280, 17280, 66, 17280, 17280, 33, 33, 17280, 66, 17280, 33, 66, 17280, 33, 17280, 66, 33, 17280, 33, 33, 17280, 33, 33, 66]
Prompts retrieved: 556128 . Total input tokens: 123911371 . Total output tokens: 111312136
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 120.38779092906043,
    "estimated_duration": 3600.092783387411,
    "input_throughput": 7707.082752987533,
    "output_throughput": 6818.927865770584,
    "total_throughput": 14526.010618758117,
    "itl": 99.17345156484467,
    "ttft": 1304366.776717456,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 111,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3397141395765353,
    "arrivals": 184921,
    "finished_requests": 111868,
    "scheduler_time": 238.74618996138082
}
#Debug simulation 
Total elapsed time: 120.38793693808839. Arrivals time: 0.44493071967735887 Scheduler time: 119.70454496564344 Scheduler overhead time: 0.09265874372795224 Adapter cache time: 0.017002310138195753 Engine time: 0.09293193090707064 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-16/adapters_96_slots_16_rate_1.6-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-16/adapters_96_slots_16_rate_1.6-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 17280, 66, 66, 66, 66, 17280, 66, 17280, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 17280, 17280, 66, 33, 17280, 66, 33, 33, 66, 17280, 33, 66, 33, 33, 66, 66, 66, 33, 33, 17280, 66, 66, 33, 17280, 17280, 66, 17280, 17280, 66, 17280, 33, 17280, 66, 66, 66, 17280, 17280, 33, 33, 66, 33, 17280, 33, 33, 17280, 33, 66, 66, 33, 66, 17280, 17280, 17280, 66, 17280, 17280, 33, 33, 17280, 66, 17280, 33, 66, 17280, 33, 17280, 66, 33, 17280, 33, 33, 17280, 33, 33, 66]
Prompts retrieved: 556128 . Total input tokens: 123911371 . Total output tokens: 111312136
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 123.8005413399078,
    "estimated_duration": 3600.09868617774,
    "input_throughput": 7710.098088858224,
    "output_throughput": 6812.459917880471,
    "total_throughput": 14522.558006738696,
    "itl": 99.09813314382997,
    "ttft": 1300786.4744618563,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 111,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3617230409802869,
    "arrivals": 184921,
    "finished_requests": 111832,
    "scheduler_time": 239.02834338201833
}
#Debug simulation 
Total elapsed time: 123.80074584111571. Arrivals time: 0.45841401908546686 Scheduler time: 123.10123473173007 Scheduler overhead time: 0.09374146163463593 Adapter cache time: 0.017047486267983913 Engine time: 0.09487789124250412 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-32/adapters_96_slots_16_rate_1.6-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-32/adapters_96_slots_16_rate_1.6-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 17280, 66, 66, 66, 66, 17280, 66, 17280, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 17280, 17280, 66, 33, 17280, 66, 33, 33, 66, 17280, 33, 66, 33, 33, 66, 66, 66, 33, 33, 17280, 66, 66, 33, 17280, 17280, 66, 17280, 17280, 66, 17280, 33, 17280, 66, 66, 66, 17280, 17280, 33, 33, 66, 33, 17280, 33, 33, 17280, 33, 66, 66, 33, 66, 17280, 17280, 17280, 66, 17280, 17280, 33, 33, 17280, 66, 17280, 33, 66, 17280, 33, 17280, 66, 33, 17280, 33, 33, 17280, 33, 33, 66]
Prompts retrieved: 556128 . Total input tokens: 123911371 . Total output tokens: 111312136
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 124.00105879502371,
    "estimated_duration": 3600.099342299318,
    "input_throughput": 7710.096683685411,
    "output_throughput": 6812.45867630308,
    "total_throughput": 14522.555359988492,
    "itl": 99.09815027740044,
    "ttft": 1300786.7389700145,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 111,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.36244965931400724,
    "arrivals": 184921,
    "finished_requests": 111832,
    "scheduler_time": 239.02837292383185
}
#Debug simulation 
Total elapsed time: 124.0012104450725. Arrivals time: 0.4532027100212872 Scheduler time: 123.30922258319333 Scheduler overhead time: 0.09381688944995403 Adapter cache time: 0.01689547160640359 Engine time: 0.09301605820655823 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-16/adapters_96_slots_16_rate_1.6-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-16/adapters_96_slots_16_rate_1.6-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 17280, 66, 66, 66, 66, 17280, 66, 17280, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 17280, 17280, 66, 33, 17280, 66, 33, 33, 66, 17280, 33, 66, 33, 33, 66, 66, 66, 33, 33, 17280, 66, 66, 33, 17280, 17280, 66, 17280, 17280, 66, 17280, 33, 17280, 66, 66, 66, 17280, 17280, 33, 33, 66, 33, 17280, 33, 33, 17280, 33, 66, 66, 33, 66, 17280, 17280, 17280, 66, 17280, 17280, 33, 33, 17280, 66, 17280, 33, 66, 17280, 33, 17280, 66, 33, 17280, 33, 33, 17280, 33, 33, 66]
Prompts retrieved: 556128 . Total input tokens: 123911371 . Total output tokens: 111312136
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 120.37673141993582,
    "estimated_duration": 3600.0991488787586,
    "input_throughput": 7707.069125760463,
    "output_throughput": 6818.915808928666,
    "total_throughput": 14525.984934689128,
    "itl": 99.1734802884003,
    "ttft": 1304369.055236161,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 111,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3466050141979942,
    "arrivals": 184921,
    "finished_requests": 111868,
    "scheduler_time": 238.74626480957343
}
#Debug simulation 
Total elapsed time: 120.37687945086509. Arrivals time: 0.443096827249974 Scheduler time: 119.694772280287 Scheduler overhead time: 0.09304327005520463 Adapter cache time: 0.017273800913244486 Engine time: 0.09382217517122626 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-32/adapters_96_slots_16_rate_1.6-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-32/adapters_96_slots_16_rate_1.6-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 17280, 66, 66, 66, 66, 17280, 66, 17280, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 17280, 17280, 66, 33, 17280, 66, 33, 33, 66, 17280, 33, 66, 33, 33, 66, 66, 66, 33, 33, 17280, 66, 66, 33, 17280, 17280, 66, 17280, 17280, 66, 17280, 33, 17280, 66, 66, 66, 17280, 17280, 33, 33, 66, 33, 17280, 33, 33, 17280, 33, 66, 66, 33, 66, 17280, 17280, 17280, 66, 17280, 17280, 33, 33, 17280, 66, 17280, 33, 66, 17280, 33, 17280, 66, 33, 17280, 33, 33, 17280, 33, 33, 66]
Prompts retrieved: 556128 . Total input tokens: 123911371 . Total output tokens: 111312136
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 123.19774334924296,
    "estimated_duration": 3600.10543585982,
    "input_throughput": 7710.08363352856,
    "output_throughput": 6812.447145493816,
    "total_throughput": 14522.530779022376,
    "itl": 99.09818488160055,
    "ttft": 1300789.2828180534,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 111,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3671025494113566,
    "arrivals": 184921,
    "finished_requests": 111832,
    "scheduler_time": 239.02861891587142
}
#Debug simulation 
Total elapsed time: 123.19794426299632. Arrivals time: 0.4485971978865564 Scheduler time: 122.50706393457949 Scheduler overhead time: 0.0942469728179276 Adapter cache time: 0.017418647184967995 Engine time: 0.09535709582269192 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-16/adapters_96_slots_16_rate_1.6-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-16/adapters_96_slots_16_rate_1.6-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 17280, 66, 66, 66, 66, 17280, 66, 17280, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 17280, 17280, 66, 33, 17280, 66, 33, 33, 66, 17280, 33, 66, 33, 33, 66, 66, 66, 33, 33, 17280, 66, 66, 33, 17280, 17280, 66, 17280, 17280, 66, 17280, 33, 17280, 66, 66, 66, 17280, 17280, 33, 33, 66, 33, 17280, 33, 33, 17280, 33, 66, 66, 33, 66, 17280, 17280, 17280, 66, 17280, 17280, 33, 33, 17280, 66, 17280, 33, 66, 17280, 33, 17280, 66, 33, 17280, 33, 33, 17280, 33, 33, 66]
Prompts retrieved: 556128 . Total input tokens: 123911371 . Total output tokens: 111312136
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 120.27165200281888,
    "estimated_duration": 3600.0836613943065,
    "input_throughput": 7707.102281410298,
    "output_throughput": 6818.945143761548,
    "total_throughput": 14526.047425171846,
    "itl": 99.17329551130214,
    "ttft": 1304363.0801975054,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 111,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3318955827341419,
    "arrivals": 184921,
    "finished_requests": 111868,
    "scheduler_time": 238.7457868723272
}
#Debug simulation 
Total elapsed time: 120.27179892500862. Arrivals time: 0.4569019437767565 Scheduler time: 119.57608688808978 Scheduler overhead time: 0.09262880636379123 Adapter cache time: 0.01683379290625453 Engine time: 0.09333220822736621 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-32/adapters_96_slots_16_rate_1.6-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-32/adapters_96_slots_16_rate_1.6-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 17280, 66, 66, 66, 66, 17280, 66, 17280, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 17280, 17280, 66, 33, 17280, 66, 33, 33, 66, 17280, 33, 66, 33, 33, 66, 66, 66, 33, 33, 17280, 66, 66, 33, 17280, 17280, 66, 17280, 17280, 66, 17280, 33, 17280, 66, 66, 66, 17280, 17280, 33, 33, 66, 33, 17280, 33, 33, 17280, 33, 66, 66, 33, 66, 17280, 17280, 17280, 66, 17280, 17280, 33, 33, 17280, 66, 17280, 33, 66, 17280, 33, 17280, 66, 33, 17280, 33, 33, 17280, 33, 33, 66]
Prompts retrieved: 556128 . Total input tokens: 123911371 . Total output tokens: 111312136
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 123.84871392697096,
    "estimated_duration": 3600.110276265748,
    "input_throughput": 7710.073267197626,
    "output_throughput": 6812.437986049516,
    "total_throughput": 14522.511253247141,
    "itl": 99.09824039053548,
    "ttft": 1300791.1645907618,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 111,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3716296857222912,
    "arrivals": 184921,
    "finished_requests": 111832,
    "scheduler_time": 239.02883214692037
}
#Debug simulation 
Total elapsed time: 123.8488695831038. Arrivals time: 0.4521907907910645 Scheduler time: 123.15693619474769 Scheduler overhead time: 0.09330863505601883 Adapter cache time: 0.016595850232988596 Engine time: 0.09504542034119368 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-8/adapters_96_slots_16_rate_0.8-0.4-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-8/adapters_96_slots_16_rate_0.8-0.4-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 4320, 8640, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 8640, 4320, 4320, 1080, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 1080, 8640, 4320, 4320, 4320, 8640, 8640, 1080, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 1080, 1080, 8640, 4320, 8640, 1080, 4320, 8640, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 1080, 4320]
Prompts retrieved: 449280 . Total input tokens: 100180638 . Total output tokens: 89863988
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 128.66252271970734,
    "estimated_duration": 3600.0933474873264,
    "input_throughput": 7087.775937201536,
    "output_throughput": 6325.174878005067,
    "total_throughput": 13412.950815206603,
    "itl": 97.57168727670968,
    "ttft": 1303253.00223074,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 234,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7161541320802635,
    "arrivals": 149510,
    "finished_requests": 103468,
    "scheduler_time": 245.60277065641463
}
#Debug simulation 
Total elapsed time: 128.66272546583787. Arrivals time: 0.46513254242017865 Scheduler time: 127.93465383397415 Scheduler overhead time: 0.1039166091941297 Adapter cache time: 0.019071141257882118 Engine time: 0.1014533000998199 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-16/adapters_96_slots_16_rate_0.8-0.4-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-16/adapters_96_slots_16_rate_0.8-0.4-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 4320, 8640, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 8640, 4320, 4320, 1080, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 1080, 8640, 4320, 4320, 4320, 8640, 8640, 1080, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 1080, 1080, 8640, 4320, 8640, 1080, 4320, 8640, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 1080, 4320]
Prompts retrieved: 449280 . Total input tokens: 100180638 . Total output tokens: 89863988
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 133.6242260443978,
    "estimated_duration": 3600.0518877141517,
    "input_throughput": 7069.826989677238,
    "output_throughput": 6316.203962948402,
    "total_throughput": 13386.03095262564,
    "itl": 97.25359679398971,
    "ttft": 1288788.9659538853,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 208,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6774994246475421,
    "arrivals": 149510,
    "finished_requests": 103201,
    "scheduler_time": 246.71696132778854
}
#Debug simulation 
Total elapsed time: 133.62436870438978. Arrivals time: 0.4667416540905833 Scheduler time: 132.89212307846174 Scheduler overhead time: 0.10501621337607503 Adapter cache time: 0.019135170616209507 Engine time: 0.10250353952869773 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-32/adapters_96_slots_16_rate_0.8-0.4-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-32/adapters_96_slots_16_rate_0.8-0.4-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 4320, 8640, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 8640, 4320, 4320, 1080, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 1080, 8640, 4320, 4320, 4320, 8640, 8640, 1080, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 1080, 1080, 8640, 4320, 8640, 1080, 4320, 8640, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 1080, 4320]
Prompts retrieved: 449280 . Total input tokens: 100180638 . Total output tokens: 89863988
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 133.4628740027547,
    "estimated_duration": 3600.0534515330332,
    "input_throughput": 7069.823918631465,
    "output_throughput": 6316.20121926719,
    "total_throughput": 13386.025137898654,
    "itl": 97.25363210993228,
    "ttft": 1288789.8407476435,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 208,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6789175797998934,
    "arrivals": 149510,
    "finished_requests": 103201,
    "scheduler_time": 246.71710699150606
}
#Debug simulation 
Total elapsed time: 133.46301628276706. Arrivals time: 0.4624476991593838 Scheduler time: 132.73523843148723 Scheduler overhead time: 0.10586049407720566 Adapter cache time: 0.019190284423530102 Engine time: 0.10169403860345483 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-16-16/adapters_96_slots_16_rate_0.8-0.4-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-16-16/adapters_96_slots_16_rate_0.8-0.4-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 4320, 8640, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 8640, 4320, 4320, 1080, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 1080, 8640, 4320, 4320, 4320, 8640, 8640, 1080, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 1080, 1080, 8640, 4320, 8640, 1080, 4320, 8640, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 1080, 4320]
Prompts retrieved: 449280 . Total input tokens: 100180638 . Total output tokens: 89863988
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 119.79189439537004,
    "estimated_duration": 3600.025639495013,
    "input_throughput": 7122.7876042563175,
    "output_throughput": 6340.591508454345,
    "total_throughput": 13463.379112710662,
    "itl": 97.36117695695178,
    "ttft": 1299366.3333254135,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 223,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6966086740093321,
    "arrivals": 149510,
    "finished_requests": 103905,
    "scheduler_time": 244.7159641147026
}
#Debug simulation 
Total elapsed time: 119.79209286812693. Arrivals time: 0.44228994753211737 Scheduler time: 119.09150381432846 Scheduler overhead time: 0.10242931405082345 Adapter cache time: 0.018268501851707697 Engine time: 0.09972460241988301 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-16-32/adapters_96_slots_16_rate_0.8-0.4-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-16-32/adapters_96_slots_16_rate_0.8-0.4-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 4320, 8640, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 8640, 4320, 4320, 1080, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 1080, 8640, 4320, 4320, 4320, 8640, 8640, 1080, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 1080, 1080, 8640, 4320, 8640, 1080, 4320, 8640, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 1080, 4320]
Prompts retrieved: 449280 . Total input tokens: 100180638 . Total output tokens: 89863988
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 133.5004841061309,
    "estimated_duration": 3600.0618513680533,
    "input_throughput": 7069.80742298306,
    "output_throughput": 6316.186482007002,
    "total_throughput": 13385.993904990062,
    "itl": 97.25372074841935,
    "ttft": 1288793.3862032043,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 208,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.687343083489689,
    "arrivals": 149510,
    "finished_requests": 103201,
    "scheduler_time": 246.71738143858127
}
#Debug simulation 
Total elapsed time: 133.5006193490699. Arrivals time: 0.45329969422891736 Scheduler time: 132.77747357916087 Scheduler overhead time: 0.10676411632448435 Adapter cache time: 0.019633454270660877 Engine time: 0.1034328076057136 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_16-16-16/adapters_96_slots_16_rate_0.8-0.4-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_16-16-16/adapters_96_slots_16_rate_0.8-0.4-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 4320, 8640, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 8640, 4320, 4320, 1080, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 1080, 8640, 4320, 4320, 4320, 8640, 8640, 1080, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 1080, 1080, 8640, 4320, 8640, 1080, 4320, 8640, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 1080, 4320]
Prompts retrieved: 449280 . Total input tokens: 100180638 . Total output tokens: 89863988
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 127.14507343014702,
    "estimated_duration": 3600.076278508125,
    "input_throughput": 7087.809542350621,
    "output_throughput": 6325.204867446979,
    "total_throughput": 13413.014409797599,
    "itl": 97.57110184044834,
    "ttft": 1303245.854790392,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 234,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.69967176900711,
    "arrivals": 149510,
    "finished_requests": 103468,
    "scheduler_time": 245.60206344931626
}
#Debug simulation 
Total elapsed time: 127.1452164570801. Arrivals time: 0.3968813135288656 Scheduler time: 126.4963639578782 Scheduler overhead time: 0.1002590749412775 Adapter cache time: 0.017793334554880857 Engine time: 0.09694390511140227 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_16-16-32/adapters_96_slots_16_rate_0.8-0.4-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_16-16-32/adapters_96_slots_16_rate_0.8-0.4-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 4320, 8640, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 8640, 4320, 4320, 1080, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 1080, 8640, 4320, 4320, 4320, 8640, 8640, 1080, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 1080, 1080, 8640, 4320, 8640, 1080, 4320, 8640, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 1080, 4320]
Prompts retrieved: 449280 . Total input tokens: 100180638 . Total output tokens: 89863988
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 131.62666516611353,
    "estimated_duration": 3600.0001792159787,
    "input_throughput": 7069.782148050575,
    "output_throughput": 6316.073852238512,
    "total_throughput": 13385.856000289088,
    "itl": 97.25371754271107,
    "ttft": 1288867.5595967267,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 208,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6960200947523139,
    "arrivals": 149510,
    "finished_requests": 103198,
    "scheduler_time": 246.71154847675317
}
#Debug simulation 
Total elapsed time: 131.62685844115913. Arrivals time: 0.409735900349915 Scheduler time: 130.96071922313422 Scheduler overhead time: 0.10265650879591703 Adapter cache time: 0.018069392070174217 Engine time: 0.09766681026667356 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-8/adapters_96_slots_16_rate_0.8-0.4-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-8/adapters_96_slots_16_rate_0.8-0.4-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 540, 8640, 4320, 540, 540, 4320, 8640, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 540, 8640, 4320, 4320, 540, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 540, 8640, 4320, 4320, 4320, 8640, 8640, 540, 540, 4320, 540, 8640, 540, 540, 8640, 540, 4320, 4320, 540, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 540, 540, 8640, 4320, 8640, 540, 4320, 8640, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 540, 540, 4320]
Prompts retrieved: 432000 . Total input tokens: 96291061 . Total output tokens: 86418789
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 117.47467854386196,
    "estimated_duration": 3600.100451330055,
    "input_throughput": 7142.08071347027,
    "output_throughput": 6282.00054574716,
    "total_throughput": 13424.08125921743,
    "itl": 95.1989529230138,
    "ttft": 1260258.3729906478,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 232,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.710033156592398,
    "arrivals": 143761,
    "finished_requests": 103194,
    "scheduler_time": 243.0667475789537
}
#Debug simulation 
Total elapsed time: 117.4748128480278. Arrivals time: 0.39733912935480475 Scheduler time: 116.82122468436137 Scheduler overhead time: 0.10185925336554646 Adapter cache time: 0.01851194677874446 Engine time: 0.09772070636972785 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-16/adapters_96_slots_16_rate_0.8-0.4-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-16/adapters_96_slots_16_rate_0.8-0.4-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 540, 8640, 4320, 540, 540, 4320, 8640, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 540, 8640, 4320, 4320, 540, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 540, 8640, 4320, 4320, 4320, 8640, 8640, 540, 540, 4320, 540, 8640, 540, 540, 8640, 540, 4320, 4320, 540, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 540, 540, 8640, 4320, 8640, 540, 4320, 8640, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 540, 540, 4320]
Prompts retrieved: 432000 . Total input tokens: 96291061 . Total output tokens: 86418789
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 120.31346214562654,
    "estimated_duration": 3600.0287393852936,
    "input_throughput": 7202.867498337707,
    "output_throughput": 6335.598588553083,
    "total_throughput": 13538.46608689079,
    "itl": 95.54852153773172,
    "ttft": 1249388.4396598688,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 231,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7532167018437786,
    "arrivals": 143761,
    "finished_requests": 104039,
    "scheduler_time": 240.5294201525706
}
#Debug simulation 
Total elapsed time: 120.31359971361235. Arrivals time: 0.4003341933712363 Scheduler time: 119.66154859121889 Scheduler overhead time: 0.10026855720207095 Adapter cache time: 0.017916289623826742 Engine time: 0.09618211071938276 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-32/adapters_96_slots_16_rate_0.8-0.4-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-32/adapters_96_slots_16_rate_0.8-0.4-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 540, 8640, 4320, 540, 540, 4320, 8640, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 540, 8640, 4320, 4320, 540, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 540, 8640, 4320, 4320, 4320, 8640, 8640, 540, 540, 4320, 540, 8640, 540, 540, 8640, 540, 4320, 4320, 540, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 540, 540, 8640, 4320, 8640, 540, 4320, 8640, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 540, 540, 4320]
Prompts retrieved: 432000 . Total input tokens: 96291061 . Total output tokens: 86418789
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 119.81433676416054,
    "estimated_duration": 3600.0306211833795,
    "input_throughput": 7202.8637332746575,
    "output_throughput": 6335.595276826447,
    "total_throughput": 13538.459010101105,
    "itl": 95.54856320704978,
    "ttft": 1249389.3791284892,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 231,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7546517207287287,
    "arrivals": 143761,
    "finished_requests": 104039,
    "scheduler_time": 240.52956681601697
}
#Debug simulation 
Total elapsed time: 119.81451941095293. Arrivals time: 0.401197322178632 Scheduler time: 119.15855373302475 Scheduler overhead time: 0.10053474828600883 Adapter cache time: 0.01792727829888463 Engine time: 0.09833379462361336 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-16-16/adapters_96_slots_16_rate_0.8-0.4-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-16-16/adapters_96_slots_16_rate_0.8-0.4-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 540, 8640, 4320, 540, 540, 4320, 8640, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 540, 8640, 4320, 4320, 540, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 540, 8640, 4320, 4320, 4320, 8640, 8640, 540, 540, 4320, 540, 8640, 540, 540, 8640, 540, 4320, 4320, 540, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 540, 540, 8640, 4320, 8640, 540, 4320, 8640, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 540, 540, 4320]
Prompts retrieved: 432000 . Total input tokens: 96291061 . Total output tokens: 86418789
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 125.4203355317004,
    "estimated_duration": 3600.076151413389,
    "input_throughput": 7119.009132609061,
    "output_throughput": 6277.385268955383,
    "total_throughput": 13396.394401564445,
    "itl": 94.20552368343901,
    "ttft": 1252001.9037038167,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 224,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7008245102595551,
    "arrivals": 143761,
    "finished_requests": 102936,
    "scheduler_time": 244.56729651492728
}
#Debug simulation 
Total elapsed time: 125.42049772897735. Arrivals time: 0.49300924129784107 Scheduler time: 124.66060115443543 Scheduler overhead time: 0.1058483300730586 Adapter cache time: 0.019313025753945112 Engine time: 0.10238112322986126 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-16-32/adapters_96_slots_16_rate_0.8-0.4-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-16-32/adapters_96_slots_16_rate_0.8-0.4-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 540, 8640, 4320, 540, 540, 4320, 8640, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 540, 8640, 4320, 4320, 540, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 540, 8640, 4320, 4320, 4320, 8640, 8640, 540, 540, 4320, 540, 8640, 540, 540, 8640, 540, 4320, 4320, 540, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 540, 540, 8640, 4320, 8640, 540, 4320, 8640, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 540, 540, 4320]
Prompts retrieved: 432000 . Total input tokens: 96291061 . Total output tokens: 86418789
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 120.2554527381435,
    "estimated_duration": 3600.040765460962,
    "input_throughput": 7202.843436879738,
    "output_throughput": 6335.577424240511,
    "total_throughput": 13538.420861120248,
    "itl": 95.5485003036971,
    "ttft": 1249393.2706196036,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 231,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7637059933505984,
    "arrivals": 143761,
    "finished_requests": 104039,
    "scheduler_time": 240.52995655092766
}
#Debug simulation 
Total elapsed time: 120.25562553899363. Arrivals time: 0.43150607869029045 Scheduler time: 119.56895073223859 Scheduler overhead time: 0.10044397786259651 Adapter cache time: 0.018453515600413084 Engine time: 0.09785107616335154 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_16-16-16/adapters_96_slots_16_rate_0.8-0.4-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_16-16-16/adapters_96_slots_16_rate_0.8-0.4-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 540, 8640, 4320, 540, 540, 4320, 8640, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 540, 8640, 4320, 4320, 540, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 540, 8640, 4320, 4320, 4320, 8640, 8640, 540, 540, 4320, 540, 8640, 540, 540, 8640, 540, 4320, 4320, 540, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 540, 540, 8640, 4320, 8640, 540, 4320, 8640, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 540, 540, 4320]
Prompts retrieved: 432000 . Total input tokens: 96291061 . Total output tokens: 86418789
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 121.11270111985505,
    "estimated_duration": 3600.074181114572,
    "input_throughput": 7179.042347399197,
    "output_throughput": 6309.366934480155,
    "total_throughput": 13488.40928187935,
    "itl": 95.59241519183526,
    "ttft": 1241352.3437374162,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 229,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6847215175325991,
    "arrivals": 143761,
    "finished_requests": 103722,
    "scheduler_time": 241.81394842082454
}
#Debug simulation 
Total elapsed time: 121.11288912501186. Arrivals time: 0.40079774474725127 Scheduler time: 120.45721717691049 Scheduler overhead time: 0.10035725124180317 Adapter cache time: 0.018189555499702692 Engine time: 0.09781222976744175 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_16-16-32/adapters_96_slots_16_rate_0.8-0.4-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_16-16-32/adapters_96_slots_16_rate_0.8-0.4-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 540, 8640, 4320, 540, 540, 4320, 8640, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 540, 8640, 4320, 4320, 540, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 540, 8640, 4320, 4320, 4320, 8640, 8640, 540, 540, 4320, 540, 8640, 540, 540, 8640, 540, 4320, 4320, 540, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 540, 540, 8640, 4320, 8640, 540, 4320, 8640, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 540, 540, 4320]
Prompts retrieved: 432000 . Total input tokens: 96291061 . Total output tokens: 86418789
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 117.287861822173,
    "estimated_duration": 3600.0182203379463,
    "input_throughput": 7142.029130504338,
    "output_throughput": 6281.759040063164,
    "total_throughput": 13423.788170567503,
    "itl": 95.19912782909445,
    "ttft": 1260252.07785995,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 232,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7773985701799421,
    "arrivals": 143761,
    "finished_requests": 103191,
    "scheduler_time": 243.0569032887694
}
#Debug simulation 
Total elapsed time: 117.28799691330642. Arrivals time: 0.4026168119162321 Scheduler time: 116.631850566715 Scheduler overhead time: 0.1006710147485137 Adapter cache time: 0.018134789541363716 Engine time: 0.09725782927125692 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-8/adapters_96_slots_16_rate_0.8-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-8/adapters_96_slots_16_rate_0.8-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 270, 8640, 4320, 270, 270, 4320, 8640, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 8640, 4320, 4320, 270, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 270, 8640, 4320, 4320, 4320, 8640, 8640, 270, 270, 4320, 270, 8640, 270, 270, 8640, 270, 4320, 4320, 270, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 270, 270, 8640, 4320, 8640, 270, 4320, 8640, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 270, 270, 4320]
Prompts retrieved: 423360 . Total input tokens: 94371362 . Total output tokens: 84676963
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 136.78097726078704,
    "estimated_duration": 3600.1048043385726,
    "input_throughput": 6968.021311426471,
    "output_throughput": 6141.939527247304,
    "total_throughput": 13109.960838673775,
    "itl": 96.58541466176632,
    "ttft": 1291213.6090112887,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 176,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.538645842932164,
    "arrivals": 140843,
    "finished_requests": 100903,
    "scheduler_time": 249.31113464387988
}
#Debug simulation 
Total elapsed time: 136.78111351188272. Arrivals time: 0.39754856564104557 Scheduler time: 136.11653664289042 Scheduler overhead time: 0.10755497869104147 Adapter cache time: 0.018602811731398106 Engine time: 0.10160276154056191 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-16/adapters_96_slots_16_rate_0.8-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-16/adapters_96_slots_16_rate_0.8-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 270, 8640, 4320, 270, 270, 4320, 8640, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 8640, 4320, 4320, 270, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 270, 8640, 4320, 4320, 4320, 8640, 8640, 270, 270, 4320, 270, 8640, 270, 270, 8640, 270, 4320, 4320, 270, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 270, 270, 8640, 4320, 8640, 270, 4320, 8640, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 270, 270, 4320]
Prompts retrieved: 423360 . Total input tokens: 94371362 . Total output tokens: 84676963
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 128.52551690023392,
    "estimated_duration": 3600.0112415792505,
    "input_throughput": 6988.742620971101,
    "output_throughput": 6147.258026419923,
    "total_throughput": 13136.000647391023,
    "itl": 96.85583771003174,
    "ttft": 1296481.60762367,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 185,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6017821474513052,
    "arrivals": 140843,
    "finished_requests": 101231,
    "scheduler_time": 248.36354058692655
}
#Debug simulation 
Total elapsed time: 128.52569821709767. Arrivals time: 0.3969105379655957 Scheduler time: 127.86648165248334 Scheduler overhead time: 0.10497623402625322 Adapter cache time: 0.018454674631357193 Engine time: 0.10048469342291355 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-32/adapters_96_slots_16_rate_0.8-0.4-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-32/adapters_96_slots_16_rate_0.8-0.4-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 270, 8640, 4320, 270, 270, 4320, 8640, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 8640, 4320, 4320, 270, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 270, 8640, 4320, 4320, 4320, 8640, 8640, 270, 270, 4320, 270, 8640, 270, 270, 8640, 270, 4320, 4320, 270, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 270, 270, 8640, 4320, 8640, 270, 4320, 8640, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 270, 270, 4320]
Prompts retrieved: 423360 . Total input tokens: 94371362 . Total output tokens: 84676963
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 128.74617411196232,
    "estimated_duration": 3600.0127346862746,
    "input_throughput": 6988.7397223867165,
    "output_throughput": 6147.255476841681,
    "total_throughput": 13135.995199228399,
    "itl": 96.85587060164868,
    "ttft": 1296482.3034085543,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 185,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6031834388710582,
    "arrivals": 140843,
    "finished_requests": 101231,
    "scheduler_time": 248.36363240252786
}
#Debug simulation 
Total elapsed time: 128.7463117800653. Arrivals time: 0.39775798888877034 Scheduler time: 128.08267280552536 Scheduler overhead time: 0.1063668467104435 Adapter cache time: 0.01853476883843541 Engine time: 0.10107657266780734 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-16-16/adapters_96_slots_16_rate_0.8-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-16-16/adapters_96_slots_16_rate_0.8-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 270, 8640, 4320, 270, 270, 4320, 8640, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 8640, 4320, 4320, 270, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 270, 8640, 4320, 4320, 4320, 8640, 8640, 270, 270, 4320, 270, 8640, 270, 270, 8640, 270, 4320, 4320, 270, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 270, 270, 8640, 4320, 8640, 270, 4320, 8640, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 270, 270, 4320]
Prompts retrieved: 423360 . Total input tokens: 94371362 . Total output tokens: 84676963
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 128.88597029820085,
    "estimated_duration": 3600.1122652874446,
    "input_throughput": 6988.60900605586,
    "output_throughput": 6147.285798109131,
    "total_throughput": 13135.894804164991,
    "itl": 96.85621417345723,
    "ttft": 1296442.7622372182,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 185,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5776750236633243,
    "arrivals": 140843,
    "finished_requests": 101234,
    "scheduler_time": 248.37073461550665
}
#Debug simulation 
Total elapsed time: 128.8861277261749. Arrivals time: 0.4011612362228334 Scheduler time: 128.2226927978918 Scheduler overhead time: 0.10411674622446299 Adapter cache time: 0.018368623219430447 Engine time: 0.10058405064046383 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-16-32/adapters_96_slots_16_rate_0.8-0.4-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-16-32/adapters_96_slots_16_rate_0.8-0.4-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 270, 8640, 4320, 270, 270, 4320, 8640, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 8640, 4320, 4320, 270, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 270, 8640, 4320, 4320, 4320, 8640, 8640, 270, 270, 4320, 270, 8640, 270, 270, 8640, 270, 4320, 4320, 270, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 270, 270, 8640, 4320, 8640, 270, 4320, 8640, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 270, 270, 4320]
Prompts retrieved: 423360 . Total input tokens: 94371362 . Total output tokens: 84676963
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 128.9888462498784,
    "estimated_duration": 3600.020822691072,
    "input_throughput": 6988.724021099644,
    "output_throughput": 6147.241666079401,
    "total_throughput": 13135.965687179045,
    "itl": 96.85582901848421,
    "ttft": 1296485.9284034658,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 185,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6106029122695343,
    "arrivals": 140843,
    "finished_requests": 101231,
    "scheduler_time": 248.36400081818152
}
#Debug simulation 
Total elapsed time: 128.98904206883162. Arrivals time: 0.5150571935810149 Scheduler time: 128.20564515097067 Scheduler overhead time: 0.10749239567667246 Adapter cache time: 0.019545244984328747 Engine time: 0.10178695246577263 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_16-16-16/adapters_96_slots_16_rate_0.8-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_16-16-16/adapters_96_slots_16_rate_0.8-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 270, 8640, 4320, 270, 270, 4320, 8640, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 8640, 4320, 4320, 270, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 270, 8640, 4320, 4320, 4320, 8640, 8640, 270, 270, 4320, 270, 8640, 270, 270, 8640, 270, 4320, 4320, 270, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 270, 270, 8640, 4320, 8640, 270, 4320, 8640, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 270, 270, 4320]
Prompts retrieved: 423360 . Total input tokens: 94371362 . Total output tokens: 84676963
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 136.6156167211011,
    "estimated_duration": 3600.092031975821,
    "input_throughput": 6968.046032487783,
    "output_throughput": 6141.9613175457025,
    "total_throughput": 13110.007350033486,
    "itl": 96.58491573448401,
    "ttft": 1291208.0485890715,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 176,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5262488519027836,
    "arrivals": 140843,
    "finished_requests": 100903,
    "scheduler_time": 249.31055919496262
}
#Debug simulation 
Total elapsed time: 136.61576123628765. Arrivals time: 0.4069361216388643 Scheduler time: 135.94206303544343 Scheduler overhead time: 0.10743865417316556 Adapter cache time: 0.018373672850430012 Engine time: 0.10197475086897612 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_16-16-32/adapters_96_slots_16_rate_0.8-0.4-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_16-16-32/adapters_96_slots_16_rate_0.8-0.4-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 270, 8640, 4320, 270, 270, 4320, 8640, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 8640, 4320, 4320, 270, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 270, 8640, 4320, 4320, 4320, 8640, 8640, 270, 270, 4320, 270, 8640, 270, 270, 8640, 270, 4320, 4320, 270, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 270, 270, 8640, 4320, 8640, 270, 4320, 8640, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 270, 270, 4320]
Prompts retrieved: 423360 . Total input tokens: 94371362 . Total output tokens: 84676963
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 129.07982267905027,
    "estimated_duration": 3600.028859918502,
    "input_throughput": 6988.708418456836,
    "output_throughput": 6147.22794208405,
    "total_throughput": 13135.936360540885,
    "itl": 96.85599964304681,
    "ttft": 1296489.4271547026,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 185,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6181481394544255,
    "arrivals": 140843,
    "finished_requests": 101231,
    "scheduler_time": 248.36429600788892
}
#Debug simulation 
Total elapsed time: 129.0799607639201. Arrivals time: 0.4035352268256247 Scheduler time: 128.41104813478887 Scheduler overhead time: 0.10602762410417199 Adapter cache time: 0.018603492062538862 Engine time: 0.10196443274617195 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-8/adapters_96_slots_16_rate_0.8-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-8/adapters_96_slots_16_rate_0.8-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 135, 8640, 4320, 135, 135, 4320, 8640, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 8640, 4320, 4320, 135, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 135, 8640, 4320, 4320, 4320, 8640, 8640, 135, 135, 4320, 135, 8640, 135, 135, 8640, 135, 4320, 4320, 135, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 135, 135, 8640, 4320, 8640, 135, 4320, 8640, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 135, 135, 4320]
Prompts retrieved: 419040 . Total input tokens: 93435824 . Total output tokens: 83813115
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 113.37860002322122,
    "estimated_duration": 3600.107721940224,
    "input_throughput": 7307.082740797162,
    "output_throughput": 6411.927859636217,
    "total_throughput": 13719.01060043338,
    "itl": 98.17125521272466,
    "ttft": 1181120.2186575567,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 229,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7008516933605997,
    "arrivals": 139377,
    "finished_requests": 105612,
    "scheduler_time": 230.22076145738015
}
#Debug simulation 
Total elapsed time: 113.37878907937557. Arrivals time: 0.40437623765319586 Scheduler time: 112.72341436939314 Scheduler overhead time: 0.0993697615340352 Adapter cache time: 0.017834538128226995 Engine time: 0.09673552261665463 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-16/adapters_96_slots_16_rate_0.8-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-16/adapters_96_slots_16_rate_0.8-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 135, 8640, 4320, 135, 135, 4320, 8640, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 8640, 4320, 4320, 135, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 135, 8640, 4320, 4320, 4320, 8640, 8640, 135, 135, 4320, 135, 8640, 135, 135, 8640, 135, 4320, 4320, 135, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 135, 135, 8640, 4320, 8640, 135, 4320, 8640, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 135, 135, 4320]
Prompts retrieved: 419040 . Total input tokens: 93435824 . Total output tokens: 83813115
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 113.50569943571463,
    "estimated_duration": 3600.0069918674867,
    "input_throughput": 7306.822197685401,
    "output_throughput": 6411.7389361030555,
    "total_throughput": 13718.561133788457,
    "itl": 98.17139180357952,
    "ttft": 1181192.6392405352,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 229,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7476451965724147,
    "arrivals": 139377,
    "finished_requests": 105608,
    "scheduler_time": 230.20999128947227
}
#Debug simulation 
Total elapsed time: 113.505838887766. Arrivals time: 0.40238240314647555 Scheduler time: 112.85518702119589 Scheduler overhead time: 0.09872305346652865 Adapter cache time: 0.017762911040335894 Engine time: 0.09496457036584616 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-32/adapters_96_slots_16_rate_0.8-0.4-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-32/adapters_96_slots_16_rate_0.8-0.4-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 135, 8640, 4320, 135, 135, 4320, 8640, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 8640, 4320, 4320, 135, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 135, 8640, 4320, 4320, 4320, 8640, 8640, 135, 135, 4320, 135, 8640, 135, 135, 8640, 135, 4320, 4320, 135, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 135, 135, 8640, 4320, 8640, 135, 4320, 8640, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 135, 135, 4320]
Prompts retrieved: 419040 . Total input tokens: 93435824 . Total output tokens: 83813115
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 112.94178988505155,
    "estimated_duration": 3600.008333086597,
    "input_throughput": 7306.819475455712,
    "output_throughput": 6411.7365473455875,
    "total_throughput": 13718.5560228013,
    "itl": 98.1713932122102,
    "ttft": 1181193.0270111808,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 229,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7489019305259024,
    "arrivals": 139377,
    "finished_requests": 105608,
    "scheduler_time": 230.21007577461785
}
#Debug simulation 
Total elapsed time: 112.94192629028112. Arrivals time: 0.39890061458572745 Scheduler time: 112.29316149558872 Scheduler overhead time: 0.0985278319567442 Adapter cache time: 0.017683885991573334 Engine time: 0.09653615904971957 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-16/adapters_96_slots_16_rate_0.8-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-16/adapters_96_slots_16_rate_0.8-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 135, 8640, 4320, 135, 135, 4320, 8640, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 8640, 4320, 4320, 135, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 135, 8640, 4320, 4320, 4320, 8640, 8640, 135, 135, 4320, 135, 8640, 135, 135, 8640, 135, 4320, 4320, 135, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 135, 135, 8640, 4320, 8640, 135, 4320, 8640, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 135, 135, 4320]
Prompts retrieved: 419040 . Total input tokens: 93435824 . Total output tokens: 83813115
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 112.8427071319893,
    "estimated_duration": 3600.0608763096407,
    "input_throughput": 7293.7494398474055,
    "output_throughput": 6404.565587133946,
    "total_throughput": 13698.31502698135,
    "itl": 97.93318736803427,
    "ttft": 1184225.3063713799,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 240,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7511168868886328,
    "arrivals": 139377,
    "finished_requests": 105491,
    "scheduler_time": 230.43611510254985
}
#Debug simulation 
Total elapsed time: 112.84289837721735. Arrivals time: 0.39910794887691736 Scheduler time: 112.19345155963674 Scheduler overhead time: 0.09929999196901917 Adapter cache time: 0.018299506045877934 Engine time: 0.09595442516729236 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-32/adapters_96_slots_16_rate_0.8-0.4-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-32/adapters_96_slots_16_rate_0.8-0.4-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 135, 8640, 4320, 135, 135, 4320, 8640, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 8640, 4320, 4320, 135, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 135, 8640, 4320, 4320, 4320, 8640, 8640, 135, 135, 4320, 135, 8640, 135, 135, 8640, 135, 4320, 4320, 135, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 135, 135, 8640, 4320, 8640, 135, 4320, 8640, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 135, 135, 4320]
Prompts retrieved: 419040 . Total input tokens: 93435824 . Total output tokens: 83813115
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 114.23924631578848,
    "estimated_duration": 3600.105820438178,
    "input_throughput": 7313.552799066157,
    "output_throughput": 6419.210198989997,
    "total_throughput": 13732.762998056154,
    "itl": 98.18699816174663,
    "ttft": 1180610.7237472918,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 234,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7756145575828881,
    "arrivals": 139377,
    "finished_requests": 105717,
    "scheduler_time": 229.85290064569082
}
#Debug simulation 
Total elapsed time: 114.23939116066322. Arrivals time: 0.40422960463911295 Scheduler time: 113.58151626819745 Scheduler overhead time: 0.1000515278428793 Adapter cache time: 0.01799116376787424 Engine time: 0.0984506793320179 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-16/adapters_96_slots_16_rate_0.8-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-16/adapters_96_slots_16_rate_0.8-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 135, 8640, 4320, 135, 135, 4320, 8640, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 8640, 4320, 4320, 135, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 135, 8640, 4320, 4320, 4320, 8640, 8640, 135, 135, 4320, 135, 8640, 135, 135, 8640, 135, 4320, 4320, 135, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 135, 135, 8640, 4320, 8640, 135, 4320, 8640, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 135, 135, 4320]
Prompts retrieved: 419040 . Total input tokens: 93435824 . Total output tokens: 83813115
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 113.53662007115781,
    "estimated_duration": 3600.112877632129,
    "input_throughput": 7307.072276384347,
    "output_throughput": 6411.91867716731,
    "total_throughput": 13718.990953551658,
    "itl": 98.1702869259742,
    "ttft": 1181119.0312624648,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 229,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6847215175325991,
    "arrivals": 139377,
    "finished_requests": 105612,
    "scheduler_time": 230.2236489090916
}
#Debug simulation 
Total elapsed time: 113.53676124708727. Arrivals time: 0.4060262469574809 Scheduler time: 112.87886175746098 Scheduler overhead time: 0.09940965194255114 Adapter cache time: 0.017802173271775246 Engine time: 0.09663053508847952 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-32/adapters_96_slots_16_rate_0.8-0.4-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-32/adapters_96_slots_16_rate_0.8-0.4-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 135, 8640, 4320, 135, 135, 4320, 8640, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 8640, 4320, 4320, 135, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 135, 8640, 4320, 4320, 4320, 8640, 8640, 135, 135, 4320, 135, 8640, 135, 135, 8640, 135, 4320, 4320, 135, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 135, 135, 8640, 4320, 8640, 135, 4320, 8640, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 135, 135, 4320]
Prompts retrieved: 419040 . Total input tokens: 93435824 . Total output tokens: 83813115
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 114.38296296074986,
    "estimated_duration": 3600.117488123118,
    "input_throughput": 7313.529096442525,
    "output_throughput": 6419.189394857239,
    "total_throughput": 13732.718491299764,
    "itl": 98.18740037591519,
    "ttft": 1180615.8369063176,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 234,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7858006142824918,
    "arrivals": 139377,
    "finished_requests": 105717,
    "scheduler_time": 229.85372645063535
}
#Debug simulation 
Total elapsed time: 114.38315390981734. Arrivals time: 0.3978224345482886 Scheduler time: 113.73413587082177 Scheduler overhead time: 0.09969629254192114 Adapter cache time: 0.017652776557952166 Engine time: 0.09650794882327318 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-8/adapters_96_slots_16_rate_0.8-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-8/adapters_96_slots_16_rate_0.8-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 66, 8640, 66, 66, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 66, 8640, 4320, 66, 66, 4320, 8640, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 66, 8640, 4320, 4320, 66, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 66, 8640, 4320, 4320, 4320, 8640, 8640, 66, 66, 4320, 66, 8640, 66, 66, 8640, 66, 4320, 4320, 66, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 66, 66, 8640, 4320, 8640, 66, 4320, 8640, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 66, 66, 4320]
Prompts retrieved: 416832 . Total input tokens: 92923418 . Total output tokens: 83384390
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 118.42796522099525,
    "estimated_duration": 3600.0816321897346,
    "input_throughput": 7136.021797476299,
    "output_throughput": 6332.830565881581,
    "total_throughput": 13468.85236335788,
    "itl": 99.95911066829909,
    "ttft": 1221879.0136206807,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 215,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6580048649455412,
    "arrivals": 138774,
    "finished_requests": 104087,
    "scheduler_time": 235.9574541643822
}
#Debug simulation 
Total elapsed time: 118.42810609797016. Arrivals time: 0.4046234688721597 Scheduler time: 117.76594259683043 Scheduler overhead time: 0.10238701896741986 Adapter cache time: 0.018340814858675003 Engine time: 0.09832097496837378 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-16/adapters_96_slots_16_rate_0.8-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-16/adapters_96_slots_16_rate_0.8-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 66, 8640, 66, 66, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 66, 8640, 4320, 66, 66, 4320, 8640, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 66, 8640, 4320, 4320, 66, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 66, 8640, 4320, 4320, 4320, 8640, 8640, 66, 66, 4320, 66, 8640, 66, 66, 8640, 66, 4320, 4320, 66, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 66, 66, 8640, 4320, 8640, 66, 4320, 8640, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 66, 66, 4320]
Prompts retrieved: 416832 . Total input tokens: 92923418 . Total output tokens: 83384390
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 132.27242936519906,
    "estimated_duration": 3600.0079060683393,
    "input_throughput": 6999.5151837096155,
    "output_throughput": 6192.971121651969,
    "total_throughput": 13192.486305361585,
    "itl": 96.3009130264383,
    "ttft": 1256887.3109416338,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 210,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6838881205557865,
    "arrivals": 138774,
    "finished_requests": 101887,
    "scheduler_time": 243.7005850746508
}
#Debug simulation 
Total elapsed time: 132.27257020026445. Arrivals time: 0.4019381874240935 Scheduler time: 131.6054964917712 Scheduler overhead time: 0.10602824110537767 Adapter cache time: 0.018602825701236725 Engine time: 0.10158975282683969 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-32/adapters_96_slots_16_rate_0.8-0.4-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-32/adapters_96_slots_16_rate_0.8-0.4-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 66, 8640, 66, 66, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 66, 8640, 4320, 66, 66, 4320, 8640, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 66, 8640, 4320, 4320, 66, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 66, 8640, 4320, 4320, 4320, 8640, 8640, 66, 66, 4320, 66, 8640, 66, 66, 8640, 66, 4320, 4320, 66, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 66, 66, 8640, 4320, 8640, 66, 4320, 8640, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 66, 66, 4320]
Prompts retrieved: 416832 . Total input tokens: 92923418 . Total output tokens: 83384390
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 132.10080680297688,
    "estimated_duration": 3600.0091324418504,
    "input_throughput": 6999.512799265661,
    "output_throughput": 6192.96901196406,
    "total_throughput": 13192.481811229722,
    "itl": 96.30092674409964,
    "ttft": 1256887.8558415212,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 210,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6853418649919361,
    "arrivals": 138774,
    "finished_requests": 101887,
    "scheduler_time": 243.70065781946045
}
#Debug simulation 
Total elapsed time: 132.10099060600623. Arrivals time: 0.40277330158278346 Scheduler time: 131.43158676009625 Scheduler overhead time: 0.10708401864394546 Adapter cache time: 0.018888358492404222 Engine time: 0.10126988729462028 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-16/adapters_96_slots_16_rate_0.8-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-16/adapters_96_slots_16_rate_0.8-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 66, 8640, 66, 66, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 66, 8640, 4320, 66, 66, 4320, 8640, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 66, 8640, 4320, 4320, 66, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 66, 8640, 4320, 4320, 4320, 8640, 8640, 66, 66, 4320, 66, 8640, 66, 66, 8640, 66, 4320, 4320, 66, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 66, 66, 8640, 4320, 8640, 66, 4320, 8640, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 66, 66, 4320]
Prompts retrieved: 416832 . Total input tokens: 92923418 . Total output tokens: 83384390
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 118.04313140688464,
    "estimated_duration": 3600.085674512163,
    "input_throughput": 7137.349864175624,
    "output_throughput": 6333.795931978719,
    "total_throughput": 13471.145796154344,
    "itl": 99.96406785333598,
    "ttft": 1221563.7217880648,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 215,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.673096866968555,
    "arrivals": 138774,
    "finished_requests": 104104,
    "scheduler_time": 235.8877293412589
}
#Debug simulation 
Total elapsed time: 118.04326890874654. Arrivals time: 0.4014907875098288 Scheduler time: 117.38529321039096 Scheduler overhead time: 0.10208163969218731 Adapter cache time: 0.0180955627001822 Engine time: 0.09892255300655961 
