INFO 06-01 00:47:14 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:47:14 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-8/adapters_256_slots_32_rate_3.2-0.4-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-8/adapters_256_slots_32_rate_3.2-0.4-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 540, 34560, 34560, 540, 34560, 4320, 34560, 540, 4320, 540, 34560, 4320, 4320, 4320, 4320, 34560, 540, 540, 540, 4320, 34560, 540, 34560, 34560, 4320, 4320, 4320, 540, 34560, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 34560, 4320, 540, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 540, 34560, 34560, 4320, 540, 540, 34560, 4320, 540, 4320, 4320, 34560, 4320, 540, 540, 34560, 34560, 34560, 34560, 34560, 34560, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 34560, 34560, 540, 34560, 540, 4320, 34560, 34560, 34560, 4320, 540, 34560, 4320, 540, 540, 540, 540, 540, 34560, 4320, 540, 34560, 540, 34560, 540, 540, 4320, 4320, 34560, 4320, 34560, 540, 4320, 540, 34560, 34560, 540, 34560, 4320, 540, 34560, 540, 540, 34560, 34560, 4320, 34560, 34560, 540, 34560, 4320, 4320, 540, 4320, 34560, 34560, 540, 34560, 4320, 540, 4320, 34560, 540, 540, 540, 540, 540, 540, 34560, 540, 540, 540, 34560, 540, 4320, 34560, 34560, 4320, 540, 34560, 540, 4320, 4320, 540, 4320, 540, 34560, 540, 540, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 34560, 540, 34560, 540, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 4320, 4320, 540, 4320, 34560, 4320, 4320, 34560, 540, 34560, 34560, 4320, 540, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 540, 34560, 4320, 34560, 34560, 540, 34560, 4320, 4320, 34560, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 540, 540, 540, 540]
Prompts retrieved: 3385260 . Total input tokens: 754628110 . Total output tokens: 677025174
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 101.63818126078695,
    "estimated_duration": 3600.0116247258748,
    "input_throughput": 7318.61220087205,
    "output_throughput": 6488.447103772518,
    "total_throughput": 13807.059304644568,
    "itl": 121.33045643476356,
    "ttft": 1995560.6168072727,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 403,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2333765608049065,
    "arrivals": 1127186,
    "finished_requests": 106847,
    "scheduler_time": 229.08065092896706
}
#Debug simulation 
Total elapsed time: 101.63840898498893. Arrivals time: 0.7231233878992498 Scheduler time: 100.71874800790101 Scheduler overhead time: 0.0774735570885241 Adapter cache time: 0.017684323713183403 Engine time: 0.07410297822207212 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-16/adapters_256_slots_32_rate_3.2-0.4-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-16/adapters_256_slots_32_rate_3.2-0.4-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 540, 34560, 34560, 540, 34560, 4320, 34560, 540, 4320, 540, 34560, 4320, 4320, 4320, 4320, 34560, 540, 540, 540, 4320, 34560, 540, 34560, 34560, 4320, 4320, 4320, 540, 34560, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 34560, 4320, 540, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 540, 34560, 34560, 4320, 540, 540, 34560, 4320, 540, 4320, 4320, 34560, 4320, 540, 540, 34560, 34560, 34560, 34560, 34560, 34560, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 34560, 34560, 540, 34560, 540, 4320, 34560, 34560, 34560, 4320, 540, 34560, 4320, 540, 540, 540, 540, 540, 34560, 4320, 540, 34560, 540, 34560, 540, 540, 4320, 4320, 34560, 4320, 34560, 540, 4320, 540, 34560, 34560, 540, 34560, 4320, 540, 34560, 540, 540, 34560, 34560, 4320, 34560, 34560, 540, 34560, 4320, 4320, 540, 4320, 34560, 34560, 540, 34560, 4320, 540, 4320, 34560, 540, 540, 540, 540, 540, 540, 34560, 540, 540, 540, 34560, 540, 4320, 34560, 34560, 4320, 540, 34560, 540, 4320, 4320, 540, 4320, 540, 34560, 540, 540, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 34560, 540, 34560, 540, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 4320, 4320, 540, 4320, 34560, 4320, 4320, 34560, 540, 34560, 34560, 4320, 540, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 540, 34560, 4320, 34560, 34560, 540, 34560, 4320, 4320, 34560, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 540, 540, 540, 540]
Prompts retrieved: 3385260 . Total input tokens: 754628110 . Total output tokens: 677025174
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 104.61262144707143,
    "estimated_duration": 3600.0816946417763,
    "input_throughput": 7351.525672151029,
    "output_throughput": 6520.136205502322,
    "total_throughput": 13871.66187765335,
    "itl": 122.47043940564593,
    "ttft": 1999747.9111681092,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 396,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.293972057441721,
    "arrivals": 1127186,
    "finished_requests": 107346,
    "scheduler_time": 227.63982944691088
}
#Debug simulation 
Total elapsed time: 104.61282758973539. Arrivals time: 0.6698054629378021 Scheduler time: 103.74204539554194 Scheduler overhead time: 0.08049424318596721 Adapter cache time: 0.018191820476204157 Engine time: 0.07528702728450298 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-32/adapters_256_slots_32_rate_3.2-0.4-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-32/adapters_256_slots_32_rate_3.2-0.4-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 540, 34560, 34560, 540, 34560, 4320, 34560, 540, 4320, 540, 34560, 4320, 4320, 4320, 4320, 34560, 540, 540, 540, 4320, 34560, 540, 34560, 34560, 4320, 4320, 4320, 540, 34560, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 34560, 4320, 540, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 540, 34560, 34560, 4320, 540, 540, 34560, 4320, 540, 4320, 4320, 34560, 4320, 540, 540, 34560, 34560, 34560, 34560, 34560, 34560, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 34560, 34560, 540, 34560, 540, 4320, 34560, 34560, 34560, 4320, 540, 34560, 4320, 540, 540, 540, 540, 540, 34560, 4320, 540, 34560, 540, 34560, 540, 540, 4320, 4320, 34560, 4320, 34560, 540, 4320, 540, 34560, 34560, 540, 34560, 4320, 540, 34560, 540, 540, 34560, 34560, 4320, 34560, 34560, 540, 34560, 4320, 4320, 540, 4320, 34560, 34560, 540, 34560, 4320, 540, 4320, 34560, 540, 540, 540, 540, 540, 540, 34560, 540, 540, 540, 34560, 540, 4320, 34560, 34560, 4320, 540, 34560, 540, 4320, 4320, 540, 4320, 540, 34560, 540, 540, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 34560, 540, 34560, 540, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 4320, 4320, 540, 4320, 34560, 4320, 4320, 34560, 540, 34560, 34560, 4320, 540, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 540, 34560, 4320, 34560, 34560, 540, 34560, 4320, 4320, 34560, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 540, 540, 540, 540]
Prompts retrieved: 3385260 . Total input tokens: 754628110 . Total output tokens: 677025174
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 104.65239627985284,
    "estimated_duration": 3600.084286362468,
    "input_throughput": 7351.520379746828,
    "output_throughput": 6520.13151162002,
    "total_throughput": 13871.651891366848,
    "itl": 122.47048704952195,
    "ttft": 1999749.052281519,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 396,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2959530401416197,
    "arrivals": 1127186,
    "finished_requests": 107346,
    "scheduler_time": 227.63987465973872
}
#Debug simulation 
Total elapsed time: 104.65257663791999. Arrivals time: 0.6436688462272286 Scheduler time: 103.80989448772743 Scheduler overhead time: 0.07975854724645615 Adapter cache time: 0.017842366825789213 Engine time: 0.0748299672268331 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-16-16/adapters_256_slots_32_rate_3.2-0.4-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-16-16/adapters_256_slots_32_rate_3.2-0.4-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 540, 34560, 34560, 540, 34560, 4320, 34560, 540, 4320, 540, 34560, 4320, 4320, 4320, 4320, 34560, 540, 540, 540, 4320, 34560, 540, 34560, 34560, 4320, 4320, 4320, 540, 34560, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 34560, 4320, 540, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 540, 34560, 34560, 4320, 540, 540, 34560, 4320, 540, 4320, 4320, 34560, 4320, 540, 540, 34560, 34560, 34560, 34560, 34560, 34560, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 34560, 34560, 540, 34560, 540, 4320, 34560, 34560, 34560, 4320, 540, 34560, 4320, 540, 540, 540, 540, 540, 34560, 4320, 540, 34560, 540, 34560, 540, 540, 4320, 4320, 34560, 4320, 34560, 540, 4320, 540, 34560, 34560, 540, 34560, 4320, 540, 34560, 540, 540, 34560, 34560, 4320, 34560, 34560, 540, 34560, 4320, 4320, 540, 4320, 34560, 34560, 540, 34560, 4320, 540, 4320, 34560, 540, 540, 540, 540, 540, 540, 34560, 540, 540, 540, 34560, 540, 4320, 34560, 34560, 4320, 540, 34560, 540, 4320, 4320, 540, 4320, 540, 34560, 540, 540, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 34560, 540, 34560, 540, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 4320, 4320, 540, 4320, 34560, 4320, 4320, 34560, 540, 34560, 34560, 4320, 540, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 540, 34560, 4320, 34560, 34560, 540, 34560, 4320, 4320, 34560, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 540, 540, 540, 540]
Prompts retrieved: 3385260 . Total input tokens: 754628110 . Total output tokens: 677025174
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 101.92719459300861,
    "estimated_duration": 3600.0370333397177,
    "input_throughput": 7318.560547016949,
    "output_throughput": 6488.401309119471,
    "total_throughput": 13806.96185613642,
    "itl": 121.33073758409664,
    "ttft": 1995571.27654562,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 403,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2593334461981416,
    "arrivals": 1127186,
    "finished_requests": 106847,
    "scheduler_time": 229.08089439259027
}
#Debug simulation 
Total elapsed time: 101.92737756902352. Arrivals time: 0.6548258266411722 Scheduler time: 101.0733112054877 Scheduler overhead time: 0.0792220993898809 Adapter cache time: 0.018197018187493086 Engine time: 0.07470888458192348 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-16-32/adapters_256_slots_32_rate_3.2-0.4-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-16-32/adapters_256_slots_32_rate_3.2-0.4-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 540, 34560, 34560, 540, 34560, 4320, 34560, 540, 4320, 540, 34560, 4320, 4320, 4320, 4320, 34560, 540, 540, 540, 4320, 34560, 540, 34560, 34560, 4320, 4320, 4320, 540, 34560, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 34560, 4320, 540, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 540, 34560, 34560, 4320, 540, 540, 34560, 4320, 540, 4320, 4320, 34560, 4320, 540, 540, 34560, 34560, 34560, 34560, 34560, 34560, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 34560, 34560, 540, 34560, 540, 4320, 34560, 34560, 34560, 4320, 540, 34560, 4320, 540, 540, 540, 540, 540, 34560, 4320, 540, 34560, 540, 34560, 540, 540, 4320, 4320, 34560, 4320, 34560, 540, 4320, 540, 34560, 34560, 540, 34560, 4320, 540, 34560, 540, 540, 34560, 34560, 4320, 34560, 34560, 540, 34560, 4320, 4320, 540, 4320, 34560, 34560, 540, 34560, 4320, 540, 4320, 34560, 540, 540, 540, 540, 540, 540, 34560, 540, 540, 540, 34560, 540, 4320, 34560, 34560, 4320, 540, 34560, 540, 4320, 4320, 540, 4320, 540, 34560, 540, 540, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 34560, 540, 34560, 540, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 4320, 4320, 540, 4320, 34560, 4320, 4320, 34560, 540, 34560, 34560, 4320, 540, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 540, 34560, 4320, 34560, 34560, 540, 34560, 4320, 4320, 34560, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 540, 540, 540, 540]
Prompts retrieved: 3385260 . Total input tokens: 754628110 . Total output tokens: 677025174
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 104.81337887700647,
    "estimated_duration": 3600.1024773648346,
    "input_throughput": 7351.483233158511,
    "output_throughput": 6520.098565966805,
    "total_throughput": 13871.581799125315,
    "itl": 122.47088093404388,
    "ttft": 1999757.3549224471,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 396,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3130555550940377,
    "arrivals": 1127186,
    "finished_requests": 107346,
    "scheduler_time": 227.64005830690962
}
#Debug simulation 
Total elapsed time: 104.81356256222352. Arrivals time: 0.6421321080997586 Scheduler time: 103.97155272215605 Scheduler overhead time: 0.079652298707515 Adapter cache time: 0.01824505627155304 Engine time: 0.07475023297592998 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_16-16-16/adapters_256_slots_32_rate_3.2-0.4-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_16-16-16/adapters_256_slots_32_rate_3.2-0.4-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 540, 34560, 34560, 540, 34560, 4320, 34560, 540, 4320, 540, 34560, 4320, 4320, 4320, 4320, 34560, 540, 540, 540, 4320, 34560, 540, 34560, 34560, 4320, 4320, 4320, 540, 34560, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 34560, 4320, 540, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 540, 34560, 34560, 4320, 540, 540, 34560, 4320, 540, 4320, 4320, 34560, 4320, 540, 540, 34560, 34560, 34560, 34560, 34560, 34560, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 34560, 34560, 540, 34560, 540, 4320, 34560, 34560, 34560, 4320, 540, 34560, 4320, 540, 540, 540, 540, 540, 34560, 4320, 540, 34560, 540, 34560, 540, 540, 4320, 4320, 34560, 4320, 34560, 540, 4320, 540, 34560, 34560, 540, 34560, 4320, 540, 34560, 540, 540, 34560, 34560, 4320, 34560, 34560, 540, 34560, 4320, 4320, 540, 4320, 34560, 34560, 540, 34560, 4320, 540, 4320, 34560, 540, 540, 540, 540, 540, 540, 34560, 540, 540, 540, 34560, 540, 4320, 34560, 34560, 4320, 540, 34560, 540, 4320, 4320, 540, 4320, 540, 34560, 540, 540, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 34560, 540, 34560, 540, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 4320, 4320, 540, 4320, 34560, 4320, 4320, 34560, 540, 34560, 34560, 4320, 540, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 540, 34560, 4320, 34560, 34560, 540, 34560, 4320, 4320, 34560, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 540, 540, 540, 540]
Prompts retrieved: 3385260 . Total input tokens: 754628110 . Total output tokens: 677025174
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 102.13272786000744,
    "estimated_duration": 3600.125663135839,
    "input_throughput": 7318.617033231555,
    "output_throughput": 6488.706835764299,
    "total_throughput": 13807.323868995854,
    "itl": 121.33018079901147,
    "ttft": 1995580.994547487,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 403,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.204990268845571,
    "arrivals": 1127186,
    "finished_requests": 106852,
    "scheduler_time": 229.08905598577306
}
#Debug simulation 
Total elapsed time: 102.13291034987196. Arrivals time: 0.6393201090395451 Scheduler time: 101.29653281811625 Scheduler overhead time: 0.0785312750376761 Adapter cache time: 0.017645216546952724 Engine time: 0.07385320914909244 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_16-16-32/adapters_256_slots_32_rate_3.2-0.4-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_16-16-32/adapters_256_slots_32_rate_3.2-0.4-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 540, 34560, 34560, 540, 34560, 4320, 34560, 540, 4320, 540, 34560, 4320, 4320, 4320, 4320, 34560, 540, 540, 540, 4320, 34560, 540, 34560, 34560, 4320, 4320, 4320, 540, 34560, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 34560, 4320, 540, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 540, 34560, 34560, 4320, 540, 540, 34560, 4320, 540, 4320, 4320, 34560, 4320, 540, 540, 34560, 34560, 34560, 34560, 34560, 34560, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 34560, 34560, 540, 34560, 540, 4320, 34560, 34560, 34560, 4320, 540, 34560, 4320, 540, 540, 540, 540, 540, 34560, 4320, 540, 34560, 540, 34560, 540, 540, 4320, 4320, 34560, 4320, 34560, 540, 4320, 540, 34560, 34560, 540, 34560, 4320, 540, 34560, 540, 540, 34560, 34560, 4320, 34560, 34560, 540, 34560, 4320, 4320, 540, 4320, 34560, 34560, 540, 34560, 4320, 540, 4320, 34560, 540, 540, 540, 540, 540, 540, 34560, 540, 540, 540, 34560, 540, 4320, 34560, 34560, 4320, 540, 34560, 540, 4320, 4320, 540, 4320, 540, 34560, 540, 540, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 34560, 540, 34560, 540, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 4320, 4320, 540, 4320, 34560, 4320, 4320, 34560, 540, 34560, 34560, 4320, 540, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 540, 34560, 4320, 34560, 34560, 540, 34560, 4320, 4320, 34560, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 540, 540, 540, 540]
Prompts retrieved: 3385260 . Total input tokens: 754628110 . Total output tokens: 677025174
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 107.5868538361974,
    "estimated_duration": 3600.0909445229704,
    "input_throughput": 7359.054926183396,
    "output_throughput": 6522.4952263286295,
    "total_throughput": 13881.550152512025,
    "itl": 122.40770175931242,
    "ttft": 1996690.7062695941,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 395,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3253482859954258,
    "arrivals": 1127186,
    "finished_requests": 107346,
    "scheduler_time": 227.5130265071131
}
#Debug simulation 
Total elapsed time: 107.58711286727339. Arrivals time: 0.6130885677412152 Scheduler time: 106.77419332275167 Scheduler overhead time: 0.08012333558872342 Adapter cache time: 0.01744964998215437 Engine time: 0.07503026956692338 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-8/adapters_256_slots_32_rate_3.2-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-8/adapters_256_slots_32_rate_3.2-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 270, 34560, 34560, 270, 34560, 4320, 34560, 270, 4320, 270, 34560, 4320, 4320, 4320, 4320, 34560, 270, 270, 270, 4320, 34560, 270, 34560, 34560, 4320, 4320, 4320, 270, 34560, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 34560, 4320, 270, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 270, 34560, 34560, 4320, 270, 270, 34560, 4320, 270, 4320, 4320, 34560, 4320, 270, 270, 34560, 34560, 34560, 34560, 34560, 34560, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 34560, 34560, 270, 34560, 270, 4320, 34560, 34560, 34560, 4320, 270, 34560, 4320, 270, 270, 270, 270, 270, 34560, 4320, 270, 34560, 270, 34560, 270, 270, 4320, 4320, 34560, 4320, 34560, 270, 4320, 270, 34560, 34560, 270, 34560, 4320, 270, 34560, 270, 270, 34560, 34560, 4320, 34560, 34560, 270, 34560, 4320, 4320, 270, 4320, 34560, 34560, 270, 34560, 4320, 270, 4320, 34560, 270, 270, 270, 270, 270, 270, 34560, 270, 270, 270, 34560, 270, 4320, 34560, 34560, 4320, 270, 34560, 270, 4320, 4320, 270, 4320, 270, 34560, 270, 270, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 34560, 270, 34560, 270, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 4320, 4320, 270, 4320, 34560, 4320, 4320, 34560, 270, 34560, 34560, 4320, 270, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 270, 34560, 4320, 34560, 34560, 270, 34560, 4320, 4320, 34560, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 270, 270, 270, 270]
Prompts retrieved: 3362310 . Total input tokens: 749481355 . Total output tokens: 672460316
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 103.99744505481794,
    "estimated_duration": 3600.1414343483766,
    "input_throughput": 7367.613601769762,
    "output_throughput": 6562.07524921198,
    "total_throughput": 13929.688850981742,
    "itl": 123.52979999638373,
    "ttft": 1988769.4896756832,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 386,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.181348269158048,
    "arrivals": 1119422,
    "finished_requests": 107921,
    "scheduler_time": 225.26294080278694
}
#Debug simulation 
Total elapsed time: 103.99761693691835. Arrivals time: 0.7243763669393957 Scheduler time: 103.07861143816262 Scheduler overhead time: 0.07765902392566204 Adapter cache time: 0.01725603872910142 Engine time: 0.07292035967111588 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-16/adapters_256_slots_32_rate_3.2-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-16/adapters_256_slots_32_rate_3.2-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 270, 34560, 34560, 270, 34560, 4320, 34560, 270, 4320, 270, 34560, 4320, 4320, 4320, 4320, 34560, 270, 270, 270, 4320, 34560, 270, 34560, 34560, 4320, 4320, 4320, 270, 34560, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 34560, 4320, 270, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 270, 34560, 34560, 4320, 270, 270, 34560, 4320, 270, 4320, 4320, 34560, 4320, 270, 270, 34560, 34560, 34560, 34560, 34560, 34560, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 34560, 34560, 270, 34560, 270, 4320, 34560, 34560, 34560, 4320, 270, 34560, 4320, 270, 270, 270, 270, 270, 34560, 4320, 270, 34560, 270, 34560, 270, 270, 4320, 4320, 34560, 4320, 34560, 270, 4320, 270, 34560, 34560, 270, 34560, 4320, 270, 34560, 270, 270, 34560, 34560, 4320, 34560, 34560, 270, 34560, 4320, 4320, 270, 4320, 34560, 34560, 270, 34560, 4320, 270, 4320, 34560, 270, 270, 270, 270, 270, 270, 34560, 270, 270, 270, 34560, 270, 4320, 34560, 34560, 4320, 270, 34560, 270, 4320, 4320, 270, 4320, 270, 34560, 270, 270, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 34560, 270, 34560, 270, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 4320, 4320, 270, 4320, 34560, 4320, 4320, 34560, 270, 34560, 34560, 4320, 270, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 270, 34560, 4320, 34560, 34560, 270, 34560, 4320, 4320, 34560, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 270, 270, 270, 270]
Prompts retrieved: 3362310 . Total input tokens: 749481355 . Total output tokens: 672460316
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 104.7287937249057,
    "estimated_duration": 3600.0240591369925,
    "input_throughput": 7395.348353972457,
    "output_throughput": 6583.741833570362,
    "total_throughput": 13979.090187542819,
    "itl": 124.2184648011746,
    "ttft": 1987800.9346624382,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 396,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2935634621232812,
    "arrivals": 1119422,
    "finished_requests": 108165,
    "scheduler_time": 224.30108360447525
}
#Debug simulation 
Total elapsed time: 104.72896302305162. Arrivals time: 0.6324516381137073 Scheduler time: 103.89997832942754 Scheduler overhead time: 0.0779769723303616 Adapter cache time: 0.01743187801912427 Engine time: 0.07404455868527293 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-32/adapters_256_slots_32_rate_3.2-0.4-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-32/adapters_256_slots_32_rate_3.2-0.4-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 270, 34560, 34560, 270, 34560, 4320, 34560, 270, 4320, 270, 34560, 4320, 4320, 4320, 4320, 34560, 270, 270, 270, 4320, 34560, 270, 34560, 34560, 4320, 4320, 4320, 270, 34560, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 34560, 4320, 270, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 270, 34560, 34560, 4320, 270, 270, 34560, 4320, 270, 4320, 4320, 34560, 4320, 270, 270, 34560, 34560, 34560, 34560, 34560, 34560, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 34560, 34560, 270, 34560, 270, 4320, 34560, 34560, 34560, 4320, 270, 34560, 4320, 270, 270, 270, 270, 270, 34560, 4320, 270, 34560, 270, 34560, 270, 270, 4320, 4320, 34560, 4320, 34560, 270, 4320, 270, 34560, 34560, 270, 34560, 4320, 270, 34560, 270, 270, 34560, 34560, 4320, 34560, 34560, 270, 34560, 4320, 4320, 270, 4320, 34560, 34560, 270, 34560, 4320, 270, 4320, 34560, 270, 270, 270, 270, 270, 270, 34560, 270, 270, 270, 34560, 270, 4320, 34560, 34560, 4320, 270, 34560, 270, 4320, 4320, 270, 4320, 270, 34560, 270, 270, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 34560, 270, 34560, 270, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 4320, 4320, 270, 4320, 34560, 4320, 4320, 34560, 270, 34560, 34560, 4320, 270, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 270, 34560, 4320, 34560, 34560, 270, 34560, 4320, 4320, 34560, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 270, 270, 270, 270]
Prompts retrieved: 3362310 . Total input tokens: 749481355 . Total output tokens: 672460316
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 104.72872873721644,
    "estimated_duration": 3600.0262543809945,
    "input_throughput": 7395.343844395868,
    "output_throughput": 6583.7378188997045,
    "total_throughput": 13979.081663295572,
    "itl": 124.21851736569059,
    "ttft": 1987802.0830669426,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 396,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2956157926470115,
    "arrivals": 1119422,
    "finished_requests": 108165,
    "scheduler_time": 224.30111341291706
}
#Debug simulation 
Total elapsed time: 104.72889413032681. Arrivals time: 0.6514959214255214 Scheduler time: 103.88163451617584 Scheduler overhead time: 0.07790821744129062 Adapter cache time: 0.01744328858330846 Engine time: 0.07338249403983355 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-16-16/adapters_256_slots_32_rate_3.2-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-16-16/adapters_256_slots_32_rate_3.2-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 270, 34560, 34560, 270, 34560, 4320, 34560, 270, 4320, 270, 34560, 4320, 4320, 4320, 4320, 34560, 270, 270, 270, 4320, 34560, 270, 34560, 34560, 4320, 4320, 4320, 270, 34560, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 34560, 4320, 270, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 270, 34560, 34560, 4320, 270, 270, 34560, 4320, 270, 4320, 4320, 34560, 4320, 270, 270, 34560, 34560, 34560, 34560, 34560, 34560, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 34560, 34560, 270, 34560, 270, 4320, 34560, 34560, 34560, 4320, 270, 34560, 4320, 270, 270, 270, 270, 270, 34560, 4320, 270, 34560, 270, 34560, 270, 270, 4320, 4320, 34560, 4320, 34560, 270, 4320, 270, 34560, 34560, 270, 34560, 4320, 270, 34560, 270, 270, 34560, 34560, 4320, 34560, 34560, 270, 34560, 4320, 4320, 270, 4320, 34560, 34560, 270, 34560, 4320, 270, 4320, 34560, 270, 270, 270, 270, 270, 270, 34560, 270, 270, 270, 34560, 270, 4320, 34560, 34560, 4320, 270, 34560, 270, 4320, 4320, 270, 4320, 270, 34560, 270, 270, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 34560, 270, 34560, 270, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 4320, 4320, 270, 4320, 34560, 4320, 4320, 34560, 270, 34560, 34560, 4320, 270, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 270, 34560, 4320, 34560, 34560, 270, 34560, 4320, 4320, 34560, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 270, 270, 270, 270]
Prompts retrieved: 3362310 . Total input tokens: 749481355 . Total output tokens: 672460316
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 103.65768372314051,
    "estimated_duration": 3600.0207706263823,
    "input_throughput": 7367.85999025914,
    "output_throughput": 6562.120194625878,
    "total_throughput": 13929.980184885018,
    "itl": 123.52995451601333,
    "ttft": 1988736.9651220706,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 386,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.206051019274164,
    "arrivals": 1119422,
    "finished_requests": 107919,
    "scheduler_time": 225.25430849643845
}
#Debug simulation 
Total elapsed time: 103.65785838710144. Arrivals time: 0.6374062793329358 Scheduler time: 102.82571719400585 Scheduler overhead time: 0.07786135887727141 Adapter cache time: 0.01725056581199169 Engine time: 0.07324803899973631 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-16-32/adapters_256_slots_32_rate_3.2-0.4-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-16-32/adapters_256_slots_32_rate_3.2-0.4-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 270, 34560, 34560, 270, 34560, 4320, 34560, 270, 4320, 270, 34560, 4320, 4320, 4320, 4320, 34560, 270, 270, 270, 4320, 34560, 270, 34560, 34560, 4320, 4320, 4320, 270, 34560, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 34560, 4320, 270, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 270, 34560, 34560, 4320, 270, 270, 34560, 4320, 270, 4320, 4320, 34560, 4320, 270, 270, 34560, 34560, 34560, 34560, 34560, 34560, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 34560, 34560, 270, 34560, 270, 4320, 34560, 34560, 34560, 4320, 270, 34560, 4320, 270, 270, 270, 270, 270, 34560, 4320, 270, 34560, 270, 34560, 270, 270, 4320, 4320, 34560, 4320, 34560, 270, 4320, 270, 34560, 34560, 270, 34560, 4320, 270, 34560, 270, 270, 34560, 34560, 4320, 34560, 34560, 270, 34560, 4320, 4320, 270, 4320, 34560, 34560, 270, 34560, 4320, 270, 4320, 34560, 270, 270, 270, 270, 270, 270, 34560, 270, 270, 270, 34560, 270, 4320, 34560, 34560, 4320, 270, 34560, 270, 4320, 4320, 270, 4320, 270, 34560, 270, 270, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 34560, 270, 34560, 270, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 4320, 4320, 270, 4320, 34560, 4320, 4320, 34560, 270, 34560, 34560, 4320, 270, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 270, 34560, 4320, 34560, 34560, 270, 34560, 4320, 4320, 34560, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 270, 270, 270, 270]
Prompts retrieved: 3362310 . Total input tokens: 749481355 . Total output tokens: 672460316
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 104.91582115599886,
    "estimated_duration": 3600.042478537328,
    "input_throughput": 7395.310516118386,
    "output_throughput": 6583.70814825213,
    "total_throughput": 13979.018664370516,
    "itl": 124.21890727600451,
    "ttft": 1987809.1284716073,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 396,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3123410462401854,
    "arrivals": 1119422,
    "finished_requests": 108165,
    "scheduler_time": 224.30117784081637
}
#Debug simulation 
Total elapsed time: 104.91599248396233. Arrivals time: 0.6545933377929032 Scheduler time: 104.06436588708311 Scheduler overhead time: 0.07834984781220555 Adapter cache time: 0.017550084739923477 Engine time: 0.07434166967868805 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_16-16-16/adapters_256_slots_32_rate_3.2-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_16-16-16/adapters_256_slots_32_rate_3.2-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 270, 34560, 34560, 270, 34560, 4320, 34560, 270, 4320, 270, 34560, 4320, 4320, 4320, 4320, 34560, 270, 270, 270, 4320, 34560, 270, 34560, 34560, 4320, 4320, 4320, 270, 34560, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 34560, 4320, 270, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 270, 34560, 34560, 4320, 270, 270, 34560, 4320, 270, 4320, 4320, 34560, 4320, 270, 270, 34560, 34560, 34560, 34560, 34560, 34560, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 34560, 34560, 270, 34560, 270, 4320, 34560, 34560, 34560, 4320, 270, 34560, 4320, 270, 270, 270, 270, 270, 34560, 4320, 270, 34560, 270, 34560, 270, 270, 4320, 4320, 34560, 4320, 34560, 270, 4320, 270, 34560, 34560, 270, 34560, 4320, 270, 34560, 270, 270, 34560, 34560, 4320, 34560, 34560, 270, 34560, 4320, 4320, 270, 4320, 34560, 34560, 270, 34560, 4320, 270, 4320, 34560, 270, 270, 270, 270, 270, 270, 34560, 270, 270, 270, 34560, 270, 4320, 34560, 34560, 4320, 270, 34560, 270, 4320, 4320, 270, 4320, 270, 34560, 270, 270, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 34560, 270, 34560, 270, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 4320, 4320, 270, 4320, 34560, 4320, 4320, 34560, 270, 34560, 34560, 4320, 270, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 270, 34560, 4320, 34560, 34560, 270, 34560, 4320, 4320, 34560, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 270, 270, 270, 270]
Prompts retrieved: 3362310 . Total input tokens: 749481355 . Total output tokens: 672460316
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 104.24757247930393,
    "estimated_duration": 3600.114923893218,
    "input_throughput": 7367.66785525726,
    "output_throughput": 6562.123570892071,
    "total_throughput": 13929.791426149332,
    "itl": 123.52925331813786,
    "ttft": 1988758.2717668954,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 386,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1541594138322357,
    "arrivals": 1119422,
    "finished_requests": 107921,
    "scheduler_time": 225.26271436264443
}
#Debug simulation 
Total elapsed time: 104.24775369325653. Arrivals time: 0.7160582528449595 Scheduler time: 103.33575475588441 Scheduler overhead time: 0.07795572141185403 Adapter cache time: 0.017370604909956455 Engine time: 0.07390784099698067 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_16-16-32/adapters_256_slots_32_rate_3.2-0.4-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_16-16-32/adapters_256_slots_32_rate_3.2-0.4-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 270, 34560, 34560, 270, 34560, 4320, 34560, 270, 4320, 270, 34560, 4320, 4320, 4320, 4320, 34560, 270, 270, 270, 4320, 34560, 270, 34560, 34560, 4320, 4320, 4320, 270, 34560, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 34560, 4320, 270, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 270, 34560, 34560, 4320, 270, 270, 34560, 4320, 270, 4320, 4320, 34560, 4320, 270, 270, 34560, 34560, 34560, 34560, 34560, 34560, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 34560, 34560, 270, 34560, 270, 4320, 34560, 34560, 34560, 4320, 270, 34560, 4320, 270, 270, 270, 270, 270, 34560, 4320, 270, 34560, 270, 34560, 270, 270, 4320, 4320, 34560, 4320, 34560, 270, 4320, 270, 34560, 34560, 270, 34560, 4320, 270, 34560, 270, 270, 34560, 34560, 4320, 34560, 34560, 270, 34560, 4320, 4320, 270, 4320, 34560, 34560, 270, 34560, 4320, 270, 4320, 34560, 270, 270, 270, 270, 270, 270, 34560, 270, 270, 270, 34560, 270, 4320, 34560, 34560, 4320, 270, 34560, 270, 4320, 4320, 270, 4320, 270, 34560, 270, 270, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 34560, 270, 34560, 270, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 4320, 4320, 270, 4320, 34560, 4320, 4320, 34560, 270, 34560, 34560, 4320, 270, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 270, 34560, 4320, 34560, 34560, 270, 34560, 4320, 4320, 34560, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 270, 270, 270, 270]
Prompts retrieved: 3362310 . Total input tokens: 749481355 . Total output tokens: 672460316
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 104.54827190283686,
    "estimated_duration": 3600.0591803650286,
    "input_throughput": 7395.276206904052,
    "output_throughput": 6583.677604321151,
    "total_throughput": 13978.953811225203,
    "itl": 124.21930792391807,
    "ttft": 1987816.2476406586,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 396,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3293178074061889,
    "arrivals": 1119422,
    "finished_requests": 108165,
    "scheduler_time": 224.30124222244743
}
#Debug simulation 
Total elapsed time: 104.54855276690796. Arrivals time: 0.6577430064789951 Scheduler time: 103.69289599638432 Scheduler overhead time: 0.07928267540410161 Adapter cache time: 0.018023003824055195 Engine time: 0.07436516601592302 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-8/adapters_256_slots_32_rate_3.2-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-8/adapters_256_slots_32_rate_3.2-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 135, 34560, 34560, 135, 34560, 4320, 34560, 135, 4320, 135, 34560, 4320, 4320, 4320, 4320, 34560, 135, 135, 135, 4320, 34560, 135, 34560, 34560, 4320, 4320, 4320, 135, 34560, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 34560, 4320, 135, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 135, 34560, 34560, 4320, 135, 135, 34560, 4320, 135, 4320, 4320, 34560, 4320, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 34560, 34560, 135, 34560, 135, 4320, 34560, 34560, 34560, 4320, 135, 34560, 4320, 135, 135, 135, 135, 135, 34560, 4320, 135, 34560, 135, 34560, 135, 135, 4320, 4320, 34560, 4320, 34560, 135, 4320, 135, 34560, 34560, 135, 34560, 4320, 135, 34560, 135, 135, 34560, 34560, 4320, 34560, 34560, 135, 34560, 4320, 4320, 135, 4320, 34560, 34560, 135, 34560, 4320, 135, 4320, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 4320, 34560, 34560, 4320, 135, 34560, 135, 4320, 4320, 135, 4320, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 34560, 135, 34560, 135, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 4320, 4320, 135, 4320, 34560, 4320, 4320, 34560, 135, 34560, 34560, 4320, 135, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 135, 34560, 4320, 34560, 34560, 135, 34560, 4320, 4320, 34560, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 135, 135, 135, 135]
Prompts retrieved: 3350835 . Total input tokens: 746922044 . Total output tokens: 670198486
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 103.26081738062203,
    "estimated_duration": 3600.026704814461,
    "input_throughput": 7354.867663784348,
    "output_throughput": 6529.37573173126,
    "total_throughput": 13884.243395515608,
    "itl": 122.68219214415736,
    "ttft": 1975842.503178514,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 417,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2762233892199666,
    "arrivals": 1115519,
    "finished_requests": 107542,
    "scheduler_time": 228.0228705124278
}
#Debug simulation 
Total elapsed time: 103.26098839193583. Arrivals time: 0.6495565352961421 Scheduler time: 102.41172918817028 Scheduler overhead time: 0.07932463940232992 Adapter cache time: 0.01811595866456628 Engine time: 0.07478997902944684 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-16/adapters_256_slots_32_rate_3.2-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-16/adapters_256_slots_32_rate_3.2-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 135, 34560, 34560, 135, 34560, 4320, 34560, 135, 4320, 135, 34560, 4320, 4320, 4320, 4320, 34560, 135, 135, 135, 4320, 34560, 135, 34560, 34560, 4320, 4320, 4320, 135, 34560, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 34560, 4320, 135, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 135, 34560, 34560, 4320, 135, 135, 34560, 4320, 135, 4320, 4320, 34560, 4320, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 34560, 34560, 135, 34560, 135, 4320, 34560, 34560, 34560, 4320, 135, 34560, 4320, 135, 135, 135, 135, 135, 34560, 4320, 135, 34560, 135, 34560, 135, 135, 4320, 4320, 34560, 4320, 34560, 135, 4320, 135, 34560, 34560, 135, 34560, 4320, 135, 34560, 135, 135, 34560, 34560, 4320, 34560, 34560, 135, 34560, 4320, 4320, 135, 4320, 34560, 34560, 135, 34560, 4320, 135, 4320, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 4320, 34560, 34560, 4320, 135, 34560, 135, 4320, 4320, 135, 4320, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 34560, 135, 34560, 135, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 4320, 4320, 135, 4320, 34560, 4320, 4320, 34560, 135, 34560, 34560, 4320, 135, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 135, 34560, 4320, 34560, 34560, 135, 34560, 4320, 4320, 34560, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 135, 135, 135, 135]
Prompts retrieved: 3350835 . Total input tokens: 746922044 . Total output tokens: 670198486
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 103.47902926895767,
    "estimated_duration": 3600.0545886016616,
    "input_throughput": 7330.159960227171,
    "output_throughput": 6518.771430384184,
    "total_throughput": 13848.931390611355,
    "itl": 122.29300653094828,
    "ttft": 1978470.9323552414,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 418,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3642477124324133,
    "arrivals": 1115519,
    "finished_requests": 107337,
    "scheduler_time": 228.29490472625798
}
#Debug simulation 
Total elapsed time: 103.47920025372878. Arrivals time: 0.6510159377939999 Scheduler time: 102.62771202903241 Scheduler overhead time: 0.08066536579281092 Adapter cache time: 0.018212100956588984 Engine time: 0.07435962790623307 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-32/adapters_256_slots_32_rate_3.2-0.4-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-32/adapters_256_slots_32_rate_3.2-0.4-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 135, 34560, 34560, 135, 34560, 4320, 34560, 135, 4320, 135, 34560, 4320, 4320, 4320, 4320, 34560, 135, 135, 135, 4320, 34560, 135, 34560, 34560, 4320, 4320, 4320, 135, 34560, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 34560, 4320, 135, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 135, 34560, 34560, 4320, 135, 135, 34560, 4320, 135, 4320, 4320, 34560, 4320, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 34560, 34560, 135, 34560, 135, 4320, 34560, 34560, 34560, 4320, 135, 34560, 4320, 135, 135, 135, 135, 135, 34560, 4320, 135, 34560, 135, 34560, 135, 135, 4320, 4320, 34560, 4320, 34560, 135, 4320, 135, 34560, 34560, 135, 34560, 4320, 135, 34560, 135, 135, 34560, 34560, 4320, 34560, 34560, 135, 34560, 4320, 4320, 135, 4320, 34560, 34560, 135, 34560, 4320, 135, 4320, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 4320, 34560, 34560, 4320, 135, 34560, 135, 4320, 4320, 135, 4320, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 34560, 135, 34560, 135, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 4320, 4320, 135, 4320, 34560, 4320, 4320, 34560, 135, 34560, 34560, 4320, 135, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 135, 34560, 4320, 34560, 34560, 135, 34560, 4320, 4320, 34560, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 135, 135, 135, 135]
Prompts retrieved: 3350835 . Total input tokens: 746922044 . Total output tokens: 670198486
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 103.68007471598685,
    "estimated_duration": 3600.0569784122326,
    "input_throughput": 7330.155094278141,
    "output_throughput": 6518.767103055765,
    "total_throughput": 13848.922197333906,
    "itl": 122.29305824158025,
    "ttft": 1978472.091468623,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 418,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3666201772540887,
    "arrivals": 1115519,
    "finished_requests": 107337,
    "scheduler_time": 228.2949220719925
}
#Debug simulation 
Total elapsed time: 103.68024850124493. Arrivals time: 0.6554575157351792 Scheduler time: 102.82511797640473 Scheduler overhead time: 0.08014359092339873 Adapter cache time: 0.018266713712364435 Engine time: 0.07457456737756729 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-16/adapters_256_slots_32_rate_3.2-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-16/adapters_256_slots_32_rate_3.2-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 135, 34560, 34560, 135, 34560, 4320, 34560, 135, 4320, 135, 34560, 4320, 4320, 4320, 4320, 34560, 135, 135, 135, 4320, 34560, 135, 34560, 34560, 4320, 4320, 4320, 135, 34560, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 34560, 4320, 135, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 135, 34560, 34560, 4320, 135, 135, 34560, 4320, 135, 4320, 4320, 34560, 4320, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 34560, 34560, 135, 34560, 135, 4320, 34560, 34560, 34560, 4320, 135, 34560, 4320, 135, 135, 135, 135, 135, 34560, 4320, 135, 34560, 135, 34560, 135, 135, 4320, 4320, 34560, 4320, 34560, 135, 4320, 135, 34560, 34560, 135, 34560, 4320, 135, 34560, 135, 135, 34560, 34560, 4320, 34560, 34560, 135, 34560, 4320, 4320, 135, 4320, 34560, 34560, 135, 34560, 4320, 135, 4320, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 4320, 34560, 34560, 4320, 135, 34560, 135, 4320, 4320, 135, 4320, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 34560, 135, 34560, 135, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 4320, 4320, 135, 4320, 34560, 4320, 4320, 34560, 135, 34560, 34560, 4320, 135, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 135, 34560, 4320, 34560, 34560, 135, 34560, 4320, 4320, 34560, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 135, 135, 135, 135]
Prompts retrieved: 3350835 . Total input tokens: 746922044 . Total output tokens: 670198486
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 103.56650054408237,
    "estimated_duration": 3600.123546504681,
    "input_throughput": 7330.362599811874,
    "output_throughput": 6519.144884010019,
    "total_throughput": 13849.507483821893,
    "itl": 122.29065331653061,
    "ttft": 1978475.3539297206,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 418,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3070443678507573,
    "arrivals": 1115519,
    "finished_requests": 107344,
    "scheduler_time": 228.30242861302798
}
#Debug simulation 
Total elapsed time: 103.56667365413159. Arrivals time: 0.6521142674610019 Scheduler time: 102.71413588477299 Scheduler overhead time: 0.07938826875761151 Adapter cache time: 0.018343619536608458 Engine time: 0.07554505532607436 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-32/adapters_256_slots_32_rate_3.2-0.4-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-32/adapters_256_slots_32_rate_3.2-0.4-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 135, 34560, 34560, 135, 34560, 4320, 34560, 135, 4320, 135, 34560, 4320, 4320, 4320, 4320, 34560, 135, 135, 135, 4320, 34560, 135, 34560, 34560, 4320, 4320, 4320, 135, 34560, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 34560, 4320, 135, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 135, 34560, 34560, 4320, 135, 135, 34560, 4320, 135, 4320, 4320, 34560, 4320, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 34560, 34560, 135, 34560, 135, 4320, 34560, 34560, 34560, 4320, 135, 34560, 4320, 135, 135, 135, 135, 135, 34560, 4320, 135, 34560, 135, 34560, 135, 135, 4320, 4320, 34560, 4320, 34560, 135, 4320, 135, 34560, 34560, 135, 34560, 4320, 135, 34560, 135, 135, 34560, 34560, 4320, 34560, 34560, 135, 34560, 4320, 4320, 135, 4320, 34560, 34560, 135, 34560, 4320, 135, 4320, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 4320, 34560, 34560, 4320, 135, 34560, 135, 4320, 4320, 135, 4320, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 34560, 135, 34560, 135, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 4320, 4320, 135, 4320, 34560, 4320, 4320, 34560, 135, 34560, 34560, 4320, 135, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 135, 34560, 4320, 34560, 34560, 135, 34560, 4320, 4320, 34560, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 135, 135, 135, 135]
Prompts retrieved: 3350835 . Total input tokens: 746922044 . Total output tokens: 670198486
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 103.69239374063909,
    "estimated_duration": 3600.0750469696773,
    "input_throughput": 7330.118304676072,
    "output_throughput": 6518.734385760616,
    "total_throughput": 13848.852690436688,
    "itl": 122.2934834825756,
    "ttft": 1978479.8653633052,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 418,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.384225707352166,
    "arrivals": 1115519,
    "finished_requests": 107337,
    "scheduler_time": 228.2950457842591
}
#Debug simulation 
Total elapsed time: 103.6925605549477. Arrivals time: 0.6520392098464072 Scheduler time: 102.82719995267689 Scheduler overhead time: 0.07999738305807114 Adapter cache time: 0.018476441968232393 Engine time: 0.0756548154167831 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-16/adapters_256_slots_32_rate_3.2-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-16/adapters_256_slots_32_rate_3.2-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 135, 34560, 34560, 135, 34560, 4320, 34560, 135, 4320, 135, 34560, 4320, 4320, 4320, 4320, 34560, 135, 135, 135, 4320, 34560, 135, 34560, 34560, 4320, 4320, 4320, 135, 34560, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 34560, 4320, 135, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 135, 34560, 34560, 4320, 135, 135, 34560, 4320, 135, 4320, 4320, 34560, 4320, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 34560, 34560, 135, 34560, 135, 4320, 34560, 34560, 34560, 4320, 135, 34560, 4320, 135, 135, 135, 135, 135, 34560, 4320, 135, 34560, 135, 34560, 135, 135, 4320, 4320, 34560, 4320, 34560, 135, 4320, 135, 34560, 34560, 135, 34560, 4320, 135, 34560, 135, 135, 34560, 34560, 4320, 34560, 34560, 135, 34560, 4320, 4320, 135, 4320, 34560, 34560, 135, 34560, 4320, 135, 4320, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 4320, 34560, 34560, 4320, 135, 34560, 135, 4320, 4320, 135, 4320, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 34560, 135, 34560, 135, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 4320, 4320, 135, 4320, 34560, 4320, 4320, 34560, 135, 34560, 34560, 4320, 135, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 135, 34560, 4320, 34560, 34560, 135, 34560, 4320, 4320, 34560, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 135, 135, 135, 135]
Prompts retrieved: 3350835 . Total input tokens: 746922044 . Total output tokens: 670198486
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 104.1648162631318,
    "estimated_duration": 3600.0631512058,
    "input_throughput": 7394.20334642854,
    "output_throughput": 6571.798328614243,
    "total_throughput": 13966.001675042782,
    "itl": 123.57759812474252,
    "ttft": 1980289.3337018443,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 402,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2020002185506689,
    "arrivals": 1115519,
    "finished_requests": 108148,
    "scheduler_time": 226.026303558313
}
#Debug simulation 
Total elapsed time: 104.16498244181275. Arrivals time: 0.6439427924342453 Scheduler time: 103.32003775751218 Scheduler overhead time: 0.07907854253426194 Adapter cache time: 0.018174830358475447 Engine time: 0.07656051171943545 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-32/adapters_256_slots_32_rate_3.2-0.4-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-32/adapters_256_slots_32_rate_3.2-0.4-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 135, 34560, 34560, 135, 34560, 4320, 34560, 135, 4320, 135, 34560, 4320, 4320, 4320, 4320, 34560, 135, 135, 135, 4320, 34560, 135, 34560, 34560, 4320, 4320, 4320, 135, 34560, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 34560, 4320, 135, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 135, 34560, 34560, 4320, 135, 135, 34560, 4320, 135, 4320, 4320, 34560, 4320, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 34560, 34560, 135, 34560, 135, 4320, 34560, 34560, 34560, 4320, 135, 34560, 4320, 135, 135, 135, 135, 135, 34560, 4320, 135, 34560, 135, 34560, 135, 135, 4320, 4320, 34560, 4320, 34560, 135, 4320, 135, 34560, 34560, 135, 34560, 4320, 135, 34560, 135, 135, 34560, 34560, 4320, 34560, 34560, 135, 34560, 4320, 4320, 135, 4320, 34560, 34560, 135, 34560, 4320, 135, 4320, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 4320, 34560, 34560, 4320, 135, 34560, 135, 4320, 4320, 135, 4320, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 34560, 135, 34560, 135, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 4320, 4320, 135, 4320, 34560, 4320, 4320, 34560, 135, 34560, 34560, 4320, 135, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 135, 34560, 4320, 34560, 34560, 135, 34560, 4320, 4320, 34560, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 135, 135, 135, 135]
Prompts retrieved: 3350835 . Total input tokens: 746922044 . Total output tokens: 670198486
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 103.3027671398595,
    "estimated_duration": 3600.0920001594372,
    "input_throughput": 7330.083786423044,
    "output_throughput": 6518.703688394818,
    "total_throughput": 13848.787474817862,
    "itl": 122.29387344703848,
    "ttft": 1978486.3193841341,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 418,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4018312374502426,
    "arrivals": 1115519,
    "finished_requests": 107337,
    "scheduler_time": 228.29507207412072
}
#Debug simulation 
Total elapsed time: 103.30303349392489. Arrivals time: 0.6553784357383847 Scheduler time: 102.44739213353023 Scheduler overhead time: 0.07927934173494577 Adapter cache time: 0.0181649224832654 Engine time: 0.07546950643882155 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-8/adapters_256_slots_32_rate_3.2-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-8/adapters_256_slots_32_rate_3.2-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 66, 34560, 34560, 66, 34560, 4320, 34560, 66, 4320, 66, 34560, 4320, 4320, 4320, 4320, 34560, 66, 66, 66, 4320, 34560, 66, 34560, 34560, 4320, 4320, 4320, 66, 34560, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 34560, 4320, 66, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 66, 34560, 34560, 4320, 66, 66, 34560, 4320, 66, 4320, 4320, 34560, 4320, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 34560, 34560, 66, 34560, 66, 4320, 34560, 34560, 34560, 4320, 66, 34560, 4320, 66, 66, 66, 66, 66, 34560, 4320, 66, 34560, 66, 34560, 66, 66, 4320, 4320, 34560, 4320, 34560, 66, 4320, 66, 34560, 34560, 66, 34560, 4320, 66, 34560, 66, 66, 34560, 34560, 4320, 34560, 34560, 66, 34560, 4320, 4320, 66, 4320, 34560, 34560, 66, 34560, 4320, 66, 4320, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 4320, 34560, 34560, 4320, 66, 34560, 66, 4320, 4320, 66, 4320, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 34560, 66, 34560, 66, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 4320, 4320, 66, 4320, 34560, 4320, 4320, 34560, 66, 34560, 34560, 4320, 66, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 66, 34560, 4320, 34560, 34560, 66, 34560, 4320, 4320, 34560, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 66, 66, 66, 66]
Prompts retrieved: 3344970 . Total input tokens: 745610682 . Total output tokens: 669045759
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 102.65271300729364,
    "estimated_duration": 3600.126799244554,
    "input_throughput": 7422.698279851545,
    "output_throughput": 6570.628013703226,
    "total_throughput": 13993.326293554772,
    "itl": 124.09290014536006,
    "ttft": 1984490.006047152,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 364,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.114017538791525,
    "arrivals": 1113643,
    "finished_requests": 108369,
    "scheduler_time": 224.8330145893978
}
#Debug simulation 
Total elapsed time: 102.65288290195167. Arrivals time: 0.649836556520313 Scheduler time: 101.806648329366 Scheduler overhead time: 0.0779081997461617 Adapter cache time: 0.017294214107096195 Engine time: 0.0741990259848535 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-16/adapters_256_slots_32_rate_3.2-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-16/adapters_256_slots_32_rate_3.2-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 66, 34560, 34560, 66, 34560, 4320, 34560, 66, 4320, 66, 34560, 4320, 4320, 4320, 4320, 34560, 66, 66, 66, 4320, 34560, 66, 34560, 34560, 4320, 4320, 4320, 66, 34560, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 34560, 4320, 66, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 66, 34560, 34560, 4320, 66, 66, 34560, 4320, 66, 4320, 4320, 34560, 4320, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 34560, 34560, 66, 34560, 66, 4320, 34560, 34560, 34560, 4320, 66, 34560, 4320, 66, 66, 66, 66, 66, 34560, 4320, 66, 34560, 66, 34560, 66, 66, 4320, 4320, 34560, 4320, 34560, 66, 4320, 66, 34560, 34560, 66, 34560, 4320, 66, 34560, 66, 66, 34560, 34560, 4320, 34560, 34560, 66, 34560, 4320, 4320, 66, 4320, 34560, 34560, 66, 34560, 4320, 66, 4320, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 4320, 34560, 34560, 4320, 66, 34560, 66, 4320, 4320, 66, 4320, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 34560, 66, 34560, 66, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 4320, 4320, 66, 4320, 34560, 4320, 4320, 34560, 66, 34560, 34560, 4320, 66, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 66, 34560, 4320, 34560, 34560, 66, 34560, 4320, 4320, 34560, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 66, 66, 66, 66]
Prompts retrieved: 3344970 . Total input tokens: 745610682 . Total output tokens: 669045759
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 102.39002303406596,
    "estimated_duration": 3600.0598153861183,
    "input_throughput": 7422.536949468442,
    "output_throughput": 6570.472773509465,
    "total_throughput": 13993.009722977906,
    "itl": 124.09421989313059,
    "ttft": 1984491.5227632811,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 364,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1888927556807238,
    "arrivals": 1113643,
    "finished_requests": 108366,
    "scheduler_time": 224.82562757922935
}
#Debug simulation 
Total elapsed time: 102.3902034717612. Arrivals time: 0.6641267691738904 Scheduler time: 101.527609415818 Scheduler overhead time: 0.07905667694285512 Adapter cache time: 0.017366417217999697 Engine time: 0.07454430172219872 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-32/adapters_256_slots_32_rate_3.2-0.4-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-32/adapters_256_slots_32_rate_3.2-0.4-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 66, 34560, 34560, 66, 34560, 4320, 34560, 66, 4320, 66, 34560, 4320, 4320, 4320, 4320, 34560, 66, 66, 66, 4320, 34560, 66, 34560, 34560, 4320, 4320, 4320, 66, 34560, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 34560, 4320, 66, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 66, 34560, 34560, 4320, 66, 66, 34560, 4320, 66, 4320, 4320, 34560, 4320, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 34560, 34560, 66, 34560, 66, 4320, 34560, 34560, 34560, 4320, 66, 34560, 4320, 66, 66, 66, 66, 66, 34560, 4320, 66, 34560, 66, 34560, 66, 66, 4320, 4320, 34560, 4320, 34560, 66, 4320, 66, 34560, 34560, 66, 34560, 4320, 66, 34560, 66, 66, 34560, 34560, 4320, 34560, 34560, 66, 34560, 4320, 4320, 66, 4320, 34560, 34560, 66, 34560, 4320, 66, 4320, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 4320, 34560, 34560, 4320, 66, 34560, 66, 4320, 4320, 66, 4320, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 34560, 66, 34560, 66, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 4320, 4320, 66, 4320, 34560, 4320, 4320, 34560, 66, 34560, 34560, 4320, 66, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 66, 34560, 4320, 34560, 34560, 66, 34560, 4320, 4320, 34560, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 66, 66, 66, 66]
Prompts retrieved: 3344970 . Total input tokens: 745610682 . Total output tokens: 669045759
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 101.81496773194522,
    "estimated_duration": 3600.0631985336086,
    "input_throughput": 7422.52997416388,
    "output_throughput": 6570.466598929395,
    "total_throughput": 13992.996573093274,
    "itl": 124.0942111706938,
    "ttft": 1984493.699912228,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 364,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1908037446066804,
    "arrivals": 1113643,
    "finished_requests": 108366,
    "scheduler_time": 224.82572669013138
}
#Debug simulation 
Total elapsed time: 101.81513682380319. Arrivals time: 0.6598338480107486 Scheduler time: 100.95635823067278 Scheduler overhead time: 0.07917928416281939 Adapter cache time: 0.017515996005386114 Engine time: 0.07542951731011271 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-16-16/adapters_256_slots_32_rate_3.2-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-16-16/adapters_256_slots_32_rate_3.2-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 66, 34560, 34560, 66, 34560, 4320, 34560, 66, 4320, 66, 34560, 4320, 4320, 4320, 4320, 34560, 66, 66, 66, 4320, 34560, 66, 34560, 34560, 4320, 4320, 4320, 66, 34560, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 34560, 4320, 66, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 66, 34560, 34560, 4320, 66, 66, 34560, 4320, 66, 4320, 4320, 34560, 4320, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 34560, 34560, 66, 34560, 66, 4320, 34560, 34560, 34560, 4320, 66, 34560, 4320, 66, 66, 66, 66, 66, 34560, 4320, 66, 34560, 66, 34560, 66, 66, 4320, 4320, 34560, 4320, 34560, 66, 4320, 66, 34560, 34560, 66, 34560, 4320, 66, 34560, 66, 66, 34560, 34560, 4320, 34560, 34560, 66, 34560, 4320, 4320, 66, 4320, 34560, 34560, 66, 34560, 4320, 66, 4320, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 4320, 34560, 34560, 4320, 66, 34560, 66, 4320, 4320, 66, 4320, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 34560, 66, 34560, 66, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 4320, 4320, 66, 4320, 34560, 4320, 4320, 34560, 66, 34560, 34560, 4320, 66, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 66, 34560, 4320, 34560, 34560, 66, 34560, 4320, 4320, 34560, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 66, 66, 66, 66]
Prompts retrieved: 3344970 . Total input tokens: 745610682 . Total output tokens: 669045759
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 102.15138363279402,
    "estimated_duration": 3600.006953854991,
    "input_throughput": 7422.6459399990235,
    "output_throughput": 6570.569252559502,
    "total_throughput": 13993.215192558526,
    "itl": 124.09315100883161,
    "ttft": 1984469.84465338,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 364,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1365925549203544,
    "arrivals": 1113643,
    "finished_requests": 108366,
    "scheduler_time": 224.82517935387827
}
#Debug simulation 
Total elapsed time: 102.15155806811526. Arrivals time: 0.676611393224448 Scheduler time: 101.27657298976555 Scheduler overhead time: 0.07897235592827201 Adapter cache time: 0.01741217216476798 Engine time: 0.07508601387962699 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-16-32/adapters_256_slots_32_rate_3.2-0.4-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-16-32/adapters_256_slots_32_rate_3.2-0.4-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 66, 34560, 34560, 66, 34560, 4320, 34560, 66, 4320, 66, 34560, 4320, 4320, 4320, 4320, 34560, 66, 66, 66, 4320, 34560, 66, 34560, 34560, 4320, 4320, 4320, 66, 34560, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 34560, 4320, 66, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 66, 34560, 34560, 4320, 66, 66, 34560, 4320, 66, 4320, 4320, 34560, 4320, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 34560, 34560, 66, 34560, 66, 4320, 34560, 34560, 34560, 4320, 66, 34560, 4320, 66, 66, 66, 66, 66, 34560, 4320, 66, 34560, 66, 34560, 66, 66, 4320, 4320, 34560, 4320, 34560, 66, 4320, 66, 34560, 34560, 66, 34560, 4320, 66, 34560, 66, 66, 34560, 34560, 4320, 34560, 34560, 66, 34560, 4320, 4320, 66, 4320, 34560, 34560, 66, 34560, 4320, 66, 4320, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 4320, 34560, 34560, 4320, 66, 34560, 66, 4320, 4320, 66, 4320, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 34560, 66, 34560, 66, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 4320, 4320, 66, 4320, 34560, 4320, 4320, 34560, 66, 34560, 34560, 4320, 66, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 66, 34560, 4320, 34560, 34560, 66, 34560, 4320, 4320, 34560, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 66, 66, 66, 66]
Prompts retrieved: 3344970 . Total input tokens: 745610682 . Total output tokens: 669045759
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 102.06079024635255,
    "estimated_duration": 3600.078470947082,
    "input_throughput": 7422.498485976136,
    "output_throughput": 6570.438725402909,
    "total_throughput": 13992.937211379045,
    "itl": 124.09451527206757,
    "ttft": 1984499.5838587403,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 364,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2069002292677808,
    "arrivals": 1113643,
    "finished_requests": 108366,
    "scheduler_time": 224.82580745920177
}
#Debug simulation 
Total elapsed time: 102.06094983918592. Arrivals time: 0.6551678818650544 Scheduler time: 101.20913092978299 Scheduler overhead time: 0.07783640315756202 Adapter cache time: 0.01750263012945652 Engine time: 0.07434477703645825 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_16-16-16/adapters_256_slots_32_rate_3.2-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_16-16-16/adapters_256_slots_32_rate_3.2-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 66, 34560, 34560, 66, 34560, 4320, 34560, 66, 4320, 66, 34560, 4320, 4320, 4320, 4320, 34560, 66, 66, 66, 4320, 34560, 66, 34560, 34560, 4320, 4320, 4320, 66, 34560, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 34560, 4320, 66, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 66, 34560, 34560, 4320, 66, 66, 34560, 4320, 66, 4320, 4320, 34560, 4320, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 34560, 34560, 66, 34560, 66, 4320, 34560, 34560, 34560, 4320, 66, 34560, 4320, 66, 66, 66, 66, 66, 34560, 4320, 66, 34560, 66, 34560, 66, 66, 4320, 4320, 34560, 4320, 34560, 66, 4320, 66, 34560, 34560, 66, 34560, 4320, 66, 34560, 66, 66, 34560, 34560, 4320, 34560, 34560, 66, 34560, 4320, 4320, 66, 4320, 34560, 34560, 66, 34560, 4320, 66, 4320, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 4320, 34560, 34560, 4320, 66, 34560, 66, 4320, 4320, 66, 4320, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 34560, 66, 34560, 66, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 4320, 4320, 66, 4320, 34560, 4320, 4320, 34560, 66, 34560, 34560, 4320, 66, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 66, 34560, 4320, 34560, 34560, 66, 34560, 4320, 4320, 34560, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 66, 66, 66, 66]
Prompts retrieved: 3344970 . Total input tokens: 745610682 . Total output tokens: 669045759
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 102.27580848382786,
    "estimated_duration": 3600.1004390076823,
    "input_throughput": 7422.7526294698955,
    "output_throughput": 6570.67612439174,
    "total_throughput": 13993.428753861635,
    "itl": 124.09243707186035,
    "ttft": 1984478.7392682433,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 364,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0883783073443902,
    "arrivals": 1113643,
    "finished_requests": 108369,
    "scheduler_time": 224.83274600403936
}
#Debug simulation 
Total elapsed time: 102.27598556596786. Arrivals time: 0.6632839660160244 Scheduler time: 101.4176259576343 Scheduler overhead time: 0.07793284673243761 Adapter cache time: 0.017164988908916712 Engine time: 0.07371009234338999 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_16-16-32/adapters_256_slots_32_rate_3.2-0.4-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_16-16-32/adapters_256_slots_32_rate_3.2-0.4-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 66, 34560, 34560, 66, 34560, 4320, 34560, 66, 4320, 66, 34560, 4320, 4320, 4320, 4320, 34560, 66, 66, 66, 4320, 34560, 66, 34560, 34560, 4320, 4320, 4320, 66, 34560, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 34560, 4320, 66, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 66, 34560, 34560, 4320, 66, 66, 34560, 4320, 66, 4320, 4320, 34560, 4320, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 34560, 34560, 66, 34560, 66, 4320, 34560, 34560, 34560, 4320, 66, 34560, 4320, 66, 66, 66, 66, 66, 34560, 4320, 66, 34560, 66, 34560, 66, 66, 4320, 4320, 34560, 4320, 34560, 66, 4320, 66, 34560, 34560, 66, 34560, 4320, 66, 34560, 66, 66, 34560, 34560, 4320, 34560, 34560, 66, 34560, 4320, 4320, 66, 4320, 34560, 34560, 66, 34560, 4320, 66, 4320, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 4320, 34560, 34560, 4320, 66, 34560, 66, 4320, 4320, 66, 4320, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 34560, 66, 34560, 66, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 4320, 4320, 66, 4320, 34560, 4320, 4320, 34560, 66, 34560, 34560, 4320, 66, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 66, 34560, 4320, 34560, 34560, 66, 34560, 4320, 4320, 34560, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 66, 66, 66, 66]
Prompts retrieved: 3344970 . Total input tokens: 745610682 . Total output tokens: 669045759
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 102.32871572021395,
    "estimated_duration": 3600.09236324893,
    "input_throughput": 7422.4698434917145,
    "output_throughput": 6570.413370909514,
    "total_throughput": 13992.883214401229,
    "itl": 124.09484017814017,
    "ttft": 1984504.7736006768,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 364,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.221739176064732,
    "arrivals": 1113643,
    "finished_requests": 108366,
    "scheduler_time": 224.82587875954127
}
#Debug simulation 
Total elapsed time: 102.32889050990343. Arrivals time: 0.6571736088953912 Scheduler time: 101.47375319944695 Scheduler overhead time: 0.07926742406561971 Adapter cache time: 0.017422195058315992 Engine time: 0.07446270529180765 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-8/adapters_256_slots_32_rate_3.2-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-8/adapters_256_slots_32_rate_3.2-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 33, 34560, 34560, 33, 34560, 4320, 34560, 33, 4320, 33, 34560, 4320, 4320, 4320, 4320, 34560, 33, 33, 33, 4320, 34560, 33, 34560, 34560, 4320, 4320, 4320, 33, 34560, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 34560, 4320, 33, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 33, 34560, 34560, 4320, 33, 33, 34560, 4320, 33, 4320, 4320, 34560, 4320, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 34560, 34560, 33, 34560, 33, 4320, 34560, 34560, 34560, 4320, 33, 34560, 4320, 33, 33, 33, 33, 33, 34560, 4320, 33, 34560, 33, 34560, 33, 33, 4320, 4320, 34560, 4320, 34560, 33, 4320, 33, 34560, 34560, 33, 34560, 4320, 33, 34560, 33, 33, 34560, 34560, 4320, 34560, 34560, 33, 34560, 4320, 4320, 33, 4320, 34560, 34560, 33, 34560, 4320, 33, 4320, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 4320, 34560, 34560, 4320, 33, 34560, 33, 4320, 4320, 33, 4320, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 34560, 33, 34560, 33, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 4320, 4320, 33, 4320, 34560, 4320, 4320, 34560, 33, 34560, 34560, 4320, 33, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 33, 34560, 4320, 34560, 34560, 33, 34560, 4320, 4320, 34560, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 33, 33, 33, 33]
Prompts retrieved: 3342165 . Total input tokens: 745000425 . Total output tokens: 668483509
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 105.58860387606546,
    "estimated_duration": 3600.0936036560856,
    "input_throughput": 7431.166782116726,
    "output_throughput": 6557.850044794374,
    "total_throughput": 13989.0168269111,
    "itl": 122.61513747614518,
    "ttft": 1989222.8179771542,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 335,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.025263394217472,
    "arrivals": 1112647,
    "finished_requests": 107860,
    "scheduler_time": 225.54644211296483
}
#Debug simulation 
Total elapsed time: 105.5887737320736. Arrivals time: 0.7988253617659211 Scheduler time: 104.59260001499206 Scheduler overhead time: 0.07868526224046946 Adapter cache time: 0.017413916997611523 Engine time: 0.07397451857104897 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-16/adapters_256_slots_32_rate_3.2-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-16/adapters_256_slots_32_rate_3.2-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 33, 34560, 34560, 33, 34560, 4320, 34560, 33, 4320, 33, 34560, 4320, 4320, 4320, 4320, 34560, 33, 33, 33, 4320, 34560, 33, 34560, 34560, 4320, 4320, 4320, 33, 34560, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 34560, 4320, 33, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 33, 34560, 34560, 4320, 33, 33, 34560, 4320, 33, 4320, 4320, 34560, 4320, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 34560, 34560, 33, 34560, 33, 4320, 34560, 34560, 34560, 4320, 33, 34560, 4320, 33, 33, 33, 33, 33, 34560, 4320, 33, 34560, 33, 34560, 33, 33, 4320, 4320, 34560, 4320, 34560, 33, 4320, 33, 34560, 34560, 33, 34560, 4320, 33, 34560, 33, 33, 34560, 34560, 4320, 34560, 34560, 33, 34560, 4320, 4320, 33, 4320, 34560, 34560, 33, 34560, 4320, 33, 4320, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 4320, 34560, 34560, 4320, 33, 34560, 33, 4320, 4320, 33, 4320, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 34560, 33, 34560, 33, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 4320, 4320, 33, 4320, 34560, 4320, 4320, 34560, 33, 34560, 34560, 4320, 33, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 33, 34560, 4320, 34560, 34560, 33, 34560, 4320, 4320, 34560, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 33, 33, 33, 33]
Prompts retrieved: 3342165 . Total input tokens: 745000425 . Total output tokens: 668483509
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 105.421025340911,
    "estimated_duration": 3600.101210878575,
    "input_throughput": 7496.080643081179,
    "output_throughput": 6613.389903610416,
    "total_throughput": 14109.470546691595,
    "itl": 124.37858746984,
    "ttft": 1984153.3476438983,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 344,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.122145629369194,
    "arrivals": 1112647,
    "finished_requests": 108719,
    "scheduler_time": 223.12661044721784
}
#Debug simulation 
Total elapsed time: 105.42120015667751. Arrivals time: 0.6645597079768777 Scheduler time: 104.55987044610083 Scheduler overhead time: 0.07869406789541245 Adapter cache time: 0.017062528990209103 Engine time: 0.07447076588869095 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-32/adapters_256_slots_32_rate_3.2-0.4-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-32/adapters_256_slots_32_rate_3.2-0.4-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 33, 34560, 34560, 33, 34560, 4320, 34560, 33, 4320, 33, 34560, 4320, 4320, 4320, 4320, 34560, 33, 33, 33, 4320, 34560, 33, 34560, 34560, 4320, 4320, 4320, 33, 34560, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 34560, 4320, 33, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 33, 34560, 34560, 4320, 33, 33, 34560, 4320, 33, 4320, 4320, 34560, 4320, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 34560, 34560, 33, 34560, 33, 4320, 34560, 34560, 34560, 4320, 33, 34560, 4320, 33, 33, 33, 33, 33, 34560, 4320, 33, 34560, 33, 34560, 33, 33, 4320, 4320, 34560, 4320, 34560, 33, 4320, 33, 34560, 34560, 33, 34560, 4320, 33, 34560, 33, 33, 34560, 34560, 4320, 34560, 34560, 33, 34560, 4320, 4320, 33, 4320, 34560, 34560, 33, 34560, 4320, 33, 4320, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 4320, 34560, 34560, 4320, 33, 34560, 33, 4320, 4320, 33, 4320, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 34560, 33, 34560, 33, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 4320, 4320, 33, 4320, 34560, 4320, 4320, 34560, 33, 34560, 34560, 4320, 33, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 33, 34560, 4320, 34560, 34560, 33, 34560, 4320, 4320, 34560, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 33, 33, 33, 33]
Prompts retrieved: 3342165 . Total input tokens: 745000425 . Total output tokens: 668483509
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 105.29331569606438,
    "estimated_duration": 3600.1032718019187,
    "input_throughput": 7496.076351857729,
    "output_throughput": 6613.386117694123,
    "total_throughput": 14109.46246955185,
    "itl": 124.37865179425322,
    "ttft": 1984154.2560104572,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 344,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1242001602239968,
    "arrivals": 1112647,
    "finished_requests": 108719,
    "scheduler_time": 223.12661683969839
}
#Debug simulation 
Total elapsed time: 105.2934789438732. Arrivals time: 0.6807753099128604 Scheduler time: 104.41598519263789 Scheduler overhead time: 0.0779020949266851 Adapter cache time: 0.0170945986174047 Engine time: 0.07455854443833232 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-16/adapters_256_slots_32_rate_3.2-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-16/adapters_256_slots_32_rate_3.2-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 33, 34560, 34560, 33, 34560, 4320, 34560, 33, 4320, 33, 34560, 4320, 4320, 4320, 4320, 34560, 33, 33, 33, 4320, 34560, 33, 34560, 34560, 4320, 4320, 4320, 33, 34560, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 34560, 4320, 33, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 33, 34560, 34560, 4320, 33, 33, 34560, 4320, 33, 4320, 4320, 34560, 4320, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 34560, 34560, 33, 34560, 33, 4320, 34560, 34560, 34560, 4320, 33, 34560, 4320, 33, 33, 33, 33, 33, 34560, 4320, 33, 34560, 33, 34560, 33, 33, 4320, 4320, 34560, 4320, 34560, 33, 4320, 33, 34560, 34560, 33, 34560, 4320, 33, 34560, 33, 33, 34560, 34560, 4320, 34560, 34560, 33, 34560, 4320, 4320, 33, 4320, 34560, 34560, 33, 34560, 4320, 33, 4320, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 4320, 34560, 34560, 4320, 33, 34560, 33, 4320, 4320, 33, 4320, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 34560, 33, 34560, 33, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 4320, 4320, 33, 4320, 34560, 4320, 4320, 34560, 33, 34560, 34560, 4320, 33, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 33, 34560, 4320, 34560, 34560, 33, 34560, 4320, 4320, 34560, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 33, 33, 33, 33]
Prompts retrieved: 3342165 . Total input tokens: 745000425 . Total output tokens: 668483509
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 105.8962068837136,
    "estimated_duration": 3600.1138824315985,
    "input_throughput": 7431.124923728937,
    "output_throughput": 6557.813105638212,
    "total_throughput": 13988.93802936715,
    "itl": 122.6156393342441,
    "ttft": 1989230.2966888044,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 335,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0466123338206699,
    "arrivals": 1112647,
    "finished_requests": 107860,
    "scheduler_time": 225.54650299914982
}
#Debug simulation 
Total elapsed time: 105.89639144297689. Arrivals time: 1.2040694830939174 Scheduler time: 104.49413915351033 Scheduler overhead time: 0.07906545978039503 Adapter cache time: 0.017544252797961235 Engine time: 0.07464582612738013 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-32/adapters_256_slots_32_rate_3.2-0.4-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-32/adapters_256_slots_32_rate_3.2-0.4-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 33, 34560, 34560, 33, 34560, 4320, 34560, 33, 4320, 33, 34560, 4320, 4320, 4320, 4320, 34560, 33, 33, 33, 4320, 34560, 33, 34560, 34560, 4320, 4320, 4320, 33, 34560, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 34560, 4320, 33, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 33, 34560, 34560, 4320, 33, 33, 34560, 4320, 33, 4320, 4320, 34560, 4320, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 34560, 34560, 33, 34560, 33, 4320, 34560, 34560, 34560, 4320, 33, 34560, 4320, 33, 33, 33, 33, 33, 34560, 4320, 33, 34560, 33, 34560, 33, 33, 4320, 4320, 34560, 4320, 34560, 33, 4320, 33, 34560, 34560, 33, 34560, 4320, 33, 34560, 33, 33, 34560, 34560, 4320, 34560, 34560, 33, 34560, 4320, 4320, 33, 4320, 34560, 34560, 33, 34560, 4320, 33, 4320, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 4320, 34560, 34560, 4320, 33, 34560, 33, 4320, 4320, 33, 4320, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 34560, 33, 34560, 33, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 4320, 4320, 33, 4320, 34560, 4320, 4320, 34560, 33, 34560, 34560, 4320, 33, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 33, 34560, 4320, 34560, 34560, 33, 34560, 4320, 4320, 34560, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 33, 33, 33, 33]
Prompts retrieved: 3342165 . Total input tokens: 745000425 . Total output tokens: 668483509
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 105.47005249094218,
    "estimated_duration": 3600.1177731789858,
    "input_throughput": 7496.0461574483925,
    "output_throughput": 6613.359478786224,
    "total_throughput": 14109.405636234616,
    "itl": 124.37896769596149,
    "ttft": 1984160.1792669154,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 344,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1391648608073648,
    "arrivals": 1112647,
    "finished_requests": 108719,
    "scheduler_time": 223.12671904134646
}
#Debug simulation 
Total elapsed time: 105.47021294897422. Arrivals time: 0.7770366766490042 Scheduler time: 104.49742103274912 Scheduler overhead time: 0.07755113858729601 Adapter cache time: 0.017236337065696716 Engine time: 0.07392803905531764 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-16/adapters_256_slots_32_rate_3.2-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-16/adapters_256_slots_32_rate_3.2-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 33, 34560, 34560, 33, 34560, 4320, 34560, 33, 4320, 33, 34560, 4320, 4320, 4320, 4320, 34560, 33, 33, 33, 4320, 34560, 33, 34560, 34560, 4320, 4320, 4320, 33, 34560, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 34560, 4320, 33, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 33, 34560, 34560, 4320, 33, 33, 34560, 4320, 33, 4320, 4320, 34560, 4320, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 34560, 34560, 33, 34560, 33, 4320, 34560, 34560, 34560, 4320, 33, 34560, 4320, 33, 33, 33, 33, 33, 34560, 4320, 33, 34560, 33, 34560, 33, 33, 4320, 4320, 34560, 4320, 34560, 33, 4320, 33, 34560, 34560, 33, 34560, 4320, 33, 34560, 33, 33, 34560, 34560, 4320, 34560, 34560, 33, 34560, 4320, 4320, 33, 4320, 34560, 34560, 33, 34560, 4320, 33, 4320, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 4320, 34560, 34560, 4320, 33, 34560, 33, 4320, 4320, 33, 4320, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 34560, 33, 34560, 33, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 4320, 4320, 33, 4320, 34560, 4320, 4320, 34560, 33, 34560, 34560, 4320, 33, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 33, 34560, 4320, 34560, 34560, 33, 34560, 4320, 4320, 34560, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 33, 33, 33, 33]
Prompts retrieved: 3342165 . Total input tokens: 745000425 . Total output tokens: 668483509
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 105.35837385477498,
    "estimated_duration": 3600.069708817455,
    "input_throughput": 7431.21610519807,
    "output_throughput": 6557.8935713872615,
    "total_throughput": 13989.109676585333,
    "itl": 122.61467444728676,
    "ttft": 1989212.9537879613,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 335,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0016668487922302,
    "arrivals": 1112647,
    "finished_requests": 107860,
    "scheduler_time": 225.54625692474016
}
#Debug simulation 
Total elapsed time: 105.35855027707294. Arrivals time: 0.7858599368482828 Scheduler time: 104.37565951328725 Scheduler overhead time: 0.07853130251169205 Adapter cache time: 0.017189137637615204 Engine time: 0.07420785771682858 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-32/adapters_256_slots_32_rate_3.2-0.4-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-32/adapters_256_slots_32_rate_3.2-0.4-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 34560, 33, 34560, 34560, 33, 34560, 4320, 34560, 33, 4320, 33, 34560, 4320, 4320, 4320, 4320, 34560, 33, 33, 33, 4320, 34560, 33, 34560, 34560, 4320, 4320, 4320, 33, 34560, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 34560, 4320, 33, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 33, 34560, 34560, 4320, 33, 33, 34560, 4320, 33, 4320, 4320, 34560, 4320, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 34560, 34560, 33, 34560, 33, 4320, 34560, 34560, 34560, 4320, 33, 34560, 4320, 33, 33, 33, 33, 33, 34560, 4320, 33, 34560, 33, 34560, 33, 33, 4320, 4320, 34560, 4320, 34560, 33, 4320, 33, 34560, 34560, 33, 34560, 4320, 33, 34560, 33, 33, 34560, 34560, 4320, 34560, 34560, 33, 34560, 4320, 4320, 33, 4320, 34560, 34560, 33, 34560, 4320, 33, 4320, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 4320, 34560, 34560, 4320, 33, 34560, 33, 4320, 4320, 33, 4320, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 34560, 33, 34560, 33, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 4320, 4320, 33, 4320, 34560, 4320, 4320, 34560, 33, 34560, 34560, 4320, 33, 34560, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 33, 34560, 4320, 34560, 34560, 33, 34560, 4320, 4320, 34560, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 33, 33, 33, 33]
Prompts retrieved: 3342165 . Total input tokens: 745000425 . Total output tokens: 668483509
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 105.3297614119947,
    "estimated_duration": 3600.131625318565,
    "input_throughput": 7496.017315092481,
    "output_throughput": 6613.334032722546,
    "total_throughput": 14109.351347815027,
    "itl": 124.379345191969,
    "ttft": 1984165.7592773633,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 344,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1529977773129978,
    "arrivals": 1112647,
    "finished_requests": 108719,
    "scheduler_time": 223.12685136945697
}
#Debug simulation 
Total elapsed time: 105.3300136406906. Arrivals time: 0.7671170812100172 Scheduler time: 104.3667411673814 Scheduler overhead time: 0.07817466603592038 Adapter cache time: 0.016891804989427328 Engine time: 0.0738883763551712 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-8/adapters_256_slots_32_rate_3.2-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-8/adapters_256_slots_32_rate_3.2-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 540, 34560, 34560, 540, 34560, 1080, 34560, 540, 1080, 540, 34560, 1080, 1080, 1080, 1080, 34560, 540, 540, 540, 1080, 34560, 540, 34560, 34560, 1080, 1080, 1080, 540, 34560, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 34560, 1080, 540, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 540, 34560, 34560, 1080, 540, 540, 34560, 1080, 540, 1080, 1080, 34560, 1080, 540, 540, 34560, 34560, 34560, 34560, 34560, 34560, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 34560, 34560, 540, 34560, 540, 1080, 34560, 34560, 34560, 1080, 540, 34560, 1080, 540, 540, 540, 540, 540, 34560, 1080, 540, 34560, 540, 34560, 540, 540, 1080, 1080, 34560, 1080, 34560, 540, 1080, 540, 34560, 34560, 540, 34560, 1080, 540, 34560, 540, 540, 34560, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 540, 1080, 34560, 34560, 540, 34560, 1080, 540, 1080, 34560, 540, 540, 540, 540, 540, 540, 34560, 540, 540, 540, 34560, 540, 1080, 34560, 34560, 1080, 540, 34560, 540, 1080, 1080, 540, 1080, 540, 34560, 540, 540, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 34560, 540, 34560, 540, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 1080, 1080, 540, 1080, 34560, 1080, 1080, 34560, 540, 34560, 34560, 1080, 540, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 540, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 34560, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 540, 540, 540, 540]
Prompts retrieved: 3109860 . Total input tokens: 693311361 . Total output tokens: 622101039
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 100.97700888011605,
    "estimated_duration": 3600.0263715985398,
    "input_throughput": 7405.181309314276,
    "output_throughput": 6538.772378366638,
    "total_throughput": 13943.953687680914,
    "itl": 124.61494523189336,
    "ttft": 1979614.0109753602,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 375,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1476829039747865,
    "arrivals": 1035175,
    "finished_requests": 107577,
    "scheduler_time": 226.50798026255737
}
#Debug simulation 
Total elapsed time: 100.97718036733568. Arrivals time: 0.6432031085714698 Scheduler time: 100.13692937931046 Scheduler overhead time: 0.0781739866361022 Adapter cache time: 0.017589190509170294 Engine time: 0.07419248251244426 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-16/adapters_256_slots_32_rate_3.2-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-16/adapters_256_slots_32_rate_3.2-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 540, 34560, 34560, 540, 34560, 1080, 34560, 540, 1080, 540, 34560, 1080, 1080, 1080, 1080, 34560, 540, 540, 540, 1080, 34560, 540, 34560, 34560, 1080, 1080, 1080, 540, 34560, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 34560, 1080, 540, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 540, 34560, 34560, 1080, 540, 540, 34560, 1080, 540, 1080, 1080, 34560, 1080, 540, 540, 34560, 34560, 34560, 34560, 34560, 34560, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 34560, 34560, 540, 34560, 540, 1080, 34560, 34560, 34560, 1080, 540, 34560, 1080, 540, 540, 540, 540, 540, 34560, 1080, 540, 34560, 540, 34560, 540, 540, 1080, 1080, 34560, 1080, 34560, 540, 1080, 540, 34560, 34560, 540, 34560, 1080, 540, 34560, 540, 540, 34560, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 540, 1080, 34560, 34560, 540, 34560, 1080, 540, 1080, 34560, 540, 540, 540, 540, 540, 540, 34560, 540, 540, 540, 34560, 540, 1080, 34560, 34560, 1080, 540, 34560, 540, 1080, 1080, 540, 1080, 540, 34560, 540, 540, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 34560, 540, 34560, 540, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 1080, 1080, 540, 1080, 34560, 1080, 1080, 34560, 540, 34560, 34560, 1080, 540, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 540, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 34560, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 540, 540, 540, 540]
Prompts retrieved: 3109860 . Total input tokens: 693311361 . Total output tokens: 622101039
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 101.80370578775182,
    "estimated_duration": 3600.133613312493,
    "input_throughput": 7409.731378123857,
    "output_throughput": 6539.165911217128,
    "total_throughput": 13948.897289340986,
    "itl": 124.59406391932855,
    "ttft": 1979071.7357799662,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 370,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2080588434054573,
    "arrivals": 1035175,
    "finished_requests": 107559,
    "scheduler_time": 226.559987796535
}
#Debug simulation 
Total elapsed time: 101.80389038380235. Arrivals time: 0.6236646850593388 Scheduler time: 100.98269636603072 Scheduler overhead time: 0.07872379198670387 Adapter cache time: 0.01717889215797186 Engine time: 0.0743451677262783 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-32/adapters_256_slots_32_rate_3.2-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-32/adapters_256_slots_32_rate_3.2-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 540, 34560, 34560, 540, 34560, 1080, 34560, 540, 1080, 540, 34560, 1080, 1080, 1080, 1080, 34560, 540, 540, 540, 1080, 34560, 540, 34560, 34560, 1080, 1080, 1080, 540, 34560, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 34560, 1080, 540, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 540, 34560, 34560, 1080, 540, 540, 34560, 1080, 540, 1080, 1080, 34560, 1080, 540, 540, 34560, 34560, 34560, 34560, 34560, 34560, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 34560, 34560, 540, 34560, 540, 1080, 34560, 34560, 34560, 1080, 540, 34560, 1080, 540, 540, 540, 540, 540, 34560, 1080, 540, 34560, 540, 34560, 540, 540, 1080, 1080, 34560, 1080, 34560, 540, 1080, 540, 34560, 34560, 540, 34560, 1080, 540, 34560, 540, 540, 34560, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 540, 1080, 34560, 34560, 540, 34560, 1080, 540, 1080, 34560, 540, 540, 540, 540, 540, 540, 34560, 540, 540, 540, 34560, 540, 1080, 34560, 34560, 1080, 540, 34560, 540, 1080, 1080, 540, 1080, 540, 34560, 540, 540, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 34560, 540, 34560, 540, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 1080, 1080, 540, 1080, 34560, 1080, 1080, 34560, 540, 34560, 34560, 1080, 540, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 540, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 34560, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 540, 540, 540, 540]
Prompts retrieved: 3109860 . Total input tokens: 693311361 . Total output tokens: 622101039
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 101.88132145488635,
    "estimated_duration": 3600.1356415296955,
    "input_throughput": 7409.727203685407,
    "output_throughput": 6539.16222723127,
    "total_throughput": 13948.889430916677,
    "itl": 124.59409353534842,
    "ttft": 1979072.607059685,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 370,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2100766001828083,
    "arrivals": 1035175,
    "finished_requests": 107559,
    "scheduler_time": 226.55999825695773
}
#Debug simulation 
Total elapsed time: 101.88150123180822. Arrivals time: 0.640216198284179 Scheduler time: 101.0438512917608 Scheduler overhead time: 0.07895948551595211 Adapter cache time: 0.01738817524164915 Engine time: 0.07445871829986572 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-16-16/adapters_256_slots_32_rate_3.2-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-16-16/adapters_256_slots_32_rate_3.2-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 540, 34560, 34560, 540, 34560, 1080, 34560, 540, 1080, 540, 34560, 1080, 1080, 1080, 1080, 34560, 540, 540, 540, 1080, 34560, 540, 34560, 34560, 1080, 1080, 1080, 540, 34560, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 34560, 1080, 540, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 540, 34560, 34560, 1080, 540, 540, 34560, 1080, 540, 1080, 1080, 34560, 1080, 540, 540, 34560, 34560, 34560, 34560, 34560, 34560, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 34560, 34560, 540, 34560, 540, 1080, 34560, 34560, 34560, 1080, 540, 34560, 1080, 540, 540, 540, 540, 540, 34560, 1080, 540, 34560, 540, 34560, 540, 540, 1080, 1080, 34560, 1080, 34560, 540, 1080, 540, 34560, 34560, 540, 34560, 1080, 540, 34560, 540, 540, 34560, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 540, 1080, 34560, 34560, 540, 34560, 1080, 540, 1080, 34560, 540, 540, 540, 540, 540, 540, 34560, 540, 540, 540, 34560, 540, 1080, 34560, 34560, 1080, 540, 34560, 540, 1080, 1080, 540, 1080, 540, 34560, 540, 540, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 34560, 540, 34560, 540, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 1080, 1080, 540, 1080, 34560, 1080, 1080, 34560, 540, 34560, 34560, 1080, 540, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 540, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 34560, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 540, 540, 540, 540]
Prompts retrieved: 3109860 . Total input tokens: 693311361 . Total output tokens: 622101039
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 100.20870585693046,
    "estimated_duration": 3600.0508304532123,
    "input_throughput": 7405.130998287573,
    "output_throughput": 6538.727953748522,
    "total_throughput": 13943.858952036095,
    "itl": 124.61542848364807,
    "ttft": 1979624.5897126747,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 375,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.17234327539336,
    "arrivals": 1035175,
    "finished_requests": 107577,
    "scheduler_time": 226.50811806085903
}
#Debug simulation 
Total elapsed time: 100.2089020460844. Arrivals time: 0.6197616676799953 Scheduler time: 99.39181260066107 Scheduler overhead time: 0.07845313474535942 Adapter cache time: 0.017167252954095602 Engine time: 0.07464449759572744 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-16-32/adapters_256_slots_32_rate_3.2-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-16-32/adapters_256_slots_32_rate_3.2-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 540, 34560, 34560, 540, 34560, 1080, 34560, 540, 1080, 540, 34560, 1080, 1080, 1080, 1080, 34560, 540, 540, 540, 1080, 34560, 540, 34560, 34560, 1080, 1080, 1080, 540, 34560, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 34560, 1080, 540, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 540, 34560, 34560, 1080, 540, 540, 34560, 1080, 540, 1080, 1080, 34560, 1080, 540, 540, 34560, 34560, 34560, 34560, 34560, 34560, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 34560, 34560, 540, 34560, 540, 1080, 34560, 34560, 34560, 1080, 540, 34560, 1080, 540, 540, 540, 540, 540, 34560, 1080, 540, 34560, 540, 34560, 540, 540, 1080, 1080, 34560, 1080, 34560, 540, 1080, 540, 34560, 34560, 540, 34560, 1080, 540, 34560, 540, 540, 34560, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 540, 1080, 34560, 34560, 540, 34560, 1080, 540, 1080, 34560, 540, 540, 540, 540, 540, 540, 34560, 540, 540, 540, 34560, 540, 1080, 34560, 34560, 1080, 540, 34560, 540, 1080, 1080, 540, 1080, 540, 34560, 540, 540, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 34560, 540, 34560, 540, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 1080, 1080, 540, 1080, 34560, 1080, 1080, 34560, 540, 34560, 34560, 1080, 540, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 540, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 34560, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 540, 540, 540, 540]
Prompts retrieved: 3109860 . Total input tokens: 693311361 . Total output tokens: 622101039
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 102.5679128030315,
    "estimated_duration": 3600.0093634249347,
    "input_throughput": 7409.007396198724,
    "output_throughput": 6538.977436882116,
    "total_throughput": 13947.98483308084,
    "itl": 124.59396978687354,
    "ttft": 1979079.809747368,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 370,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.225921577271079,
    "arrivals": 1035175,
    "finished_requests": 107552,
    "scheduler_time": 226.55144240004327
}
#Debug simulation 
Total elapsed time: 102.5680851880461. Arrivals time: 0.63827188545838 Scheduler time: 101.7320668194443 Scheduler overhead time: 0.07854519272223115 Adapter cache time: 0.017795745749026537 Engine time: 0.07468148041516542 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_16-16-16/adapters_256_slots_32_rate_3.2-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_16-16-16/adapters_256_slots_32_rate_3.2-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 540, 34560, 34560, 540, 34560, 1080, 34560, 540, 1080, 540, 34560, 1080, 1080, 1080, 1080, 34560, 540, 540, 540, 1080, 34560, 540, 34560, 34560, 1080, 1080, 1080, 540, 34560, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 34560, 1080, 540, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 540, 34560, 34560, 1080, 540, 540, 34560, 1080, 540, 1080, 1080, 34560, 1080, 540, 540, 34560, 34560, 34560, 34560, 34560, 34560, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 34560, 34560, 540, 34560, 540, 1080, 34560, 34560, 34560, 1080, 540, 34560, 1080, 540, 540, 540, 540, 540, 34560, 1080, 540, 34560, 540, 34560, 540, 540, 1080, 1080, 34560, 1080, 34560, 540, 1080, 540, 34560, 34560, 540, 34560, 1080, 540, 34560, 540, 540, 34560, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 540, 1080, 34560, 34560, 540, 34560, 1080, 540, 1080, 34560, 540, 540, 540, 540, 540, 540, 34560, 540, 540, 540, 34560, 540, 1080, 34560, 34560, 1080, 540, 34560, 540, 1080, 1080, 540, 1080, 540, 34560, 540, 540, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 34560, 540, 34560, 540, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 1080, 1080, 540, 1080, 34560, 1080, 1080, 34560, 540, 34560, 34560, 1080, 540, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 540, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 34560, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 540, 540, 540, 540]
Prompts retrieved: 3109860 . Total input tokens: 693311361 . Total output tokens: 622101039
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 100.90627718390897,
    "estimated_duration": 3600.143298193162,
    "input_throughput": 7405.045241776825,
    "output_throughput": 6538.908885047645,
    "total_throughput": 13943.95412682447,
    "itl": 124.61478502308738,
    "ttft": 1979633.1697776064,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 375,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.121268860588313,
    "arrivals": 1035175,
    "finished_requests": 107582,
    "scheduler_time": 226.51650952022797
}
#Debug simulation 
Total elapsed time: 100.9064535186626. Arrivals time: 0.9924737545661628 Scheduler time: 99.71985555300489 Scheduler overhead time: 0.07784745888784528 Adapter cache time: 0.017183222342282534 Engine time: 0.07250524219125509 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_16-16-32/adapters_256_slots_32_rate_3.2-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_16-16-32/adapters_256_slots_32_rate_3.2-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 540, 34560, 34560, 540, 34560, 1080, 34560, 540, 1080, 540, 34560, 1080, 1080, 1080, 1080, 34560, 540, 540, 540, 1080, 34560, 540, 34560, 34560, 1080, 1080, 1080, 540, 34560, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 34560, 1080, 540, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 540, 34560, 34560, 1080, 540, 540, 34560, 1080, 540, 1080, 1080, 34560, 1080, 540, 540, 34560, 34560, 34560, 34560, 34560, 34560, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 34560, 34560, 540, 34560, 540, 1080, 34560, 34560, 34560, 1080, 540, 34560, 1080, 540, 540, 540, 540, 540, 34560, 1080, 540, 34560, 540, 34560, 540, 540, 1080, 1080, 34560, 1080, 34560, 540, 1080, 540, 34560, 34560, 540, 34560, 1080, 540, 34560, 540, 540, 34560, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 540, 1080, 34560, 34560, 540, 34560, 1080, 540, 1080, 34560, 540, 540, 540, 540, 540, 540, 34560, 540, 540, 540, 34560, 540, 1080, 34560, 34560, 1080, 540, 34560, 540, 1080, 1080, 540, 1080, 540, 34560, 540, 540, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 34560, 540, 34560, 540, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 1080, 1080, 540, 1080, 34560, 1080, 1080, 34560, 540, 34560, 34560, 1080, 540, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 540, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 34560, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 540, 540, 540, 540]
Prompts retrieved: 3109860 . Total input tokens: 693311361 . Total output tokens: 622101039
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 102.9497897149995,
    "estimated_duration": 3600.0271857489774,
    "input_throughput": 7408.9707171060845,
    "output_throughput": 6538.9450649669125,
    "total_throughput": 13947.915782072998,
    "itl": 124.59442748130084,
    "ttft": 1979087.887319064,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 370,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2413892930001051,
    "arrivals": 1035175,
    "finished_requests": 107552,
    "scheduler_time": 226.55198732785996
}
#Debug simulation 
Total elapsed time: 102.95007804874331. Arrivals time: 0.6217542644590139 Scheduler time: 102.13299286272377 Scheduler overhead time: 0.07764628482982516 Adapter cache time: 0.017455960623919964 Engine time: 0.0734610864892602 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-8/adapters_256_slots_32_rate_3.2-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-8/adapters_256_slots_32_rate_3.2-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 270, 34560, 34560, 270, 34560, 1080, 34560, 270, 1080, 270, 34560, 1080, 1080, 1080, 1080, 34560, 270, 270, 270, 1080, 34560, 270, 34560, 34560, 1080, 1080, 1080, 270, 34560, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 34560, 1080, 270, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 270, 34560, 34560, 1080, 270, 270, 34560, 1080, 270, 1080, 1080, 34560, 1080, 270, 270, 34560, 34560, 34560, 34560, 34560, 34560, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 34560, 34560, 270, 34560, 270, 1080, 34560, 34560, 34560, 1080, 270, 34560, 1080, 270, 270, 270, 270, 270, 34560, 1080, 270, 34560, 270, 34560, 270, 270, 1080, 1080, 34560, 1080, 34560, 270, 1080, 270, 34560, 34560, 270, 34560, 1080, 270, 34560, 270, 270, 34560, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 270, 1080, 34560, 34560, 270, 34560, 1080, 270, 1080, 34560, 270, 270, 270, 270, 270, 270, 34560, 270, 270, 270, 34560, 270, 1080, 34560, 34560, 1080, 270, 34560, 270, 1080, 1080, 270, 1080, 270, 34560, 270, 270, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 34560, 270, 34560, 270, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 1080, 1080, 270, 1080, 34560, 1080, 1080, 34560, 270, 34560, 34560, 1080, 270, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 270, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 34560, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 270, 270, 270, 270]
Prompts retrieved: 3086910 . Total input tokens: 688216455 . Total output tokens: 617448558
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 95.68407921586186,
    "estimated_duration": 3600.1240853960353,
    "input_throughput": 7410.313468977349,
    "output_throughput": 6547.913472101002,
    "total_throughput": 13958.226941078352,
    "itl": 124.88073228516865,
    "ttft": 1974710.1243878247,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 388,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1874692446459136,
    "arrivals": 1027687,
    "finished_requests": 107813,
    "scheduler_time": 225.8375540900772
}
#Debug simulation 
Total elapsed time: 95.68425089679658. Arrivals time: 0.623344074934721 Scheduler time: 94.86762065906078 Scheduler overhead time: 0.07609790144488215 Adapter cache time: 0.017609902657568455 Engine time: 0.07247761031612754 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-16/adapters_256_slots_32_rate_3.2-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-16/adapters_256_slots_32_rate_3.2-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 270, 34560, 34560, 270, 34560, 1080, 34560, 270, 1080, 270, 34560, 1080, 1080, 1080, 1080, 34560, 270, 270, 270, 1080, 34560, 270, 34560, 34560, 1080, 1080, 1080, 270, 34560, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 34560, 1080, 270, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 270, 34560, 34560, 1080, 270, 270, 34560, 1080, 270, 1080, 1080, 34560, 1080, 270, 270, 34560, 34560, 34560, 34560, 34560, 34560, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 34560, 34560, 270, 34560, 270, 1080, 34560, 34560, 34560, 1080, 270, 34560, 1080, 270, 270, 270, 270, 270, 34560, 1080, 270, 34560, 270, 34560, 270, 270, 1080, 1080, 34560, 1080, 34560, 270, 1080, 270, 34560, 34560, 270, 34560, 1080, 270, 34560, 270, 270, 34560, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 270, 1080, 34560, 34560, 270, 34560, 1080, 270, 1080, 34560, 270, 270, 270, 270, 270, 270, 34560, 270, 270, 270, 34560, 270, 1080, 34560, 34560, 1080, 270, 34560, 270, 1080, 1080, 270, 1080, 270, 34560, 270, 270, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 34560, 270, 34560, 270, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 1080, 1080, 270, 1080, 34560, 1080, 1080, 34560, 270, 34560, 34560, 1080, 270, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 270, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 34560, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 270, 270, 270, 270]
Prompts retrieved: 3086910 . Total input tokens: 688216455 . Total output tokens: 617448558
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 95.56284305918962,
    "estimated_duration": 3600.0294343601267,
    "input_throughput": 7410.343022581892,
    "output_throughput": 6547.657853855762,
    "total_throughput": 13958.000876437654,
    "itl": 124.88250061000603,
    "ttft": 1974683.0106477411,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 388,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2647399159427786,
    "arrivals": 1027687,
    "finished_requests": 107807,
    "scheduler_time": 225.82509084300077
}
#Debug simulation 
Total elapsed time: 95.56302870204672. Arrivals time: 0.7029200345277786 Scheduler time: 94.6645532194525 Scheduler overhead time: 0.07819468807429075 Adapter cache time: 0.01716529857367277 Engine time: 0.07353201555088162 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-32/adapters_256_slots_32_rate_3.2-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-32/adapters_256_slots_32_rate_3.2-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 270, 34560, 34560, 270, 34560, 1080, 34560, 270, 1080, 270, 34560, 1080, 1080, 1080, 1080, 34560, 270, 270, 270, 1080, 34560, 270, 34560, 34560, 1080, 1080, 1080, 270, 34560, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 34560, 1080, 270, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 270, 34560, 34560, 1080, 270, 270, 34560, 1080, 270, 1080, 1080, 34560, 1080, 270, 270, 34560, 34560, 34560, 34560, 34560, 34560, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 34560, 34560, 270, 34560, 270, 1080, 34560, 34560, 34560, 1080, 270, 34560, 1080, 270, 270, 270, 270, 270, 34560, 1080, 270, 34560, 270, 34560, 270, 270, 1080, 1080, 34560, 1080, 34560, 270, 1080, 270, 34560, 34560, 270, 34560, 1080, 270, 34560, 270, 270, 34560, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 270, 1080, 34560, 34560, 270, 34560, 1080, 270, 1080, 34560, 270, 270, 270, 270, 270, 270, 34560, 270, 270, 270, 34560, 270, 1080, 34560, 34560, 1080, 270, 34560, 270, 1080, 1080, 270, 1080, 270, 34560, 270, 270, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 34560, 270, 34560, 270, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 1080, 1080, 270, 1080, 34560, 1080, 1080, 34560, 270, 34560, 34560, 1080, 270, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 270, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 34560, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 270, 270, 270, 270]
Prompts retrieved: 3086910 . Total input tokens: 688216455 . Total output tokens: 617448558
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 95.47158599691465,
    "estimated_duration": 3600.031945916244,
    "input_throughput": 7410.337852768783,
    "output_throughput": 6547.6532858934825,
    "total_throughput": 13957.991138662264,
    "itl": 124.88251468973193,
    "ttft": 1974684.0895244693,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 388,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2672206719219756,
    "arrivals": 1027687,
    "finished_requests": 107807,
    "scheduler_time": 225.82512164313434
}
#Debug simulation 
Total elapsed time: 95.4717579879798. Arrivals time: 0.6200048257596791 Scheduler time: 94.65810395264998 Scheduler overhead time: 0.07671392802149057 Adapter cache time: 0.01718525355681777 Engine time: 0.07302316697314382 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-16-16/adapters_256_slots_32_rate_3.2-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-16-16/adapters_256_slots_32_rate_3.2-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 270, 34560, 34560, 270, 34560, 1080, 34560, 270, 1080, 270, 34560, 1080, 1080, 1080, 1080, 34560, 270, 270, 270, 1080, 34560, 270, 34560, 34560, 1080, 1080, 1080, 270, 34560, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 34560, 1080, 270, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 270, 34560, 34560, 1080, 270, 270, 34560, 1080, 270, 1080, 1080, 34560, 1080, 270, 270, 34560, 34560, 34560, 34560, 34560, 34560, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 34560, 34560, 270, 34560, 270, 1080, 34560, 34560, 34560, 1080, 270, 34560, 1080, 270, 270, 270, 270, 270, 34560, 1080, 270, 34560, 270, 34560, 270, 270, 1080, 1080, 34560, 1080, 34560, 270, 1080, 270, 34560, 34560, 270, 34560, 1080, 270, 34560, 270, 270, 34560, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 270, 1080, 34560, 34560, 270, 34560, 1080, 270, 1080, 34560, 270, 270, 270, 270, 270, 270, 34560, 270, 270, 270, 34560, 270, 1080, 34560, 34560, 1080, 270, 34560, 270, 1080, 1080, 270, 1080, 270, 34560, 270, 270, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 34560, 270, 34560, 270, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 1080, 1080, 270, 1080, 34560, 1080, 1080, 34560, 270, 34560, 34560, 1080, 270, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 270, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 34560, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 270, 270, 270, 270]
Prompts retrieved: 3086910 . Total input tokens: 688216455 . Total output tokens: 617448558
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 96.53280741488561,
    "estimated_duration": 3600.0562412860413,
    "input_throughput": 7406.142074734754,
    "output_throughput": 6543.201111654071,
    "total_throughput": 13949.343186388824,
    "itl": 124.75929306746607,
    "ttft": 1974135.0341113377,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 386,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2056424239557233,
    "arrivals": 1027687,
    "finished_requests": 107751,
    "scheduler_time": 226.22284848051584
}
#Debug simulation 
Total elapsed time: 96.53299512108788. Arrivals time: 0.6140911220572889 Scheduler time: 95.72287907730788 Scheduler overhead time: 0.07779179327189922 Adapter cache time: 0.01736201671883464 Engine time: 0.07338450290262699 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-16-32/adapters_256_slots_32_rate_3.2-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-16-32/adapters_256_slots_32_rate_3.2-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 270, 34560, 34560, 270, 34560, 1080, 34560, 270, 1080, 270, 34560, 1080, 1080, 1080, 1080, 34560, 270, 270, 270, 1080, 34560, 270, 34560, 34560, 1080, 1080, 1080, 270, 34560, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 34560, 1080, 270, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 270, 34560, 34560, 1080, 270, 270, 34560, 1080, 270, 1080, 1080, 34560, 1080, 270, 270, 34560, 34560, 34560, 34560, 34560, 34560, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 34560, 34560, 270, 34560, 270, 1080, 34560, 34560, 34560, 1080, 270, 34560, 1080, 270, 270, 270, 270, 270, 34560, 1080, 270, 34560, 270, 34560, 270, 270, 1080, 1080, 34560, 1080, 34560, 270, 1080, 270, 34560, 34560, 270, 34560, 1080, 270, 34560, 270, 270, 34560, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 270, 1080, 34560, 34560, 270, 34560, 1080, 270, 1080, 34560, 270, 270, 270, 270, 270, 270, 34560, 270, 270, 270, 34560, 270, 1080, 34560, 34560, 1080, 270, 34560, 270, 1080, 1080, 270, 1080, 270, 34560, 270, 270, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 34560, 270, 34560, 270, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 1080, 1080, 270, 1080, 34560, 1080, 1080, 34560, 270, 34560, 34560, 1080, 270, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 270, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 34560, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 270, 270, 270, 270]
Prompts retrieved: 3086910 . Total input tokens: 688216455 . Total output tokens: 617448558
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 95.64759988384321,
    "estimated_duration": 3600.048420016315,
    "input_throughput": 7410.303942489501,
    "output_throughput": 6547.623323325517,
    "total_throughput": 13957.927265815018,
    "itl": 124.88276031788222,
    "ttft": 1974691.1682539878,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 388,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2834429103694904,
    "arrivals": 1027687,
    "finished_requests": 107807,
    "scheduler_time": 225.8252603997312
}
#Debug simulation 
Total elapsed time: 95.6477769240737. Arrivals time: 0.6305513209663332 Scheduler time: 94.82255096826702 Scheduler overhead time: 0.07754095364362001 Adapter cache time: 0.017559343948960304 Engine time: 0.07301395479589701 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_16-16-16/adapters_256_slots_32_rate_3.2-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_16-16-16/adapters_256_slots_32_rate_3.2-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 270, 34560, 34560, 270, 34560, 1080, 34560, 270, 1080, 270, 34560, 1080, 1080, 1080, 1080, 34560, 270, 270, 270, 1080, 34560, 270, 34560, 34560, 1080, 1080, 1080, 270, 34560, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 34560, 1080, 270, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 270, 34560, 34560, 1080, 270, 270, 34560, 1080, 270, 1080, 1080, 34560, 1080, 270, 270, 34560, 34560, 34560, 34560, 34560, 34560, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 34560, 34560, 270, 34560, 270, 1080, 34560, 34560, 34560, 1080, 270, 34560, 1080, 270, 270, 270, 270, 270, 34560, 1080, 270, 34560, 270, 34560, 270, 270, 1080, 1080, 34560, 1080, 34560, 270, 1080, 270, 34560, 34560, 270, 34560, 1080, 270, 34560, 270, 270, 34560, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 270, 1080, 34560, 34560, 270, 34560, 1080, 270, 1080, 34560, 270, 270, 270, 270, 270, 270, 34560, 270, 270, 270, 34560, 270, 1080, 34560, 34560, 1080, 270, 34560, 270, 1080, 1080, 270, 1080, 270, 34560, 270, 270, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 34560, 270, 34560, 270, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 1080, 1080, 270, 1080, 34560, 1080, 1080, 34560, 270, 34560, 34560, 1080, 270, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 270, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 34560, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 270, 270, 270, 270]
Prompts retrieved: 3086910 . Total input tokens: 688216455 . Total output tokens: 617448558
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 95.55586872622371,
    "estimated_duration": 3600.097342873491,
    "input_throughput": 7410.368514843094,
    "output_throughput": 6547.962111820146,
    "total_throughput": 13958.330626663239,
    "itl": 124.88029668936468,
    "ttft": 1974699.0340984422,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 388,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1601395144220399,
    "arrivals": 1027687,
    "finished_requests": 107813,
    "scheduler_time": 225.83734956247199
}
#Debug simulation 
Total elapsed time: 95.55604580696672. Arrivals time: 0.6963944830931723 Scheduler time: 94.66613126732409 Scheduler overhead time: 0.07723119156435132 Adapter cache time: 0.017160273622721434 Engine time: 0.07241108687594533 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_16-16-32/adapters_256_slots_32_rate_3.2-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_16-16-32/adapters_256_slots_32_rate_3.2-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 270, 34560, 34560, 270, 34560, 1080, 34560, 270, 1080, 270, 34560, 1080, 1080, 1080, 1080, 34560, 270, 270, 270, 1080, 34560, 270, 34560, 34560, 1080, 1080, 1080, 270, 34560, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 34560, 1080, 270, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 270, 34560, 34560, 1080, 270, 270, 34560, 1080, 270, 1080, 1080, 34560, 1080, 270, 270, 34560, 34560, 34560, 34560, 34560, 34560, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 34560, 34560, 270, 34560, 270, 1080, 34560, 34560, 34560, 1080, 270, 34560, 1080, 270, 270, 270, 270, 270, 34560, 1080, 270, 34560, 270, 34560, 270, 270, 1080, 1080, 34560, 1080, 34560, 270, 1080, 270, 34560, 34560, 270, 34560, 1080, 270, 34560, 270, 270, 34560, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 270, 1080, 34560, 34560, 270, 34560, 1080, 270, 1080, 34560, 270, 270, 270, 270, 270, 270, 34560, 270, 270, 270, 34560, 270, 1080, 34560, 34560, 1080, 270, 34560, 270, 1080, 1080, 270, 1080, 270, 34560, 270, 270, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 34560, 270, 34560, 270, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 1080, 1080, 270, 1080, 34560, 1080, 1080, 34560, 270, 34560, 34560, 1080, 270, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 270, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 34560, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 270, 270, 270, 270]
Prompts retrieved: 3086910 . Total input tokens: 688216455 . Total output tokens: 617448558
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 96.1589436228387,
    "estimated_duration": 3600.0655452446026,
    "input_throughput": 7410.268692257221,
    "output_throughput": 6547.592176797004,
    "total_throughput": 13957.860869054224,
    "itl": 124.88306246496202,
    "ttft": 1974698.506537409,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 388,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2994136412441757,
    "arrivals": 1027687,
    "finished_requests": 107807,
    "scheduler_time": 225.82539695186568
}
#Debug simulation 
Total elapsed time: 96.1592113096267. Arrivals time: 0.6218859567306936 Scheduler time: 95.34305789414793 Scheduler overhead time: 0.07722228206694126 Adapter cache time: 0.017247668467462063 Engine time: 0.07274912390857935 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-8/adapters_256_slots_32_rate_3.2-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-8/adapters_256_slots_32_rate_3.2-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 135, 34560, 34560, 135, 34560, 1080, 34560, 135, 1080, 135, 34560, 1080, 1080, 1080, 1080, 34560, 135, 135, 135, 1080, 34560, 135, 34560, 34560, 1080, 1080, 1080, 135, 34560, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 34560, 1080, 135, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 135, 34560, 34560, 1080, 135, 135, 34560, 1080, 135, 1080, 1080, 34560, 1080, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 34560, 34560, 135, 34560, 135, 1080, 34560, 34560, 34560, 1080, 135, 34560, 1080, 135, 135, 135, 135, 135, 34560, 1080, 135, 34560, 135, 34560, 135, 135, 1080, 1080, 34560, 1080, 34560, 135, 1080, 135, 34560, 34560, 135, 34560, 1080, 135, 34560, 135, 135, 34560, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 135, 1080, 34560, 34560, 135, 34560, 1080, 135, 1080, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 1080, 34560, 34560, 1080, 135, 34560, 135, 1080, 1080, 135, 1080, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 34560, 135, 34560, 135, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 1080, 1080, 135, 1080, 34560, 1080, 1080, 34560, 135, 34560, 34560, 1080, 135, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 135, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 34560, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 135, 135, 135, 135]
Prompts retrieved: 3075435 . Total input tokens: 685649461 . Total output tokens: 615185283
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 102.9087477158755,
    "estimated_duration": 3600.137462046852,
    "input_throughput": 7462.33672553317,
    "output_throughput": 6565.695129474582,
    "total_throughput": 14028.031855007752,
    "itl": 125.00038344970716,
    "ttft": 1973103.493931683,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 349,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.068110222632532,
    "arrivals": 1023854,
    "finished_requests": 108175,
    "scheduler_time": 224.87075534225178
}
#Debug simulation 
Total elapsed time: 102.90892567299306. Arrivals time: 0.7525579654611647 Scheduler time: 101.96142610767856 Scheduler overhead time: 0.07839638413861394 Adapter cache time: 0.016738763079047203 Engine time: 0.07335231639444828 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-16/adapters_256_slots_32_rate_3.2-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-16/adapters_256_slots_32_rate_3.2-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 135, 34560, 34560, 135, 34560, 1080, 34560, 135, 1080, 135, 34560, 1080, 1080, 1080, 1080, 34560, 135, 135, 135, 1080, 34560, 135, 34560, 34560, 1080, 1080, 1080, 135, 34560, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 34560, 1080, 135, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 135, 34560, 34560, 1080, 135, 135, 34560, 1080, 135, 1080, 1080, 34560, 1080, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 34560, 34560, 135, 34560, 135, 1080, 34560, 34560, 34560, 1080, 135, 34560, 1080, 135, 135, 135, 135, 135, 34560, 1080, 135, 34560, 135, 34560, 135, 135, 1080, 1080, 34560, 1080, 34560, 135, 1080, 135, 34560, 34560, 135, 34560, 1080, 135, 34560, 135, 135, 34560, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 135, 1080, 34560, 34560, 135, 34560, 1080, 135, 1080, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 1080, 34560, 34560, 1080, 135, 34560, 135, 1080, 1080, 135, 1080, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 34560, 135, 34560, 135, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 1080, 1080, 135, 1080, 34560, 1080, 1080, 34560, 135, 34560, 34560, 1080, 135, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 135, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 34560, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 135, 135, 135, 135]
Prompts retrieved: 3075435 . Total input tokens: 685649461 . Total output tokens: 615185283
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 99.16519875824451,
    "estimated_duration": 3600.045062272977,
    "input_throughput": 7472.880904166882,
    "output_throughput": 6573.339108444091,
    "total_throughput": 14046.220012610973,
    "itl": 125.1140647015099,
    "ttft": 1972231.7435339196,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 367,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1978629065654296,
    "arrivals": 1023854,
    "finished_requests": 108330,
    "scheduler_time": 224.39831330792055
}
#Debug simulation 
Total elapsed time: 99.1653805100359. Arrivals time: 0.7619339996017516 Scheduler time: 98.20927031291649 Scheduler overhead time: 0.07705799536779523 Adapter cache time: 0.017176448367536068 Engine time: 0.07355517847463489 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-32/adapters_256_slots_32_rate_3.2-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-32/adapters_256_slots_32_rate_3.2-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 135, 34560, 34560, 135, 34560, 1080, 34560, 135, 1080, 135, 34560, 1080, 1080, 1080, 1080, 34560, 135, 135, 135, 1080, 34560, 135, 34560, 34560, 1080, 1080, 1080, 135, 34560, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 34560, 1080, 135, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 135, 34560, 34560, 1080, 135, 135, 34560, 1080, 135, 1080, 1080, 34560, 1080, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 34560, 34560, 135, 34560, 135, 1080, 34560, 34560, 34560, 1080, 135, 34560, 1080, 135, 135, 135, 135, 135, 34560, 1080, 135, 34560, 135, 34560, 135, 135, 1080, 1080, 34560, 1080, 34560, 135, 1080, 135, 34560, 34560, 135, 34560, 1080, 135, 34560, 135, 135, 34560, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 135, 1080, 34560, 34560, 135, 34560, 1080, 135, 1080, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 1080, 34560, 34560, 1080, 135, 34560, 135, 1080, 1080, 135, 1080, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 34560, 135, 34560, 135, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 1080, 1080, 135, 1080, 34560, 1080, 1080, 34560, 135, 34560, 34560, 1080, 135, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 135, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 34560, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 135, 135, 135, 135]
Prompts retrieved: 3075435 . Total input tokens: 685649461 . Total output tokens: 615185283
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 99.42835400532931,
    "estimated_duration": 3600.047264764638,
    "input_throughput": 7472.876332294163,
    "output_throughput": 6573.335086906731,
    "total_throughput": 14046.211419200894,
    "itl": 125.11412292112115,
    "ttft": 1972232.7247413886,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 367,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.199934301152832,
    "arrivals": 1023854,
    "finished_requests": 108330,
    "scheduler_time": 224.3983312999589
}
#Debug simulation 
Total elapsed time: 99.42853485932574. Arrivals time: 0.735665685031563 Scheduler time: 98.49827478220686 Scheduler overhead time: 0.07762130163609982 Adapter cache time: 0.017084550112485886 Engine time: 0.07320719957351685 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-16/adapters_256_slots_32_rate_3.2-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-16/adapters_256_slots_32_rate_3.2-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 135, 34560, 34560, 135, 34560, 1080, 34560, 135, 1080, 135, 34560, 1080, 1080, 1080, 1080, 34560, 135, 135, 135, 1080, 34560, 135, 34560, 34560, 1080, 1080, 1080, 135, 34560, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 34560, 1080, 135, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 135, 34560, 34560, 1080, 135, 135, 34560, 1080, 135, 1080, 1080, 34560, 1080, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 34560, 34560, 135, 34560, 135, 1080, 34560, 34560, 34560, 1080, 135, 34560, 1080, 135, 135, 135, 135, 135, 34560, 1080, 135, 34560, 135, 34560, 135, 135, 1080, 1080, 34560, 1080, 34560, 135, 1080, 135, 34560, 34560, 135, 34560, 1080, 135, 34560, 135, 135, 34560, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 135, 1080, 34560, 34560, 135, 34560, 1080, 135, 1080, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 1080, 34560, 34560, 1080, 135, 34560, 135, 1080, 1080, 135, 1080, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 34560, 135, 34560, 135, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 1080, 1080, 135, 1080, 34560, 1080, 1080, 34560, 135, 34560, 34560, 1080, 135, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 135, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 34560, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 135, 135, 135, 135]
Prompts retrieved: 3075435 . Total input tokens: 685649461 . Total output tokens: 615185283
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 99.80967445997521,
    "estimated_duration": 3600.0229069431166,
    "input_throughput": 7472.926893913535,
    "output_throughput": 6573.379562213412,
    "total_throughput": 14046.306456126948,
    "itl": 125.11222372527334,
    "ttft": 1972230.1793894707,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 367,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1459713011235004,
    "arrivals": 1023854,
    "finished_requests": 108330,
    "scheduler_time": 224.40147971807556
}
#Debug simulation 
Total elapsed time: 99.8098524082452. Arrivals time: 1.1186681743711233 Scheduler time: 98.49675032356754 Scheduler overhead time: 0.07753103459253907 Adapter cache time: 0.017261231318116188 Engine time: 0.07280978327617049 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-32/adapters_256_slots_32_rate_3.2-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-32/adapters_256_slots_32_rate_3.2-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 135, 34560, 34560, 135, 34560, 1080, 34560, 135, 1080, 135, 34560, 1080, 1080, 1080, 1080, 34560, 135, 135, 135, 1080, 34560, 135, 34560, 34560, 1080, 1080, 1080, 135, 34560, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 34560, 1080, 135, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 135, 34560, 34560, 1080, 135, 135, 34560, 1080, 135, 1080, 1080, 34560, 1080, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 34560, 34560, 135, 34560, 135, 1080, 34560, 34560, 34560, 1080, 135, 34560, 1080, 135, 135, 135, 135, 135, 34560, 1080, 135, 34560, 135, 34560, 135, 135, 1080, 1080, 34560, 1080, 34560, 135, 1080, 135, 34560, 34560, 135, 34560, 1080, 135, 34560, 135, 135, 34560, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 135, 1080, 34560, 34560, 135, 34560, 1080, 135, 1080, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 1080, 34560, 34560, 1080, 135, 34560, 135, 1080, 1080, 135, 1080, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 34560, 135, 34560, 135, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 1080, 1080, 135, 1080, 34560, 1080, 1080, 34560, 135, 34560, 34560, 1080, 135, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 135, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 34560, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 135, 135, 135, 135]
Prompts retrieved: 3075435 . Total input tokens: 685649461 . Total output tokens: 615185283
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 99.63992242887616,
    "estimated_duration": 3600.0639396024494,
    "input_throughput": 7472.841719297584,
    "output_throughput": 6573.304640420698,
    "total_throughput": 14046.146359718281,
    "itl": 125.11449298381677,
    "ttft": 1972240.3735017616,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 367,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.215905032027517,
    "arrivals": 1023854,
    "finished_requests": 108330,
    "scheduler_time": 224.3984698817452
}
#Debug simulation 
Total elapsed time: 99.64009153284132. Arrivals time: 0.739895333070308 Scheduler time: 98.70629934733734 Scheduler overhead time: 0.07712755212560296 Adapter cache time: 0.017061958089470863 Engine time: 0.072602151427418 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-16/adapters_256_slots_32_rate_3.2-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-16/adapters_256_slots_32_rate_3.2-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 135, 34560, 34560, 135, 34560, 1080, 34560, 135, 1080, 135, 34560, 1080, 1080, 1080, 1080, 34560, 135, 135, 135, 1080, 34560, 135, 34560, 34560, 1080, 1080, 1080, 135, 34560, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 34560, 1080, 135, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 135, 34560, 34560, 1080, 135, 135, 34560, 1080, 135, 1080, 1080, 34560, 1080, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 34560, 34560, 135, 34560, 135, 1080, 34560, 34560, 34560, 1080, 135, 34560, 1080, 135, 135, 135, 135, 135, 34560, 1080, 135, 34560, 135, 34560, 135, 135, 1080, 1080, 34560, 1080, 34560, 135, 1080, 135, 34560, 34560, 135, 34560, 1080, 135, 34560, 135, 135, 34560, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 135, 1080, 34560, 34560, 135, 34560, 1080, 135, 1080, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 1080, 34560, 34560, 1080, 135, 34560, 135, 1080, 1080, 135, 1080, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 34560, 135, 34560, 135, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 1080, 1080, 135, 1080, 34560, 1080, 1080, 34560, 135, 34560, 34560, 1080, 135, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 135, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 34560, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 135, 135, 135, 135]
Prompts retrieved: 3075435 . Total input tokens: 685649461 . Total output tokens: 615185283
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 102.51866144221276,
    "estimated_duration": 3600.111376643247,
    "input_throughput": 7462.390795545166,
    "output_throughput": 6565.742702671488,
    "total_throughput": 14028.133498216654,
    "itl": 124.99963031915806,
    "ttft": 1973092.4436474298,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 349,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0435275529208592,
    "arrivals": 1023854,
    "finished_requests": 108175,
    "scheduler_time": 224.86993123848768
}
#Debug simulation 
Total elapsed time: 102.51884158095345. Arrivals time: 0.7367183826863766 Scheduler time: 101.58881016867235 Scheduler overhead time: 0.07716614287346601 Adapter cache time: 0.016679120250046253 Engine time: 0.073125877417624 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-32/adapters_256_slots_32_rate_3.2-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-32/adapters_256_slots_32_rate_3.2-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 135, 34560, 34560, 135, 34560, 1080, 34560, 135, 1080, 135, 34560, 1080, 1080, 1080, 1080, 34560, 135, 135, 135, 1080, 34560, 135, 34560, 34560, 1080, 1080, 1080, 135, 34560, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 34560, 1080, 135, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 135, 34560, 34560, 1080, 135, 135, 34560, 1080, 135, 1080, 1080, 34560, 1080, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 34560, 34560, 135, 34560, 135, 1080, 34560, 34560, 34560, 1080, 135, 34560, 1080, 135, 135, 135, 135, 135, 34560, 1080, 135, 34560, 135, 34560, 135, 135, 1080, 1080, 34560, 1080, 34560, 135, 1080, 135, 34560, 34560, 135, 34560, 1080, 135, 34560, 135, 135, 34560, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 135, 1080, 34560, 34560, 135, 34560, 1080, 135, 1080, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 1080, 34560, 34560, 1080, 135, 34560, 135, 1080, 1080, 135, 1080, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 34560, 135, 34560, 135, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 1080, 1080, 135, 1080, 34560, 1080, 1080, 34560, 135, 34560, 34560, 1080, 135, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 135, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 34560, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 135, 135, 135, 135]
Prompts retrieved: 3075435 . Total input tokens: 685649461 . Total output tokens: 615185283
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 99.25456675421447,
    "estimated_duration": 3600.080319627448,
    "input_throughput": 7472.80771857446,
    "output_throughput": 6573.274732506215,
    "total_throughput": 14046.082451080674,
    "itl": 125.11507123159527,
    "ttft": 1972247.444237742,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 367,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2308697326108842,
    "arrivals": 1023854,
    "finished_requests": 108330,
    "scheduler_time": 224.39909347093953
}
#Debug simulation 
Total elapsed time: 99.25485213892534. Arrivals time: 0.6231078337877989 Scheduler time: 98.43754895869642 Scheduler overhead time: 0.07748909620568156 Adapter cache time: 0.01740607852116227 Engine time: 0.07261609332635999 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-8/adapters_256_slots_32_rate_3.2-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-8/adapters_256_slots_32_rate_3.2-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 66, 34560, 34560, 66, 34560, 1080, 34560, 66, 1080, 66, 34560, 1080, 1080, 1080, 1080, 34560, 66, 66, 66, 1080, 34560, 66, 34560, 34560, 1080, 1080, 1080, 66, 34560, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 34560, 1080, 66, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 66, 34560, 34560, 1080, 66, 66, 34560, 1080, 66, 1080, 1080, 34560, 1080, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 34560, 34560, 66, 34560, 66, 1080, 34560, 34560, 34560, 1080, 66, 34560, 1080, 66, 66, 66, 66, 66, 34560, 1080, 66, 34560, 66, 34560, 66, 66, 1080, 1080, 34560, 1080, 34560, 66, 1080, 66, 34560, 34560, 66, 34560, 1080, 66, 34560, 66, 66, 34560, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 66, 1080, 34560, 34560, 66, 34560, 1080, 66, 1080, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 1080, 34560, 34560, 1080, 66, 34560, 66, 1080, 1080, 66, 1080, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 34560, 66, 34560, 66, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 1080, 1080, 66, 1080, 34560, 1080, 1080, 34560, 66, 34560, 34560, 1080, 66, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 66, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 34560, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 66, 66, 66, 66]
Prompts retrieved: 3069570 . Total input tokens: 684327705 . Total output tokens: 614027875
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 101.26886766916141,
    "estimated_duration": 3600.0489033599342,
    "input_throughput": 7499.6447894920775,
    "output_throughput": 6609.202996601938,
    "total_throughput": 14108.847786094017,
    "itl": 125.49761310538396,
    "ttft": 1970483.8017673027,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 391,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1966507078777122,
    "arrivals": 1021838,
    "finished_requests": 109004,
    "scheduler_time": 222.3565117115703
}
#Debug simulation 
Total elapsed time: 101.26903653517365. Arrivals time: 0.6216874090023339 Scheduler time: 100.45655323145911 Scheduler overhead time: 0.07628614222630858 Adapter cache time: 0.016235283110290766 Engine time: 0.07236373471096158 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-16/adapters_256_slots_32_rate_3.2-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-16/adapters_256_slots_32_rate_3.2-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 66, 34560, 34560, 66, 34560, 1080, 34560, 66, 1080, 66, 34560, 1080, 1080, 1080, 1080, 34560, 66, 66, 66, 1080, 34560, 66, 34560, 34560, 1080, 1080, 1080, 66, 34560, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 34560, 1080, 66, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 66, 34560, 34560, 1080, 66, 66, 34560, 1080, 66, 1080, 1080, 34560, 1080, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 34560, 34560, 66, 34560, 66, 1080, 34560, 34560, 34560, 1080, 66, 34560, 1080, 66, 66, 66, 66, 66, 34560, 1080, 66, 34560, 66, 34560, 66, 66, 1080, 1080, 34560, 1080, 34560, 66, 1080, 66, 34560, 34560, 66, 34560, 1080, 66, 34560, 66, 66, 34560, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 66, 1080, 34560, 34560, 66, 34560, 1080, 66, 1080, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 1080, 34560, 34560, 1080, 66, 34560, 66, 1080, 1080, 66, 1080, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 34560, 66, 34560, 66, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 1080, 1080, 66, 1080, 34560, 1080, 1080, 34560, 66, 34560, 34560, 1080, 66, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 66, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 34560, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 66, 66, 66, 66]
Prompts retrieved: 3069570 . Total input tokens: 684327705 . Total output tokens: 614027875
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 104.6795776039362,
    "estimated_duration": 3600.109218081716,
    "input_throughput": 7476.065132918722,
    "output_throughput": 6590.404502406254,
    "total_throughput": 14066.469635324976,
    "itl": 124.99838711487176,
    "ttft": 1970820.7819844794,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 360,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1781583404564364,
    "arrivals": 1021838,
    "finished_requests": 108709,
    "scheduler_time": 223.52107062904628
}
#Debug simulation 
Total elapsed time: 104.67975387582555. Arrivals time: 0.6342691578902304 Scheduler time: 103.84906459925696 Scheduler overhead time: 0.07917820103466511 Adapter cache time: 0.016581477597355843 Engine time: 0.07402760349214077 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-32/adapters_256_slots_32_rate_3.2-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-32/adapters_256_slots_32_rate_3.2-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 66, 34560, 34560, 66, 34560, 1080, 34560, 66, 1080, 66, 34560, 1080, 1080, 1080, 1080, 34560, 66, 66, 66, 1080, 34560, 66, 34560, 34560, 1080, 1080, 1080, 66, 34560, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 34560, 1080, 66, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 66, 34560, 34560, 1080, 66, 66, 34560, 1080, 66, 1080, 1080, 34560, 1080, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 34560, 34560, 66, 34560, 66, 1080, 34560, 34560, 34560, 1080, 66, 34560, 1080, 66, 66, 66, 66, 66, 34560, 1080, 66, 34560, 66, 34560, 66, 66, 1080, 1080, 34560, 1080, 34560, 66, 1080, 66, 34560, 34560, 66, 34560, 1080, 66, 34560, 66, 66, 34560, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 66, 1080, 34560, 34560, 66, 34560, 1080, 66, 1080, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 1080, 34560, 34560, 1080, 66, 34560, 66, 1080, 1080, 66, 1080, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 34560, 66, 34560, 66, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 1080, 1080, 66, 1080, 34560, 1080, 1080, 34560, 66, 34560, 34560, 1080, 66, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 66, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 34560, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 66, 66, 66, 66]
Prompts retrieved: 3069570 . Total input tokens: 684327705 . Total output tokens: 614027875
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 104.01352263288572,
    "estimated_duration": 3600.1119786572035,
    "input_throughput": 7476.0594002519965,
    "output_throughput": 6590.399448866467,
    "total_throughput": 14066.458849118462,
    "itl": 124.99854404798165,
    "ttft": 1970822.2785452714,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 360,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.179641411695636,
    "arrivals": 1021838,
    "finished_requests": 108709,
    "scheduler_time": 223.5213301880036
}
#Debug simulation 
Total elapsed time: 104.01369772711769. Arrivals time: 0.5980490944348276 Scheduler time: 103.22286013001576 Scheduler overhead time: 0.07788583962246776 Adapter cache time: 0.015906674321740866 Engine time: 0.07273640530183911 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-16/adapters_256_slots_32_rate_3.2-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-16/adapters_256_slots_32_rate_3.2-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 66, 34560, 34560, 66, 34560, 1080, 34560, 66, 1080, 66, 34560, 1080, 1080, 1080, 1080, 34560, 66, 66, 66, 1080, 34560, 66, 34560, 34560, 1080, 1080, 1080, 66, 34560, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 34560, 1080, 66, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 66, 34560, 34560, 1080, 66, 66, 34560, 1080, 66, 1080, 1080, 34560, 1080, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 34560, 34560, 66, 34560, 66, 1080, 34560, 34560, 34560, 1080, 66, 34560, 1080, 66, 66, 66, 66, 66, 34560, 1080, 66, 34560, 66, 34560, 66, 66, 1080, 1080, 34560, 1080, 34560, 66, 1080, 66, 34560, 34560, 66, 34560, 1080, 66, 34560, 66, 66, 34560, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 66, 1080, 34560, 34560, 66, 34560, 1080, 66, 1080, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 1080, 34560, 34560, 1080, 66, 34560, 66, 1080, 1080, 66, 1080, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 34560, 66, 34560, 66, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 1080, 1080, 66, 1080, 34560, 1080, 1080, 34560, 66, 34560, 34560, 1080, 66, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 66, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 34560, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 66, 66, 66, 66]
Prompts retrieved: 3069570 . Total input tokens: 684327705 . Total output tokens: 614027875
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 102.27489562425762,
    "estimated_duration": 3600.057188029926,
    "input_throughput": 7466.898050780783,
    "output_throughput": 6584.70262050819,
    "total_throughput": 14051.600671288974,
    "itl": 124.89252275742136,
    "ttft": 1971002.9306688018,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 364,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1406785081047583,
    "arrivals": 1021838,
    "finished_requests": 108678,
    "scheduler_time": 223.8923985232991
}
#Debug simulation 
Total elapsed time: 102.27506204508245. Arrivals time: 0.5248055798001587 Scheduler time: 101.56828784756362 Scheduler overhead time: 0.07333488902077079 Adapter cache time: 0.015040744561702013 Engine time: 0.06875421712175012 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-32/adapters_256_slots_32_rate_3.2-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-32/adapters_256_slots_32_rate_3.2-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 66, 34560, 34560, 66, 34560, 1080, 34560, 66, 1080, 66, 34560, 1080, 1080, 1080, 1080, 34560, 66, 66, 66, 1080, 34560, 66, 34560, 34560, 1080, 1080, 1080, 66, 34560, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 34560, 1080, 66, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 66, 34560, 34560, 1080, 66, 66, 34560, 1080, 66, 1080, 1080, 34560, 1080, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 34560, 34560, 66, 34560, 66, 1080, 34560, 34560, 34560, 1080, 66, 34560, 1080, 66, 66, 66, 66, 66, 34560, 1080, 66, 34560, 66, 34560, 66, 66, 1080, 1080, 34560, 1080, 34560, 66, 1080, 66, 34560, 34560, 66, 34560, 1080, 66, 34560, 66, 66, 34560, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 66, 1080, 34560, 34560, 66, 34560, 1080, 66, 1080, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 1080, 34560, 34560, 1080, 66, 34560, 66, 1080, 1080, 66, 1080, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 34560, 66, 34560, 66, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 1080, 1080, 66, 1080, 34560, 1080, 1080, 34560, 66, 34560, 34560, 1080, 66, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 66, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 34560, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 66, 66, 66, 66]
Prompts retrieved: 3069570 . Total input tokens: 684327705 . Total output tokens: 614027875
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 102.86136307287961,
    "estimated_duration": 3600.127139681405,
    "input_throughput": 7476.027916720137,
    "output_throughput": 6590.371695067319,
    "total_throughput": 14066.399611787456,
    "itl": 124.99879778912849,
    "ttft": 1970828.4712127692,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 360,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1949833736382471,
    "arrivals": 1021838,
    "finished_requests": 108709,
    "scheduler_time": 223.52160167039656
}
#Debug simulation 
Total elapsed time: 102.86153577268124. Arrivals time: 0.5254588802345097 Scheduler time: 102.15183494845405 Scheduler overhead time: 0.07376656541600823 Adapter cache time: 0.01512335566803813 Engine time: 0.07013555336743593 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-16/adapters_256_slots_32_rate_3.2-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-16/adapters_256_slots_32_rate_3.2-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 66, 34560, 34560, 66, 34560, 1080, 34560, 66, 1080, 66, 34560, 1080, 1080, 1080, 1080, 34560, 66, 66, 66, 1080, 34560, 66, 34560, 34560, 1080, 1080, 1080, 66, 34560, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 34560, 1080, 66, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 66, 34560, 34560, 1080, 66, 66, 34560, 1080, 66, 1080, 1080, 34560, 1080, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 34560, 34560, 66, 34560, 66, 1080, 34560, 34560, 34560, 1080, 66, 34560, 1080, 66, 66, 66, 66, 66, 34560, 1080, 66, 34560, 66, 34560, 66, 66, 1080, 1080, 34560, 1080, 34560, 66, 1080, 66, 34560, 34560, 66, 34560, 1080, 66, 34560, 66, 66, 34560, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 66, 1080, 34560, 34560, 66, 34560, 1080, 66, 1080, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 1080, 34560, 34560, 1080, 66, 34560, 66, 1080, 1080, 66, 1080, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 34560, 66, 34560, 66, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 1080, 1080, 66, 1080, 34560, 1080, 1080, 34560, 66, 34560, 34560, 1080, 66, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 66, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 34560, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 66, 66, 66, 66]
Prompts retrieved: 3069570 . Total input tokens: 684327705 . Total output tokens: 614027875
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 99.8758532279171,
    "estimated_duration": 3600.020812894725,
    "input_throughput": 7499.703308184605,
    "output_throughput": 6609.254567300133,
    "total_throughput": 14108.957875484737,
    "itl": 125.49690745115136,
    "ttft": 1970472.1540176785,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 391,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.169109665306746,
    "arrivals": 1021838,
    "finished_requests": 109004,
    "scheduler_time": 222.35630160396042
}
#Debug simulation 
Total elapsed time: 99.87602669280022. Arrivals time: 0.5375493024475873 Scheduler time: 99.15390552952886 Scheduler overhead time: 0.07463066233322024 Adapter cache time: 0.015885408967733383 Engine time: 0.06893593352288008 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-32/adapters_256_slots_32_rate_3.2-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-32/adapters_256_slots_32_rate_3.2-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 66, 34560, 34560, 66, 34560, 1080, 34560, 66, 1080, 66, 34560, 1080, 1080, 1080, 1080, 34560, 66, 66, 66, 1080, 34560, 66, 34560, 34560, 1080, 1080, 1080, 66, 34560, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 34560, 1080, 66, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 66, 34560, 34560, 1080, 66, 66, 34560, 1080, 66, 1080, 1080, 34560, 1080, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 34560, 34560, 66, 34560, 66, 1080, 34560, 34560, 34560, 1080, 66, 34560, 1080, 66, 66, 66, 66, 66, 34560, 1080, 66, 34560, 66, 34560, 66, 66, 1080, 1080, 34560, 1080, 34560, 66, 1080, 66, 34560, 34560, 66, 34560, 1080, 66, 34560, 66, 66, 34560, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 66, 1080, 34560, 34560, 66, 34560, 1080, 66, 1080, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 1080, 34560, 34560, 1080, 66, 34560, 66, 1080, 1080, 66, 1080, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 34560, 66, 34560, 66, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 1080, 1080, 66, 1080, 34560, 1080, 1080, 34560, 66, 34560, 34560, 1080, 66, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 66, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 34560, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 66, 66, 66, 66]
Prompts retrieved: 3069570 . Total input tokens: 684327705 . Total output tokens: 614027875
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 102.83884961297736,
    "estimated_duration": 3600.142807584352,
    "input_throughput": 7475.995380877509,
    "output_throughput": 6590.343013620604,
    "total_throughput": 14066.338394498112,
    "itl": 124.99922856718196,
    "ttft": 1970834.5291926826,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 360,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2109541045129324,
    "arrivals": 1021838,
    "finished_requests": 108709,
    "scheduler_time": 223.521638157567
}
#Debug simulation 
Total elapsed time: 102.8390133548528. Arrivals time: 0.5409417608752847 Scheduler time: 102.11123235616833 Scheduler overhead time: 0.07572111114859581 Adapter cache time: 0.015265183988958597 Engine time: 0.07018381636589766 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-8/adapters_256_slots_32_rate_3.2-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-8/adapters_256_slots_32_rate_3.2-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 33, 34560, 34560, 33, 34560, 1080, 34560, 33, 1080, 33, 34560, 1080, 1080, 1080, 1080, 34560, 33, 33, 33, 1080, 34560, 33, 34560, 34560, 1080, 1080, 1080, 33, 34560, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 34560, 1080, 33, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 33, 34560, 34560, 1080, 33, 33, 34560, 1080, 33, 1080, 1080, 34560, 1080, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 34560, 34560, 33, 34560, 33, 1080, 34560, 34560, 34560, 1080, 33, 34560, 1080, 33, 33, 33, 33, 33, 34560, 1080, 33, 34560, 33, 34560, 33, 33, 1080, 1080, 34560, 1080, 34560, 33, 1080, 33, 34560, 34560, 33, 34560, 1080, 33, 34560, 33, 33, 34560, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 33, 1080, 34560, 34560, 33, 34560, 1080, 33, 1080, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 1080, 34560, 34560, 1080, 33, 34560, 33, 1080, 1080, 33, 1080, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 34560, 33, 34560, 33, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 1080, 1080, 33, 1080, 34560, 1080, 1080, 34560, 33, 34560, 34560, 1080, 33, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 33, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 34560, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 33, 33, 33, 33]
Prompts retrieved: 3066765 . Total input tokens: 683706646 . Total output tokens: 613459381
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 98.72810811037198,
    "estimated_duration": 3600.077208468235,
    "input_throughput": 7442.49677117346,
    "output_throughput": 6611.95902799206,
    "total_throughput": 14054.45579916552,
    "itl": 125.97938798070548,
    "ttft": 1966905.834867029,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 326,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9977190045220764,
    "arrivals": 1020948,
    "finished_requests": 108799,
    "scheduler_time": 222.47240094334882
}
#Debug simulation 
Total elapsed time: 98.72826369805261. Arrivals time: 0.5385104450397193 Scheduler time: 98.00736896693707 Scheduler overhead time: 0.07325181271880865 Adapter cache time: 0.015274805948138237 Engine time: 0.06882302509620786 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-16/adapters_256_slots_32_rate_3.2-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-16/adapters_256_slots_32_rate_3.2-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 33, 34560, 34560, 33, 34560, 1080, 34560, 33, 1080, 33, 34560, 1080, 1080, 1080, 1080, 34560, 33, 33, 33, 1080, 34560, 33, 34560, 34560, 1080, 1080, 1080, 33, 34560, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 34560, 1080, 33, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 33, 34560, 34560, 1080, 33, 33, 34560, 1080, 33, 1080, 1080, 34560, 1080, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 34560, 34560, 33, 34560, 33, 1080, 34560, 34560, 34560, 1080, 33, 34560, 1080, 33, 33, 33, 33, 33, 34560, 1080, 33, 34560, 33, 34560, 33, 33, 1080, 1080, 34560, 1080, 34560, 33, 1080, 33, 34560, 34560, 33, 34560, 1080, 33, 34560, 33, 33, 34560, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 33, 1080, 34560, 34560, 33, 34560, 1080, 33, 1080, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 1080, 34560, 34560, 1080, 33, 34560, 33, 1080, 1080, 33, 1080, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 34560, 33, 34560, 33, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 1080, 1080, 33, 1080, 34560, 1080, 1080, 34560, 33, 34560, 34560, 1080, 33, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 33, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 34560, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 33, 33, 33, 33]
Prompts retrieved: 3066765 . Total input tokens: 683706646 . Total output tokens: 613459381
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 95.65794856194407,
    "estimated_duration": 3600.1103992552535,
    "input_throughput": 7435.627253413578,
    "output_throughput": 6608.439009237498,
    "total_throughput": 14044.066262651077,
    "itl": 125.46348625951079,
    "ttft": 1971711.219103343,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 338,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1074740901473041,
    "arrivals": 1020948,
    "finished_requests": 108884,
    "scheduler_time": 222.64432552219253
}
#Debug simulation 
Total elapsed time: 95.6581184132956. Arrivals time: 0.5283951153978705 Scheduler time: 94.95023057749495 Scheduler overhead time: 0.07180544128641486 Adapter cache time: 0.014567840844392776 Engine time: 0.0679899463430047 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-32/adapters_256_slots_32_rate_3.2-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-32/adapters_256_slots_32_rate_3.2-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 33, 34560, 34560, 33, 34560, 1080, 34560, 33, 1080, 33, 34560, 1080, 1080, 1080, 1080, 34560, 33, 33, 33, 1080, 34560, 33, 34560, 34560, 1080, 1080, 1080, 33, 34560, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 34560, 1080, 33, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 33, 34560, 34560, 1080, 33, 33, 34560, 1080, 33, 1080, 1080, 34560, 1080, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 34560, 34560, 33, 34560, 33, 1080, 34560, 34560, 34560, 1080, 33, 34560, 1080, 33, 33, 33, 33, 33, 34560, 1080, 33, 34560, 33, 34560, 33, 33, 1080, 1080, 34560, 1080, 34560, 33, 1080, 33, 34560, 34560, 33, 34560, 1080, 33, 34560, 33, 33, 34560, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 33, 1080, 34560, 34560, 33, 34560, 1080, 33, 1080, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 1080, 34560, 34560, 1080, 33, 34560, 33, 1080, 1080, 33, 1080, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 34560, 33, 34560, 33, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 1080, 1080, 33, 1080, 34560, 1080, 1080, 34560, 33, 34560, 34560, 1080, 33, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 33, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 34560, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 33, 33, 33, 33]
Prompts retrieved: 3066765 . Total input tokens: 683706646 . Total output tokens: 613459381
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 95.21957326075062,
    "estimated_duration": 3600.111566260146,
    "input_throughput": 7435.624843095668,
    "output_throughput": 6608.4368670592585,
    "total_throughput": 14044.061710154927,
    "itl": 125.46350325925718,
    "ttft": 1971711.761793496,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 338,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1086370270885588,
    "arrivals": 1020948,
    "finished_requests": 108884,
    "scheduler_time": 222.6443295901347
}
#Debug simulation 
Total elapsed time: 95.21973684290424. Arrivals time: 0.5335069540888071 Scheduler time: 94.50786462193355 Scheduler overhead time: 0.07142146304249763 Adapter cache time: 0.014691577758640051 Engine time: 0.06740963691845536 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-16/adapters_256_slots_32_rate_3.2-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-16/adapters_256_slots_32_rate_3.2-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 33, 34560, 34560, 33, 34560, 1080, 34560, 33, 1080, 33, 34560, 1080, 1080, 1080, 1080, 34560, 33, 33, 33, 1080, 34560, 33, 34560, 34560, 1080, 1080, 1080, 33, 34560, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 34560, 1080, 33, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 33, 34560, 34560, 1080, 33, 33, 34560, 1080, 33, 1080, 1080, 34560, 1080, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 34560, 34560, 33, 34560, 33, 1080, 34560, 34560, 34560, 1080, 33, 34560, 1080, 33, 33, 33, 33, 33, 34560, 1080, 33, 34560, 33, 34560, 33, 33, 1080, 1080, 34560, 1080, 34560, 33, 1080, 33, 34560, 34560, 33, 34560, 1080, 33, 34560, 33, 33, 34560, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 33, 1080, 34560, 34560, 33, 34560, 1080, 33, 1080, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 1080, 34560, 34560, 1080, 33, 34560, 33, 1080, 1080, 33, 1080, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 34560, 33, 34560, 33, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 1080, 1080, 33, 1080, 34560, 1080, 1080, 34560, 33, 34560, 34560, 1080, 33, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 33, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 34560, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 33, 33, 33, 33]
Prompts retrieved: 3066765 . Total input tokens: 683706646 . Total output tokens: 613459381
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 105.78198153711855,
    "estimated_duration": 3600.0126063732655,
    "input_throughput": 7430.861756606392,
    "output_throughput": 6592.617469723161,
    "total_throughput": 14023.479226329553,
    "itl": 125.3320269454701,
    "ttft": 1968114.9815726404,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 310,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9730868624034373,
    "arrivals": 1020948,
    "finished_requests": 108666,
    "scheduler_time": 223.5170036861247
}
#Debug simulation 
Total elapsed time: 105.78213288914412. Arrivals time: 0.6052594385109842 Scheduler time: 104.9944023587741 Scheduler overhead time: 0.07348467875272036 Adapter cache time: 0.014424316119402647 Engine time: 0.06889272853732109 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-32/adapters_256_slots_32_rate_3.2-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-32/adapters_256_slots_32_rate_3.2-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 33, 34560, 34560, 33, 34560, 1080, 34560, 33, 1080, 33, 34560, 1080, 1080, 1080, 1080, 34560, 33, 33, 33, 1080, 34560, 33, 34560, 34560, 1080, 1080, 1080, 33, 34560, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 34560, 1080, 33, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 33, 34560, 34560, 1080, 33, 33, 34560, 1080, 33, 1080, 1080, 34560, 1080, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 34560, 34560, 33, 34560, 33, 1080, 34560, 34560, 34560, 1080, 33, 34560, 1080, 33, 33, 33, 33, 33, 34560, 1080, 33, 34560, 33, 34560, 33, 33, 1080, 1080, 34560, 1080, 34560, 33, 1080, 33, 34560, 34560, 33, 34560, 1080, 33, 34560, 33, 33, 34560, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 33, 1080, 34560, 34560, 33, 34560, 1080, 33, 1080, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 1080, 34560, 34560, 1080, 33, 34560, 33, 1080, 1080, 33, 1080, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 34560, 33, 34560, 33, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 1080, 1080, 33, 1080, 34560, 1080, 1080, 34560, 33, 34560, 34560, 1080, 33, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 33, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 34560, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 33, 33, 33, 33]
Prompts retrieved: 3066765 . Total input tokens: 683706646 . Total output tokens: 613459381
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 97.0495117479004,
    "estimated_duration": 3600.1267321331575,
    "input_throughput": 7435.593519825539,
    "output_throughput": 6608.409028396404,
    "total_throughput": 14044.002548221943,
    "itl": 125.4638627302889,
    "ttft": 1971718.3454307003,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 338,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1232244663126814,
    "arrivals": 1020948,
    "finished_requests": 108884,
    "scheduler_time": 222.64445560380554
}
#Debug simulation 
Total elapsed time: 97.0496648135595. Arrivals time: 0.8597642341628671 Scheduler time: 96.0131289595738 Scheduler overhead time: 0.06950285471975803 Adapter cache time: 0.014707650057971478 Engine time: 0.0675459043122828 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-16/adapters_256_slots_32_rate_3.2-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-16/adapters_256_slots_32_rate_3.2-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 33, 34560, 34560, 33, 34560, 1080, 34560, 33, 1080, 33, 34560, 1080, 1080, 1080, 1080, 34560, 33, 33, 33, 1080, 34560, 33, 34560, 34560, 1080, 1080, 1080, 33, 34560, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 34560, 1080, 33, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 33, 34560, 34560, 1080, 33, 33, 34560, 1080, 33, 1080, 1080, 34560, 1080, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 34560, 34560, 33, 34560, 33, 1080, 34560, 34560, 34560, 1080, 33, 34560, 1080, 33, 33, 33, 33, 33, 34560, 1080, 33, 34560, 33, 34560, 33, 33, 1080, 1080, 34560, 1080, 34560, 33, 1080, 33, 34560, 34560, 33, 34560, 1080, 33, 34560, 33, 33, 34560, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 33, 1080, 34560, 34560, 33, 34560, 1080, 33, 1080, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 1080, 34560, 34560, 1080, 33, 34560, 33, 1080, 1080, 33, 1080, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 34560, 33, 34560, 33, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 1080, 1080, 33, 1080, 34560, 1080, 1080, 34560, 33, 34560, 34560, 1080, 33, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 33, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 34560, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 33, 33, 33, 33]
Prompts retrieved: 3066765 . Total input tokens: 683706646 . Total output tokens: 613459381
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 102.44246576912701,
    "estimated_duration": 3600.0811728717404,
    "input_throughput": 7468.66354087009,
    "output_throughput": 6635.780654063353,
    "total_throughput": 14104.444194933443,
    "itl": 126.36174295039318,
    "ttft": 1965211.8202913245,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 346,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.034557402036153,
    "arrivals": 1020948,
    "finished_requests": 109174,
    "scheduler_time": 221.14250682226944
}
#Debug simulation 
Total elapsed time: 102.44260770082474. Arrivals time: 0.5473263817839324 Scheduler time: 101.71948244981468 Scheduler overhead time: 0.06932084122672677 Adapter cache time: 0.014964054338634014 Engine time: 0.06670879200100899 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-32/adapters_256_slots_32_rate_3.2-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-32/adapters_256_slots_32_rate_3.2-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 34560, 33, 34560, 34560, 33, 34560, 1080, 34560, 33, 1080, 33, 34560, 1080, 1080, 1080, 1080, 34560, 33, 33, 33, 1080, 34560, 33, 34560, 34560, 1080, 1080, 1080, 33, 34560, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 34560, 1080, 33, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 33, 34560, 34560, 1080, 33, 33, 34560, 1080, 33, 1080, 1080, 34560, 1080, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 34560, 34560, 33, 34560, 33, 1080, 34560, 34560, 34560, 1080, 33, 34560, 1080, 33, 33, 33, 33, 33, 34560, 1080, 33, 34560, 33, 34560, 33, 33, 1080, 1080, 34560, 1080, 34560, 33, 1080, 33, 34560, 34560, 33, 34560, 1080, 33, 34560, 33, 33, 34560, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 33, 1080, 34560, 34560, 33, 34560, 1080, 33, 1080, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 1080, 34560, 34560, 1080, 33, 34560, 33, 1080, 1080, 33, 1080, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 34560, 33, 34560, 33, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 1080, 1080, 33, 1080, 34560, 1080, 1080, 34560, 33, 34560, 34560, 1080, 33, 34560, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 33, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 34560, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 33, 33, 33, 33]
Prompts retrieved: 3066765 . Total input tokens: 683706646 . Total output tokens: 613459381
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 95.67704480979592,
    "estimated_duration": 3600.1398033408445,
    "input_throughput": 7435.566523044168,
    "output_throughput": 6608.385034915148,
    "total_throughput": 14043.951557959317,
    "itl": 125.46404731386127,
    "ttft": 1971723.2245820109,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 338,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1384406744688786,
    "arrivals": 1020948,
    "finished_requests": 108884,
    "scheduler_time": 222.64457270396463
}
#Debug simulation 
Total elapsed time: 95.6771906260401. Arrivals time: 0.552043171133846 Scheduler time: 94.95041194511577 Scheduler overhead time: 0.06874052295461297 Adapter cache time: 0.014664473477751017 Engine time: 0.06696935603395104 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-8/adapters_256_slots_32_rate_3.2-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-8/adapters_256_slots_32_rate_3.2-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 270, 34560, 34560, 270, 34560, 540, 34560, 270, 540, 270, 34560, 540, 540, 540, 540, 34560, 270, 270, 270, 540, 34560, 270, 34560, 34560, 540, 540, 540, 270, 34560, 270, 540, 540, 270, 540, 270, 270, 540, 540, 34560, 540, 270, 540, 34560, 540, 540, 34560, 540, 34560, 270, 34560, 34560, 540, 270, 270, 34560, 540, 270, 540, 540, 34560, 540, 270, 270, 34560, 34560, 34560, 34560, 34560, 34560, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 34560, 34560, 270, 34560, 270, 540, 34560, 34560, 34560, 540, 270, 34560, 540, 270, 270, 270, 270, 270, 34560, 540, 270, 34560, 270, 34560, 270, 270, 540, 540, 34560, 540, 34560, 270, 540, 270, 34560, 34560, 270, 34560, 540, 270, 34560, 270, 270, 34560, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 270, 540, 34560, 34560, 270, 34560, 540, 270, 540, 34560, 270, 270, 270, 270, 270, 270, 34560, 270, 270, 270, 34560, 270, 540, 34560, 34560, 540, 270, 34560, 270, 540, 540, 270, 540, 270, 34560, 270, 270, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 540, 34560, 540, 34560, 270, 34560, 270, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 540, 540, 270, 540, 34560, 540, 540, 34560, 270, 34560, 34560, 540, 270, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 270, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 34560, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 34560, 540, 270, 270, 270, 270]
Prompts retrieved: 3041010 . Total input tokens: 677979927 . Total output tokens: 608266809
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 96.26985347969458,
    "estimated_duration": 3600.0031765091558,
    "input_throughput": 7421.480951554947,
    "output_throughput": 6573.219755585351,
    "total_throughput": 13994.700707140297,
    "itl": 125.44995593431968,
    "ttft": 1972974.3125800837,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 367,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1231990020233236,
    "arrivals": 1012432,
    "finished_requests": 108120,
    "scheduler_time": 224.83370552846367
}
#Debug simulation 
Total elapsed time: 96.27000108268112. Arrivals time: 0.527827869169414 Scheduler time: 95.56591587839648 Scheduler overhead time: 0.06920901592820883 Adapter cache time: 0.014798421412706375 Engine time: 0.06727058393880725 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-16/adapters_256_slots_32_rate_3.2-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-16/adapters_256_slots_32_rate_3.2-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 270, 34560, 34560, 270, 34560, 540, 34560, 270, 540, 270, 34560, 540, 540, 540, 540, 34560, 270, 270, 270, 540, 34560, 270, 34560, 34560, 540, 540, 540, 270, 34560, 270, 540, 540, 270, 540, 270, 270, 540, 540, 34560, 540, 270, 540, 34560, 540, 540, 34560, 540, 34560, 270, 34560, 34560, 540, 270, 270, 34560, 540, 270, 540, 540, 34560, 540, 270, 270, 34560, 34560, 34560, 34560, 34560, 34560, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 34560, 34560, 270, 34560, 270, 540, 34560, 34560, 34560, 540, 270, 34560, 540, 270, 270, 270, 270, 270, 34560, 540, 270, 34560, 270, 34560, 270, 270, 540, 540, 34560, 540, 34560, 270, 540, 270, 34560, 34560, 270, 34560, 540, 270, 34560, 270, 270, 34560, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 270, 540, 34560, 34560, 270, 34560, 540, 270, 540, 34560, 270, 270, 270, 270, 270, 270, 34560, 270, 270, 270, 34560, 270, 540, 34560, 34560, 540, 270, 34560, 270, 540, 540, 270, 540, 270, 34560, 270, 270, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 540, 34560, 540, 34560, 270, 34560, 270, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 540, 540, 270, 540, 34560, 540, 540, 34560, 270, 34560, 34560, 540, 270, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 270, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 34560, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 34560, 540, 270, 270, 270, 270]
Prompts retrieved: 3041010 . Total input tokens: 677979927 . Total output tokens: 608266809
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 94.41132634226233,
    "estimated_duration": 3600.063030953255,
    "input_throughput": 7421.125899822308,
    "output_throughput": 6573.306577283443,
    "total_throughput": 13994.432477105753,
    "itl": 125.21328171851253,
    "ttft": 1972222.5993127448,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 368,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.202487338134093,
    "arrivals": 1012432,
    "finished_requests": 108140,
    "scheduler_time": 224.6224514639524
}
#Debug simulation 
Total elapsed time: 94.41147458925843. Arrivals time: 0.5372261465527117 Scheduler time: 93.69597424101084 Scheduler overhead time: 0.07002204610034823 Adapter cache time: 0.015446016564965248 Engine time: 0.06753901392221451 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-32/adapters_256_slots_32_rate_3.2-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-32/adapters_256_slots_32_rate_3.2-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 270, 34560, 34560, 270, 34560, 540, 34560, 270, 540, 270, 34560, 540, 540, 540, 540, 34560, 270, 270, 270, 540, 34560, 270, 34560, 34560, 540, 540, 540, 270, 34560, 270, 540, 540, 270, 540, 270, 270, 540, 540, 34560, 540, 270, 540, 34560, 540, 540, 34560, 540, 34560, 270, 34560, 34560, 540, 270, 270, 34560, 540, 270, 540, 540, 34560, 540, 270, 270, 34560, 34560, 34560, 34560, 34560, 34560, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 34560, 34560, 270, 34560, 270, 540, 34560, 34560, 34560, 540, 270, 34560, 540, 270, 270, 270, 270, 270, 34560, 540, 270, 34560, 270, 34560, 270, 270, 540, 540, 34560, 540, 34560, 270, 540, 270, 34560, 34560, 270, 34560, 540, 270, 34560, 270, 270, 34560, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 270, 540, 34560, 34560, 270, 34560, 540, 270, 540, 34560, 270, 270, 270, 270, 270, 270, 34560, 270, 270, 270, 34560, 270, 540, 34560, 34560, 540, 270, 34560, 270, 540, 540, 270, 540, 270, 34560, 270, 270, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 540, 34560, 540, 34560, 270, 34560, 270, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 540, 540, 270, 540, 34560, 540, 540, 34560, 270, 34560, 34560, 540, 270, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 270, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 34560, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 34560, 540, 270, 270, 270, 270]
Prompts retrieved: 3041010 . Total input tokens: 677979927 . Total output tokens: 608266809
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 94.38829676201567,
    "estimated_duration": 3600.0648650011854,
    "input_throughput": 7421.122119140263,
    "output_throughput": 6573.303228521747,
    "total_throughput": 13994.42534766201,
    "itl": 125.21332293223637,
    "ttft": 1972223.246731019,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 368,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.204326809979982,
    "arrivals": 1012432,
    "finished_requests": 108140,
    "scheduler_time": 224.6224460400295
}
#Debug simulation 
Total elapsed time: 94.38843846181408. Arrivals time: 0.5322223487310112 Scheduler time: 93.67956191301346 Scheduler overhead time: 0.06943454779684544 Adapter cache time: 0.015052327886223793 Engine time: 0.06696249404922128 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-16-16/adapters_256_slots_32_rate_3.2-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-16-16/adapters_256_slots_32_rate_3.2-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 270, 34560, 34560, 270, 34560, 540, 34560, 270, 540, 270, 34560, 540, 540, 540, 540, 34560, 270, 270, 270, 540, 34560, 270, 34560, 34560, 540, 540, 540, 270, 34560, 270, 540, 540, 270, 540, 270, 270, 540, 540, 34560, 540, 270, 540, 34560, 540, 540, 34560, 540, 34560, 270, 34560, 34560, 540, 270, 270, 34560, 540, 270, 540, 540, 34560, 540, 270, 270, 34560, 34560, 34560, 34560, 34560, 34560, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 34560, 34560, 270, 34560, 270, 540, 34560, 34560, 34560, 540, 270, 34560, 540, 270, 270, 270, 270, 270, 34560, 540, 270, 34560, 270, 34560, 270, 270, 540, 540, 34560, 540, 34560, 270, 540, 270, 34560, 34560, 270, 34560, 540, 270, 34560, 270, 270, 34560, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 270, 540, 34560, 34560, 270, 34560, 540, 270, 540, 34560, 270, 270, 270, 270, 270, 270, 34560, 270, 270, 270, 34560, 270, 540, 34560, 34560, 540, 270, 34560, 270, 540, 540, 270, 540, 270, 34560, 270, 270, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 540, 34560, 540, 34560, 270, 34560, 270, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 540, 540, 270, 540, 34560, 540, 540, 34560, 270, 34560, 34560, 540, 270, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 270, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 34560, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 34560, 540, 270, 270, 270, 270]
Prompts retrieved: 3041010 . Total input tokens: 677979927 . Total output tokens: 608266809
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 95.44609711226076,
    "estimated_duration": 3600.1227020375845,
    "input_throughput": 7444.053499852133,
    "output_throughput": 6591.811714242025,
    "total_throughput": 14035.865214094158,
    "itl": 125.38175985589548,
    "ttft": 1970637.2754318942,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 410,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2823067748546588,
    "arrivals": 1012432,
    "finished_requests": 108460,
    "scheduler_time": 223.73537504280065
}
#Debug simulation 
Total elapsed time: 95.44624306308106. Arrivals time: 0.530275852419436 Scheduler time: 94.73610144667327 Scheduler overhead time: 0.07123690843582153 Adapter cache time: 0.015855370555073023 Engine time: 0.06792026292532682 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-16-32/adapters_256_slots_32_rate_3.2-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-16-32/adapters_256_slots_32_rate_3.2-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 270, 34560, 34560, 270, 34560, 540, 34560, 270, 540, 270, 34560, 540, 540, 540, 540, 34560, 270, 270, 270, 540, 34560, 270, 34560, 34560, 540, 540, 540, 270, 34560, 270, 540, 540, 270, 540, 270, 270, 540, 540, 34560, 540, 270, 540, 34560, 540, 540, 34560, 540, 34560, 270, 34560, 34560, 540, 270, 270, 34560, 540, 270, 540, 540, 34560, 540, 270, 270, 34560, 34560, 34560, 34560, 34560, 34560, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 34560, 34560, 270, 34560, 270, 540, 34560, 34560, 34560, 540, 270, 34560, 540, 270, 270, 270, 270, 270, 34560, 540, 270, 34560, 270, 34560, 270, 270, 540, 540, 34560, 540, 34560, 270, 540, 270, 34560, 34560, 270, 34560, 540, 270, 34560, 270, 270, 34560, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 270, 540, 34560, 34560, 270, 34560, 540, 270, 540, 34560, 270, 270, 270, 270, 270, 270, 34560, 270, 270, 270, 34560, 270, 540, 34560, 34560, 540, 270, 34560, 270, 540, 540, 270, 540, 270, 34560, 270, 270, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 540, 34560, 540, 34560, 270, 34560, 270, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 540, 540, 270, 540, 34560, 540, 540, 34560, 270, 34560, 34560, 540, 270, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 270, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 34560, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 34560, 540, 270, 270, 270, 270]
Prompts retrieved: 3041010 . Total input tokens: 677979927 . Total output tokens: 608266809
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 94.46365925110877,
    "estimated_duration": 3600.0818410497927,
    "input_throughput": 7421.087125121966,
    "output_throughput": 6573.2722323610915,
    "total_throughput": 13994.359357483057,
    "itl": 125.21367744199904,
    "ttft": 1972231.0529823133,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 368,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2204232946410822,
    "arrivals": 1012432,
    "finished_requests": 108140,
    "scheduler_time": 224.62264697379504
}
#Debug simulation 
Total elapsed time: 94.4638049788773. Arrivals time: 0.5260857683606446 Scheduler time: 93.75917213223875 Scheduler overhead time: 0.07028961787000299 Adapter cache time: 0.01511465897783637 Engine time: 0.06805225368589163 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_16-16-16/adapters_256_slots_32_rate_3.2-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_16-16-16/adapters_256_slots_32_rate_3.2-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 270, 34560, 34560, 270, 34560, 540, 34560, 270, 540, 270, 34560, 540, 540, 540, 540, 34560, 270, 270, 270, 540, 34560, 270, 34560, 34560, 540, 540, 540, 270, 34560, 270, 540, 540, 270, 540, 270, 270, 540, 540, 34560, 540, 270, 540, 34560, 540, 540, 34560, 540, 34560, 270, 34560, 34560, 540, 270, 270, 34560, 540, 270, 540, 540, 34560, 540, 270, 270, 34560, 34560, 34560, 34560, 34560, 34560, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 34560, 34560, 270, 34560, 270, 540, 34560, 34560, 34560, 540, 270, 34560, 540, 270, 270, 270, 270, 270, 34560, 540, 270, 34560, 270, 34560, 270, 270, 540, 540, 34560, 540, 34560, 270, 540, 270, 34560, 34560, 270, 34560, 540, 270, 34560, 270, 270, 34560, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 270, 540, 34560, 34560, 270, 34560, 540, 270, 540, 34560, 270, 270, 270, 270, 270, 270, 34560, 270, 270, 270, 34560, 270, 540, 34560, 34560, 540, 270, 34560, 270, 540, 540, 270, 540, 270, 34560, 270, 270, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 540, 34560, 540, 34560, 270, 34560, 270, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 540, 540, 270, 540, 34560, 540, 540, 34560, 270, 34560, 34560, 540, 270, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 270, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 34560, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 34560, 540, 270, 270, 270, 270]
Prompts retrieved: 3041010 . Total input tokens: 677979927 . Total output tokens: 608266809
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 96.65697387419641,
    "estimated_duration": 3600.129106222304,
    "input_throughput": 7400.317936918699,
    "output_throughput": 6553.990510845591,
    "total_throughput": 13954.30844776429,
    "itl": 125.29634883054867,
    "ttft": 1972808.6562125478,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 361,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.079408156459684,
    "arrivals": 1012432,
    "finished_requests": 107811,
    "scheduler_time": 225.7947337073195
}
#Debug simulation 
Total elapsed time: 96.65711841685697. Arrivals time: 0.532083161175251 Scheduler time: 95.94699375191703 Scheduler overhead time: 0.06993203004822135 Adapter cache time: 0.014802674297243357 Engine time: 0.06849205447360873 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_16-16-32/adapters_256_slots_32_rate_3.2-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_16-16-32/adapters_256_slots_32_rate_3.2-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 270, 34560, 34560, 270, 34560, 540, 34560, 270, 540, 270, 34560, 540, 540, 540, 540, 34560, 270, 270, 270, 540, 34560, 270, 34560, 34560, 540, 540, 540, 270, 34560, 270, 540, 540, 270, 540, 270, 270, 540, 540, 34560, 540, 270, 540, 34560, 540, 540, 34560, 540, 34560, 270, 34560, 34560, 540, 270, 270, 34560, 540, 270, 540, 540, 34560, 540, 270, 270, 34560, 34560, 34560, 34560, 34560, 34560, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 34560, 34560, 270, 34560, 270, 540, 34560, 34560, 34560, 540, 270, 34560, 540, 270, 270, 270, 270, 270, 34560, 540, 270, 34560, 270, 34560, 270, 270, 540, 540, 34560, 540, 34560, 270, 540, 270, 34560, 34560, 270, 34560, 540, 270, 34560, 270, 270, 34560, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 270, 540, 34560, 34560, 270, 34560, 540, 270, 540, 34560, 270, 270, 270, 270, 270, 270, 34560, 270, 270, 270, 34560, 270, 540, 34560, 34560, 540, 270, 34560, 270, 540, 540, 270, 540, 270, 34560, 270, 270, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 540, 34560, 540, 34560, 270, 34560, 270, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 540, 540, 270, 540, 34560, 540, 540, 34560, 270, 34560, 34560, 540, 270, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 270, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 34560, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 34560, 540, 270, 270, 270, 270]
Prompts retrieved: 3041010 . Total input tokens: 677979927 . Total output tokens: 608266809
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 95.09550809673965,
    "estimated_duration": 3600.0974955708684,
    "input_throughput": 7421.054855561225,
    "output_throughput": 6573.243649404984,
    "total_throughput": 13994.29850496621,
    "itl": 125.21399779824077,
    "ttft": 1972237.8391750772,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 368,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2357652565836936,
    "arrivals": 1012432,
    "finished_requests": 108140,
    "scheduler_time": 224.62273332287006
}
#Debug simulation 
Total elapsed time: 95.09565702173859. Arrivals time: 0.5335329854860902 Scheduler time: 94.38512117089704 Scheduler overhead time: 0.06930371141061187 Adapter cache time: 0.015047000255435705 Engine time: 0.06742217438295484 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-8/adapters_256_slots_32_rate_3.2-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-8/adapters_256_slots_32_rate_3.2-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 135, 34560, 34560, 135, 34560, 540, 34560, 135, 540, 135, 34560, 540, 540, 540, 540, 34560, 135, 135, 135, 540, 34560, 135, 34560, 34560, 540, 540, 540, 135, 34560, 135, 540, 540, 135, 540, 135, 135, 540, 540, 34560, 540, 135, 540, 34560, 540, 540, 34560, 540, 34560, 135, 34560, 34560, 540, 135, 135, 34560, 540, 135, 540, 540, 34560, 540, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 34560, 34560, 135, 34560, 135, 540, 34560, 34560, 34560, 540, 135, 34560, 540, 135, 135, 135, 135, 135, 34560, 540, 135, 34560, 135, 34560, 135, 135, 540, 540, 34560, 540, 34560, 135, 540, 135, 34560, 34560, 135, 34560, 540, 135, 34560, 135, 135, 34560, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 135, 540, 34560, 34560, 135, 34560, 540, 135, 540, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 540, 34560, 34560, 540, 135, 34560, 135, 540, 540, 135, 540, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 540, 34560, 540, 34560, 135, 34560, 135, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 540, 540, 135, 540, 34560, 540, 540, 34560, 135, 34560, 34560, 540, 135, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 135, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 34560, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 34560, 540, 135, 135, 135, 135]
Prompts retrieved: 3029535 . Total input tokens: 675430113 . Total output tokens: 605954314
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 96.17065574787557,
    "estimated_duration": 3600.06897947287,
    "input_throughput": 7494.381955967553,
    "output_throughput": 6607.03451395611,
    "total_throughput": 14101.416469923663,
    "itl": 125.29044716010327,
    "ttft": 1972802.811603314,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 372,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1385014407429879,
    "arrivals": 1008682,
    "finished_requests": 108990,
    "scheduler_time": 222.89134419116445
}
#Debug simulation 
Total elapsed time: 96.17080450989306. Arrivals time: 0.5345498165115714 Scheduler time: 95.45958968484774 Scheduler overhead time: 0.06970766186714172 Adapter cache time: 0.014823990408331156 Engine time: 0.067668282892555 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-16/adapters_256_slots_32_rate_3.2-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-16/adapters_256_slots_32_rate_3.2-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 135, 34560, 34560, 135, 34560, 540, 34560, 135, 540, 135, 34560, 540, 540, 540, 540, 34560, 135, 135, 135, 540, 34560, 135, 34560, 34560, 540, 540, 540, 135, 34560, 135, 540, 540, 135, 540, 135, 135, 540, 540, 34560, 540, 135, 540, 34560, 540, 540, 34560, 540, 34560, 135, 34560, 34560, 540, 135, 135, 34560, 540, 135, 540, 540, 34560, 540, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 34560, 34560, 135, 34560, 135, 540, 34560, 34560, 34560, 540, 135, 34560, 540, 135, 135, 135, 135, 135, 34560, 540, 135, 34560, 135, 34560, 135, 135, 540, 540, 34560, 540, 34560, 135, 540, 135, 34560, 34560, 135, 34560, 540, 135, 34560, 135, 135, 34560, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 135, 540, 34560, 34560, 135, 34560, 540, 135, 540, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 540, 34560, 34560, 540, 135, 34560, 135, 540, 540, 135, 540, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 540, 34560, 540, 34560, 135, 34560, 135, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 540, 540, 135, 540, 34560, 540, 540, 34560, 135, 34560, 34560, 540, 135, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 135, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 34560, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 34560, 540, 135, 135, 135, 135]
Prompts retrieved: 3029535 . Total input tokens: 675430113 . Total output tokens: 605954314
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 93.90632008900866,
    "estimated_duration": 3600.0362999975614,
    "input_throughput": 7467.016929806571,
    "output_throughput": 6582.6752913619375,
    "total_throughput": 14049.692221168509,
    "itl": 124.81013027321225,
    "ttft": 1971115.1651630315,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 377,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.228172004832892,
    "arrivals": 1008682,
    "finished_requests": 108600,
    "scheduler_time": 224.09753959080163
}
#Debug simulation 
Total elapsed time: 93.90647448133677. Arrivals time: 0.5313185667619109 Scheduler time: 93.19742830330506 Scheduler overhead time: 0.06925344280898571 Adapter cache time: 0.015029270201921463 Engine time: 0.06847292836755514 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-32/adapters_256_slots_32_rate_3.2-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-32/adapters_256_slots_32_rate_3.2-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 135, 34560, 34560, 135, 34560, 540, 34560, 135, 540, 135, 34560, 540, 540, 540, 540, 34560, 135, 135, 135, 540, 34560, 135, 34560, 34560, 540, 540, 540, 135, 34560, 135, 540, 540, 135, 540, 135, 135, 540, 540, 34560, 540, 135, 540, 34560, 540, 540, 34560, 540, 34560, 135, 34560, 34560, 540, 135, 135, 34560, 540, 135, 540, 540, 34560, 540, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 34560, 34560, 135, 34560, 135, 540, 34560, 34560, 34560, 540, 135, 34560, 540, 135, 135, 135, 135, 135, 34560, 540, 135, 34560, 135, 34560, 135, 135, 540, 540, 34560, 540, 34560, 135, 540, 135, 34560, 34560, 135, 34560, 540, 135, 34560, 135, 135, 34560, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 135, 540, 34560, 34560, 135, 34560, 540, 135, 540, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 540, 34560, 34560, 540, 135, 34560, 135, 540, 540, 135, 540, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 540, 34560, 540, 34560, 135, 34560, 135, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 540, 540, 135, 540, 34560, 540, 540, 34560, 135, 34560, 34560, 540, 135, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 135, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 34560, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 34560, 540, 135, 135, 135, 135]
Prompts retrieved: 3029535 . Total input tokens: 675430113 . Total output tokens: 605954314
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 94.61411362793297,
    "estimated_duration": 3600.0386141837075,
    "input_throughput": 7467.012129839409,
    "output_throughput": 6582.671059869558,
    "total_throughput": 14049.683189708967,
    "itl": 124.81016440786313,
    "ttft": 1971116.1484836338,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 377,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2307067371346125,
    "arrivals": 1008682,
    "finished_requests": 108600,
    "scheduler_time": 224.09754525470433
}
#Debug simulation 
Total elapsed time: 94.614256773144. Arrivals time: 0.842445301823318 Scheduler time: 93.59474732307717 Scheduler overhead time: 0.06962595181539655 Adapter cache time: 0.014917343854904175 Engine time: 0.06768179591745138 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-16/adapters_256_slots_32_rate_3.2-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-16/adapters_256_slots_32_rate_3.2-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 135, 34560, 34560, 135, 34560, 540, 34560, 135, 540, 135, 34560, 540, 540, 540, 540, 34560, 135, 135, 135, 540, 34560, 135, 34560, 34560, 540, 540, 540, 135, 34560, 135, 540, 540, 135, 540, 135, 135, 540, 540, 34560, 540, 135, 540, 34560, 540, 540, 34560, 540, 34560, 135, 34560, 34560, 540, 135, 135, 34560, 540, 135, 540, 540, 34560, 540, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 34560, 34560, 135, 34560, 135, 540, 34560, 34560, 34560, 540, 135, 34560, 540, 135, 135, 135, 135, 135, 34560, 540, 135, 34560, 135, 34560, 135, 135, 540, 540, 34560, 540, 34560, 135, 540, 135, 34560, 34560, 135, 34560, 540, 135, 34560, 135, 135, 34560, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 135, 540, 34560, 34560, 135, 34560, 540, 135, 540, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 540, 34560, 34560, 540, 135, 34560, 135, 540, 540, 135, 540, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 540, 34560, 540, 34560, 135, 34560, 135, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 540, 540, 135, 540, 34560, 540, 540, 34560, 135, 34560, 34560, 540, 135, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 135, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 34560, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 34560, 540, 135, 135, 135, 135]
Prompts retrieved: 3029535 . Total input tokens: 675430113 . Total output tokens: 605954314
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 96.97348583722487,
    "estimated_duration": 3600.093759275109,
    "input_throughput": 7496.555313446666,
    "output_throughput": 6608.74093590013,
    "total_throughput": 14105.296249346797,
    "itl": 125.32443721594453,
    "ttft": 1972338.9670863359,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 371,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1579315023031092,
    "arrivals": 1008682,
    "finished_requests": 109016,
    "scheduler_time": 222.83285872846787
}
#Debug simulation 
Total elapsed time: 96.97362763527781. Arrivals time: 0.8492334284819663 Scheduler time: 95.94851079909131 Scheduler overhead time: 0.06869507161900401 Adapter cache time: 0.015022991225123405 Engine time: 0.06738887121900916 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-32/adapters_256_slots_32_rate_3.2-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-32/adapters_256_slots_32_rate_3.2-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 135, 34560, 34560, 135, 34560, 540, 34560, 135, 540, 135, 34560, 540, 540, 540, 540, 34560, 135, 135, 135, 540, 34560, 135, 34560, 34560, 540, 540, 540, 135, 34560, 135, 540, 540, 135, 540, 135, 135, 540, 540, 34560, 540, 135, 540, 34560, 540, 540, 34560, 540, 34560, 135, 34560, 34560, 540, 135, 135, 34560, 540, 135, 540, 540, 34560, 540, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 34560, 34560, 135, 34560, 135, 540, 34560, 34560, 34560, 540, 135, 34560, 540, 135, 135, 135, 135, 135, 34560, 540, 135, 34560, 135, 34560, 135, 135, 540, 540, 34560, 540, 34560, 135, 540, 135, 34560, 34560, 135, 34560, 540, 135, 34560, 135, 135, 34560, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 135, 540, 34560, 34560, 135, 34560, 540, 135, 540, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 540, 34560, 34560, 540, 135, 34560, 135, 540, 540, 135, 540, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 540, 34560, 540, 34560, 135, 34560, 135, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 540, 540, 135, 540, 34560, 540, 540, 34560, 135, 34560, 34560, 540, 135, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 135, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 34560, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 34560, 540, 135, 135, 135, 135]
Prompts retrieved: 3029535 . Total input tokens: 675430113 . Total output tokens: 605954314
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 95.98589294403791,
    "estimated_duration": 3600.0534842664015,
    "input_throughput": 7466.981287217672,
    "output_throughput": 6582.643870033786,
    "total_throughput": 14049.625157251457,
    "itl": 124.81052842073319,
    "ttft": 1971122.3412129784,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 377,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2463002066500533,
    "arrivals": 1008682,
    "finished_requests": 108600,
    "scheduler_time": 224.09761360310253
}
#Debug simulation 
Total elapsed time: 95.98603798914701. Arrivals time: 0.8403272172436118 Scheduler time: 94.96983147133142 Scheduler overhead time: 0.06921706395223737 Adapter cache time: 0.015142041724175215 Engine time: 0.06657954212278128 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-16/adapters_256_slots_32_rate_3.2-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-16/adapters_256_slots_32_rate_3.2-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 135, 34560, 34560, 135, 34560, 540, 34560, 135, 540, 135, 34560, 540, 540, 540, 540, 34560, 135, 135, 135, 540, 34560, 135, 34560, 34560, 540, 540, 540, 135, 34560, 135, 540, 540, 135, 540, 135, 135, 540, 540, 34560, 540, 135, 540, 34560, 540, 540, 34560, 540, 34560, 135, 34560, 34560, 540, 135, 135, 34560, 540, 135, 540, 540, 34560, 540, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 34560, 34560, 135, 34560, 135, 540, 34560, 34560, 34560, 540, 135, 34560, 540, 135, 135, 135, 135, 135, 34560, 540, 135, 34560, 135, 34560, 135, 135, 540, 540, 34560, 540, 34560, 135, 540, 135, 34560, 34560, 135, 34560, 540, 135, 34560, 135, 135, 34560, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 135, 540, 34560, 34560, 135, 34560, 540, 135, 540, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 540, 34560, 34560, 540, 135, 34560, 135, 540, 540, 135, 540, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 540, 34560, 540, 34560, 135, 34560, 135, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 540, 540, 135, 540, 34560, 540, 540, 34560, 135, 34560, 34560, 540, 135, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 135, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 34560, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 34560, 540, 135, 135, 135, 135]
Prompts retrieved: 3029535 . Total input tokens: 675430113 . Total output tokens: 605954314
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 96.65127308294177,
    "estimated_duration": 3600.1085025210023,
    "input_throughput": 7494.846330632945,
    "output_throughput": 6607.478075547593,
    "total_throughput": 14102.324406180538,
    "itl": 125.30650813885707,
    "ttft": 1972690.2679105715,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 371,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1093086594087047,
    "arrivals": 1008682,
    "finished_requests": 108996,
    "scheduler_time": 222.8849386459807
}
#Debug simulation 
Total elapsed time: 96.65143399871886. Arrivals time: 0.5275408527813852 Scheduler time: 95.94921338325366 Scheduler overhead time: 0.06852520117536187 Adapter cache time: 0.014786002691835165 Engine time: 0.06649378407746553 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-32/adapters_256_slots_32_rate_3.2-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-32/adapters_256_slots_32_rate_3.2-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 135, 34560, 34560, 135, 34560, 540, 34560, 135, 540, 135, 34560, 540, 540, 540, 540, 34560, 135, 135, 135, 540, 34560, 135, 34560, 34560, 540, 540, 540, 135, 34560, 135, 540, 540, 135, 540, 135, 135, 540, 540, 34560, 540, 135, 540, 34560, 540, 540, 34560, 540, 34560, 135, 34560, 34560, 540, 135, 135, 34560, 540, 135, 540, 540, 34560, 540, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 34560, 34560, 135, 34560, 135, 540, 34560, 34560, 34560, 540, 135, 34560, 540, 135, 135, 135, 135, 135, 34560, 540, 135, 34560, 135, 34560, 135, 135, 540, 540, 34560, 540, 34560, 135, 540, 135, 34560, 34560, 135, 34560, 540, 135, 34560, 135, 135, 34560, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 135, 540, 34560, 34560, 135, 34560, 540, 135, 540, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 540, 34560, 34560, 540, 135, 34560, 135, 540, 540, 135, 540, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 540, 34560, 540, 34560, 135, 34560, 135, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 540, 540, 135, 540, 34560, 540, 540, 34560, 135, 34560, 34560, 540, 135, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 135, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 34560, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 34560, 540, 135, 135, 135, 135]
Prompts retrieved: 3029535 . Total input tokens: 675430113 . Total output tokens: 605954314
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 94.67961029708385,
    "estimated_duration": 3600.070339229528,
    "input_throughput": 7466.946327985656,
    "output_throughput": 6582.613051130473,
    "total_throughput": 14049.559379116128,
    "itl": 124.81087964011729,
    "ttft": 1971129.7787302125,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 377,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2617679223790788,
    "arrivals": 1008682,
    "finished_requests": 108600,
    "scheduler_time": 224.09775669516083
}
#Debug simulation 
Total elapsed time: 94.67976179113612. Arrivals time: 0.8555634235963225 Scheduler time: 93.64791908394545 Scheduler overhead time: 0.06862203544005752 Adapter cache time: 0.015181513037532568 Engine time: 0.06735515408217907 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-8/adapters_256_slots_32_rate_3.2-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-8/adapters_256_slots_32_rate_3.2-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 66, 34560, 34560, 66, 34560, 540, 34560, 66, 540, 66, 34560, 540, 540, 540, 540, 34560, 66, 66, 66, 540, 34560, 66, 34560, 34560, 540, 540, 540, 66, 34560, 66, 540, 540, 66, 540, 66, 66, 540, 540, 34560, 540, 66, 540, 34560, 540, 540, 34560, 540, 34560, 66, 34560, 34560, 540, 66, 66, 34560, 540, 66, 540, 540, 34560, 540, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 34560, 34560, 66, 34560, 66, 540, 34560, 34560, 34560, 540, 66, 34560, 540, 66, 66, 66, 66, 66, 34560, 540, 66, 34560, 66, 34560, 66, 66, 540, 540, 34560, 540, 34560, 66, 540, 66, 34560, 34560, 66, 34560, 540, 66, 34560, 66, 66, 34560, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 66, 540, 34560, 34560, 66, 34560, 540, 66, 540, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 540, 34560, 34560, 540, 66, 34560, 66, 540, 540, 66, 540, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 540, 34560, 540, 34560, 66, 34560, 66, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 540, 540, 66, 540, 34560, 540, 540, 34560, 66, 34560, 34560, 540, 66, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 66, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 34560, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 34560, 540, 66, 66, 66, 66]
Prompts retrieved: 3023670 . Total input tokens: 674122022 . Total output tokens: 604779064
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 95.14134144317359,
    "estimated_duration": 3600.1032711317544,
    "input_throughput": 7480.145699135545,
    "output_throughput": 6585.50330767229,
    "total_throughput": 14065.649006807835,
    "itl": 125.4635823572598,
    "ttft": 1973791.2671288904,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 371,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.135440952999055,
    "arrivals": 1006798,
    "finished_requests": 108525,
    "scheduler_time": 224.00281673234508
}
#Debug simulation 
Total elapsed time: 95.14149380708113. Arrivals time: 0.5350727802142501 Scheduler time: 94.43013559095562 Scheduler overhead time: 0.06906595407053828 Adapter cache time: 0.015099312644451857 Engine time: 0.06749222334474325 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-16/adapters_256_slots_32_rate_3.2-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-16/adapters_256_slots_32_rate_3.2-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 66, 34560, 34560, 66, 34560, 540, 34560, 66, 540, 66, 34560, 540, 540, 540, 540, 34560, 66, 66, 66, 540, 34560, 66, 34560, 34560, 540, 540, 540, 66, 34560, 66, 540, 540, 66, 540, 66, 66, 540, 540, 34560, 540, 66, 540, 34560, 540, 540, 34560, 540, 34560, 66, 34560, 34560, 540, 66, 66, 34560, 540, 66, 540, 540, 34560, 540, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 34560, 34560, 66, 34560, 66, 540, 34560, 34560, 34560, 540, 66, 34560, 540, 66, 66, 66, 66, 66, 34560, 540, 66, 34560, 66, 34560, 66, 66, 540, 540, 34560, 540, 34560, 66, 540, 66, 34560, 34560, 66, 34560, 540, 66, 34560, 66, 66, 34560, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 66, 540, 34560, 34560, 66, 34560, 540, 66, 540, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 540, 34560, 34560, 540, 66, 34560, 66, 540, 540, 66, 540, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 540, 34560, 540, 34560, 66, 34560, 66, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 540, 540, 66, 540, 34560, 540, 540, 34560, 66, 34560, 34560, 540, 66, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 66, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 34560, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 34560, 540, 66, 66, 66, 66]
Prompts retrieved: 3023670 . Total input tokens: 674122022 . Total output tokens: 604779064
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 94.15790450433269,
    "estimated_duration": 3600.045271056168,
    "input_throughput": 7489.204709942478,
    "output_throughput": 6589.928796378699,
    "total_throughput": 14079.133506321177,
    "itl": 124.8748689258787,
    "ttft": 1972620.020435923,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 361,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.177062437566934,
    "arrivals": 1006798,
    "finished_requests": 108624,
    "scheduler_time": 223.7153496706111
}
#Debug simulation 
Total elapsed time: 94.15805438300595. Arrivals time: 0.5415984294377267 Scheduler time: 93.43768293689936 Scheduler overhead time: 0.07035299763083458 Adapter cache time: 0.014803359284996986 Engine time: 0.06871001003310084 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-32/adapters_256_slots_32_rate_3.2-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-32/adapters_256_slots_32_rate_3.2-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 66, 34560, 34560, 66, 34560, 540, 34560, 66, 540, 66, 34560, 540, 540, 540, 540, 34560, 66, 66, 66, 540, 34560, 66, 34560, 34560, 540, 540, 540, 66, 34560, 66, 540, 540, 66, 540, 66, 66, 540, 540, 34560, 540, 66, 540, 34560, 540, 540, 34560, 540, 34560, 66, 34560, 34560, 540, 66, 66, 34560, 540, 66, 540, 540, 34560, 540, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 34560, 34560, 66, 34560, 66, 540, 34560, 34560, 34560, 540, 66, 34560, 540, 66, 66, 66, 66, 66, 34560, 540, 66, 34560, 66, 34560, 66, 66, 540, 540, 34560, 540, 34560, 66, 540, 66, 34560, 34560, 66, 34560, 540, 66, 34560, 66, 66, 34560, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 66, 540, 34560, 34560, 66, 34560, 540, 66, 540, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 540, 34560, 34560, 540, 66, 34560, 66, 540, 540, 66, 540, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 540, 34560, 540, 34560, 66, 34560, 66, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 540, 540, 66, 540, 34560, 540, 540, 34560, 66, 34560, 34560, 540, 66, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 66, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 34560, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 34560, 540, 66, 66, 66, 66]
Prompts retrieved: 3023670 . Total input tokens: 674122022 . Total output tokens: 604779064
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 94.53050995478407,
    "estimated_duration": 3600.0477669965744,
    "input_throughput": 7489.199517620083,
    "output_throughput": 6589.924227531111,
    "total_throughput": 14079.123745151193,
    "itl": 124.87492444291632,
    "ttft": 1972621.1375844774,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 361,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1793124555982715,
    "arrivals": 1006798,
    "finished_requests": 108624,
    "scheduler_time": 223.7153693829191
}
#Debug simulation 
Total elapsed time: 94.53066247981042. Arrivals time: 0.5432210373692214 Scheduler time: 93.80973640177399 Scheduler overhead time: 0.06975120678544044 Adapter cache time: 0.015425738878548145 Engine time: 0.06761828390881419 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-16/adapters_256_slots_32_rate_3.2-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-16/adapters_256_slots_32_rate_3.2-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 66, 34560, 34560, 66, 34560, 540, 34560, 66, 540, 66, 34560, 540, 540, 540, 540, 34560, 66, 66, 66, 540, 34560, 66, 34560, 34560, 540, 540, 540, 66, 34560, 66, 540, 540, 66, 540, 66, 66, 540, 540, 34560, 540, 66, 540, 34560, 540, 540, 34560, 540, 34560, 66, 34560, 34560, 540, 66, 66, 34560, 540, 66, 540, 540, 34560, 540, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 34560, 34560, 66, 34560, 66, 540, 34560, 34560, 34560, 540, 66, 34560, 540, 66, 66, 66, 66, 66, 34560, 540, 66, 34560, 66, 34560, 66, 66, 540, 540, 34560, 540, 34560, 66, 540, 66, 34560, 34560, 66, 34560, 540, 66, 34560, 66, 66, 34560, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 66, 540, 34560, 34560, 66, 34560, 540, 66, 540, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 540, 34560, 34560, 540, 66, 34560, 66, 540, 540, 66, 540, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 540, 34560, 540, 34560, 66, 34560, 66, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 540, 540, 66, 540, 34560, 540, 540, 34560, 66, 34560, 34560, 540, 66, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 66, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 34560, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 34560, 540, 66, 66, 66, 66]
Prompts retrieved: 3023670 . Total input tokens: 674122022 . Total output tokens: 604779064
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 94.87431287532672,
    "estimated_duration": 3600.1315323796634,
    "input_throughput": 7480.086979544303,
    "output_throughput": 6585.451611077344,
    "total_throughput": 14065.538590621647,
    "itl": 125.46433325417216,
    "ttft": 1973801.2456331789,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 371,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1632432414428353,
    "arrivals": 1006798,
    "finished_requests": 108525,
    "scheduler_time": 224.0029363766695
}
#Debug simulation 
Total elapsed time: 94.87446224410087. Arrivals time: 0.5427130828611553 Scheduler time: 94.15394841320813 Scheduler overhead time: 0.07016900880262256 Adapter cache time: 0.015012137591838837 Engine time: 0.06792472722008824 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-32/adapters_256_slots_32_rate_3.2-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-32/adapters_256_slots_32_rate_3.2-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 66, 34560, 34560, 66, 34560, 540, 34560, 66, 540, 66, 34560, 540, 540, 540, 540, 34560, 66, 66, 66, 540, 34560, 66, 34560, 34560, 540, 540, 540, 66, 34560, 66, 540, 540, 66, 540, 66, 66, 540, 540, 34560, 540, 66, 540, 34560, 540, 540, 34560, 540, 34560, 66, 34560, 34560, 540, 66, 66, 34560, 540, 66, 540, 540, 34560, 540, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 34560, 34560, 66, 34560, 66, 540, 34560, 34560, 34560, 540, 66, 34560, 540, 66, 66, 66, 66, 66, 34560, 540, 66, 34560, 66, 34560, 66, 66, 540, 540, 34560, 540, 34560, 66, 540, 66, 34560, 34560, 66, 34560, 540, 66, 34560, 66, 66, 34560, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 66, 540, 34560, 34560, 66, 34560, 540, 66, 540, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 540, 34560, 34560, 540, 66, 34560, 66, 540, 540, 66, 540, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 540, 34560, 540, 34560, 66, 34560, 66, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 540, 540, 66, 540, 34560, 540, 540, 34560, 66, 34560, 34560, 540, 66, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 66, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 34560, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 34560, 540, 66, 66, 66, 66]
Prompts retrieved: 3023670 . Total input tokens: 674122022 . Total output tokens: 604779064
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 94.47825322207063,
    "estimated_duration": 3600.0987100214516,
    "input_throughput": 7474.860876756252,
    "output_throughput": 6576.464676952962,
    "total_throughput": 14051.325553709214,
    "itl": 124.44766200859779,
    "ttft": 1971887.3856440277,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 370,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2248298070579817,
    "arrivals": 1006798,
    "finished_requests": 108414,
    "scheduler_time": 224.49558036666323
}
#Debug simulation 
Total elapsed time: 94.47839966416359. Arrivals time: 0.539118227083236 Scheduler time: 93.76207996206358 Scheduler overhead time: 0.06975403241813183 Adapter cache time: 0.015421612188220024 Engine time: 0.06713591888546944 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-16/adapters_256_slots_32_rate_3.2-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-16/adapters_256_slots_32_rate_3.2-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 66, 34560, 34560, 66, 34560, 540, 34560, 66, 540, 66, 34560, 540, 540, 540, 540, 34560, 66, 66, 66, 540, 34560, 66, 34560, 34560, 540, 540, 540, 66, 34560, 66, 540, 540, 66, 540, 66, 66, 540, 540, 34560, 540, 66, 540, 34560, 540, 540, 34560, 540, 34560, 66, 34560, 34560, 540, 66, 66, 34560, 540, 66, 540, 540, 34560, 540, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 34560, 34560, 66, 34560, 66, 540, 34560, 34560, 34560, 540, 66, 34560, 540, 66, 66, 66, 66, 66, 34560, 540, 66, 34560, 66, 34560, 66, 66, 540, 540, 34560, 540, 34560, 66, 540, 66, 34560, 34560, 66, 34560, 540, 66, 34560, 66, 66, 34560, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 66, 540, 34560, 34560, 66, 34560, 540, 66, 540, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 540, 34560, 34560, 540, 66, 34560, 66, 540, 540, 66, 540, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 540, 34560, 540, 34560, 66, 34560, 66, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 540, 540, 66, 540, 34560, 540, 540, 34560, 66, 34560, 34560, 540, 66, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 66, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 34560, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 34560, 540, 66, 66, 66, 66]
Prompts retrieved: 3023670 . Total input tokens: 674122022 . Total output tokens: 604779064
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 95.32992352405563,
    "estimated_duration": 3600.0762799326367,
    "input_throughput": 7480.201780753348,
    "output_throughput": 6585.552681801405,
    "total_throughput": 14065.754462554753,
    "itl": 125.46308946557703,
    "ttft": 1973780.2608844156,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 371,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1093086594087047,
    "arrivals": 1006798,
    "finished_requests": 108525,
    "scheduler_time": 224.0025233519105
}
#Debug simulation 
Total elapsed time: 95.33007252216339. Arrivals time: 0.5481614889577031 Scheduler time: 94.60332773579285 Scheduler overhead time: 0.07020768150687218 Adapter cache time: 0.01526362681761384 Engine time: 0.06753300130367279 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-32/adapters_256_slots_32_rate_3.2-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-32/adapters_256_slots_32_rate_3.2-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 66, 34560, 34560, 66, 34560, 540, 34560, 66, 540, 66, 34560, 540, 540, 540, 540, 34560, 66, 66, 66, 540, 34560, 66, 34560, 34560, 540, 540, 540, 66, 34560, 66, 540, 540, 66, 540, 66, 66, 540, 540, 34560, 540, 66, 540, 34560, 540, 540, 34560, 540, 34560, 66, 34560, 34560, 540, 66, 66, 34560, 540, 66, 540, 540, 34560, 540, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 34560, 34560, 66, 34560, 66, 540, 34560, 34560, 34560, 540, 66, 34560, 540, 66, 66, 66, 66, 66, 34560, 540, 66, 34560, 66, 34560, 66, 66, 540, 540, 34560, 540, 34560, 66, 540, 66, 34560, 34560, 66, 34560, 540, 66, 34560, 66, 66, 34560, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 66, 540, 34560, 34560, 66, 34560, 540, 66, 540, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 540, 34560, 34560, 540, 66, 34560, 66, 540, 540, 66, 540, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 540, 34560, 540, 34560, 66, 34560, 66, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 540, 540, 66, 540, 34560, 540, 540, 34560, 66, 34560, 34560, 540, 66, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 66, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 34560, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 34560, 540, 66, 66, 66, 66]
Prompts retrieved: 3023670 . Total input tokens: 674122022 . Total output tokens: 604779064
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 94.37457162234932,
    "estimated_duration": 3600.115784427608,
    "input_throughput": 7474.825425449068,
    "output_throughput": 6576.433486503628,
    "total_throughput": 14051.258911952697,
    "itl": 124.44809709307638,
    "ttft": 1971894.063780416,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 370,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2409262917190815,
    "arrivals": 1006798,
    "finished_requests": 108414,
    "scheduler_time": 224.49606803112587
}
#Debug simulation 
Total elapsed time: 94.37471721693873. Arrivals time: 0.5294876308180392 Scheduler time: 93.66664999350905 Scheduler overhead time: 0.07024962967261672 Adapter cache time: 0.014765329658985138 Engine time: 0.06765683926641941 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-8/adapters_256_slots_32_rate_3.2-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-8/adapters_256_slots_32_rate_3.2-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 33, 34560, 34560, 33, 34560, 540, 34560, 33, 540, 33, 34560, 540, 540, 540, 540, 34560, 33, 33, 33, 540, 34560, 33, 34560, 34560, 540, 540, 540, 33, 34560, 33, 540, 540, 33, 540, 33, 33, 540, 540, 34560, 540, 33, 540, 34560, 540, 540, 34560, 540, 34560, 33, 34560, 34560, 540, 33, 33, 34560, 540, 33, 540, 540, 34560, 540, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 34560, 34560, 33, 34560, 33, 540, 34560, 34560, 34560, 540, 33, 34560, 540, 33, 33, 33, 33, 33, 34560, 540, 33, 34560, 33, 34560, 33, 33, 540, 540, 34560, 540, 34560, 33, 540, 33, 34560, 34560, 33, 34560, 540, 33, 34560, 33, 33, 34560, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 33, 540, 34560, 34560, 33, 34560, 540, 33, 540, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 540, 34560, 34560, 540, 33, 34560, 33, 540, 540, 33, 540, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 540, 34560, 540, 34560, 33, 34560, 33, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 540, 540, 33, 540, 34560, 540, 540, 34560, 33, 34560, 34560, 540, 33, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 33, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 34560, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 34560, 540, 33, 33, 33, 33]
Prompts retrieved: 3020865 . Total input tokens: 673492761 . Total output tokens: 604222272
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 99.94627425819635,
    "estimated_duration": 3600.0241750652117,
    "input_throughput": 7476.8489574135765,
    "output_throughput": 6613.768086590337,
    "total_throughput": 14090.617044003913,
    "itl": 126.33144949521791,
    "ttft": 1971366.207736574,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 334,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0222029064735392,
    "arrivals": 1005871,
    "finished_requests": 109015,
    "scheduler_time": 222.31600697845766
}
#Debug simulation 
Total elapsed time: 99.9464186350815. Arrivals time: 0.5515827178023756 Scheduler time: 99.21733623277396 Scheduler overhead time: 0.0700013441964984 Adapter cache time: 0.014790372923016548 Engine time: 0.06783175095915794 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-16/adapters_256_slots_32_rate_3.2-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-16/adapters_256_slots_32_rate_3.2-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 33, 34560, 34560, 33, 34560, 540, 34560, 33, 540, 33, 34560, 540, 540, 540, 540, 34560, 33, 33, 33, 540, 34560, 33, 34560, 34560, 540, 540, 540, 33, 34560, 33, 540, 540, 33, 540, 33, 33, 540, 540, 34560, 540, 33, 540, 34560, 540, 540, 34560, 540, 34560, 33, 34560, 34560, 540, 33, 33, 34560, 540, 33, 540, 540, 34560, 540, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 34560, 34560, 33, 34560, 33, 540, 34560, 34560, 34560, 540, 33, 34560, 540, 33, 33, 33, 33, 33, 34560, 540, 33, 34560, 33, 34560, 33, 33, 540, 540, 34560, 540, 34560, 33, 540, 33, 34560, 34560, 33, 34560, 540, 33, 34560, 33, 33, 34560, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 33, 540, 34560, 34560, 33, 34560, 540, 33, 540, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 540, 34560, 34560, 540, 33, 34560, 33, 540, 540, 33, 540, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 540, 34560, 540, 34560, 33, 34560, 33, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 540, 540, 33, 540, 34560, 540, 540, 34560, 33, 34560, 34560, 540, 33, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 33, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 34560, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 34560, 540, 33, 33, 33, 33]
Prompts retrieved: 3020865 . Total input tokens: 673492761 . Total output tokens: 604222272
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 94.08265074901283,
    "estimated_duration": 3600.043226580855,
    "input_throughput": 7475.258575036331,
    "output_throughput": 6612.419491031729,
    "total_throughput": 14087.678066068062,
    "itl": 126.2644105743119,
    "ttft": 1968275.7512286867,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 365,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1902484247018643,
    "arrivals": 1005871,
    "finished_requests": 109003,
    "scheduler_time": 222.32328152808157
}
#Debug simulation 
Total elapsed time: 94.08279574615881. Arrivals time: 0.5393410120159388 Scheduler time: 93.36834054486826 Scheduler overhead time: 0.06822234764695168 Adapter cache time: 0.014723870903253555 Engine time: 0.0674973470158875 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-32/adapters_256_slots_32_rate_3.2-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-32/adapters_256_slots_32_rate_3.2-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 33, 34560, 34560, 33, 34560, 540, 34560, 33, 540, 33, 34560, 540, 540, 540, 540, 34560, 33, 33, 33, 540, 34560, 33, 34560, 34560, 540, 540, 540, 33, 34560, 33, 540, 540, 33, 540, 33, 33, 540, 540, 34560, 540, 33, 540, 34560, 540, 540, 34560, 540, 34560, 33, 34560, 34560, 540, 33, 33, 34560, 540, 33, 540, 540, 34560, 540, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 34560, 34560, 33, 34560, 33, 540, 34560, 34560, 34560, 540, 33, 34560, 540, 33, 33, 33, 33, 33, 34560, 540, 33, 34560, 33, 34560, 33, 33, 540, 540, 34560, 540, 34560, 33, 540, 33, 34560, 34560, 33, 34560, 540, 33, 34560, 33, 33, 34560, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 33, 540, 34560, 34560, 33, 34560, 540, 33, 540, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 540, 34560, 34560, 540, 33, 34560, 33, 540, 540, 33, 540, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 540, 34560, 540, 34560, 33, 34560, 33, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 540, 540, 33, 540, 34560, 540, 540, 34560, 33, 34560, 34560, 540, 33, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 33, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 34560, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 34560, 540, 33, 33, 33, 33]
Prompts retrieved: 3020865 . Total input tokens: 673492761 . Total output tokens: 604222272
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 93.90179467201233,
    "estimated_duration": 3600.0451495814846,
    "input_throughput": 7475.254582051147,
    "output_throughput": 6612.415958940792,
    "total_throughput": 14087.67054099194,
    "itl": 126.2644234553969,
    "ttft": 1968276.4636151136,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 365,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.192498273476965,
    "arrivals": 1005871,
    "finished_requests": 109003,
    "scheduler_time": 222.32329399502203
}
#Debug simulation 
Total elapsed time: 93.90194027684629. Arrivals time: 0.5387484133243561 Scheduler time: 93.1870585968718 Scheduler overhead time: 0.06960757123306394 Adapter cache time: 0.014893603511154652 Engine time: 0.06666786363348365 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-16/adapters_256_slots_32_rate_3.2-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-16/adapters_256_slots_32_rate_3.2-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 33, 34560, 34560, 33, 34560, 540, 34560, 33, 540, 33, 34560, 540, 540, 540, 540, 34560, 33, 33, 33, 540, 34560, 33, 34560, 34560, 540, 540, 540, 33, 34560, 33, 540, 540, 33, 540, 33, 33, 540, 540, 34560, 540, 33, 540, 34560, 540, 540, 34560, 540, 34560, 33, 34560, 34560, 540, 33, 33, 34560, 540, 33, 540, 540, 34560, 540, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 34560, 34560, 33, 34560, 33, 540, 34560, 34560, 34560, 540, 33, 34560, 540, 33, 33, 33, 33, 33, 34560, 540, 33, 34560, 33, 34560, 33, 33, 540, 540, 34560, 540, 34560, 33, 540, 33, 34560, 34560, 33, 34560, 540, 33, 34560, 33, 33, 34560, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 33, 540, 34560, 34560, 33, 34560, 540, 33, 540, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 540, 34560, 34560, 540, 33, 34560, 33, 540, 540, 33, 540, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 540, 34560, 540, 34560, 33, 34560, 33, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 540, 540, 33, 540, 34560, 540, 540, 34560, 33, 34560, 34560, 540, 33, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 33, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 34560, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 34560, 540, 33, 33, 33, 33]
Prompts retrieved: 3020865 . Total input tokens: 673492761 . Total output tokens: 604222272
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 99.93489904981107,
    "estimated_duration": 3600.043247137433,
    "input_throughput": 7476.809347055169,
    "output_throughput": 6613.733048604973,
    "total_throughput": 14090.542395660143,
    "itl": 126.3319015002737,
    "ttft": 1971373.5741842252,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 334,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0411707116151259,
    "arrivals": 1005871,
    "finished_requests": 109015,
    "scheduler_time": 222.3160281537786
}
#Debug simulation 
Total elapsed time: 99.93504203576595. Arrivals time: 0.5439006425440311 Scheduler time: 99.21473749773577 Scheduler overhead time: 0.0693483748473227 Adapter cache time: 0.014600913971662521 Engine time: 0.06765269348397851 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-32/adapters_256_slots_32_rate_3.2-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-32/adapters_256_slots_32_rate_3.2-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 33, 34560, 34560, 33, 34560, 540, 34560, 33, 540, 33, 34560, 540, 540, 540, 540, 34560, 33, 33, 33, 540, 34560, 33, 34560, 34560, 540, 540, 540, 33, 34560, 33, 540, 540, 33, 540, 33, 33, 540, 540, 34560, 540, 33, 540, 34560, 540, 540, 34560, 540, 34560, 33, 34560, 34560, 540, 33, 33, 34560, 540, 33, 540, 540, 34560, 540, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 34560, 34560, 33, 34560, 33, 540, 34560, 34560, 34560, 540, 33, 34560, 540, 33, 33, 33, 33, 33, 34560, 540, 33, 34560, 33, 34560, 33, 33, 540, 540, 34560, 540, 34560, 33, 540, 33, 34560, 34560, 33, 34560, 540, 33, 34560, 33, 33, 34560, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 33, 540, 34560, 34560, 33, 34560, 540, 33, 540, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 540, 34560, 34560, 540, 33, 34560, 33, 540, 540, 33, 540, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 540, 34560, 540, 34560, 33, 34560, 33, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 540, 540, 33, 540, 34560, 540, 540, 34560, 33, 34560, 34560, 540, 33, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 33, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 34560, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 34560, 540, 33, 33, 33, 33]
Prompts retrieved: 3020865 . Total input tokens: 673492761 . Total output tokens: 604222272
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 103.11109124915674,
    "estimated_duration": 3600.0599221765005,
    "input_throughput": 7475.223907864892,
    "output_throughput": 6612.388825352699,
    "total_throughput": 14087.612733217591,
    "itl": 126.264364126327,
    "ttft": 1968282.0958521552,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 365,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2073372202739179,
    "arrivals": 1005871,
    "finished_requests": 109003,
    "scheduler_time": 222.3234538533043
}
#Debug simulation 
Total elapsed time: 103.11123888706788. Arrivals time: 0.5480073229409754 Scheduler time: 102.38316241186112 Scheduler overhead time: 0.07025421038269997 Adapter cache time: 0.015322316903620958 Engine time: 0.0691490201279521 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-16/adapters_256_slots_32_rate_3.2-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-16/adapters_256_slots_32_rate_3.2-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 33, 34560, 34560, 33, 34560, 540, 34560, 33, 540, 33, 34560, 540, 540, 540, 540, 34560, 33, 33, 33, 540, 34560, 33, 34560, 34560, 540, 540, 540, 33, 34560, 33, 540, 540, 33, 540, 33, 33, 540, 540, 34560, 540, 33, 540, 34560, 540, 540, 34560, 540, 34560, 33, 34560, 34560, 540, 33, 33, 34560, 540, 33, 540, 540, 34560, 540, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 34560, 34560, 33, 34560, 33, 540, 34560, 34560, 34560, 540, 33, 34560, 540, 33, 33, 33, 33, 33, 34560, 540, 33, 34560, 33, 34560, 33, 33, 540, 540, 34560, 540, 34560, 33, 540, 33, 34560, 34560, 33, 34560, 540, 33, 34560, 33, 33, 34560, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 33, 540, 34560, 34560, 33, 34560, 540, 33, 540, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 540, 34560, 34560, 540, 33, 34560, 33, 540, 540, 33, 540, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 540, 34560, 540, 34560, 33, 34560, 33, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 540, 540, 33, 540, 34560, 540, 540, 34560, 33, 34560, 34560, 540, 33, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 33, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 34560, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 34560, 540, 33, 33, 33, 33]
Prompts retrieved: 3020865 . Total input tokens: 673492761 . Total output tokens: 604222272
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 99.82852482283488,
    "estimated_duration": 3600.1446324436993,
    "input_throughput": 7476.896277283369,
    "output_throughput": 6613.704012174116,
    "total_throughput": 14090.600289457485,
    "itl": 126.33047264777913,
    "ttft": 1971371.8396881633,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 334,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.998676798497328,
    "arrivals": 1005871,
    "finished_requests": 109017,
    "scheduler_time": 222.3245004544016
}
#Debug simulation 
Total elapsed time: 99.82867294875905. Arrivals time: 0.5591280655935407 Scheduler time: 99.09208929771557 Scheduler overhead time: 0.07024157606065273 Adapter cache time: 0.014586880803108215 Engine time: 0.06790386652573943 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-32/adapters_256_slots_32_rate_3.2-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-32/adapters_256_slots_32_rate_3.2-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 33, 34560, 34560, 33, 34560, 540, 34560, 33, 540, 33, 34560, 540, 540, 540, 540, 34560, 33, 33, 33, 540, 34560, 33, 34560, 34560, 540, 540, 540, 33, 34560, 33, 540, 540, 33, 540, 33, 33, 540, 540, 34560, 540, 33, 540, 34560, 540, 540, 34560, 540, 34560, 33, 34560, 34560, 540, 33, 33, 34560, 540, 33, 540, 540, 34560, 540, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 34560, 34560, 33, 34560, 33, 540, 34560, 34560, 34560, 540, 33, 34560, 540, 33, 33, 33, 33, 33, 34560, 540, 33, 34560, 33, 34560, 33, 33, 540, 540, 34560, 540, 34560, 33, 540, 33, 34560, 34560, 33, 34560, 540, 33, 34560, 33, 33, 34560, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 33, 540, 34560, 34560, 33, 34560, 540, 33, 540, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 540, 34560, 34560, 540, 33, 34560, 33, 540, 540, 33, 540, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 540, 34560, 540, 34560, 33, 34560, 33, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 540, 540, 33, 540, 34560, 540, 540, 34560, 33, 34560, 34560, 540, 33, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 33, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 34560, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 34560, 540, 33, 33, 33, 33]
Prompts retrieved: 3020865 . Total input tokens: 673492761 . Total output tokens: 604222272
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 93.90314918197691,
    "estimated_duration": 3600.075683935691,
    "input_throughput": 7475.191180030959,
    "output_throughput": 6612.359875161234,
    "total_throughput": 14087.551055192194,
    "itl": 126.26476367843709,
    "ttft": 1968288.064730079,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 365,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2229306897893577,
    "arrivals": 1005871,
    "finished_requests": 109003,
    "scheduler_time": 222.32350903795682
}
#Debug simulation 
Total elapsed time: 93.90328914998099. Arrivals time: 0.5514547037892044 Scheduler time: 93.17578229308128 Scheduler overhead time: 0.06933731120079756 Adapter cache time: 0.01522962050512433 Engine time: 0.06685620918869972 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-8/adapters_256_slots_32_rate_3.2-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-8/adapters_256_slots_32_rate_3.2-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 135, 34560, 34560, 135, 34560, 270, 34560, 135, 270, 135, 34560, 270, 270, 270, 270, 34560, 135, 135, 135, 270, 34560, 135, 34560, 34560, 270, 270, 270, 135, 34560, 135, 270, 270, 135, 270, 135, 135, 270, 270, 34560, 270, 135, 270, 34560, 270, 270, 34560, 270, 34560, 135, 34560, 34560, 270, 135, 135, 34560, 270, 135, 270, 270, 34560, 270, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 34560, 34560, 135, 34560, 135, 270, 34560, 34560, 34560, 270, 135, 34560, 270, 135, 135, 135, 135, 135, 34560, 270, 135, 34560, 135, 34560, 135, 135, 270, 270, 34560, 270, 34560, 135, 270, 135, 34560, 34560, 135, 34560, 270, 135, 34560, 135, 135, 34560, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 135, 270, 34560, 34560, 135, 34560, 270, 135, 270, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 270, 34560, 34560, 270, 135, 34560, 135, 270, 270, 135, 270, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 270, 34560, 270, 34560, 135, 34560, 135, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 270, 270, 135, 270, 34560, 270, 270, 34560, 135, 34560, 34560, 270, 135, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 135, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 34560, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 34560, 270, 135, 135, 135, 135]
Prompts retrieved: 3006585 . Total input tokens: 670334443 . Total output tokens: 601394933
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 95.59755511581898,
    "estimated_duration": 3600.1255617322354,
    "input_throughput": 7468.890331442252,
    "output_throughput": 6617.220869523622,
    "total_throughput": 14086.111200965874,
    "itl": 126.1810775463652,
    "ttft": 1967751.4015046996,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 376,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1507433917187193,
    "arrivals": 1001073,
    "finished_requests": 108672,
    "scheduler_time": 222.17989414734748
}
#Debug simulation 
Total elapsed time: 95.59771248698235. Arrivals time: 0.6644684080965817 Scheduler time: 94.75682826293632 Scheduler overhead time: 0.06938778748735785 Adapter cache time: 0.015155354514718056 Engine time: 0.0669894888997078 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-16/adapters_256_slots_32_rate_3.2-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-16/adapters_256_slots_32_rate_3.2-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 135, 34560, 34560, 135, 34560, 270, 34560, 135, 270, 135, 34560, 270, 270, 270, 270, 34560, 135, 135, 135, 270, 34560, 135, 34560, 34560, 270, 270, 270, 135, 34560, 135, 270, 270, 135, 270, 135, 135, 270, 270, 34560, 270, 135, 270, 34560, 270, 270, 34560, 270, 34560, 135, 34560, 34560, 270, 135, 135, 34560, 270, 135, 270, 270, 34560, 270, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 34560, 34560, 135, 34560, 135, 270, 34560, 34560, 34560, 270, 135, 34560, 270, 135, 135, 135, 135, 135, 34560, 270, 135, 34560, 135, 34560, 135, 135, 270, 270, 34560, 270, 34560, 135, 270, 135, 34560, 34560, 135, 34560, 270, 135, 34560, 135, 135, 34560, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 135, 270, 34560, 34560, 135, 34560, 270, 135, 270, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 270, 34560, 34560, 270, 135, 34560, 135, 270, 270, 135, 270, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 270, 34560, 270, 34560, 135, 34560, 135, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 270, 270, 135, 270, 34560, 270, 270, 34560, 135, 34560, 34560, 270, 135, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 135, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 34560, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 34560, 270, 135, 135, 135, 135]
Prompts retrieved: 3006585 . Total input tokens: 670334443 . Total output tokens: 601394933
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 95.53849487798288,
    "estimated_duration": 3600.076900057773,
    "input_throughput": 7462.936138827714,
    "output_throughput": 6610.126022479718,
    "total_throughput": 14073.06216130743,
    "itl": 126.1537195111149,
    "ttft": 1966309.7157745513,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 394,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.286766170896596,
    "arrivals": 1001073,
    "finished_requests": 108561,
    "scheduler_time": 222.51764014957377
}
#Debug simulation 
Total elapsed time: 95.53864859370515. Arrivals time: 0.5427127038128674 Scheduler time: 94.81746598053724 Scheduler overhead time: 0.0694196610711515 Adapter cache time: 0.015936492010951042 Engine time: 0.06831692438572645 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-32/adapters_256_slots_32_rate_3.2-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-32/adapters_256_slots_32_rate_3.2-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 135, 34560, 34560, 135, 34560, 270, 34560, 135, 270, 135, 34560, 270, 270, 270, 270, 34560, 135, 135, 135, 270, 34560, 135, 34560, 34560, 270, 270, 270, 135, 34560, 135, 270, 270, 135, 270, 135, 135, 270, 270, 34560, 270, 135, 270, 34560, 270, 270, 34560, 270, 34560, 135, 34560, 34560, 270, 135, 135, 34560, 270, 135, 270, 270, 34560, 270, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 34560, 34560, 135, 34560, 135, 270, 34560, 34560, 34560, 270, 135, 34560, 270, 135, 135, 135, 135, 135, 34560, 270, 135, 34560, 135, 34560, 135, 135, 270, 270, 34560, 270, 34560, 135, 270, 135, 34560, 34560, 135, 34560, 270, 135, 34560, 135, 135, 34560, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 135, 270, 34560, 34560, 135, 34560, 270, 135, 270, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 270, 34560, 34560, 270, 135, 34560, 135, 270, 270, 135, 270, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 270, 34560, 270, 34560, 135, 34560, 135, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 270, 270, 135, 270, 34560, 270, 270, 34560, 135, 34560, 34560, 270, 135, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 135, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 34560, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 34560, 270, 135, 135, 135, 135]
Prompts retrieved: 3006585 . Total input tokens: 670334443 . Total output tokens: 601394933
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 95.95782213006169,
    "estimated_duration": 3600.079002287789,
    "input_throughput": 7462.931780921026,
    "output_throughput": 6610.122162562942,
    "total_throughput": 14073.053943483968,
    "itl": 126.153768495366,
    "ttft": 1966310.6705818148,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 394,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2888542599603607,
    "arrivals": 1001073,
    "finished_requests": 108561,
    "scheduler_time": 222.51765429051562
}
#Debug simulation 
Total elapsed time: 95.95797511516139. Arrivals time: 0.8502489617094398 Scheduler time: 94.9317059693858 Scheduler overhead time: 0.06875922484323382 Adapter cache time: 0.015625030733644962 Engine time: 0.06699930690228939 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-16/adapters_256_slots_32_rate_3.2-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-16/adapters_256_slots_32_rate_3.2-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 135, 34560, 34560, 135, 34560, 270, 34560, 135, 270, 135, 34560, 270, 270, 270, 270, 34560, 135, 135, 135, 270, 34560, 135, 34560, 34560, 270, 270, 270, 135, 34560, 135, 270, 270, 135, 270, 135, 135, 270, 270, 34560, 270, 135, 270, 34560, 270, 270, 34560, 270, 34560, 135, 34560, 34560, 270, 135, 135, 34560, 270, 135, 270, 270, 34560, 270, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 34560, 34560, 135, 34560, 135, 270, 34560, 34560, 34560, 270, 135, 34560, 270, 135, 135, 135, 135, 135, 34560, 270, 135, 34560, 135, 34560, 135, 135, 270, 270, 34560, 270, 34560, 135, 270, 135, 34560, 34560, 135, 34560, 270, 135, 34560, 135, 135, 34560, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 135, 270, 34560, 34560, 135, 34560, 270, 135, 270, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 270, 34560, 34560, 270, 135, 34560, 135, 270, 270, 135, 270, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 270, 34560, 270, 34560, 135, 34560, 135, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 270, 270, 135, 270, 34560, 270, 270, 34560, 135, 34560, 34560, 270, 135, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 135, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 34560, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 34560, 270, 135, 135, 135, 135]
Prompts retrieved: 3006585 . Total input tokens: 670334443 . Total output tokens: 601394933
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 96.11193869495764,
    "estimated_duration": 3600.022798597952,
    "input_throughput": 7463.048292489579,
    "output_throughput": 6610.225360036013,
    "total_throughput": 14073.273652525591,
    "itl": 126.15242296888482,
    "ttft": 1966287.7806014097,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 394,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2324229935440232,
    "arrivals": 1001073,
    "finished_requests": 108561,
    "scheduler_time": 222.51731634193303
}
#Debug simulation 
Total elapsed time: 96.11209658812732. Arrivals time: 0.6688669873401523 Scheduler time: 95.26475224550813 Scheduler overhead time: 0.06981756119057536 Adapter cache time: 0.015575702302157879 Engine time: 0.0678917863406241 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-32/adapters_256_slots_32_rate_3.2-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-32/adapters_256_slots_32_rate_3.2-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 135, 34560, 34560, 135, 34560, 270, 34560, 135, 270, 135, 34560, 270, 270, 270, 270, 34560, 135, 135, 135, 270, 34560, 135, 34560, 34560, 270, 270, 270, 135, 34560, 135, 270, 270, 135, 270, 135, 135, 270, 270, 34560, 270, 135, 270, 34560, 270, 270, 34560, 270, 34560, 135, 34560, 34560, 270, 135, 135, 34560, 270, 135, 270, 270, 34560, 270, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 34560, 34560, 135, 34560, 135, 270, 34560, 34560, 34560, 270, 135, 34560, 270, 135, 135, 135, 135, 135, 34560, 270, 135, 34560, 135, 34560, 135, 135, 270, 270, 34560, 270, 34560, 135, 270, 135, 34560, 34560, 135, 34560, 270, 135, 34560, 135, 135, 34560, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 135, 270, 34560, 34560, 135, 34560, 270, 135, 270, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 270, 34560, 34560, 270, 135, 34560, 135, 270, 270, 135, 270, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 270, 34560, 270, 34560, 135, 34560, 135, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 270, 270, 135, 270, 34560, 270, 270, 34560, 135, 34560, 34560, 270, 135, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 135, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 34560, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 34560, 270, 135, 135, 135, 135]
Prompts retrieved: 3006585 . Total input tokens: 670334443 . Total output tokens: 601394933
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 95.9628583965823,
    "estimated_duration": 3600.097736409084,
    "input_throughput": 7462.892945456148,
    "output_throughput": 6610.087764932812,
    "total_throughput": 14072.98071038896,
    "itl": 126.15447373984978,
    "ttft": 1966318.1802553565,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 394,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3055795135535342,
    "arrivals": 1001073,
    "finished_requests": 108561,
    "scheduler_time": 222.5184190028803
}
#Debug simulation 
Total elapsed time: 95.9630101728253. Arrivals time: 0.5494371638633311 Scheduler time: 95.2349444013089 Scheduler overhead time: 0.07020476227626204 Adapter cache time: 0.015518454369157553 Engine time: 0.06768496800214052 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-16/adapters_256_slots_32_rate_3.2-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-16/adapters_256_slots_32_rate_3.2-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 135, 34560, 34560, 135, 34560, 270, 34560, 135, 270, 135, 34560, 270, 270, 270, 270, 34560, 135, 135, 135, 270, 34560, 135, 34560, 34560, 270, 270, 270, 135, 34560, 135, 270, 270, 135, 270, 135, 135, 270, 270, 34560, 270, 135, 270, 34560, 270, 270, 34560, 270, 34560, 135, 34560, 34560, 270, 135, 135, 34560, 270, 135, 270, 270, 34560, 270, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 34560, 34560, 135, 34560, 135, 270, 34560, 34560, 34560, 270, 135, 34560, 270, 135, 135, 135, 135, 135, 34560, 270, 135, 34560, 135, 34560, 135, 135, 270, 270, 34560, 270, 34560, 135, 270, 135, 34560, 34560, 135, 34560, 270, 135, 34560, 135, 135, 34560, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 135, 270, 34560, 34560, 135, 34560, 270, 135, 270, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 270, 34560, 34560, 270, 135, 34560, 135, 270, 270, 135, 270, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 270, 34560, 270, 34560, 135, 34560, 135, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 270, 270, 135, 270, 34560, 270, 270, 34560, 135, 34560, 34560, 270, 135, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 135, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 34560, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 34560, 270, 135, 135, 135, 135]
Prompts retrieved: 3006585 . Total input tokens: 670334443 . Total output tokens: 601394933
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 91.5322876246646,
    "estimated_duration": 3600.0262936051367,
    "input_throughput": 7443.225636323382,
    "output_throughput": 6595.206552289756,
    "total_throughput": 14038.432188613137,
    "itl": 125.92999858882919,
    "ttft": 1965923.6091992282,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 394,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1780798161914523,
    "arrivals": 1001073,
    "finished_requests": 108295,
    "scheduler_time": 223.30584850847822
}
#Debug simulation 
Total elapsed time: 91.53243407187983. Arrivals time: 0.6489225928671658 Scheduler time: 90.70699469279498 Scheduler overhead time: 0.06949815433472395 Adapter cache time: 0.015089085791260004 Engine time: 0.066850402392447 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-32/adapters_256_slots_32_rate_3.2-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-32/adapters_256_slots_32_rate_3.2-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 135, 34560, 34560, 135, 34560, 270, 34560, 135, 270, 135, 34560, 270, 270, 270, 270, 34560, 135, 135, 135, 270, 34560, 135, 34560, 34560, 270, 270, 270, 135, 34560, 135, 270, 270, 135, 270, 135, 135, 270, 270, 34560, 270, 135, 270, 34560, 270, 270, 34560, 270, 34560, 135, 34560, 34560, 270, 135, 135, 34560, 270, 135, 270, 270, 34560, 270, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 34560, 34560, 135, 34560, 135, 270, 34560, 34560, 34560, 270, 135, 34560, 270, 135, 135, 135, 135, 135, 34560, 270, 135, 34560, 135, 34560, 135, 135, 270, 270, 34560, 270, 34560, 135, 270, 135, 34560, 34560, 135, 34560, 270, 135, 34560, 135, 135, 34560, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 135, 270, 34560, 34560, 135, 34560, 270, 135, 270, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 270, 34560, 34560, 270, 135, 34560, 135, 270, 270, 135, 270, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 270, 34560, 270, 34560, 135, 34560, 135, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 270, 270, 135, 270, 34560, 270, 270, 34560, 135, 34560, 34560, 270, 135, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 135, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 34560, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 34560, 270, 135, 135, 135, 135]
Prompts retrieved: 3006585 . Total input tokens: 670334443 . Total output tokens: 601394933
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 95.6298076719977,
    "estimated_duration": 3600.114562586378,
    "input_throughput": 7462.85806546618,
    "output_throughput": 6610.056870774661,
    "total_throughput": 14072.91493624084,
    "itl": 126.15486392215927,
    "ttft": 1966325.005449487,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 394,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.322304767146708,
    "arrivals": 1001073,
    "finished_requests": 108561,
    "scheduler_time": 222.5185199265885
}
#Debug simulation 
Total elapsed time: 95.62995181791484. Arrivals time: 0.5400519608519971 Scheduler time: 94.91225251602009 Scheduler overhead time: 0.06986475875601172 Adapter cache time: 0.015879854559898376 Engine time: 0.06713298335671425 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-8/adapters_256_slots_32_rate_3.2-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-8/adapters_256_slots_32_rate_3.2-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 66, 34560, 34560, 66, 34560, 270, 34560, 66, 270, 66, 34560, 270, 270, 270, 270, 34560, 66, 66, 66, 270, 34560, 66, 34560, 34560, 270, 270, 270, 66, 34560, 66, 270, 270, 66, 270, 66, 66, 270, 270, 34560, 270, 66, 270, 34560, 270, 270, 34560, 270, 34560, 66, 34560, 34560, 270, 66, 66, 34560, 270, 66, 270, 270, 34560, 270, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 34560, 34560, 66, 34560, 66, 270, 34560, 34560, 34560, 270, 66, 34560, 270, 66, 66, 66, 66, 66, 34560, 270, 66, 34560, 66, 34560, 66, 66, 270, 270, 34560, 270, 34560, 66, 270, 66, 34560, 34560, 66, 34560, 270, 66, 34560, 66, 66, 34560, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 66, 270, 34560, 34560, 66, 34560, 270, 66, 270, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 270, 34560, 34560, 270, 66, 34560, 66, 270, 270, 66, 270, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 270, 34560, 270, 34560, 66, 34560, 66, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 270, 270, 66, 270, 34560, 270, 270, 34560, 66, 34560, 34560, 270, 66, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 66, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 34560, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 34560, 270, 66, 66, 66, 66]
Prompts retrieved: 3000720 . Total input tokens: 669021209 . Total output tokens: 600212181
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 93.11652200203389,
    "estimated_duration": 3600.0297560953663,
    "input_throughput": 7451.454520502409,
    "output_throughput": 6618.693625978129,
    "total_throughput": 14070.148146480538,
    "itl": 126.34819461172638,
    "ttft": 1967451.5588731635,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 402,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2303160730609737,
    "arrivals": 999127,
    "finished_requests": 108715,
    "scheduler_time": 222.06447939198333
}
#Debug simulation 
Total elapsed time: 93.11666567157954. Arrivals time: 0.535300524905324 Scheduler time: 92.40476130787283 Scheduler overhead time: 0.06937662838026881 Adapter cache time: 0.015609915368258953 Engine time: 0.06646117800846696 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-16/adapters_256_slots_32_rate_3.2-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-16/adapters_256_slots_32_rate_3.2-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 66, 34560, 34560, 66, 34560, 270, 34560, 66, 270, 66, 34560, 270, 270, 270, 270, 34560, 66, 66, 66, 270, 34560, 66, 34560, 34560, 270, 270, 270, 66, 34560, 66, 270, 270, 66, 270, 66, 66, 270, 270, 34560, 270, 66, 270, 34560, 270, 270, 34560, 270, 34560, 66, 34560, 34560, 270, 66, 66, 34560, 270, 66, 270, 270, 34560, 270, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 34560, 34560, 66, 34560, 66, 270, 34560, 34560, 34560, 270, 66, 34560, 270, 66, 66, 66, 66, 66, 34560, 270, 66, 34560, 66, 34560, 66, 66, 270, 270, 34560, 270, 34560, 66, 270, 66, 34560, 34560, 66, 34560, 270, 66, 34560, 66, 66, 34560, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 66, 270, 34560, 34560, 66, 34560, 270, 66, 270, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 270, 34560, 34560, 270, 66, 34560, 66, 270, 270, 66, 270, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 270, 34560, 270, 34560, 66, 34560, 66, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 270, 270, 66, 270, 34560, 270, 270, 34560, 66, 34560, 34560, 270, 66, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 66, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 34560, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 34560, 270, 66, 66, 66, 66]
Prompts retrieved: 3000720 . Total input tokens: 669021209 . Total output tokens: 600212181
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 94.66214025579393,
    "estimated_duration": 3600.096161863033,
    "input_throughput": 7470.372120860919,
    "output_throughput": 6638.281569576925,
    "total_throughput": 14108.653690437844,
    "itl": 126.91279192860061,
    "ttft": 1968936.740976763,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 383,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2518326410604708,
    "arrivals": 999127,
    "finished_requests": 109037,
    "scheduler_time": 220.94710605507927
}
#Debug simulation 
Total elapsed time: 94.66229785606265. Arrivals time: 0.5456491578370333 Scheduler time: 93.94228241126984 Scheduler overhead time: 0.06841742573305964 Adapter cache time: 0.014927256852388382 Engine time: 0.06662999698892236 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-32/adapters_256_slots_32_rate_3.2-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-32/adapters_256_slots_32_rate_3.2-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 66, 34560, 34560, 66, 34560, 270, 34560, 66, 270, 66, 34560, 270, 270, 270, 270, 34560, 66, 66, 66, 270, 34560, 66, 34560, 34560, 270, 270, 270, 66, 34560, 66, 270, 270, 66, 270, 66, 66, 270, 270, 34560, 270, 66, 270, 34560, 270, 270, 34560, 270, 34560, 66, 34560, 34560, 270, 66, 66, 34560, 270, 66, 270, 270, 34560, 270, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 34560, 34560, 66, 34560, 66, 270, 34560, 34560, 34560, 270, 66, 34560, 270, 66, 66, 66, 66, 66, 34560, 270, 66, 34560, 66, 34560, 66, 66, 270, 270, 34560, 270, 34560, 66, 270, 66, 34560, 34560, 66, 34560, 270, 66, 34560, 66, 66, 34560, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 66, 270, 34560, 34560, 66, 34560, 270, 66, 270, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 270, 34560, 34560, 270, 66, 34560, 66, 270, 270, 66, 270, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 270, 34560, 270, 34560, 66, 34560, 66, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 270, 270, 66, 270, 34560, 270, 270, 34560, 66, 34560, 34560, 270, 66, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 66, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 34560, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 34560, 270, 66, 66, 66, 66]
Prompts retrieved: 3000720 . Total input tokens: 669021209 . Total output tokens: 600212181
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 94.71425989456475,
    "estimated_duration": 3600.0980278352886,
    "input_throughput": 7470.368248881043,
    "output_throughput": 6638.278128879162,
    "total_throughput": 14108.646377760204,
    "itl": 126.91285331816351,
    "ttft": 1968937.6110919141,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 383,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2536893151514303,
    "arrivals": 999127,
    "finished_requests": 109037,
    "scheduler_time": 220.94711535323282
}
#Debug simulation 
Total elapsed time: 94.71440363395959. Arrivals time: 0.5440945127047598 Scheduler time: 93.99389975657687 Scheduler overhead time: 0.06948012113571167 Adapter cache time: 0.015265157911926508 Engine time: 0.06693234760314226 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-16/adapters_256_slots_32_rate_3.2-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-16/adapters_256_slots_32_rate_3.2-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 66, 34560, 34560, 66, 34560, 270, 34560, 66, 270, 66, 34560, 270, 270, 270, 270, 34560, 66, 66, 66, 270, 34560, 66, 34560, 34560, 270, 270, 270, 66, 34560, 66, 270, 270, 66, 270, 66, 66, 270, 270, 34560, 270, 66, 270, 34560, 270, 270, 34560, 270, 34560, 66, 34560, 34560, 270, 66, 66, 34560, 270, 66, 270, 270, 34560, 270, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 34560, 34560, 66, 34560, 66, 270, 34560, 34560, 34560, 270, 66, 34560, 270, 66, 66, 66, 66, 66, 34560, 270, 66, 34560, 66, 34560, 66, 66, 270, 270, 34560, 270, 34560, 66, 270, 66, 34560, 34560, 66, 34560, 270, 66, 34560, 66, 66, 34560, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 66, 270, 34560, 34560, 66, 34560, 270, 66, 270, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 270, 34560, 34560, 270, 66, 34560, 66, 270, 270, 66, 270, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 270, 34560, 270, 34560, 66, 34560, 66, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 270, 270, 66, 270, 34560, 270, 270, 34560, 66, 34560, 34560, 270, 66, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 66, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 34560, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 34560, 270, 66, 66, 66, 66]
Prompts retrieved: 3000720 . Total input tokens: 669021209 . Total output tokens: 600212181
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 94.07613911293447,
    "estimated_duration": 3600.0583104610605,
    "input_throughput": 7451.395418249338,
    "output_throughput": 6618.641128884495,
    "total_throughput": 14070.036547133834,
    "itl": 126.34883283529075,
    "ttft": 1967461.8236665218,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 402,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.260020753769204,
    "arrivals": 999127,
    "finished_requests": 108715,
    "scheduler_time": 222.0645732322629
}
#Debug simulation 
Total elapsed time: 94.07628141669556. Arrivals time: 0.5403464105911553 Scheduler time: 93.35988473938778 Scheduler overhead time: 0.06856605503708124 Adapter cache time: 0.015496537555009127 Engine time: 0.06721264449879527 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-32/adapters_256_slots_32_rate_3.2-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-32/adapters_256_slots_32_rate_3.2-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 66, 34560, 34560, 66, 34560, 270, 34560, 66, 270, 66, 34560, 270, 270, 270, 270, 34560, 66, 66, 66, 270, 34560, 66, 34560, 34560, 270, 270, 270, 66, 34560, 66, 270, 270, 66, 270, 66, 66, 270, 270, 34560, 270, 66, 270, 34560, 270, 270, 34560, 270, 34560, 66, 34560, 34560, 270, 66, 66, 34560, 270, 66, 270, 270, 34560, 270, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 34560, 34560, 66, 34560, 66, 270, 34560, 34560, 34560, 270, 66, 34560, 270, 66, 66, 66, 66, 66, 34560, 270, 66, 34560, 66, 34560, 66, 66, 270, 270, 34560, 270, 34560, 66, 270, 66, 34560, 34560, 66, 34560, 270, 66, 34560, 66, 66, 34560, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 66, 270, 34560, 34560, 66, 34560, 270, 66, 270, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 270, 34560, 34560, 270, 66, 34560, 66, 270, 270, 66, 270, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 270, 34560, 270, 34560, 66, 34560, 66, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 270, 270, 66, 270, 34560, 270, 270, 34560, 66, 34560, 34560, 270, 66, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 66, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 34560, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 34560, 270, 66, 66, 66, 66]
Prompts retrieved: 3000720 . Total input tokens: 669021209 . Total output tokens: 600212181
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 92.48607608303428,
    "estimated_duration": 3600.102060730345,
    "input_throughput": 7433.492592310282,
    "output_throughput": 6606.183824459467,
    "total_throughput": 14039.67641676975,
    "itl": 126.27773947441739,
    "ttft": 1966957.0893985706,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 388,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.285552135258918,
    "arrivals": 999127,
    "finished_requests": 108527,
    "scheduler_time": 222.69737645490795
}
#Debug simulation 
Total elapsed time: 92.48621905874461. Arrivals time: 0.5348886521533132 Scheduler time: 91.77592757483944 Scheduler overhead time: 0.06920739309862256 Adapter cache time: 0.01466885069385171 Engine time: 0.0668387757614255 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-16/adapters_256_slots_32_rate_3.2-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-16/adapters_256_slots_32_rate_3.2-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 66, 34560, 34560, 66, 34560, 270, 34560, 66, 270, 66, 34560, 270, 270, 270, 270, 34560, 66, 66, 66, 270, 34560, 66, 34560, 34560, 270, 270, 270, 66, 34560, 66, 270, 270, 66, 270, 66, 66, 270, 270, 34560, 270, 66, 270, 34560, 270, 270, 34560, 270, 34560, 66, 34560, 34560, 270, 66, 66, 34560, 270, 66, 270, 270, 34560, 270, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 34560, 34560, 66, 34560, 66, 270, 34560, 34560, 34560, 270, 66, 34560, 270, 66, 66, 66, 66, 66, 34560, 270, 66, 34560, 66, 34560, 66, 66, 270, 270, 34560, 270, 34560, 66, 270, 66, 34560, 34560, 66, 34560, 270, 66, 34560, 66, 66, 34560, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 66, 270, 34560, 34560, 66, 34560, 270, 66, 270, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 270, 34560, 34560, 270, 66, 34560, 66, 270, 270, 66, 270, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 270, 34560, 270, 34560, 66, 34560, 66, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 270, 270, 66, 270, 34560, 270, 270, 34560, 66, 34560, 34560, 270, 66, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 66, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 34560, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 34560, 270, 66, 66, 66, 66]
Prompts retrieved: 3000720 . Total input tokens: 669021209 . Total output tokens: 600212181
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 94.6927612950094,
    "estimated_duration": 3600.1238888666635,
    "input_throughput": 7471.558154757777,
    "output_throughput": 6639.289296103793,
    "total_throughput": 14110.847450861569,
    "itl": 126.4769764551251,
    "ttft": 1968937.4804026235,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 395,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1810698664863544,
    "arrivals": 999127,
    "finished_requests": 109053,
    "scheduler_time": 220.98284794300346
}
#Debug simulation 
Total elapsed time: 94.69290614081547. Arrivals time: 0.5349524253979325 Scheduler time: 93.98252824693918 Scheduler overhead time: 0.06854602601379156 Adapter cache time: 0.015557666309177876 Engine time: 0.0666643506847322 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-32/adapters_256_slots_32_rate_3.2-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-32/adapters_256_slots_32_rate_3.2-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 66, 34560, 34560, 66, 34560, 270, 34560, 66, 270, 66, 34560, 270, 270, 270, 270, 34560, 66, 66, 66, 270, 34560, 66, 34560, 34560, 270, 270, 270, 66, 34560, 66, 270, 270, 66, 270, 66, 66, 270, 270, 34560, 270, 66, 270, 34560, 270, 270, 34560, 270, 34560, 66, 34560, 34560, 270, 66, 66, 34560, 270, 66, 270, 270, 34560, 270, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 34560, 34560, 66, 34560, 66, 270, 34560, 34560, 34560, 270, 66, 34560, 270, 66, 66, 66, 66, 66, 34560, 270, 66, 34560, 66, 34560, 66, 66, 270, 270, 34560, 270, 34560, 66, 270, 66, 34560, 34560, 66, 34560, 270, 66, 34560, 66, 66, 34560, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 66, 270, 34560, 34560, 66, 34560, 270, 66, 270, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 270, 34560, 34560, 270, 66, 34560, 66, 270, 270, 66, 270, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 270, 34560, 270, 34560, 66, 34560, 66, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 270, 270, 66, 270, 34560, 270, 270, 34560, 66, 34560, 34560, 270, 66, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 66, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 34560, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 34560, 270, 66, 66, 66, 66]
Prompts retrieved: 3000720 . Total input tokens: 669021209 . Total output tokens: 600212181
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 92.70504915202036,
    "estimated_duration": 3600.1197294752606,
    "input_throughput": 7433.456110055714,
    "output_throughput": 6606.1514024886355,
    "total_throughput": 14039.60751254435,
    "itl": 126.27813918501444,
    "ttft": 1966964.3848579186,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 388,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.302654650211336,
    "arrivals": 999127,
    "finished_requests": 108527,
    "scheduler_time": 222.6974902647523
}
#Debug simulation 
Total elapsed time: 92.70519502274692. Arrivals time: 0.541555873118341 Scheduler time: 91.98904800508171 Scheduler overhead time: 0.06829153187572956 Adapter cache time: 0.014932830352336168 Engine time: 0.06694113276898861 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-8/adapters_256_slots_32_rate_3.2-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-8/adapters_256_slots_32_rate_3.2-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 33, 34560, 34560, 33, 34560, 270, 34560, 33, 270, 33, 34560, 270, 270, 270, 270, 34560, 33, 33, 33, 270, 34560, 33, 34560, 34560, 270, 270, 270, 33, 34560, 33, 270, 270, 33, 270, 33, 33, 270, 270, 34560, 270, 33, 270, 34560, 270, 270, 34560, 270, 34560, 33, 34560, 34560, 270, 33, 33, 34560, 270, 33, 270, 270, 34560, 270, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 34560, 34560, 33, 34560, 33, 270, 34560, 34560, 34560, 270, 33, 34560, 270, 33, 33, 33, 33, 33, 34560, 270, 33, 34560, 33, 34560, 33, 33, 270, 270, 34560, 270, 34560, 33, 270, 33, 34560, 34560, 33, 34560, 270, 33, 34560, 33, 33, 34560, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 33, 270, 34560, 34560, 33, 34560, 270, 33, 270, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 270, 34560, 34560, 270, 33, 34560, 33, 270, 270, 33, 270, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 270, 34560, 270, 34560, 33, 34560, 33, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 270, 270, 33, 270, 34560, 270, 270, 34560, 33, 34560, 34560, 270, 33, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 33, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 34560, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 34560, 270, 33, 33, 33, 33]
Prompts retrieved: 2997915 . Total input tokens: 668391315 . Total output tokens: 599640789
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 96.16216265317053,
    "estimated_duration": 3600.124620332659,
    "input_throughput": 7500.863122206245,
    "output_throughput": 6633.886189693394,
    "total_throughput": 14134.749311899639,
    "itl": 125.88914566572102,
    "ttft": 1966971.5340182108,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 346,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0589287594007335,
    "arrivals": 998127,
    "finished_requests": 109511,
    "scheduler_time": 221.2707572073979
}
#Debug simulation 
Total elapsed time: 96.16230267612264. Arrivals time: 0.5474124983884394 Scheduler time: 95.4385487549007 Scheduler overhead time: 0.06938875187188387 Adapter cache time: 0.01465512439608574 Engine time: 0.06766806961968541 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-16/adapters_256_slots_32_rate_3.2-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-16/adapters_256_slots_32_rate_3.2-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 33, 34560, 34560, 33, 34560, 270, 34560, 33, 270, 33, 34560, 270, 270, 270, 270, 34560, 33, 33, 33, 270, 34560, 33, 34560, 34560, 270, 270, 270, 33, 34560, 33, 270, 270, 33, 270, 33, 33, 270, 270, 34560, 270, 33, 270, 34560, 270, 270, 34560, 270, 34560, 33, 34560, 34560, 270, 33, 33, 34560, 270, 33, 270, 270, 34560, 270, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 34560, 34560, 33, 34560, 33, 270, 34560, 34560, 34560, 270, 33, 34560, 270, 33, 33, 33, 33, 33, 34560, 270, 33, 34560, 33, 34560, 33, 33, 270, 270, 34560, 270, 34560, 33, 270, 33, 34560, 34560, 33, 34560, 270, 33, 34560, 33, 33, 34560, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 33, 270, 34560, 34560, 33, 34560, 270, 33, 270, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 270, 34560, 34560, 270, 33, 34560, 33, 270, 270, 33, 270, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 270, 34560, 270, 34560, 33, 34560, 33, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 270, 270, 33, 270, 34560, 270, 270, 34560, 33, 34560, 34560, 270, 33, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 33, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 34560, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 34560, 270, 33, 33, 33, 33]
Prompts retrieved: 2997915 . Total input tokens: 668391315 . Total output tokens: 599640789
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 98.65339264599606,
    "estimated_duration": 3600.0300883571804,
    "input_throughput": 7501.671746394734,
    "output_throughput": 6629.24459358912,
    "total_throughput": 14130.916339983854,
    "itl": 125.83109963777217,
    "ttft": 1967078.1142958838,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 339,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1051524013024807,
    "arrivals": 998127,
    "finished_requests": 109461,
    "scheduler_time": 221.59881304676045
}
#Debug simulation 
Total elapsed time: 98.65354112023488. Arrivals time: 0.6162770576775074 Scheduler time: 97.85952386911958 Scheduler overhead time: 0.07042717095464468 Adapter cache time: 0.014991609379649162 Engine time: 0.06771139055490494 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-32/adapters_256_slots_32_rate_3.2-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-32/adapters_256_slots_32_rate_3.2-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 33, 34560, 34560, 33, 34560, 270, 34560, 33, 270, 33, 34560, 270, 270, 270, 270, 34560, 33, 33, 33, 270, 34560, 33, 34560, 34560, 270, 270, 270, 33, 34560, 33, 270, 270, 33, 270, 33, 33, 270, 270, 34560, 270, 33, 270, 34560, 270, 270, 34560, 270, 34560, 33, 34560, 34560, 270, 33, 33, 34560, 270, 33, 270, 270, 34560, 270, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 34560, 34560, 33, 34560, 33, 270, 34560, 34560, 34560, 270, 33, 34560, 270, 33, 33, 33, 33, 33, 34560, 270, 33, 34560, 33, 34560, 33, 33, 270, 270, 34560, 270, 34560, 33, 270, 33, 34560, 34560, 33, 34560, 270, 33, 34560, 33, 33, 34560, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 33, 270, 34560, 34560, 33, 34560, 270, 33, 270, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 270, 34560, 34560, 270, 33, 34560, 33, 270, 270, 33, 270, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 270, 34560, 270, 34560, 33, 34560, 33, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 270, 270, 33, 270, 34560, 270, 270, 34560, 33, 34560, 34560, 270, 33, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 33, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 34560, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 34560, 270, 33, 33, 33, 33]
Prompts retrieved: 2997915 . Total input tokens: 668391315 . Total output tokens: 599640789
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 98.67065873881802,
    "estimated_duration": 3600.032247587607,
    "input_throughput": 7501.667247035626,
    "output_throughput": 6629.240617495117,
    "total_throughput": 14130.907864530742,
    "itl": 125.83116591516402,
    "ttft": 1967079.0651822204,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 339,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1072963285073698,
    "arrivals": 998127,
    "finished_requests": 109461,
    "scheduler_time": 221.59882834997148
}
#Debug simulation 
Total elapsed time: 98.6708023888059. Arrivals time: 0.5527741392143071 Scheduler time: 97.9402812384069 Scheduler overhead time: 0.06993594020605087 Adapter cache time: 0.015000761486589909 Engine time: 0.06802793452516198 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-16/adapters_256_slots_32_rate_3.2-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-16/adapters_256_slots_32_rate_3.2-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 33, 34560, 34560, 33, 34560, 270, 34560, 33, 270, 33, 34560, 270, 270, 270, 270, 34560, 33, 33, 33, 270, 34560, 33, 34560, 34560, 270, 270, 270, 33, 34560, 33, 270, 270, 33, 270, 33, 33, 270, 270, 34560, 270, 33, 270, 34560, 270, 270, 34560, 270, 34560, 33, 34560, 34560, 270, 33, 33, 34560, 270, 33, 270, 270, 34560, 270, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 34560, 34560, 33, 34560, 33, 270, 34560, 34560, 34560, 270, 33, 34560, 270, 33, 33, 33, 33, 33, 34560, 270, 33, 34560, 33, 34560, 33, 33, 270, 270, 34560, 270, 34560, 33, 270, 33, 34560, 34560, 33, 34560, 270, 33, 34560, 33, 33, 34560, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 33, 270, 34560, 34560, 33, 34560, 270, 33, 270, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 270, 34560, 34560, 270, 33, 34560, 33, 270, 270, 33, 270, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 270, 34560, 270, 34560, 33, 34560, 33, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 270, 270, 33, 270, 34560, 270, 270, 34560, 33, 34560, 34560, 270, 33, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 33, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 34560, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 34560, 270, 33, 33, 33, 33]
Prompts retrieved: 2997915 . Total input tokens: 668391315 . Total output tokens: 599640789
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 96.38733162498102,
    "estimated_duration": 3600.0083499920866,
    "input_throughput": 7500.968157493123,
    "output_throughput": 6633.721835687546,
    "total_throughput": 14134.68999318067,
    "itl": 125.88988517588204,
    "ttft": 1966951.5134828025,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 346,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0844060308858776,
    "arrivals": 998127,
    "finished_requests": 109506,
    "scheduler_time": 221.26223750513753
}
#Debug simulation 
Total elapsed time: 96.38747459696606. Arrivals time: 0.5428019338287413 Scheduler time: 95.66901949420571 Scheduler overhead time: 0.06949613988399506 Adapter cache time: 0.014468901325017214 Engine time: 0.06728117726743221 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-32/adapters_256_slots_32_rate_3.2-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-32/adapters_256_slots_32_rate_3.2-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 33, 34560, 34560, 33, 34560, 270, 34560, 33, 270, 33, 34560, 270, 270, 270, 270, 34560, 33, 33, 33, 270, 34560, 33, 34560, 34560, 270, 270, 270, 33, 34560, 33, 270, 270, 33, 270, 33, 33, 270, 270, 34560, 270, 33, 270, 34560, 270, 270, 34560, 270, 34560, 33, 34560, 34560, 270, 33, 33, 34560, 270, 33, 270, 270, 34560, 270, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 34560, 34560, 33, 34560, 33, 270, 34560, 34560, 34560, 270, 33, 34560, 270, 33, 33, 33, 33, 33, 34560, 270, 33, 34560, 33, 34560, 33, 33, 270, 270, 34560, 270, 34560, 33, 270, 33, 34560, 34560, 33, 34560, 270, 33, 34560, 33, 33, 34560, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 33, 270, 34560, 34560, 33, 34560, 270, 33, 270, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 270, 34560, 34560, 270, 33, 34560, 33, 270, 270, 33, 270, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 270, 34560, 270, 34560, 33, 34560, 33, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 270, 270, 33, 270, 34560, 270, 270, 34560, 33, 34560, 34560, 270, 33, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 33, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 34560, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 34560, 270, 33, 33, 33, 33]
Prompts retrieved: 2997915 . Total input tokens: 668391315 . Total output tokens: 599640789
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 99.03189888596535,
    "estimated_duration": 3600.0454537179257,
    "input_throughput": 7501.6397284955,
    "output_throughput": 6629.216299297851,
    "total_throughput": 14130.85602779335,
    "itl": 125.83147819489001,
    "ttft": 1967084.8101384449,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 339,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1205004760809294,
    "arrivals": 998127,
    "finished_requests": 109461,
    "scheduler_time": 221.59894343775565
}
#Debug simulation 
Total elapsed time: 99.03204231103882. Arrivals time: 0.5583775704726577 Scheduler time: 98.2953750519082 Scheduler overhead time: 0.07020196365192533 Adapter cache time: 0.014804196543991566 Engine time: 0.06789396610110998 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-16/adapters_256_slots_32_rate_3.2-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-16/adapters_256_slots_32_rate_3.2-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 33, 34560, 34560, 33, 34560, 270, 34560, 33, 270, 33, 34560, 270, 270, 270, 270, 34560, 33, 33, 33, 270, 34560, 33, 34560, 34560, 270, 270, 270, 33, 34560, 33, 270, 270, 33, 270, 33, 33, 270, 270, 34560, 270, 33, 270, 34560, 270, 270, 34560, 270, 34560, 33, 34560, 34560, 270, 33, 33, 34560, 270, 33, 270, 270, 34560, 270, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 34560, 34560, 33, 34560, 33, 270, 34560, 34560, 34560, 270, 33, 34560, 270, 33, 33, 33, 33, 33, 34560, 270, 33, 34560, 33, 34560, 33, 33, 270, 270, 34560, 270, 34560, 33, 270, 33, 34560, 34560, 33, 34560, 270, 33, 34560, 33, 33, 34560, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 33, 270, 34560, 34560, 33, 34560, 270, 33, 270, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 270, 34560, 34560, 270, 33, 34560, 33, 270, 270, 33, 270, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 270, 34560, 270, 34560, 33, 34560, 33, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 270, 270, 33, 270, 34560, 270, 270, 34560, 33, 34560, 34560, 270, 33, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 33, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 34560, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 34560, 270, 33, 33, 33, 33]
Prompts retrieved: 2997915 . Total input tokens: 668391315 . Total output tokens: 599640789
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 96.7444784748368,
    "estimated_duration": 3600.101340618956,
    "input_throughput": 7500.911625825863,
    "output_throughput": 6633.929087088946,
    "total_throughput": 14134.840712914809,
    "itl": 125.88856354319802,
    "ttft": 1966962.1328204537,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 346,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.034557402036153,
    "arrivals": 998127,
    "finished_requests": 109511,
    "scheduler_time": 221.27060469565828
}
#Debug simulation 
Total elapsed time: 96.7446286319755. Arrivals time: 0.550554109737277 Scheduler time: 96.01823790045455 Scheduler overhead time: 0.06899677775800228 Adapter cache time: 0.014863461256027222 Engine time: 0.0666247378103435 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-32/adapters_256_slots_32_rate_3.2-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-32/adapters_256_slots_32_rate_3.2-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 33, 34560, 34560, 33, 34560, 270, 34560, 33, 270, 33, 34560, 270, 270, 270, 270, 34560, 33, 33, 33, 270, 34560, 33, 34560, 34560, 270, 270, 270, 33, 34560, 33, 270, 270, 33, 270, 33, 33, 270, 270, 34560, 270, 33, 270, 34560, 270, 270, 34560, 270, 34560, 33, 34560, 34560, 270, 33, 33, 34560, 270, 33, 270, 270, 34560, 270, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 34560, 34560, 33, 34560, 33, 270, 34560, 34560, 34560, 270, 33, 34560, 270, 33, 33, 33, 33, 33, 34560, 270, 33, 34560, 33, 34560, 33, 33, 270, 270, 34560, 270, 34560, 33, 270, 33, 34560, 34560, 33, 34560, 270, 33, 34560, 33, 33, 34560, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 33, 270, 34560, 34560, 33, 34560, 270, 33, 270, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 270, 34560, 34560, 270, 33, 34560, 33, 270, 270, 33, 270, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 270, 34560, 270, 34560, 33, 34560, 33, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 270, 270, 33, 270, 34560, 270, 270, 34560, 33, 34560, 34560, 270, 33, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 33, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 34560, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 34560, 270, 33, 33, 33, 33]
Prompts retrieved: 2997915 . Total input tokens: 668391315 . Total output tokens: 599640789
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 98.17441784916446,
    "estimated_duration": 3600.061780996575,
    "input_throughput": 7501.605706478761,
    "output_throughput": 6629.186233963329,
    "total_throughput": 14130.79194044209,
    "itl": 125.83186384391831,
    "ttft": 1967091.3040208432,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 339,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.135465176664297,
    "arrivals": 998127,
    "finished_requests": 109461,
    "scheduler_time": 221.5998535957084
}
#Debug simulation 
Total elapsed time: 98.17456034384668. Arrivals time: 0.5484079332090914 Scheduler time: 97.45123746711761 Scheduler overhead time: 0.06831009546294808 Adapter cache time: 0.014757390134036541 Engine time: 0.0672235544770956 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-8/adapters_256_slots_32_rate_3.2-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-8/adapters_256_slots_32_rate_3.2-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 66, 34560, 34560, 66, 34560, 135, 34560, 66, 135, 66, 34560, 135, 135, 135, 135, 34560, 66, 66, 66, 135, 34560, 66, 34560, 34560, 135, 135, 135, 66, 34560, 66, 135, 135, 66, 135, 66, 66, 135, 135, 34560, 135, 66, 135, 34560, 135, 135, 34560, 135, 34560, 66, 34560, 34560, 135, 66, 66, 34560, 135, 66, 135, 135, 34560, 135, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 34560, 34560, 66, 34560, 66, 135, 34560, 34560, 34560, 135, 66, 34560, 135, 66, 66, 66, 66, 66, 34560, 135, 66, 34560, 66, 34560, 66, 66, 135, 135, 34560, 135, 34560, 66, 135, 66, 34560, 34560, 66, 34560, 135, 66, 34560, 66, 66, 34560, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 66, 135, 34560, 34560, 66, 34560, 135, 66, 135, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 135, 34560, 34560, 135, 66, 34560, 66, 135, 135, 66, 135, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 135, 34560, 135, 34560, 66, 34560, 66, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 135, 135, 66, 135, 34560, 135, 135, 34560, 66, 34560, 34560, 135, 66, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 66, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 34560, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 34560, 135, 66, 66, 66, 66]
Prompts retrieved: 2989245 . Total input tokens: 666447743 . Total output tokens: 597918174
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 97.30682071298361,
    "estimated_duration": 3600.052096610308,
    "input_throughput": 7529.631036596145,
    "output_throughput": 6640.234740632878,
    "total_throughput": 14169.865777229024,
    "itl": 126.48401990824826,
    "ttft": 1966871.7409476838,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 445,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3619170460500867,
    "arrivals": 995247,
    "finished_requests": 109503,
    "scheduler_time": 220.70042179126264
}
#Debug simulation 
Total elapsed time: 97.30695859296247. Arrivals time: 0.5537227354943752 Scheduler time: 96.57666666107252 Scheduler overhead time: 0.06938452506437898 Adapter cache time: 0.015320432372391224 Engine time: 0.06724991649389267 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-16/adapters_256_slots_32_rate_3.2-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-16/adapters_256_slots_32_rate_3.2-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 66, 34560, 34560, 66, 34560, 135, 34560, 66, 135, 66, 34560, 135, 135, 135, 135, 34560, 66, 66, 66, 135, 34560, 66, 34560, 34560, 135, 135, 135, 66, 34560, 66, 135, 135, 66, 135, 66, 66, 135, 135, 34560, 135, 66, 135, 34560, 135, 135, 34560, 135, 34560, 66, 34560, 34560, 135, 66, 66, 34560, 135, 66, 135, 135, 34560, 135, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 34560, 34560, 66, 34560, 66, 135, 34560, 34560, 34560, 135, 66, 34560, 135, 66, 66, 66, 66, 66, 34560, 135, 66, 34560, 66, 34560, 66, 66, 135, 135, 34560, 135, 34560, 66, 135, 66, 34560, 34560, 66, 34560, 135, 66, 34560, 66, 66, 34560, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 66, 135, 34560, 34560, 66, 34560, 135, 66, 135, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 135, 34560, 34560, 135, 66, 34560, 66, 135, 135, 66, 135, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 135, 34560, 135, 34560, 66, 34560, 66, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 135, 135, 66, 135, 34560, 135, 135, 34560, 66, 34560, 34560, 135, 66, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 66, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 34560, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 34560, 135, 66, 66, 66, 66]
Prompts retrieved: 2989245 . Total input tokens: 666447743 . Total output tokens: 597918174
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 97.31221081735566,
    "estimated_duration": 3600.1455441654525,
    "input_throughput": 7529.435592938971,
    "output_throughput": 6640.062382683877,
    "total_throughput": 14169.49797562285,
    "itl": 126.4863761447075,
    "ttft": 1966908.167915566,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 445,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4547853580373404,
    "arrivals": 995247,
    "finished_requests": 109503,
    "scheduler_time": 220.7011141394124
}
#Debug simulation 
Total elapsed time: 97.3123486242257. Arrivals time: 0.5510747791267931 Scheduler time: 96.58342600893229 Scheduler overhead time: 0.06974375061690807 Adapter cache time: 0.01565707940608263 Engine time: 0.06773208361119032 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-32/adapters_256_slots_32_rate_3.2-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-32/adapters_256_slots_32_rate_3.2-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 66, 34560, 34560, 66, 34560, 135, 34560, 66, 135, 66, 34560, 135, 135, 135, 135, 34560, 66, 66, 66, 135, 34560, 66, 34560, 34560, 135, 135, 135, 66, 34560, 66, 135, 135, 66, 135, 66, 66, 135, 135, 34560, 135, 66, 135, 34560, 135, 135, 34560, 135, 34560, 66, 34560, 34560, 135, 66, 66, 34560, 135, 66, 135, 135, 34560, 135, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 34560, 34560, 66, 34560, 66, 135, 34560, 34560, 34560, 135, 66, 34560, 135, 66, 66, 66, 66, 66, 34560, 135, 66, 34560, 66, 34560, 66, 66, 135, 135, 34560, 135, 34560, 66, 135, 66, 34560, 34560, 66, 34560, 135, 66, 34560, 66, 66, 34560, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 66, 135, 34560, 34560, 66, 34560, 135, 66, 135, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 135, 34560, 34560, 135, 66, 34560, 66, 135, 135, 66, 135, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 135, 34560, 135, 34560, 66, 34560, 66, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 135, 135, 66, 135, 34560, 135, 135, 34560, 66, 34560, 34560, 135, 66, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 66, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 34560, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 34560, 135, 66, 66, 66, 66]
Prompts retrieved: 2989245 . Total input tokens: 666447743 . Total output tokens: 597918174
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 98.46851160284132,
    "estimated_duration": 3600.147656456776,
    "input_throughput": 7529.431175241979,
    "output_throughput": 6640.05848680307,
    "total_throughput": 14169.489662045049,
    "itl": 126.48645499496611,
    "ttft": 1966908.9677772024,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 445,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.45688912604005,
    "arrivals": 995247,
    "finished_requests": 109503,
    "scheduler_time": 220.70112266271983
}
#Debug simulation 
Total elapsed time: 98.46864357683808. Arrivals time: 0.6183587778359652 Scheduler time: 97.6723839645274 Scheduler overhead time: 0.07000562222674489 Adapter cache time: 0.015246975235641003 Engine time: 0.06797707499936223 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-16/adapters_256_slots_32_rate_3.2-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-16/adapters_256_slots_32_rate_3.2-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 66, 34560, 34560, 66, 34560, 135, 34560, 66, 135, 66, 34560, 135, 135, 135, 135, 34560, 66, 66, 66, 135, 34560, 66, 34560, 34560, 135, 135, 135, 66, 34560, 66, 135, 135, 66, 135, 66, 66, 135, 135, 34560, 135, 66, 135, 34560, 135, 135, 34560, 135, 34560, 66, 34560, 34560, 135, 66, 66, 34560, 135, 66, 135, 135, 34560, 135, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 34560, 34560, 66, 34560, 66, 135, 34560, 34560, 34560, 135, 66, 34560, 135, 66, 66, 66, 66, 66, 34560, 135, 66, 34560, 66, 34560, 66, 66, 135, 135, 34560, 135, 34560, 66, 135, 66, 34560, 34560, 66, 34560, 135, 66, 34560, 66, 66, 34560, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 66, 135, 34560, 34560, 66, 34560, 135, 66, 135, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 135, 34560, 34560, 135, 66, 34560, 66, 135, 135, 66, 135, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 135, 34560, 135, 34560, 66, 34560, 66, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 135, 135, 66, 135, 34560, 135, 135, 34560, 66, 34560, 34560, 135, 66, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 66, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 34560, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 34560, 135, 66, 66, 66, 66]
Prompts retrieved: 2989245 . Total input tokens: 666447743 . Total output tokens: 597918174
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 97.46312982821837,
    "estimated_duration": 3600.0806879401694,
    "input_throughput": 7529.571237335139,
    "output_throughput": 6640.182004831023,
    "total_throughput": 14169.753242166162,
    "itl": 126.48474191512771,
    "ttft": 1966881.2157576296,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 445,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3914530836790777,
    "arrivals": 995247,
    "finished_requests": 109503,
    "scheduler_time": 220.70049502871743
}
#Debug simulation 
Total elapsed time: 97.46326543530449. Arrivals time: 0.8770038858056068 Scheduler time: 96.40835555410013 Scheduler overhead time: 0.0705012921243906 Adapter cache time: 0.015552842989563942 Engine time: 0.06748838583007455 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-32/adapters_256_slots_32_rate_3.2-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-32/adapters_256_slots_32_rate_3.2-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 66, 34560, 34560, 66, 34560, 135, 34560, 66, 135, 66, 34560, 135, 135, 135, 135, 34560, 66, 66, 66, 135, 34560, 66, 34560, 34560, 135, 135, 135, 66, 34560, 66, 135, 135, 66, 135, 66, 66, 135, 135, 34560, 135, 66, 135, 34560, 135, 135, 34560, 135, 34560, 66, 34560, 34560, 135, 66, 66, 34560, 135, 66, 135, 135, 34560, 135, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 34560, 34560, 66, 34560, 66, 135, 34560, 34560, 34560, 135, 66, 34560, 135, 66, 66, 66, 66, 66, 34560, 135, 66, 34560, 66, 34560, 66, 66, 135, 135, 34560, 135, 34560, 66, 135, 66, 34560, 34560, 66, 34560, 135, 66, 34560, 66, 66, 34560, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 66, 135, 34560, 34560, 66, 34560, 135, 66, 135, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 135, 34560, 34560, 135, 66, 34560, 66, 135, 135, 66, 135, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 135, 34560, 135, 34560, 66, 34560, 66, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 135, 135, 66, 135, 34560, 135, 135, 34560, 66, 34560, 34560, 135, 66, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 66, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 34560, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 34560, 135, 66, 66, 66, 66]
Prompts retrieved: 2989245 . Total input tokens: 666447743 . Total output tokens: 597918174
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 96.15177784487605,
    "estimated_duration": 3600.13853354887,
    "input_throughput": 7529.65302512352,
    "output_throughput": 6653.4997964057775,
    "total_throughput": 14183.152821529296,
    "itl": 126.66314795204403,
    "ttft": 1966435.7689955612,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 452,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4997490937076552,
    "arrivals": 995247,
    "finished_requests": 109404,
    "scheduler_time": 220.31191385890355
}
#Debug simulation 
Total elapsed time: 96.15191381983459. Arrivals time: 0.630682475399226 Scheduler time: 95.34089234936982 Scheduler overhead time: 0.07050711894407868 Adapter cache time: 0.015443193726241589 Engine time: 0.0697511644102633 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-16/adapters_256_slots_32_rate_3.2-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-16/adapters_256_slots_32_rate_3.2-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 66, 34560, 34560, 66, 34560, 135, 34560, 66, 135, 66, 34560, 135, 135, 135, 135, 34560, 66, 66, 66, 135, 34560, 66, 34560, 34560, 135, 135, 135, 66, 34560, 66, 135, 135, 66, 135, 66, 66, 135, 135, 34560, 135, 66, 135, 34560, 135, 135, 34560, 135, 34560, 66, 34560, 34560, 135, 66, 66, 34560, 135, 66, 135, 135, 34560, 135, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 34560, 34560, 66, 34560, 66, 135, 34560, 34560, 34560, 135, 66, 34560, 135, 66, 66, 66, 66, 66, 34560, 135, 66, 34560, 66, 34560, 66, 66, 135, 135, 34560, 135, 34560, 66, 135, 66, 34560, 34560, 66, 34560, 135, 66, 34560, 66, 66, 34560, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 66, 135, 34560, 34560, 66, 34560, 135, 66, 135, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 135, 34560, 34560, 135, 66, 34560, 66, 135, 135, 66, 135, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 135, 34560, 135, 34560, 66, 34560, 66, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 135, 135, 66, 135, 34560, 135, 135, 34560, 66, 34560, 34560, 135, 66, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 66, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 34560, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 34560, 135, 66, 66, 66, 66]
Prompts retrieved: 2989245 . Total input tokens: 666447743 . Total output tokens: 597918174
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 96.22482119780034,
    "estimated_duration": 3600.015654837933,
    "input_throughput": 7529.910033466326,
    "output_throughput": 6653.72689916215,
    "total_throughput": 14183.636932628477,
    "itl": 126.65813026473849,
    "ttft": 1966396.741309325,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 452,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3515027332957723,
    "arrivals": 995247,
    "finished_requests": 109404,
    "scheduler_time": 220.31444410896745
}
#Debug simulation 
Total elapsed time: 96.2249626009725. Arrivals time: 0.6233511953614652 Scheduler time: 95.42431453242898 Scheduler overhead time: 0.06935493182390928 Adapter cache time: 0.015413557179272175 Engine time: 0.0677058594301343 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-32/adapters_256_slots_32_rate_3.2-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-32/adapters_256_slots_32_rate_3.2-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 66, 34560, 34560, 66, 34560, 135, 34560, 66, 135, 66, 34560, 135, 135, 135, 135, 34560, 66, 66, 66, 135, 34560, 66, 34560, 34560, 135, 135, 135, 66, 34560, 66, 135, 135, 66, 135, 66, 66, 135, 135, 34560, 135, 66, 135, 34560, 135, 135, 34560, 135, 34560, 66, 34560, 34560, 135, 66, 66, 34560, 135, 66, 135, 135, 34560, 135, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 34560, 34560, 66, 34560, 66, 135, 34560, 34560, 34560, 135, 66, 34560, 135, 66, 66, 66, 66, 66, 34560, 135, 66, 34560, 66, 34560, 66, 66, 135, 135, 34560, 135, 34560, 66, 135, 66, 34560, 34560, 66, 34560, 135, 66, 34560, 66, 66, 34560, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 66, 135, 34560, 34560, 66, 34560, 135, 66, 135, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 135, 34560, 34560, 135, 66, 34560, 66, 135, 135, 66, 135, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 135, 34560, 135, 34560, 66, 34560, 66, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 135, 135, 66, 135, 34560, 135, 135, 34560, 66, 34560, 34560, 135, 66, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 66, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 34560, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 34560, 135, 66, 66, 66, 66]
Prompts retrieved: 2989245 . Total input tokens: 666447743 . Total output tokens: 597918174
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 95.8396955630742,
    "estimated_duration": 3600.0180883111375,
    "input_throughput": 7529.451890258754,
    "output_throughput": 6653.381569878902,
    "total_throughput": 14182.833460137655,
    "itl": 126.66427218843666,
    "ttft": 1966386.4383273532,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 452,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5187379154562948,
    "arrivals": 995247,
    "finished_requests": 109398,
    "scheduler_time": 220.30344560865115
}
#Debug simulation 
Total elapsed time: 95.83982943929732. Arrivals time: 0.5535692446865141 Scheduler time: 95.10789521876723 Scheduler overhead time: 0.07025424251332879 Adapter cache time: 0.015818309970200062 Engine time: 0.06743153231218457 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-8/adapters_256_slots_32_rate_3.2-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-8/adapters_256_slots_32_rate_3.2-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 33, 34560, 34560, 33, 34560, 135, 34560, 33, 135, 33, 34560, 135, 135, 135, 135, 34560, 33, 33, 33, 135, 34560, 33, 34560, 34560, 135, 135, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 33, 135, 135, 34560, 135, 33, 135, 34560, 135, 135, 34560, 135, 34560, 33, 34560, 34560, 135, 33, 33, 34560, 135, 33, 135, 135, 34560, 135, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 34560, 34560, 33, 34560, 33, 135, 34560, 34560, 34560, 135, 33, 34560, 135, 33, 33, 33, 33, 33, 34560, 135, 33, 34560, 33, 34560, 33, 33, 135, 135, 34560, 135, 34560, 33, 135, 33, 34560, 34560, 33, 34560, 135, 33, 34560, 33, 33, 34560, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 33, 135, 34560, 34560, 33, 34560, 135, 33, 135, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 135, 34560, 34560, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 135, 34560, 135, 34560, 33, 34560, 33, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 135, 135, 33, 135, 34560, 135, 135, 34560, 33, 34560, 34560, 135, 33, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 33, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 34560, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 34560, 135, 33, 33, 33, 33]
Prompts retrieved: 2986440 . Total input tokens: 665820289 . Total output tokens: 597372628
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 95.8975649937056,
    "estimated_duration": 3600.075834038665,
    "input_throughput": 7576.573454954352,
    "output_throughput": 6649.706034982064,
    "total_throughput": 14226.279489936416,
    "itl": 126.24719966178438,
    "ttft": 1961447.2955930363,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 471,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.441489727392341,
    "arrivals": 994382,
    "finished_requests": 109682,
    "scheduler_time": 220.26570630568062
}
#Debug simulation 
Total elapsed time: 95.89770292676985. Arrivals time: 0.6756859952583909 Scheduler time: 95.04457548912615 Scheduler overhead time: 0.06956236390396953 Adapter cache time: 0.015856007114052773 Engine time: 0.06728589022532105 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-16/adapters_256_slots_32_rate_3.2-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-16/adapters_256_slots_32_rate_3.2-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 33, 34560, 34560, 33, 34560, 135, 34560, 33, 135, 33, 34560, 135, 135, 135, 135, 34560, 33, 33, 33, 135, 34560, 33, 34560, 34560, 135, 135, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 33, 135, 135, 34560, 135, 33, 135, 34560, 135, 135, 34560, 135, 34560, 33, 34560, 34560, 135, 33, 33, 34560, 135, 33, 135, 135, 34560, 135, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 34560, 34560, 33, 34560, 33, 135, 34560, 34560, 34560, 135, 33, 34560, 135, 33, 33, 33, 33, 33, 34560, 135, 33, 34560, 33, 34560, 33, 33, 135, 135, 34560, 135, 34560, 33, 135, 33, 34560, 34560, 33, 34560, 135, 33, 34560, 33, 33, 34560, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 33, 135, 34560, 34560, 33, 34560, 135, 33, 135, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 135, 34560, 34560, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 135, 34560, 135, 34560, 33, 34560, 33, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 135, 135, 33, 135, 34560, 135, 135, 34560, 33, 34560, 34560, 135, 33, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 33, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 34560, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 34560, 135, 33, 33, 33, 33]
Prompts retrieved: 2986440 . Total input tokens: 665820289 . Total output tokens: 597372628
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 93.45468803914264,
    "estimated_duration": 3600.0440921300096,
    "input_throughput": 7573.755571384635,
    "output_throughput": 6651.4738117644265,
    "total_throughput": 14225.22938314906,
    "itl": 126.28370110765482,
    "ttft": 1962342.8832453855,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 425,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3896726129995718,
    "arrivals": 994382,
    "finished_requests": 109687,
    "scheduler_time": 220.27540520678434
}
#Debug simulation 
Total elapsed time: 93.45482231117785. Arrivals time: 0.5463053653948009 Scheduler time: 92.73158582206815 Scheduler overhead time: 0.0690932278521359 Adapter cache time: 0.015594533644616604 Engine time: 0.06762598548084497 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-32/adapters_256_slots_32_rate_3.2-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-32/adapters_256_slots_32_rate_3.2-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 33, 34560, 34560, 33, 34560, 135, 34560, 33, 135, 33, 34560, 135, 135, 135, 135, 34560, 33, 33, 33, 135, 34560, 33, 34560, 34560, 135, 135, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 33, 135, 135, 34560, 135, 33, 135, 34560, 135, 135, 34560, 135, 34560, 33, 34560, 34560, 135, 33, 33, 34560, 135, 33, 135, 135, 34560, 135, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 34560, 34560, 33, 34560, 33, 135, 34560, 34560, 34560, 135, 33, 34560, 135, 33, 33, 33, 33, 33, 34560, 135, 33, 34560, 33, 34560, 33, 33, 135, 135, 34560, 135, 34560, 33, 135, 33, 34560, 34560, 33, 34560, 135, 33, 34560, 33, 33, 34560, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 33, 135, 34560, 34560, 33, 34560, 135, 33, 135, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 135, 34560, 34560, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 135, 34560, 135, 34560, 33, 34560, 33, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 135, 135, 33, 135, 34560, 135, 135, 34560, 33, 34560, 34560, 135, 33, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 33, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 34560, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 34560, 135, 33, 33, 33, 33]
Prompts retrieved: 2986440 . Total input tokens: 665820289 . Total output tokens: 597372628
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 93.39313144795597,
    "estimated_duration": 3600.04605772918,
    "input_throughput": 7573.751436168744,
    "output_throughput": 6651.470180107721,
    "total_throughput": 14225.221616276463,
    "itl": 126.2837698869232,
    "ttft": 1962343.6012080766,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 425,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3916345316357992,
    "arrivals": 994382,
    "finished_requests": 109687,
    "scheduler_time": 220.27540888730346
}
#Debug simulation 
Total elapsed time: 93.39326581079513. Arrivals time: 0.5553873921744525 Scheduler time: 92.6623279848136 Scheduler overhead time: 0.06905971700325608 Adapter cache time: 0.015251108445227146 Engine time: 0.06713797990232706 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-16/adapters_256_slots_32_rate_3.2-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-16/adapters_256_slots_32_rate_3.2-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 33, 34560, 34560, 33, 34560, 135, 34560, 33, 135, 33, 34560, 135, 135, 135, 135, 34560, 33, 33, 33, 135, 34560, 33, 34560, 34560, 135, 135, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 33, 135, 135, 34560, 135, 33, 135, 34560, 135, 135, 34560, 135, 34560, 33, 34560, 34560, 135, 33, 33, 34560, 135, 33, 135, 135, 34560, 135, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 34560, 34560, 33, 34560, 33, 135, 34560, 34560, 34560, 135, 33, 34560, 135, 33, 33, 33, 33, 33, 34560, 135, 33, 34560, 33, 34560, 33, 33, 135, 135, 34560, 135, 34560, 33, 135, 33, 34560, 34560, 33, 34560, 135, 33, 34560, 33, 33, 34560, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 33, 135, 34560, 34560, 33, 34560, 135, 33, 135, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 135, 34560, 34560, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 135, 34560, 135, 34560, 33, 34560, 33, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 135, 135, 33, 135, 34560, 135, 135, 34560, 33, 34560, 34560, 135, 33, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 33, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 34560, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 34560, 135, 33, 33, 33, 33]
Prompts retrieved: 2986440 . Total input tokens: 665820289 . Total output tokens: 597372628
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 96.31343268789351,
    "estimated_duration": 3600.0855496522386,
    "input_throughput": 7579.922372299182,
    "output_throughput": 6653.011343664781,
    "total_throughput": 14232.933715963962,
    "itl": 126.2410943516944,
    "ttft": 1962010.9472588804,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 430,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3466023292555458,
    "arrivals": 994382,
    "finished_requests": 109733,
    "scheduler_time": 220.07176698754702
}
#Debug simulation 
Total elapsed time: 96.31357353460044. Arrivals time: 0.5462761581875384 Scheduler time: 95.58825594512746 Scheduler overhead time: 0.07036188244819641 Adapter cache time: 0.015709612984210253 Engine time: 0.06836534617468715 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-32/adapters_256_slots_32_rate_3.2-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-32/adapters_256_slots_32_rate_3.2-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 33, 34560, 34560, 33, 34560, 135, 34560, 33, 135, 33, 34560, 135, 135, 135, 135, 34560, 33, 33, 33, 135, 34560, 33, 34560, 34560, 135, 135, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 33, 135, 135, 34560, 135, 33, 135, 34560, 135, 135, 34560, 135, 34560, 33, 34560, 34560, 135, 33, 33, 34560, 135, 33, 135, 135, 34560, 135, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 34560, 34560, 33, 34560, 33, 135, 34560, 34560, 34560, 135, 33, 34560, 135, 33, 33, 33, 33, 33, 34560, 135, 33, 34560, 33, 34560, 33, 33, 135, 135, 34560, 135, 34560, 33, 135, 33, 34560, 34560, 33, 34560, 135, 33, 34560, 33, 33, 34560, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 33, 135, 34560, 34560, 33, 34560, 135, 33, 135, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 135, 34560, 34560, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 135, 34560, 135, 34560, 33, 34560, 33, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 135, 135, 33, 135, 34560, 135, 135, 34560, 33, 34560, 34560, 135, 33, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 33, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 34560, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 34560, 135, 33, 33, 33, 33]
Prompts retrieved: 2986440 . Total input tokens: 665820289 . Total output tokens: 597372628
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 97.484689258039,
    "estimated_duration": 3600.117326269577,
    "input_throughput": 7572.420432266393,
    "output_throughput": 6650.89768749583,
    "total_throughput": 14223.318119762223,
    "itl": 126.25996243787546,
    "ttft": 1960173.8524527138,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 439,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4553418421559083,
    "arrivals": 994382,
    "finished_requests": 109626,
    "scheduler_time": 220.36577239613285
}
#Debug simulation 
Total elapsed time: 97.48482359619811. Arrivals time: 0.6965332287363708 Scheduler time: 96.61009094817564 Scheduler overhead time: 0.07092496193945408 Adapter cache time: 0.01577040320262313 Engine time: 0.06703987810760736 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-16/adapters_256_slots_32_rate_3.2-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-16/adapters_256_slots_32_rate_3.2-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 33, 34560, 34560, 33, 34560, 135, 34560, 33, 135, 33, 34560, 135, 135, 135, 135, 34560, 33, 33, 33, 135, 34560, 33, 34560, 34560, 135, 135, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 33, 135, 135, 34560, 135, 33, 135, 34560, 135, 135, 34560, 135, 34560, 33, 34560, 34560, 135, 33, 33, 34560, 135, 33, 135, 135, 34560, 135, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 34560, 34560, 33, 34560, 33, 135, 34560, 34560, 34560, 135, 33, 34560, 135, 33, 33, 33, 33, 33, 34560, 135, 33, 34560, 33, 34560, 33, 33, 135, 135, 34560, 135, 34560, 33, 135, 33, 34560, 34560, 33, 34560, 135, 33, 34560, 33, 33, 34560, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 33, 135, 34560, 34560, 33, 34560, 135, 33, 135, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 135, 34560, 34560, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 135, 34560, 135, 34560, 33, 34560, 33, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 135, 135, 33, 135, 34560, 135, 135, 34560, 33, 34560, 34560, 135, 33, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 33, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 34560, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 34560, 135, 33, 33, 33, 33]
Prompts retrieved: 2986440 . Total input tokens: 665820289 . Total output tokens: 597372628
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 96.15942731732503,
    "estimated_duration": 3600.114689630615,
    "input_throughput": 7577.534148724309,
    "output_throughput": 6650.536736777297,
    "total_throughput": 14228.070885501606,
    "itl": 126.2378616314426,
    "ttft": 1961720.6826469717,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 468,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3993435380142054,
    "arrivals": 994382,
    "finished_requests": 109697,
    "scheduler_time": 220.2373394626036
}
#Debug simulation 
Total elapsed time: 96.15956716705114. Arrivals time: 0.679113607853651 Scheduler time: 95.30356024531648 Scheduler overhead time: 0.06843855790793896 Adapter cache time: 0.015396815724670887 Engine time: 0.06848382903262973 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-32/adapters_256_slots_32_rate_3.2-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-32/adapters_256_slots_32_rate_3.2-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 33, 34560, 34560, 33, 34560, 135, 34560, 33, 135, 33, 34560, 135, 135, 135, 135, 34560, 33, 33, 33, 135, 34560, 33, 34560, 34560, 135, 135, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 33, 135, 135, 34560, 135, 33, 135, 34560, 135, 135, 34560, 135, 34560, 33, 34560, 34560, 135, 33, 33, 34560, 135, 33, 135, 135, 34560, 135, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 34560, 34560, 33, 34560, 33, 135, 34560, 34560, 34560, 135, 33, 34560, 135, 33, 33, 33, 33, 33, 34560, 135, 33, 34560, 33, 34560, 33, 33, 135, 135, 34560, 135, 34560, 33, 135, 33, 34560, 34560, 33, 34560, 135, 33, 34560, 33, 33, 34560, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 33, 135, 34560, 34560, 33, 34560, 135, 33, 135, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 135, 34560, 34560, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 135, 34560, 135, 34560, 33, 34560, 33, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 135, 135, 33, 135, 34560, 135, 135, 34560, 33, 34560, 34560, 135, 33, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 33, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 34560, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 34560, 135, 33, 33, 33, 33]
Prompts retrieved: 2986440 . Total input tokens: 665820289 . Total output tokens: 597372628
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 97.37643192894757,
    "estimated_duration": 3600.137322446031,
    "input_throughput": 7572.378372910989,
    "output_throughput": 6650.860746537243,
    "total_throughput": 14223.239119448232,
    "itl": 126.26053837577555,
    "ttft": 1960181.9182123707,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 439,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4740791563317184,
    "arrivals": 994382,
    "finished_requests": 109626,
    "scheduler_time": 220.36590020811423
}
#Debug simulation 
Total elapsed time: 97.3765685511753. Arrivals time: 0.6668079039081931 Scheduler time: 96.53025813540444 Scheduler overhead time: 0.0706239496357739 Adapter cache time: 0.015669590327888727 Engine time: 0.06836231984198093 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-8/adapters_256_slots_32_rate_3.2-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-8/adapters_256_slots_32_rate_3.2-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [66, 66, 34560, 33, 34560, 34560, 33, 34560, 66, 34560, 33, 66, 33, 34560, 66, 66, 66, 66, 34560, 33, 33, 33, 66, 34560, 33, 34560, 34560, 66, 66, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 33, 66, 66, 34560, 66, 33, 66, 34560, 66, 66, 34560, 66, 34560, 33, 34560, 34560, 66, 33, 33, 34560, 66, 33, 66, 66, 34560, 66, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 34560, 34560, 33, 34560, 33, 66, 34560, 34560, 34560, 66, 33, 34560, 66, 33, 33, 33, 33, 33, 34560, 66, 33, 34560, 33, 34560, 33, 33, 66, 66, 34560, 66, 34560, 33, 66, 33, 34560, 34560, 33, 34560, 66, 33, 34560, 33, 33, 34560, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 33, 66, 34560, 34560, 33, 34560, 66, 33, 66, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 66, 34560, 34560, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 66, 34560, 66, 34560, 33, 34560, 33, 66, 34560, 66, 34560, 66, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 66, 66, 33, 66, 34560, 66, 66, 34560, 33, 34560, 34560, 66, 33, 34560, 34560, 66, 66, 34560, 34560, 66, 66, 66, 66, 34560, 34560, 66, 66, 34560, 33, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 34560, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 34560, 66, 33, 33, 33, 33]
Prompts retrieved: 2980575 . Total input tokens: 664496257 . Total output tokens: 596195076
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 98.20437971921638,
    "estimated_duration": 3600.0280773323225,
    "input_throughput": 7515.192498178545,
    "output_throughput": 6642.614025866252,
    "total_throughput": 14157.806524044796,
    "itl": 126.98638715003605,
    "ttft": 1962860.4743521388,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 304,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9303882741555559,
    "arrivals": 992438,
    "finished_requests": 109415,
    "scheduler_time": 220.81615591242445
}
#Debug simulation 
Total elapsed time: 98.20453072013333. Arrivals time: 0.6316513693891466 Scheduler time: 97.39459017245099 Scheduler overhead time: 0.07093971781432629 Adapter cache time: 0.014232015237212181 Engine time: 0.06830982537940145 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-16/adapters_256_slots_32_rate_3.2-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-16/adapters_256_slots_32_rate_3.2-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [66, 66, 34560, 33, 34560, 34560, 33, 34560, 66, 34560, 33, 66, 33, 34560, 66, 66, 66, 66, 34560, 33, 33, 33, 66, 34560, 33, 34560, 34560, 66, 66, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 33, 66, 66, 34560, 66, 33, 66, 34560, 66, 66, 34560, 66, 34560, 33, 34560, 34560, 66, 33, 33, 34560, 66, 33, 66, 66, 34560, 66, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 34560, 34560, 33, 34560, 33, 66, 34560, 34560, 34560, 66, 33, 34560, 66, 33, 33, 33, 33, 33, 34560, 66, 33, 34560, 33, 34560, 33, 33, 66, 66, 34560, 66, 34560, 33, 66, 33, 34560, 34560, 33, 34560, 66, 33, 34560, 33, 33, 34560, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 33, 66, 34560, 34560, 33, 34560, 66, 33, 66, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 66, 34560, 34560, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 66, 34560, 66, 34560, 33, 34560, 33, 66, 34560, 66, 34560, 66, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 66, 66, 33, 66, 34560, 66, 66, 34560, 33, 34560, 34560, 66, 33, 34560, 34560, 66, 66, 34560, 34560, 66, 66, 66, 66, 34560, 34560, 66, 66, 34560, 33, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 34560, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 34560, 66, 33, 33, 33, 33]
Prompts retrieved: 2980575 . Total input tokens: 664496257 . Total output tokens: 596195076
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 95.63878005323932,
    "estimated_duration": 3600.0756596502893,
    "input_throughput": 7523.209387946848,
    "output_throughput": 6644.427023604173,
    "total_throughput": 14167.63641155102,
    "itl": 126.20169814758397,
    "ttft": 1964997.4484589999,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 405,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3172051522298769,
    "arrivals": 992438,
    "finished_requests": 109429,
    "scheduler_time": 220.7420053966177
}
#Debug simulation 
Total elapsed time: 95.63892445806414. Arrivals time: 0.554098395165056 Scheduler time: 94.90807263553143 Scheduler overhead time: 0.06966163078323007 Adapter cache time: 0.015032431576400995 Engine time: 0.06763567728921771 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-32/adapters_256_slots_32_rate_3.2-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-32/adapters_256_slots_32_rate_3.2-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [66, 66, 34560, 33, 34560, 34560, 33, 34560, 66, 34560, 33, 66, 33, 34560, 66, 66, 66, 66, 34560, 33, 33, 33, 66, 34560, 33, 34560, 34560, 66, 66, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 33, 66, 66, 34560, 66, 33, 66, 34560, 66, 66, 34560, 66, 34560, 33, 34560, 34560, 66, 33, 33, 34560, 66, 33, 66, 66, 34560, 66, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 34560, 34560, 33, 34560, 33, 66, 34560, 34560, 34560, 66, 33, 34560, 66, 33, 33, 33, 33, 33, 34560, 66, 33, 34560, 33, 34560, 33, 33, 66, 66, 34560, 66, 34560, 33, 66, 33, 34560, 34560, 33, 34560, 66, 33, 34560, 33, 33, 34560, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 33, 66, 34560, 34560, 33, 34560, 66, 33, 66, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 66, 34560, 34560, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 66, 34560, 66, 34560, 33, 34560, 33, 66, 34560, 66, 34560, 66, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 66, 66, 33, 66, 34560, 66, 66, 34560, 33, 34560, 34560, 66, 33, 34560, 34560, 66, 66, 34560, 34560, 66, 66, 66, 66, 34560, 34560, 66, 66, 34560, 33, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 34560, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 34560, 66, 33, 33, 33, 33]
Prompts retrieved: 2980575 . Total input tokens: 664496257 . Total output tokens: 596195076
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 95.23861867422238,
    "estimated_duration": 3600.0785416908425,
    "input_throughput": 7523.203365246428,
    "output_throughput": 6644.421704412407,
    "total_throughput": 14167.625069658836,
    "itl": 126.20179542794146,
    "ttft": 1964998.3303995838,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 405,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3203094823286012,
    "arrivals": 992438,
    "finished_requests": 109429,
    "scheduler_time": 220.7420093171166
}
#Debug simulation 
Total elapsed time: 95.2387623093091. Arrivals time: 0.5496570426039398 Scheduler time: 94.5122565519996 Scheduler overhead time: 0.06926297815516591 Adapter cache time: 0.015133081935346127 Engine time: 0.06767990905791521 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-16/adapters_256_slots_32_rate_3.2-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-16/adapters_256_slots_32_rate_3.2-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [66, 66, 34560, 33, 34560, 34560, 33, 34560, 66, 34560, 33, 66, 33, 34560, 66, 66, 66, 66, 34560, 33, 33, 33, 66, 34560, 33, 34560, 34560, 66, 66, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 33, 66, 66, 34560, 66, 33, 66, 34560, 66, 66, 34560, 66, 34560, 33, 34560, 34560, 66, 33, 33, 34560, 66, 33, 66, 66, 34560, 66, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 34560, 34560, 33, 34560, 33, 66, 34560, 34560, 34560, 66, 33, 34560, 66, 33, 33, 33, 33, 33, 34560, 66, 33, 34560, 33, 34560, 33, 33, 66, 66, 34560, 66, 34560, 33, 66, 33, 34560, 34560, 33, 34560, 66, 33, 34560, 33, 33, 34560, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 33, 66, 34560, 34560, 33, 34560, 66, 33, 66, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 66, 34560, 34560, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 66, 34560, 66, 34560, 33, 34560, 33, 66, 34560, 66, 34560, 66, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 66, 66, 33, 66, 34560, 66, 66, 34560, 33, 34560, 34560, 66, 33, 34560, 34560, 66, 66, 34560, 34560, 66, 66, 66, 66, 34560, 34560, 66, 66, 34560, 33, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 34560, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 34560, 66, 33, 33, 33, 33]
Prompts retrieved: 2980575 . Total input tokens: 664496257 . Total output tokens: 596195076
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 99.96906452812254,
    "estimated_duration": 3600.066603343464,
    "input_throughput": 7535.160870303472,
    "output_throughput": 6647.248964165041,
    "total_throughput": 14182.409834468514,
    "itl": 126.31227946263712,
    "ttft": 1961171.6901656974,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 358,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.120695229743144,
    "arrivals": 992438,
    "finished_requests": 109570,
    "scheduler_time": 220.5765598131252
}
#Debug simulation 
Total elapsed time: 99.96919973613694. Arrivals time: 0.5601521567441523 Scheduler time: 99.22995785437524 Scheduler overhead time: 0.0703226812183857 Adapter cache time: 0.015369542874395847 Engine time: 0.0684118876233697 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-32/adapters_256_slots_32_rate_3.2-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-32/adapters_256_slots_32_rate_3.2-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [66, 66, 34560, 33, 34560, 34560, 33, 34560, 66, 34560, 33, 66, 33, 34560, 66, 66, 66, 66, 34560, 33, 33, 33, 66, 34560, 33, 34560, 34560, 66, 66, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 33, 66, 66, 34560, 66, 33, 66, 34560, 66, 66, 34560, 66, 34560, 33, 34560, 34560, 66, 33, 33, 34560, 66, 33, 66, 66, 34560, 66, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 34560, 34560, 33, 34560, 33, 66, 34560, 34560, 34560, 66, 33, 34560, 66, 33, 33, 33, 33, 33, 34560, 66, 33, 34560, 33, 34560, 33, 33, 66, 66, 34560, 66, 34560, 33, 66, 33, 34560, 34560, 33, 34560, 66, 33, 34560, 33, 33, 34560, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 33, 66, 34560, 34560, 33, 34560, 66, 33, 66, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 66, 34560, 34560, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 66, 34560, 66, 34560, 33, 34560, 33, 66, 34560, 66, 34560, 66, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 66, 66, 33, 66, 34560, 66, 66, 34560, 33, 34560, 34560, 66, 33, 34560, 34560, 66, 66, 34560, 34560, 66, 66, 66, 66, 34560, 34560, 66, 66, 34560, 33, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 34560, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 34560, 66, 33, 33, 33, 33]
Prompts retrieved: 2980575 . Total input tokens: 664496257 . Total output tokens: 596195076
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 95.77957613626495,
    "estimated_duration": 3600.0936287846685,
    "input_throughput": 7523.171837378893,
    "output_throughput": 6644.393859299471,
    "total_throughput": 14167.565696678364,
    "itl": 126.2021824004253,
    "ttft": 1965003.9987964442,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 405,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3355256904847974,
    "arrivals": 992438,
    "finished_requests": 109429,
    "scheduler_time": 220.74210641286248
}
#Debug simulation 
Total elapsed time: 95.77971955388784. Arrivals time: 0.5530657935887575 Scheduler time: 95.05031888280064 Scheduler overhead time: 0.06905206758528948 Adapter cache time: 0.014790104236453772 Engine time: 0.06778981629759073 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-16/adapters_256_slots_32_rate_3.2-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-16/adapters_256_slots_32_rate_3.2-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [66, 66, 34560, 33, 34560, 34560, 33, 34560, 66, 34560, 33, 66, 33, 34560, 66, 66, 66, 66, 34560, 33, 33, 33, 66, 34560, 33, 34560, 34560, 66, 66, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 33, 66, 66, 34560, 66, 33, 66, 34560, 66, 66, 34560, 66, 34560, 33, 34560, 34560, 66, 33, 33, 34560, 66, 33, 66, 66, 34560, 66, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 34560, 34560, 33, 34560, 33, 66, 34560, 34560, 34560, 66, 33, 34560, 66, 33, 33, 33, 33, 33, 34560, 66, 33, 34560, 33, 34560, 33, 33, 66, 66, 34560, 66, 34560, 33, 66, 33, 34560, 34560, 33, 34560, 66, 33, 34560, 33, 33, 34560, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 33, 66, 34560, 34560, 33, 34560, 66, 33, 66, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 66, 34560, 34560, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 66, 34560, 66, 34560, 33, 34560, 33, 66, 34560, 66, 34560, 66, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 66, 66, 33, 66, 34560, 66, 66, 34560, 33, 34560, 34560, 66, 33, 34560, 34560, 66, 66, 34560, 34560, 66, 66, 66, 66, 34560, 34560, 66, 66, 34560, 33, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 34560, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 34560, 66, 33, 33, 33, 33]
Prompts retrieved: 2980575 . Total input tokens: 664496257 . Total output tokens: 596195076
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 98.01179910125211,
    "estimated_duration": 3600.0047152795914,
    "input_throughput": 7515.241267648952,
    "output_throughput": 6642.657132781775,
    "total_throughput": 14157.898400430726,
    "itl": 126.98582073257242,
    "ttft": 1962849.8463791069,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 304,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9089752896502626,
    "arrivals": 992438,
    "finished_requests": 109415,
    "scheduler_time": 220.81590341961885
}
#Debug simulation 
Total elapsed time: 98.0119526842609. Arrivals time: 0.6348009156063199 Scheduler time: 97.20031222514808 Scheduler overhead time: 0.06966343382373452 Adapter cache time: 0.014424575958400965 Engine time: 0.06778225023299456 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-32/adapters_256_slots_32_rate_3.2-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-32/adapters_256_slots_32_rate_3.2-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [66, 66, 34560, 33, 34560, 34560, 33, 34560, 66, 34560, 33, 66, 33, 34560, 66, 66, 66, 66, 34560, 33, 33, 33, 66, 34560, 33, 34560, 34560, 66, 66, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 33, 66, 66, 34560, 66, 33, 66, 34560, 66, 66, 34560, 66, 34560, 33, 34560, 34560, 66, 33, 33, 34560, 66, 33, 66, 66, 34560, 66, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 34560, 34560, 33, 34560, 33, 66, 34560, 34560, 34560, 66, 33, 34560, 66, 33, 33, 33, 33, 33, 34560, 66, 33, 34560, 33, 34560, 33, 33, 66, 66, 34560, 66, 34560, 33, 66, 33, 34560, 34560, 33, 34560, 66, 33, 34560, 33, 33, 34560, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 33, 66, 34560, 34560, 33, 34560, 66, 33, 66, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 66, 34560, 34560, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 66, 34560, 66, 34560, 33, 34560, 33, 66, 34560, 66, 34560, 66, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 66, 66, 33, 66, 34560, 66, 66, 34560, 33, 34560, 34560, 66, 33, 34560, 34560, 66, 66, 34560, 34560, 66, 66, 66, 66, 34560, 34560, 66, 66, 34560, 33, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 34560, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 34560, 66, 33, 33, 33, 33]
Prompts retrieved: 2980575 . Total input tokens: 664496257 . Total output tokens: 596195076
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 95.86227653268725,
    "estimated_duration": 3600.1119052163767,
    "input_throughput": 7523.133645028229,
    "output_throughput": 6644.360128178381,
    "total_throughput": 14167.49377320661,
    "itl": 126.20277162892043,
    "ttft": 1965010.7590301493,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 405,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3530054667964595,
    "arrivals": 992438,
    "finished_requests": 109429,
    "scheduler_time": 220.74222443809225
}
#Debug simulation 
Total elapsed time: 95.86242017010227. Arrivals time: 0.5574445487000048 Scheduler time: 95.12810754962265 Scheduler overhead time: 0.0696901441551745 Adapter cache time: 0.015152903273701668 Engine time: 0.06771134538576007 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-8/adapters_256_slots_32_rate_1.6-0.8-0.4_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-8/adapters_256_slots_32_rate_1.6-0.8-0.4_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 4320, 17280, 17280, 4320, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 8640, 8640, 8640, 8640, 17280, 4320, 4320, 4320, 8640, 17280, 4320, 17280, 17280, 8640, 8640, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 4320, 17280, 8640, 4320, 8640, 8640, 17280, 8640, 4320, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 17280, 17280, 4320, 17280, 4320, 8640, 17280, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 8640, 4320, 17280, 4320, 17280, 4320, 4320, 8640, 8640, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 17280, 4320, 17280, 8640, 4320, 8640, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 4320, 4320, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 17280, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 17280, 4320, 17280, 4320, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 17280, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 4320, 4320, 4320, 4320]
Prompts retrieved: 2587680 . Total input tokens: 577057570 . Total output tokens: 517693652
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 104.3033945648931,
    "estimated_duration": 3600.110550329913,
    "input_throughput": 7332.774266496017,
    "output_throughput": 6489.350444490955,
    "total_throughput": 13822.124710986973,
    "itl": 121.02969988446415,
    "ttft": 1953843.8812447733,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 522,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.597574602332917,
    "arrivals": 861811,
    "finished_requests": 106564,
    "scheduler_time": 227.76857933628887
}
#Debug simulation 
Total elapsed time: 104.30353997973725. Arrivals time: 0.6284472425468266 Scheduler time: 103.48747186781839 Scheduler overhead time: 0.07386406790465117 Adapter cache time: 0.017755387350916862 Engine time: 0.07031619688495994 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-16/adapters_256_slots_32_rate_1.6-0.8-0.4_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-16/adapters_256_slots_32_rate_1.6-0.8-0.4_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 4320, 17280, 17280, 4320, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 8640, 8640, 8640, 8640, 17280, 4320, 4320, 4320, 8640, 17280, 4320, 17280, 17280, 8640, 8640, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 4320, 17280, 8640, 4320, 8640, 8640, 17280, 8640, 4320, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 17280, 17280, 4320, 17280, 4320, 8640, 17280, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 8640, 4320, 17280, 4320, 17280, 4320, 4320, 8640, 8640, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 17280, 4320, 17280, 8640, 4320, 8640, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 4320, 4320, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 17280, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 17280, 4320, 17280, 4320, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 17280, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 4320, 4320, 4320, 4320]
Prompts retrieved: 2587680 . Total input tokens: 577057570 . Total output tokens: 517693652
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 103.6320471521467,
    "estimated_duration": 3600.0158787939754,
    "input_throughput": 7274.289859180558,
    "output_throughput": 6450.5698813138415,
    "total_throughput": 13724.8597404944,
    "itl": 118.18708676126083,
    "ttft": 1948432.059937861,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 524,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.708977525345986,
    "arrivals": 861811,
    "finished_requests": 105665,
    "scheduler_time": 230.9538538423781
}
#Debug simulation 
Total elapsed time: 103.63218475924805. Arrivals time: 0.6306855012662709 Scheduler time: 102.81182531500235 Scheduler overhead time: 0.07426476525142789 Adapter cache time: 0.017983718775212765 Engine time: 0.07134214648976922 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-32/adapters_256_slots_32_rate_1.6-0.8-0.4_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-32/adapters_256_slots_32_rate_1.6-0.8-0.4_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 4320, 17280, 17280, 4320, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 8640, 8640, 8640, 8640, 17280, 4320, 4320, 4320, 8640, 17280, 4320, 17280, 17280, 8640, 8640, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 4320, 17280, 8640, 4320, 8640, 8640, 17280, 8640, 4320, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 17280, 17280, 4320, 17280, 4320, 8640, 17280, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 8640, 4320, 17280, 4320, 17280, 4320, 4320, 8640, 8640, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 17280, 4320, 17280, 8640, 4320, 8640, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 4320, 4320, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 17280, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 17280, 4320, 17280, 4320, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 17280, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 4320, 4320, 4320, 4320]
Prompts retrieved: 2587680 . Total input tokens: 577057570 . Total output tokens: 517693652
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 103.45497704204172,
    "estimated_duration": 3600.0189824966214,
    "input_throughput": 7274.283587760104,
    "output_throughput": 6450.564320051274,
    "total_throughput": 13724.847907811378,
    "itl": 118.18713696583218,
    "ttft": 1948433.1861346764,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 524,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7121660048514709,
    "arrivals": 861811,
    "finished_requests": 105665,
    "scheduler_time": 230.95388217053002
}
#Debug simulation 
Total elapsed time: 103.45511857420206. Arrivals time: 0.634955259039998 Scheduler time: 102.63231914304197 Scheduler overhead time: 0.07392213121056557 Adapter cache time: 0.01797831477597356 Engine time: 0.0699781714938581 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-16-16/adapters_256_slots_32_rate_1.6-0.8-0.4_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-16-16/adapters_256_slots_32_rate_1.6-0.8-0.4_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 4320, 17280, 17280, 4320, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 8640, 8640, 8640, 8640, 17280, 4320, 4320, 4320, 8640, 17280, 4320, 17280, 17280, 8640, 8640, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 4320, 17280, 8640, 4320, 8640, 8640, 17280, 8640, 4320, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 17280, 17280, 4320, 17280, 4320, 8640, 17280, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 8640, 4320, 17280, 4320, 17280, 4320, 4320, 8640, 8640, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 17280, 4320, 17280, 8640, 4320, 8640, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 4320, 4320, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 17280, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 17280, 4320, 17280, 4320, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 17280, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 4320, 4320, 4320, 4320]
Prompts retrieved: 2587680 . Total input tokens: 577057570 . Total output tokens: 517693652
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 104.31056068325415,
    "estimated_duration": 3600.0144058766764,
    "input_throughput": 7332.824823397195,
    "output_throughput": 6489.270143437388,
    "total_throughput": 13822.094966834582,
    "itl": 121.0299833594614,
    "ttft": 1953870.176701065,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 522,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6327190299844294,
    "arrivals": 861811,
    "finished_requests": 106561,
    "scheduler_time": 227.7605651224389
}
#Debug simulation 
Total elapsed time: 104.31070788390934. Arrivals time: 0.6256995517760515 Scheduler time: 103.49769018031657 Scheduler overhead time: 0.0731974714435637 Adapter cache time: 0.017762672621756792 Engine time: 0.07050944585353136 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-16-32/adapters_256_slots_32_rate_1.6-0.8-0.4_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-16-32/adapters_256_slots_32_rate_1.6-0.8-0.4_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 4320, 17280, 17280, 4320, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 8640, 8640, 8640, 8640, 17280, 4320, 4320, 4320, 8640, 17280, 4320, 17280, 17280, 8640, 8640, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 4320, 17280, 8640, 4320, 8640, 8640, 17280, 8640, 4320, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 17280, 17280, 4320, 17280, 4320, 8640, 17280, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 8640, 4320, 17280, 4320, 17280, 4320, 4320, 8640, 8640, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 17280, 4320, 17280, 8640, 4320, 8640, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 4320, 4320, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 17280, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 17280, 4320, 17280, 4320, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 17280, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 4320, 4320, 4320, 4320]
Prompts retrieved: 2587680 . Total input tokens: 577057570 . Total output tokens: 517693652
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 104.19709909986705,
    "estimated_duration": 3600.0415002040318,
    "input_throughput": 7274.238088231989,
    "output_throughput": 6450.523972760839,
    "total_throughput": 13724.762060992829,
    "itl": 118.18780778513094,
    "ttft": 1948442.9680098766,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 524,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7341729174740654,
    "arrivals": 861811,
    "finished_requests": 105665,
    "scheduler_time": 230.95427986030538
}
#Debug simulation 
Total elapsed time: 104.19724013609812. Arrivals time: 0.640334099996835 Scheduler time: 103.36599257960916 Scheduler overhead time: 0.07578591210767627 Adapter cache time: 0.017896242439746857 Engine time: 0.07127489522099495 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_16-16-16/adapters_256_slots_32_rate_1.6-0.8-0.4_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_16-16-16/adapters_256_slots_32_rate_1.6-0.8-0.4_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 4320, 17280, 17280, 4320, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 8640, 8640, 8640, 8640, 17280, 4320, 4320, 4320, 8640, 17280, 4320, 17280, 17280, 8640, 8640, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 4320, 17280, 8640, 4320, 8640, 8640, 17280, 8640, 4320, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 17280, 17280, 4320, 17280, 4320, 8640, 17280, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 8640, 4320, 17280, 4320, 17280, 4320, 4320, 8640, 8640, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 17280, 4320, 17280, 8640, 4320, 8640, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 4320, 4320, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 17280, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 17280, 4320, 17280, 4320, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 17280, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 4320, 4320, 4320, 4320]
Prompts retrieved: 2587680 . Total input tokens: 577057570 . Total output tokens: 517693652
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 104.46961990790442,
    "estimated_duration": 3600.0735471119397,
    "input_throughput": 7332.849636135271,
    "output_throughput": 6489.417145030781,
    "total_throughput": 13822.266781166052,
    "itl": 121.02882444785831,
    "ttft": 1953828.047007621,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 522,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5608062539389171,
    "arrivals": 861811,
    "finished_requests": 106564,
    "scheduler_time": 227.76811825657424
}
#Debug simulation 
Total elapsed time: 104.46976118301973. Arrivals time: 0.6292754490859807 Scheduler time: 103.65304595744237 Scheduler overhead time: 0.07317637512460351 Adapter cache time: 0.01746437605470419 Engine time: 0.07086450280621648 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_16-16-32/adapters_256_slots_32_rate_1.6-0.8-0.4_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_16-16-32/adapters_256_slots_32_rate_1.6-0.8-0.4_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 4320, 17280, 17280, 4320, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 8640, 8640, 8640, 8640, 17280, 4320, 4320, 4320, 8640, 17280, 4320, 17280, 17280, 8640, 8640, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 4320, 17280, 8640, 4320, 8640, 8640, 17280, 8640, 4320, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 17280, 17280, 4320, 17280, 4320, 8640, 17280, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 8640, 4320, 17280, 4320, 17280, 4320, 4320, 8640, 8640, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 17280, 4320, 17280, 8640, 4320, 8640, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 4320, 4320, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 17280, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 17280, 4320, 17280, 4320, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 17280, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 4320, 4320, 4320, 4320]
Prompts retrieved: 2587680 . Total input tokens: 577057570 . Total output tokens: 517693652
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 103.93769339192659,
    "estimated_duration": 3600.0630051751587,
    "input_throughput": 7274.194635581346,
    "output_throughput": 6450.485440565267,
    "total_throughput": 13724.680076146613,
    "itl": 118.18832666829383,
    "ttft": 1948452.2262610863,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 524,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7559283225238298,
    "arrivals": 861811,
    "finished_requests": 105665,
    "scheduler_time": 230.9544818465266
}
#Debug simulation 
Total elapsed time: 103.93789274524897. Arrivals time: 0.6142576169222593 Scheduler time: 103.13402695581317 Scheduler overhead time: 0.07482879888266325 Adapter cache time: 0.018151761032640934 Engine time: 0.07011693762615323 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-8/adapters_256_slots_32_rate_1.6-0.8-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-8/adapters_256_slots_32_rate_1.6-0.8-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 1080, 17280, 17280, 1080, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 8640, 8640, 8640, 8640, 17280, 1080, 1080, 1080, 8640, 17280, 1080, 17280, 17280, 8640, 8640, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 1080, 17280, 8640, 1080, 8640, 8640, 17280, 8640, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 8640, 17280, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 8640, 1080, 17280, 1080, 17280, 1080, 1080, 8640, 8640, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 17280, 1080, 17280, 8640, 1080, 8640, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 17280, 1080, 17280, 1080, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 17280, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 1080, 1080, 1080, 1080]
Prompts retrieved: 2312280 . Total input tokens: 515501074 . Total output tokens: 462498738
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 101.71811428386718,
    "estimated_duration": 3600.0765730266903,
    "input_throughput": 7394.2002232524865,
    "output_throughput": 6516.058346025098,
    "total_throughput": 13910.258569277585,
    "itl": 120.86260935255667,
    "ttft": 1925254.7717954996,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 496,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5180019209906626,
    "arrivals": 769968,
    "finished_requests": 107338,
    "scheduler_time": 226.7798773315208
}
#Debug simulation 
Total elapsed time: 101.71825688006356. Arrivals time: 0.6164920455776155 Scheduler time: 100.91575912944973 Scheduler overhead time: 0.07278224546462297 Adapter cache time: 0.017300193663686514 Engine time: 0.06990341376513243 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-16/adapters_256_slots_32_rate_1.6-0.8-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-16/adapters_256_slots_32_rate_1.6-0.8-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 1080, 17280, 17280, 1080, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 8640, 8640, 8640, 8640, 17280, 1080, 1080, 1080, 8640, 17280, 1080, 17280, 17280, 8640, 8640, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 1080, 17280, 8640, 1080, 8640, 8640, 17280, 8640, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 8640, 17280, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 8640, 1080, 17280, 1080, 17280, 1080, 1080, 8640, 8640, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 17280, 1080, 17280, 8640, 1080, 8640, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 17280, 1080, 17280, 1080, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 17280, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 1080, 1080, 1080, 1080]
Prompts retrieved: 2312280 . Total input tokens: 515501074 . Total output tokens: 462498738
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 98.6126051438041,
    "estimated_duration": 3600.059766633114,
    "input_throughput": 7331.659392056388,
    "output_throughput": 6456.71586217554,
    "total_throughput": 13788.375254231927,
    "itl": 119.00912055224615,
    "ttft": 1925695.0927929517,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 544,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.774907461020635,
    "arrivals": 769968,
    "finished_requests": 106409,
    "scheduler_time": 229.64665368019394
}
#Debug simulation 
Total elapsed time: 98.61274020001292. Arrivals time: 0.5903726839460433 Scheduler time: 97.83566982019693 Scheduler overhead time: 0.07346865674480796 Adapter cache time: 0.017601314466446638 Engine time: 0.07004804536700249 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-32/adapters_256_slots_32_rate_1.6-0.8-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-32/adapters_256_slots_32_rate_1.6-0.8-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 1080, 17280, 17280, 1080, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 8640, 8640, 8640, 8640, 17280, 1080, 1080, 1080, 8640, 17280, 1080, 17280, 17280, 8640, 8640, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 1080, 17280, 8640, 1080, 8640, 8640, 17280, 8640, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 8640, 17280, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 8640, 1080, 17280, 1080, 17280, 1080, 1080, 8640, 8640, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 17280, 1080, 17280, 8640, 1080, 8640, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 17280, 1080, 17280, 1080, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 17280, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 1080, 1080, 1080, 1080]
Prompts retrieved: 2312280 . Total input tokens: 515501074 . Total output tokens: 462498738
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 99.32309952704236,
    "estimated_duration": 3600.062733913911,
    "input_throughput": 7331.653349080549,
    "output_throughput": 6456.71054035467,
    "total_throughput": 13788.363889435219,
    "itl": 119.0091854660864,
    "ttft": 1925695.9994441944,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 544,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.778095094244938,
    "arrivals": 769968,
    "finished_requests": 106409,
    "scheduler_time": 229.64665953780815
}
#Debug simulation 
Total elapsed time: 99.32324060611427. Arrivals time: 0.6122144809924066 Scheduler time: 98.5243196641095 Scheduler overhead time: 0.07333356933668256 Adapter cache time: 0.017463411670178175 Engine time: 0.0693701347336173 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-16-16/adapters_256_slots_32_rate_1.6-0.8-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-16-16/adapters_256_slots_32_rate_1.6-0.8-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 1080, 17280, 17280, 1080, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 8640, 8640, 8640, 8640, 17280, 1080, 1080, 1080, 8640, 17280, 1080, 17280, 17280, 8640, 8640, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 1080, 17280, 8640, 1080, 8640, 8640, 17280, 8640, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 8640, 17280, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 8640, 1080, 17280, 1080, 17280, 1080, 1080, 8640, 8640, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 17280, 1080, 17280, 8640, 1080, 8640, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 17280, 1080, 17280, 1080, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 17280, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 1080, 1080, 1080, 1080]
Prompts retrieved: 2312280 . Total input tokens: 515501074 . Total output tokens: 462498738
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 101.28080913983285,
    "estimated_duration": 3600.028797567281,
    "input_throughput": 7393.819743327355,
    "output_throughput": 6515.738156275572,
    "total_throughput": 13909.557899602927,
    "itl": 120.86342709819895,
    "ttft": 1925294.2250128926,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 496,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5521175550878923,
    "arrivals": 769968,
    "finished_requests": 107333,
    "scheduler_time": 226.77375679194844
}
#Debug simulation 
Total elapsed time: 101.2809483949095. Arrivals time: 0.6162434751167893 Scheduler time: 100.47889769030735 Scheduler overhead time: 0.07317498326301575 Adapter cache time: 0.017008427530527115 Engine time: 0.0697206580080092 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-16-32/adapters_256_slots_32_rate_1.6-0.8-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-16-32/adapters_256_slots_32_rate_1.6-0.8-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 1080, 17280, 17280, 1080, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 8640, 8640, 8640, 8640, 17280, 1080, 1080, 1080, 8640, 17280, 1080, 17280, 17280, 8640, 8640, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 1080, 17280, 8640, 1080, 8640, 8640, 17280, 8640, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 8640, 17280, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 8640, 1080, 17280, 1080, 17280, 1080, 1080, 8640, 8640, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 17280, 1080, 17280, 8640, 1080, 8640, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 17280, 1080, 17280, 1080, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 17280, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 1080, 1080, 1080, 1080]
Prompts retrieved: 2312280 . Total input tokens: 515501074 . Total output tokens: 462498738
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 99.22116013243794,
    "estimated_duration": 3600.001598334987,
    "input_throughput": 7333.690632862688,
    "output_throughput": 6488.818785748308,
    "total_throughput": 13822.509418610996,
    "itl": 119.37052791911938,
    "ttft": 1915346.4144773867,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 520,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7202325768768834,
    "arrivals": 769968,
    "finished_requests": 106410,
    "scheduler_time": 229.62106533138964
}
#Debug simulation 
Total elapsed time: 99.22129093203694. Arrivals time: 0.6127929659560323 Scheduler time: 98.42140317801386 Scheduler overhead time: 0.07341589406132698 Adapter cache time: 0.017577725928276777 Engine time: 0.07056499645113945 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_16-16-16/adapters_256_slots_32_rate_1.6-0.8-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_16-16-16/adapters_256_slots_32_rate_1.6-0.8-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 1080, 17280, 17280, 1080, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 8640, 8640, 8640, 8640, 17280, 1080, 1080, 1080, 8640, 17280, 1080, 17280, 17280, 8640, 8640, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 1080, 17280, 8640, 1080, 8640, 8640, 17280, 8640, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 8640, 17280, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 8640, 1080, 17280, 1080, 17280, 1080, 1080, 8640, 8640, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 17280, 1080, 17280, 8640, 1080, 8640, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 17280, 1080, 17280, 1080, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 17280, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 1080, 1080, 1080, 1080]
Prompts retrieved: 2312280 . Total input tokens: 515501074 . Total output tokens: 462498738
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 101.52175282780081,
    "estimated_duration": 3600.0417432643494,
    "input_throughput": 7394.271760822005,
    "output_throughput": 6516.121387728439,
    "total_throughput": 13910.393148550444,
    "itl": 120.86189726283925,
    "ttft": 1925240.0062562325,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 496,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4830649462714633,
    "arrivals": 769968,
    "finished_requests": 107338,
    "scheduler_time": 226.7794190186744
}
#Debug simulation 
Total elapsed time: 101.52189514180645. Arrivals time: 0.6235010833479464 Scheduler time: 100.7114021293819 Scheduler overhead time: 0.07376892725005746 Adapter cache time: 0.01721835322678089 Engine time: 0.06990756932646036 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_16-16-32/adapters_256_slots_32_rate_1.6-0.8-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_16-16-32/adapters_256_slots_32_rate_1.6-0.8-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 1080, 17280, 17280, 1080, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 8640, 8640, 8640, 8640, 17280, 1080, 1080, 1080, 8640, 17280, 1080, 17280, 17280, 8640, 8640, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 1080, 17280, 8640, 1080, 8640, 8640, 17280, 8640, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 8640, 17280, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 8640, 1080, 17280, 1080, 17280, 1080, 1080, 8640, 8640, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 17280, 1080, 17280, 8640, 1080, 8640, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 17280, 1080, 17280, 1080, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 17280, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 1080, 1080, 1080, 1080]
Prompts retrieved: 2312280 . Total input tokens: 515501074 . Total output tokens: 462498738
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 99.27594987861812,
    "estimated_duration": 3600.0238772992225,
    "input_throughput": 7333.645247877229,
    "output_throughput": 6488.778629303078,
    "total_throughput": 13822.423877180307,
    "itl": 119.37095386728068,
    "ttft": 1915355.908370513,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 520,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.742365243285892,
    "arrivals": 769968,
    "finished_requests": 106410,
    "scheduler_time": 229.62132473426524
}
#Debug simulation 
Total elapsed time: 99.27614558581263. Arrivals time: 0.607231792062521 Scheduler time: 98.48088049096987 Scheduler overhead time: 0.07404802925884724 Adapter cache time: 0.017668983433395624 Engine time: 0.06988226436078548 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-8/adapters_256_slots_32_rate_1.6-0.8-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-8/adapters_256_slots_32_rate_1.6-0.8-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 540, 17280, 17280, 540, 17280, 8640, 17280, 540, 8640, 540, 17280, 8640, 8640, 8640, 8640, 17280, 540, 540, 540, 8640, 17280, 540, 17280, 17280, 8640, 8640, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 540, 8640, 8640, 17280, 8640, 540, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 540, 17280, 17280, 8640, 540, 540, 17280, 8640, 540, 8640, 8640, 17280, 8640, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 8640, 540, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 540, 17280, 17280, 540, 17280, 540, 8640, 17280, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 540, 540, 540, 17280, 8640, 540, 17280, 540, 17280, 540, 540, 8640, 8640, 17280, 8640, 17280, 540, 8640, 540, 17280, 17280, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 17280, 540, 17280, 8640, 540, 8640, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 8640, 17280, 17280, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 17280, 540, 17280, 540, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 8640, 8640, 17280, 540, 17280, 17280, 8640, 540, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 540, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 17280, 540, 8640, 540, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 540, 540, 540, 540]
Prompts retrieved: 2266380 . Total input tokens: 505284175 . Total output tokens: 453316467
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 101.69517554016784,
    "estimated_duration": 3600.0521878143445,
    "input_throughput": 7341.028302160519,
    "output_throughput": 6451.024537535862,
    "total_throughput": 13792.052839696382,
    "itl": 120.20092979191404,
    "ttft": 1931250.7065753494,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 469,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4353687519044753,
    "arrivals": 754714,
    "finished_requests": 106408,
    "scheduler_time": 230.02488446013373
}
#Debug simulation 
Total elapsed time: 101.69531399384141. Arrivals time: 0.5969802793115377 Scheduler time: 100.91003897739574 Scheduler overhead time: 0.07436962146311998 Adapter cache time: 0.017026090994477272 Engine time: 0.07064300356432796 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-16/adapters_256_slots_32_rate_1.6-0.8-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-16/adapters_256_slots_32_rate_1.6-0.8-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 540, 17280, 17280, 540, 17280, 8640, 17280, 540, 8640, 540, 17280, 8640, 8640, 8640, 8640, 17280, 540, 540, 540, 8640, 17280, 540, 17280, 17280, 8640, 8640, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 540, 8640, 8640, 17280, 8640, 540, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 540, 17280, 17280, 8640, 540, 540, 17280, 8640, 540, 8640, 8640, 17280, 8640, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 8640, 540, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 540, 17280, 17280, 540, 17280, 540, 8640, 17280, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 540, 540, 540, 17280, 8640, 540, 17280, 540, 17280, 540, 540, 8640, 8640, 17280, 8640, 17280, 540, 8640, 540, 17280, 17280, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 17280, 540, 17280, 8640, 540, 8640, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 8640, 17280, 17280, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 17280, 540, 17280, 540, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 8640, 8640, 17280, 540, 17280, 17280, 8640, 540, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 540, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 17280, 540, 8640, 540, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 540, 540, 540, 540]
Prompts retrieved: 2266380 . Total input tokens: 505284175 . Total output tokens: 453316467
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 104.18990574218333,
    "estimated_duration": 3600.1083425135307,
    "input_throughput": 7358.514933332297,
    "output_throughput": 6472.437155524973,
    "total_throughput": 13830.95208885727,
    "itl": 120.957656817237,
    "ttft": 1932831.5765818737,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 460,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4992275171424312,
    "arrivals": 754714,
    "finished_requests": 106807,
    "scheduler_time": 228.9661102559518
}
#Debug simulation 
Total elapsed time: 104.19005748210475. Arrivals time: 0.619726930744946 Scheduler time: 103.38011837052181 Scheduler overhead time: 0.07578449044376612 Adapter cache time: 0.016970868222415447 Engine time: 0.07081299042329192 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-32/adapters_256_slots_32_rate_1.6-0.8-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-32/adapters_256_slots_32_rate_1.6-0.8-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 540, 17280, 17280, 540, 17280, 8640, 17280, 540, 8640, 540, 17280, 8640, 8640, 8640, 8640, 17280, 540, 540, 540, 8640, 17280, 540, 17280, 17280, 8640, 8640, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 540, 8640, 8640, 17280, 8640, 540, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 540, 17280, 17280, 8640, 540, 540, 17280, 8640, 540, 8640, 8640, 17280, 8640, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 8640, 540, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 540, 17280, 17280, 540, 17280, 540, 8640, 17280, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 540, 540, 540, 17280, 8640, 540, 17280, 540, 17280, 540, 540, 8640, 8640, 17280, 8640, 17280, 540, 8640, 540, 17280, 17280, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 17280, 540, 17280, 8640, 540, 8640, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 8640, 17280, 17280, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 17280, 540, 17280, 540, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 8640, 8640, 17280, 540, 17280, 17280, 8640, 540, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 540, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 17280, 540, 8640, 540, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 540, 540, 540, 540]
Prompts retrieved: 2266380 . Total input tokens: 505284175 . Total output tokens: 453316467
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 104.24777157371864,
    "estimated_duration": 3600.1118351352234,
    "input_throughput": 7358.507794523822,
    "output_throughput": 6472.430876338256,
    "total_throughput": 13830.938670862077,
    "itl": 120.95774434623162,
    "ttft": 1932833.176703206,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 460,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5022046612762003,
    "arrivals": 754714,
    "finished_requests": 106807,
    "scheduler_time": 228.96617331337475
}
#Debug simulation 
Total elapsed time: 104.24791842792183. Arrivals time: 0.6220583636313677 Scheduler time: 103.43533182004467 Scheduler overhead time: 0.07566873682662845 Adapter cache time: 0.017398998141288757 Engine time: 0.07130609638988972 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-16-16/adapters_256_slots_32_rate_1.6-0.8-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-16-16/adapters_256_slots_32_rate_1.6-0.8-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 540, 17280, 17280, 540, 17280, 8640, 17280, 540, 8640, 540, 17280, 8640, 8640, 8640, 8640, 17280, 540, 540, 540, 8640, 17280, 540, 17280, 17280, 8640, 8640, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 540, 8640, 8640, 17280, 8640, 540, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 540, 17280, 17280, 8640, 540, 540, 17280, 8640, 540, 8640, 8640, 17280, 8640, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 8640, 540, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 540, 17280, 17280, 540, 17280, 540, 8640, 17280, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 540, 540, 540, 17280, 8640, 540, 17280, 540, 17280, 540, 540, 8640, 8640, 17280, 8640, 17280, 540, 8640, 540, 17280, 17280, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 17280, 540, 17280, 8640, 540, 8640, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 8640, 17280, 17280, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 17280, 540, 17280, 540, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 8640, 8640, 17280, 540, 17280, 17280, 8640, 540, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 540, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 17280, 540, 8640, 540, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 540, 540, 540, 540]
Prompts retrieved: 2266380 . Total input tokens: 505284175 . Total output tokens: 453316467
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 102.34350020298734,
    "estimated_duration": 3600.1060114405036,
    "input_throughput": 7376.659163815539,
    "output_throughput": 6484.394605551965,
    "total_throughput": 13861.053769367503,
    "itl": 121.21406026819808,
    "ttft": 1933629.4478912856,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 466,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.455469925827342,
    "arrivals": 754714,
    "finished_requests": 107001,
    "scheduler_time": 228.34304484274236
}
#Debug simulation 
Total elapsed time: 102.34364586416632. Arrivals time: 0.6031184983439744 Scheduler time: 101.55227301083505 Scheduler overhead time: 0.07443396421149373 Adapter cache time: 0.016654574777930975 Engine time: 0.07045519165694714 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-16-32/adapters_256_slots_32_rate_1.6-0.8-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-16-32/adapters_256_slots_32_rate_1.6-0.8-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 540, 17280, 17280, 540, 17280, 8640, 17280, 540, 8640, 540, 17280, 8640, 8640, 8640, 8640, 17280, 540, 540, 540, 8640, 17280, 540, 17280, 17280, 8640, 8640, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 540, 8640, 8640, 17280, 8640, 540, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 540, 17280, 17280, 8640, 540, 540, 17280, 8640, 540, 8640, 8640, 17280, 8640, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 8640, 540, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 540, 17280, 17280, 540, 17280, 540, 8640, 17280, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 540, 540, 540, 17280, 8640, 540, 17280, 540, 17280, 540, 540, 8640, 8640, 17280, 8640, 17280, 540, 8640, 540, 17280, 17280, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 17280, 540, 17280, 8640, 540, 8640, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 8640, 17280, 17280, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 17280, 540, 17280, 540, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 8640, 8640, 17280, 540, 17280, 17280, 8640, 540, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 540, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 17280, 540, 8640, 540, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 540, 540, 540, 540]
Prompts retrieved: 2266380 . Total input tokens: 505284175 . Total output tokens: 453316467
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 104.23502787714824,
    "estimated_duration": 3600.13078612904,
    "input_throughput": 7358.469059532234,
    "output_throughput": 6472.396805632272,
    "total_throughput": 13830.865865164506,
    "itl": 120.95809953630042,
    "ttft": 1932841.235826246,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 460,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.521570744384085,
    "arrivals": 754714,
    "finished_requests": 106807,
    "scheduler_time": 228.9663654665761
}
#Debug simulation 
Total elapsed time: 104.23516998905689. Arrivals time: 0.6158375586383045 Scheduler time: 103.42924424540251 Scheduler overhead time: 0.07453130977228284 Adapter cache time: 0.017292762640863657 Engine time: 0.0716808745637536 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_16-16-16/adapters_256_slots_32_rate_1.6-0.8-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_16-16-16/adapters_256_slots_32_rate_1.6-0.8-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 540, 17280, 17280, 540, 17280, 8640, 17280, 540, 8640, 540, 17280, 8640, 8640, 8640, 8640, 17280, 540, 540, 540, 8640, 17280, 540, 17280, 17280, 8640, 8640, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 540, 8640, 8640, 17280, 8640, 540, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 540, 17280, 17280, 8640, 540, 540, 17280, 8640, 540, 8640, 8640, 17280, 8640, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 8640, 540, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 540, 17280, 17280, 540, 17280, 540, 8640, 17280, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 540, 540, 540, 17280, 8640, 540, 17280, 540, 17280, 540, 540, 8640, 8640, 17280, 8640, 17280, 540, 8640, 540, 17280, 17280, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 17280, 540, 17280, 8640, 540, 8640, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 8640, 17280, 17280, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 17280, 540, 17280, 540, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 8640, 8640, 17280, 540, 17280, 17280, 8640, 540, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 540, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 17280, 540, 8640, 540, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 540, 540, 540, 540]
Prompts retrieved: 2266380 . Total input tokens: 505284175 . Total output tokens: 453316467
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 104.37302429880947,
    "estimated_duration": 3600.0832469199277,
    "input_throughput": 7370.549284576079,
    "output_throughput": 6484.97531827193,
    "total_throughput": 13855.524602848009,
    "itl": 121.45528659658171,
    "ttft": 1933442.1029654397,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 438,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3096420291671433,
    "arrivals": 754714,
    "finished_requests": 107060,
    "scheduler_time": 228.15657323007989
}
#Debug simulation 
Total elapsed time: 104.37316906871274. Arrivals time: 0.6112254280596972 Scheduler time: 103.57278743293136 Scheduler overhead time: 0.07467376906424761 Adapter cache time: 0.016532592941075563 Engine time: 0.07127416133880615 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_16-16-32/adapters_256_slots_32_rate_1.6-0.8-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_16-16-32/adapters_256_slots_32_rate_1.6-0.8-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 540, 17280, 17280, 540, 17280, 8640, 17280, 540, 8640, 540, 17280, 8640, 8640, 8640, 8640, 17280, 540, 540, 540, 8640, 17280, 540, 17280, 17280, 8640, 8640, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 540, 8640, 8640, 17280, 8640, 540, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 540, 17280, 17280, 8640, 540, 540, 17280, 8640, 540, 8640, 8640, 17280, 8640, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 8640, 540, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 540, 17280, 17280, 540, 17280, 540, 8640, 17280, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 540, 540, 540, 17280, 8640, 540, 17280, 540, 17280, 540, 540, 8640, 8640, 17280, 8640, 17280, 540, 8640, 540, 17280, 17280, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 17280, 540, 17280, 8640, 540, 8640, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 8640, 17280, 17280, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 17280, 540, 17280, 540, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 8640, 8640, 17280, 540, 17280, 17280, 8640, 540, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 540, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 17280, 540, 8640, 540, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 540, 540, 540, 540]
Prompts retrieved: 2266380 . Total input tokens: 505284175 . Total output tokens: 453316467
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 102.96147730015218,
    "estimated_duration": 3600.0798569164176,
    "input_throughput": 7363.431660848142,
    "output_throughput": 6482.158987436537,
    "total_throughput": 13845.59064828468,
    "itl": 121.54047214977095,
    "ttft": 1934175.597957162,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 453,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5143734138086449,
    "arrivals": 754714,
    "finished_requests": 106943,
    "scheduler_time": 228.32716636164662
}
#Debug simulation 
Total elapsed time: 102.96169152110815. Arrivals time: 0.6210344582796097 Scheduler time: 102.15190682932734 Scheduler overhead time: 0.07522932719439268 Adapter cache time: 0.016693342477083206 Engine time: 0.07049699453637004 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-8/adapters_256_slots_32_rate_1.6-0.8-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-8/adapters_256_slots_32_rate_1.6-0.8-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 270, 17280, 17280, 270, 17280, 8640, 17280, 270, 8640, 270, 17280, 8640, 8640, 8640, 8640, 17280, 270, 270, 270, 8640, 17280, 270, 17280, 17280, 8640, 8640, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 270, 8640, 8640, 17280, 8640, 270, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 270, 17280, 17280, 8640, 270, 270, 17280, 8640, 270, 8640, 8640, 17280, 8640, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 8640, 270, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 270, 17280, 17280, 270, 17280, 270, 8640, 17280, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 270, 270, 270, 17280, 8640, 270, 17280, 270, 17280, 270, 270, 8640, 8640, 17280, 8640, 17280, 270, 8640, 270, 17280, 17280, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 17280, 270, 17280, 8640, 270, 8640, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 8640, 17280, 17280, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 17280, 270, 17280, 270, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 8640, 8640, 17280, 270, 17280, 17280, 8640, 270, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 270, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 17280, 270, 8640, 270, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 270, 270, 270, 270]
Prompts retrieved: 2243430 . Total input tokens: 500187779 . Total output tokens: 448743425
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 102.37165381480008,
    "estimated_duration": 3600.1116470764423,
    "input_throughput": 7413.358144510152,
    "output_throughput": 6549.511601715984,
    "total_throughput": 13962.869746226135,
    "itl": 123.8157363522581,
    "ttft": 1923198.0756463758,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 478,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.462913141599871,
    "arrivals": 746983,
    "finished_requests": 107471,
    "scheduler_time": 224.83128059548847
}
#Debug simulation 
Total elapsed time: 102.37179543823004. Arrivals time: 0.6192357954569161 Scheduler time: 101.56492805993184 Scheduler overhead time: 0.07405020110309124 Adapter cache time: 0.016218807082623243 Engine time: 0.07102509960532188 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-16/adapters_256_slots_32_rate_1.6-0.8-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-16/adapters_256_slots_32_rate_1.6-0.8-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 270, 17280, 17280, 270, 17280, 8640, 17280, 270, 8640, 270, 17280, 8640, 8640, 8640, 8640, 17280, 270, 270, 270, 8640, 17280, 270, 17280, 17280, 8640, 8640, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 270, 8640, 8640, 17280, 8640, 270, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 270, 17280, 17280, 8640, 270, 270, 17280, 8640, 270, 8640, 8640, 17280, 8640, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 8640, 270, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 270, 17280, 17280, 270, 17280, 270, 8640, 17280, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 270, 270, 270, 17280, 8640, 270, 17280, 270, 17280, 270, 270, 8640, 8640, 17280, 8640, 17280, 270, 8640, 270, 17280, 17280, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 17280, 270, 17280, 8640, 270, 8640, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 8640, 17280, 17280, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 17280, 270, 17280, 270, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 8640, 8640, 17280, 270, 17280, 17280, 8640, 270, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 270, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 17280, 270, 8640, 270, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 270, 270, 270, 270]
Prompts retrieved: 2243430 . Total input tokens: 500187779 . Total output tokens: 448743425
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 103.6626221681945,
    "estimated_duration": 3600.053882828821,
    "input_throughput": 7368.5749889820045,
    "output_throughput": 6526.503148207797,
    "total_throughput": 13895.078137189801,
    "itl": 122.66078399283347,
    "ttft": 1917126.125354989,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 448,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4613039370114038,
    "arrivals": 746983,
    "finished_requests": 106930,
    "scheduler_time": 227.29252531722756
}
#Debug simulation 
Total elapsed time: 103.66276238299906. Arrivals time: 0.6127862152643502 Scheduler time: 102.8602288775146 Scheduler overhead time: 0.07509171450510621 Adapter cache time: 0.01671859296038747 Engine time: 0.07151365093886852 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-32/adapters_256_slots_32_rate_1.6-0.8-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-32/adapters_256_slots_32_rate_1.6-0.8-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 270, 17280, 17280, 270, 17280, 8640, 17280, 270, 8640, 270, 17280, 8640, 8640, 8640, 8640, 17280, 270, 270, 270, 8640, 17280, 270, 17280, 17280, 8640, 8640, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 270, 8640, 8640, 17280, 8640, 270, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 270, 17280, 17280, 8640, 270, 270, 17280, 8640, 270, 8640, 8640, 17280, 8640, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 8640, 270, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 270, 17280, 17280, 270, 17280, 270, 8640, 17280, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 270, 270, 270, 17280, 8640, 270, 17280, 270, 17280, 270, 270, 8640, 8640, 17280, 8640, 17280, 270, 8640, 270, 17280, 17280, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 17280, 270, 17280, 8640, 270, 8640, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 8640, 17280, 17280, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 17280, 270, 17280, 270, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 8640, 8640, 17280, 270, 17280, 17280, 8640, 270, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 270, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 17280, 270, 8640, 270, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 270, 270, 270, 270]
Prompts retrieved: 2243430 . Total input tokens: 500187779 . Total output tokens: 448743425
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 103.72346910228953,
    "estimated_duration": 3600.0564833158137,
    "input_throughput": 7368.569666320122,
    "output_throughput": 6526.498433813279,
    "total_throughput": 13895.068100133401,
    "itl": 122.66082607372073,
    "ttft": 1917127.2580517645,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 448,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4639961976185527,
    "arrivals": 746983,
    "finished_requests": 106930,
    "scheduler_time": 227.2925466486302
}
#Debug simulation 
Total elapsed time: 103.72360373428091. Arrivals time: 0.6088618701323867 Scheduler time: 102.9261441193521 Scheduler overhead time: 0.07470277138054371 Adapter cache time: 0.016583166550844908 Engine time: 0.07116622570902109 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-16-16/adapters_256_slots_32_rate_1.6-0.8-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-16-16/adapters_256_slots_32_rate_1.6-0.8-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 270, 17280, 17280, 270, 17280, 8640, 17280, 270, 8640, 270, 17280, 8640, 8640, 8640, 8640, 17280, 270, 270, 270, 8640, 17280, 270, 17280, 17280, 8640, 8640, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 270, 8640, 8640, 17280, 8640, 270, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 270, 17280, 17280, 8640, 270, 270, 17280, 8640, 270, 8640, 8640, 17280, 8640, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 8640, 270, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 270, 17280, 17280, 270, 17280, 270, 8640, 17280, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 270, 270, 270, 17280, 8640, 270, 17280, 270, 17280, 270, 270, 8640, 8640, 17280, 8640, 17280, 270, 8640, 270, 17280, 17280, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 17280, 270, 17280, 8640, 270, 8640, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 8640, 17280, 17280, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 17280, 270, 17280, 270, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 8640, 8640, 17280, 270, 17280, 17280, 8640, 270, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 270, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 17280, 270, 8640, 270, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 270, 270, 270, 270]
Prompts retrieved: 2243430 . Total input tokens: 500187779 . Total output tokens: 448743425
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 104.62203288590536,
    "estimated_duration": 3600.030489946962,
    "input_throughput": 7413.126937264683,
    "output_throughput": 6549.3267531596275,
    "total_throughput": 13962.45369042431,
    "itl": 123.81596762938595,
    "ttft": 1923226.8320200478,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 478,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4933935059583696,
    "arrivals": 746983,
    "finished_requests": 107468,
    "scheduler_time": 224.82402922848235
}
#Debug simulation 
Total elapsed time: 104.62217041291296. Arrivals time: 0.6281965216621757 Scheduler time: 103.80427531339228 Scheduler overhead time: 0.07476654602214694 Adapter cache time: 0.017153207678347826 Engine time: 0.07202955707907677 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-16-32/adapters_256_slots_32_rate_1.6-0.8-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-16-32/adapters_256_slots_32_rate_1.6-0.8-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 270, 17280, 17280, 270, 17280, 8640, 17280, 270, 8640, 270, 17280, 8640, 8640, 8640, 8640, 17280, 270, 270, 270, 8640, 17280, 270, 17280, 17280, 8640, 8640, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 270, 8640, 8640, 17280, 8640, 270, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 270, 17280, 17280, 8640, 270, 270, 17280, 8640, 270, 8640, 8640, 17280, 8640, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 8640, 270, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 270, 17280, 17280, 270, 17280, 270, 8640, 17280, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 270, 270, 270, 17280, 8640, 270, 17280, 270, 17280, 270, 270, 8640, 8640, 17280, 8640, 17280, 270, 8640, 270, 17280, 17280, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 17280, 270, 17280, 8640, 270, 8640, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 8640, 17280, 17280, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 17280, 270, 17280, 270, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 8640, 8640, 17280, 270, 17280, 17280, 8640, 270, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 270, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 17280, 270, 8640, 270, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 270, 270, 270, 270]
Prompts retrieved: 2243430 . Total input tokens: 500187779 . Total output tokens: 448743425
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 104.66035602428019,
    "estimated_duration": 3600.102142466153,
    "input_throughput": 7351.466973064869,
    "output_throughput": 6492.049412795163,
    "total_throughput": 13843.516385860034,
    "itl": 122.82582771663375,
    "ttft": 1928793.0514051798,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 450,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4904210470430597,
    "arrivals": 746983,
    "finished_requests": 106646,
    "scheduler_time": 227.8153993582472
}
#Debug simulation 
Total elapsed time: 104.66049068421125. Arrivals time: 0.6985808005556464 Scheduler time: 103.7730024899356 Scheduler overhead time: 0.07472127908840775 Adapter cache time: 0.01674991101026535 Engine time: 0.07121583772823215 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_16-16-16/adapters_256_slots_32_rate_1.6-0.8-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_16-16-16/adapters_256_slots_32_rate_1.6-0.8-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 270, 17280, 17280, 270, 17280, 8640, 17280, 270, 8640, 270, 17280, 8640, 8640, 8640, 8640, 17280, 270, 270, 270, 8640, 17280, 270, 17280, 17280, 8640, 8640, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 270, 8640, 8640, 17280, 8640, 270, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 270, 17280, 17280, 8640, 270, 270, 17280, 8640, 270, 8640, 8640, 17280, 8640, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 8640, 270, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 270, 17280, 17280, 270, 17280, 270, 8640, 17280, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 270, 270, 270, 17280, 8640, 270, 17280, 270, 17280, 270, 270, 8640, 8640, 17280, 8640, 17280, 270, 8640, 270, 17280, 17280, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 17280, 270, 17280, 8640, 270, 8640, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 8640, 17280, 17280, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 17280, 270, 17280, 270, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 8640, 8640, 17280, 270, 17280, 17280, 8640, 270, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 270, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 17280, 270, 8640, 270, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 270, 270, 270, 270]
Prompts retrieved: 2243430 . Total input tokens: 500187779 . Total output tokens: 448743425
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 100.52344884024933,
    "estimated_duration": 3600.0283949602554,
    "input_throughput": 7379.361517589722,
    "output_throughput": 6523.27965881482,
    "total_throughput": 13902.641176404542,
    "itl": 122.88232368934304,
    "ttft": 1919735.6653995651,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 476,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.423263940373422,
    "arrivals": 746983,
    "finished_requests": 107056,
    "scheduler_time": 226.61122045658414
}
#Debug simulation 
Total elapsed time: 100.52358910813928. Arrivals time: 0.702045766171068 Scheduler time: 99.63577742641792 Scheduler overhead time: 0.07318869046866894 Adapter cache time: 0.016489276196807623 Engine time: 0.07001195102930069 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_16-16-32/adapters_256_slots_32_rate_1.6-0.8-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_16-16-32/adapters_256_slots_32_rate_1.6-0.8-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 270, 17280, 17280, 270, 17280, 8640, 17280, 270, 8640, 270, 17280, 8640, 8640, 8640, 8640, 17280, 270, 270, 270, 8640, 17280, 270, 17280, 17280, 8640, 8640, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 270, 8640, 8640, 17280, 8640, 270, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 270, 17280, 17280, 8640, 270, 270, 17280, 8640, 270, 8640, 8640, 17280, 8640, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 8640, 270, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 270, 17280, 17280, 270, 17280, 270, 8640, 17280, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 270, 270, 270, 17280, 8640, 270, 17280, 270, 17280, 270, 270, 8640, 8640, 17280, 8640, 17280, 270, 8640, 270, 17280, 17280, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 17280, 270, 17280, 8640, 270, 8640, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 8640, 17280, 17280, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 17280, 270, 17280, 270, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 8640, 8640, 17280, 270, 17280, 17280, 8640, 270, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 270, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 17280, 270, 8640, 270, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 270, 270, 270, 270]
Prompts retrieved: 2243430 . Total input tokens: 500187779 . Total output tokens: 448743425
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 104.1429724288173,
    "estimated_duration": 3600.1216140738265,
    "input_throughput": 7351.427211941199,
    "output_throughput": 6492.014299914902,
    "total_throughput": 13843.441511856101,
    "itl": 122.82629646548504,
    "ttft": 1928801.5550684212,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 450,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5094098687916997,
    "arrivals": 746983,
    "finished_requests": 106646,
    "scheduler_time": 227.81554282909005
}
#Debug simulation 
Total elapsed time: 104.14316171500832. Arrivals time: 0.7017468842677772 Scheduler time: 103.25252009509131 Scheduler overhead time: 0.07461908739060163 Adapter cache time: 0.016666570212692022 Engine time: 0.07130125630646944 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-8/adapters_256_slots_32_rate_1.6-0.8-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-8/adapters_256_slots_32_rate_1.6-0.8-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 135, 17280, 17280, 135, 17280, 8640, 17280, 135, 8640, 135, 17280, 8640, 8640, 8640, 8640, 17280, 135, 135, 135, 8640, 17280, 135, 17280, 17280, 8640, 8640, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 135, 8640, 8640, 17280, 8640, 135, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 135, 17280, 17280, 8640, 135, 135, 17280, 8640, 135, 8640, 8640, 17280, 8640, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 8640, 135, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 135, 17280, 17280, 135, 17280, 135, 8640, 17280, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 135, 135, 135, 17280, 8640, 135, 17280, 135, 17280, 135, 135, 8640, 8640, 17280, 8640, 17280, 135, 8640, 135, 17280, 17280, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 17280, 135, 17280, 8640, 135, 8640, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 8640, 17280, 17280, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 17280, 135, 17280, 135, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 8640, 8640, 17280, 135, 17280, 17280, 8640, 135, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 135, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 17280, 135, 8640, 135, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 135, 135, 135, 135]
Prompts retrieved: 2231955 . Total input tokens: 497616808 . Total output tokens: 446425470
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 102.70555768581107,
    "estimated_duration": 3600.0382035175394,
    "input_throughput": 7437.411351312498,
    "output_throughput": 6556.945417116875,
    "total_throughput": 13994.356768429374,
    "itl": 122.90155418951827,
    "ttft": 1914733.7155524646,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 460,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4078243622090796,
    "arrivals": 743226,
    "finished_requests": 108293,
    "scheduler_time": 225.78027747215626
}
#Debug simulation 
Total elapsed time: 102.70569367799908. Arrivals time: 0.6238322062417865 Scheduler time: 101.89643844496459 Scheduler overhead time: 0.07307294849306345 Adapter cache time: 0.01667481753975153 Engine time: 0.07014844613149762 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-16/adapters_256_slots_32_rate_1.6-0.8-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-16/adapters_256_slots_32_rate_1.6-0.8-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 135, 17280, 17280, 135, 17280, 8640, 17280, 135, 8640, 135, 17280, 8640, 8640, 8640, 8640, 17280, 135, 135, 135, 8640, 17280, 135, 17280, 17280, 8640, 8640, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 135, 8640, 8640, 17280, 8640, 135, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 135, 17280, 17280, 8640, 135, 135, 17280, 8640, 135, 8640, 8640, 17280, 8640, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 8640, 135, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 135, 17280, 17280, 135, 17280, 135, 8640, 17280, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 135, 135, 135, 17280, 8640, 135, 17280, 135, 17280, 135, 135, 8640, 8640, 17280, 8640, 17280, 135, 8640, 135, 17280, 17280, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 17280, 135, 17280, 8640, 135, 8640, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 8640, 17280, 17280, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 17280, 135, 17280, 135, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 8640, 8640, 17280, 135, 17280, 17280, 8640, 135, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 135, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 17280, 135, 8640, 135, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 135, 135, 135, 135]
Prompts retrieved: 2231955 . Total input tokens: 497616808 . Total output tokens: 446425470
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 102.81577153597027,
    "estimated_duration": 3600.0172228072847,
    "input_throughput": 7431.996944485802,
    "output_throughput": 6542.758976478622,
    "total_throughput": 13974.755920964422,
    "itl": 122.58749846873867,
    "ttft": 1916499.0339717078,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 451,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4706826832145503,
    "arrivals": 743226,
    "finished_requests": 108197,
    "scheduler_time": 225.33493688538826
}
#Debug simulation 
Total elapsed time: 102.81591176893562. Arrivals time: 0.6155112413689494 Scheduler time: 102.01478281756863 Scheduler overhead time: 0.07290938217192888 Adapter cache time: 0.016602669842541218 Engine time: 0.0701733366586268 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-32/adapters_256_slots_32_rate_1.6-0.8-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-32/adapters_256_slots_32_rate_1.6-0.8-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 135, 17280, 17280, 135, 17280, 8640, 17280, 135, 8640, 135, 17280, 8640, 8640, 8640, 8640, 17280, 135, 135, 135, 8640, 17280, 135, 17280, 17280, 8640, 8640, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 135, 8640, 8640, 17280, 8640, 135, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 135, 17280, 17280, 8640, 135, 135, 17280, 8640, 135, 8640, 8640, 17280, 8640, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 8640, 135, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 135, 17280, 17280, 135, 17280, 135, 8640, 17280, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 135, 135, 135, 17280, 8640, 135, 17280, 135, 17280, 135, 135, 8640, 8640, 17280, 8640, 17280, 135, 8640, 135, 17280, 17280, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 17280, 135, 17280, 8640, 135, 8640, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 8640, 17280, 17280, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 17280, 135, 17280, 135, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 8640, 8640, 17280, 135, 17280, 17280, 8640, 135, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 135, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 17280, 135, 8640, 135, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 135, 135, 135, 135]
Prompts retrieved: 2231955 . Total input tokens: 497616808 . Total output tokens: 446425470
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 102.37460205378011,
    "estimated_duration": 3600.020768818758,
    "input_throughput": 7431.989623987358,
    "output_throughput": 6542.752531877358,
    "total_throughput": 13974.742155864715,
    "itl": 122.58759432724332,
    "ttft": 1916500.7011393069,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 451,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4734640016593126,
    "arrivals": 743226,
    "finished_requests": 108197,
    "scheduler_time": 225.33502294821523
}
#Debug simulation 
Total elapsed time: 102.37474681576714. Arrivals time: 0.5866444874554873 Scheduler time: 101.6037698960863 Scheduler overhead time: 0.0728411772288382 Adapter cache time: 0.016450967639684677 Engine time: 0.06950731296092272 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-16/adapters_256_slots_32_rate_1.6-0.8-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-16/adapters_256_slots_32_rate_1.6-0.8-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 135, 17280, 17280, 135, 17280, 8640, 17280, 135, 8640, 135, 17280, 8640, 8640, 8640, 8640, 17280, 135, 135, 135, 8640, 17280, 135, 17280, 17280, 8640, 8640, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 135, 8640, 8640, 17280, 8640, 135, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 135, 17280, 17280, 8640, 135, 135, 17280, 8640, 135, 8640, 8640, 17280, 8640, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 8640, 135, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 135, 17280, 17280, 135, 17280, 135, 8640, 17280, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 135, 135, 135, 17280, 8640, 135, 17280, 135, 17280, 135, 135, 8640, 8640, 17280, 8640, 17280, 135, 8640, 135, 17280, 17280, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 17280, 135, 17280, 8640, 135, 8640, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 8640, 17280, 17280, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 17280, 135, 17280, 135, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 8640, 8640, 17280, 135, 17280, 17280, 8640, 135, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 135, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 17280, 135, 8640, 135, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 135, 135, 135, 135]
Prompts retrieved: 2231955 . Total input tokens: 497616808 . Total output tokens: 446425470
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 103.19172725407407,
    "estimated_duration": 3600.0522677055606,
    "input_throughput": 7431.924875094133,
    "output_throughput": 6542.850838944118,
    "total_throughput": 13974.775714038251,
    "itl": 122.58630709257312,
    "ttft": 1916467.1783662827,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 451,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4081675994931675,
    "arrivals": 743226,
    "finished_requests": 108198,
    "scheduler_time": 225.3413440291355
}
#Debug simulation 
Total elapsed time: 103.19187114620581. Arrivals time: 0.61267557926476 Scheduler time: 102.39199545281008 Scheduler overhead time: 0.07410827279090881 Adapter cache time: 0.01662467746064067 Engine time: 0.07024634815752506 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-32/adapters_256_slots_32_rate_1.6-0.8-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-32/adapters_256_slots_32_rate_1.6-0.8-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 135, 17280, 17280, 135, 17280, 8640, 17280, 135, 8640, 135, 17280, 8640, 8640, 8640, 8640, 17280, 135, 135, 135, 8640, 17280, 135, 17280, 17280, 8640, 8640, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 135, 8640, 8640, 17280, 8640, 135, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 135, 17280, 17280, 8640, 135, 135, 17280, 8640, 135, 8640, 8640, 17280, 8640, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 8640, 135, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 135, 17280, 17280, 135, 17280, 135, 8640, 17280, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 135, 135, 135, 17280, 8640, 135, 17280, 135, 17280, 135, 135, 8640, 8640, 17280, 8640, 17280, 135, 8640, 135, 17280, 17280, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 17280, 135, 17280, 8640, 135, 8640, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 8640, 17280, 17280, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 17280, 135, 17280, 135, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 8640, 8640, 17280, 135, 17280, 17280, 8640, 135, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 135, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 17280, 135, 8640, 135, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 135, 135, 135, 135]
Prompts retrieved: 2231955 . Total input tokens: 497616808 . Total output tokens: 446425470
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 102.68858843808994,
    "estimated_duration": 3600.040049098276,
    "input_throughput": 7431.949821419783,
    "output_throughput": 6542.717491684495,
    "total_throughput": 13974.667313104279,
    "itl": 122.58803760508593,
    "ttft": 1916508.9152948577,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 451,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4927043309807815,
    "arrivals": 743226,
    "finished_requests": 108197,
    "scheduler_time": 225.33517600345968
}
#Debug simulation 
Total elapsed time: 102.688728032168. Arrivals time: 0.6183144319802523 Scheduler time: 101.8834011349827 Scheduler overhead time: 0.07384557044133544 Adapter cache time: 0.01648885803297162 Engine time: 0.07076797168701887 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-16/adapters_256_slots_32_rate_1.6-0.8-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-16/adapters_256_slots_32_rate_1.6-0.8-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 135, 17280, 17280, 135, 17280, 8640, 17280, 135, 8640, 135, 17280, 8640, 8640, 8640, 8640, 17280, 135, 135, 135, 8640, 17280, 135, 17280, 17280, 8640, 8640, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 135, 8640, 8640, 17280, 8640, 135, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 135, 17280, 17280, 8640, 135, 135, 17280, 8640, 135, 8640, 8640, 17280, 8640, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 8640, 135, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 135, 17280, 17280, 135, 17280, 135, 8640, 17280, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 135, 135, 135, 17280, 8640, 135, 17280, 135, 17280, 135, 135, 8640, 8640, 17280, 8640, 17280, 135, 8640, 135, 17280, 17280, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 17280, 135, 17280, 8640, 135, 8640, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 8640, 17280, 17280, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 17280, 135, 17280, 135, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 8640, 8640, 17280, 135, 17280, 17280, 8640, 135, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 135, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 17280, 135, 8640, 135, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 135, 135, 135, 135]
Prompts retrieved: 2231955 . Total input tokens: 497616808 . Total output tokens: 446425470
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 101.2668755943887,
    "estimated_duration": 3600.0045632692013,
    "input_throughput": 7441.570289475413,
    "output_throughput": 6550.286697021793,
    "total_throughput": 13991.856986497207,
    "itl": 122.81974972630474,
    "ttft": 1918024.4277037957,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 467,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3963534877193033,
    "arrivals": 743226,
    "finished_requests": 108432,
    "scheduler_time": 224.75277651258898
}
#Debug simulation 
Total elapsed time: 101.26701231533661. Arrivals time: 0.628074289765209 Scheduler time: 100.45365415560082 Scheduler overhead time: 0.07300991285592318 Adapter cache time: 0.0165646905079484 Engine time: 0.06985347485169768 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-32/adapters_256_slots_32_rate_1.6-0.8-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-32/adapters_256_slots_32_rate_1.6-0.8-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 135, 17280, 17280, 135, 17280, 8640, 17280, 135, 8640, 135, 17280, 8640, 8640, 8640, 8640, 17280, 135, 135, 135, 8640, 17280, 135, 17280, 17280, 8640, 8640, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 135, 8640, 8640, 17280, 8640, 135, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 135, 17280, 17280, 8640, 135, 135, 17280, 8640, 135, 8640, 8640, 17280, 8640, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 8640, 135, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 135, 17280, 17280, 135, 17280, 135, 8640, 17280, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 135, 135, 135, 17280, 8640, 135, 17280, 135, 17280, 135, 135, 8640, 8640, 17280, 8640, 17280, 135, 8640, 135, 17280, 17280, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 17280, 135, 17280, 8640, 135, 8640, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 8640, 17280, 17280, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 17280, 135, 17280, 135, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 8640, 8640, 17280, 135, 17280, 17280, 8640, 135, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 135, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 17280, 135, 8640, 135, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 135, 135, 135, 135]
Prompts retrieved: 2231955 . Total input tokens: 497616808 . Total output tokens: 446425470
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 103.14310909574851,
    "estimated_duration": 3600.0580268677677,
    "input_throughput": 7431.912708162228,
    "output_throughput": 6542.684819025878,
    "total_throughput": 13974.597527188107,
    "itl": 122.58821132175854,
    "ttft": 1916516.904036259,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 451,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5110643837973479,
    "arrivals": 743226,
    "finished_requests": 108197,
    "scheduler_time": 225.33547235033117
}
#Debug simulation 
Total elapsed time: 103.14331280672923. Arrivals time: 0.6240126797929406 Scheduler time: 102.33083012327552 Scheduler overhead time: 0.07420137571170926 Adapter cache time: 0.016802857629954815 Engine time: 0.07141171488910913 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-8/adapters_256_slots_32_rate_1.6-0.8-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-8/adapters_256_slots_32_rate_1.6-0.8-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 66, 17280, 17280, 66, 17280, 8640, 17280, 66, 8640, 66, 17280, 8640, 8640, 8640, 8640, 17280, 66, 66, 66, 8640, 17280, 66, 17280, 17280, 8640, 8640, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 66, 8640, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 66, 17280, 17280, 8640, 66, 66, 17280, 8640, 66, 8640, 8640, 17280, 8640, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 8640, 66, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 66, 17280, 17280, 66, 17280, 66, 8640, 17280, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 66, 66, 66, 17280, 8640, 66, 17280, 66, 17280, 66, 66, 8640, 8640, 17280, 8640, 17280, 66, 8640, 66, 17280, 17280, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 8640, 17280, 17280, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 17280, 66, 17280, 66, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 8640, 8640, 17280, 66, 17280, 17280, 8640, 66, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 66, 8640, 66, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 66, 66, 66, 66]
Prompts retrieved: 2226090 . Total input tokens: 496312659 . Total output tokens: 445233650
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 101.10836021089926,
    "estimated_duration": 3600.018885622855,
    "input_throughput": 7368.794954365999,
    "output_throughput": 6506.550588816525,
    "total_throughput": 13875.345543182524,
    "itl": 121.70273901984505,
    "ttft": 1927285.7726537012,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 429,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.312949242147161,
    "arrivals": 741292,
    "finished_requests": 106969,
    "scheduler_time": 226.87370082891334
}
#Debug simulation 
Total elapsed time: 101.10850893566385. Arrivals time: 0.612105983775109 Scheduler time: 100.30997092323378 Scheduler overhead time: 0.07379212602972984 Adapter cache time: 0.016218802891671658 Engine time: 0.0703882803209126 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-16/adapters_256_slots_32_rate_1.6-0.8-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-16/adapters_256_slots_32_rate_1.6-0.8-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 66, 17280, 17280, 66, 17280, 8640, 17280, 66, 8640, 66, 17280, 8640, 8640, 8640, 8640, 17280, 66, 66, 66, 8640, 17280, 66, 17280, 17280, 8640, 8640, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 66, 8640, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 66, 17280, 17280, 8640, 66, 66, 17280, 8640, 66, 8640, 8640, 17280, 8640, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 8640, 66, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 66, 17280, 17280, 66, 17280, 66, 8640, 17280, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 66, 66, 66, 17280, 8640, 66, 17280, 66, 17280, 66, 66, 8640, 8640, 17280, 8640, 17280, 66, 8640, 66, 17280, 17280, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 8640, 17280, 17280, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 17280, 66, 17280, 66, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 8640, 8640, 17280, 66, 17280, 17280, 8640, 66, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 66, 8640, 66, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 66, 66, 66, 66]
Prompts retrieved: 2226090 . Total input tokens: 496312659 . Total output tokens: 445233650
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 101.32878518104553,
    "estimated_duration": 3600.09438138039,
    "input_throughput": 7362.048099927175,
    "output_throughput": 6505.193619679575,
    "total_throughput": 13867.24171960675,
    "itl": 122.00029468410074,
    "ttft": 1920591.819179558,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 465,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5186723171197871,
    "arrivals": 741292,
    "finished_requests": 106919,
    "scheduler_time": 226.9078180175647
}
#Debug simulation 
Total elapsed time: 101.3289355658926. Arrivals time: 0.6065356004983187 Scheduler time: 100.5363887436688 Scheduler overhead time: 0.07315419381484389 Adapter cache time: 0.01636643661186099 Engine time: 0.0702557465992868 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-32/adapters_256_slots_32_rate_1.6-0.8-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-32/adapters_256_slots_32_rate_1.6-0.8-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 66, 17280, 17280, 66, 17280, 8640, 17280, 66, 8640, 66, 17280, 8640, 8640, 8640, 8640, 17280, 66, 66, 66, 8640, 17280, 66, 17280, 17280, 8640, 8640, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 66, 8640, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 66, 17280, 17280, 8640, 66, 66, 17280, 8640, 66, 8640, 8640, 17280, 8640, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 8640, 66, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 66, 17280, 17280, 66, 17280, 66, 8640, 17280, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 66, 66, 66, 17280, 8640, 66, 17280, 66, 17280, 66, 66, 8640, 8640, 17280, 8640, 17280, 66, 8640, 66, 17280, 17280, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 8640, 17280, 17280, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 17280, 66, 17280, 66, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 8640, 8640, 17280, 66, 17280, 17280, 8640, 66, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 66, 8640, 66, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 66, 66, 66, 66]
Prompts retrieved: 2226090 . Total input tokens: 496312659 . Total output tokens: 445233650
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 100.19280744483694,
    "estimated_duration": 3600.096999064226,
    "input_throughput": 7362.0427468729895,
    "output_throughput": 6505.188889656969,
    "total_throughput": 13867.231636529958,
    "itl": 122.00032852332104,
    "ttft": 1920593.063344099,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 465,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5211319779604764,
    "arrivals": 741292,
    "finished_requests": 106919,
    "scheduler_time": 226.90786293550602
}
#Debug simulation 
Total elapsed time: 100.19295225292444. Arrivals time: 0.6057863235473633 Scheduler time: 99.4022638653405 Scheduler overhead time: 0.07336485106498003 Adapter cache time: 0.016407957766205072 Engine time: 0.06934320973232388 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-16/adapters_256_slots_32_rate_1.6-0.8-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-16/adapters_256_slots_32_rate_1.6-0.8-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 66, 17280, 17280, 66, 17280, 8640, 17280, 66, 8640, 66, 17280, 8640, 8640, 8640, 8640, 17280, 66, 66, 66, 8640, 17280, 66, 17280, 17280, 8640, 8640, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 66, 8640, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 66, 17280, 17280, 8640, 66, 66, 17280, 8640, 66, 8640, 8640, 17280, 8640, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 8640, 66, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 66, 17280, 17280, 66, 17280, 66, 8640, 17280, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 66, 66, 66, 17280, 8640, 66, 17280, 66, 17280, 66, 66, 8640, 8640, 17280, 8640, 17280, 66, 8640, 66, 17280, 17280, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 8640, 17280, 17280, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 17280, 66, 17280, 66, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 8640, 8640, 17280, 66, 17280, 17280, 8640, 66, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 66, 8640, 66, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 66, 66, 66, 66]
Prompts retrieved: 2226090 . Total input tokens: 496312659 . Total output tokens: 445233650
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 106.36799689987674,
    "estimated_duration": 3600.0180123248133,
    "input_throughput": 7348.685453636294,
    "output_throughput": 6488.845033559886,
    "total_throughput": 13837.530487196182,
    "itl": 121.365822326153,
    "ttft": 1924022.8393026723,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 421,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3151973280985825,
    "arrivals": 741292,
    "finished_requests": 106636,
    "scheduler_time": 227.69864050230586
}
#Debug simulation 
Total elapsed time: 106.36813926277682. Arrivals time: 0.619032989256084 Scheduler time: 105.56188424024731 Scheduler overhead time: 0.07408595411106944 Adapter cache time: 0.01658374397084117 Engine time: 0.07047078479081392 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-32/adapters_256_slots_32_rate_1.6-0.8-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-32/adapters_256_slots_32_rate_1.6-0.8-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 66, 17280, 17280, 66, 17280, 8640, 17280, 66, 8640, 66, 17280, 8640, 8640, 8640, 8640, 17280, 66, 66, 66, 8640, 17280, 66, 17280, 17280, 8640, 8640, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 66, 8640, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 66, 17280, 17280, 8640, 66, 66, 17280, 8640, 66, 8640, 8640, 17280, 8640, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 8640, 66, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 66, 17280, 17280, 66, 17280, 66, 8640, 17280, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 66, 66, 66, 17280, 8640, 66, 17280, 66, 17280, 66, 66, 8640, 8640, 17280, 8640, 17280, 66, 8640, 66, 17280, 17280, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 8640, 17280, 17280, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 17280, 66, 17280, 66, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 8640, 8640, 17280, 66, 17280, 17280, 8640, 66, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 66, 8640, 66, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 66, 66, 66, 66]
Prompts retrieved: 2226090 . Total input tokens: 496312659 . Total output tokens: 445233650
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 100.20150400092825,
    "estimated_duration": 3600.1184645765884,
    "input_throughput": 7361.998851089795,
    "output_throughput": 6505.1501028187295,
    "total_throughput": 13867.148953908525,
    "itl": 122.00078493745607,
    "ttft": 1920602.4608661649,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 465,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5415040913596796,
    "arrivals": 741292,
    "finished_requests": 106919,
    "scheduler_time": 226.90816459926813
}
#Debug simulation 
Total elapsed time: 100.20165196526796. Arrivals time: 0.6027995976619422 Scheduler time: 99.41447636112571 Scheduler overhead time: 0.07244555093348026 Adapter cache time: 0.016406098380684853 Engine time: 0.06949172867462039 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-16/adapters_256_slots_32_rate_1.6-0.8-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-16/adapters_256_slots_32_rate_1.6-0.8-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 66, 17280, 17280, 66, 17280, 8640, 17280, 66, 8640, 66, 17280, 8640, 8640, 8640, 8640, 17280, 66, 66, 66, 8640, 17280, 66, 17280, 17280, 8640, 8640, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 66, 8640, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 66, 17280, 17280, 8640, 66, 66, 17280, 8640, 66, 8640, 8640, 17280, 8640, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 8640, 66, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 66, 17280, 17280, 66, 17280, 66, 8640, 17280, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 66, 66, 66, 17280, 8640, 66, 17280, 66, 17280, 66, 66, 8640, 8640, 17280, 8640, 17280, 66, 8640, 66, 17280, 17280, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 8640, 17280, 17280, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 17280, 66, 17280, 66, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 8640, 8640, 17280, 66, 17280, 17280, 8640, 66, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 66, 8640, 66, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 66, 66, 66, 66]
Prompts retrieved: 2226090 . Total input tokens: 496312659 . Total output tokens: 445233650
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 101.30276910029352,
    "estimated_duration": 3600.013881229342,
    "input_throughput": 7427.024417714091,
    "output_throughput": 6563.334414680484,
    "total_throughput": 13990.358832394575,
    "itl": 123.897522881918,
    "ttft": 1922017.2804577218,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 460,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3754231356549889,
    "arrivals": 741292,
    "finished_requests": 107885,
    "scheduler_time": 223.74686804936235
}
#Debug simulation 
Total elapsed time: 101.30291213700548. Arrivals time: 0.6202025013044477 Scheduler time: 100.49611464655027 Scheduler overhead time: 0.07381552224978805 Adapter cache time: 0.016702712513506413 Engine time: 0.07000782899558544 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-32/adapters_256_slots_32_rate_1.6-0.8-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-32/adapters_256_slots_32_rate_1.6-0.8-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 66, 17280, 17280, 66, 17280, 8640, 17280, 66, 8640, 66, 17280, 8640, 8640, 8640, 8640, 17280, 66, 66, 66, 8640, 17280, 66, 17280, 17280, 8640, 8640, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 66, 8640, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 66, 17280, 17280, 8640, 66, 66, 17280, 8640, 66, 8640, 8640, 17280, 8640, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 8640, 66, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 66, 17280, 17280, 66, 17280, 66, 8640, 17280, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 66, 66, 66, 17280, 8640, 66, 17280, 66, 17280, 66, 66, 8640, 8640, 17280, 8640, 17280, 66, 8640, 66, 17280, 17280, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 8640, 17280, 17280, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 17280, 66, 17280, 66, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 8640, 8640, 17280, 66, 17280, 17280, 8640, 66, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 66, 8640, 66, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 66, 66, 66, 66]
Prompts retrieved: 2226090 . Total input tokens: 496312659 . Total output tokens: 445233650
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 99.96173253003508,
    "estimated_duration": 3600.13727791951,
    "input_throughput": 7361.960379276561,
    "output_throughput": 6505.11610866512,
    "total_throughput": 13867.07648794168,
    "itl": 122.00124646928936,
    "ttft": 1920609.7872960533,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 465,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5606186668947333,
    "arrivals": 741292,
    "finished_requests": 106919,
    "scheduler_time": 226.90831578679968
}
#Debug simulation 
Total elapsed time: 99.96187849389389. Arrivals time: 0.5925169815309346 Scheduler time: 99.18421981157735 Scheduler overhead time: 0.07339579099789262 Adapter cache time: 0.01631828583776951 Engine time: 0.06970671424642205 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-8/adapters_256_slots_32_rate_1.6-0.8-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-8/adapters_256_slots_32_rate_1.6-0.8-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 33, 17280, 17280, 33, 17280, 8640, 17280, 33, 8640, 33, 17280, 8640, 8640, 8640, 8640, 17280, 33, 33, 33, 8640, 17280, 33, 17280, 17280, 8640, 8640, 8640, 33, 17280, 33, 8640, 8640, 33, 8640, 33, 33, 8640, 8640, 17280, 8640, 33, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 33, 17280, 17280, 8640, 33, 33, 17280, 8640, 33, 8640, 8640, 17280, 8640, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 8640, 33, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 33, 17280, 17280, 33, 17280, 33, 8640, 17280, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 33, 33, 33, 17280, 8640, 33, 17280, 33, 17280, 33, 33, 8640, 8640, 17280, 8640, 17280, 33, 8640, 33, 17280, 17280, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 33, 8640, 17280, 17280, 33, 17280, 8640, 33, 8640, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 8640, 17280, 17280, 8640, 33, 17280, 33, 8640, 8640, 33, 8640, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 17280, 33, 17280, 33, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 8640, 8640, 33, 8640, 17280, 8640, 8640, 17280, 33, 17280, 17280, 8640, 33, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 33, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 17280, 33, 8640, 33, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 33, 33, 33, 33]
Prompts retrieved: 2223285 . Total input tokens: 495676136 . Total output tokens: 444666343
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 99.95244286302477,
    "estimated_duration": 3600.1267110119143,
    "input_throughput": 7447.88340865463,
    "output_throughput": 6554.105145195795,
    "total_throughput": 14001.988553850424,
    "itl": 123.59719867179393,
    "ttft": 1916514.204294575,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 428,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.309888754403228,
    "arrivals": 740358,
    "finished_requests": 108322,
    "scheduler_time": 224.2259856503074
}
#Debug simulation 
Total elapsed time: 99.95259081572294. Arrivals time: 0.5992603707127273 Scheduler time: 99.16926055867225 Scheduler overhead time: 0.07291685789823532 Adapter cache time: 0.015902382787317038 Engine time: 0.06977621698752046 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-16/adapters_256_slots_32_rate_1.6-0.8-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-16/adapters_256_slots_32_rate_1.6-0.8-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 33, 17280, 17280, 33, 17280, 8640, 17280, 33, 8640, 33, 17280, 8640, 8640, 8640, 8640, 17280, 33, 33, 33, 8640, 17280, 33, 17280, 17280, 8640, 8640, 8640, 33, 17280, 33, 8640, 8640, 33, 8640, 33, 33, 8640, 8640, 17280, 8640, 33, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 33, 17280, 17280, 8640, 33, 33, 17280, 8640, 33, 8640, 8640, 17280, 8640, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 8640, 33, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 33, 17280, 17280, 33, 17280, 33, 8640, 17280, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 33, 33, 33, 17280, 8640, 33, 17280, 33, 17280, 33, 33, 8640, 8640, 17280, 8640, 17280, 33, 8640, 33, 17280, 17280, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 33, 8640, 17280, 17280, 33, 17280, 8640, 33, 8640, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 8640, 17280, 17280, 8640, 33, 17280, 33, 8640, 8640, 33, 8640, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 17280, 33, 17280, 33, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 8640, 8640, 33, 8640, 17280, 8640, 8640, 17280, 33, 17280, 17280, 8640, 33, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 33, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 17280, 33, 8640, 33, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 33, 33, 33, 33]
Prompts retrieved: 2223285 . Total input tokens: 495676136 . Total output tokens: 444666343
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 100.48846038104966,
    "estimated_duration": 3600.0745673361344,
    "input_throughput": 7447.806288034738,
    "output_throughput": 6553.9636912184515,
    "total_throughput": 14001.76997925319,
    "itl": 123.59867201981375,
    "ttft": 1916552.2609872618,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 428,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3970083826105169,
    "arrivals": 740358,
    "finished_requests": 108319,
    "scheduler_time": 224.21919778828368
}
#Debug simulation 
Total elapsed time: 100.48861149698496. Arrivals time: 0.5993563043884933 Scheduler time: 99.70429423451424 Scheduler overhead time: 0.07430094014853239 Adapter cache time: 0.015725061297416687 Engine time: 0.06875408021733165 
