INFO 06-01 00:47:08 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:47:09 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-32/adapters_192_slots_96_rate_0.4-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-32/adapters_192_slots_96_rate_0.4-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [64 64 64]
Adapter prompts. [4320, 270, 4320, 270, 4320, 270, 4320, 270, 270, 270, 540, 540, 540, 540, 4320, 540, 270, 4320, 270, 540, 540, 270, 4320, 4320, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 4320, 540, 270, 540, 4320, 4320, 540, 4320, 270, 540, 540, 4320, 540, 270, 270, 540, 4320, 270, 540, 270, 4320, 4320, 540, 4320, 4320, 4320, 270, 540, 4320, 270, 540, 270, 540, 270, 270, 540, 4320, 4320, 270, 270, 270, 4320, 4320, 4320, 540, 270, 270, 270, 270, 270, 4320, 270, 540, 270, 4320, 4320, 270, 4320, 270, 540, 540, 4320, 270, 270, 270, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 270, 4320, 540, 540, 540, 4320, 540, 270, 540, 4320, 4320, 540, 4320, 540, 270, 4320, 540, 270, 540, 540, 270, 540, 4320, 270, 540, 4320, 270, 540, 4320, 4320, 540, 270, 4320, 540, 270, 270, 540, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 540, 270, 4320, 4320, 540, 4320, 270, 4320, 4320, 4320, 270, 4320, 4320, 4320, 540, 540, 540, 540, 540, 540, 270, 4320, 540, 4320, 270, 4320, 540, 270, 540, 270, 270, 540, 540, 540, 4320, 540, 270, 270]
Prompts retrieved: 328320 . Total input tokens: 73268759 . Total output tokens: 65629823
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 9.226913527119905,
    "estimated_duration": 3600.062919396439,
    "input_throughput": 5390.362178240322,
    "output_throughput": 4720.829713401039,
    "total_throughput": 10111.19189164136,
    "itl": 177.19721979540472,
    "ttft": 1270273.8596713713,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 821,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.68725032428278,
    "arrivals": 109355,
    "finished_requests": 77899,
    "scheduler_time": 90.35775711207114
}
#Debug simulation 
Total elapsed time: 9.227074989117682. Arrivals time: 0.25061557115986943 Scheduler time: 8.873825499787927 Scheduler overhead time: 0.03368009813129902 Adapter cache time: 0.019247613847255707 Engine time: 0.034205683041363955 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-16/adapters_192_slots_96_rate_0.4-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-16/adapters_192_slots_96_rate_0.4-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [64 64 64]
Adapter prompts. [4320, 270, 4320, 270, 4320, 270, 4320, 270, 270, 270, 540, 540, 540, 540, 4320, 540, 270, 4320, 270, 540, 540, 270, 4320, 4320, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 4320, 540, 270, 540, 4320, 4320, 540, 4320, 270, 540, 540, 4320, 540, 270, 270, 540, 4320, 270, 540, 270, 4320, 4320, 540, 4320, 4320, 4320, 270, 540, 4320, 270, 540, 270, 540, 270, 270, 540, 4320, 4320, 270, 270, 270, 4320, 4320, 4320, 540, 270, 270, 270, 270, 270, 4320, 270, 540, 270, 4320, 4320, 270, 4320, 270, 540, 540, 4320, 270, 270, 270, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 270, 4320, 540, 540, 540, 4320, 540, 270, 540, 4320, 4320, 540, 4320, 540, 270, 4320, 540, 270, 540, 540, 270, 540, 4320, 270, 540, 4320, 270, 540, 4320, 4320, 540, 270, 4320, 540, 270, 270, 540, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 540, 270, 4320, 4320, 540, 4320, 270, 4320, 4320, 4320, 270, 4320, 4320, 4320, 540, 540, 540, 540, 540, 540, 270, 4320, 540, 4320, 270, 4320, 540, 270, 540, 270, 270, 540, 540, 540, 4320, 540, 270, 270]
Prompts retrieved: 328320 . Total input tokens: 73268759 . Total output tokens: 65629823
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 9.378785500768572,
    "estimated_duration": 3600.1590376232107,
    "input_throughput": 5402.445502196612,
    "output_throughput": 4733.2786751693075,
    "total_throughput": 10135.72417736592,
    "itl": 179.21549630423718,
    "ttft": 1266821.795096469,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 806,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.519075487714704,
    "arrivals": 109355,
    "finished_requests": 78092,
    "scheduler_time": 90.15962406515673
}
#Debug simulation 
Total elapsed time: 9.378909497987479. Arrivals time: 0.2535538743250072 Scheduler time: 9.024915242101997 Scheduler overhead time: 0.03357816254720092 Adapter cache time: 0.017469242215156555 Engine time: 0.034003862645477057 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-32/adapters_192_slots_96_rate_0.4-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-32/adapters_192_slots_96_rate_0.4-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [64 64 64]
Adapter prompts. [4320, 270, 4320, 270, 4320, 270, 4320, 270, 270, 270, 540, 540, 540, 540, 4320, 540, 270, 4320, 270, 540, 540, 270, 4320, 4320, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 4320, 540, 270, 540, 4320, 4320, 540, 4320, 270, 540, 540, 4320, 540, 270, 270, 540, 4320, 270, 540, 270, 4320, 4320, 540, 4320, 4320, 4320, 270, 540, 4320, 270, 540, 270, 540, 270, 270, 540, 4320, 4320, 270, 270, 270, 4320, 4320, 4320, 540, 270, 270, 270, 270, 270, 4320, 270, 540, 270, 4320, 4320, 270, 4320, 270, 540, 540, 4320, 270, 270, 270, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 270, 4320, 540, 540, 540, 4320, 540, 270, 540, 4320, 4320, 540, 4320, 540, 270, 4320, 540, 270, 540, 540, 270, 540, 4320, 270, 540, 4320, 270, 540, 4320, 4320, 540, 270, 4320, 540, 270, 270, 540, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 540, 270, 4320, 4320, 540, 4320, 270, 4320, 4320, 4320, 270, 4320, 4320, 4320, 540, 540, 540, 540, 540, 540, 270, 4320, 540, 4320, 270, 4320, 540, 270, 540, 270, 270, 540, 540, 540, 4320, 540, 270, 270]
Prompts retrieved: 328320 . Total input tokens: 73268759 . Total output tokens: 65629823
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 9.233170935884118,
    "estimated_duration": 3600.051752313382,
    "input_throughput": 5389.47335619053,
    "output_throughput": 4720.471306858227,
    "total_throughput": 10109.944663048756,
    "itl": 177.24078918581426,
    "ttft": 1270367.595059129,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 818,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7126963468082272,
    "arrivals": 109355,
    "finished_requests": 77892,
    "scheduler_time": 90.35282416865361
}
#Debug simulation 
Total elapsed time: 9.2333066589199. Arrivals time: 0.2507953937165439 Scheduler time: 8.88080973783508 Scheduler overhead time: 0.03380234446376562 Adapter cache time: 0.017800690606236458 Engine time: 0.03456047410145402 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-16/adapters_192_slots_96_rate_0.4-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-16/adapters_192_slots_96_rate_0.4-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [64 64 64]
Adapter prompts. [4320, 270, 4320, 270, 4320, 270, 4320, 270, 270, 270, 540, 540, 540, 540, 4320, 540, 270, 4320, 270, 540, 540, 270, 4320, 4320, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 4320, 540, 270, 540, 4320, 4320, 540, 4320, 270, 540, 540, 4320, 540, 270, 270, 540, 4320, 270, 540, 270, 4320, 4320, 540, 4320, 4320, 4320, 270, 540, 4320, 270, 540, 270, 540, 270, 270, 540, 4320, 4320, 270, 270, 270, 4320, 4320, 4320, 540, 270, 270, 270, 270, 270, 4320, 270, 540, 270, 4320, 4320, 270, 4320, 270, 540, 540, 4320, 270, 270, 270, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 270, 4320, 540, 540, 540, 4320, 540, 270, 540, 4320, 4320, 540, 4320, 540, 270, 4320, 540, 270, 540, 540, 270, 540, 4320, 270, 540, 4320, 270, 540, 4320, 4320, 540, 270, 4320, 540, 270, 270, 540, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 540, 270, 4320, 4320, 540, 4320, 270, 4320, 4320, 4320, 270, 4320, 4320, 4320, 540, 540, 540, 540, 540, 540, 270, 4320, 540, 4320, 270, 4320, 540, 270, 540, 270, 270, 540, 540, 540, 4320, 540, 270, 270]
Prompts retrieved: 328320 . Total input tokens: 73268759 . Total output tokens: 65629823
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 9.455227904953063,
    "estimated_duration": 3600.0801869450665,
    "input_throughput": 5403.790190714674,
    "output_throughput": 4732.85346859414,
    "total_throughput": 10136.643659308815,
    "itl": 179.17231542200997,
    "ttft": 1266882.2992730367,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 798,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3860601353318884,
    "arrivals": 109355,
    "finished_requests": 78099,
    "scheduler_time": 90.15942687765069
}
#Debug simulation 
Total elapsed time: 9.455339688807726. Arrivals time: 0.2492126259021461 Scheduler time: 9.105985464528203 Scheduler overhead time: 0.03334225155413151 Adapter cache time: 0.017752917483448982 Engine time: 0.03375971596688032 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-32/adapters_192_slots_96_rate_0.4-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-32/adapters_192_slots_96_rate_0.4-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [64 64 64]
Adapter prompts. [4320, 270, 4320, 270, 4320, 270, 4320, 270, 270, 270, 540, 540, 540, 540, 4320, 540, 270, 4320, 270, 540, 540, 270, 4320, 4320, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 4320, 540, 270, 540, 4320, 4320, 540, 4320, 270, 540, 540, 4320, 540, 270, 270, 540, 4320, 270, 540, 270, 4320, 4320, 540, 4320, 4320, 4320, 270, 540, 4320, 270, 540, 270, 540, 270, 270, 540, 4320, 4320, 270, 270, 270, 4320, 4320, 4320, 540, 270, 270, 270, 270, 270, 4320, 270, 540, 270, 4320, 4320, 270, 4320, 270, 540, 540, 4320, 270, 270, 270, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 270, 4320, 540, 540, 540, 4320, 540, 270, 540, 4320, 4320, 540, 4320, 540, 270, 4320, 540, 270, 540, 540, 270, 540, 4320, 270, 540, 4320, 270, 540, 4320, 4320, 540, 270, 4320, 540, 270, 270, 540, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 540, 270, 4320, 4320, 540, 4320, 270, 4320, 4320, 4320, 270, 4320, 4320, 4320, 540, 540, 540, 540, 540, 540, 270, 4320, 540, 4320, 270, 4320, 540, 270, 540, 270, 270, 540, 540, 540, 4320, 540, 270, 270]
Prompts retrieved: 328320 . Total input tokens: 73268759 . Total output tokens: 65629823
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 9.17111229011789,
    "estimated_duration": 3600.0534139057613,
    "input_throughput": 5390.422521244288,
    "output_throughput": 4721.696887702057,
    "total_throughput": 10112.119408946346,
    "itl": 177.1856255870887,
    "ttft": 1270068.9207454738,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 822,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.759664207175395,
    "arrivals": 109355,
    "finished_requests": 77902,
    "scheduler_time": 90.35557937709844
}
#Debug simulation 
Total elapsed time: 9.171222914010286. Arrivals time: 0.2548877405934036 Scheduler time: 8.815072300843894 Scheduler overhead time: 0.033723125234246254 Adapter cache time: 0.01777393138036132 Engine time: 0.034383142832666636 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-8/adapters_192_slots_96_rate_0.4-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-8/adapters_192_slots_96_rate_0.4-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [64 64 64]
Adapter prompts. [4320, 135, 4320, 135, 4320, 135, 4320, 135, 135, 135, 540, 540, 540, 540, 4320, 540, 135, 4320, 135, 540, 540, 135, 4320, 4320, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 4320, 540, 135, 540, 4320, 4320, 540, 4320, 135, 540, 540, 4320, 540, 135, 135, 540, 4320, 135, 540, 135, 4320, 4320, 540, 4320, 4320, 4320, 135, 540, 4320, 135, 540, 135, 540, 135, 135, 540, 4320, 4320, 135, 135, 135, 4320, 4320, 4320, 540, 135, 135, 135, 135, 135, 4320, 135, 540, 135, 4320, 4320, 135, 4320, 135, 540, 540, 4320, 135, 135, 135, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 135, 4320, 540, 540, 540, 4320, 540, 135, 540, 4320, 4320, 540, 4320, 540, 135, 4320, 540, 135, 540, 540, 135, 540, 4320, 135, 540, 4320, 135, 540, 4320, 4320, 540, 135, 4320, 540, 135, 135, 540, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 540, 135, 4320, 4320, 540, 4320, 135, 4320, 4320, 4320, 135, 4320, 4320, 4320, 540, 540, 540, 540, 540, 540, 135, 4320, 540, 4320, 135, 4320, 540, 135, 540, 135, 135, 540, 540, 540, 4320, 540, 135, 135]
Prompts retrieved: 319680 . Total input tokens: 71334936 . Total output tokens: 63900430
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 8.203697321936488,
    "estimated_duration": 3600.2014136193043,
    "input_throughput": 5378.7696229285675,
    "output_throughput": 4736.3008456957095,
    "total_throughput": 10115.070468624277,
    "itl": 179.6233312183718,
    "ttft": 1244745.3521252652,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 879,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.690168726916948,
    "arrivals": 106484,
    "finished_requests": 77885,
    "scheduler_time": 88.4897650776902
}
#Debug simulation 
Total elapsed time: 8.20383148593828. Arrivals time: 0.23189160833135247 Scheduler time: 7.871586381457746 Scheduler overhead time: 0.033048040233552456 Adapter cache time: 0.01867093937471509 Engine time: 0.033387907315045595 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-16/adapters_192_slots_96_rate_0.4-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-16/adapters_192_slots_96_rate_0.4-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [64 64 64]
Adapter prompts. [4320, 135, 4320, 135, 4320, 135, 4320, 135, 135, 135, 540, 540, 540, 540, 4320, 540, 135, 4320, 135, 540, 540, 135, 4320, 4320, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 4320, 540, 135, 540, 4320, 4320, 540, 4320, 135, 540, 540, 4320, 540, 135, 135, 540, 4320, 135, 540, 135, 4320, 4320, 540, 4320, 4320, 4320, 135, 540, 4320, 135, 540, 135, 540, 135, 135, 540, 4320, 4320, 135, 135, 135, 4320, 4320, 4320, 540, 135, 135, 135, 135, 135, 4320, 135, 540, 135, 4320, 4320, 135, 4320, 135, 540, 540, 4320, 135, 135, 135, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 135, 4320, 540, 540, 540, 4320, 540, 135, 540, 4320, 4320, 540, 4320, 540, 135, 4320, 540, 135, 540, 540, 135, 540, 4320, 135, 540, 4320, 135, 540, 4320, 4320, 540, 135, 4320, 540, 135, 135, 540, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 540, 135, 4320, 4320, 540, 4320, 135, 4320, 4320, 4320, 135, 4320, 4320, 4320, 540, 540, 540, 540, 540, 540, 135, 4320, 540, 4320, 135, 4320, 540, 135, 540, 135, 135, 540, 540, 540, 4320, 540, 135, 135]
Prompts retrieved: 319680 . Total input tokens: 71334936 . Total output tokens: 63900430
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 8.295842899940908,
    "estimated_duration": 3600.0893748281146,
    "input_throughput": 5378.448139478336,
    "output_throughput": 4736.5676861325555,
    "total_throughput": 10115.015825610892,
    "itl": 179.63056163916588,
    "ttft": 1244663.2466284551,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 857,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8006841733818946,
    "arrivals": 106484,
    "finished_requests": 77888,
    "scheduler_time": 88.48574811364261
}
#Debug simulation 
Total elapsed time: 8.295950140804052. Arrivals time: 0.24349469831213355 Scheduler time: 7.951554767321795 Scheduler overhead time: 0.03321543848142028 Adapter cache time: 0.018550823908299208 Engine time: 0.033837972208857536 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-32/adapters_192_slots_96_rate_0.4-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-32/adapters_192_slots_96_rate_0.4-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [64 64 64]
Adapter prompts. [4320, 135, 4320, 135, 4320, 135, 4320, 135, 135, 135, 540, 540, 540, 540, 4320, 540, 135, 4320, 135, 540, 540, 135, 4320, 4320, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 4320, 540, 135, 540, 4320, 4320, 540, 4320, 135, 540, 540, 4320, 540, 135, 135, 540, 4320, 135, 540, 135, 4320, 4320, 540, 4320, 4320, 4320, 135, 540, 4320, 135, 540, 135, 540, 135, 135, 540, 4320, 4320, 135, 135, 135, 4320, 4320, 4320, 540, 135, 135, 135, 135, 135, 4320, 135, 540, 135, 4320, 4320, 135, 4320, 135, 540, 540, 4320, 135, 135, 135, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 135, 4320, 540, 540, 540, 4320, 540, 135, 540, 4320, 4320, 540, 4320, 540, 135, 4320, 540, 135, 540, 540, 135, 540, 4320, 135, 540, 4320, 135, 540, 4320, 4320, 540, 135, 4320, 540, 135, 135, 540, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 540, 135, 4320, 4320, 540, 4320, 135, 4320, 4320, 4320, 135, 4320, 4320, 4320, 540, 540, 540, 540, 540, 540, 135, 4320, 540, 4320, 135, 4320, 540, 135, 540, 135, 135, 540, 540, 540, 4320, 540, 135, 135]
Prompts retrieved: 319680 . Total input tokens: 71334936 . Total output tokens: 63900430
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 8.059296456165612,
    "estimated_duration": 3600.063771991071,
    "input_throughput": 5360.3805994045215,
    "output_throughput": 4723.434938097029,
    "total_throughput": 10083.81553750155,
    "itl": 177.47688493220255,
    "ttft": 1249598.5602388582,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 887,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.902961458060868,
    "arrivals": 106484,
    "finished_requests": 77634,
    "scheduler_time": 88.6921538919806
}
#Debug simulation 
Total elapsed time: 8.059455533977598. Arrivals time: 0.2439411971718073 Scheduler time: 7.7143484484404325 Scheduler overhead time: 0.03338626166805625 Adapter cache time: 0.018880176357924938 Engine time: 0.03358038421720266 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-16/adapters_192_slots_96_rate_0.4-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-16/adapters_192_slots_96_rate_0.4-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [64 64 64]
Adapter prompts. [4320, 135, 4320, 135, 4320, 135, 4320, 135, 135, 135, 540, 540, 540, 540, 4320, 540, 135, 4320, 135, 540, 540, 135, 4320, 4320, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 4320, 540, 135, 540, 4320, 4320, 540, 4320, 135, 540, 540, 4320, 540, 135, 135, 540, 4320, 135, 540, 135, 4320, 4320, 540, 4320, 4320, 4320, 135, 540, 4320, 135, 540, 135, 540, 135, 135, 540, 4320, 4320, 135, 135, 135, 4320, 4320, 4320, 540, 135, 135, 135, 135, 135, 4320, 135, 540, 135, 4320, 4320, 135, 4320, 135, 540, 540, 4320, 135, 135, 135, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 135, 4320, 540, 540, 540, 4320, 540, 135, 540, 4320, 4320, 540, 4320, 540, 135, 4320, 540, 135, 540, 540, 135, 540, 4320, 135, 540, 4320, 135, 540, 4320, 4320, 540, 135, 4320, 540, 135, 135, 540, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 540, 135, 4320, 4320, 540, 4320, 135, 4320, 4320, 4320, 135, 4320, 4320, 4320, 540, 540, 540, 540, 540, 540, 135, 4320, 540, 4320, 135, 4320, 540, 135, 540, 135, 135, 540, 540, 540, 4320, 540, 135, 135]
Prompts retrieved: 319680 . Total input tokens: 71334936 . Total output tokens: 63900430
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 8.290107594337314,
    "estimated_duration": 3600.028974169351,
    "input_throughput": 5378.235047251926,
    "output_throughput": 4737.321316680528,
    "total_throughput": 10115.556363932454,
    "itl": 179.64185493043945,
    "ttft": 1244136.5874907696,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 856,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.674298336917975,
    "arrivals": 106484,
    "finished_requests": 77895,
    "scheduler_time": 88.4810042078837
}
#Debug simulation 
Total elapsed time: 8.290231578052044. Arrivals time: 0.25228890450671315 Scheduler time: 7.936926381662488 Scheduler overhead time: 0.03330387640744448 Adapter cache time: 0.01836683228611946 Engine time: 0.033938659355044365 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-32/adapters_192_slots_96_rate_0.4-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-32/adapters_192_slots_96_rate_0.4-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [64 64 64]
Adapter prompts. [4320, 135, 4320, 135, 4320, 135, 4320, 135, 135, 135, 540, 540, 540, 540, 4320, 540, 135, 4320, 135, 540, 540, 135, 4320, 4320, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 4320, 540, 135, 540, 4320, 4320, 540, 4320, 135, 540, 540, 4320, 540, 135, 135, 540, 4320, 135, 540, 135, 4320, 4320, 540, 4320, 4320, 4320, 135, 540, 4320, 135, 540, 135, 540, 135, 135, 540, 4320, 4320, 135, 135, 135, 4320, 4320, 4320, 540, 135, 135, 135, 135, 135, 4320, 135, 540, 135, 4320, 4320, 135, 4320, 135, 540, 540, 4320, 135, 135, 135, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 135, 4320, 540, 540, 540, 4320, 540, 135, 540, 4320, 4320, 540, 4320, 540, 135, 4320, 540, 135, 540, 540, 135, 540, 4320, 135, 540, 4320, 135, 540, 4320, 4320, 540, 135, 4320, 540, 135, 135, 540, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 540, 135, 4320, 4320, 540, 4320, 135, 4320, 4320, 4320, 135, 4320, 4320, 4320, 540, 540, 540, 540, 540, 540, 135, 4320, 540, 4320, 135, 4320, 540, 135, 540, 135, 135, 540, 540, 540, 4320, 540, 135, 135]
Prompts retrieved: 319680 . Total input tokens: 71334936 . Total output tokens: 63900430
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 8.167674493044615,
    "estimated_duration": 3600.077664617636,
    "input_throughput": 5359.281881506075,
    "output_throughput": 4723.459209540714,
    "total_throughput": 10082.74109104679,
    "itl": 177.4987180668735,
    "ttft": 1249469.7955287357,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 874,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.898000881578776,
    "arrivals": 106484,
    "finished_requests": 77639,
    "scheduler_time": 88.68849032786007
}
#Debug simulation 
Total elapsed time: 8.167782704345882. Arrivals time: 0.24689852399751544 Scheduler time: 7.819045018404722 Scheduler overhead time: 0.03343481058254838 Adapter cache time: 0.018824061378836632 Engine time: 0.034182106610387564 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-16/adapters_192_slots_96_rate_0.4-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-16/adapters_192_slots_96_rate_0.4-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [64 64 64]
Adapter prompts. [4320, 135, 4320, 135, 4320, 135, 4320, 135, 135, 135, 540, 540, 540, 540, 4320, 540, 135, 4320, 135, 540, 540, 135, 4320, 4320, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 4320, 540, 135, 540, 4320, 4320, 540, 4320, 135, 540, 540, 4320, 540, 135, 135, 540, 4320, 135, 540, 135, 4320, 4320, 540, 4320, 4320, 4320, 135, 540, 4320, 135, 540, 135, 540, 135, 135, 540, 4320, 4320, 135, 135, 135, 4320, 4320, 4320, 540, 135, 135, 135, 135, 135, 4320, 135, 540, 135, 4320, 4320, 135, 4320, 135, 540, 540, 4320, 135, 135, 135, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 135, 4320, 540, 540, 540, 4320, 540, 135, 540, 4320, 4320, 540, 4320, 540, 135, 4320, 540, 135, 540, 540, 135, 540, 4320, 135, 540, 4320, 135, 540, 4320, 4320, 540, 135, 4320, 540, 135, 135, 540, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 540, 135, 4320, 4320, 540, 4320, 135, 4320, 4320, 4320, 135, 4320, 4320, 4320, 540, 540, 540, 540, 540, 540, 135, 4320, 540, 4320, 135, 4320, 540, 135, 540, 135, 135, 540, 540, 540, 4320, 540, 135, 135]
Prompts retrieved: 319680 . Total input tokens: 71334936 . Total output tokens: 63900430
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 8.2169965589419,
    "estimated_duration": 3600.120739771981,
    "input_throughput": 5378.338505731995,
    "output_throughput": 4737.569163049864,
    "total_throughput": 10115.90766878186,
    "itl": 179.63749168732272,
    "ttft": 1244345.9654975191,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 868,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5953636559750333,
    "arrivals": 106484,
    "finished_requests": 77887,
    "scheduler_time": 88.48724637443678
}
#Debug simulation 
Total elapsed time: 8.217119039967656. Arrivals time: 0.24076475575566292 Scheduler time: 7.875790698453784 Scheduler overhead time: 0.032952320761978626 Adapter cache time: 0.018686954863369465 Engine time: 0.03371474472805858 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-32/adapters_192_slots_96_rate_0.4-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-32/adapters_192_slots_96_rate_0.4-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [64 64 64]
Adapter prompts. [4320, 135, 4320, 135, 4320, 135, 4320, 135, 135, 135, 540, 540, 540, 540, 4320, 540, 135, 4320, 135, 540, 540, 135, 4320, 4320, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 4320, 540, 135, 540, 4320, 4320, 540, 4320, 135, 540, 540, 4320, 540, 135, 135, 540, 4320, 135, 540, 135, 4320, 4320, 540, 4320, 4320, 4320, 135, 540, 4320, 135, 540, 135, 540, 135, 135, 540, 4320, 4320, 135, 135, 135, 4320, 4320, 4320, 540, 135, 135, 135, 135, 135, 4320, 135, 540, 135, 4320, 4320, 135, 4320, 135, 540, 540, 4320, 135, 135, 135, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 135, 4320, 540, 540, 540, 4320, 540, 135, 540, 4320, 4320, 540, 4320, 540, 135, 4320, 540, 135, 540, 540, 135, 540, 4320, 135, 540, 4320, 135, 540, 4320, 4320, 540, 135, 4320, 540, 135, 135, 540, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 540, 135, 4320, 4320, 540, 4320, 135, 4320, 4320, 4320, 135, 4320, 4320, 4320, 540, 540, 540, 540, 540, 540, 135, 4320, 540, 4320, 135, 4320, 540, 135, 540, 135, 135, 540, 540, 540, 4320, 540, 135, 135]
Prompts retrieved: 319680 . Total input tokens: 71334936 . Total output tokens: 63900430
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 8.119132733903825,
    "estimated_duration": 3600.0121160905974,
    "input_throughput": 5360.436959016712,
    "output_throughput": 4723.475769427679,
    "total_throughput": 10083.912728444391,
    "itl": 177.4445008630503,
    "ttft": 1249660.786537232,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 882,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9617213919014014,
    "arrivals": 106484,
    "finished_requests": 77638,
    "scheduler_time": 88.69501446544801
}
#Debug simulation 
Total elapsed time: 8.119275884702802. Arrivals time: 0.23939048405736685 Scheduler time: 7.777452843263745 Scheduler overhead time: 0.03355204639956355 Adapter cache time: 0.01923811249434948 Engine time: 0.03402344463393092 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-8/adapters_192_slots_96_rate_0.4-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-8/adapters_192_slots_96_rate_0.4-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 540, 540, 540, 540, 4320, 540, 66, 4320, 66, 540, 540, 66, 4320, 4320, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 4320, 540, 66, 540, 4320, 4320, 540, 4320, 66, 540, 540, 4320, 540, 66, 66, 540, 4320, 66, 540, 66, 4320, 4320, 540, 4320, 4320, 4320, 66, 540, 4320, 66, 540, 66, 540, 66, 66, 540, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 540, 66, 66, 66, 66, 66, 4320, 66, 540, 66, 4320, 4320, 66, 4320, 66, 540, 540, 4320, 66, 66, 66, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 66, 4320, 540, 540, 540, 4320, 540, 66, 540, 4320, 4320, 540, 4320, 540, 66, 4320, 540, 66, 540, 540, 66, 540, 4320, 66, 540, 4320, 66, 540, 4320, 4320, 540, 66, 4320, 540, 66, 66, 540, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 540, 66, 4320, 4320, 540, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 540, 540, 540, 540, 540, 540, 66, 4320, 540, 4320, 66, 4320, 540, 66, 540, 66, 66, 540, 540, 540, 4320, 540, 66, 66]
Prompts retrieved: 315264 . Total input tokens: 70341685 . Total output tokens: 63018840
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 7.605723057873547,
    "estimated_duration": 3600.0388922058514,
    "input_throughput": 5428.2449676609185,
    "output_throughput": 4740.233789403244,
    "total_throughput": 10168.478757064162,
    "itl": 178.79475481347706,
    "ttft": 1220583.701326715,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 887,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7146526288684107,
    "arrivals": 105023,
    "finished_requests": 78428,
    "scheduler_time": 87.02622132788872
}
#Debug simulation 
Total elapsed time: 7.605826963670552. Arrivals time: 0.24445285042747855 Scheduler time: 7.260750839021057 Scheduler overhead time: 0.032950632739812136 Adapter cache time: 0.018642681185156107 Engine time: 0.033798576798290014 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-16/adapters_192_slots_96_rate_0.4-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-16/adapters_192_slots_96_rate_0.4-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 540, 540, 540, 540, 4320, 540, 66, 4320, 66, 540, 540, 66, 4320, 4320, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 4320, 540, 66, 540, 4320, 4320, 540, 4320, 66, 540, 540, 4320, 540, 66, 66, 540, 4320, 66, 540, 66, 4320, 4320, 540, 4320, 4320, 4320, 66, 540, 4320, 66, 540, 66, 540, 66, 66, 540, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 540, 66, 66, 66, 66, 66, 4320, 66, 540, 66, 4320, 4320, 66, 4320, 66, 540, 540, 4320, 66, 66, 66, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 66, 4320, 540, 540, 540, 4320, 540, 66, 540, 4320, 4320, 540, 4320, 540, 66, 4320, 540, 66, 540, 540, 66, 540, 4320, 66, 540, 4320, 66, 540, 4320, 4320, 540, 66, 4320, 540, 66, 66, 540, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 540, 66, 4320, 4320, 540, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 540, 540, 540, 540, 540, 540, 66, 4320, 540, 4320, 66, 4320, 540, 66, 540, 66, 66, 540, 540, 540, 4320, 540, 66, 66]
Prompts retrieved: 315264 . Total input tokens: 70341685 . Total output tokens: 63018840
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 7.578471468761563,
    "estimated_duration": 3600.177238861097,
    "input_throughput": 5428.0363725042625,
    "output_throughput": 4740.051632957509,
    "total_throughput": 10168.088005461772,
    "itl": 178.80523667404717,
    "ttft": 1220641.8213652337,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 887,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.893654444776481,
    "arrivals": 105023,
    "finished_requests": 78428,
    "scheduler_time": 87.02953511230756
}
#Debug simulation 
Total elapsed time: 7.578573968727142. Arrivals time: 0.24734311224892735 Scheduler time: 7.230171388015151 Scheduler overhead time: 0.03315472463145852 Adapter cache time: 0.01878473535180092 Engine time: 0.03384991968050599 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-32/adapters_192_slots_96_rate_0.4-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-32/adapters_192_slots_96_rate_0.4-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 540, 540, 540, 540, 4320, 540, 66, 4320, 66, 540, 540, 66, 4320, 4320, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 4320, 540, 66, 540, 4320, 4320, 540, 4320, 66, 540, 540, 4320, 540, 66, 66, 540, 4320, 66, 540, 66, 4320, 4320, 540, 4320, 4320, 4320, 66, 540, 4320, 66, 540, 66, 540, 66, 66, 540, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 540, 66, 66, 66, 66, 66, 4320, 66, 540, 66, 4320, 4320, 66, 4320, 66, 540, 540, 4320, 66, 66, 66, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 66, 4320, 540, 540, 540, 4320, 540, 66, 540, 4320, 4320, 540, 4320, 540, 66, 4320, 540, 66, 540, 540, 66, 540, 4320, 66, 540, 4320, 66, 540, 4320, 4320, 540, 66, 4320, 540, 66, 66, 540, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 540, 66, 4320, 4320, 540, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 540, 540, 540, 540, 540, 540, 66, 4320, 540, 4320, 66, 4320, 540, 66, 540, 66, 66, 540, 540, 540, 4320, 540, 66, 66]
Prompts retrieved: 315264 . Total input tokens: 70341685 . Total output tokens: 63018840
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 7.504225293174386,
    "estimated_duration": 3600.0751897857763,
    "input_throughput": 5416.081323890419,
    "output_throughput": 4729.2462247193,
    "total_throughput": 10145.327548609719,
    "itl": 177.10174607399398,
    "ttft": 1224369.9871967116,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 901,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9445589794590834,
    "arrivals": 105023,
    "finished_requests": 78252,
    "scheduler_time": 87.19386405873686
}
#Debug simulation 
Total elapsed time: 7.504374139942229. Arrivals time: 0.24532945919781923 Scheduler time: 7.157460233196616 Scheduler overhead time: 0.03318921523168683 Adapter cache time: 0.01894167996942997 Engine time: 0.03404362592846155 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-16/adapters_192_slots_96_rate_0.4-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-16/adapters_192_slots_96_rate_0.4-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 540, 540, 540, 540, 4320, 540, 66, 4320, 66, 540, 540, 66, 4320, 4320, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 4320, 540, 66, 540, 4320, 4320, 540, 4320, 66, 540, 540, 4320, 540, 66, 66, 540, 4320, 66, 540, 66, 4320, 4320, 540, 4320, 4320, 4320, 66, 540, 4320, 66, 540, 66, 540, 66, 66, 540, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 540, 66, 66, 66, 66, 66, 4320, 66, 540, 66, 4320, 4320, 66, 4320, 66, 540, 540, 4320, 66, 66, 66, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 66, 4320, 540, 540, 540, 4320, 540, 66, 540, 4320, 4320, 540, 4320, 540, 66, 4320, 540, 66, 540, 540, 66, 540, 4320, 66, 540, 4320, 66, 540, 4320, 4320, 540, 66, 4320, 540, 66, 66, 540, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 540, 66, 4320, 4320, 540, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 540, 540, 540, 540, 540, 540, 66, 4320, 540, 4320, 66, 4320, 540, 66, 540, 66, 66, 540, 540, 540, 4320, 540, 66, 66]
Prompts retrieved: 315264 . Total input tokens: 70341685 . Total output tokens: 63018840
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 7.607753128744662,
    "estimated_duration": 3600.103553346009,
    "input_throughput": 5427.923033446668,
    "output_throughput": 4739.6339430684275,
    "total_throughput": 10167.556976515096,
    "itl": 178.79526630059954,
    "ttft": 1220604.9453820577,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 889,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.774195782605065,
    "arrivals": 105023,
    "finished_requests": 78429,
    "scheduler_time": 87.02831140557745
}
#Debug simulation 
Total elapsed time: 7.607913054060191. Arrivals time: 0.2510707569308579 Scheduler time: 7.255684277974069 Scheduler overhead time: 0.033147369511425495 Adapter cache time: 0.019265434704720974 Engine time: 0.03349431185051799 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-32/adapters_192_slots_96_rate_0.4-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-32/adapters_192_slots_96_rate_0.4-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 540, 540, 540, 540, 4320, 540, 66, 4320, 66, 540, 540, 66, 4320, 4320, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 4320, 540, 66, 540, 4320, 4320, 540, 4320, 66, 540, 540, 4320, 540, 66, 66, 540, 4320, 66, 540, 66, 4320, 4320, 540, 4320, 4320, 4320, 66, 540, 4320, 66, 540, 66, 540, 66, 66, 540, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 540, 66, 66, 66, 66, 66, 4320, 66, 540, 66, 4320, 4320, 66, 4320, 66, 540, 540, 4320, 66, 66, 66, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 66, 4320, 540, 540, 540, 4320, 540, 66, 540, 4320, 4320, 540, 4320, 540, 66, 4320, 540, 66, 540, 540, 66, 540, 4320, 66, 540, 4320, 66, 540, 4320, 4320, 540, 66, 4320, 540, 66, 66, 540, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 540, 66, 4320, 4320, 540, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 540, 540, 540, 540, 540, 540, 66, 4320, 540, 4320, 66, 4320, 540, 66, 540, 66, 66, 540, 540, 540, 4320, 540, 66, 66]
Prompts retrieved: 315264 . Total input tokens: 70341685 . Total output tokens: 63018840
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 7.533238614909351,
    "estimated_duration": 3600.0303443820735,
    "input_throughput": 5415.694073363846,
    "output_throughput": 4729.581245494344,
    "total_throughput": 10145.27531885819,
    "itl": 177.1105079321919,
    "ttft": 1224223.4329791027,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 904,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9951539838500367,
    "arrivals": 105023,
    "finished_requests": 78252,
    "scheduler_time": 87.19194530218452
}
#Debug simulation 
Total elapsed time: 7.533345375210047. Arrivals time: 0.23743486311286688 Scheduler time: 7.194108107127249 Scheduler overhead time: 0.03339428501203656 Adapter cache time: 0.01898618694394827 Engine time: 0.034035773016512394 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-16/adapters_192_slots_96_rate_0.4-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-16/adapters_192_slots_96_rate_0.4-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 540, 540, 540, 540, 4320, 540, 66, 4320, 66, 540, 540, 66, 4320, 4320, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 4320, 540, 66, 540, 4320, 4320, 540, 4320, 66, 540, 540, 4320, 540, 66, 66, 540, 4320, 66, 540, 66, 4320, 4320, 540, 4320, 4320, 4320, 66, 540, 4320, 66, 540, 66, 540, 66, 66, 540, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 540, 66, 66, 66, 66, 66, 4320, 66, 540, 66, 4320, 4320, 66, 4320, 66, 540, 540, 4320, 66, 66, 66, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 66, 4320, 540, 540, 540, 4320, 540, 66, 540, 4320, 4320, 540, 4320, 540, 66, 4320, 540, 66, 540, 540, 66, 540, 4320, 66, 540, 4320, 66, 540, 4320, 4320, 540, 66, 4320, 540, 66, 66, 540, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 540, 66, 4320, 4320, 540, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 540, 540, 540, 540, 540, 540, 66, 4320, 540, 4320, 66, 4320, 540, 66, 540, 66, 66, 540, 540, 540, 4320, 540, 66, 66]
Prompts retrieved: 315264 . Total input tokens: 70341685 . Total output tokens: 63018840
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 7.56311434879899,
    "estimated_duration": 3600.150426720227,
    "input_throughput": 5428.292622151227,
    "output_throughput": 4740.258038480622,
    "total_throughput": 10168.550660631849,
    "itl": 178.79366438144498,
    "ttft": 1220570.2106553183,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 887,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6521746115781726,
    "arrivals": 105023,
    "finished_requests": 78430,
    "scheduler_time": 87.02962665356048
}
#Debug simulation 
Total elapsed time: 7.563231055624783. Arrivals time: 0.24310764763504267 Scheduler time: 7.219447303563356 Scheduler overhead time: 0.033209368120878935 Adapter cache time: 0.01877779047936201 Engine time: 0.033514061477035284 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-32/adapters_192_slots_96_rate_0.4-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-32/adapters_192_slots_96_rate_0.4-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 540, 540, 540, 540, 4320, 540, 66, 4320, 66, 540, 540, 66, 4320, 4320, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 4320, 540, 66, 540, 4320, 4320, 540, 4320, 66, 540, 540, 4320, 540, 66, 66, 540, 4320, 66, 540, 66, 4320, 4320, 540, 4320, 4320, 4320, 66, 540, 4320, 66, 540, 66, 540, 66, 66, 540, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 540, 66, 66, 66, 66, 66, 4320, 66, 540, 66, 4320, 4320, 66, 4320, 66, 540, 540, 4320, 66, 66, 66, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 66, 4320, 540, 540, 540, 4320, 540, 66, 540, 4320, 4320, 540, 4320, 540, 66, 4320, 540, 66, 540, 540, 66, 540, 4320, 66, 540, 4320, 66, 540, 4320, 4320, 540, 66, 4320, 540, 66, 66, 540, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 540, 66, 4320, 4320, 540, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 540, 540, 540, 540, 540, 540, 66, 4320, 540, 4320, 66, 4320, 540, 66, 540, 66, 66, 540, 540, 540, 4320, 540, 66, 66]
Prompts retrieved: 315264 . Total input tokens: 70341685 . Total output tokens: 63018840
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 7.54906760295853,
    "estimated_duration": 3600.0655199106395,
    "input_throughput": 5415.641157687582,
    "output_throughput": 4729.535033690896,
    "total_throughput": 10145.176191378478,
    "itl": 177.11060037775792,
    "ttft": 1224237.7900892426,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 904,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0309938129782967,
    "arrivals": 105023,
    "finished_requests": 78252,
    "scheduler_time": 87.19287149455184
}
#Debug simulation 
Total elapsed time: 7.549206154886633. Arrivals time: 0.2449663346633315 Scheduler time: 7.2018805225379765 Scheduler overhead time: 0.033624494448304176 Adapter cache time: 0.01912445155903697 Engine time: 0.03418433200567961 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-8/adapters_192_slots_96_rate_0.4-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-8/adapters_192_slots_96_rate_0.4-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 540, 540, 540, 540, 4320, 540, 33, 4320, 33, 540, 540, 33, 4320, 4320, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 4320, 540, 33, 540, 4320, 4320, 540, 4320, 33, 540, 540, 4320, 540, 33, 33, 540, 4320, 33, 540, 33, 4320, 4320, 540, 4320, 4320, 4320, 33, 540, 4320, 33, 540, 33, 540, 33, 33, 540, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 540, 33, 33, 33, 33, 33, 4320, 33, 540, 33, 4320, 4320, 33, 4320, 33, 540, 540, 4320, 33, 33, 33, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 33, 4320, 540, 540, 540, 4320, 540, 33, 540, 4320, 4320, 540, 4320, 540, 33, 4320, 540, 33, 540, 540, 33, 540, 4320, 33, 540, 4320, 33, 540, 4320, 4320, 540, 33, 4320, 540, 33, 33, 540, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 540, 33, 4320, 4320, 540, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 540, 540, 540, 540, 540, 540, 33, 4320, 540, 4320, 33, 4320, 540, 33, 540, 33, 33, 540, 540, 540, 4320, 540, 33, 33]
Prompts retrieved: 313152 . Total input tokens: 69892023 . Total output tokens: 62596468
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 6.9908374808728695,
    "estimated_duration": 3600.117803643775,
    "input_throughput": 5420.876222507926,
    "output_throughput": 4737.579415522827,
    "total_throughput": 10158.455638030753,
    "itl": 178.64637966415802,
    "ttft": 1203974.0008514128,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 896,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7421970185638065,
    "arrivals": 104293,
    "finished_requests": 78406,
    "scheduler_time": 86.57712820331682
}
#Debug simulation 
Total elapsed time: 6.990946678910404. Arrivals time: 0.24081660620868206 Scheduler time: 6.6493762456811965 Scheduler overhead time: 0.033138791564852 Adapter cache time: 0.018911008723080158 Engine time: 0.033494943752884865 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-16/adapters_192_slots_96_rate_0.4-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-16/adapters_192_slots_96_rate_0.4-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 540, 540, 540, 540, 4320, 540, 33, 4320, 33, 540, 540, 33, 4320, 4320, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 4320, 540, 33, 540, 4320, 4320, 540, 4320, 33, 540, 540, 4320, 540, 33, 33, 540, 4320, 33, 540, 33, 4320, 4320, 540, 4320, 4320, 4320, 33, 540, 4320, 33, 540, 33, 540, 33, 33, 540, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 540, 33, 33, 33, 33, 33, 4320, 33, 540, 33, 4320, 4320, 33, 4320, 33, 540, 540, 4320, 33, 33, 33, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 33, 4320, 540, 540, 540, 4320, 540, 33, 540, 4320, 4320, 540, 4320, 540, 33, 4320, 540, 33, 540, 540, 33, 540, 4320, 33, 540, 4320, 33, 540, 4320, 4320, 540, 33, 4320, 540, 33, 33, 540, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 540, 33, 4320, 4320, 540, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 540, 540, 540, 540, 540, 540, 33, 4320, 540, 4320, 33, 4320, 540, 33, 540, 33, 33, 540, 540, 540, 4320, 540, 33, 33]
Prompts retrieved: 313152 . Total input tokens: 69892023 . Total output tokens: 62596468
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 7.028106709010899,
    "estimated_duration": 3600.1904837311295,
    "input_throughput": 5420.446803630127,
    "output_throughput": 4737.7357051182735,
    "total_throughput": 10158.1825087484,
    "itl": 178.65760273445318,
    "ttft": 1203802.7165578166,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 892,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.910239077524755,
    "arrivals": 104293,
    "finished_requests": 78414,
    "scheduler_time": 86.57524523485273
}
#Debug simulation 
Total elapsed time: 7.028215359896421. Arrivals time: 0.2431060867384076 Scheduler time: 6.683418621774763 Scheduler overhead time: 0.033398366533219814 Adapter cache time: 0.0189392720349133 Engine time: 0.033998928498476744 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-32/adapters_192_slots_96_rate_0.4-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-32/adapters_192_slots_96_rate_0.4-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 540, 540, 540, 540, 4320, 540, 33, 4320, 33, 540, 540, 33, 4320, 4320, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 4320, 540, 33, 540, 4320, 4320, 540, 4320, 33, 540, 540, 4320, 540, 33, 33, 540, 4320, 33, 540, 33, 4320, 4320, 540, 4320, 4320, 4320, 33, 540, 4320, 33, 540, 33, 540, 33, 33, 540, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 540, 33, 33, 33, 33, 33, 4320, 33, 540, 33, 4320, 4320, 33, 4320, 33, 540, 540, 4320, 33, 33, 33, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 33, 4320, 540, 540, 540, 4320, 540, 33, 540, 4320, 4320, 540, 4320, 540, 33, 4320, 540, 33, 540, 540, 33, 540, 4320, 33, 540, 4320, 33, 540, 4320, 4320, 540, 33, 4320, 540, 33, 33, 540, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 540, 33, 4320, 4320, 540, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 540, 540, 540, 540, 540, 540, 33, 4320, 540, 4320, 33, 4320, 540, 33, 540, 33, 33, 540, 540, 540, 4320, 540, 33, 33]
Prompts retrieved: 313152 . Total input tokens: 69892023 . Total output tokens: 62596468
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 6.853923306800425,
    "estimated_duration": 3600.190406237548,
    "input_throughput": 5404.928018886585,
    "output_throughput": 4724.834267245594,
    "total_throughput": 10129.762286132178,
    "itl": 176.75243273289692,
    "ttft": 1213427.3478162424,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 942,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.07912342960012,
    "arrivals": 104293,
    "finished_requests": 78180,
    "scheduler_time": 86.76263967080507
}
#Debug simulation 
Total elapsed time: 6.854061265010387. Arrivals time: 0.23551546083763242 Scheduler time: 6.516027548816055 Scheduler overhead time: 0.03342680353671312 Adapter cache time: 0.01989693008363247 Engine time: 0.03376317350193858 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-16/adapters_192_slots_96_rate_0.4-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-16/adapters_192_slots_96_rate_0.4-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 540, 540, 540, 540, 4320, 540, 33, 4320, 33, 540, 540, 33, 4320, 4320, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 4320, 540, 33, 540, 4320, 4320, 540, 4320, 33, 540, 540, 4320, 540, 33, 33, 540, 4320, 33, 540, 33, 4320, 4320, 540, 4320, 4320, 4320, 33, 540, 4320, 33, 540, 33, 540, 33, 33, 540, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 540, 33, 33, 33, 33, 33, 4320, 33, 540, 33, 4320, 4320, 33, 4320, 33, 540, 540, 4320, 33, 33, 33, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 33, 4320, 540, 540, 540, 4320, 540, 33, 540, 4320, 4320, 540, 4320, 540, 33, 4320, 540, 33, 540, 540, 33, 540, 4320, 33, 540, 4320, 33, 540, 4320, 4320, 540, 33, 4320, 540, 33, 33, 540, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 540, 33, 4320, 4320, 540, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 540, 540, 540, 540, 540, 540, 33, 4320, 540, 4320, 33, 4320, 540, 33, 540, 33, 33, 540, 540, 540, 4320, 540, 33, 33]
Prompts retrieved: 313152 . Total input tokens: 69892023 . Total output tokens: 62596468
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 7.001157599966973,
    "estimated_duration": 3600.1834672158634,
    "input_throughput": 5420.7776291723785,
    "output_throughput": 4737.4935625683065,
    "total_throughput": 10158.271191740685,
    "itl": 178.64680367396494,
    "ttft": 1203992.2994696444,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 896,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7943089440324993,
    "arrivals": 104293,
    "finished_requests": 78407,
    "scheduler_time": 86.57890327371526
}
#Debug simulation 
Total elapsed time: 7.0012654438614845. Arrivals time: 0.23169000633060932 Scheduler time: 6.668471636250615 Scheduler overhead time: 0.0330695272423327 Adapter cache time: 0.01892612362280488 Engine time: 0.033843529876321554 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-32/adapters_192_slots_96_rate_0.4-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-32/adapters_192_slots_96_rate_0.4-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 540, 540, 540, 540, 4320, 540, 33, 4320, 33, 540, 540, 33, 4320, 4320, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 4320, 540, 33, 540, 4320, 4320, 540, 4320, 33, 540, 540, 4320, 540, 33, 33, 540, 4320, 33, 540, 33, 4320, 4320, 540, 4320, 4320, 4320, 33, 540, 4320, 33, 540, 33, 540, 33, 33, 540, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 540, 33, 33, 33, 33, 33, 4320, 33, 540, 33, 4320, 4320, 33, 4320, 33, 540, 540, 4320, 33, 33, 33, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 33, 4320, 540, 540, 540, 4320, 540, 33, 540, 4320, 4320, 540, 4320, 540, 33, 4320, 540, 33, 540, 540, 33, 540, 4320, 33, 540, 4320, 33, 540, 4320, 4320, 540, 33, 4320, 540, 33, 33, 540, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 540, 33, 4320, 4320, 540, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 540, 540, 540, 540, 540, 540, 33, 4320, 540, 4320, 33, 4320, 540, 33, 540, 33, 33, 540, 540, 540, 4320, 540, 33, 33]
Prompts retrieved: 313152 . Total input tokens: 69892023 . Total output tokens: 62596468
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 6.853699521161616,
    "estimated_duration": 3600.0883941714906,
    "input_throughput": 5405.371999061263,
    "output_throughput": 4725.588968188431,
    "total_throughput": 10130.960967249694,
    "itl": 176.8318721596515,
    "ttft": 1213248.2306654537,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 947,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1376917784847342,
    "arrivals": 104293,
    "finished_requests": 78184,
    "scheduler_time": 86.75053197655399
}
#Debug simulation 
Total elapsed time: 6.8538549998775125. Arrivals time: 0.2419935674406588 Scheduler time: 6.510156729724258 Scheduler overhead time: 0.03315268782898784 Adapter cache time: 0.019498913548886776 Engine time: 0.03375233570113778 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-16/adapters_192_slots_96_rate_0.4-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-16/adapters_192_slots_96_rate_0.4-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 540, 540, 540, 540, 4320, 540, 33, 4320, 33, 540, 540, 33, 4320, 4320, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 4320, 540, 33, 540, 4320, 4320, 540, 4320, 33, 540, 540, 4320, 540, 33, 33, 540, 4320, 33, 540, 33, 4320, 4320, 540, 4320, 4320, 4320, 33, 540, 4320, 33, 540, 33, 540, 33, 33, 540, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 540, 33, 33, 33, 33, 33, 4320, 33, 540, 33, 4320, 4320, 33, 4320, 33, 540, 540, 4320, 33, 33, 33, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 33, 4320, 540, 540, 540, 4320, 540, 33, 540, 4320, 4320, 540, 4320, 540, 33, 4320, 540, 33, 540, 540, 33, 540, 4320, 33, 540, 4320, 33, 540, 4320, 4320, 540, 33, 4320, 540, 33, 33, 540, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 540, 33, 4320, 4320, 540, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 540, 540, 540, 540, 540, 540, 33, 4320, 540, 4320, 33, 4320, 540, 33, 540, 33, 33, 540, 540, 540, 4320, 540, 33, 33]
Prompts retrieved: 313152 . Total input tokens: 69892023 . Total output tokens: 62596468
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 6.973170929122716,
    "estimated_duration": 3600.1460928218194,
    "input_throughput": 5420.514472706936,
    "output_throughput": 4738.1135543390965,
    "total_throughput": 10158.628027046032,
    "itl": 178.64607782860924,
    "ttft": 1203614.8779286442,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 892,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.667124863052683,
    "arrivals": 104293,
    "finished_requests": 78417,
    "scheduler_time": 86.57486601010288
}
#Debug simulation 
Total elapsed time: 6.973292084876448. Arrivals time: 0.23958748253062367 Scheduler time: 6.632519902661443 Scheduler overhead time: 0.03351337509229779 Adapter cache time: 0.01880953647196293 Engine time: 0.03360541816800833 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-32/adapters_192_slots_96_rate_0.4-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-32/adapters_192_slots_96_rate_0.4-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 540, 540, 540, 540, 4320, 540, 33, 4320, 33, 540, 540, 33, 4320, 4320, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 4320, 540, 33, 540, 4320, 4320, 540, 4320, 33, 540, 540, 4320, 540, 33, 33, 540, 4320, 33, 540, 33, 4320, 4320, 540, 4320, 4320, 4320, 33, 540, 4320, 33, 540, 33, 540, 33, 33, 540, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 540, 33, 33, 33, 33, 33, 4320, 33, 540, 33, 4320, 4320, 33, 4320, 33, 540, 540, 4320, 33, 33, 33, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 33, 4320, 540, 540, 540, 4320, 540, 33, 540, 4320, 4320, 540, 4320, 540, 33, 4320, 540, 33, 540, 540, 33, 540, 4320, 33, 540, 4320, 33, 540, 4320, 4320, 540, 33, 4320, 540, 33, 33, 540, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 540, 33, 4320, 4320, 540, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 540, 540, 540, 540, 540, 540, 33, 4320, 540, 4320, 33, 4320, 540, 33, 540, 33, 33, 540, 540, 540, 4320, 540, 33, 33]
Prompts retrieved: 313152 . Total input tokens: 69892023 . Total output tokens: 62596468
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 6.892323985695839,
    "estimated_duration": 3600.1109281481645,
    "input_throughput": 5405.032619372435,
    "output_throughput": 4725.283286965396,
    "total_throughput": 10130.31590633783,
    "itl": 176.76487071706546,
    "ttft": 1213715.6300684672,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 931,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1210398436710567,
    "arrivals": 104293,
    "finished_requests": 78174,
    "scheduler_time": 86.75964329254106
}
#Debug simulation 
Total elapsed time: 6.8924341588281095. Arrivals time: 0.23867607209831476 Scheduler time: 6.551999971270561 Scheduler overhead time: 0.033270270098000765 Adapter cache time: 0.01947074383497238 Engine time: 0.03367818705737591 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-8/adapters_192_slots_96_rate_0.4-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-8/adapters_192_slots_96_rate_0.4-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [64 64 64]
Adapter prompts. [4320, 135, 4320, 135, 4320, 135, 4320, 135, 135, 135, 270, 270, 270, 270, 4320, 270, 135, 4320, 135, 270, 270, 135, 4320, 4320, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 4320, 270, 135, 270, 4320, 4320, 270, 4320, 135, 270, 270, 4320, 270, 135, 135, 270, 4320, 135, 270, 135, 4320, 4320, 270, 4320, 4320, 4320, 135, 270, 4320, 135, 270, 135, 270, 135, 135, 270, 4320, 4320, 135, 135, 135, 4320, 4320, 4320, 270, 135, 135, 135, 135, 135, 4320, 135, 270, 135, 4320, 4320, 135, 4320, 135, 270, 270, 4320, 135, 135, 135, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 135, 4320, 270, 270, 270, 4320, 270, 135, 270, 4320, 4320, 270, 4320, 270, 135, 4320, 270, 135, 270, 270, 135, 270, 4320, 135, 270, 4320, 135, 270, 4320, 4320, 270, 135, 4320, 270, 135, 135, 270, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 270, 135, 4320, 4320, 270, 4320, 135, 4320, 4320, 4320, 135, 4320, 4320, 4320, 270, 270, 270, 270, 270, 270, 135, 4320, 270, 4320, 135, 4320, 270, 135, 270, 135, 135, 270, 270, 270, 4320, 270, 135, 135]
Prompts retrieved: 302400 . Total input tokens: 67494451 . Total output tokens: 60433434
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 6.838030245155096,
    "estimated_duration": 3600.0826214605077,
    "input_throughput": 5423.858853572203,
    "output_throughput": 4737.877097131814,
    "total_throughput": 10161.735950704016,
    "itl": 178.73858881518854,
    "ttft": 1088348.3889511717,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1203,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.6817667559511946,
    "arrivals": 100777,
    "finished_requests": 78407,
    "scheduler_time": 83.93779616503262
}
#Debug simulation 
Total elapsed time: 6.8381432900205255. Arrivals time: 0.23313585156574845 Scheduler time: 6.500851685646921 Scheduler overhead time: 0.03283371543511748 Adapter cache time: 0.022374889347702265 Engine time: 0.03371330024674535 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-16/adapters_192_slots_96_rate_0.4-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-16/adapters_192_slots_96_rate_0.4-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [64 64 64]
Adapter prompts. [4320, 135, 4320, 135, 4320, 135, 4320, 135, 135, 135, 270, 270, 270, 270, 4320, 270, 135, 4320, 135, 270, 270, 135, 4320, 4320, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 4320, 270, 135, 270, 4320, 4320, 270, 4320, 135, 270, 270, 4320, 270, 135, 135, 270, 4320, 135, 270, 135, 4320, 4320, 270, 4320, 4320, 4320, 135, 270, 4320, 135, 270, 135, 270, 135, 135, 270, 4320, 4320, 135, 135, 135, 4320, 4320, 4320, 270, 135, 135, 135, 135, 135, 4320, 135, 270, 135, 4320, 4320, 135, 4320, 135, 270, 270, 4320, 135, 135, 135, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 135, 4320, 270, 270, 270, 4320, 270, 135, 270, 4320, 4320, 270, 4320, 270, 135, 4320, 270, 135, 270, 270, 135, 270, 4320, 135, 270, 4320, 135, 270, 4320, 4320, 270, 135, 4320, 270, 135, 135, 270, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 270, 135, 4320, 4320, 270, 4320, 135, 4320, 4320, 4320, 135, 4320, 4320, 4320, 270, 270, 270, 270, 270, 270, 135, 4320, 270, 4320, 135, 4320, 270, 135, 270, 135, 135, 270, 270, 270, 4320, 270, 135, 135]
Prompts retrieved: 302400 . Total input tokens: 67494451 . Total output tokens: 60433434
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 6.781271138694137,
    "estimated_duration": 3600.1584672309614,
    "input_throughput": 5423.1773900266635,
    "output_throughput": 4737.283137738578,
    "total_throughput": 10160.460527765243,
    "itl": 178.75121814894416,
    "ttft": 1088745.1621575442,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1212,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9581719279056484,
    "arrivals": 100777,
    "finished_requests": 78400,
    "scheduler_time": 83.9398327594533
}
#Debug simulation 
Total elapsed time: 6.781374196056277. Arrivals time: 0.2218909589573741 Scheduler time: 6.454958380199969 Scheduler overhead time: 0.03302857372909784 Adapter cache time: 0.022885186597704887 Engine time: 0.03342370921745896 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-32/adapters_192_slots_96_rate_0.4-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-32/adapters_192_slots_96_rate_0.4-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [64 64 64]
Adapter prompts. [4320, 135, 4320, 135, 4320, 135, 4320, 135, 135, 135, 270, 270, 270, 270, 4320, 270, 135, 4320, 135, 270, 270, 135, 4320, 4320, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 4320, 270, 135, 270, 4320, 4320, 270, 4320, 135, 270, 270, 4320, 270, 135, 135, 270, 4320, 135, 270, 135, 4320, 4320, 270, 4320, 4320, 4320, 135, 270, 4320, 135, 270, 135, 270, 135, 135, 270, 4320, 4320, 135, 135, 135, 4320, 4320, 4320, 270, 135, 135, 135, 135, 135, 4320, 135, 270, 135, 4320, 4320, 135, 4320, 135, 270, 270, 4320, 135, 135, 135, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 135, 4320, 270, 270, 270, 4320, 270, 135, 270, 4320, 4320, 270, 4320, 270, 135, 4320, 270, 135, 270, 270, 135, 270, 4320, 135, 270, 4320, 135, 270, 4320, 4320, 270, 135, 4320, 270, 135, 135, 270, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 270, 135, 4320, 4320, 270, 4320, 135, 4320, 4320, 4320, 135, 4320, 4320, 4320, 270, 270, 270, 270, 270, 270, 135, 4320, 270, 4320, 135, 4320, 270, 135, 270, 135, 135, 270, 270, 270, 4320, 270, 135, 135]
Prompts retrieved: 302400 . Total input tokens: 67494451 . Total output tokens: 60433434
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 6.7720509697683156,
    "estimated_duration": 3600.1736205641164,
    "input_throughput": 5413.378090622814,
    "output_throughput": 4725.6048716156665,
    "total_throughput": 10138.98296223848,
    "itl": 177.09647340334396,
    "ttft": 1097125.0076974689,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1234,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.034943184852535,
    "arrivals": 100777,
    "finished_requests": 78222,
    "scheduler_time": 84.07570168577966
}
#Debug simulation 
Total elapsed time: 6.772173483856022. Arrivals time: 0.2255485444329679 Scheduler time: 6.441166443284601 Scheduler overhead time: 0.03307795012369752 Adapter cache time: 0.023306021932512522 Engine time: 0.033737507183104753 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-16/adapters_192_slots_96_rate_0.4-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-16/adapters_192_slots_96_rate_0.4-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [64 64 64]
Adapter prompts. [4320, 135, 4320, 135, 4320, 135, 4320, 135, 135, 135, 270, 270, 270, 270, 4320, 270, 135, 4320, 135, 270, 270, 135, 4320, 4320, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 4320, 270, 135, 270, 4320, 4320, 270, 4320, 135, 270, 270, 4320, 270, 135, 135, 270, 4320, 135, 270, 135, 4320, 4320, 270, 4320, 4320, 4320, 135, 270, 4320, 135, 270, 135, 270, 135, 135, 270, 4320, 4320, 135, 135, 135, 4320, 4320, 4320, 270, 135, 135, 135, 135, 135, 4320, 135, 270, 135, 4320, 4320, 135, 4320, 135, 270, 270, 4320, 135, 135, 135, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 135, 4320, 270, 270, 270, 4320, 270, 135, 270, 4320, 4320, 270, 4320, 270, 135, 4320, 270, 135, 270, 270, 135, 270, 4320, 135, 270, 4320, 135, 270, 4320, 4320, 270, 135, 4320, 270, 135, 135, 270, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 270, 135, 4320, 4320, 270, 4320, 135, 4320, 4320, 4320, 135, 4320, 4320, 4320, 270, 270, 270, 270, 270, 270, 135, 4320, 270, 4320, 135, 4320, 270, 135, 270, 135, 135, 270, 270, 270, 4320, 270, 135, 135]
Prompts retrieved: 302400 . Total input tokens: 67494451 . Total output tokens: 60433434
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 6.784301721025258,
    "estimated_duration": 3600.144829593174,
    "input_throughput": 5423.908182662359,
    "output_throughput": 4737.656624199589,
    "total_throughput": 10161.564806861947,
    "itl": 178.73851677559176,
    "ttft": 1088456.6290256076,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1211,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7839804391841882,
    "arrivals": 100777,
    "finished_requests": 78407,
    "scheduler_time": 83.93993342834243
}
#Debug simulation 
Total elapsed time: 6.784437974914908. Arrivals time: 0.22874114708974957 Scheduler time: 6.451633764896542 Scheduler overhead time: 0.03274806123226881 Adapter cache time: 0.022863813675940037 Engine time: 0.03324295813217759 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-32/adapters_192_slots_96_rate_0.4-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-32/adapters_192_slots_96_rate_0.4-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [64 64 64]
Adapter prompts. [4320, 135, 4320, 135, 4320, 135, 4320, 135, 135, 135, 270, 270, 270, 270, 4320, 270, 135, 4320, 135, 270, 270, 135, 4320, 4320, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 4320, 270, 135, 270, 4320, 4320, 270, 4320, 135, 270, 270, 4320, 270, 135, 135, 270, 4320, 135, 270, 135, 4320, 4320, 270, 4320, 4320, 4320, 135, 270, 4320, 135, 270, 135, 270, 135, 135, 270, 4320, 4320, 135, 135, 135, 4320, 4320, 4320, 270, 135, 135, 135, 135, 135, 4320, 135, 270, 135, 4320, 4320, 135, 4320, 135, 270, 270, 4320, 135, 135, 135, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 135, 4320, 270, 270, 270, 4320, 270, 135, 270, 4320, 4320, 270, 4320, 270, 135, 4320, 270, 135, 270, 270, 135, 270, 4320, 135, 270, 4320, 135, 270, 4320, 4320, 270, 135, 4320, 270, 135, 135, 270, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 270, 135, 4320, 4320, 270, 4320, 135, 4320, 4320, 4320, 135, 4320, 4320, 4320, 270, 270, 270, 270, 270, 270, 135, 4320, 270, 4320, 135, 4320, 270, 135, 270, 135, 135, 270, 270, 270, 4320, 270, 135, 135]
Prompts retrieved: 302400 . Total input tokens: 67494451 . Total output tokens: 60433434
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 6.7465533637441695,
    "estimated_duration": 3600.121306887812,
    "input_throughput": 5413.456475122972,
    "output_throughput": 4725.672984254851,
    "total_throughput": 10139.129459377822,
    "itl": 177.1044645472936,
    "ttft": 1097080.1368754555,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1234,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.088262790292497,
    "arrivals": 100777,
    "finished_requests": 78221,
    "scheduler_time": 84.07417217136356
}
#Debug simulation 
Total elapsed time: 6.746660165954381. Arrivals time: 0.22935519367456436 Scheduler time: 6.412288494408131 Scheduler overhead time: 0.03317065583541989 Adapter cache time: 0.022908422630280256 Engine time: 0.03362570842728019 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-16/adapters_192_slots_96_rate_0.4-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-16/adapters_192_slots_96_rate_0.4-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [64 64 64]
Adapter prompts. [4320, 135, 4320, 135, 4320, 135, 4320, 135, 135, 135, 270, 270, 270, 270, 4320, 270, 135, 4320, 135, 270, 270, 135, 4320, 4320, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 4320, 270, 135, 270, 4320, 4320, 270, 4320, 135, 270, 270, 4320, 270, 135, 135, 270, 4320, 135, 270, 135, 4320, 4320, 270, 4320, 4320, 4320, 135, 270, 4320, 135, 270, 135, 270, 135, 135, 270, 4320, 4320, 135, 135, 135, 4320, 4320, 4320, 270, 135, 135, 135, 135, 135, 4320, 135, 270, 135, 4320, 4320, 135, 4320, 135, 270, 270, 4320, 135, 135, 135, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 135, 4320, 270, 270, 270, 4320, 270, 135, 270, 4320, 4320, 270, 4320, 270, 135, 4320, 270, 135, 270, 270, 135, 270, 4320, 135, 270, 4320, 135, 270, 4320, 4320, 270, 135, 4320, 270, 135, 135, 270, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 270, 135, 4320, 4320, 270, 4320, 135, 4320, 4320, 4320, 135, 4320, 4320, 4320, 270, 270, 270, 270, 270, 270, 135, 4320, 270, 4320, 135, 4320, 270, 135, 270, 135, 135, 270, 270, 270, 4320, 270, 135, 135]
Prompts retrieved: 302400 . Total input tokens: 67494451 . Total output tokens: 60433434
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 6.79495552694425,
    "estimated_duration": 3600.077852398695,
    "input_throughput": 5424.256030182476,
    "output_throughput": 4737.598101839922,
    "total_throughput": 10161.854132022398,
    "itl": 178.72652945577406,
    "ttft": 1088315.6815464622,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1211,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.620950907126443,
    "arrivals": 100777,
    "finished_requests": 78409,
    "scheduler_time": 83.94041059718829
}
#Debug simulation 
Total elapsed time: 6.795107738114893. Arrivals time: 0.23587926710024476 Scheduler time: 6.45446406211704 Scheduler overhead time: 0.03301564836874604 Adapter cache time: 0.023121343459933996 Engine time: 0.03348233876749873 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-32/adapters_192_slots_96_rate_0.4-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-32/adapters_192_slots_96_rate_0.4-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [64 64 64]
Adapter prompts. [4320, 135, 4320, 135, 4320, 135, 4320, 135, 135, 135, 270, 270, 270, 270, 4320, 270, 135, 4320, 135, 270, 270, 135, 4320, 4320, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 4320, 270, 135, 270, 4320, 4320, 270, 4320, 135, 270, 270, 4320, 270, 135, 135, 270, 4320, 135, 270, 135, 4320, 4320, 270, 4320, 4320, 4320, 135, 270, 4320, 135, 270, 135, 270, 135, 135, 270, 4320, 4320, 135, 135, 135, 4320, 4320, 4320, 270, 135, 135, 135, 135, 135, 4320, 135, 270, 135, 4320, 4320, 135, 4320, 135, 270, 270, 4320, 135, 135, 135, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 135, 4320, 270, 270, 270, 4320, 270, 135, 270, 4320, 4320, 270, 4320, 270, 135, 4320, 270, 135, 270, 270, 135, 270, 4320, 135, 270, 4320, 135, 270, 4320, 4320, 270, 135, 4320, 270, 135, 135, 270, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 270, 135, 4320, 4320, 270, 4320, 135, 4320, 4320, 4320, 135, 4320, 4320, 4320, 270, 270, 270, 270, 270, 270, 135, 4320, 270, 4320, 135, 4320, 270, 135, 270, 135, 135, 270, 270, 270, 4320, 270, 135, 135]
Prompts retrieved: 302400 . Total input tokens: 67494451 . Total output tokens: 60433434
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 6.79080964718014,
    "estimated_duration": 3600.0315353060005,
    "input_throughput": 5413.060360412537,
    "output_throughput": 4725.529716381772,
    "total_throughput": 10138.59007679431,
    "itl": 177.096899944275,
    "ttft": 1097118.5264997915,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1234,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.139067320004153,
    "arrivals": 100777,
    "finished_requests": 78218,
    "scheduler_time": 84.07200186131061
}
#Debug simulation 
Total elapsed time: 6.7909400733187795. Arrivals time: 0.22280350048094988 Scheduler time: 6.46286551700905 Scheduler overhead time: 0.03306523337960243 Adapter cache time: 0.023159124422818422 Engine time: 0.03366844402626157 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_192_slots_96_rate_0.4-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_192_slots_96_rate_0.4-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 270, 270, 270, 270, 4320, 270, 66, 4320, 66, 270, 270, 66, 4320, 4320, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 4320, 270, 66, 270, 4320, 4320, 270, 4320, 66, 270, 270, 4320, 270, 66, 66, 270, 4320, 66, 270, 66, 4320, 4320, 270, 4320, 4320, 4320, 66, 270, 4320, 66, 270, 66, 270, 66, 66, 270, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 270, 66, 66, 66, 66, 66, 4320, 66, 270, 66, 4320, 4320, 66, 4320, 66, 270, 270, 4320, 66, 66, 66, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 66, 4320, 270, 270, 270, 4320, 270, 66, 270, 4320, 4320, 270, 4320, 270, 66, 4320, 270, 66, 270, 270, 66, 270, 4320, 66, 270, 4320, 66, 270, 4320, 4320, 270, 66, 4320, 270, 66, 66, 270, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 270, 66, 4320, 4320, 270, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 270, 270, 270, 270, 270, 270, 66, 4320, 270, 4320, 66, 4320, 270, 66, 270, 66, 66, 270, 270, 270, 4320, 270, 66, 66]
Prompts retrieved: 297984 . Total input tokens: 66511279 . Total output tokens: 59553787
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 6.306480982806534,
    "estimated_duration": 3600.140288753823,
    "input_throughput": 5447.4224410817205,
    "output_throughput": 4737.848981408499,
    "total_throughput": 10185.27142249022,
    "itl": 178.0907948854761,
    "ttft": 1033801.3316274455,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1314,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.021480895527742,
    "arrivals": 99385,
    "finished_requests": 78314,
    "scheduler_time": 82.40640094881601
}
#Debug simulation 
Total elapsed time: 6.306590897962451. Arrivals time: 0.2255900981836021 Scheduler time: 5.976483751554042 Scheduler overhead time: 0.03265177644789219 Adapter cache time: 0.02360974019393325 Engine time: 0.03316179709509015 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_192_slots_96_rate_0.4-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_192_slots_96_rate_0.4-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 270, 270, 270, 270, 4320, 270, 66, 4320, 66, 270, 270, 66, 4320, 4320, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 4320, 270, 66, 270, 4320, 4320, 270, 4320, 66, 270, 270, 4320, 270, 66, 66, 270, 4320, 66, 270, 66, 4320, 4320, 270, 4320, 4320, 4320, 66, 270, 4320, 66, 270, 66, 270, 66, 66, 270, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 270, 66, 66, 66, 66, 66, 4320, 66, 270, 66, 4320, 4320, 66, 4320, 66, 270, 270, 4320, 66, 66, 66, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 66, 4320, 270, 270, 270, 4320, 270, 66, 270, 4320, 4320, 270, 4320, 270, 66, 4320, 270, 66, 270, 270, 66, 270, 4320, 66, 270, 4320, 66, 270, 4320, 4320, 270, 66, 4320, 270, 66, 66, 270, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 270, 66, 4320, 4320, 270, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 270, 270, 270, 270, 270, 270, 66, 4320, 270, 4320, 66, 4320, 270, 66, 270, 66, 66, 270, 270, 270, 4320, 270, 66, 66]
Prompts retrieved: 297984 . Total input tokens: 66511279 . Total output tokens: 59553787
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 6.351126106921583,
    "estimated_duration": 3600.100053979798,
    "input_throughput": 5447.2527724114325,
    "output_throughput": 4737.649160929601,
    "total_throughput": 10184.901933341032,
    "itl": 178.1011033631811,
    "ttft": 1033972.9379529158,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1315,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.295974566526692,
    "arrivals": 99385,
    "finished_requests": 78311,
    "scheduler_time": 82.40495202229012
}
#Debug simulation 
Total elapsed time: 6.351245109923184. Arrivals time: 0.22120650252327323 Scheduler time: 6.024264715146273 Scheduler overhead time: 0.03305468708276749 Adapter cache time: 0.024012991227209568 Engine time: 0.03336062701418996 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-32/adapters_192_slots_96_rate_0.4-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-32/adapters_192_slots_96_rate_0.4-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 270, 270, 270, 270, 4320, 270, 66, 4320, 66, 270, 270, 66, 4320, 4320, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 4320, 270, 66, 270, 4320, 4320, 270, 4320, 66, 270, 270, 4320, 270, 66, 66, 270, 4320, 66, 270, 66, 4320, 4320, 270, 4320, 4320, 4320, 66, 270, 4320, 66, 270, 66, 270, 66, 66, 270, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 270, 66, 66, 66, 66, 66, 4320, 66, 270, 66, 4320, 4320, 66, 4320, 66, 270, 270, 4320, 66, 66, 66, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 66, 4320, 270, 270, 270, 4320, 270, 66, 270, 4320, 4320, 270, 4320, 270, 66, 4320, 270, 66, 270, 270, 66, 270, 4320, 66, 270, 4320, 66, 270, 4320, 4320, 270, 66, 4320, 270, 66, 66, 270, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 270, 66, 4320, 4320, 270, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 270, 270, 270, 270, 270, 270, 66, 4320, 270, 4320, 66, 4320, 270, 66, 270, 66, 66, 270, 270, 270, 4320, 270, 66, 66]
Prompts retrieved: 297984 . Total input tokens: 66511279 . Total output tokens: 59553787
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 6.371212874073535,
    "estimated_duration": 3600.0768524147998,
    "input_throughput": 5434.565927912514,
    "output_throughput": 4726.348269089538,
    "total_throughput": 10160.914197002052,
    "itl": 176.20694948061532,
    "ttft": 1043039.8340301774,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1344,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.397384552769301,
    "arrivals": 99385,
    "finished_requests": 78123,
    "scheduler_time": 82.54966138790515
}
#Debug simulation 
Total elapsed time: 6.371333539951593. Arrivals time: 0.2274676850065589 Scheduler time: 6.036729166749865 Scheduler overhead time: 0.03323107631877065 Adapter cache time: 0.02445966051891446 Engine time: 0.03376324288547039 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_192_slots_96_rate_0.4-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_192_slots_96_rate_0.4-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 270, 270, 270, 270, 4320, 270, 66, 4320, 66, 270, 270, 66, 4320, 4320, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 4320, 270, 66, 270, 4320, 4320, 270, 4320, 66, 270, 270, 4320, 270, 66, 66, 270, 4320, 66, 270, 66, 4320, 4320, 270, 4320, 4320, 4320, 66, 270, 4320, 66, 270, 66, 270, 66, 66, 270, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 270, 66, 66, 66, 66, 66, 4320, 66, 270, 66, 4320, 4320, 66, 4320, 66, 270, 270, 4320, 66, 66, 66, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 66, 4320, 270, 270, 270, 4320, 270, 66, 270, 4320, 4320, 270, 4320, 270, 66, 4320, 270, 66, 270, 270, 66, 270, 4320, 66, 270, 4320, 66, 270, 4320, 4320, 270, 66, 4320, 270, 66, 66, 270, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 270, 66, 4320, 4320, 270, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 270, 270, 270, 270, 270, 270, 66, 4320, 270, 4320, 66, 4320, 270, 66, 270, 66, 66, 270, 270, 270, 4320, 270, 66, 66]
Prompts retrieved: 297984 . Total input tokens: 66511279 . Total output tokens: 59553787
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 6.3689091936685145,
    "estimated_duration": 3600.189621540686,
    "input_throughput": 5447.310575715566,
    "output_throughput": 4737.897386832749,
    "total_throughput": 10185.207962548315,
    "itl": 178.09144505864288,
    "ttft": 1033812.8000694443,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1317,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.115635201907661,
    "arrivals": 99385,
    "finished_requests": 78315,
    "scheduler_time": 82.40785938690476
}
#Debug simulation 
Total elapsed time: 6.369057372678071. Arrivals time: 0.2256152513436973 Scheduler time: 6.038333243690431 Scheduler overhead time: 0.03283113241195679 Adapter cache time: 0.023745985701680183 Engine time: 0.03328398009762168 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-32/adapters_192_slots_96_rate_0.4-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-32/adapters_192_slots_96_rate_0.4-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 270, 270, 270, 270, 4320, 270, 66, 4320, 66, 270, 270, 66, 4320, 4320, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 4320, 270, 66, 270, 4320, 4320, 270, 4320, 66, 270, 270, 4320, 270, 66, 66, 270, 4320, 66, 270, 66, 4320, 4320, 270, 4320, 4320, 4320, 66, 270, 4320, 66, 270, 66, 270, 66, 66, 270, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 270, 66, 66, 66, 66, 66, 4320, 66, 270, 66, 4320, 4320, 66, 4320, 66, 270, 270, 4320, 66, 66, 66, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 66, 4320, 270, 270, 270, 4320, 270, 66, 270, 4320, 4320, 270, 4320, 270, 66, 4320, 270, 66, 270, 270, 66, 270, 4320, 66, 270, 4320, 66, 270, 4320, 4320, 270, 66, 4320, 270, 66, 66, 270, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 270, 66, 4320, 4320, 270, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 270, 270, 270, 270, 270, 270, 66, 4320, 270, 4320, 66, 4320, 270, 66, 270, 66, 66, 270, 270, 270, 4320, 270, 66, 66]
Prompts retrieved: 297984 . Total input tokens: 66511279 . Total output tokens: 59553787
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 6.286475787870586,
    "estimated_duration": 3600.1147372762052,
    "input_throughput": 5435.01538920503,
    "output_throughput": 4726.751295953056,
    "total_throughput": 10161.766685158087,
    "itl": 176.21635647023328,
    "ttft": 1042912.6045154713,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1342,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.44952151818199,
    "arrivals": 99385,
    "finished_requests": 78130,
    "scheduler_time": 82.55035745713606
}
#Debug simulation 
Total elapsed time: 6.286579936742783. Arrivals time: 0.23065639147534966 Scheduler time: 5.949209833052009 Scheduler overhead time: 0.03345323586836457 Adapter cache time: 0.024168077390640974 Engine time: 0.033545775804668665 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_192_slots_96_rate_0.4-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_192_slots_96_rate_0.4-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 270, 270, 270, 270, 4320, 270, 66, 4320, 66, 270, 270, 66, 4320, 4320, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 4320, 270, 66, 270, 4320, 4320, 270, 4320, 66, 270, 270, 4320, 270, 66, 66, 270, 4320, 66, 270, 66, 4320, 4320, 270, 4320, 4320, 4320, 66, 270, 4320, 66, 270, 66, 270, 66, 66, 270, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 270, 66, 66, 66, 66, 66, 4320, 66, 270, 66, 4320, 4320, 66, 4320, 66, 270, 270, 4320, 66, 66, 66, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 66, 4320, 270, 270, 270, 4320, 270, 66, 270, 4320, 4320, 270, 4320, 270, 66, 4320, 270, 66, 270, 270, 66, 270, 4320, 66, 270, 4320, 66, 270, 4320, 4320, 270, 66, 4320, 270, 66, 66, 270, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 270, 66, 4320, 4320, 270, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 270, 270, 270, 270, 270, 270, 66, 4320, 270, 4320, 66, 4320, 270, 66, 270, 66, 66, 270, 270, 270, 4320, 270, 66, 66]
Prompts retrieved: 297984 . Total input tokens: 66511279 . Total output tokens: 59553787
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 6.35021886928007,
    "estimated_duration": 3600.1902217157003,
    "input_throughput": 5447.351332078775,
    "output_throughput": 4737.8504883198275,
    "total_throughput": 10185.201820398603,
    "itl": 178.087981820538,
    "ttft": 1033765.7862319993,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1314,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.928926087501356,
    "arrivals": 99385,
    "finished_requests": 78314,
    "scheduler_time": 82.4079777193461
}
#Debug simulation 
Total elapsed time: 6.350331463385373. Arrivals time: 0.22589878691360354 Scheduler time: 6.019211877137423 Scheduler overhead time: 0.032931949477642775 Adapter cache time: 0.023852355778217316 Engine time: 0.03327326476573944 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-32/adapters_192_slots_96_rate_0.4-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-32/adapters_192_slots_96_rate_0.4-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 270, 270, 270, 270, 4320, 270, 66, 4320, 66, 270, 270, 66, 4320, 4320, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 4320, 270, 66, 270, 4320, 4320, 270, 4320, 66, 270, 270, 4320, 270, 66, 66, 270, 4320, 66, 270, 66, 4320, 4320, 270, 4320, 4320, 4320, 66, 270, 4320, 66, 270, 66, 270, 66, 66, 270, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 270, 66, 66, 66, 66, 66, 4320, 66, 270, 66, 4320, 4320, 66, 4320, 66, 270, 270, 4320, 66, 66, 66, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 66, 4320, 270, 270, 270, 4320, 270, 66, 270, 4320, 4320, 270, 4320, 270, 66, 4320, 270, 66, 270, 270, 66, 270, 4320, 66, 270, 4320, 66, 270, 4320, 4320, 270, 66, 4320, 270, 66, 66, 270, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 270, 66, 4320, 4320, 270, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 270, 270, 270, 270, 270, 270, 66, 4320, 270, 4320, 66, 4320, 270, 66, 270, 66, 66, 270, 270, 270, 4320, 270, 66, 66]
Prompts retrieved: 297984 . Total input tokens: 66511279 . Total output tokens: 59553787
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 6.306074119638652,
    "estimated_duration": 3600.0157003225736,
    "input_throughput": 5434.564632106175,
    "output_throughput": 4726.202165861513,
    "total_throughput": 10160.766797967688,
    "itl": 176.18811625380735,
    "ttft": 1043169.9046418291,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1347,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.522803060077143,
    "arrivals": 99385,
    "finished_requests": 78119,
    "scheduler_time": 82.55008037232508
}
#Debug simulation 
Total elapsed time: 6.306233479641378. Arrivals time: 0.2269252398982644 Scheduler time: 5.972851090598851 Scheduler overhead time: 0.03338659927248955 Adapter cache time: 0.02413131855428219 Engine time: 0.03356095030903816 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_192_slots_96_rate_0.4-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_192_slots_96_rate_0.4-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 270, 270, 270, 270, 4320, 270, 33, 4320, 33, 270, 270, 33, 4320, 4320, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 4320, 270, 33, 270, 4320, 4320, 270, 4320, 33, 270, 270, 4320, 270, 33, 33, 270, 4320, 33, 270, 33, 4320, 4320, 270, 4320, 4320, 4320, 33, 270, 4320, 33, 270, 33, 270, 33, 33, 270, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 270, 33, 33, 33, 33, 33, 4320, 33, 270, 33, 4320, 4320, 33, 4320, 33, 270, 270, 4320, 33, 33, 33, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 33, 4320, 270, 270, 270, 4320, 270, 33, 270, 4320, 4320, 270, 4320, 270, 33, 4320, 270, 33, 270, 270, 33, 270, 4320, 33, 270, 4320, 33, 270, 4320, 4320, 270, 33, 4320, 270, 33, 33, 270, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 270, 33, 4320, 4320, 270, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 270, 270, 270, 270, 270, 270, 33, 4320, 270, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 270, 270, 4320, 270, 33, 33]
Prompts retrieved: 295872 . Total input tokens: 66041597 . Total output tokens: 59123757
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.998862683773041,
    "estimated_duration": 3600.0893147082425,
    "input_throughput": 5447.2406892464205,
    "output_throughput": 4737.127195796278,
    "total_throughput": 10184.367885042699,
    "itl": 177.92863895510732,
    "ttft": 999055.08836366,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1355,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.146960893028989,
    "arrivals": 98651,
    "finished_requests": 78403,
    "scheduler_time": 81.58519445632146
}
#Debug simulation 
Total elapsed time: 5.998974482063204. Arrivals time: 0.21886126045137644 Scheduler time: 5.6748703927733 Scheduler overhead time: 0.03266935795545578 Adapter cache time: 0.024348985869437456 Engine time: 0.03310647280886769 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_192_slots_96_rate_0.4-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_192_slots_96_rate_0.4-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 270, 270, 270, 270, 4320, 270, 33, 4320, 33, 270, 270, 33, 4320, 4320, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 4320, 270, 33, 270, 4320, 4320, 270, 4320, 33, 270, 270, 4320, 270, 33, 33, 270, 4320, 33, 270, 33, 4320, 4320, 270, 4320, 4320, 4320, 33, 270, 4320, 33, 270, 33, 270, 33, 33, 270, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 270, 33, 33, 33, 33, 33, 4320, 33, 270, 33, 4320, 4320, 33, 4320, 33, 270, 270, 4320, 33, 33, 33, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 33, 4320, 270, 270, 270, 4320, 270, 33, 270, 4320, 4320, 270, 4320, 270, 33, 4320, 270, 33, 270, 270, 33, 270, 4320, 33, 270, 4320, 33, 270, 4320, 4320, 270, 33, 4320, 270, 33, 33, 270, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 270, 33, 4320, 4320, 270, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 270, 270, 270, 270, 270, 270, 33, 4320, 270, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 270, 270, 4320, 270, 33, 33]
Prompts retrieved: 295872 . Total input tokens: 66041597 . Total output tokens: 59123757
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 6.028634832240641,
    "estimated_duration": 3600.094903632052,
    "input_throughput": 5446.530306803278,
    "output_throughput": 4736.484580669482,
    "total_throughput": 10183.01488747276,
    "itl": 177.94215082038662,
    "ttft": 999420.3233978208,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1355,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.412716411093683,
    "arrivals": 98651,
    "finished_requests": 78394,
    "scheduler_time": 81.58456721910697
}
#Debug simulation 
Total elapsed time: 6.02874821703881. Arrivals time: 0.22188313212245703 Scheduler time: 5.701644857879728 Scheduler overhead time: 0.03270129952579737 Adapter cache time: 0.02430792897939682 Engine time: 0.03304312424734235 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-32/adapters_192_slots_96_rate_0.4-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-32/adapters_192_slots_96_rate_0.4-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 270, 270, 270, 270, 4320, 270, 33, 4320, 33, 270, 270, 33, 4320, 4320, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 4320, 270, 33, 270, 4320, 4320, 270, 4320, 33, 270, 270, 4320, 270, 33, 33, 270, 4320, 33, 270, 33, 4320, 4320, 270, 4320, 4320, 4320, 33, 270, 4320, 33, 270, 33, 270, 33, 33, 270, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 270, 33, 33, 33, 33, 33, 4320, 33, 270, 33, 4320, 4320, 33, 4320, 33, 270, 270, 4320, 33, 33, 33, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 33, 4320, 270, 270, 270, 4320, 270, 33, 270, 4320, 4320, 270, 4320, 270, 33, 4320, 270, 33, 270, 270, 33, 270, 4320, 33, 270, 4320, 33, 270, 4320, 4320, 270, 33, 4320, 270, 33, 33, 270, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 270, 33, 4320, 4320, 270, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 270, 270, 270, 270, 270, 270, 33, 4320, 270, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 270, 270, 4320, 270, 33, 33]
Prompts retrieved: 295872 . Total input tokens: 66041597 . Total output tokens: 59123757
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 6.007646443322301,
    "estimated_duration": 3600.0690254003252,
    "input_throughput": 5435.013290564401,
    "output_throughput": 4727.8182390148295,
    "total_throughput": 10162.83152957923,
    "itl": 176.28815557583903,
    "ttft": 1007119.9552673374,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1398,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.5627463130838555,
    "arrivals": 98651,
    "finished_requests": 78229,
    "scheduler_time": 81.70131775498642
}
#Debug simulation 
Total elapsed time: 6.007751801051199. Arrivals time: 0.23099016724154353 Scheduler time: 5.669947678688914 Scheduler overhead time: 0.03302317205816507 Adapter cache time: 0.024919999297708273 Engine time: 0.033534342888742685 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_192_slots_96_rate_0.4-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_192_slots_96_rate_0.4-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 270, 270, 270, 270, 4320, 270, 33, 4320, 33, 270, 270, 33, 4320, 4320, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 4320, 270, 33, 270, 4320, 4320, 270, 4320, 33, 270, 270, 4320, 270, 33, 33, 270, 4320, 33, 270, 33, 4320, 4320, 270, 4320, 4320, 4320, 33, 270, 4320, 33, 270, 33, 270, 33, 33, 270, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 270, 33, 33, 33, 33, 33, 4320, 33, 270, 33, 4320, 4320, 33, 4320, 33, 270, 270, 4320, 33, 33, 33, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 33, 4320, 270, 270, 270, 4320, 270, 33, 270, 4320, 4320, 270, 4320, 270, 33, 4320, 270, 33, 270, 270, 33, 270, 4320, 33, 270, 4320, 33, 270, 4320, 4320, 270, 33, 4320, 270, 33, 33, 270, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 270, 33, 4320, 4320, 270, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 270, 270, 270, 270, 270, 270, 33, 4320, 270, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 270, 270, 4320, 270, 33, 33]
Prompts retrieved: 295872 . Total input tokens: 66041597 . Total output tokens: 59123757
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 6.032458288129419,
    "estimated_duration": 3600.2035111436744,
    "input_throughput": 5447.219563921306,
    "output_throughput": 4737.100263141041,
    "total_throughput": 10184.319827062347,
    "itl": 177.93156914093427,
    "ttft": 999103.8101396919,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1355,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.221493802063567,
    "arrivals": 98651,
    "finished_requests": 78405,
    "scheduler_time": 81.58798737362382
}
#Debug simulation 
Total elapsed time: 6.032585263252258. Arrivals time: 0.2256905548274517 Scheduler time: 5.700737110339105 Scheduler overhead time: 0.032878934405744076 Adapter cache time: 0.024702501017600298 Engine time: 0.03338290145620704 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-32/adapters_192_slots_96_rate_0.4-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-32/adapters_192_slots_96_rate_0.4-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 270, 270, 270, 270, 4320, 270, 33, 4320, 33, 270, 270, 33, 4320, 4320, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 4320, 270, 33, 270, 4320, 4320, 270, 4320, 33, 270, 270, 4320, 270, 33, 33, 270, 4320, 33, 270, 33, 4320, 4320, 270, 4320, 4320, 4320, 33, 270, 4320, 33, 270, 33, 270, 33, 33, 270, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 270, 33, 33, 33, 33, 33, 4320, 33, 270, 33, 4320, 4320, 33, 4320, 33, 270, 270, 4320, 33, 33, 33, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 33, 4320, 270, 270, 270, 4320, 270, 33, 270, 4320, 4320, 270, 4320, 270, 33, 4320, 270, 33, 270, 270, 33, 270, 4320, 33, 270, 4320, 33, 270, 4320, 4320, 270, 33, 4320, 270, 33, 33, 270, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 270, 33, 4320, 4320, 270, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 270, 270, 270, 270, 270, 270, 33, 4320, 270, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 270, 270, 4320, 270, 33, 33]
Prompts retrieved: 295872 . Total input tokens: 66041597 . Total output tokens: 59123757
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 5.971002044621855,
    "estimated_duration": 3600.134369989337,
    "input_throughput": 5434.914641827092,
    "output_throughput": 4727.732426290081,
    "total_throughput": 10162.647068117172,
    "itl": 176.29031766041223,
    "ttft": 1007279.813838269,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1398,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.623988407067929,
    "arrivals": 98651,
    "finished_requests": 78229,
    "scheduler_time": 81.70303850951375
}
#Debug simulation 
Total elapsed time: 5.971122817602009. Arrivals time: 0.2223907127045095 Scheduler time: 5.642432558815926 Scheduler overhead time: 0.03281596815213561 Adapter cache time: 0.0249660462141037 Engine time: 0.033334008418023586 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_192_slots_96_rate_0.4-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_192_slots_96_rate_0.4-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 270, 270, 270, 270, 4320, 270, 33, 4320, 33, 270, 270, 33, 4320, 4320, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 4320, 270, 33, 270, 4320, 4320, 270, 4320, 33, 270, 270, 4320, 270, 33, 33, 270, 4320, 33, 270, 33, 4320, 4320, 270, 4320, 4320, 4320, 33, 270, 4320, 33, 270, 33, 270, 33, 33, 270, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 270, 33, 33, 33, 33, 33, 4320, 33, 270, 33, 4320, 4320, 33, 4320, 33, 270, 270, 4320, 33, 33, 33, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 33, 4320, 270, 270, 270, 4320, 270, 33, 270, 4320, 4320, 270, 4320, 270, 33, 4320, 270, 33, 270, 270, 33, 270, 4320, 33, 270, 4320, 33, 270, 4320, 4320, 270, 33, 4320, 270, 33, 33, 270, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 270, 33, 4320, 4320, 270, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 270, 270, 270, 270, 270, 270, 33, 4320, 270, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 270, 270, 4320, 270, 33, 33]
Prompts retrieved: 295872 . Total input tokens: 66041597 . Total output tokens: 59123757
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.996897719800472,
    "estimated_duration": 3600.1586581416436,
    "input_throughput": 5447.458532320162,
    "output_throughput": 4737.399270287653,
    "total_throughput": 10184.857802607816,
    "itl": 177.92630502024878,
    "ttft": 998895.3855475739,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1355,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.051518149592341,
    "arrivals": 98651,
    "finished_requests": 78408,
    "scheduler_time": 81.58738153767308
}
#Debug simulation 
Total elapsed time: 5.996998827904463. Arrivals time: 0.2228226438164711 Scheduler time: 5.668522662017494 Scheduler overhead time: 0.03276408929377794 Adapter cache time: 0.02435798104852438 Engine time: 0.03339959820732474 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-32/adapters_192_slots_96_rate_0.4-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-32/adapters_192_slots_96_rate_0.4-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 270, 270, 270, 270, 4320, 270, 33, 4320, 33, 270, 270, 33, 4320, 4320, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 4320, 270, 33, 270, 4320, 4320, 270, 4320, 33, 270, 270, 4320, 270, 33, 33, 270, 4320, 33, 270, 33, 4320, 4320, 270, 4320, 4320, 4320, 33, 270, 4320, 33, 270, 33, 270, 33, 33, 270, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 270, 33, 33, 33, 33, 33, 4320, 33, 270, 33, 4320, 4320, 33, 4320, 33, 270, 270, 4320, 33, 33, 33, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 33, 4320, 270, 270, 270, 4320, 270, 33, 270, 4320, 4320, 270, 4320, 270, 33, 4320, 270, 33, 270, 270, 33, 270, 4320, 33, 270, 4320, 33, 270, 4320, 4320, 270, 33, 4320, 270, 33, 33, 270, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 270, 33, 4320, 4320, 270, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 270, 270, 270, 270, 270, 270, 33, 4320, 270, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 270, 270, 4320, 270, 33, 33]
Prompts retrieved: 295872 . Total input tokens: 66041597 . Total output tokens: 59123757
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 6.006691303104162,
    "estimated_duration": 3600.129010583934,
    "input_throughput": 5434.521358118385,
    "output_throughput": 4727.001990753588,
    "total_throughput": 10161.523348871973,
    "itl": 176.28319229279126,
    "ttft": 1007551.876786957,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1405,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.7007161571457905,
    "arrivals": 98651,
    "finished_requests": 78221,
    "scheduler_time": 81.70329899350976
}
#Debug simulation 
Total elapsed time: 6.00679399818182. Arrivals time: 0.2329102330841124 Scheduler time: 5.666520768776536 Scheduler overhead time: 0.03310257662087679 Adapter cache time: 0.025208414066582918 Engine time: 0.033744965214282274 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_192_slots_96_rate_0.4-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_192_slots_96_rate_0.4-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 135, 135, 135, 135, 4320, 135, 66, 4320, 66, 135, 135, 66, 4320, 4320, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 4320, 135, 66, 135, 4320, 4320, 135, 4320, 66, 135, 135, 4320, 135, 66, 66, 135, 4320, 66, 135, 66, 4320, 4320, 135, 4320, 4320, 4320, 66, 135, 4320, 66, 135, 66, 135, 66, 66, 135, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 135, 66, 66, 66, 66, 66, 4320, 66, 135, 66, 4320, 4320, 66, 4320, 66, 135, 135, 4320, 66, 66, 66, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 66, 4320, 135, 135, 135, 4320, 135, 66, 135, 4320, 4320, 135, 4320, 135, 66, 4320, 135, 66, 135, 135, 66, 135, 4320, 66, 135, 4320, 66, 135, 4320, 4320, 135, 66, 4320, 135, 66, 66, 135, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 135, 66, 4320, 4320, 135, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 135, 135, 135, 135, 135, 135, 66, 4320, 135, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 135, 135, 4320, 135, 66, 66]
Prompts retrieved: 289344 . Total input tokens: 64591017 . Total output tokens: 57818491
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.712159775197506,
    "estimated_duration": 3600.0831568710314,
    "input_throughput": 5346.003456411123,
    "output_throughput": 4750.658875020171,
    "total_throughput": 10096.662331431295,
    "itl": 179.72234646411175,
    "ttft": 947192.2116689426,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1964,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.010797929084101,
    "arrivals": 96558,
    "finished_requests": 77883,
    "scheduler_time": 80.57329197108328
}
#Debug simulation 
Total elapsed time: 5.712299347855151. Arrivals time: 0.20700752921402454 Scheduler time: 5.394431641325355 Scheduler overhead time: 0.03221112070605159 Adapter cache time: 0.03104789275676012 Engine time: 0.032633624505251646 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_192_slots_96_rate_0.4-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_192_slots_96_rate_0.4-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 135, 135, 135, 135, 4320, 135, 66, 4320, 66, 135, 135, 66, 4320, 4320, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 4320, 135, 66, 135, 4320, 4320, 135, 4320, 66, 135, 135, 4320, 135, 66, 66, 135, 4320, 66, 135, 66, 4320, 4320, 135, 4320, 4320, 4320, 66, 135, 4320, 66, 135, 66, 135, 66, 66, 135, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 135, 66, 66, 66, 66, 66, 4320, 66, 135, 66, 4320, 4320, 66, 4320, 66, 135, 135, 4320, 66, 66, 66, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 66, 4320, 135, 135, 135, 4320, 135, 66, 135, 4320, 4320, 135, 4320, 135, 66, 4320, 135, 66, 135, 135, 66, 135, 4320, 66, 135, 4320, 66, 135, 4320, 4320, 135, 66, 4320, 135, 66, 66, 135, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 135, 66, 4320, 4320, 135, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 135, 135, 135, 135, 135, 135, 66, 4320, 135, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 135, 135, 4320, 135, 66, 66]
Prompts retrieved: 289344 . Total input tokens: 64591017 . Total output tokens: 57818491
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.757428834214807,
    "estimated_duration": 3600.043657363561,
    "input_throughput": 5345.261844433425,
    "output_throughput": 4749.945452751243,
    "total_throughput": 10095.207297184666,
    "itl": 179.74344687847625,
    "ttft": 947616.8984336721,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1964,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.417933529305522,
    "arrivals": 96558,
    "finished_requests": 77873,
    "scheduler_time": 80.5702765086483
}
#Debug simulation 
Total elapsed time: 5.757529576309025. Arrivals time: 0.2199971335940063 Scheduler time: 5.425981182605028 Scheduler overhead time: 0.03230314143002033 Adapter cache time: 0.031367126386612654 Engine time: 0.03285464411601424 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-32/adapters_192_slots_96_rate_0.4-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-32/adapters_192_slots_96_rate_0.4-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 135, 135, 135, 135, 4320, 135, 66, 4320, 66, 135, 135, 66, 4320, 4320, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 4320, 135, 66, 135, 4320, 4320, 135, 4320, 66, 135, 135, 4320, 135, 66, 66, 135, 4320, 66, 135, 66, 4320, 4320, 135, 4320, 4320, 4320, 66, 135, 4320, 66, 135, 66, 135, 66, 66, 135, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 135, 66, 66, 66, 66, 66, 4320, 66, 135, 66, 4320, 4320, 66, 4320, 66, 135, 135, 4320, 66, 66, 66, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 66, 4320, 135, 135, 135, 4320, 135, 66, 135, 4320, 4320, 135, 4320, 135, 66, 4320, 135, 66, 135, 135, 66, 135, 4320, 66, 135, 4320, 66, 135, 4320, 4320, 135, 66, 4320, 135, 66, 66, 135, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 135, 66, 4320, 4320, 135, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 135, 135, 135, 135, 135, 135, 66, 4320, 135, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 135, 135, 4320, 135, 66, 66]
Prompts retrieved: 289344 . Total input tokens: 64591017 . Total output tokens: 57818491
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.678722231183201,
    "estimated_duration": 3600.1323285948715,
    "input_throughput": 5328.977451083832,
    "output_throughput": 4735.307606499486,
    "total_throughput": 10064.285057583318,
    "itl": 177.49023260373755,
    "ttft": 958916.6863751784,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2013,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.586609025113248,
    "arrivals": 96558,
    "finished_requests": 77643,
    "scheduler_time": 80.71537564484385
}
#Debug simulation 
Total elapsed time: 5.678835743106902. Arrivals time: 0.21966711850836873 Scheduler time: 5.346073475200683 Scheduler overhead time: 0.03254569647833705 Adapter cache time: 0.03241143515333533 Engine time: 0.03311046026647091 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_192_slots_96_rate_0.4-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_192_slots_96_rate_0.4-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 135, 135, 135, 135, 4320, 135, 66, 4320, 66, 135, 135, 66, 4320, 4320, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 4320, 135, 66, 135, 4320, 4320, 135, 4320, 66, 135, 135, 4320, 135, 66, 66, 135, 4320, 66, 135, 66, 4320, 4320, 135, 4320, 4320, 4320, 66, 135, 4320, 66, 135, 66, 135, 66, 66, 135, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 135, 66, 66, 66, 66, 66, 4320, 66, 135, 66, 4320, 4320, 66, 4320, 66, 135, 135, 4320, 66, 66, 66, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 66, 4320, 135, 135, 135, 4320, 135, 66, 135, 4320, 4320, 135, 4320, 135, 66, 4320, 135, 66, 135, 135, 66, 135, 4320, 66, 135, 4320, 66, 135, 4320, 4320, 135, 66, 4320, 135, 66, 66, 135, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 135, 66, 4320, 4320, 135, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 135, 135, 135, 135, 135, 135, 66, 4320, 135, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 135, 135, 4320, 135, 66, 66]
Prompts retrieved: 289344 . Total input tokens: 64591017 . Total output tokens: 57818491
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 5.733385610859841,
    "estimated_duration": 3600.0873056028927,
    "input_throughput": 5345.900075825243,
    "output_throughput": 4750.500904070702,
    "total_throughput": 10096.400979895945,
    "itl": 179.7290221565691,
    "ttft": 947323.1536968559,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1964,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.131916806397305,
    "arrivals": 96558,
    "finished_requests": 77880,
    "scheduler_time": 80.57269588118352
}
#Debug simulation 
Total elapsed time: 5.733490654733032. Arrivals time: 0.21469948859885335 Scheduler time: 5.404964785091579 Scheduler overhead time: 0.032409715466201305 Adapter cache time: 0.03139854921028018 Engine time: 0.03504200326278806 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-32/adapters_192_slots_96_rate_0.4-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-32/adapters_192_slots_96_rate_0.4-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 135, 135, 135, 135, 4320, 135, 66, 4320, 66, 135, 135, 66, 4320, 4320, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 4320, 135, 66, 135, 4320, 4320, 135, 4320, 66, 135, 135, 4320, 135, 66, 66, 135, 4320, 66, 135, 66, 4320, 4320, 135, 4320, 4320, 4320, 66, 135, 4320, 66, 135, 66, 135, 66, 66, 135, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 135, 66, 66, 66, 66, 66, 4320, 66, 135, 66, 4320, 4320, 66, 4320, 66, 135, 135, 4320, 66, 66, 66, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 66, 4320, 135, 135, 135, 4320, 135, 66, 135, 4320, 4320, 135, 4320, 135, 66, 4320, 135, 66, 135, 135, 66, 135, 4320, 66, 135, 4320, 66, 135, 4320, 4320, 135, 66, 4320, 135, 66, 66, 135, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 135, 66, 4320, 4320, 135, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 135, 135, 135, 135, 135, 135, 66, 4320, 135, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 135, 135, 4320, 135, 66, 66]
Prompts retrieved: 289344 . Total input tokens: 64591017 . Total output tokens: 57818491
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 5.722370353993028,
    "estimated_duration": 3600.1721133324168,
    "input_throughput": 5328.619131556691,
    "output_throughput": 4735.192502844084,
    "total_throughput": 10063.811634400774,
    "itl": 177.47008881396798,
    "ttft": 959066.8130755926,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2015,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.684164791591337,
    "arrivals": 96558,
    "finished_requests": 77641,
    "scheduler_time": 80.71767047184522
}
#Debug simulation 
Total elapsed time: 5.72247720323503. Arrivals time: 0.21615579864010215 Scheduler time: 5.392265344038606 Scheduler overhead time: 0.03298011561855674 Adapter cache time: 0.03256132174283266 Engine time: 0.03328385856002569 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_192_slots_96_rate_0.4-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_192_slots_96_rate_0.4-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 135, 135, 135, 135, 4320, 135, 66, 4320, 66, 135, 135, 66, 4320, 4320, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 4320, 135, 66, 135, 4320, 4320, 135, 4320, 66, 135, 135, 4320, 135, 66, 66, 135, 4320, 66, 135, 66, 4320, 4320, 135, 4320, 4320, 4320, 66, 135, 4320, 66, 135, 66, 135, 66, 66, 135, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 135, 66, 66, 66, 66, 66, 4320, 66, 135, 66, 4320, 4320, 66, 4320, 66, 135, 135, 4320, 66, 66, 66, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 66, 4320, 135, 135, 135, 4320, 135, 66, 135, 4320, 4320, 135, 4320, 135, 66, 4320, 135, 66, 135, 135, 66, 135, 4320, 66, 135, 4320, 66, 135, 4320, 4320, 135, 66, 4320, 135, 66, 66, 135, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 135, 66, 4320, 4320, 135, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 135, 135, 135, 135, 135, 135, 66, 4320, 135, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 135, 135, 4320, 135, 66, 66]
Prompts retrieved: 289344 . Total input tokens: 64591017 . Total output tokens: 57818491
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.721672649029642,
    "estimated_duration": 3600.078550295782,
    "input_throughput": 5346.7416699612095,
    "output_throughput": 4751.133832508933,
    "total_throughput": 10097.875502470142,
    "itl": 179.71565125878485,
    "ttft": 947011.4885546468,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1965,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.875448829482603,
    "arrivals": 96558,
    "finished_requests": 77887,
    "scheduler_time": 80.57394843430038
}
#Debug simulation 
Total elapsed time: 5.721813670825213. Arrivals time: 0.21786965057253838 Scheduler time: 5.391990051139146 Scheduler overhead time: 0.03221599059179425 Adapter cache time: 0.03196943365037441 Engine time: 0.0327831981703639 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-32/adapters_192_slots_96_rate_0.4-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-32/adapters_192_slots_96_rate_0.4-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 135, 135, 135, 135, 4320, 135, 66, 4320, 66, 135, 135, 66, 4320, 4320, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 4320, 135, 66, 135, 4320, 4320, 135, 4320, 66, 135, 135, 4320, 135, 66, 66, 135, 4320, 66, 135, 66, 4320, 4320, 135, 4320, 4320, 4320, 66, 135, 4320, 66, 135, 66, 135, 66, 66, 135, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 135, 66, 66, 66, 66, 66, 4320, 66, 135, 66, 4320, 4320, 66, 4320, 66, 135, 135, 4320, 66, 66, 66, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 66, 4320, 135, 135, 135, 4320, 135, 66, 135, 4320, 4320, 135, 4320, 135, 66, 4320, 135, 66, 135, 135, 66, 135, 4320, 66, 135, 4320, 66, 135, 4320, 4320, 135, 66, 4320, 135, 66, 66, 135, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 135, 66, 4320, 4320, 135, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 135, 135, 135, 135, 135, 135, 66, 4320, 135, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 135, 135, 4320, 135, 66, 66]
Prompts retrieved: 289344 . Total input tokens: 64591017 . Total output tokens: 57818491
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.6572582218796015,
    "estimated_duration": 3600.136757949169,
    "input_throughput": 5328.671461616421,
    "output_throughput": 4735.23900511801,
    "total_throughput": 10063.91046673443,
    "itl": 177.49607596527682,
    "ttft": 959043.8702646046,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2013,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.758600191063971,
    "arrivals": 96558,
    "finished_requests": 77641,
    "scheduler_time": 80.71536776115236
}
#Debug simulation 
Total elapsed time: 5.6573684848845005. Arrivals time: 0.21686665061861277 Scheduler time: 5.327930586412549 Scheduler overhead time: 0.03255216404795647 Adapter cache time: 0.032083154655992985 Engine time: 0.0329122468829155 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_192_slots_96_rate_0.4-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_192_slots_96_rate_0.4-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 135, 135, 135, 135, 4320, 135, 33, 4320, 33, 135, 135, 33, 4320, 4320, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 4320, 135, 33, 135, 4320, 4320, 135, 4320, 33, 135, 135, 4320, 135, 33, 33, 135, 4320, 33, 135, 33, 4320, 4320, 135, 4320, 4320, 4320, 33, 135, 4320, 33, 135, 33, 135, 33, 33, 135, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 135, 33, 33, 33, 33, 33, 4320, 33, 135, 33, 4320, 4320, 33, 4320, 33, 135, 135, 4320, 33, 33, 33, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 33, 4320, 135, 135, 135, 4320, 135, 33, 135, 4320, 4320, 135, 4320, 135, 33, 4320, 135, 33, 135, 135, 33, 135, 4320, 33, 135, 4320, 33, 135, 4320, 4320, 135, 33, 4320, 135, 33, 33, 135, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 135, 33, 4320, 4320, 135, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 135, 135, 135, 135, 135, 135, 33, 4320, 135, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 135, 135, 4320, 135, 33, 33]
Prompts retrieved: 287232 . Total input tokens: 64128402 . Total output tokens: 57391951
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.628275209106505,
    "estimated_duration": 3600.1050685188097,
    "input_throughput": 5486.881805959934,
    "output_throughput": 4779.985215009313,
    "total_throughput": 10266.867020969248,
    "itl": 176.47567550039395,
    "ttft": 853934.936674007,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2045,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.258697436342663,
    "arrivals": 95849,
    "finished_requests": 79330,
    "scheduler_time": 79.6451962296704
}
#Debug simulation 
Total elapsed time: 5.628383318893611. Arrivals time: 0.21891829557716846 Scheduler time: 5.296767072286457 Scheduler overhead time: 0.032132670283317566 Adapter cache time: 0.03264366649091244 Engine time: 0.03298260271549225 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_192_slots_96_rate_0.4-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_192_slots_96_rate_0.4-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 135, 135, 135, 135, 4320, 135, 33, 4320, 33, 135, 135, 33, 4320, 4320, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 4320, 135, 33, 135, 4320, 4320, 135, 4320, 33, 135, 135, 4320, 135, 33, 33, 135, 4320, 33, 135, 33, 4320, 4320, 135, 4320, 4320, 4320, 33, 135, 4320, 33, 135, 33, 135, 33, 33, 135, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 135, 33, 33, 33, 33, 33, 4320, 33, 135, 33, 4320, 4320, 33, 4320, 33, 135, 135, 4320, 33, 33, 33, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 33, 4320, 135, 135, 135, 4320, 135, 33, 135, 4320, 4320, 135, 4320, 135, 33, 4320, 135, 33, 135, 135, 33, 135, 4320, 33, 135, 4320, 33, 135, 4320, 4320, 135, 33, 4320, 135, 33, 33, 135, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 135, 33, 4320, 4320, 135, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 135, 135, 135, 135, 135, 135, 33, 4320, 135, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 135, 135, 4320, 135, 33, 33]
Prompts retrieved: 287232 . Total input tokens: 64128402 . Total output tokens: 57391951
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.626120239961892,
    "estimated_duration": 3600.061534557497,
    "input_throughput": 5486.390388165336,
    "output_throughput": 4779.504137591066,
    "total_throughput": 10265.894525756401,
    "itl": 176.4961078119791,
    "ttft": 854385.6463284047,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2048,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.694839259139026,
    "arrivals": 95849,
    "finished_requests": 79319,
    "scheduler_time": 79.64267918634107
}
#Debug simulation 
Total elapsed time: 5.626288230996579. Arrivals time: 0.21559268841519952 Scheduler time: 5.298011131584644 Scheduler overhead time: 0.03203515987843275 Adapter cache time: 0.03259149147197604 Engine time: 0.03303626738488674 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-32/adapters_192_slots_96_rate_0.4-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-32/adapters_192_slots_96_rate_0.4-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 135, 135, 135, 135, 4320, 135, 33, 4320, 33, 135, 135, 33, 4320, 4320, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 4320, 135, 33, 135, 4320, 4320, 135, 4320, 33, 135, 135, 4320, 135, 33, 33, 135, 4320, 33, 135, 33, 4320, 4320, 135, 4320, 4320, 4320, 33, 135, 4320, 33, 135, 33, 135, 33, 33, 135, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 135, 33, 33, 33, 33, 33, 4320, 33, 135, 33, 4320, 4320, 33, 4320, 33, 135, 135, 4320, 33, 33, 33, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 33, 4320, 135, 135, 135, 4320, 135, 33, 135, 4320, 4320, 135, 4320, 135, 33, 4320, 135, 33, 135, 135, 33, 135, 4320, 33, 135, 4320, 33, 135, 4320, 4320, 135, 33, 4320, 135, 33, 33, 135, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 135, 33, 4320, 4320, 135, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 135, 135, 135, 135, 135, 135, 33, 4320, 135, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 135, 135, 4320, 135, 33, 33]
Prompts retrieved: 287232 . Total input tokens: 64128402 . Total output tokens: 57391951
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.651731925085187,
    "estimated_duration": 3600.10060735162,
    "input_throughput": 5481.188764476299,
    "output_throughput": 4775.129607460153,
    "total_throughput": 10256.318371936452,
    "itl": 174.94706652879387,
    "ttft": 858466.370585115,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2050,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.710348389837847,
    "arrivals": 95849,
    "finished_requests": 79243,
    "scheduler_time": 79.73722839825366
}
#Debug simulation 
Total elapsed time: 5.651872684713453. Arrivals time: 0.21590474620461464 Scheduler time: 5.322117368225008 Scheduler overhead time: 0.03244720073416829 Adapter cache time: 0.03314230125397444 Engine time: 0.033237408846616745 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_192_slots_96_rate_0.4-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_192_slots_96_rate_0.4-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 135, 135, 135, 135, 4320, 135, 33, 4320, 33, 135, 135, 33, 4320, 4320, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 4320, 135, 33, 135, 4320, 4320, 135, 4320, 33, 135, 135, 4320, 135, 33, 33, 135, 4320, 33, 135, 33, 4320, 4320, 135, 4320, 4320, 4320, 33, 135, 4320, 33, 135, 33, 135, 33, 33, 135, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 135, 33, 33, 33, 33, 33, 4320, 33, 135, 33, 4320, 4320, 33, 4320, 33, 135, 135, 4320, 33, 33, 33, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 33, 4320, 135, 135, 135, 4320, 135, 33, 135, 4320, 4320, 135, 4320, 135, 33, 4320, 135, 33, 135, 135, 33, 135, 4320, 33, 135, 4320, 33, 135, 4320, 4320, 135, 33, 4320, 135, 33, 33, 135, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 135, 33, 4320, 4320, 135, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 135, 135, 135, 135, 135, 135, 33, 4320, 135, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 135, 135, 4320, 135, 33, 33]
Prompts retrieved: 287232 . Total input tokens: 64128402 . Total output tokens: 57391951
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 5.6280194711871445,
    "estimated_duration": 3600.107913048661,
    "input_throughput": 5486.716642133336,
    "output_throughput": 4779.961716599633,
    "total_throughput": 10266.678358732968,
    "itl": 176.485098711028,
    "ttft": 854080.5275517004,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2048,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.394521700085407,
    "arrivals": 95849,
    "finished_requests": 79327,
    "scheduler_time": 79.6445761497105
}
#Debug simulation 
Total elapsed time: 5.628122962079942. Arrivals time: 0.20791111420840025 Scheduler time: 5.30671475501731 Scheduler overhead time: 0.0324072171933949 Adapter cache time: 0.032992010936141014 Engine time: 0.03309705760329962 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-32/adapters_192_slots_96_rate_0.4-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-32/adapters_192_slots_96_rate_0.4-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 135, 135, 135, 135, 4320, 135, 33, 4320, 33, 135, 135, 33, 4320, 4320, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 4320, 135, 33, 135, 4320, 4320, 135, 4320, 33, 135, 135, 4320, 135, 33, 33, 135, 4320, 33, 135, 33, 4320, 4320, 135, 4320, 4320, 4320, 33, 135, 4320, 33, 135, 33, 135, 33, 33, 135, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 135, 33, 33, 33, 33, 33, 4320, 33, 135, 33, 4320, 4320, 33, 4320, 33, 135, 135, 4320, 33, 33, 33, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 33, 4320, 135, 135, 135, 4320, 135, 33, 135, 4320, 4320, 135, 4320, 135, 33, 4320, 135, 33, 135, 135, 33, 135, 4320, 33, 135, 4320, 33, 135, 4320, 4320, 135, 33, 4320, 135, 33, 33, 135, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 135, 33, 4320, 4320, 135, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 135, 135, 135, 135, 135, 135, 33, 4320, 135, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 135, 135, 4320, 135, 33, 33]
Prompts retrieved: 287232 . Total input tokens: 64128402 . Total output tokens: 57391951
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 5.632304269820452,
    "estimated_duration": 3600.001777998871,
    "input_throughput": 5480.937293027689,
    "output_throughput": 4774.964030588707,
    "total_throughput": 10255.901323616396,
    "itl": 174.9491379614425,
    "ttft": 858552.3157191548,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2050,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.8026516690662655,
    "arrivals": 95849,
    "finished_requests": 79238,
    "scheduler_time": 79.73454440372309
}
#Debug simulation 
Total elapsed time: 5.632413853891194. Arrivals time: 0.2146444940008223 Scheduler time: 5.304250962566584 Scheduler overhead time: 0.03230713214725256 Adapter cache time: 0.03275104658678174 Engine time: 0.03337431652471423 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_192_slots_96_rate_0.4-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_192_slots_96_rate_0.4-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 135, 135, 135, 135, 4320, 135, 33, 4320, 33, 135, 135, 33, 4320, 4320, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 4320, 135, 33, 135, 4320, 4320, 135, 4320, 33, 135, 135, 4320, 135, 33, 33, 135, 4320, 33, 135, 33, 4320, 4320, 135, 4320, 4320, 4320, 33, 135, 4320, 33, 135, 33, 135, 33, 33, 135, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 135, 33, 33, 33, 33, 33, 4320, 33, 135, 33, 4320, 4320, 33, 4320, 33, 135, 135, 4320, 33, 33, 33, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 33, 4320, 135, 135, 135, 4320, 135, 33, 135, 4320, 4320, 135, 4320, 135, 33, 4320, 135, 33, 135, 135, 33, 135, 4320, 33, 135, 4320, 33, 135, 4320, 4320, 135, 33, 4320, 135, 33, 33, 135, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 135, 33, 4320, 4320, 135, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 135, 135, 135, 135, 135, 135, 33, 4320, 135, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 135, 135, 4320, 135, 33, 33]
Prompts retrieved: 287232 . Total input tokens: 64128402 . Total output tokens: 57391951
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.611984814982861,
    "estimated_duration": 3600.0890311653943,
    "input_throughput": 5486.906526199323,
    "output_throughput": 4780.1209500725245,
    "total_throughput": 10267.027476271847,
    "itl": 176.4676790981553,
    "ttft": 853834.065610948,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2048,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.123623003959475,
    "arrivals": 95849,
    "finished_requests": 79331,
    "scheduler_time": 79.6450105976489
}
#Debug simulation 
Total elapsed time: 5.612110042013228. Arrivals time: 0.22047384921461344 Scheduler time: 5.278077164199203 Scheduler overhead time: 0.032316484954208136 Adapter cache time: 0.032732484862208366 Engine time: 0.03349869651719928 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-32/adapters_192_slots_96_rate_0.4-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-32/adapters_192_slots_96_rate_0.4-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 135, 135, 135, 135, 4320, 135, 33, 4320, 33, 135, 135, 33, 4320, 4320, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 4320, 135, 33, 135, 4320, 4320, 135, 4320, 33, 135, 135, 4320, 135, 33, 33, 135, 4320, 33, 135, 33, 4320, 4320, 135, 4320, 4320, 4320, 33, 135, 4320, 33, 135, 33, 135, 33, 33, 135, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 135, 33, 33, 33, 33, 33, 4320, 33, 135, 33, 4320, 4320, 33, 4320, 33, 135, 135, 4320, 33, 33, 33, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 33, 4320, 135, 135, 135, 4320, 135, 33, 135, 4320, 4320, 135, 4320, 135, 33, 4320, 135, 33, 135, 135, 33, 135, 4320, 33, 135, 4320, 33, 135, 4320, 4320, 135, 33, 4320, 135, 33, 33, 135, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 135, 33, 4320, 4320, 135, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 135, 135, 135, 135, 135, 135, 33, 4320, 135, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 135, 135, 4320, 135, 33, 33]
Prompts retrieved: 287232 . Total input tokens: 64128402 . Total output tokens: 57391951
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.594763267785311,
    "estimated_duration": 3600.121904860441,
    "input_throughput": 5480.881070543889,
    "output_throughput": 4774.881921857137,
    "total_throughput": 10255.762992401025,
    "itl": 174.95408149320534,
    "ttft": 858625.0007551013,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2050,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.886026429459231,
    "arrivals": 95849,
    "finished_requests": 79240,
    "scheduler_time": 79.73697661135027
}
#Debug simulation 
Total elapsed time: 5.594870971050113. Arrivals time: 0.22389640798792243 Scheduler time: 5.257618555333465 Scheduler overhead time: 0.03221642877906561 Adapter cache time: 0.03257231181487441 Engine time: 0.03353231633082032 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_192_slots_96_rate_0.4-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_192_slots_96_rate_0.4-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 66, 66, 66, 66, 4320, 66, 33, 4320, 33, 66, 66, 33, 4320, 4320, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 4320, 66, 33, 66, 4320, 4320, 66, 4320, 33, 66, 66, 4320, 66, 33, 33, 66, 4320, 33, 66, 33, 4320, 4320, 66, 4320, 4320, 4320, 33, 66, 4320, 33, 66, 33, 66, 33, 33, 66, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 66, 33, 33, 33, 33, 33, 4320, 33, 66, 33, 4320, 4320, 33, 4320, 33, 66, 66, 4320, 33, 33, 33, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 33, 4320, 66, 66, 66, 4320, 66, 33, 66, 4320, 4320, 66, 4320, 66, 33, 4320, 66, 33, 66, 66, 33, 66, 4320, 33, 66, 4320, 33, 66, 4320, 4320, 66, 33, 4320, 66, 33, 33, 66, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 66, 33, 4320, 4320, 66, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 66, 66, 66, 66, 66, 66, 33, 4320, 66, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 66, 66, 4320, 66, 33, 33]
Prompts retrieved: 282816 . Total input tokens: 63124961 . Total output tokens: 56509939
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.896104712039232,
    "estimated_duration": 3600.070251864663,
    "input_throughput": 5756.261281086532,
    "output_throughput": 5034.922857578005,
    "total_throughput": 10791.184138664537,
    "itl": 167.16027873906225,
    "ttft": 620750.7638969637,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1482,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.535642836508463,
    "arrivals": 94443,
    "finished_requests": 82865,
    "scheduler_time": 79.88995749533258
}
#Debug simulation 
Total elapsed time: 5.896219674963504. Arrivals time: 0.20580125926062465 Scheduler time: 5.580071676056832 Scheduler overhead time: 0.03321074042469263 Adapter cache time: 0.02720382669940591 Engine time: 0.03454365395009518 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_192_slots_96_rate_0.4-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_192_slots_96_rate_0.4-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 66, 66, 66, 66, 4320, 66, 33, 4320, 33, 66, 66, 33, 4320, 4320, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 4320, 66, 33, 66, 4320, 4320, 66, 4320, 33, 66, 66, 4320, 66, 33, 33, 66, 4320, 33, 66, 33, 4320, 4320, 66, 4320, 4320, 4320, 33, 66, 4320, 33, 66, 33, 66, 33, 33, 66, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 66, 33, 33, 33, 33, 33, 4320, 33, 66, 33, 4320, 4320, 33, 4320, 33, 66, 66, 4320, 33, 33, 33, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 33, 4320, 66, 66, 66, 4320, 66, 33, 66, 4320, 4320, 66, 4320, 66, 33, 4320, 66, 33, 66, 66, 33, 66, 4320, 33, 66, 4320, 33, 66, 4320, 4320, 66, 33, 4320, 66, 33, 33, 66, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 66, 33, 4320, 4320, 66, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 66, 66, 66, 66, 66, 66, 33, 4320, 66, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 66, 66, 4320, 66, 33, 33]
Prompts retrieved: 282816 . Total input tokens: 63124961 . Total output tokens: 56509939
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.874834695830941,
    "estimated_duration": 3600.146510512047,
    "input_throughput": 5755.808531540222,
    "output_throughput": 5034.424556633429,
    "total_throughput": 10790.233088173653,
    "itl": 167.17633304035806,
    "ttft": 621238.7167310218,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1480,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.826106443845132,
    "arrivals": 94443,
    "finished_requests": 82858,
    "scheduler_time": 79.89141382973096
}
#Debug simulation 
Total elapsed time: 5.874944377690554. Arrivals time: 0.21389036485925317 Scheduler time: 5.5500177731737494 Scheduler overhead time: 0.033305748365819454 Adapter cache time: 0.02735207276418805 Engine time: 0.034820029977709055 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-32/adapters_192_slots_96_rate_0.4-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-32/adapters_192_slots_96_rate_0.4-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 66, 66, 66, 66, 4320, 66, 33, 4320, 33, 66, 66, 33, 4320, 4320, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 4320, 66, 33, 66, 4320, 4320, 66, 4320, 33, 66, 66, 4320, 66, 33, 33, 66, 4320, 33, 66, 33, 4320, 4320, 66, 4320, 4320, 4320, 33, 66, 4320, 33, 66, 33, 66, 33, 33, 66, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 66, 33, 33, 33, 33, 33, 4320, 33, 66, 33, 4320, 4320, 33, 4320, 33, 66, 66, 4320, 33, 33, 33, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 33, 4320, 66, 66, 66, 4320, 66, 33, 66, 4320, 4320, 66, 4320, 66, 33, 4320, 66, 33, 66, 66, 33, 66, 4320, 33, 66, 4320, 33, 66, 4320, 4320, 66, 33, 4320, 66, 33, 33, 66, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 66, 33, 4320, 4320, 66, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 66, 66, 66, 66, 66, 66, 33, 4320, 66, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 66, 66, 4320, 66, 33, 33]
Prompts retrieved: 282816 . Total input tokens: 63124961 . Total output tokens: 56509939
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.856540087610483,
    "estimated_duration": 3600.0794271968048,
    "input_throughput": 5746.98848133746,
    "output_throughput": 5026.930479167641,
    "total_throughput": 10773.918960505101,
    "itl": 165.05922134556909,
    "ttft": 627845.2820339645,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1483,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.8437037498689595,
    "arrivals": 94443,
    "finished_requests": 82728,
    "scheduler_time": 79.98315368632643
}
#Debug simulation 
Total elapsed time: 5.856668327003717. Arrivals time: 0.21216969983652234 Scheduler time: 5.532292063813657 Scheduler overhead time: 0.033746537286788225 Adapter cache time: 0.02779420418664813 Engine time: 0.03495283704251051 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_192_slots_96_rate_0.4-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_192_slots_96_rate_0.4-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 66, 66, 66, 66, 4320, 66, 33, 4320, 33, 66, 66, 33, 4320, 4320, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 4320, 66, 33, 66, 4320, 4320, 66, 4320, 33, 66, 66, 4320, 66, 33, 33, 66, 4320, 33, 66, 33, 4320, 4320, 66, 4320, 4320, 4320, 33, 66, 4320, 33, 66, 33, 66, 33, 33, 66, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 66, 33, 33, 33, 33, 33, 4320, 33, 66, 33, 4320, 4320, 33, 4320, 33, 66, 66, 4320, 33, 33, 33, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 33, 4320, 66, 66, 66, 4320, 66, 33, 66, 4320, 4320, 66, 4320, 66, 33, 4320, 66, 33, 66, 66, 33, 66, 4320, 33, 66, 4320, 33, 66, 4320, 4320, 66, 33, 4320, 66, 33, 33, 66, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 66, 33, 4320, 4320, 66, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 66, 66, 66, 66, 66, 66, 33, 4320, 66, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 66, 66, 4320, 66, 33, 33]
Prompts retrieved: 282816 . Total input tokens: 63124961 . Total output tokens: 56509939
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 5.7929164888337255,
    "estimated_duration": 3600.068910660851,
    "input_throughput": 5756.005374962708,
    "output_throughput": 5034.534185256171,
    "total_throughput": 10790.53956021888,
    "itl": 167.16572379284534,
    "ttft": 620969.594974022,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1481,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.621121477053878,
    "arrivals": 94443,
    "finished_requests": 82860,
    "scheduler_time": 79.88975560818275
}
#Debug simulation 
Total elapsed time: 5.793022543657571. Arrivals time: 0.2091909907758236 Scheduler time: 5.474256828892976 Scheduler overhead time: 0.033127573784440756 Adapter cache time: 0.026870237197726965 Engine time: 0.034234975930303335 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-32/adapters_192_slots_96_rate_0.4-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-32/adapters_192_slots_96_rate_0.4-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 66, 66, 66, 66, 4320, 66, 33, 4320, 33, 66, 66, 33, 4320, 4320, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 4320, 66, 33, 66, 4320, 4320, 66, 4320, 33, 66, 66, 4320, 66, 33, 33, 66, 4320, 33, 66, 33, 4320, 4320, 66, 4320, 4320, 4320, 33, 66, 4320, 33, 66, 33, 66, 33, 33, 66, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 66, 33, 33, 33, 33, 33, 4320, 33, 66, 33, 4320, 4320, 33, 4320, 33, 66, 66, 4320, 33, 33, 33, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 33, 4320, 66, 66, 66, 4320, 66, 33, 66, 4320, 4320, 66, 4320, 66, 33, 4320, 66, 33, 66, 66, 33, 66, 4320, 33, 66, 4320, 33, 66, 4320, 4320, 66, 33, 4320, 66, 33, 33, 66, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 66, 33, 4320, 4320, 66, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 66, 66, 66, 66, 66, 66, 33, 4320, 66, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 66, 66, 4320, 66, 33, 33]
Prompts retrieved: 282816 . Total input tokens: 63124961 . Total output tokens: 56509939
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 5.900876028928906,
    "estimated_duration": 3600.0084737760026,
    "input_throughput": 5747.101194542171,
    "output_throughput": 5026.87844537724,
    "total_throughput": 10773.97963991941,
    "itl": 165.04594009608263,
    "ttft": 627908.991698866,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1483,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.907586673367729,
    "arrivals": 94443,
    "finished_requests": 82726,
    "scheduler_time": 79.98199600908538
}
#Debug simulation 
Total elapsed time: 5.900988317094743. Arrivals time: 0.2153469929471612 Scheduler time: 5.573572574183345 Scheduler overhead time: 0.03378797648474574 Adapter cache time: 0.02766159502789378 Engine time: 0.03487753635272384 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_192_slots_96_rate_0.4-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_192_slots_96_rate_0.4-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 66, 66, 66, 66, 4320, 66, 33, 4320, 33, 66, 66, 33, 4320, 4320, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 4320, 66, 33, 66, 4320, 4320, 66, 4320, 33, 66, 66, 4320, 66, 33, 33, 66, 4320, 33, 66, 33, 4320, 4320, 66, 4320, 4320, 4320, 33, 66, 4320, 33, 66, 33, 66, 33, 33, 66, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 66, 33, 33, 33, 33, 33, 4320, 33, 66, 33, 4320, 4320, 33, 4320, 33, 66, 66, 4320, 33, 33, 33, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 33, 4320, 66, 66, 66, 4320, 66, 33, 66, 4320, 4320, 66, 4320, 66, 33, 4320, 66, 33, 66, 66, 33, 66, 4320, 33, 66, 4320, 33, 66, 4320, 4320, 66, 33, 4320, 66, 33, 33, 66, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 66, 33, 4320, 4320, 66, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 66, 66, 66, 66, 66, 66, 33, 4320, 66, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 66, 66, 4320, 66, 33, 33]
Prompts retrieved: 282816 . Total input tokens: 63124961 . Total output tokens: 56509939
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 5.831216167658567,
    "estimated_duration": 3600.1203703200913,
    "input_throughput": 5756.803903242073,
    "output_throughput": 5035.185253649805,
    "total_throughput": 10791.98915689188,
    "itl": 167.15652449889143,
    "ttft": 620635.1396422815,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1480,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.4252744364550995,
    "arrivals": 94443,
    "finished_requests": 82870,
    "scheduler_time": 79.89159615885185
}
#Debug simulation 
Total elapsed time: 5.831320290919393. Arrivals time: 0.2107624993659556 Scheduler time: 5.510567256715149 Scheduler overhead time: 0.03319055214524269 Adapter cache time: 0.027084833476692438 Engine time: 0.03427363373339176 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-32/adapters_192_slots_96_rate_0.4-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-32/adapters_192_slots_96_rate_0.4-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 66, 66, 66, 66, 4320, 66, 33, 4320, 33, 66, 66, 33, 4320, 4320, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 4320, 66, 33, 66, 4320, 4320, 66, 4320, 33, 66, 66, 4320, 66, 33, 33, 66, 4320, 33, 66, 33, 4320, 4320, 66, 4320, 4320, 4320, 33, 66, 4320, 33, 66, 33, 66, 33, 33, 66, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 66, 33, 33, 33, 33, 33, 4320, 33, 66, 33, 4320, 4320, 33, 4320, 33, 66, 66, 4320, 33, 33, 33, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 33, 4320, 66, 66, 66, 4320, 66, 33, 66, 4320, 4320, 66, 4320, 66, 33, 4320, 66, 33, 66, 66, 33, 66, 4320, 33, 66, 4320, 33, 66, 4320, 4320, 66, 33, 4320, 66, 33, 33, 66, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 66, 33, 4320, 4320, 66, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 66, 66, 66, 66, 66, 66, 33, 4320, 66, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 66, 66, 4320, 66, 33, 33]
Prompts retrieved: 282816 . Total input tokens: 63124961 . Total output tokens: 56509939
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.918683224823326,
    "estimated_duration": 3600.0336112109717,
    "input_throughput": 5747.061065088354,
    "output_throughput": 5026.843344918837,
    "total_throughput": 10773.904410007191,
    "itl": 165.05418774396645,
    "ttft": 627944.2452482604,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1483,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.966816706769132,
    "arrivals": 94443,
    "finished_requests": 82726,
    "scheduler_time": 79.9819426785462
}
#Debug simulation 
Total elapsed time: 5.9188095247372985. Arrivals time: 0.2135330713354051 Scheduler time: 5.592745000496507 Scheduler overhead time: 0.03386700013652444 Adapter cache time: 0.02792514907196164 Engine time: 0.034824518486857414 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_192_slots_96_rate_0.1-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_192_slots_96_rate_0.1-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [64 64 64]
Adapter prompts. [1080, 270, 1080, 270, 1080, 270, 1080, 270, 270, 270, 540, 540, 540, 540, 1080, 540, 270, 1080, 270, 540, 540, 270, 1080, 1080, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 1080, 540, 270, 540, 1080, 1080, 540, 1080, 270, 540, 540, 1080, 540, 270, 270, 540, 1080, 270, 540, 270, 1080, 1080, 540, 1080, 1080, 1080, 270, 540, 1080, 270, 540, 270, 540, 270, 270, 540, 1080, 1080, 270, 270, 270, 1080, 1080, 1080, 540, 270, 270, 270, 270, 270, 1080, 270, 540, 270, 1080, 1080, 270, 1080, 270, 540, 540, 1080, 270, 270, 270, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 270, 1080, 540, 540, 540, 1080, 540, 270, 540, 1080, 1080, 540, 1080, 540, 270, 1080, 540, 270, 540, 540, 270, 540, 1080, 270, 540, 1080, 270, 540, 1080, 1080, 540, 270, 1080, 540, 270, 270, 540, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 540, 270, 1080, 1080, 540, 1080, 270, 1080, 1080, 1080, 270, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 270, 1080, 540, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 540, 540, 1080, 540, 270, 270]
Prompts retrieved: 120960 . Total input tokens: 26955942 . Total output tokens: 24190742
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 3.348984234035015,
    "estimated_duration": 3599.7871399074215,
    "input_throughput": 2798.0634989042824,
    "output_throughput": 2443.267520597397,
    "total_throughput": 5241.331019501679,
    "itl": 55.67501114363633,
    "ttft": 15693.382877307726,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 14429,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 44.15977765719894,
    "arrivals": 40505,
    "finished_requests": 40339,
    "scheduler_time": 24.117647419389254
}
#Debug simulation 
Total elapsed time: 3.349108267109841. Arrivals time: 0.10551561927422881 Scheduler time: 2.8820884563028812 Scheduler overhead time: 0.07291712379083037 Adapter cache time: 0.18207380874082446 Engine time: 0.07223517447710037 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_192_slots_96_rate_0.1-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_192_slots_96_rate_0.1-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [64 64 64]
Adapter prompts. [1080, 270, 1080, 270, 1080, 270, 1080, 270, 270, 270, 540, 540, 540, 540, 1080, 540, 270, 1080, 270, 540, 540, 270, 1080, 1080, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 1080, 540, 270, 540, 1080, 1080, 540, 1080, 270, 540, 540, 1080, 540, 270, 270, 540, 1080, 270, 540, 270, 1080, 1080, 540, 1080, 1080, 1080, 270, 540, 1080, 270, 540, 270, 540, 270, 270, 540, 1080, 1080, 270, 270, 270, 1080, 1080, 1080, 540, 270, 270, 270, 270, 270, 1080, 270, 540, 270, 1080, 1080, 270, 1080, 270, 540, 540, 1080, 270, 270, 270, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 270, 1080, 540, 540, 540, 1080, 540, 270, 540, 1080, 1080, 540, 1080, 540, 270, 1080, 540, 270, 540, 540, 270, 540, 1080, 270, 540, 1080, 270, 540, 1080, 1080, 540, 270, 1080, 540, 270, 270, 540, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 540, 270, 1080, 1080, 540, 1080, 270, 1080, 1080, 1080, 270, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 270, 1080, 540, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 540, 540, 1080, 540, 270, 270]
Prompts retrieved: 120960 . Total input tokens: 26955942 . Total output tokens: 24190742
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 3.3763079536147416,
    "estimated_duration": 3599.7678048966927,
    "input_throughput": 2798.030746955096,
    "output_throughput": 2443.0959096964284,
    "total_throughput": 5241.126656651524,
    "itl": 55.77148265880475,
    "ttft": 15798.04446945524,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 14405,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 46.97171681258514,
    "arrivals": 40505,
    "finished_requests": 40338,
    "scheduler_time": 24.138530337264754
}
#Debug simulation 
Total elapsed time: 3.3764109439216554. Arrivals time: 0.10741738649085164 Scheduler time: 2.909492313861847 Scheduler overhead time: 0.07252254383638501 Adapter cache time: 0.1825173208490014 Engine time: 0.07045177696272731 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-32/adapters_192_slots_96_rate_0.1-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-32/adapters_192_slots_96_rate_0.1-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [64 64 64]
Adapter prompts. [1080, 270, 1080, 270, 1080, 270, 1080, 270, 270, 270, 540, 540, 540, 540, 1080, 540, 270, 1080, 270, 540, 540, 270, 1080, 1080, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 1080, 540, 270, 540, 1080, 1080, 540, 1080, 270, 540, 540, 1080, 540, 270, 270, 540, 1080, 270, 540, 270, 1080, 1080, 540, 1080, 1080, 1080, 270, 540, 1080, 270, 540, 270, 540, 270, 270, 540, 1080, 1080, 270, 270, 270, 1080, 1080, 1080, 540, 270, 270, 270, 270, 270, 1080, 270, 540, 270, 1080, 1080, 270, 1080, 270, 540, 540, 1080, 270, 270, 270, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 270, 1080, 540, 540, 540, 1080, 540, 270, 540, 1080, 1080, 540, 1080, 540, 270, 1080, 540, 270, 540, 540, 270, 540, 1080, 270, 540, 1080, 270, 540, 1080, 1080, 540, 270, 1080, 540, 270, 270, 540, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 540, 270, 1080, 1080, 540, 1080, 270, 1080, 1080, 1080, 270, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 270, 1080, 540, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 540, 540, 1080, 540, 270, 270]
Prompts retrieved: 120960 . Total input tokens: 26955942 . Total output tokens: 24190742
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 3.3760115448385477,
    "estimated_duration": 3599.8028739076162,
    "input_throughput": 2798.167108818888,
    "output_throughput": 2443.2776760502466,
    "total_throughput": 5241.444784869135,
    "itl": 55.7726693975759,
    "ttft": 15620.752477226888,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 14404,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 47.05686109048375,
    "arrivals": 40505,
    "finished_requests": 40340,
    "scheduler_time": 24.139264238253585
}
#Debug simulation 
Total elapsed time: 3.3761111716739833. Arrivals time: 0.10689925402402878 Scheduler time: 2.9099520947784185 Scheduler overhead time: 0.07251960039138794 Adapter cache time: 0.18312340090051293 Engine time: 0.06983519392088056 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_192_slots_96_rate_0.1-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_192_slots_96_rate_0.1-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [64 64 64]
Adapter prompts. [1080, 270, 1080, 270, 1080, 270, 1080, 270, 270, 270, 540, 540, 540, 540, 1080, 540, 270, 1080, 270, 540, 540, 270, 1080, 1080, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 1080, 540, 270, 540, 1080, 1080, 540, 1080, 270, 540, 540, 1080, 540, 270, 270, 540, 1080, 270, 540, 270, 1080, 1080, 540, 1080, 1080, 1080, 270, 540, 1080, 270, 540, 270, 540, 270, 270, 540, 1080, 1080, 270, 270, 270, 1080, 1080, 1080, 540, 270, 270, 270, 270, 270, 1080, 270, 540, 270, 1080, 1080, 270, 1080, 270, 540, 540, 1080, 270, 270, 270, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 270, 1080, 540, 540, 540, 1080, 540, 270, 540, 1080, 1080, 540, 1080, 540, 270, 1080, 540, 270, 540, 540, 270, 540, 1080, 270, 540, 1080, 270, 540, 1080, 1080, 540, 270, 1080, 540, 270, 270, 540, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 540, 270, 1080, 1080, 540, 1080, 270, 1080, 1080, 1080, 270, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 270, 1080, 540, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 540, 540, 1080, 540, 270, 270]
Prompts retrieved: 120960 . Total input tokens: 26955942 . Total output tokens: 24190742
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 3.402943808119744,
    "estimated_duration": 3599.7754265192416,
    "input_throughput": 2798.072603584445,
    "output_throughput": 2443.275470799147,
    "total_throughput": 5241.348074383592,
    "itl": 55.7065024420141,
    "ttft": 15698.333182842423,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 14423,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 45.09165607571523,
    "arrivals": 40505,
    "finished_requests": 40339,
    "scheduler_time": 24.124621958350797
}
#Debug simulation 
Total elapsed time: 3.4030892900191247. Arrivals time: 0.1071009412407875 Scheduler time: 2.933449888601899 Scheduler overhead time: 0.07295724144205451 Adapter cache time: 0.18356520030647516 Engine time: 0.07193736685439944 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-32/adapters_192_slots_96_rate_0.1-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-32/adapters_192_slots_96_rate_0.1-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [64 64 64]
Adapter prompts. [1080, 270, 1080, 270, 1080, 270, 1080, 270, 270, 270, 540, 540, 540, 540, 1080, 540, 270, 1080, 270, 540, 540, 270, 1080, 1080, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 1080, 540, 270, 540, 1080, 1080, 540, 1080, 270, 540, 540, 1080, 540, 270, 270, 540, 1080, 270, 540, 270, 1080, 1080, 540, 1080, 1080, 1080, 270, 540, 1080, 270, 540, 270, 540, 270, 270, 540, 1080, 1080, 270, 270, 270, 1080, 1080, 1080, 540, 270, 270, 270, 270, 270, 1080, 270, 540, 270, 1080, 1080, 270, 1080, 270, 540, 540, 1080, 270, 270, 270, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 270, 1080, 540, 540, 540, 1080, 540, 270, 540, 1080, 1080, 540, 1080, 540, 270, 1080, 540, 270, 540, 540, 270, 540, 1080, 270, 540, 1080, 270, 540, 1080, 1080, 540, 270, 1080, 540, 270, 270, 540, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 540, 270, 1080, 1080, 540, 1080, 270, 1080, 1080, 1080, 270, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 270, 1080, 540, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 540, 540, 1080, 540, 270, 270]
Prompts retrieved: 120960 . Total input tokens: 26955942 . Total output tokens: 24190742
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 3.3720308942720294,
    "estimated_duration": 3599.8049132206143,
    "input_throughput": 2798.165523638943,
    "output_throughput": 2443.2762919174834,
    "total_throughput": 5241.441815556426,
    "itl": 55.792899705993996,
    "ttft": 15624.756780813332,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 14403,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 47.65136526300217,
    "arrivals": 40505,
    "finished_requests": 40340,
    "scheduler_time": 24.143949328616802
}
#Debug simulation 
Total elapsed time: 3.372136464342475. Arrivals time: 0.10824682610109448 Scheduler time: 2.902470922563225 Scheduler overhead time: 0.0725396191701293 Adapter cache time: 0.184235495980829 Engine time: 0.07104297634214163 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_192_slots_96_rate_0.1-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_192_slots_96_rate_0.1-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [64 64 64]
Adapter prompts. [1080, 270, 1080, 270, 1080, 270, 1080, 270, 270, 270, 540, 540, 540, 540, 1080, 540, 270, 1080, 270, 540, 540, 270, 1080, 1080, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 1080, 540, 270, 540, 1080, 1080, 540, 1080, 270, 540, 540, 1080, 540, 270, 270, 540, 1080, 270, 540, 270, 1080, 1080, 540, 1080, 1080, 1080, 270, 540, 1080, 270, 540, 270, 540, 270, 270, 540, 1080, 1080, 270, 270, 270, 1080, 1080, 1080, 540, 270, 270, 270, 270, 270, 1080, 270, 540, 270, 1080, 1080, 270, 1080, 270, 540, 540, 1080, 270, 270, 270, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 270, 1080, 540, 540, 540, 1080, 540, 270, 540, 1080, 1080, 540, 1080, 540, 270, 1080, 540, 270, 540, 540, 270, 540, 1080, 270, 540, 1080, 270, 540, 1080, 1080, 540, 270, 1080, 540, 270, 270, 540, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 540, 270, 1080, 1080, 540, 1080, 270, 1080, 1080, 1080, 270, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 270, 1080, 540, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 540, 540, 1080, 540, 270, 270]
Prompts retrieved: 120960 . Total input tokens: 26955942 . Total output tokens: 24190742
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 3.4020257010124624,
    "estimated_duration": 3599.7617306557945,
    "input_throughput": 2798.0832492946784,
    "output_throughput": 2443.2847666275143,
    "total_throughput": 5241.368015922192,
    "itl": 55.64008481747233,
    "ttft": 15687.080198199114,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 14439,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 43.17333620809859,
    "arrivals": 40505,
    "finished_requests": 40339,
    "scheduler_time": 24.10985428100139
}
#Debug simulation 
Total elapsed time: 3.4021399337798357. Arrivals time: 0.10971743613481522 Scheduler time: 2.9306008787825704 Scheduler overhead time: 0.07294447207823396 Adapter cache time: 0.18351858714595437 Engine time: 0.07118625473231077 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-32/adapters_192_slots_96_rate_0.1-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-32/adapters_192_slots_96_rate_0.1-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [64 64 64]
Adapter prompts. [1080, 270, 1080, 270, 1080, 270, 1080, 270, 270, 270, 540, 540, 540, 540, 1080, 540, 270, 1080, 270, 540, 540, 270, 1080, 1080, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 1080, 540, 270, 540, 1080, 1080, 540, 1080, 270, 540, 540, 1080, 540, 270, 270, 540, 1080, 270, 540, 270, 1080, 1080, 540, 1080, 1080, 1080, 270, 540, 1080, 270, 540, 270, 540, 270, 270, 540, 1080, 1080, 270, 270, 270, 1080, 1080, 1080, 540, 270, 270, 270, 270, 270, 1080, 270, 540, 270, 1080, 1080, 270, 1080, 270, 540, 540, 1080, 270, 270, 270, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 270, 1080, 540, 540, 540, 1080, 540, 270, 540, 1080, 1080, 540, 1080, 540, 270, 1080, 540, 270, 540, 540, 270, 540, 1080, 270, 540, 1080, 270, 540, 1080, 1080, 540, 270, 1080, 540, 270, 270, 540, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 540, 270, 1080, 1080, 540, 1080, 270, 1080, 1080, 1080, 270, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 270, 1080, 540, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 540, 540, 1080, 540, 270, 270]
Prompts retrieved: 120960 . Total input tokens: 26955942 . Total output tokens: 24190742
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 3.378415140323341,
    "estimated_duration": 3599.7916102324607,
    "input_throughput": 2798.012243644729,
    "output_throughput": 2443.0797535616457,
    "total_throughput": 5241.091997206375,
    "itl": 55.81386713142656,
    "ttft": 15805.889639534373,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 14399,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 48.24343813132648,
    "arrivals": 40505,
    "finished_requests": 40338,
    "scheduler_time": 24.14824487682756
}
#Debug simulation 
Total elapsed time: 3.3785165110602975. Arrivals time: 0.10776941059157252 Scheduler time: 2.9083140189759433 Scheduler overhead time: 0.07279668236151338 Adapter cache time: 0.18377575743943453 Engine time: 0.07167924707755446 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_192_slots_96_rate_0.1-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_192_slots_96_rate_0.1-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [64 64 64]
Adapter prompts. [1080, 135, 1080, 135, 1080, 135, 1080, 135, 135, 135, 540, 540, 540, 540, 1080, 540, 135, 1080, 135, 540, 540, 135, 1080, 1080, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 1080, 540, 135, 540, 1080, 1080, 540, 1080, 135, 540, 540, 1080, 540, 135, 135, 540, 1080, 135, 540, 135, 1080, 1080, 540, 1080, 1080, 1080, 135, 540, 1080, 135, 540, 135, 540, 135, 135, 540, 1080, 1080, 135, 135, 135, 1080, 1080, 1080, 540, 135, 135, 135, 135, 135, 1080, 135, 540, 135, 1080, 1080, 135, 1080, 135, 540, 540, 1080, 135, 135, 135, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 135, 1080, 540, 540, 540, 1080, 540, 135, 540, 1080, 1080, 540, 1080, 540, 135, 1080, 540, 135, 540, 540, 135, 540, 1080, 135, 540, 1080, 135, 540, 1080, 1080, 540, 135, 1080, 540, 135, 135, 540, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 540, 135, 1080, 1080, 540, 1080, 135, 1080, 1080, 1080, 135, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 135, 1080, 540, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 540, 540, 1080, 540, 135, 135]
Prompts retrieved: 112320 . Total input tokens: 25029474 . Total output tokens: 22460635
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 3.100084717851132,
    "estimated_duration": 3600.002081837182,
    "input_throughput": 2583.542950412285,
    "output_throughput": 2337.7247592326876,
    "total_throughput": 4921.2677096449725,
    "itl": 49.55115115658013,
    "ttft": 8248.996136151512,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12455,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 38.11837485068073,
    "arrivals": 37714,
    "finished_requests": 37628,
    "scheduler_time": 20.879662723845883
}
#Debug simulation 
Total elapsed time: 3.100188259035349. Arrivals time: 0.09875869937241077 Scheduler time: 2.6349584087729454 Scheduler overhead time: 0.07710757944732904 Adapter cache time: 0.17801641346886754 Engine time: 0.0751543459482491 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_192_slots_96_rate_0.1-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_192_slots_96_rate_0.1-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [64 64 64]
Adapter prompts. [1080, 135, 1080, 135, 1080, 135, 1080, 135, 135, 135, 540, 540, 540, 540, 1080, 540, 135, 1080, 135, 540, 540, 135, 1080, 1080, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 1080, 540, 135, 540, 1080, 1080, 540, 1080, 135, 540, 540, 1080, 540, 135, 135, 540, 1080, 135, 540, 135, 1080, 1080, 540, 1080, 1080, 1080, 135, 540, 1080, 135, 540, 135, 540, 135, 135, 540, 1080, 1080, 135, 135, 135, 1080, 1080, 1080, 540, 135, 135, 135, 135, 135, 1080, 135, 540, 135, 1080, 1080, 135, 1080, 135, 540, 540, 1080, 135, 135, 135, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 135, 1080, 540, 540, 540, 1080, 540, 135, 540, 1080, 1080, 540, 1080, 540, 135, 1080, 540, 135, 540, 540, 135, 540, 1080, 135, 540, 1080, 135, 540, 1080, 1080, 540, 135, 1080, 540, 135, 135, 540, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 540, 135, 1080, 1080, 540, 1080, 135, 1080, 1080, 1080, 135, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 135, 1080, 540, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 540, 540, 1080, 540, 135, 135]
Prompts retrieved: 112320 . Total input tokens: 25029474 . Total output tokens: 22460635
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 3.062994509935379,
    "estimated_duration": 3600.007478208517,
    "input_throughput": 2583.539077710018,
    "output_throughput": 2337.7212550091667,
    "total_throughput": 4921.260332719185,
    "itl": 49.64178446343501,
    "ttft": 8250.531886750627,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12435,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 40.507649904532926,
    "arrivals": 37714,
    "finished_requests": 37628,
    "scheduler_time": 20.90363448249047
}
#Debug simulation 
Total elapsed time: 3.0630907672457397. Arrivals time: 0.09931297833099961 Scheduler time: 2.5965471658855677 Scheduler overhead time: 0.0779432114213705 Adapter cache time: 0.17766397818922997 Engine time: 0.07536615105345845 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-32/adapters_192_slots_96_rate_0.1-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-32/adapters_192_slots_96_rate_0.1-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [64 64 64]
Adapter prompts. [1080, 135, 1080, 135, 1080, 135, 1080, 135, 135, 135, 540, 540, 540, 540, 1080, 540, 135, 1080, 135, 540, 540, 135, 1080, 1080, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 1080, 540, 135, 540, 1080, 1080, 540, 1080, 135, 540, 540, 1080, 540, 135, 135, 540, 1080, 135, 540, 135, 1080, 1080, 540, 1080, 1080, 1080, 135, 540, 1080, 135, 540, 135, 540, 135, 135, 540, 1080, 1080, 135, 135, 135, 1080, 1080, 1080, 540, 135, 135, 135, 135, 135, 1080, 135, 540, 135, 1080, 1080, 135, 1080, 135, 540, 540, 1080, 135, 135, 135, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 135, 1080, 540, 540, 540, 1080, 540, 135, 540, 1080, 1080, 540, 1080, 540, 135, 1080, 540, 135, 540, 540, 135, 540, 1080, 135, 540, 1080, 135, 540, 1080, 1080, 540, 135, 1080, 540, 135, 135, 540, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 540, 135, 1080, 1080, 540, 1080, 135, 1080, 1080, 1080, 135, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 135, 1080, 540, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 540, 540, 1080, 540, 135, 135]
Prompts retrieved: 112320 . Total input tokens: 25029474 . Total output tokens: 22460635
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 3.1122150579467416,
    "estimated_duration": 3600.0207155442063,
    "input_throughput": 2583.5929109630115,
    "output_throughput": 2337.7132147218217,
    "total_throughput": 4921.306125684833,
    "itl": 49.64233152233161,
    "ttft": 8155.104365072397,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12441,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 40.61197333546981,
    "arrivals": 37714,
    "finished_requests": 37629,
    "scheduler_time": 20.90473966739506
}
#Debug simulation 
Total elapsed time: 3.1123203388415277. Arrivals time: 0.10209438763558865 Scheduler time: 2.6422465541400015 Scheduler overhead time: 0.0768061438575387 Adapter cache time: 0.17993369046598673 Engine time: 0.07488823030143976 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_192_slots_96_rate_0.1-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_192_slots_96_rate_0.1-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [64 64 64]
Adapter prompts. [1080, 135, 1080, 135, 1080, 135, 1080, 135, 135, 135, 540, 540, 540, 540, 1080, 540, 135, 1080, 135, 540, 540, 135, 1080, 1080, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 1080, 540, 135, 540, 1080, 1080, 540, 1080, 135, 540, 540, 1080, 540, 135, 135, 540, 1080, 135, 540, 135, 1080, 1080, 540, 1080, 1080, 1080, 135, 540, 1080, 135, 540, 135, 540, 135, 135, 540, 1080, 1080, 135, 135, 135, 1080, 1080, 1080, 540, 135, 135, 135, 135, 135, 1080, 135, 540, 135, 1080, 1080, 135, 1080, 135, 540, 540, 1080, 135, 135, 135, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 135, 1080, 540, 540, 540, 1080, 540, 135, 540, 1080, 1080, 540, 1080, 540, 135, 1080, 540, 135, 540, 540, 135, 540, 1080, 135, 540, 1080, 135, 540, 1080, 1080, 540, 135, 1080, 540, 135, 135, 540, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 540, 135, 1080, 1080, 540, 1080, 135, 1080, 1080, 1080, 135, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 135, 1080, 540, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 540, 540, 1080, 540, 135, 135]
Prompts retrieved: 112320 . Total input tokens: 25029474 . Total output tokens: 22460635
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 3.149213552940637,
    "estimated_duration": 3600.0019056642373,
    "input_throughput": 2583.543076842876,
    "output_throughput": 2337.724873633698,
    "total_throughput": 4921.267950476574,
    "itl": 49.57784266202273,
    "ttft": 8249.391157506587,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12445,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 38.87048150824515,
    "arrivals": 37714,
    "finished_requests": 37628,
    "scheduler_time": 20.887111260743932
}
#Debug simulation 
Total elapsed time: 3.1493190471082926. Arrivals time: 0.10010884096845984 Scheduler time: 2.67867383453995 Scheduler overhead time: 0.07739272993057966 Adapter cache time: 0.1803416283801198 Engine time: 0.07624108297750354 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-32/adapters_192_slots_96_rate_0.1-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-32/adapters_192_slots_96_rate_0.1-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [64 64 64]
Adapter prompts. [1080, 135, 1080, 135, 1080, 135, 1080, 135, 135, 135, 540, 540, 540, 540, 1080, 540, 135, 1080, 135, 540, 540, 135, 1080, 1080, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 1080, 540, 135, 540, 1080, 1080, 540, 1080, 135, 540, 540, 1080, 540, 135, 135, 540, 1080, 135, 540, 135, 1080, 1080, 540, 1080, 1080, 1080, 135, 540, 1080, 135, 540, 135, 540, 135, 135, 540, 1080, 1080, 135, 135, 135, 1080, 1080, 1080, 540, 135, 135, 135, 135, 135, 1080, 135, 540, 135, 1080, 1080, 135, 1080, 135, 540, 540, 1080, 135, 135, 135, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 135, 1080, 540, 540, 540, 1080, 540, 135, 540, 1080, 1080, 540, 1080, 540, 135, 1080, 540, 135, 540, 540, 135, 540, 1080, 135, 540, 1080, 135, 540, 1080, 1080, 540, 135, 1080, 540, 135, 135, 540, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 540, 135, 1080, 1080, 540, 1080, 135, 1080, 1080, 1080, 135, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 135, 1080, 540, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 540, 540, 1080, 540, 135, 135]
Prompts retrieved: 112320 . Total input tokens: 25029474 . Total output tokens: 22460635
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 3.120576495770365,
    "estimated_duration": 3600.0141529544453,
    "input_throughput": 2583.5342875991446,
    "output_throughput": 2337.7169206663657,
    "total_throughput": 4921.25120826551,
    "itl": 49.6661902463262,
    "ttft": 8251.058786079453,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12445,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 41.13730288716337,
    "arrivals": 37714,
    "finished_requests": 37628,
    "scheduler_time": 20.909985617392362
}
#Debug simulation 
Total elapsed time: 3.120756959076971. Arrivals time: 0.09905736334621906 Scheduler time: 2.651527924463153 Scheduler overhead time: 0.0774515406228602 Adapter cache time: 0.18121083872392774 Engine time: 0.07516968343406916 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_192_slots_96_rate_0.1-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_192_slots_96_rate_0.1-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [64 64 64]
Adapter prompts. [1080, 135, 1080, 135, 1080, 135, 1080, 135, 135, 135, 540, 540, 540, 540, 1080, 540, 135, 1080, 135, 540, 540, 135, 1080, 1080, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 1080, 540, 135, 540, 1080, 1080, 540, 1080, 135, 540, 540, 1080, 540, 135, 135, 540, 1080, 135, 540, 135, 1080, 1080, 540, 1080, 1080, 1080, 135, 540, 1080, 135, 540, 135, 540, 135, 135, 540, 1080, 1080, 135, 135, 135, 1080, 1080, 1080, 540, 135, 135, 135, 135, 135, 1080, 135, 540, 135, 1080, 1080, 135, 1080, 135, 540, 540, 1080, 135, 135, 135, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 135, 1080, 540, 540, 540, 1080, 540, 135, 540, 1080, 1080, 540, 1080, 540, 135, 1080, 540, 135, 540, 540, 135, 540, 1080, 135, 540, 1080, 135, 540, 1080, 1080, 540, 135, 1080, 540, 135, 135, 540, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 540, 135, 1080, 1080, 540, 1080, 135, 1080, 1080, 1080, 135, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 135, 1080, 540, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 540, 540, 1080, 540, 135, 135]
Prompts retrieved: 112320 . Total input tokens: 25029474 . Total output tokens: 22460635
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 3.140331198927015,
    "estimated_duration": 3600.026800178498,
    "input_throughput": 2583.588544268291,
    "output_throughput": 2337.7092636040165,
    "total_throughput": 4921.297807872307,
    "itl": 49.51856813085887,
    "ttft": 8248.264191998136,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12453,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 37.23509632241779,
    "arrivals": 37714,
    "finished_requests": 37629,
    "scheduler_time": 20.870858313117083
}
#Debug simulation 
Total elapsed time: 3.140461944974959. Arrivals time: 0.1005278523080051 Scheduler time: 2.6686557861976326 Scheduler overhead time: 0.07707406487315893 Adapter cache time: 0.18019003560766578 Engine time: 0.07739055715501308 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-32/adapters_192_slots_96_rate_0.1-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-32/adapters_192_slots_96_rate_0.1-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [64 64 64]
Adapter prompts. [1080, 135, 1080, 135, 1080, 135, 1080, 135, 135, 135, 540, 540, 540, 540, 1080, 540, 135, 1080, 135, 540, 540, 135, 1080, 1080, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 1080, 540, 135, 540, 1080, 1080, 540, 1080, 135, 540, 540, 1080, 540, 135, 135, 540, 1080, 135, 540, 135, 1080, 1080, 540, 1080, 1080, 1080, 135, 540, 1080, 135, 540, 135, 540, 135, 135, 540, 1080, 1080, 135, 135, 135, 1080, 1080, 1080, 540, 135, 135, 135, 135, 135, 1080, 135, 540, 135, 1080, 1080, 135, 1080, 135, 540, 540, 1080, 135, 135, 135, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 135, 1080, 540, 540, 540, 1080, 540, 135, 540, 1080, 1080, 540, 1080, 540, 135, 1080, 540, 135, 540, 540, 135, 540, 1080, 135, 540, 1080, 135, 540, 1080, 1080, 540, 135, 1080, 540, 135, 135, 540, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 540, 135, 1080, 1080, 540, 1080, 135, 1080, 1080, 1080, 135, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 135, 1080, 540, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 540, 540, 1080, 540, 135, 135]
Prompts retrieved: 112320 . Total input tokens: 25029474 . Total output tokens: 22460635
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 3.147928307764232,
    "estimated_duration": 3600.0106857802707,
    "input_throughput": 2583.5367758038033,
    "output_throughput": 2337.7191721240533,
    "total_throughput": 4921.255947927857,
    "itl": 49.681319984432136,
    "ttft": 8251.490575404796,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12441,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 41.63371142569907,
    "arrivals": 37714,
    "finished_requests": 37628,
    "scheduler_time": 20.915038011342908
}
#Debug simulation 
Total elapsed time: 3.1480244430713356. Arrivals time: 0.09895736537873745 Scheduler time: 2.678843453992158 Scheduler overhead time: 0.07758203987032175 Adapter cache time: 0.18043496599420905 Engine time: 0.07583939330652356 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_192_slots_96_rate_0.1-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_192_slots_96_rate_0.1-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 540, 540, 540, 540, 1080, 540, 66, 1080, 66, 540, 540, 66, 1080, 1080, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 1080, 540, 66, 540, 1080, 1080, 540, 1080, 66, 540, 540, 1080, 540, 66, 66, 540, 1080, 66, 540, 66, 1080, 1080, 540, 1080, 1080, 1080, 66, 540, 1080, 66, 540, 66, 540, 66, 66, 540, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 540, 66, 66, 66, 66, 66, 1080, 66, 540, 66, 1080, 1080, 66, 1080, 66, 540, 540, 1080, 66, 66, 66, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 66, 1080, 540, 540, 540, 1080, 540, 66, 540, 1080, 1080, 540, 1080, 540, 66, 1080, 540, 66, 540, 540, 66, 540, 1080, 66, 540, 1080, 66, 540, 1080, 1080, 540, 66, 1080, 540, 66, 66, 540, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 540, 66, 1080, 1080, 540, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 66, 1080, 540, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 540, 540, 1080, 540, 66, 66]
Prompts retrieved: 107904 . Total input tokens: 24015577 . Total output tokens: 21599596
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 2.9594745188951492,
    "estimated_duration": 3600.0261225694217,
    "input_throughput": 2493.4996842726096,
    "output_throughput": 2193.8438031008204,
    "total_throughput": 4687.3434873734295,
    "itl": 43.57652412423252,
    "ttft": 9602.595023141232,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10396,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 31.816830585928248,
    "arrivals": 36267,
    "finished_requests": 36171,
    "scheduler_time": 17.03745560546262
}
#Debug simulation 
Total elapsed time: 2.9595769881270826. Arrivals time: 0.09637254988774657 Scheduler time: 2.4780813097022474 Scheduler overhead time: 0.08455728041008115 Adapter cache time: 0.17854939866811037 Engine time: 0.08200874645262957 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_192_slots_96_rate_0.1-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_192_slots_96_rate_0.1-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 540, 540, 540, 540, 1080, 540, 66, 1080, 66, 540, 540, 66, 1080, 1080, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 1080, 540, 66, 540, 1080, 1080, 540, 1080, 66, 540, 540, 1080, 540, 66, 66, 540, 1080, 66, 540, 66, 1080, 1080, 540, 1080, 1080, 1080, 66, 540, 1080, 66, 540, 66, 540, 66, 66, 540, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 540, 66, 66, 66, 66, 66, 1080, 66, 540, 66, 1080, 1080, 66, 1080, 66, 540, 540, 1080, 66, 66, 66, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 66, 1080, 540, 540, 540, 1080, 540, 66, 540, 1080, 1080, 540, 1080, 540, 66, 1080, 540, 66, 540, 540, 66, 540, 1080, 66, 540, 1080, 66, 540, 1080, 1080, 540, 66, 1080, 540, 66, 66, 540, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 540, 66, 1080, 1080, 540, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 66, 1080, 540, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 540, 540, 1080, 540, 66, 66]
Prompts retrieved: 107904 . Total input tokens: 24015577 . Total output tokens: 21599596
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.9410256058909,
    "estimated_duration": 3600.012947678888,
    "input_throughput": 2493.5088096801746,
    "output_throughput": 2193.8518318641536,
    "total_throughput": 4687.360641544328,
    "itl": 43.833002067108936,
    "ttft": 9603.10237834805,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10358,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 33.70852958814364,
    "arrivals": 36267,
    "finished_requests": 36171,
    "scheduler_time": 17.129663799602383
}
#Debug simulation 
Total elapsed time: 2.9411285342648625. Arrivals time: 0.09672742802649736 Scheduler time: 2.462049387395382 Scheduler overhead time: 0.08446292672306299 Adapter cache time: 0.17637303564697504 Engine time: 0.08169326325878501 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-32/adapters_192_slots_96_rate_0.1-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-32/adapters_192_slots_96_rate_0.1-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 540, 540, 540, 540, 1080, 540, 66, 1080, 66, 540, 540, 66, 1080, 1080, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 1080, 540, 66, 540, 1080, 1080, 540, 1080, 66, 540, 540, 1080, 540, 66, 66, 540, 1080, 66, 540, 66, 1080, 1080, 540, 1080, 1080, 1080, 66, 540, 1080, 66, 540, 66, 540, 66, 66, 540, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 540, 66, 66, 66, 66, 66, 1080, 66, 540, 66, 1080, 1080, 66, 1080, 66, 540, 540, 1080, 66, 66, 66, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 66, 1080, 540, 540, 540, 1080, 540, 66, 540, 1080, 1080, 540, 1080, 540, 66, 1080, 540, 66, 540, 540, 66, 540, 1080, 66, 540, 1080, 66, 540, 1080, 1080, 540, 66, 1080, 540, 66, 66, 540, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 540, 66, 1080, 1080, 540, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 66, 1080, 540, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 540, 540, 1080, 540, 66, 66]
Prompts retrieved: 107904 . Total input tokens: 24015577 . Total output tokens: 21599596
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.9630011138506234,
    "estimated_duration": 3600.0243141767814,
    "input_throughput": 2493.5009368270603,
    "output_throughput": 2193.8449051297625,
    "total_throughput": 4687.345841956823,
    "itl": 43.836903070300195,
    "ttft": 9603.040352135447,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10355,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 33.77452139735465,
    "arrivals": 36267,
    "finished_requests": 36171,
    "scheduler_time": 17.13033678058709
}
#Debug simulation 
Total elapsed time: 2.9631013008765876. Arrivals time: 0.09631476132199168 Scheduler time: 2.480285746511072 Scheduler overhead time: 0.08611200284212828 Adapter cache time: 0.17725217249244452 Engine time: 0.08323751715943217 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_192_slots_96_rate_0.1-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_192_slots_96_rate_0.1-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 540, 540, 540, 540, 1080, 540, 66, 1080, 66, 540, 540, 66, 1080, 1080, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 1080, 540, 66, 540, 1080, 1080, 540, 1080, 66, 540, 540, 1080, 540, 66, 66, 540, 1080, 66, 540, 66, 1080, 1080, 540, 1080, 1080, 1080, 66, 540, 1080, 66, 540, 66, 540, 66, 66, 540, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 540, 66, 66, 66, 66, 66, 1080, 66, 540, 66, 1080, 1080, 66, 1080, 66, 540, 540, 1080, 66, 66, 66, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 66, 1080, 540, 540, 540, 1080, 540, 66, 540, 1080, 1080, 540, 1080, 540, 66, 1080, 540, 66, 540, 540, 66, 540, 1080, 66, 540, 1080, 66, 540, 1080, 1080, 540, 66, 1080, 540, 66, 66, 540, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 540, 66, 1080, 1080, 540, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 66, 1080, 540, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 540, 540, 1080, 540, 66, 66]
Prompts retrieved: 107904 . Total input tokens: 24015577 . Total output tokens: 21599596
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 2.9573889118619263,
    "estimated_duration": 3600.0349063726553,
    "input_throughput": 2493.4936003286593,
    "output_throughput": 2193.8384502937524,
    "total_throughput": 4687.332050622412,
    "itl": 43.792916966430944,
    "ttft": 9602.948383414878,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10354,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 32.33390399996506,
    "arrivals": 36267,
    "finished_requests": 36171,
    "scheduler_time": 17.11593277608905
}
#Debug simulation 
Total elapsed time: 2.95749152591452. Arrivals time: 0.09604807710275054 Scheduler time: 2.4770462843589485 Scheduler overhead time: 0.08395108999684453 Adapter cache time: 0.17774169938638806 Engine time: 0.08279668260365725 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-32/adapters_192_slots_96_rate_0.1-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-32/adapters_192_slots_96_rate_0.1-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 540, 540, 540, 540, 1080, 540, 66, 1080, 66, 540, 540, 66, 1080, 1080, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 1080, 540, 66, 540, 1080, 1080, 540, 1080, 66, 540, 540, 1080, 540, 66, 66, 540, 1080, 66, 540, 66, 1080, 1080, 540, 1080, 1080, 1080, 66, 540, 1080, 66, 540, 66, 540, 66, 66, 540, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 540, 66, 66, 66, 66, 66, 1080, 66, 540, 66, 1080, 1080, 66, 1080, 66, 540, 540, 1080, 66, 66, 66, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 66, 1080, 540, 540, 540, 1080, 540, 66, 540, 1080, 1080, 540, 1080, 540, 66, 1080, 540, 66, 540, 540, 66, 540, 1080, 66, 540, 1080, 66, 540, 1080, 1080, 540, 66, 1080, 540, 66, 66, 540, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 540, 66, 1080, 1080, 540, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 66, 1080, 540, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 540, 540, 1080, 540, 66, 66]
Prompts retrieved: 107904 . Total input tokens: 24015577 . Total output tokens: 21599596
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 2.9317732551135123,
    "estimated_duration": 3600.028216065197,
    "input_throughput": 2493.4982342475705,
    "output_throughput": 2193.8425273322828,
    "total_throughput": 4687.340761579853,
    "itl": 43.850254129875246,
    "ttft": 9603.151624267864,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10363,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 34.21880716703859,
    "arrivals": 36267,
    "finished_requests": 36171,
    "scheduler_time": 17.13486856674523
}
#Debug simulation 
Total elapsed time: 2.9318774361163378. Arrivals time: 0.09591429540887475 Scheduler time: 2.455458681564778 Scheduler overhead time: 0.08341566286981106 Adapter cache time: 0.17714740755036473 Engine time: 0.08049797918647528 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_192_slots_96_rate_0.1-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_192_slots_96_rate_0.1-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 540, 540, 540, 540, 1080, 540, 66, 1080, 66, 540, 540, 66, 1080, 1080, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 1080, 540, 66, 540, 1080, 1080, 540, 1080, 66, 540, 540, 1080, 540, 66, 66, 540, 1080, 66, 540, 66, 1080, 1080, 540, 1080, 1080, 1080, 66, 540, 1080, 66, 540, 66, 540, 66, 66, 540, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 540, 66, 66, 66, 66, 66, 1080, 66, 540, 66, 1080, 1080, 66, 1080, 66, 540, 540, 1080, 66, 66, 66, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 66, 1080, 540, 540, 540, 1080, 540, 66, 540, 1080, 1080, 540, 1080, 540, 66, 1080, 540, 66, 540, 540, 66, 540, 1080, 66, 540, 1080, 66, 540, 1080, 1080, 540, 66, 1080, 540, 66, 66, 540, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 540, 66, 1080, 1080, 540, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 66, 1080, 540, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 540, 540, 1080, 540, 66, 66]
Prompts retrieved: 107904 . Total input tokens: 24015577 . Total output tokens: 21599596
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 2.998127826023847,
    "estimated_duration": 3600.0099565146033,
    "input_throughput": 2493.5108814784708,
    "output_throughput": 2193.853654684458,
    "total_throughput": 4687.364536162929,
    "itl": 43.55385816794989,
    "ttft": 9602.389739284117,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10398,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 31.090542966389645,
    "arrivals": 36267,
    "finished_requests": 36171,
    "scheduler_time": 17.029874134211376
}
#Debug simulation 
Total elapsed time: 2.998270271345973. Arrivals time: 0.09591071819886565 Scheduler time: 2.514389069750905 Scheduler overhead time: 0.08476933324709535 Adapter cache time: 0.17996235797181726 Engine time: 0.08312643691897392 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-32/adapters_192_slots_96_rate_0.1-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-32/adapters_192_slots_96_rate_0.1-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 540, 540, 540, 540, 1080, 540, 66, 1080, 66, 540, 540, 66, 1080, 1080, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 1080, 540, 66, 540, 1080, 1080, 540, 1080, 66, 540, 540, 1080, 540, 66, 66, 540, 1080, 66, 540, 66, 1080, 1080, 540, 1080, 1080, 1080, 66, 540, 1080, 66, 540, 66, 540, 66, 66, 540, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 540, 66, 66, 66, 66, 66, 1080, 66, 540, 66, 1080, 1080, 66, 1080, 66, 540, 540, 1080, 66, 66, 66, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 66, 1080, 540, 540, 540, 1080, 540, 66, 540, 1080, 1080, 540, 1080, 540, 66, 1080, 540, 66, 540, 540, 66, 540, 1080, 66, 540, 1080, 66, 540, 1080, 1080, 540, 66, 1080, 540, 66, 66, 540, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 540, 66, 1080, 1080, 540, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 66, 1080, 540, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 540, 540, 1080, 540, 66, 66]
Prompts retrieved: 107904 . Total input tokens: 24015577 . Total output tokens: 21599596
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.933924192097038,
    "estimated_duration": 3600.0289814234293,
    "input_throughput": 2493.4977041353377,
    "output_throughput": 2193.842060926193,
    "total_throughput": 4687.339765061531,
    "itl": 43.863254189448874,
    "ttft": 9603.121339627098,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10362,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 34.63812489069798,
    "arrivals": 36267,
    "finished_requests": 36171,
    "scheduler_time": 17.139182301596644
}
#Debug simulation 
Total elapsed time: 2.9340249891392887. Arrivals time: 0.09822746785357594 Scheduler time: 2.4516850165091455 Scheduler overhead time: 0.08510078443214297 Adapter cache time: 0.17617119243368506 Engine time: 0.08280635392293334 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_192_slots_96_rate_0.1-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_192_slots_96_rate_0.1-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 540, 540, 540, 540, 1080, 540, 33, 1080, 33, 540, 540, 33, 1080, 1080, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 1080, 540, 33, 540, 1080, 1080, 540, 1080, 33, 540, 540, 1080, 540, 33, 33, 540, 1080, 33, 540, 33, 1080, 1080, 540, 1080, 1080, 1080, 33, 540, 1080, 33, 540, 33, 540, 33, 33, 540, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 540, 33, 33, 33, 33, 33, 1080, 33, 540, 33, 1080, 1080, 33, 1080, 33, 540, 540, 1080, 33, 33, 33, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 33, 1080, 540, 540, 540, 1080, 540, 33, 540, 1080, 1080, 540, 1080, 540, 33, 1080, 540, 33, 540, 540, 33, 540, 1080, 33, 540, 1080, 33, 540, 1080, 1080, 540, 33, 1080, 540, 33, 33, 540, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 540, 33, 1080, 1080, 540, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 33, 1080, 540, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 540, 540, 1080, 540, 33, 33]
Prompts retrieved: 105792 . Total input tokens: 23538003 . Total output tokens: 21187347
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 2.9085582881234586,
    "estimated_duration": 3600.0164527248126,
    "input_throughput": 2446.01771009548,
    "output_throughput": 2144.9204750593553,
    "total_throughput": 4590.938185154836,
    "itl": 41.34159102680364,
    "ttft": 10716.679200452278,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9092,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.82595456783864,
    "arrivals": 35501,
    "finished_requests": 35396,
    "scheduler_time": 15.56103348195795
}
#Debug simulation 
Total elapsed time: 2.908677951898426. Arrivals time: 0.0973698659799993 Scheduler time: 2.4183344929479063 Scheduler overhead time: 0.0883873994462192 Adapter cache time: 0.1762205888517201 Engine time: 0.0866710776463151 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_192_slots_96_rate_0.1-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_192_slots_96_rate_0.1-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 540, 540, 540, 540, 1080, 540, 33, 1080, 33, 540, 540, 33, 1080, 1080, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 1080, 540, 33, 540, 1080, 1080, 540, 1080, 33, 540, 540, 1080, 540, 33, 33, 540, 1080, 33, 540, 33, 1080, 1080, 540, 1080, 1080, 1080, 33, 540, 1080, 33, 540, 33, 540, 33, 33, 540, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 540, 33, 33, 33, 33, 33, 1080, 33, 540, 33, 1080, 1080, 33, 1080, 33, 540, 540, 1080, 33, 33, 33, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 33, 1080, 540, 540, 540, 1080, 540, 33, 540, 1080, 1080, 540, 1080, 540, 33, 1080, 540, 33, 540, 540, 33, 540, 1080, 33, 540, 1080, 33, 540, 1080, 1080, 540, 33, 1080, 540, 33, 33, 540, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 540, 33, 1080, 1080, 540, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 33, 1080, 540, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 540, 540, 1080, 540, 33, 33]
Prompts retrieved: 105792 . Total input tokens: 23538003 . Total output tokens: 21187347
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.8782384088262916,
    "estimated_duration": 3600.0294482039067,
    "input_throughput": 2446.0088803977037,
    "output_throughput": 2144.9127322701383,
    "total_throughput": 4590.921612667842,
    "itl": 41.3919251412607,
    "ttft": 10716.732738373013,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9088,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.592869960552463,
    "arrivals": 35501,
    "finished_requests": 35396,
    "scheduler_time": 15.579392249442678
}
#Debug simulation 
Total elapsed time: 2.8783414349891245. Arrivals time: 0.09382484946399927 Scheduler time: 2.394869996700436 Scheduler overhead time: 0.08742204587906599 Adapter cache time: 0.17403270257636905 Engine time: 0.08657549135386944 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-32/adapters_192_slots_96_rate_0.1-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-32/adapters_192_slots_96_rate_0.1-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 540, 540, 540, 540, 1080, 540, 33, 1080, 33, 540, 540, 33, 1080, 1080, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 1080, 540, 33, 540, 1080, 1080, 540, 1080, 33, 540, 540, 1080, 540, 33, 33, 540, 1080, 33, 540, 33, 1080, 1080, 540, 1080, 1080, 1080, 33, 540, 1080, 33, 540, 33, 540, 33, 33, 540, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 540, 33, 33, 33, 33, 33, 1080, 33, 540, 33, 1080, 1080, 33, 1080, 33, 540, 540, 1080, 33, 33, 33, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 33, 1080, 540, 540, 540, 1080, 540, 33, 540, 1080, 1080, 540, 1080, 540, 33, 1080, 540, 33, 540, 540, 33, 540, 1080, 33, 540, 1080, 33, 540, 1080, 1080, 540, 33, 1080, 540, 33, 33, 540, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 540, 33, 1080, 1080, 540, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 33, 1080, 540, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 540, 540, 1080, 540, 33, 33]
Prompts retrieved: 105792 . Total input tokens: 23538003 . Total output tokens: 21187347
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.9071968533098698,
    "estimated_duration": 3600.027700651554,
    "input_throughput": 2446.0100677576156,
    "output_throughput": 2144.913773469708,
    "total_throughput": 4590.9238412273235,
    "itl": 41.392619394641564,
    "ttft": 10716.810624238193,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9095,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.678995334637467,
    "arrivals": 35501,
    "finished_requests": 35396,
    "scheduler_time": 15.580169561450656
}
#Debug simulation 
Total elapsed time: 2.90730190416798. Arrivals time: 0.09521650103852153 Scheduler time: 2.421737791970372 Scheduler overhead time: 0.08771410118788481 Adapter cache time: 0.17485972354188561 Engine time: 0.0860509006306529 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_192_slots_96_rate_0.1-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_192_slots_96_rate_0.1-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 540, 540, 540, 540, 1080, 540, 33, 1080, 33, 540, 540, 33, 1080, 1080, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 1080, 540, 33, 540, 1080, 1080, 540, 1080, 33, 540, 540, 1080, 540, 33, 33, 540, 1080, 33, 540, 33, 1080, 1080, 540, 1080, 1080, 1080, 33, 540, 1080, 33, 540, 33, 540, 33, 33, 540, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 540, 33, 33, 33, 33, 33, 1080, 33, 540, 33, 1080, 1080, 33, 1080, 33, 540, 540, 1080, 33, 33, 33, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 33, 1080, 540, 540, 540, 1080, 540, 33, 540, 1080, 1080, 540, 1080, 540, 33, 1080, 540, 33, 540, 540, 33, 540, 1080, 33, 540, 1080, 33, 540, 1080, 1080, 540, 33, 1080, 540, 33, 33, 540, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 540, 33, 1080, 1080, 540, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 33, 1080, 540, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 540, 540, 1080, 540, 33, 33]
Prompts retrieved: 105792 . Total input tokens: 23538003 . Total output tokens: 21187347
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 2.899564042221755,
    "estimated_duration": 3600.013978366698,
    "input_throughput": 2446.0193912899995,
    "output_throughput": 2144.921949304015,
    "total_throughput": 4590.941340594014,
    "itl": 41.35962942801259,
    "ttft": 10716.72672299591,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9096,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.395090360776006,
    "arrivals": 35501,
    "finished_requests": 35396,
    "scheduler_time": 15.566893658077667
}
#Debug simulation 
Total elapsed time: 2.8996672239154577. Arrivals time: 0.0947282169945538 Scheduler time: 2.4167240490205586 Scheduler overhead time: 0.08758095232769847 Adapter cache time: 0.1725891367532313 Engine time: 0.086289890576154 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-32/adapters_192_slots_96_rate_0.1-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-32/adapters_192_slots_96_rate_0.1-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 540, 540, 540, 540, 1080, 540, 33, 1080, 33, 540, 540, 33, 1080, 1080, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 1080, 540, 33, 540, 1080, 1080, 540, 1080, 33, 540, 540, 1080, 540, 33, 33, 540, 1080, 33, 540, 33, 1080, 1080, 540, 1080, 1080, 1080, 33, 540, 1080, 33, 540, 33, 540, 33, 33, 540, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 540, 33, 33, 33, 33, 33, 1080, 33, 540, 33, 1080, 1080, 33, 1080, 33, 540, 540, 1080, 33, 33, 33, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 33, 1080, 540, 540, 540, 1080, 540, 33, 540, 1080, 1080, 540, 1080, 540, 33, 1080, 540, 33, 540, 540, 33, 540, 1080, 33, 540, 1080, 33, 540, 1080, 1080, 540, 33, 1080, 540, 33, 33, 540, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 540, 33, 1080, 1080, 540, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 33, 1080, 540, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 540, 540, 1080, 540, 33, 33]
Prompts retrieved: 105792 . Total input tokens: 23538003 . Total output tokens: 21187347
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 2.8972947420552373,
    "estimated_duration": 3600.0208116354506,
    "input_throughput": 2446.0147484535414,
    "output_throughput": 2144.9178779864033,
    "total_throughput": 4590.932626439944,
    "itl": 41.40325790898817,
    "ttft": 10716.811203935253,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9088,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 30.030407789050745,
    "arrivals": 35501,
    "finished_requests": 35396,
    "scheduler_time": 15.583605511815952
}
#Debug simulation 
Total elapsed time: 2.89739662501961. Arrivals time: 0.09501014975830913 Scheduler time: 2.411530312616378 Scheduler overhead time: 0.08769480511546135 Adapter cache time: 0.1743314303457737 Engine time: 0.08744992641732097 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_192_slots_96_rate_0.1-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_192_slots_96_rate_0.1-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 540, 540, 540, 540, 1080, 540, 33, 1080, 33, 540, 540, 33, 1080, 1080, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 1080, 540, 33, 540, 1080, 1080, 540, 1080, 33, 540, 540, 1080, 540, 33, 33, 540, 1080, 33, 540, 33, 1080, 1080, 540, 1080, 1080, 1080, 33, 540, 1080, 33, 540, 33, 540, 33, 33, 540, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 540, 33, 33, 33, 33, 33, 1080, 33, 540, 33, 1080, 1080, 33, 1080, 33, 540, 540, 1080, 33, 33, 33, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 33, 1080, 540, 540, 540, 1080, 540, 33, 540, 1080, 1080, 540, 1080, 540, 33, 1080, 540, 33, 540, 540, 33, 540, 1080, 33, 540, 1080, 33, 540, 1080, 1080, 540, 33, 1080, 540, 33, 33, 540, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 540, 33, 1080, 1080, 540, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 33, 1080, 540, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 540, 540, 1080, 540, 33, 33]
Prompts retrieved: 105792 . Total input tokens: 23538003 . Total output tokens: 21187347
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 2.9005515803582966,
    "estimated_duration": 3600.0452754473354,
    "input_throughput": 2445.998126761286,
    "output_throughput": 2144.9033023731927,
    "total_throughput": 4590.901429134478,
    "itl": 41.32541707943343,
    "ttft": 10716.51124811304,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9093,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.188527331543604,
    "arrivals": 35501,
    "finished_requests": 35396,
    "scheduler_time": 15.554638682312747
}
#Debug simulation 
Total elapsed time: 2.9006529860198498. Arrivals time: 0.0944558335468173 Scheduler time: 2.41734109306708 Scheduler overhead time: 0.0873601334169507 Adapter cache time: 0.1748950877226889 Engine time: 0.08504395419731736 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-32/adapters_192_slots_96_rate_0.1-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-32/adapters_192_slots_96_rate_0.1-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 540, 540, 540, 540, 1080, 540, 33, 1080, 33, 540, 540, 33, 1080, 1080, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 1080, 540, 33, 540, 1080, 1080, 540, 1080, 33, 540, 540, 1080, 540, 33, 33, 540, 1080, 33, 540, 33, 1080, 1080, 540, 1080, 1080, 1080, 33, 540, 1080, 33, 540, 33, 540, 33, 33, 540, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 540, 33, 33, 33, 33, 33, 1080, 33, 540, 33, 1080, 1080, 33, 1080, 33, 540, 540, 1080, 33, 33, 33, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 33, 1080, 540, 540, 540, 1080, 540, 33, 540, 1080, 1080, 540, 1080, 540, 33, 1080, 540, 33, 540, 540, 33, 540, 1080, 33, 540, 1080, 33, 540, 1080, 1080, 540, 33, 1080, 540, 33, 33, 540, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 540, 33, 1080, 1080, 540, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 33, 1080, 540, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 540, 540, 1080, 540, 33, 33]
Prompts retrieved: 105792 . Total input tokens: 23538003 . Total output tokens: 21187347
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.898229186888784,
    "estimated_duration": 3600.0380494912138,
    "input_throughput": 2446.0030363413775,
    "output_throughput": 2144.9076075991197,
    "total_throughput": 4590.910643940498,
    "itl": 41.41392634587964,
    "ttft": 10716.818847452765,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9099,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 30.436260594536765,
    "arrivals": 35501,
    "finished_requests": 35396,
    "scheduler_time": 15.587907853097814
}
#Debug simulation 
Total elapsed time: 2.898408758919686. Arrivals time: 0.09800308663398027 Scheduler time: 2.4108510478399694 Scheduler overhead time: 0.08781263651326299 Adapter cache time: 0.17459258576855063 Engine time: 0.08563400199636817 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_192_slots_96_rate_0.1-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_192_slots_96_rate_0.1-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [64 64 64]
Adapter prompts. [1080, 135, 1080, 135, 1080, 135, 1080, 135, 135, 135, 270, 270, 270, 270, 1080, 270, 135, 1080, 135, 270, 270, 135, 1080, 1080, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 1080, 270, 135, 270, 1080, 1080, 270, 1080, 135, 270, 270, 1080, 270, 135, 135, 270, 1080, 135, 270, 135, 1080, 1080, 270, 1080, 1080, 1080, 135, 270, 1080, 135, 270, 135, 270, 135, 135, 270, 1080, 1080, 135, 135, 135, 1080, 1080, 1080, 270, 135, 135, 135, 135, 135, 1080, 135, 270, 135, 1080, 1080, 135, 1080, 135, 270, 270, 1080, 135, 135, 135, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 135, 1080, 270, 270, 270, 1080, 270, 135, 270, 1080, 1080, 270, 1080, 270, 135, 1080, 270, 135, 270, 270, 135, 270, 1080, 135, 270, 1080, 135, 270, 1080, 1080, 270, 135, 1080, 270, 135, 135, 270, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 270, 135, 1080, 1080, 270, 1080, 135, 1080, 1080, 1080, 135, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 135, 1080, 270, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 270, 270, 1080, 270, 135, 135]
Prompts retrieved: 95040 . Total input tokens: 21168775 . Total output tokens: 19051203
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 2.6817987598478794,
    "estimated_duration": 3599.9895702986587,
    "input_throughput": 2181.2046525869696,
    "output_throughput": 1938.0767259892857,
    "total_throughput": 4119.2813785762555,
    "itl": 36.268167304872705,
    "ttft": 11586.715323065142,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8580,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.25898484294456,
    "arrivals": 31858,
    "finished_requests": 31756,
    "scheduler_time": 10.317591622158217
}
#Debug simulation 
Total elapsed time: 2.6819331711158156. Arrivals time: 0.08786615775898099 Scheduler time: 2.1839194064959884 Scheduler overhead time: 0.09879218833521008 Adapter cache time: 0.16990050626918674 Engine time: 0.09485266683623195 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_192_slots_96_rate_0.1-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_192_slots_96_rate_0.1-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [64 64 64]
Adapter prompts. [1080, 135, 1080, 135, 1080, 135, 1080, 135, 135, 135, 270, 270, 270, 270, 1080, 270, 135, 1080, 135, 270, 270, 135, 1080, 1080, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 1080, 270, 135, 270, 1080, 1080, 270, 1080, 135, 270, 270, 1080, 270, 135, 135, 270, 1080, 135, 270, 135, 1080, 1080, 270, 1080, 1080, 1080, 135, 270, 1080, 135, 270, 135, 270, 135, 135, 270, 1080, 1080, 135, 135, 135, 1080, 1080, 1080, 270, 135, 135, 135, 135, 135, 1080, 135, 270, 135, 1080, 1080, 135, 1080, 135, 270, 270, 1080, 135, 135, 135, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 135, 1080, 270, 270, 270, 1080, 270, 135, 270, 1080, 1080, 270, 1080, 270, 135, 1080, 270, 135, 270, 270, 135, 270, 1080, 135, 270, 1080, 135, 270, 1080, 1080, 270, 135, 1080, 270, 135, 135, 270, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 270, 135, 1080, 1080, 270, 1080, 135, 1080, 1080, 1080, 135, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 135, 1080, 270, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 270, 270, 1080, 270, 135, 135]
Prompts retrieved: 95040 . Total input tokens: 21168775 . Total output tokens: 19051203
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.648127186577767,
    "estimated_duration": 3599.9778394699533,
    "input_throughput": 2181.211760224653,
    "output_throughput": 1938.0830413742976,
    "total_throughput": 4119.2948015989505,
    "itl": 36.30709271849466,
    "ttft": 11586.840333844842,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8580,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.984442036004282,
    "arrivals": 31858,
    "finished_requests": 31756,
    "scheduler_time": 10.33509842673272
}
#Debug simulation 
Total elapsed time: 2.648231260944158. Arrivals time: 0.08805262483656406 Scheduler time: 2.153416909277439 Scheduler overhead time: 0.09659659676253796 Adapter cache time: 0.16909565264359117 Engine time: 0.09497825941070914 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-32/adapters_192_slots_96_rate_0.1-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-32/adapters_192_slots_96_rate_0.1-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [64 64 64]
Adapter prompts. [1080, 135, 1080, 135, 1080, 135, 1080, 135, 135, 135, 270, 270, 270, 270, 1080, 270, 135, 1080, 135, 270, 270, 135, 1080, 1080, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 1080, 270, 135, 270, 1080, 1080, 270, 1080, 135, 270, 270, 1080, 270, 135, 135, 270, 1080, 135, 270, 135, 1080, 1080, 270, 1080, 1080, 1080, 135, 270, 1080, 135, 270, 135, 270, 135, 135, 270, 1080, 1080, 135, 135, 135, 1080, 1080, 1080, 270, 135, 135, 135, 135, 135, 1080, 135, 270, 135, 1080, 1080, 135, 1080, 135, 270, 270, 1080, 135, 135, 135, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 135, 1080, 270, 270, 270, 1080, 270, 135, 270, 1080, 1080, 270, 1080, 270, 135, 1080, 270, 135, 270, 270, 135, 270, 1080, 135, 270, 1080, 135, 270, 1080, 1080, 270, 135, 1080, 270, 135, 135, 270, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 270, 135, 1080, 1080, 270, 1080, 135, 1080, 1080, 1080, 135, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 135, 1080, 270, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 270, 270, 1080, 270, 135, 135]
Prompts retrieved: 95040 . Total input tokens: 21168775 . Total output tokens: 19051203
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.6625696080736816,
    "estimated_duration": 3599.990261020266,
    "input_throughput": 2181.2042340843977,
    "output_throughput": 1938.0763541350932,
    "total_throughput": 4119.280588219491,
    "itl": 36.306259319274815,
    "ttft": 11586.79497957529,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8578,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.030627146047426,
    "arrivals": 31858,
    "finished_requests": 31756,
    "scheduler_time": 10.335819236550124
}
#Debug simulation 
Total elapsed time: 2.662665239069611. Arrivals time: 0.08653550315648317 Scheduler time: 2.1683559990487993 Scheduler overhead time: 0.09623914770781994 Adapter cache time: 0.1689183027483523 Engine time: 0.09669853979721665 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_192_slots_96_rate_0.1-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_192_slots_96_rate_0.1-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [64 64 64]
Adapter prompts. [1080, 135, 1080, 135, 1080, 135, 1080, 135, 135, 135, 270, 270, 270, 270, 1080, 270, 135, 1080, 135, 270, 270, 135, 1080, 1080, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 1080, 270, 135, 270, 1080, 1080, 270, 1080, 135, 270, 270, 1080, 270, 135, 135, 270, 1080, 135, 270, 135, 1080, 1080, 270, 1080, 1080, 1080, 135, 270, 1080, 135, 270, 135, 270, 135, 135, 270, 1080, 1080, 135, 135, 135, 1080, 1080, 1080, 270, 135, 135, 135, 135, 135, 1080, 135, 270, 135, 1080, 1080, 135, 1080, 135, 270, 270, 1080, 135, 135, 135, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 135, 1080, 270, 270, 270, 1080, 270, 135, 270, 1080, 1080, 270, 1080, 270, 135, 1080, 270, 135, 270, 270, 135, 270, 1080, 135, 270, 1080, 135, 270, 1080, 1080, 270, 135, 1080, 270, 135, 135, 270, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 270, 135, 1080, 1080, 270, 1080, 135, 1080, 1080, 1080, 135, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 135, 1080, 270, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 270, 270, 1080, 270, 135, 135]
Prompts retrieved: 95040 . Total input tokens: 21168775 . Total output tokens: 19051203
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 2.680423174984753,
    "estimated_duration": 3599.9840672081195,
    "input_throughput": 2181.207986870251,
    "output_throughput": 1938.0796886167573,
    "total_throughput": 4119.2876754870085,
    "itl": 36.28094110447397,
    "ttft": 11586.77629973581,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8578,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.819277017000143,
    "arrivals": 31858,
    "finished_requests": 31756,
    "scheduler_time": 10.323340461868796
}
#Debug simulation 
Total elapsed time: 2.6805272079072893. Arrivals time: 0.08918657433241606 Scheduler time: 2.1824663816951215 Scheduler overhead time: 0.09862441476434469 Adapter cache time: 0.16984488815069199 Engine time: 0.09406944736838341 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-32/adapters_192_slots_96_rate_0.1-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-32/adapters_192_slots_96_rate_0.1-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [64 64 64]
Adapter prompts. [1080, 135, 1080, 135, 1080, 135, 1080, 135, 135, 135, 270, 270, 270, 270, 1080, 270, 135, 1080, 135, 270, 270, 135, 1080, 1080, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 1080, 270, 135, 270, 1080, 1080, 270, 1080, 135, 270, 270, 1080, 270, 135, 135, 270, 1080, 135, 270, 135, 1080, 1080, 270, 1080, 1080, 1080, 135, 270, 1080, 135, 270, 135, 270, 135, 135, 270, 1080, 1080, 135, 135, 135, 1080, 1080, 1080, 270, 135, 135, 135, 135, 135, 1080, 135, 270, 135, 1080, 1080, 135, 1080, 135, 270, 270, 1080, 135, 135, 135, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 135, 1080, 270, 270, 270, 1080, 270, 135, 270, 1080, 1080, 270, 1080, 270, 135, 1080, 270, 135, 270, 270, 135, 270, 1080, 135, 270, 1080, 135, 270, 1080, 1080, 270, 135, 1080, 270, 135, 135, 270, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 270, 135, 1080, 1080, 270, 1080, 135, 1080, 1080, 1080, 135, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 135, 1080, 270, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 270, 270, 1080, 270, 135, 135]
Prompts retrieved: 95040 . Total input tokens: 21168775 . Total output tokens: 19051203
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 2.6853158678859472,
    "estimated_duration": 3600.007030124951,
    "input_throughput": 2181.1940738703106,
    "output_throughput": 1938.0673264290365,
    "total_throughput": 4119.261400299347,
    "itl": 36.74425421603036,
    "ttft": 11587.58573258078,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8694,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.76902486238551,
    "arrivals": 31858,
    "finished_requests": 31756,
    "scheduler_time": 10.546172434974928
}
#Debug simulation 
Total elapsed time: 2.685415431857109. Arrivals time: 0.08800366055220366 Scheduler time: 2.1918053864501417 Scheduler overhead time: 0.09650432458147407 Adapter cache time: 0.17005379684269428 Engine time: 0.09327364712953568 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_192_slots_96_rate_0.1-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_192_slots_96_rate_0.1-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [64 64 64]
Adapter prompts. [1080, 135, 1080, 135, 1080, 135, 1080, 135, 135, 135, 270, 270, 270, 270, 1080, 270, 135, 1080, 135, 270, 270, 135, 1080, 1080, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 1080, 270, 135, 270, 1080, 1080, 270, 1080, 135, 270, 270, 1080, 270, 135, 135, 270, 1080, 135, 270, 135, 1080, 1080, 270, 1080, 1080, 1080, 135, 270, 1080, 135, 270, 135, 270, 135, 135, 270, 1080, 1080, 135, 135, 135, 1080, 1080, 1080, 270, 135, 135, 135, 135, 135, 1080, 135, 270, 135, 1080, 1080, 135, 1080, 135, 270, 270, 1080, 135, 135, 135, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 135, 1080, 270, 270, 270, 1080, 270, 135, 270, 1080, 1080, 270, 1080, 270, 135, 1080, 270, 135, 270, 270, 135, 270, 1080, 135, 270, 1080, 135, 270, 1080, 1080, 270, 135, 1080, 270, 135, 135, 270, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 270, 135, 1080, 1080, 270, 1080, 135, 1080, 1080, 1080, 135, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 135, 1080, 270, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 270, 270, 1080, 270, 135, 135]
Prompts retrieved: 95040 . Total input tokens: 21168775 . Total output tokens: 19051203
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 2.6661639269441366,
    "estimated_duration": 3599.9820471964304,
    "input_throughput": 2181.2092107834737,
    "output_throughput": 1938.080776106521,
    "total_throughput": 4119.289986889995,
    "itl": 36.25614061825563,
    "ttft": 11586.762321813203,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8580,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.654631530259298,
    "arrivals": 31858,
    "finished_requests": 31756,
    "scheduler_time": 10.3115729256801
}
#Debug simulation 
Total elapsed time: 2.666266418993473. Arrivals time: 0.0869732927531004 Scheduler time: 2.1721337558701634 Scheduler overhead time: 0.09729199716821313 Adapter cache time: 0.16994764376431704 Engine time: 0.09375433158129454 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-32/adapters_192_slots_96_rate_0.1-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-32/adapters_192_slots_96_rate_0.1-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [64 64 64]
Adapter prompts. [1080, 135, 1080, 135, 1080, 135, 1080, 135, 135, 135, 270, 270, 270, 270, 1080, 270, 135, 1080, 135, 270, 270, 135, 1080, 1080, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 1080, 270, 135, 270, 1080, 1080, 270, 1080, 135, 270, 270, 1080, 270, 135, 135, 270, 1080, 135, 270, 135, 1080, 1080, 270, 1080, 1080, 1080, 135, 270, 1080, 135, 270, 135, 270, 135, 135, 270, 1080, 1080, 135, 135, 135, 1080, 1080, 1080, 270, 135, 135, 135, 135, 135, 1080, 135, 270, 135, 1080, 1080, 135, 1080, 135, 270, 270, 1080, 135, 135, 135, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 135, 1080, 270, 270, 270, 1080, 270, 135, 270, 1080, 1080, 270, 1080, 270, 135, 1080, 270, 135, 270, 270, 135, 270, 1080, 135, 270, 1080, 135, 270, 1080, 1080, 270, 135, 1080, 270, 135, 135, 270, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 270, 135, 1080, 1080, 270, 1080, 135, 1080, 1080, 1080, 135, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 135, 1080, 270, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 270, 270, 1080, 270, 135, 135]
Prompts retrieved: 95040 . Total input tokens: 21168775 . Total output tokens: 19051203
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.639517402742058,
    "estimated_duration": 3599.9926651021915,
    "input_throughput": 2181.2027774720755,
    "output_throughput": 1938.0750598840305,
    "total_throughput": 4119.277837356106,
    "itl": 36.74911459832005,
    "ttft": 11587.707981423891,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8692,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.12393121942635,
    "arrivals": 31858,
    "finished_requests": 31756,
    "scheduler_time": 10.549751098992994
}
#Debug simulation 
Total elapsed time: 2.639619177673012. Arrivals time: 0.08641619374975562 Scheduler time: 2.1500445613637567 Scheduler overhead time: 0.09530998347327113 Adapter cache time: 0.16900123981758952 Engine time: 0.09347520070150495 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_192_slots_96_rate_0.1-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_192_slots_96_rate_0.1-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 270, 270, 270, 270, 1080, 270, 66, 1080, 66, 270, 270, 66, 1080, 1080, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 1080, 270, 66, 270, 1080, 1080, 270, 1080, 66, 270, 270, 1080, 270, 66, 66, 270, 1080, 66, 270, 66, 1080, 1080, 270, 1080, 1080, 1080, 66, 270, 1080, 66, 270, 66, 270, 66, 66, 270, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 270, 66, 66, 66, 66, 66, 1080, 66, 270, 66, 1080, 1080, 66, 1080, 66, 270, 270, 1080, 66, 66, 66, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 66, 1080, 270, 270, 270, 1080, 270, 66, 270, 1080, 1080, 270, 1080, 270, 66, 1080, 270, 66, 270, 270, 66, 270, 1080, 66, 270, 1080, 66, 270, 1080, 1080, 270, 66, 1080, 270, 66, 66, 270, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 270, 66, 1080, 1080, 270, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 66, 1080, 270, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 270, 270, 1080, 270, 66, 66]
Prompts retrieved: 90624 . Total input tokens: 20161865 . Total output tokens: 18163334
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 2.595949620939791,
    "estimated_duration": 3599.9783790974666,
    "input_throughput": 2066.874635470845,
    "output_throughput": 1844.9446914914872,
    "total_throughput": 3911.8193269623325,
    "itl": 33.84379339944391,
    "ttft": 9055.92309514213,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6491,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.86562594586696,
    "arrivals": 30402,
    "finished_requests": 30326,
    "scheduler_time": 7.722418329289052
}
#Debug simulation 
Total elapsed time: 2.596101121045649. Arrivals time: 0.08388175582513213 Scheduler time: 2.1020317706279457 Scheduler overhead time: 0.10145841585472226 Adapter cache time: 0.1595932780764997 Engine time: 0.1005542385391891 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_192_slots_96_rate_0.1-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_192_slots_96_rate_0.1-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 270, 270, 270, 270, 1080, 270, 66, 1080, 66, 270, 270, 66, 1080, 1080, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 1080, 270, 66, 270, 1080, 1080, 270, 1080, 66, 270, 270, 1080, 270, 66, 66, 270, 1080, 66, 270, 66, 1080, 1080, 270, 1080, 1080, 1080, 66, 270, 1080, 66, 270, 66, 270, 66, 66, 270, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 270, 66, 66, 66, 66, 66, 1080, 66, 270, 66, 1080, 1080, 66, 1080, 66, 270, 270, 1080, 66, 66, 66, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 66, 1080, 270, 270, 270, 1080, 270, 66, 270, 1080, 1080, 270, 1080, 270, 66, 1080, 270, 66, 270, 270, 66, 270, 1080, 66, 270, 1080, 66, 270, 1080, 1080, 270, 66, 1080, 270, 66, 66, 270, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 270, 66, 1080, 1080, 270, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 66, 1080, 270, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 270, 270, 1080, 270, 66, 66]
Prompts retrieved: 90624 . Total input tokens: 20161865 . Total output tokens: 18163334
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.5752820167690516,
    "estimated_duration": 3600.0072728693613,
    "input_throughput": 2066.858046669844,
    "output_throughput": 1844.9298839072148,
    "total_throughput": 3911.787930577059,
    "itl": 33.868940056303984,
    "ttft": 9055.983655002,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6493,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.151743858807425,
    "arrivals": 30402,
    "finished_requests": 30326,
    "scheduler_time": 7.735418977339248
}
#Debug simulation 
Total elapsed time: 2.5753807220607996. Arrivals time: 0.08373737521469593 Scheduler time: 2.080342478118837 Scheduler overhead time: 0.10185403423383832 Adapter cache time: 0.16044953558593988 Engine time: 0.10035758931189775 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_192_slots_96_rate_0.1-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_192_slots_96_rate_0.1-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 270, 270, 270, 270, 1080, 270, 66, 1080, 66, 270, 270, 66, 1080, 1080, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 1080, 270, 66, 270, 1080, 1080, 270, 1080, 66, 270, 270, 1080, 270, 66, 66, 270, 1080, 66, 270, 66, 1080, 1080, 270, 1080, 1080, 1080, 66, 270, 1080, 66, 270, 66, 270, 66, 66, 270, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 270, 66, 66, 66, 66, 66, 1080, 66, 270, 66, 1080, 1080, 66, 1080, 66, 270, 270, 1080, 66, 66, 66, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 66, 1080, 270, 270, 270, 1080, 270, 66, 270, 1080, 1080, 270, 1080, 270, 66, 1080, 270, 66, 270, 270, 66, 270, 1080, 66, 270, 1080, 66, 270, 1080, 1080, 270, 66, 1080, 270, 66, 66, 270, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 270, 66, 1080, 1080, 270, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 66, 1080, 270, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 270, 270, 1080, 270, 66, 66]
Prompts retrieved: 90624 . Total input tokens: 20161865 . Total output tokens: 18163334
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.5541799259372056,
    "estimated_duration": 3599.9853567192054,
    "input_throughput": 2066.87062937972,
    "output_throughput": 1844.9411155530013,
    "total_throughput": 3911.8117449327215,
    "itl": 33.87048249816397,
    "ttft": 9056.003917685504,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6497,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.209067297167625,
    "arrivals": 30402,
    "finished_requests": 30326,
    "scheduler_time": 7.735943968398599
}
#Debug simulation 
Total elapsed time: 2.5542788058519363. Arrivals time: 0.08306865487247705 Scheduler time: 2.0605523912236094 Scheduler overhead time: 0.1019541323184967 Adapter cache time: 0.16006857343018055 Engine time: 0.10014049103483558 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_192_slots_96_rate_0.1-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_192_slots_96_rate_0.1-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 270, 270, 270, 270, 1080, 270, 66, 1080, 66, 270, 270, 66, 1080, 1080, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 1080, 270, 66, 270, 1080, 1080, 270, 1080, 66, 270, 270, 1080, 270, 66, 66, 270, 1080, 66, 270, 66, 1080, 1080, 270, 1080, 1080, 1080, 66, 270, 1080, 66, 270, 66, 270, 66, 66, 270, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 270, 66, 66, 66, 66, 66, 1080, 66, 270, 66, 1080, 1080, 66, 1080, 66, 270, 270, 1080, 66, 66, 66, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 66, 1080, 270, 270, 270, 1080, 270, 66, 270, 1080, 1080, 270, 1080, 270, 66, 1080, 270, 66, 270, 270, 66, 270, 1080, 66, 270, 1080, 66, 270, 1080, 1080, 270, 66, 1080, 270, 66, 66, 270, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 270, 66, 1080, 1080, 270, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 66, 1080, 270, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 270, 270, 1080, 270, 66, 66]
Prompts retrieved: 90624 . Total input tokens: 20161865 . Total output tokens: 18163334
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 2.577239590231329,
    "estimated_duration": 3600.0011850712517,
    "input_throughput": 2066.8615418393906,
    "output_throughput": 1844.933003784149,
    "total_throughput": 3911.7945456235393,
    "itl": 33.851873223174906,
    "ttft": 9055.871429082283,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6490,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.27655163282991,
    "arrivals": 30402,
    "finished_requests": 30326,
    "scheduler_time": 7.72654554435077
}
#Debug simulation 
Total elapsed time: 2.5773597238585353. Arrivals time: 0.08512668125331402 Scheduler time: 2.0815752069465816 Scheduler overhead time: 0.10194339184090495 Adapter cache time: 0.15925807785242796 Engine time: 0.10060381703078747 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_192_slots_96_rate_0.1-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_192_slots_96_rate_0.1-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 270, 270, 270, 270, 1080, 270, 66, 1080, 66, 270, 270, 66, 1080, 1080, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 1080, 270, 66, 270, 1080, 1080, 270, 1080, 66, 270, 270, 1080, 270, 66, 66, 270, 1080, 66, 270, 66, 1080, 1080, 270, 1080, 1080, 1080, 66, 270, 1080, 66, 270, 66, 270, 66, 66, 270, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 270, 66, 66, 66, 66, 66, 1080, 66, 270, 66, 1080, 1080, 66, 1080, 66, 270, 270, 1080, 66, 66, 66, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 66, 1080, 270, 270, 270, 1080, 270, 66, 270, 1080, 1080, 270, 1080, 270, 66, 1080, 270, 66, 270, 270, 66, 270, 1080, 66, 270, 1080, 66, 270, 1080, 1080, 270, 66, 1080, 270, 66, 66, 270, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 270, 66, 1080, 1080, 270, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 66, 1080, 270, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 270, 270, 1080, 270, 66, 66]
Prompts retrieved: 90624 . Total input tokens: 20161865 . Total output tokens: 18163334
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 2.595397050026804,
    "estimated_duration": 3599.9846086346624,
    "input_throughput": 2066.8710588798813,
    "output_throughput": 1844.9414989357324,
    "total_throughput": 3911.8125578156137,
    "itl": 33.873254335728845,
    "ttft": 9055.850423206602,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6488,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.446713171041463,
    "arrivals": 30402,
    "finished_requests": 30326,
    "scheduler_time": 7.7381917043079085
}
#Debug simulation 
Total elapsed time: 2.595529905986041. Arrivals time: 0.08458363031968474 Scheduler time: 2.0777197959832847 Scheduler overhead time: 0.1016274644061923 Adapter cache time: 0.1817002627067268 Engine time: 0.10090203862637281 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_192_slots_96_rate_0.1-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_192_slots_96_rate_0.1-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 270, 270, 270, 270, 1080, 270, 66, 1080, 66, 270, 270, 66, 1080, 1080, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 1080, 270, 66, 270, 1080, 1080, 270, 1080, 66, 270, 270, 1080, 270, 66, 66, 270, 1080, 66, 270, 66, 1080, 1080, 270, 1080, 1080, 1080, 66, 270, 1080, 66, 270, 66, 270, 66, 66, 270, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 270, 66, 66, 66, 66, 66, 1080, 66, 270, 66, 1080, 1080, 66, 1080, 66, 270, 270, 1080, 66, 66, 66, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 66, 1080, 270, 270, 270, 1080, 270, 66, 270, 1080, 1080, 270, 1080, 270, 66, 1080, 270, 66, 270, 270, 66, 270, 1080, 66, 270, 1080, 66, 270, 1080, 1080, 270, 66, 1080, 270, 66, 66, 270, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 270, 66, 1080, 1080, 270, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 66, 1080, 270, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 270, 270, 1080, 270, 66, 66]
Prompts retrieved: 90624 . Total input tokens: 20161865 . Total output tokens: 18163334
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 2.5900463918223977,
    "estimated_duration": 3599.978687017972,
    "input_throughput": 2066.874458682831,
    "output_throughput": 1844.944533686025,
    "total_throughput": 3911.818992368856,
    "itl": 33.83705061324709,
    "ttft": 9055.859399975527,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6492,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.411406514505632,
    "arrivals": 30402,
    "finished_requests": 30326,
    "scheduler_time": 7.717891480226873
}
#Debug simulation 
Total elapsed time: 2.590178201906383. Arrivals time: 0.08408797904849052 Scheduler time: 2.0933635155670345 Scheduler overhead time: 0.10475990129634738 Adapter cache time: 0.16006277268752456 Engine time: 0.09862444689497352 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_192_slots_96_rate_0.1-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_192_slots_96_rate_0.1-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 270, 270, 270, 270, 1080, 270, 66, 1080, 66, 270, 270, 66, 1080, 1080, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 1080, 270, 66, 270, 1080, 1080, 270, 1080, 66, 270, 270, 1080, 270, 66, 66, 270, 1080, 66, 270, 66, 1080, 1080, 270, 1080, 1080, 1080, 66, 270, 1080, 66, 270, 66, 270, 66, 66, 270, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 270, 66, 66, 66, 66, 66, 1080, 66, 270, 66, 1080, 1080, 66, 1080, 66, 270, 270, 1080, 66, 66, 66, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 66, 1080, 270, 270, 270, 1080, 270, 66, 270, 1080, 1080, 270, 1080, 270, 66, 1080, 270, 66, 270, 270, 66, 270, 1080, 66, 270, 1080, 66, 270, 1080, 1080, 270, 66, 1080, 270, 66, 66, 270, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 270, 66, 1080, 1080, 270, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 66, 1080, 270, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 270, 270, 1080, 270, 66, 66]
Prompts retrieved: 90624 . Total input tokens: 20161865 . Total output tokens: 18163334
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.578699610196054,
    "estimated_duration": 3599.9868443199166,
    "input_throughput": 2066.869775299316,
    "output_throughput": 1844.9403531791831,
    "total_throughput": 3911.8101284784993,
    "itl": 33.87869832420929,
    "ttft": 9055.937681040563,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6492,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.728131815342394,
    "arrivals": 30402,
    "finished_requests": 30326,
    "scheduler_time": 7.741123939893819
}
#Debug simulation 
Total elapsed time: 2.578799177426845. Arrivals time: 0.08457502024248242 Scheduler time: 2.083894520998001 Scheduler overhead time: 0.10323238326236606 Adapter cache time: 0.1589594418182969 Engine time: 0.09896423108875751 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_192_slots_96_rate_0.1-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_192_slots_96_rate_0.1-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 270, 270, 270, 270, 1080, 270, 33, 1080, 33, 270, 270, 33, 1080, 1080, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 1080, 270, 33, 270, 1080, 1080, 270, 1080, 33, 270, 270, 1080, 270, 33, 33, 270, 1080, 33, 270, 33, 1080, 1080, 270, 1080, 1080, 1080, 33, 270, 1080, 33, 270, 33, 270, 33, 33, 270, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 270, 33, 33, 33, 33, 33, 1080, 33, 270, 33, 1080, 1080, 33, 1080, 33, 270, 270, 1080, 33, 33, 33, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 33, 1080, 270, 270, 270, 1080, 270, 33, 270, 1080, 1080, 270, 1080, 270, 33, 1080, 270, 33, 270, 270, 33, 270, 1080, 33, 270, 1080, 33, 270, 1080, 1080, 270, 33, 1080, 270, 33, 33, 270, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 270, 33, 1080, 1080, 270, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 33, 1080, 270, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 270, 270, 1080, 270, 33, 33]
Prompts retrieved: 88512 . Total input tokens: 19700412 . Total output tokens: 17743755
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 2.5472860760055482,
    "estimated_duration": 3600.011706707192,
    "input_throughput": 2028.0834049503937,
    "output_throughput": 1820.1621366374513,
    "total_throughput": 3848.245541587845,
    "itl": 33.05507036037458,
    "ttft": 10257.78223743699,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5327,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.303218211928076,
    "arrivals": 29640,
    "finished_requests": 29555,
    "scheduler_time": 6.955063781154934
}
#Debug simulation 
Total elapsed time: 2.5473896926268935. Arrivals time: 0.08433352317661047 Scheduler time: 2.0564659759402275 Scheduler overhead time: 0.10373902274295688 Adapter cache time: 0.1516352049075067 Engine time: 0.10145232081413269 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_192_slots_96_rate_0.1-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_192_slots_96_rate_0.1-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 270, 270, 270, 270, 1080, 270, 33, 1080, 33, 270, 270, 33, 1080, 1080, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 1080, 270, 33, 270, 1080, 1080, 270, 1080, 33, 270, 270, 1080, 270, 33, 33, 270, 1080, 33, 270, 33, 1080, 1080, 270, 1080, 1080, 1080, 33, 270, 1080, 33, 270, 33, 270, 33, 33, 270, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 270, 33, 33, 33, 33, 33, 1080, 33, 270, 33, 1080, 1080, 33, 1080, 33, 270, 270, 1080, 33, 33, 33, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 33, 1080, 270, 270, 270, 1080, 270, 33, 270, 1080, 1080, 270, 1080, 270, 33, 1080, 270, 33, 270, 270, 33, 270, 1080, 33, 270, 1080, 33, 270, 1080, 1080, 270, 33, 1080, 270, 33, 33, 270, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 270, 33, 1080, 1080, 270, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 33, 1080, 270, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 270, 270, 1080, 270, 33, 33]
Prompts retrieved: 88512 . Total input tokens: 19700412 . Total output tokens: 17743755
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.536839082837105,
    "estimated_duration": 3600.0260857199655,
    "input_throughput": 2028.0753044987605,
    "output_throughput": 1820.1548666527374,
    "total_throughput": 3848.230171151498,
    "itl": 33.073595340211405,
    "ttft": 10257.852400951371,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5330,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.374814997420792,
    "arrivals": 29640,
    "finished_requests": 29555,
    "scheduler_time": 6.965108582371368
}
#Debug simulation 
Total elapsed time: 2.5369871030561626. Arrivals time: 0.08202472608536482 Scheduler time: 2.0468922704458237 Scheduler overhead time: 0.10402964474633336 Adapter cache time: 0.1513178520835936 Engine time: 0.10309177963063121 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_192_slots_96_rate_0.1-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_192_slots_96_rate_0.1-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 270, 270, 270, 270, 1080, 270, 33, 1080, 33, 270, 270, 33, 1080, 1080, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 1080, 270, 33, 270, 1080, 1080, 270, 1080, 33, 270, 270, 1080, 270, 33, 33, 270, 1080, 33, 270, 33, 1080, 1080, 270, 1080, 1080, 1080, 33, 270, 1080, 33, 270, 33, 270, 33, 33, 270, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 270, 33, 33, 33, 33, 33, 1080, 33, 270, 33, 1080, 1080, 33, 1080, 33, 270, 270, 1080, 33, 33, 33, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 33, 1080, 270, 270, 270, 1080, 270, 33, 270, 1080, 1080, 270, 1080, 270, 33, 1080, 270, 33, 270, 270, 33, 270, 1080, 33, 270, 1080, 33, 270, 1080, 1080, 270, 33, 1080, 270, 33, 33, 270, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 270, 33, 1080, 1080, 270, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 33, 1080, 270, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 270, 270, 1080, 270, 33, 33]
Prompts retrieved: 88512 . Total input tokens: 19700412 . Total output tokens: 17743755
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.5364942993037403,
    "estimated_duration": 3600.026234065886,
    "input_throughput": 2028.0752209280645,
    "output_throughput": 1820.1547916497982,
    "total_throughput": 3848.2300125778625,
    "itl": 33.07514873921546,
    "ttft": 10257.967826549657,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5327,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.39892434565236,
    "arrivals": 29640,
    "finished_requests": 29555,
    "scheduler_time": 6.965476534781148
}
#Debug simulation 
Total elapsed time: 2.5366021250374615. Arrivals time: 0.08213833952322602 Scheduler time: 2.0474879359826446 Scheduler overhead time: 0.10339905740693212 Adapter cache time: 0.15204988699406385 Engine time: 0.10212290240451694 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_192_slots_96_rate_0.1-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_192_slots_96_rate_0.1-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 270, 270, 270, 270, 1080, 270, 33, 1080, 33, 270, 270, 33, 1080, 1080, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 1080, 270, 33, 270, 1080, 1080, 270, 1080, 33, 270, 270, 1080, 270, 33, 33, 270, 1080, 33, 270, 33, 1080, 1080, 270, 1080, 1080, 1080, 33, 270, 1080, 33, 270, 33, 270, 33, 33, 270, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 270, 33, 33, 33, 33, 33, 1080, 33, 270, 33, 1080, 1080, 33, 1080, 33, 270, 270, 1080, 33, 33, 33, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 33, 1080, 270, 270, 270, 1080, 270, 33, 270, 1080, 1080, 270, 1080, 270, 33, 1080, 270, 33, 270, 270, 33, 270, 1080, 33, 270, 1080, 33, 270, 1080, 1080, 270, 33, 1080, 270, 33, 33, 270, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 270, 33, 1080, 1080, 270, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 33, 1080, 270, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 270, 270, 1080, 270, 33, 33]
Prompts retrieved: 88512 . Total input tokens: 19700412 . Total output tokens: 17743755
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 2.5472665540874004,
    "estimated_duration": 3600.00859469707,
    "input_throughput": 2028.0851581173429,
    "output_throughput": 1820.1637100678595,
    "total_throughput": 3848.2488681852024,
    "itl": 33.06224385162525,
    "ttft": 10257.943392365933,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5327,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.62424434356751,
    "arrivals": 29640,
    "finished_requests": 29555,
    "scheduler_time": 6.957968787314576
}
#Debug simulation 
Total elapsed time: 2.547371511813253. Arrivals time: 0.08258798997849226 Scheduler time: 2.0536786750890315 Scheduler overhead time: 0.10681700240820646 Adapter cache time: 0.15158538706600666 Engine time: 0.10277951415628195 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_192_slots_96_rate_0.1-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_192_slots_96_rate_0.1-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 270, 270, 270, 270, 1080, 270, 33, 1080, 33, 270, 270, 33, 1080, 1080, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 1080, 270, 33, 270, 1080, 1080, 270, 1080, 33, 270, 270, 1080, 270, 33, 33, 270, 1080, 33, 270, 33, 1080, 1080, 270, 1080, 1080, 1080, 33, 270, 1080, 33, 270, 33, 270, 33, 33, 270, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 270, 33, 33, 33, 33, 33, 1080, 33, 270, 33, 1080, 1080, 33, 1080, 33, 270, 270, 1080, 33, 33, 33, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 33, 1080, 270, 270, 270, 1080, 270, 33, 270, 1080, 1080, 270, 1080, 270, 33, 1080, 270, 33, 270, 270, 33, 270, 1080, 33, 270, 1080, 33, 270, 1080, 1080, 270, 33, 1080, 270, 33, 33, 270, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 270, 33, 1080, 1080, 270, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 33, 1080, 270, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 270, 270, 1080, 270, 33, 33]
Prompts retrieved: 88512 . Total input tokens: 19700412 . Total output tokens: 17743755
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 2.5546473949216306,
    "estimated_duration": 3600.0340526556747,
    "input_throughput": 2028.0708163341133,
    "output_throughput": 1820.1508386195046,
    "total_throughput": 3848.221654953618,
    "itl": 33.078425852088515,
    "ttft": 10257.966809143987,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5326,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.62433544285478,
    "arrivals": 29640,
    "finished_requests": 29555,
    "scheduler_time": 6.967634418937159
}
#Debug simulation 
Total elapsed time: 2.5547528630122542. Arrivals time: 0.08360148640349507 Scheduler time: 2.0625403546728194 Scheduler overhead time: 0.1038340488448739 Adapter cache time: 0.15169035224243999 Engine time: 0.10328291030600667 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_192_slots_96_rate_0.1-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_192_slots_96_rate_0.1-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 270, 270, 270, 270, 1080, 270, 33, 1080, 33, 270, 270, 33, 1080, 1080, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 1080, 270, 33, 270, 1080, 1080, 270, 1080, 33, 270, 270, 1080, 270, 33, 33, 270, 1080, 33, 270, 33, 1080, 1080, 270, 1080, 1080, 1080, 33, 270, 1080, 33, 270, 33, 270, 33, 33, 270, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 270, 33, 33, 33, 33, 33, 1080, 33, 270, 33, 1080, 1080, 33, 1080, 33, 270, 270, 1080, 33, 33, 33, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 33, 1080, 270, 270, 270, 1080, 270, 33, 270, 1080, 1080, 270, 1080, 270, 33, 1080, 270, 33, 270, 270, 33, 270, 1080, 33, 270, 1080, 33, 270, 1080, 1080, 270, 33, 1080, 270, 33, 33, 270, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 270, 33, 1080, 1080, 270, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 33, 1080, 270, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 270, 270, 1080, 270, 33, 33]
Prompts retrieved: 88512 . Total input tokens: 19700412 . Total output tokens: 17743755
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 2.583813881035894,
    "estimated_duration": 3600.0092855556395,
    "input_throughput": 2028.0847689183436,
    "output_throughput": 1820.1633607699557,
    "total_throughput": 3848.2481296882993,
    "itl": 33.04940462851871,
    "ttft": 10257.898291025185,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5330,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.936968071830423,
    "arrivals": 29640,
    "finished_requests": 29555,
    "scheduler_time": 6.951538751880937
}
#Debug simulation 
Total elapsed time: 2.583908454980701. Arrivals time: 0.08162686787545681 Scheduler time: 2.092112984508276 Scheduler overhead time: 0.10424835048615932 Adapter cache time: 0.15294951247051358 Engine time: 0.10323505802080035 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_192_slots_96_rate_0.1-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_192_slots_96_rate_0.1-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 270, 270, 270, 270, 1080, 270, 33, 1080, 33, 270, 270, 33, 1080, 1080, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 1080, 270, 33, 270, 1080, 1080, 270, 1080, 33, 270, 270, 1080, 270, 33, 33, 270, 1080, 33, 270, 33, 1080, 1080, 270, 1080, 1080, 1080, 33, 270, 1080, 33, 270, 33, 270, 33, 33, 270, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 270, 33, 33, 33, 33, 33, 1080, 33, 270, 33, 1080, 1080, 33, 1080, 33, 270, 270, 1080, 33, 33, 33, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 33, 1080, 270, 270, 270, 1080, 270, 33, 270, 1080, 1080, 270, 1080, 270, 33, 1080, 270, 33, 270, 270, 33, 270, 1080, 33, 270, 1080, 33, 270, 1080, 1080, 270, 33, 1080, 270, 33, 33, 270, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 270, 33, 1080, 1080, 270, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 33, 1080, 270, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 270, 270, 1080, 270, 33, 33]
Prompts retrieved: 88512 . Total input tokens: 19700412 . Total output tokens: 17743755
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.5549056818708777,
    "estimated_duration": 3600.027681478122,
    "input_throughput": 2028.0744055285315,
    "output_throughput": 1820.1540598458928,
    "total_throughput": 3848.2284653744246,
    "itl": 33.08231386411092,
    "ttft": 10257.904642368369,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5329,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.847750451451716,
    "arrivals": 29640,
    "finished_requests": 29555,
    "scheduler_time": 6.969832292553567
}
#Debug simulation 
Total elapsed time: 2.555012639146298. Arrivals time: 0.0825636419467628 Scheduler time: 2.0645309812389314 Scheduler overhead time: 0.1028262204490602 Adapter cache time: 0.15259778033941984 Engine time: 0.10322732012718916 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_192_slots_96_rate_0.1-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_192_slots_96_rate_0.1-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 135, 135, 135, 135, 1080, 135, 66, 1080, 66, 135, 135, 66, 1080, 1080, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 1080, 135, 66, 135, 1080, 1080, 135, 1080, 66, 135, 135, 1080, 135, 66, 66, 135, 1080, 66, 135, 66, 1080, 1080, 135, 1080, 1080, 1080, 66, 135, 1080, 66, 135, 66, 135, 66, 66, 135, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 135, 66, 66, 66, 66, 66, 1080, 66, 135, 66, 1080, 1080, 66, 1080, 66, 135, 135, 1080, 66, 66, 66, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 66, 1080, 135, 135, 135, 1080, 135, 66, 135, 1080, 1080, 135, 1080, 135, 66, 1080, 135, 66, 135, 135, 66, 135, 1080, 66, 135, 1080, 66, 135, 1080, 1080, 135, 66, 1080, 135, 66, 66, 135, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 135, 66, 1080, 1080, 135, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 135, 135, 135, 135, 135, 135, 66, 1080, 135, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 135, 135, 1080, 135, 66, 66]
Prompts retrieved: 81984 . Total input tokens: 18269562 . Total output tokens: 16390057
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 2.377157330047339,
    "estimated_duration": 3600.0227359641094,
    "input_throughput": 1887.8080774620294,
    "output_throughput": 1666.1961437289658,
    "total_throughput": 3554.004221190995,
    "itl": 30.254071647491735,
    "ttft": 9204.602474829144,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3848,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.776756838652513,
    "arrivals": 27529,
    "finished_requests": 27458,
    "scheduler_time": 3.4883174891514064
}
#Debug simulation 
Total elapsed time: 2.377262939233333. Arrivals time: 0.078328060451895 Scheduler time: 1.8870216850191355 Scheduler overhead time: 0.11131038377061486 Adapter cache time: 0.14056888548657298 Engine time: 0.10686249379068613 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_192_slots_96_rate_0.1-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_192_slots_96_rate_0.1-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 135, 135, 135, 135, 1080, 135, 66, 1080, 66, 135, 135, 66, 1080, 1080, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 1080, 135, 66, 135, 1080, 1080, 135, 1080, 66, 135, 135, 1080, 135, 66, 66, 135, 1080, 66, 135, 66, 1080, 1080, 135, 1080, 1080, 1080, 66, 135, 1080, 66, 135, 66, 135, 66, 66, 135, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 135, 66, 66, 66, 66, 66, 1080, 66, 135, 66, 1080, 1080, 66, 1080, 66, 135, 135, 1080, 66, 66, 66, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 66, 1080, 135, 135, 135, 1080, 135, 66, 135, 1080, 1080, 135, 1080, 135, 66, 1080, 135, 66, 135, 135, 66, 135, 1080, 66, 135, 1080, 66, 135, 1080, 1080, 135, 66, 1080, 135, 66, 66, 135, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 135, 66, 1080, 1080, 135, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 135, 135, 135, 135, 135, 135, 66, 1080, 135, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 135, 135, 1080, 135, 66, 66]
Prompts retrieved: 81984 . Total input tokens: 18269562 . Total output tokens: 16390057
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.4005596917122602,
    "estimated_duration": 3600.00592576466,
    "input_throughput": 1887.8168925670482,
    "output_throughput": 1666.2039240187976,
    "total_throughput": 3554.0208165858458,
    "itl": 30.264737087196252,
    "ttft": 9204.771159552165,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3850,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.551977316122972,
    "arrivals": 27529,
    "finished_requests": 27458,
    "scheduler_time": 3.4939250526926102
}
#Debug simulation 
Total elapsed time: 2.400661681778729. Arrivals time: 0.07697348902001977 Scheduler time: 1.9086682721972466 Scheduler overhead time: 0.11103871744126081 Adapter cache time: 0.14125664997845888 Engine time: 0.10941528249531984 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_192_slots_96_rate_0.1-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_192_slots_96_rate_0.1-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 135, 135, 135, 135, 1080, 135, 66, 1080, 66, 135, 135, 66, 1080, 1080, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 1080, 135, 66, 135, 1080, 1080, 135, 1080, 66, 135, 135, 1080, 135, 66, 66, 135, 1080, 66, 135, 66, 1080, 1080, 135, 1080, 1080, 1080, 66, 135, 1080, 66, 135, 66, 135, 66, 66, 135, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 135, 66, 66, 66, 66, 66, 1080, 66, 135, 66, 1080, 1080, 66, 1080, 66, 135, 135, 1080, 66, 66, 66, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 66, 1080, 135, 135, 135, 1080, 135, 66, 135, 1080, 1080, 135, 1080, 135, 66, 1080, 135, 66, 135, 135, 66, 135, 1080, 66, 135, 1080, 66, 135, 1080, 1080, 135, 66, 1080, 135, 66, 66, 135, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 135, 66, 1080, 1080, 135, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 135, 135, 135, 135, 135, 135, 66, 1080, 135, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 135, 135, 1080, 135, 66, 66]
Prompts retrieved: 81984 . Total input tokens: 18269562 . Total output tokens: 16390057
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.385818722192198,
    "estimated_duration": 3600.016984594312,
    "input_throughput": 1887.8110934151225,
    "output_throughput": 1666.198805635901,
    "total_throughput": 3554.0098990510232,
    "itl": 30.26608647031301,
    "ttft": 9204.69648381134,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3849,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.572798922489506,
    "arrivals": 27529,
    "finished_requests": 27458,
    "scheduler_time": 3.4940594904659763
}
#Debug simulation 
Total elapsed time: 2.3859688150696456. Arrivals time: 0.0774091612547636 Scheduler time: 1.8949374929070473 Scheduler overhead time: 0.11145838210359216 Adapter cache time: 0.14125900762155652 Engine time: 0.10770013649016619 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_192_slots_96_rate_0.1-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_192_slots_96_rate_0.1-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 135, 135, 135, 135, 1080, 135, 66, 1080, 66, 135, 135, 66, 1080, 1080, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 1080, 135, 66, 135, 1080, 1080, 135, 1080, 66, 135, 135, 1080, 135, 66, 66, 135, 1080, 66, 135, 66, 1080, 1080, 135, 1080, 1080, 1080, 66, 135, 1080, 66, 135, 66, 135, 66, 66, 135, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 135, 66, 66, 66, 66, 66, 1080, 66, 135, 66, 1080, 1080, 66, 1080, 66, 135, 135, 1080, 66, 66, 66, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 66, 1080, 135, 135, 135, 1080, 135, 66, 135, 1080, 1080, 135, 1080, 135, 66, 1080, 135, 66, 135, 135, 66, 135, 1080, 66, 135, 1080, 66, 135, 1080, 1080, 135, 66, 1080, 135, 66, 66, 135, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 135, 66, 1080, 1080, 135, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 135, 135, 135, 135, 135, 135, 66, 1080, 135, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 135, 135, 1080, 135, 66, 66]
Prompts retrieved: 81984 . Total input tokens: 18269562 . Total output tokens: 16390057
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 2.4140441501513124,
    "estimated_duration": 3600.0160615645696,
    "input_throughput": 1887.8115774423482,
    "output_throughput": 1666.199232842621,
    "total_throughput": 3554.0108102849695,
    "itl": 30.258217776103397,
    "ttft": 9204.72555259272,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3842,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.998108785746739,
    "arrivals": 27529,
    "finished_requests": 27458,
    "scheduler_time": 3.4899583467421227
}
#Debug simulation 
Total elapsed time: 2.4141499623656273. Arrivals time: 0.07812757510691881 Scheduler time: 1.9133444130420685 Scheduler overhead time: 0.11572334868833423 Adapter cache time: 0.1410356662236154 Engine time: 0.11170081328600645 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_192_slots_96_rate_0.1-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_192_slots_96_rate_0.1-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 135, 135, 135, 135, 1080, 135, 66, 1080, 66, 135, 135, 66, 1080, 1080, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 1080, 135, 66, 135, 1080, 1080, 135, 1080, 66, 135, 135, 1080, 135, 66, 66, 135, 1080, 66, 135, 66, 1080, 1080, 135, 1080, 1080, 1080, 66, 135, 1080, 66, 135, 66, 135, 66, 66, 135, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 135, 66, 66, 66, 66, 66, 1080, 66, 135, 66, 1080, 1080, 66, 1080, 66, 135, 135, 1080, 66, 66, 66, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 66, 1080, 135, 135, 135, 1080, 135, 66, 135, 1080, 1080, 135, 1080, 135, 66, 1080, 135, 66, 135, 135, 66, 135, 1080, 66, 135, 1080, 66, 135, 1080, 1080, 135, 66, 1080, 135, 66, 66, 135, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 135, 66, 1080, 1080, 135, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 135, 135, 135, 135, 135, 135, 66, 1080, 135, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 135, 135, 1080, 135, 66, 66]
Prompts retrieved: 81984 . Total input tokens: 18269562 . Total output tokens: 16390057
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 2.385189548600465,
    "estimated_duration": 3600.020256497252,
    "input_throughput": 1887.809377665147,
    "output_throughput": 1666.1972912997633,
    "total_throughput": 3554.00666896491,
    "itl": 30.267392874486394,
    "ttft": 9204.732534624927,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3846,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.725004761721111,
    "arrivals": 27529,
    "finished_requests": 27458,
    "scheduler_time": 3.49531625828282
}
#Debug simulation 
Total elapsed time: 2.3852906967513263. Arrivals time: 0.07727415533736348 Scheduler time: 1.8954735309816897 Scheduler overhead time: 0.11148789944127202 Adapter cache time: 0.14046166418120265 Engine time: 0.10755877709016204 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_192_slots_96_rate_0.1-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_192_slots_96_rate_0.1-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 135, 135, 135, 135, 1080, 135, 66, 1080, 66, 135, 135, 66, 1080, 1080, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 1080, 135, 66, 135, 1080, 1080, 135, 1080, 66, 135, 135, 1080, 135, 66, 66, 135, 1080, 66, 135, 66, 1080, 1080, 135, 1080, 1080, 1080, 66, 135, 1080, 66, 135, 66, 135, 66, 66, 135, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 135, 66, 66, 66, 66, 66, 1080, 66, 135, 66, 1080, 1080, 66, 1080, 66, 135, 135, 1080, 66, 66, 66, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 66, 1080, 135, 135, 135, 1080, 135, 66, 135, 1080, 1080, 135, 1080, 135, 66, 1080, 135, 66, 135, 135, 66, 135, 1080, 66, 135, 1080, 66, 135, 1080, 1080, 135, 66, 1080, 135, 66, 66, 135, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 135, 66, 1080, 1080, 135, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 135, 135, 135, 135, 135, 135, 66, 1080, 135, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 135, 135, 1080, 135, 66, 66]
Prompts retrieved: 81984 . Total input tokens: 18269562 . Total output tokens: 16390057
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 2.434564407914877,
    "estimated_duration": 3600.0120626080025,
    "input_throughput": 1887.8136744565732,
    "output_throughput": 1666.2010836859652,
    "total_throughput": 3554.014758142538,
    "itl": 30.249886042937902,
    "ttft": 9204.6790729437,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3847,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.502723484489337,
    "arrivals": 27529,
    "finished_requests": 27458,
    "scheduler_time": 3.4861575616573766
}
#Debug simulation 
Total elapsed time: 2.4346665791235864. Arrivals time: 0.07793973479419947 Scheduler time: 1.9399821255356073 Scheduler overhead time: 0.11232202686369419 Adapter cache time: 0.14064370607957244 Engine time: 0.11025263788178563 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_192_slots_96_rate_0.1-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_192_slots_96_rate_0.1-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 135, 135, 135, 135, 1080, 135, 66, 1080, 66, 135, 135, 66, 1080, 1080, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 1080, 135, 66, 135, 1080, 1080, 135, 1080, 66, 135, 135, 1080, 135, 66, 66, 135, 1080, 66, 135, 66, 1080, 1080, 135, 1080, 1080, 1080, 66, 135, 1080, 66, 135, 66, 135, 66, 66, 135, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 135, 66, 66, 66, 66, 66, 1080, 66, 135, 66, 1080, 1080, 66, 1080, 66, 135, 135, 1080, 66, 66, 66, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 66, 1080, 135, 135, 135, 1080, 135, 66, 135, 1080, 1080, 135, 1080, 135, 66, 1080, 135, 66, 135, 135, 66, 135, 1080, 66, 135, 1080, 66, 135, 1080, 1080, 135, 66, 1080, 135, 66, 66, 135, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 135, 66, 1080, 1080, 135, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 135, 135, 135, 135, 135, 135, 66, 1080, 135, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 135, 135, 1080, 135, 66, 66]
Prompts retrieved: 81984 . Total input tokens: 18269562 . Total output tokens: 16390057
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.3793108579702675,
    "estimated_duration": 3600.0048688017455,
    "input_throughput": 1887.8174468308666,
    "output_throughput": 1666.204413216957,
    "total_throughput": 3554.0218600478233,
    "itl": 30.271060974549446,
    "ttft": 9204.706466865104,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3848,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.888409786223546,
    "arrivals": 27529,
    "finished_requests": 27458,
    "scheduler_time": 3.4964417991482852
}
#Debug simulation 
Total elapsed time: 2.379417410120368. Arrivals time: 0.07717269193381071 Scheduler time: 1.8868498890660703 Scheduler overhead time: 0.11132966773584485 Adapter cache time: 0.14121934166178107 Engine time: 0.10969104710966349 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_192_slots_96_rate_0.1-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_192_slots_96_rate_0.1-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 135, 135, 135, 135, 1080, 135, 33, 1080, 33, 135, 135, 33, 1080, 1080, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 1080, 135, 33, 135, 1080, 1080, 135, 1080, 33, 135, 135, 1080, 135, 33, 33, 135, 1080, 33, 135, 33, 1080, 1080, 135, 1080, 1080, 1080, 33, 135, 1080, 33, 135, 33, 135, 33, 33, 135, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 135, 33, 33, 33, 33, 33, 1080, 33, 135, 33, 1080, 1080, 33, 1080, 33, 135, 135, 1080, 33, 33, 33, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 33, 1080, 135, 135, 135, 1080, 135, 33, 135, 1080, 1080, 135, 1080, 135, 33, 1080, 135, 33, 135, 135, 33, 135, 1080, 33, 135, 1080, 33, 135, 1080, 1080, 135, 33, 1080, 135, 33, 33, 135, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 135, 33, 1080, 1080, 135, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 135, 135, 135, 135, 135, 135, 33, 1080, 135, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 79872 . Total input tokens: 17789080 . Total output tokens: 15964667
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 2.3500446500256658,
    "estimated_duration": 3599.982442470355,
    "input_throughput": 1817.4452527358062,
    "output_throughput": 1625.8559850040708,
    "total_throughput": 3443.3012377398773,
    "itl": 29.455580151644583,
    "ttft": 7851.5147795831745,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2791,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.541821293316419,
    "arrivals": 26760,
    "finished_requests": 26702,
    "scheduler_time": 2.602111565216356
}
#Debug simulation 
Total elapsed time: 2.3501425213180482. Arrivals time: 0.07599612139165401 Scheduler time: 1.8599209506064653 Scheduler overhead time: 0.11336081428453326 Adapter cache time: 0.13487401558086276 Engine time: 0.11162713682278991 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_192_slots_96_rate_0.1-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_192_slots_96_rate_0.1-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 135, 135, 135, 135, 1080, 135, 33, 1080, 33, 135, 135, 33, 1080, 1080, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 1080, 135, 33, 135, 1080, 1080, 135, 1080, 33, 135, 135, 1080, 135, 33, 33, 135, 1080, 33, 135, 33, 1080, 1080, 135, 1080, 1080, 1080, 33, 135, 1080, 33, 135, 33, 135, 33, 33, 135, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 135, 33, 33, 33, 33, 33, 1080, 33, 135, 33, 1080, 1080, 33, 1080, 33, 135, 135, 1080, 33, 33, 33, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 33, 1080, 135, 135, 135, 1080, 135, 33, 135, 1080, 1080, 135, 1080, 135, 33, 1080, 135, 33, 135, 135, 33, 135, 1080, 33, 135, 1080, 33, 135, 1080, 1080, 135, 33, 1080, 135, 33, 33, 135, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 135, 33, 1080, 1080, 135, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 135, 135, 135, 135, 135, 135, 33, 1080, 135, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 79872 . Total input tokens: 17789080 . Total output tokens: 15964667
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.324567968957126,
    "estimated_duration": 3599.9929006384054,
    "input_throughput": 1817.4399729620957,
    "output_throughput": 1625.851261807224,
    "total_throughput": 3443.2912347693195,
    "itl": 29.46258789077706,
    "ttft": 7851.722238094453,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2789,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.089431277138493,
    "arrivals": 26760,
    "finished_requests": 26702,
    "scheduler_time": 2.6058149832781274
}
#Debug simulation 
Total elapsed time: 2.3246681271120906. Arrivals time: 0.07481981394812465 Scheduler time: 1.836889267899096 Scheduler overhead time: 0.11354480125010014 Adapter cache time: 0.13509825430810452 Engine time: 0.10978940827772021 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_192_slots_96_rate_0.1-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_192_slots_96_rate_0.1-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 135, 135, 135, 135, 1080, 135, 33, 1080, 33, 135, 135, 33, 1080, 1080, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 1080, 135, 33, 135, 1080, 1080, 135, 1080, 33, 135, 135, 1080, 135, 33, 33, 135, 1080, 33, 135, 33, 1080, 1080, 135, 1080, 1080, 1080, 33, 135, 1080, 33, 135, 33, 135, 33, 33, 135, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 135, 33, 33, 33, 33, 33, 1080, 33, 135, 33, 1080, 1080, 33, 1080, 33, 135, 135, 1080, 33, 33, 33, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 33, 1080, 135, 135, 135, 1080, 135, 33, 135, 1080, 1080, 135, 1080, 135, 33, 1080, 135, 33, 135, 135, 33, 135, 1080, 33, 135, 1080, 33, 135, 1080, 1080, 135, 33, 1080, 135, 33, 33, 135, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 135, 33, 1080, 1080, 135, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 135, 135, 135, 135, 135, 135, 33, 1080, 135, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 79872 . Total input tokens: 17789080 . Total output tokens: 15964667
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.3514109309762716,
    "estimated_duration": 3599.9892826522714,
    "input_throughput": 1817.441799487706,
    "output_throughput": 1625.8528957863443,
    "total_throughput": 3443.2946952740504,
    "itl": 29.462823211366818,
    "ttft": 7851.638751039236,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2790,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.110603988021373,
    "arrivals": 26760,
    "finished_requests": 26702,
    "scheduler_time": 2.605891376010923
}
#Debug simulation 
Total elapsed time: 2.3515133392065763. Arrivals time: 0.07585085090249777 Scheduler time: 1.861042883247137 Scheduler overhead time: 0.1128124576061964 Adapter cache time: 0.13536331802606583 Engine time: 0.1122466865926981 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_192_slots_96_rate_0.1-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_192_slots_96_rate_0.1-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 135, 135, 135, 135, 1080, 135, 33, 1080, 33, 135, 135, 33, 1080, 1080, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 1080, 135, 33, 135, 1080, 1080, 135, 1080, 33, 135, 135, 1080, 135, 33, 33, 135, 1080, 33, 135, 33, 1080, 1080, 135, 1080, 1080, 1080, 33, 135, 1080, 33, 135, 33, 135, 33, 33, 135, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 135, 33, 33, 33, 33, 33, 1080, 33, 135, 33, 1080, 1080, 33, 1080, 33, 135, 135, 1080, 33, 33, 33, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 33, 1080, 135, 135, 135, 1080, 135, 33, 135, 1080, 1080, 135, 1080, 135, 33, 1080, 135, 33, 135, 135, 33, 135, 1080, 33, 135, 1080, 33, 135, 1080, 1080, 135, 33, 1080, 135, 33, 33, 135, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 135, 33, 1080, 1080, 135, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 135, 135, 135, 135, 135, 135, 33, 1080, 135, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 79872 . Total input tokens: 17789080 . Total output tokens: 15964667
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 2.343299583066255,
    "estimated_duration": 3599.98460297302,
    "input_throughput": 1817.4441620102214,
    "output_throughput": 1625.8550092592898,
    "total_throughput": 3443.299171269511,
    "itl": 29.45650019322695,
    "ttft": 7851.73402718421,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2791,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.697848132885845,
    "arrivals": 26760,
    "finished_requests": 26702,
    "scheduler_time": 2.6030150170055757
}
#Debug simulation 
Total elapsed time: 2.3434493369422853. Arrivals time: 0.0752263879403472 Scheduler time: 1.854767831042409 Scheduler overhead time: 0.11355130607262254 Adapter cache time: 0.1356536764651537 Engine time: 0.10992161557078362 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_192_slots_96_rate_0.1-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_192_slots_96_rate_0.1-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 135, 135, 135, 135, 1080, 135, 33, 1080, 33, 135, 135, 33, 1080, 1080, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 1080, 135, 33, 135, 1080, 1080, 135, 1080, 33, 135, 135, 1080, 135, 33, 33, 135, 1080, 33, 135, 33, 1080, 1080, 135, 1080, 1080, 1080, 33, 135, 1080, 33, 135, 33, 135, 33, 33, 135, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 135, 33, 33, 33, 33, 33, 1080, 33, 135, 33, 1080, 1080, 33, 1080, 33, 135, 135, 1080, 33, 33, 33, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 33, 1080, 135, 135, 135, 1080, 135, 33, 135, 1080, 1080, 135, 1080, 135, 33, 1080, 135, 33, 135, 135, 33, 135, 1080, 33, 135, 1080, 33, 135, 1080, 1080, 135, 33, 1080, 135, 33, 33, 135, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 135, 33, 1080, 1080, 135, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 135, 135, 135, 135, 135, 135, 33, 1080, 135, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 79872 . Total input tokens: 17789080 . Total output tokens: 15964667
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 2.325736907310784,
    "estimated_duration": 3599.9715330482295,
    "input_throughput": 1817.450760356428,
    "output_throughput": 1625.8609120289357,
    "total_throughput": 3443.3116723853636,
    "itl": 29.46424662117118,
    "ttft": 7851.568909239312,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2789,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.2299189033542,
    "arrivals": 26760,
    "finished_requests": 26702,
    "scheduler_time": 2.6066801135789768
}
#Debug simulation 
Total elapsed time: 2.325839212164283. Arrivals time: 0.07553646620362997 Scheduler time: 1.8388885762542486 Scheduler overhead time: 0.11268158163875341 Adapter cache time: 0.13495973590761423 Engine time: 0.10960749164223671 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_192_slots_96_rate_0.1-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_192_slots_96_rate_0.1-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 135, 135, 135, 135, 1080, 135, 33, 1080, 33, 135, 135, 33, 1080, 1080, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 1080, 135, 33, 135, 1080, 1080, 135, 1080, 33, 135, 135, 1080, 135, 33, 33, 135, 1080, 33, 135, 33, 1080, 1080, 135, 1080, 1080, 1080, 33, 135, 1080, 33, 135, 33, 135, 33, 33, 135, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 135, 33, 33, 33, 33, 33, 1080, 33, 135, 33, 1080, 1080, 33, 1080, 33, 135, 135, 1080, 33, 33, 33, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 33, 1080, 135, 135, 135, 1080, 135, 33, 135, 1080, 1080, 135, 1080, 135, 33, 1080, 135, 33, 135, 135, 33, 135, 1080, 33, 135, 1080, 33, 135, 1080, 1080, 135, 33, 1080, 135, 33, 33, 135, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 135, 33, 1080, 1080, 135, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 135, 135, 135, 135, 135, 135, 33, 1080, 135, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 79872 . Total input tokens: 17789080 . Total output tokens: 15964667
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 2.315592702012509,
    "estimated_duration": 3599.9827325723522,
    "input_throughput": 1817.445106278299,
    "output_throughput": 1625.8558539856456,
    "total_throughput": 3443.3009602639445,
    "itl": 29.451402720025758,
    "ttft": 7851.595640175894,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2790,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.342240322776911,
    "arrivals": 26760,
    "finished_requests": 26702,
    "scheduler_time": 2.60073858219633
}
#Debug simulation 
Total elapsed time: 2.31568222399801. Arrivals time: 0.07501723896712065 Scheduler time: 1.8271993682719767 Scheduler overhead time: 0.11263254331424832 Adapter cache time: 0.13428391655907035 Engine time: 0.11258226213976741 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_192_slots_96_rate_0.1-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_192_slots_96_rate_0.1-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 135, 135, 135, 135, 1080, 135, 33, 1080, 33, 135, 135, 33, 1080, 1080, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 1080, 135, 33, 135, 1080, 1080, 135, 1080, 33, 135, 135, 1080, 135, 33, 33, 135, 1080, 33, 135, 33, 1080, 1080, 135, 1080, 1080, 1080, 33, 135, 1080, 33, 135, 33, 135, 33, 33, 135, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 135, 33, 33, 33, 33, 33, 1080, 33, 135, 33, 1080, 1080, 33, 1080, 33, 135, 135, 1080, 33, 33, 33, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 33, 1080, 135, 135, 135, 1080, 135, 33, 135, 1080, 1080, 135, 1080, 135, 33, 1080, 135, 33, 135, 135, 33, 135, 1080, 33, 135, 1080, 33, 135, 1080, 1080, 135, 33, 1080, 135, 33, 33, 135, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 135, 33, 1080, 1080, 135, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 135, 135, 135, 135, 135, 135, 33, 1080, 135, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 79872 . Total input tokens: 17789080 . Total output tokens: 15964667
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.335634760092944,
    "estimated_duration": 3599.998148934307,
    "input_throughput": 1817.4373233877438,
    "output_throughput": 1625.8488915425291,
    "total_throughput": 3443.286214930273,
    "itl": 29.46630998912995,
    "ttft": 7851.666060338309,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2789,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.338444421030111,
    "arrivals": 26760,
    "finished_requests": 26702,
    "scheduler_time": 2.6072583127528777
}
#Debug simulation 
Total elapsed time: 2.335731015074998. Arrivals time: 0.07453301083296537 Scheduler time: 1.8487558793276548 Scheduler overhead time: 0.11381823988631368 Adapter cache time: 0.1345421178266406 Engine time: 0.10934909526258707 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_192_slots_96_rate_0.1-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_192_slots_96_rate_0.1-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 66, 66, 66, 66, 1080, 66, 33, 1080, 33, 66, 66, 33, 1080, 1080, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 1080, 66, 33, 66, 1080, 1080, 66, 1080, 33, 66, 66, 1080, 66, 33, 33, 66, 1080, 33, 66, 33, 1080, 1080, 66, 1080, 1080, 1080, 33, 66, 1080, 33, 66, 33, 66, 33, 33, 66, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 66, 33, 33, 33, 33, 33, 1080, 33, 66, 33, 1080, 1080, 33, 1080, 33, 66, 66, 1080, 33, 33, 33, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 33, 1080, 66, 66, 66, 1080, 66, 33, 66, 1080, 1080, 66, 1080, 66, 33, 1080, 66, 33, 66, 66, 33, 66, 1080, 33, 66, 1080, 33, 66, 1080, 1080, 66, 33, 1080, 66, 33, 33, 66, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 66, 33, 1080, 1080, 66, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 66, 66, 66, 66, 66, 66, 33, 1080, 66, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 75456 . Total input tokens: 16792402 . Total output tokens: 15073813
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 2.210551396012306,
    "estimated_duration": 3599.8750444738275,
    "input_throughput": 1729.157518829889,
    "output_throughput": 1542.8682749769762,
    "total_throughput": 3272.0257938068653,
    "itl": 28.130425904238916,
    "ttft": 6723.203921792291,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1686,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.159982336270766,
    "arrivals": 25342,
    "finished_requests": 25295,
    "scheduler_time": 1.3076733081324816
}
#Debug simulation 
Total elapsed time: 2.210647117346525. Arrivals time: 0.07093456108123064 Scheduler time: 1.7281623082235456 Scheduler overhead time: 0.1173622696660459 Adapter cache time: 0.12403356656432152 Engine time: 0.1144952061586082 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_192_slots_96_rate_0.1-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_192_slots_96_rate_0.1-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 66, 66, 66, 66, 1080, 66, 33, 1080, 33, 66, 66, 33, 1080, 1080, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 1080, 66, 33, 66, 1080, 1080, 66, 1080, 33, 66, 66, 1080, 66, 33, 33, 66, 1080, 33, 66, 33, 1080, 1080, 66, 1080, 1080, 1080, 33, 66, 1080, 33, 66, 33, 66, 33, 33, 66, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 66, 33, 33, 33, 33, 33, 1080, 33, 66, 33, 1080, 1080, 33, 1080, 33, 66, 66, 1080, 33, 33, 33, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 33, 1080, 66, 66, 66, 1080, 66, 33, 66, 1080, 1080, 66, 1080, 66, 33, 1080, 66, 33, 66, 66, 33, 66, 1080, 33, 66, 1080, 33, 66, 1080, 1080, 66, 33, 1080, 66, 33, 33, 66, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 66, 33, 1080, 1080, 66, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 66, 66, 66, 66, 66, 66, 33, 1080, 66, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 75456 . Total input tokens: 16792402 . Total output tokens: 15073813
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.2097405907697976,
    "estimated_duration": 3599.894884495894,
    "input_throughput": 1729.147988961815,
    "output_throughput": 1542.8597718007438,
    "total_throughput": 3272.0077607625585,
    "itl": 28.134210445813565,
    "ttft": 6723.412439552259,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1686,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.497625767902805,
    "arrivals": 25342,
    "finished_requests": 25295,
    "scheduler_time": 1.309175266389807
}
#Debug simulation 
Total elapsed time: 2.209840388968587. Arrivals time: 0.07104978803545237 Scheduler time: 1.730423682834953 Scheduler overhead time: 0.11602835729718208 Adapter cache time: 0.1232044599018991 Engine time: 0.11385111091658473 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_192_slots_96_rate_0.1-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_192_slots_96_rate_0.1-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 66, 66, 66, 66, 1080, 66, 33, 1080, 33, 66, 66, 33, 1080, 1080, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 1080, 66, 33, 66, 1080, 1080, 66, 1080, 33, 66, 66, 1080, 66, 33, 33, 66, 1080, 33, 66, 33, 1080, 1080, 66, 1080, 1080, 1080, 33, 66, 1080, 33, 66, 33, 66, 33, 33, 66, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 66, 33, 33, 33, 33, 33, 1080, 33, 66, 33, 1080, 1080, 33, 1080, 33, 66, 66, 1080, 33, 33, 33, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 33, 1080, 66, 66, 66, 1080, 66, 33, 66, 1080, 1080, 66, 1080, 66, 33, 1080, 66, 33, 66, 66, 33, 66, 1080, 33, 66, 1080, 33, 66, 1080, 1080, 66, 33, 1080, 66, 33, 33, 66, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 66, 33, 1080, 1080, 66, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 66, 66, 66, 66, 66, 66, 33, 1080, 66, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 75456 . Total input tokens: 16792402 . Total output tokens: 15073813
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.220283734612167,
    "estimated_duration": 3599.872224029862,
    "input_throughput": 1729.1588735979435,
    "output_throughput": 1542.8694837903022,
    "total_throughput": 3272.0283573882457,
    "itl": 28.134151131971194,
    "ttft": 6723.387038565014,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1686,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.508078230414491,
    "arrivals": 25342,
    "finished_requests": 25295,
    "scheduler_time": 1.3091388631174337
}
#Debug simulation 
Total elapsed time: 2.220378211699426. Arrivals time: 0.07064553676173091 Scheduler time: 1.7328411196358502 Scheduler overhead time: 0.11736796563491225 Adapter cache time: 0.12416636850684881 Engine time: 0.11962237674742937 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_192_slots_96_rate_0.1-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_192_slots_96_rate_0.1-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 66, 66, 66, 66, 1080, 66, 33, 1080, 33, 66, 66, 33, 1080, 1080, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 1080, 66, 33, 66, 1080, 1080, 66, 1080, 33, 66, 66, 1080, 66, 33, 33, 66, 1080, 33, 66, 33, 1080, 1080, 66, 1080, 1080, 1080, 33, 66, 1080, 33, 66, 33, 66, 33, 33, 66, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 66, 33, 33, 33, 33, 33, 1080, 33, 66, 33, 1080, 1080, 33, 1080, 33, 66, 66, 1080, 33, 33, 33, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 33, 1080, 66, 66, 66, 1080, 66, 33, 66, 1080, 1080, 66, 1080, 66, 33, 1080, 66, 33, 66, 66, 33, 66, 1080, 33, 66, 1080, 33, 66, 1080, 1080, 66, 33, 1080, 66, 33, 33, 66, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 66, 33, 1080, 1080, 66, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 66, 66, 66, 66, 66, 66, 33, 1080, 66, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 75456 . Total input tokens: 16792402 . Total output tokens: 15073813
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 2.23442402202636,
    "estimated_duration": 3599.869961046752,
    "input_throughput": 1729.1599605975762,
    "output_throughput": 1542.8704536829985,
    "total_throughput": 3272.030414280575,
    "itl": 28.131988784957148,
    "ttft": 6723.409831672757,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1686,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.256145934704565,
    "arrivals": 25342,
    "finished_requests": 25295,
    "scheduler_time": 1.3081259931351001
}
#Debug simulation 
Total elapsed time: 2.234528435859829. Arrivals time: 0.07058762386441231 Scheduler time: 1.7546382611617446 Scheduler overhead time: 0.11700450908392668 Adapter cache time: 0.12356961937621236 Engine time: 0.11280417209491134 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_192_slots_96_rate_0.1-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_192_slots_96_rate_0.1-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 66, 66, 66, 66, 1080, 66, 33, 1080, 33, 66, 66, 33, 1080, 1080, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 1080, 66, 33, 66, 1080, 1080, 66, 1080, 33, 66, 66, 1080, 66, 33, 33, 66, 1080, 33, 66, 33, 1080, 1080, 66, 1080, 1080, 1080, 33, 66, 1080, 33, 66, 33, 66, 33, 33, 66, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 66, 33, 33, 33, 33, 33, 1080, 33, 66, 33, 1080, 1080, 33, 1080, 33, 66, 66, 1080, 33, 33, 33, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 33, 1080, 66, 66, 66, 1080, 66, 33, 66, 1080, 1080, 66, 1080, 66, 33, 1080, 66, 33, 66, 66, 33, 66, 1080, 33, 66, 1080, 33, 66, 1080, 1080, 66, 33, 1080, 66, 33, 33, 66, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 66, 33, 1080, 1080, 66, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 66, 66, 66, 66, 66, 66, 33, 1080, 66, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 75456 . Total input tokens: 16792402 . Total output tokens: 15073813
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 2.2711637099273503,
    "estimated_duration": 3599.8912876531604,
    "input_throughput": 1729.1497166454815,
    "output_throughput": 1542.8613133539507,
    "total_throughput": 3272.011029999432,
    "itl": 28.135844251541148,
    "ttft": 6723.3729327991605,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1686,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.5823987181856465,
    "arrivals": 25342,
    "finished_requests": 25295,
    "scheduler_time": 1.3094883845809953
}
#Debug simulation 
Total elapsed time: 2.2712677279487252. Arrivals time: 0.07103189406916499 Scheduler time: 1.7886912911199033 Scheduler overhead time: 0.11681379238143563 Adapter cache time: 0.12419960414990783 Engine time: 0.1150870225392282 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_192_slots_96_rate_0.1-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_192_slots_96_rate_0.1-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 66, 66, 66, 66, 1080, 66, 33, 1080, 33, 66, 66, 33, 1080, 1080, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 1080, 66, 33, 66, 1080, 1080, 66, 1080, 33, 66, 66, 1080, 66, 33, 33, 66, 1080, 33, 66, 33, 1080, 1080, 66, 1080, 1080, 1080, 33, 66, 1080, 33, 66, 33, 66, 33, 33, 66, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 66, 33, 33, 33, 33, 33, 1080, 33, 66, 33, 1080, 1080, 33, 1080, 33, 66, 66, 1080, 33, 33, 33, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 33, 1080, 66, 66, 66, 1080, 66, 33, 66, 1080, 1080, 66, 1080, 66, 33, 1080, 66, 33, 66, 66, 33, 66, 1080, 33, 66, 1080, 33, 66, 1080, 1080, 66, 33, 1080, 66, 33, 33, 66, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 66, 33, 1080, 1080, 66, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 66, 66, 66, 66, 66, 66, 33, 1080, 66, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 75456 . Total input tokens: 16792402 . Total output tokens: 15073813
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 2.2178173433057964,
    "estimated_duration": 3599.88896466427,
    "input_throughput": 1729.150832456447,
    "output_throughput": 1542.8623089540165,
    "total_throughput": 3272.0131414104635,
    "itl": 28.129009370197643,
    "ttft": 6723.291469620664,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1686,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.041224797204926,
    "arrivals": 25342,
    "finished_requests": 25295,
    "scheduler_time": 1.307202775925671
}
#Debug simulation 
Total elapsed time: 2.217915083281696. Arrivals time: 0.06904306588694453 Scheduler time: 1.742208642885089 Scheduler overhead time: 0.11644314043223858 Adapter cache time: 0.12321456521749496 Engine time: 0.11166934622451663 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_192_slots_96_rate_0.1-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_192_slots_96_rate_0.1-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 66, 66, 66, 66, 1080, 66, 33, 1080, 33, 66, 66, 33, 1080, 1080, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 1080, 66, 33, 66, 1080, 1080, 66, 1080, 33, 66, 66, 1080, 66, 33, 33, 66, 1080, 33, 66, 33, 1080, 1080, 66, 1080, 1080, 1080, 33, 66, 1080, 33, 66, 33, 66, 33, 33, 66, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 66, 33, 33, 33, 33, 33, 1080, 33, 66, 33, 1080, 1080, 33, 1080, 33, 66, 66, 1080, 33, 33, 33, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 33, 1080, 66, 66, 66, 1080, 66, 33, 66, 1080, 1080, 66, 1080, 66, 33, 1080, 66, 33, 66, 66, 33, 66, 1080, 33, 66, 1080, 33, 66, 1080, 1080, 66, 33, 1080, 66, 33, 33, 66, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 66, 33, 1080, 1080, 66, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 66, 66, 66, 66, 66, 66, 33, 1080, 66, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 75456 . Total input tokens: 16792402 . Total output tokens: 15073813
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.2029990879818797,
    "estimated_duration": 3599.8819552289447,
    "input_throughput": 1729.15419933655,
    "output_throughput": 1542.8653131062931,
    "total_throughput": 3272.019512442843,
    "itl": 28.136165363608672,
    "ttft": 6723.3438480969235,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1686,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.648545209839839,
    "arrivals": 25342,
    "finished_requests": 25295,
    "scheduler_time": 1.3096584335087502
}
#Debug simulation 
Total elapsed time: 2.2031085551716387. Arrivals time: 0.07052922062575817 Scheduler time: 1.7249172581359744 Scheduler overhead time: 0.11569433007389307 Adapter cache time: 0.12337134638801217 Engine time: 0.11184997484087944 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_192_slots_96_rate_0.05-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_192_slots_96_rate_0.05-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [64 64 64]
Adapter prompts. [540, 135, 540, 135, 540, 135, 540, 135, 135, 135, 270, 270, 270, 270, 540, 270, 135, 540, 135, 270, 270, 135, 540, 540, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 540, 270, 135, 270, 540, 540, 270, 540, 135, 270, 270, 540, 270, 135, 135, 270, 540, 135, 270, 135, 540, 540, 270, 540, 540, 540, 135, 270, 540, 135, 270, 135, 270, 135, 135, 270, 540, 540, 135, 135, 135, 540, 540, 540, 270, 135, 135, 135, 135, 135, 540, 135, 270, 135, 540, 540, 135, 540, 135, 270, 270, 540, 135, 135, 135, 540, 540, 270, 540, 270, 540, 540, 270, 270, 135, 540, 270, 270, 270, 540, 270, 135, 270, 540, 540, 270, 540, 270, 135, 540, 270, 135, 270, 270, 135, 270, 540, 135, 270, 540, 135, 270, 540, 540, 270, 135, 540, 270, 135, 135, 270, 540, 540, 540, 135, 540, 135, 540, 135, 270, 135, 540, 540, 270, 540, 135, 540, 540, 540, 135, 540, 540, 540, 270, 270, 270, 270, 270, 270, 135, 540, 270, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 60480 . Total input tokens: 13415393 . Total output tokens: 12119019
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 1.9220638321712613,
    "estimated_duration": 3599.51361862774,
    "input_throughput": 1403.3284868986636,
    "output_throughput": 1232.0875734568674,
    "total_throughput": 2635.416060355531,
    "itl": 26.32035852927324,
    "ttft": 8553.160665137848,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8172,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.01030584341959,
    "arrivals": 20309,
    "finished_requests": 20261,
    "scheduler_time": 0.0479536012316619
}
#Debug simulation 
Total elapsed time: 1.9221679139882326. Arrivals time: 0.060910257045179605 Scheduler time: 1.4174159178510308 Scheduler overhead time: 0.12079195585101843 Adapter cache time: 0.14617444016039371 Engine time: 0.11883887788280845 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_192_slots_96_rate_0.05-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_192_slots_96_rate_0.05-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [64 64 64]
Adapter prompts. [540, 135, 540, 135, 540, 135, 540, 135, 135, 135, 270, 270, 270, 270, 540, 270, 135, 540, 135, 270, 270, 135, 540, 540, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 540, 270, 135, 270, 540, 540, 270, 540, 135, 270, 270, 540, 270, 135, 135, 270, 540, 135, 270, 135, 540, 540, 270, 540, 540, 540, 135, 270, 540, 135, 270, 135, 270, 135, 135, 270, 540, 540, 135, 135, 135, 540, 540, 540, 270, 135, 135, 135, 135, 135, 540, 135, 270, 135, 540, 540, 135, 540, 135, 270, 270, 540, 135, 135, 135, 540, 540, 270, 540, 270, 540, 540, 270, 270, 135, 540, 270, 270, 270, 540, 270, 135, 270, 540, 540, 270, 540, 270, 135, 540, 270, 135, 270, 270, 135, 270, 540, 135, 270, 540, 135, 270, 540, 540, 270, 135, 540, 270, 135, 135, 270, 540, 540, 540, 135, 540, 135, 540, 135, 270, 135, 540, 540, 270, 540, 135, 540, 540, 540, 135, 540, 540, 540, 270, 270, 270, 270, 270, 270, 135, 540, 270, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 60480 . Total input tokens: 13415393 . Total output tokens: 12119019
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.9305550740100443,
    "estimated_duration": 3599.5213876951125,
    "input_throughput": 1403.3254580088792,
    "output_throughput": 1232.0849141668295,
    "total_throughput": 2635.4103721757087,
    "itl": 26.338413921641752,
    "ttft": 8553.216869835727,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8175,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.626377351930877,
    "arrivals": 20309,
    "finished_requests": 20261,
    "scheduler_time": 0.04871181529741563
}
#Debug simulation 
Total elapsed time: 1.9306606431491673. Arrivals time: 0.060571285896003246 Scheduler time: 1.4253302491270006 Scheduler overhead time: 0.11992691457271576 Adapter cache time: 0.14578028861433268 Engine time: 0.12045934284105897 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_192_slots_96_rate_0.05-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_192_slots_96_rate_0.05-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [64 64 64]
Adapter prompts. [540, 135, 540, 135, 540, 135, 540, 135, 135, 135, 270, 270, 270, 270, 540, 270, 135, 540, 135, 270, 270, 135, 540, 540, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 540, 270, 135, 270, 540, 540, 270, 540, 135, 270, 270, 540, 270, 135, 135, 270, 540, 135, 270, 135, 540, 540, 270, 540, 540, 540, 135, 270, 540, 135, 270, 135, 270, 135, 135, 270, 540, 540, 135, 135, 135, 540, 540, 540, 270, 135, 135, 135, 135, 135, 540, 135, 270, 135, 540, 540, 135, 540, 135, 270, 270, 540, 135, 135, 135, 540, 540, 270, 540, 270, 540, 540, 270, 270, 135, 540, 270, 270, 270, 540, 270, 135, 270, 540, 540, 270, 540, 270, 135, 540, 270, 135, 270, 270, 135, 270, 540, 135, 270, 540, 135, 270, 540, 540, 270, 135, 540, 270, 135, 135, 270, 540, 540, 540, 135, 540, 135, 540, 135, 270, 135, 540, 540, 270, 540, 135, 540, 540, 540, 135, 540, 540, 540, 270, 270, 270, 270, 270, 270, 135, 540, 270, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 60480 . Total input tokens: 13415393 . Total output tokens: 12119019
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.911023355089128,
    "estimated_duration": 3599.509174960595,
    "input_throughput": 1403.3302193361678,
    "output_throughput": 1232.0890944939877,
    "total_throughput": 2635.4193138301553,
    "itl": 26.338391181180615,
    "ttft": 8553.222216986182,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8173,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.67591841926847,
    "arrivals": 20309,
    "finished_requests": 20261,
    "scheduler_time": 0.04871502611944787
}
#Debug simulation 
Total elapsed time: 1.9111468391492963. Arrivals time: 0.06005484005436301 Scheduler time: 1.4099942040629685 Scheduler overhead time: 0.11896505719050765 Adapter cache time: 0.14538799598813057 Engine time: 0.11866371985524893 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_192_slots_96_rate_0.05-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_192_slots_96_rate_0.05-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [64 64 64]
Adapter prompts. [540, 135, 540, 135, 540, 135, 540, 135, 135, 135, 270, 270, 270, 270, 540, 270, 135, 540, 135, 270, 270, 135, 540, 540, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 540, 270, 135, 270, 540, 540, 270, 540, 135, 270, 270, 540, 270, 135, 135, 270, 540, 135, 270, 135, 540, 540, 270, 540, 540, 540, 135, 270, 540, 135, 270, 135, 270, 135, 135, 270, 540, 540, 135, 135, 135, 540, 540, 540, 270, 135, 135, 135, 135, 135, 540, 135, 270, 135, 540, 540, 135, 540, 135, 270, 270, 540, 135, 135, 135, 540, 540, 270, 540, 270, 540, 540, 270, 270, 135, 540, 270, 270, 270, 540, 270, 135, 270, 540, 540, 270, 540, 270, 135, 540, 270, 135, 270, 270, 135, 270, 540, 135, 270, 540, 135, 270, 540, 540, 270, 135, 540, 270, 135, 135, 270, 540, 540, 540, 135, 540, 135, 540, 135, 270, 135, 540, 540, 270, 540, 135, 540, 540, 540, 135, 540, 540, 540, 270, 270, 270, 270, 270, 270, 135, 540, 270, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 60480 . Total input tokens: 13415393 . Total output tokens: 12119019
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 1.914053580723703,
    "estimated_duration": 3599.504168761605,
    "input_throughput": 1403.3321710911866,
    "output_throughput": 1232.0908080864413,
    "total_throughput": 2635.422979177628,
    "itl": 26.325240345829144,
    "ttft": 8553.154417289663,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8172,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.52645770081133,
    "arrivals": 20309,
    "finished_requests": 20261,
    "scheduler_time": 0.048253751012723466
}
#Debug simulation 
Total elapsed time: 1.9141576727852225. Arrivals time: 0.061191672924906015 Scheduler time: 1.4104522508569062 Scheduler overhead time: 0.11996953980997205 Adapter cache time: 0.1451046816073358 Engine time: 0.11900044046342373 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_192_slots_96_rate_0.05-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_192_slots_96_rate_0.05-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [64 64 64]
Adapter prompts. [540, 135, 540, 135, 540, 135, 540, 135, 135, 135, 270, 270, 270, 270, 540, 270, 135, 540, 135, 270, 270, 135, 540, 540, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 540, 270, 135, 270, 540, 540, 270, 540, 135, 270, 270, 540, 270, 135, 135, 270, 540, 135, 270, 135, 540, 540, 270, 540, 540, 540, 135, 270, 540, 135, 270, 135, 270, 135, 135, 270, 540, 540, 135, 135, 135, 540, 540, 540, 270, 135, 135, 135, 135, 135, 540, 135, 270, 135, 540, 540, 135, 540, 135, 270, 270, 540, 135, 135, 135, 540, 540, 270, 540, 270, 540, 540, 270, 270, 135, 540, 270, 270, 270, 540, 270, 135, 270, 540, 540, 270, 540, 270, 135, 540, 270, 135, 270, 270, 135, 270, 540, 135, 270, 540, 135, 270, 540, 540, 270, 135, 540, 270, 135, 135, 270, 540, 540, 540, 135, 540, 135, 540, 135, 270, 135, 540, 540, 270, 540, 135, 540, 540, 540, 135, 540, 540, 540, 270, 270, 270, 270, 270, 270, 135, 540, 270, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 60480 . Total input tokens: 13415393 . Total output tokens: 12119019
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 1.9152149544097483,
    "estimated_duration": 3599.511598484639,
    "input_throughput": 1403.3292744845025,
    "output_throughput": 1232.0882649376817,
    "total_throughput": 2635.4175394221843,
    "itl": 26.341378086457233,
    "ttft": 8553.356448601868,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8172,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.008511756359695,
    "arrivals": 20309,
    "finished_requests": 20261,
    "scheduler_time": 0.04878891689420717
}
#Debug simulation 
Total elapsed time: 1.9153280593454838. Arrivals time: 0.060427513904869556 Scheduler time: 1.4123489037156105 Scheduler overhead time: 0.11973053915426135 Adapter cache time: 0.14600019669160247 Engine time: 0.11822621757164598 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_192_slots_96_rate_0.05-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_192_slots_96_rate_0.05-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [64 64 64]
Adapter prompts. [540, 135, 540, 135, 540, 135, 540, 135, 135, 135, 270, 270, 270, 270, 540, 270, 135, 540, 135, 270, 270, 135, 540, 540, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 540, 270, 135, 270, 540, 540, 270, 540, 135, 270, 270, 540, 270, 135, 135, 270, 540, 135, 270, 135, 540, 540, 270, 540, 540, 540, 135, 270, 540, 135, 270, 135, 270, 135, 135, 270, 540, 540, 135, 135, 135, 540, 540, 540, 270, 135, 135, 135, 135, 135, 540, 135, 270, 135, 540, 540, 135, 540, 135, 270, 270, 540, 135, 135, 135, 540, 540, 270, 540, 270, 540, 540, 270, 270, 135, 540, 270, 270, 270, 540, 270, 135, 270, 540, 540, 270, 540, 270, 135, 540, 270, 135, 270, 270, 135, 270, 540, 135, 270, 540, 135, 270, 540, 540, 270, 135, 540, 270, 135, 135, 270, 540, 540, 540, 135, 540, 135, 540, 135, 270, 135, 540, 540, 270, 540, 135, 540, 540, 540, 135, 540, 540, 540, 270, 270, 270, 270, 270, 270, 135, 540, 270, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 60480 . Total input tokens: 13415393 . Total output tokens: 12119019
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 1.9306222759187222,
    "estimated_duration": 3599.524946968532,
    "input_throughput": 1403.3240703760457,
    "output_throughput": 1232.08369585965,
    "total_throughput": 2635.407766235696,
    "itl": 26.530396093015494,
    "ttft": 8553.415247434103,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8154,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.380870104631395,
    "arrivals": 20309,
    "finished_requests": 20261,
    "scheduler_time": 0.054305203004664265
}
#Debug simulation 
Total elapsed time: 1.9307660069316626. Arrivals time: 0.05958732310682535 Scheduler time: 1.433953704778105 Scheduler overhead time: 0.1190227479673922 Adapter cache time: 0.14521160069853067 Engine time: 0.1151301683858037 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_192_slots_96_rate_0.05-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_192_slots_96_rate_0.05-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [64 64 64]
Adapter prompts. [540, 135, 540, 135, 540, 135, 540, 135, 135, 135, 270, 270, 270, 270, 540, 270, 135, 540, 135, 270, 270, 135, 540, 540, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 540, 270, 135, 270, 540, 540, 270, 540, 135, 270, 270, 540, 270, 135, 135, 270, 540, 135, 270, 135, 540, 540, 270, 540, 540, 540, 135, 270, 540, 135, 270, 135, 270, 135, 135, 270, 540, 540, 135, 135, 135, 540, 540, 540, 270, 135, 135, 135, 135, 135, 540, 135, 270, 135, 540, 540, 135, 540, 135, 270, 270, 540, 135, 135, 135, 540, 540, 270, 540, 270, 540, 540, 270, 270, 135, 540, 270, 270, 270, 540, 270, 135, 270, 540, 540, 270, 540, 270, 135, 540, 270, 135, 270, 270, 135, 270, 540, 135, 270, 540, 135, 270, 540, 540, 270, 135, 540, 270, 135, 135, 270, 540, 540, 540, 135, 540, 135, 540, 135, 270, 135, 540, 540, 270, 540, 135, 540, 540, 540, 135, 540, 540, 540, 270, 270, 270, 270, 270, 270, 135, 540, 270, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 60480 . Total input tokens: 13415393 . Total output tokens: 12119019
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.9445371329784393,
    "estimated_duration": 3599.5041527861654,
    "input_throughput": 1403.3321773195023,
    "output_throughput": 1232.090813554748,
    "total_throughput": 2635.42299087425,
    "itl": 26.34689697509024,
    "ttft": 8553.24267646439,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8177,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.36066947046441,
    "arrivals": 20309,
    "finished_requests": 20261,
    "scheduler_time": 0.048972726350085295
}
#Debug simulation 
Total elapsed time: 1.9446361549198627. Arrivals time: 0.0599546330049634 Scheduler time: 1.4415410906076431 Scheduler overhead time: 0.11979492893442512 Adapter cache time: 0.14537295140326023 Engine time: 0.11972442921251059 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_192_slots_96_rate_0.05-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_192_slots_96_rate_0.05-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [64 64 64]
Adapter prompts. [540, 66, 540, 66, 540, 66, 540, 66, 66, 66, 270, 270, 270, 270, 540, 270, 66, 540, 66, 270, 270, 66, 540, 540, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 540, 270, 66, 270, 540, 540, 270, 540, 66, 270, 270, 540, 270, 66, 66, 270, 540, 66, 270, 66, 540, 540, 270, 540, 540, 540, 66, 270, 540, 66, 270, 66, 270, 66, 66, 270, 540, 540, 66, 66, 66, 540, 540, 540, 270, 66, 66, 66, 66, 66, 540, 66, 270, 66, 540, 540, 66, 540, 66, 270, 270, 540, 66, 66, 66, 540, 540, 270, 540, 270, 540, 540, 270, 270, 66, 540, 270, 270, 270, 540, 270, 66, 270, 540, 540, 270, 540, 270, 66, 540, 270, 66, 270, 270, 66, 270, 540, 66, 270, 540, 66, 270, 540, 540, 270, 66, 540, 270, 66, 66, 270, 540, 540, 540, 66, 540, 66, 540, 66, 270, 66, 540, 540, 270, 540, 66, 540, 540, 540, 66, 540, 540, 540, 270, 270, 270, 270, 270, 270, 66, 540, 270, 540, 66, 540, 270, 66, 270, 66, 66, 270, 270, 270, 540, 270, 66, 66]
Prompts retrieved: 56064 . Total input tokens: 12438405 . Total output tokens: 11244593
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 1.852551727090031,
    "estimated_duration": 3600.0082529687134,
    "input_throughput": 1291.630927836212,
    "output_throughput": 1165.2670508576352,
    "total_throughput": 2456.897978693847,
    "itl": 25.485294634815244,
    "ttft": 6135.672592529175,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6449,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.737085460621742,
    "arrivals": 18908,
    "finished_requests": 18876,
    "scheduler_time": 0.0233895527178274
}
#Debug simulation 
Total elapsed time: 1.8526803888380527. Arrivals time: 0.058161137625575066 Scheduler time: 1.3593919361010194 Scheduler overhead time: 0.12438027327880263 Adapter cache time: 0.13246464263647795 Engine time: 0.11822894588112831 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_192_slots_96_rate_0.05-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_192_slots_96_rate_0.05-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [64 64 64]
Adapter prompts. [540, 66, 540, 66, 540, 66, 540, 66, 66, 66, 270, 270, 270, 270, 540, 270, 66, 540, 66, 270, 270, 66, 540, 540, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 540, 270, 66, 270, 540, 540, 270, 540, 66, 270, 270, 540, 270, 66, 66, 270, 540, 66, 270, 66, 540, 540, 270, 540, 540, 540, 66, 270, 540, 66, 270, 66, 270, 66, 66, 270, 540, 540, 66, 66, 66, 540, 540, 540, 270, 66, 66, 66, 66, 66, 540, 66, 270, 66, 540, 540, 66, 540, 66, 270, 270, 540, 66, 66, 66, 540, 540, 270, 540, 270, 540, 540, 270, 270, 66, 540, 270, 270, 270, 540, 270, 66, 270, 540, 540, 270, 540, 270, 66, 540, 270, 66, 270, 270, 66, 270, 540, 66, 270, 540, 66, 270, 540, 540, 270, 66, 540, 270, 66, 66, 270, 540, 540, 540, 66, 540, 66, 540, 66, 270, 66, 540, 540, 270, 540, 66, 540, 540, 540, 66, 540, 540, 540, 270, 270, 270, 270, 270, 270, 66, 540, 270, 540, 66, 540, 270, 66, 270, 66, 66, 270, 270, 270, 540, 270, 66, 66]
Prompts retrieved: 56064 . Total input tokens: 12438405 . Total output tokens: 11244593
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.812421171925962,
    "estimated_duration": 3600.007180465858,
    "input_throughput": 1291.6313126348496,
    "output_throughput": 1165.2673980103425,
    "total_throughput": 2456.8987106451923,
    "itl": 25.498930502958885,
    "ttft": 6135.745440337523,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6452,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.013625174615758,
    "arrivals": 18908,
    "finished_requests": 18876,
    "scheduler_time": 0.023710552149114546
}
#Debug simulation 
Total elapsed time: 1.8125161309726536. Arrivals time: 0.056039370596408844 Scheduler time: 1.3234794111922383 Scheduler overhead time: 0.1230426081456244 Adapter cache time: 0.13261170173063874 Engine time: 0.11734299920499325 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_192_slots_96_rate_0.05-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_192_slots_96_rate_0.05-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [64 64 64]
Adapter prompts. [540, 66, 540, 66, 540, 66, 540, 66, 66, 66, 270, 270, 270, 270, 540, 270, 66, 540, 66, 270, 270, 66, 540, 540, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 540, 270, 66, 270, 540, 540, 270, 540, 66, 270, 270, 540, 270, 66, 66, 270, 540, 66, 270, 66, 540, 540, 270, 540, 540, 540, 66, 270, 540, 66, 270, 66, 270, 66, 66, 270, 540, 540, 66, 66, 66, 540, 540, 540, 270, 66, 66, 66, 66, 66, 540, 66, 270, 66, 540, 540, 66, 540, 66, 270, 270, 540, 66, 66, 66, 540, 540, 270, 540, 270, 540, 540, 270, 270, 66, 540, 270, 270, 270, 540, 270, 66, 270, 540, 540, 270, 540, 270, 66, 540, 270, 66, 270, 270, 66, 270, 540, 66, 270, 540, 66, 270, 540, 540, 270, 66, 540, 270, 66, 66, 270, 540, 540, 540, 66, 540, 66, 540, 66, 270, 66, 540, 540, 270, 540, 66, 540, 540, 540, 66, 540, 540, 540, 270, 270, 270, 270, 270, 270, 66, 540, 270, 540, 66, 540, 270, 66, 270, 66, 66, 270, 270, 270, 540, 270, 66, 66]
Prompts retrieved: 56064 . Total input tokens: 12438405 . Total output tokens: 11244593
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.8584585417993367,
    "estimated_duration": 3600.009266929183,
    "input_throughput": 1291.6305640419534,
    "output_throughput": 1165.2667226543895,
    "total_throughput": 2456.8972866963427,
    "itl": 25.499109130077407,
    "ttft": 6135.86836911437,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6450,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.051520269009714,
    "arrivals": 18908,
    "finished_requests": 18876,
    "scheduler_time": 0.023704005383046216
}
#Debug simulation 
Total elapsed time: 1.8585563865490258. Arrivals time: 0.05627987068146467 Scheduler time: 1.3640620042569935 Scheduler overhead time: 0.12557876156643033 Adapter cache time: 0.13312179083004594 Engine time: 0.11951747862622142 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_192_slots_96_rate_0.05-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_192_slots_96_rate_0.05-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [64 64 64]
Adapter prompts. [540, 66, 540, 66, 540, 66, 540, 66, 66, 66, 270, 270, 270, 270, 540, 270, 66, 540, 66, 270, 270, 66, 540, 540, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 540, 270, 66, 270, 540, 540, 270, 540, 66, 270, 270, 540, 270, 66, 66, 270, 540, 66, 270, 66, 540, 540, 270, 540, 540, 540, 66, 270, 540, 66, 270, 66, 270, 66, 66, 270, 540, 540, 66, 66, 66, 540, 540, 540, 270, 66, 66, 66, 66, 66, 540, 66, 270, 66, 540, 540, 66, 540, 66, 270, 270, 540, 66, 66, 66, 540, 540, 270, 540, 270, 540, 540, 270, 270, 66, 540, 270, 270, 270, 540, 270, 66, 270, 540, 540, 270, 540, 270, 66, 540, 270, 66, 270, 270, 66, 270, 540, 66, 270, 540, 66, 270, 540, 540, 270, 66, 540, 270, 66, 66, 270, 540, 540, 540, 66, 540, 66, 540, 66, 270, 66, 540, 540, 270, 540, 66, 540, 540, 540, 66, 540, 540, 540, 270, 270, 270, 270, 270, 270, 66, 540, 270, 540, 66, 540, 270, 66, 270, 66, 66, 270, 270, 270, 540, 270, 66, 66]
Prompts retrieved: 56064 . Total input tokens: 12438405 . Total output tokens: 11244593
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 1.8724577371031046,
    "estimated_duration": 3600.004089396509,
    "input_throughput": 1291.6324216674677,
    "output_throughput": 1165.2683985431886,
    "total_throughput": 2456.9008202106565,
    "itl": 25.48872633936621,
    "ttft": 6135.693579221673,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6453,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.141404052812153,
    "arrivals": 18908,
    "finished_requests": 18876,
    "scheduler_time": 0.023533873201305983
}
#Debug simulation 
Total elapsed time: 1.8725564791820943. Arrivals time: 0.0568938422948122 Scheduler time: 1.3758553401567042 Scheduler overhead time: 0.12602164829149842 Adapter cache time: 0.13306498480960727 Engine time: 0.11956497840583324 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_192_slots_96_rate_0.05-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_192_slots_96_rate_0.05-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [64 64 64]
Adapter prompts. [540, 66, 540, 66, 540, 66, 540, 66, 66, 66, 270, 270, 270, 270, 540, 270, 66, 540, 66, 270, 270, 66, 540, 540, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 540, 270, 66, 270, 540, 540, 270, 540, 66, 270, 270, 540, 270, 66, 66, 270, 540, 66, 270, 66, 540, 540, 270, 540, 540, 540, 66, 270, 540, 66, 270, 66, 270, 66, 66, 270, 540, 540, 66, 66, 66, 540, 540, 540, 270, 66, 66, 66, 66, 66, 540, 66, 270, 66, 540, 540, 66, 540, 66, 270, 270, 540, 66, 66, 66, 540, 540, 270, 540, 270, 540, 540, 270, 270, 66, 540, 270, 270, 270, 540, 270, 66, 270, 540, 540, 270, 540, 270, 66, 540, 270, 66, 270, 270, 66, 270, 540, 66, 270, 540, 66, 270, 540, 540, 270, 66, 540, 270, 66, 66, 270, 540, 540, 540, 66, 540, 66, 540, 66, 270, 66, 540, 540, 270, 540, 66, 540, 540, 540, 66, 540, 540, 540, 270, 270, 270, 270, 270, 270, 66, 540, 270, 540, 66, 540, 270, 66, 270, 66, 66, 270, 270, 270, 540, 270, 66, 66]
Prompts retrieved: 56064 . Total input tokens: 12438405 . Total output tokens: 11244593
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 1.8199961679056287,
    "estimated_duration": 3600.007439953228,
    "input_throughput": 1291.6312195344829,
    "output_throughput": 1165.267314018246,
    "total_throughput": 2456.898533552729,
    "itl": 25.502162180227927,
    "ttft": 6135.713985270012,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6449,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.31784136066104,
    "arrivals": 18908,
    "finished_requests": 18876,
    "scheduler_time": 0.02371626492917385
}
#Debug simulation 
Total elapsed time: 1.820090299937874. Arrivals time: 0.05558379925787449 Scheduler time: 1.329788058064878 Scheduler overhead time: 0.12309858901426196 Adapter cache time: 0.1316619892604649 Engine time: 0.11982077825814486 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_192_slots_96_rate_0.05-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_192_slots_96_rate_0.05-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [64 64 64]
Adapter prompts. [540, 66, 540, 66, 540, 66, 540, 66, 66, 66, 270, 270, 270, 270, 540, 270, 66, 540, 66, 270, 270, 66, 540, 540, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 540, 270, 66, 270, 540, 540, 270, 540, 66, 270, 270, 540, 270, 66, 66, 270, 540, 66, 270, 66, 540, 540, 270, 540, 540, 540, 66, 270, 540, 66, 270, 66, 270, 66, 66, 270, 540, 540, 66, 66, 66, 540, 540, 540, 270, 66, 66, 66, 66, 66, 540, 66, 270, 66, 540, 540, 66, 540, 66, 270, 270, 540, 66, 66, 66, 540, 540, 270, 540, 270, 540, 540, 270, 270, 66, 540, 270, 270, 270, 540, 270, 66, 270, 540, 540, 270, 540, 270, 66, 540, 270, 66, 270, 270, 66, 270, 540, 66, 270, 540, 66, 270, 540, 540, 270, 66, 540, 270, 66, 66, 270, 540, 540, 540, 66, 540, 66, 540, 66, 270, 66, 540, 540, 270, 540, 66, 540, 540, 540, 66, 540, 540, 540, 270, 270, 270, 270, 270, 270, 66, 540, 270, 540, 66, 540, 270, 66, 270, 66, 66, 270, 270, 270, 540, 270, 66, 66]
Prompts retrieved: 56064 . Total input tokens: 12438405 . Total output tokens: 11244593
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 1.8432867899537086,
    "estimated_duration": 3600.0239865070703,
    "input_throughput": 1291.6252828947277,
    "output_throughput": 1165.2619581766114,
    "total_throughput": 2456.8872410713393,
    "itl": 25.48145278814625,
    "ttft": 6135.644076491769,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6452,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.291804502709585,
    "arrivals": 18908,
    "finished_requests": 18876,
    "scheduler_time": 0.02332875547520478
}
#Debug simulation 
Total elapsed time: 1.8433822230435908. Arrivals time: 0.056409357115626335 Scheduler time: 1.3502679369412363 Scheduler overhead time: 0.12358696572482586 Adapter cache time: 0.1326421033591032 Engine time: 0.12057973584160209 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_192_slots_96_rate_0.05-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_192_slots_96_rate_0.05-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [64 64 64]
Adapter prompts. [540, 66, 540, 66, 540, 66, 540, 66, 66, 66, 270, 270, 270, 270, 540, 270, 66, 540, 66, 270, 270, 66, 540, 540, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 540, 270, 66, 270, 540, 540, 270, 540, 66, 270, 270, 540, 270, 66, 66, 270, 540, 66, 270, 66, 540, 540, 270, 540, 540, 540, 66, 270, 540, 66, 270, 66, 270, 66, 66, 270, 540, 540, 66, 66, 66, 540, 540, 540, 270, 66, 66, 66, 66, 66, 540, 66, 270, 66, 540, 540, 66, 540, 66, 270, 270, 540, 66, 66, 66, 540, 540, 270, 540, 270, 540, 540, 270, 270, 66, 540, 270, 270, 270, 540, 270, 66, 270, 540, 540, 270, 540, 270, 66, 540, 270, 66, 270, 270, 66, 270, 540, 66, 270, 540, 66, 270, 540, 540, 270, 66, 540, 270, 66, 66, 270, 540, 540, 540, 66, 540, 66, 540, 66, 270, 66, 540, 540, 270, 540, 66, 540, 540, 540, 66, 540, 540, 540, 270, 270, 270, 270, 270, 270, 66, 540, 270, 540, 66, 540, 270, 66, 270, 66, 66, 270, 270, 270, 540, 270, 66, 66]
Prompts retrieved: 56064 . Total input tokens: 12438405 . Total output tokens: 11244593
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.8280699979513884,
    "estimated_duration": 3600.0074392812644,
    "input_throughput": 1291.631219775574,
    "output_throughput": 1165.2673142357503,
    "total_throughput": 2456.8985340113245,
    "itl": 25.505257277444667,
    "ttft": 6135.814285304666,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6452,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.588334011433815,
    "arrivals": 18908,
    "finished_requests": 18876,
    "scheduler_time": 0.023738740683399383
}
#Debug simulation 
Total elapsed time: 1.82816191483289. Arrivals time: 0.05626850528642535 Scheduler time: 1.3343396941199899 Scheduler overhead time: 0.12210671696811914 Adapter cache time: 0.1330072581768036 Engine time: 0.1229411093518138 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_192_slots_96_rate_0.05-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_192_slots_96_rate_0.05-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 270, 270, 270, 270, 540, 270, 33, 540, 33, 270, 270, 33, 540, 540, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 540, 270, 33, 270, 540, 540, 270, 540, 33, 270, 270, 540, 270, 33, 33, 270, 540, 33, 270, 33, 540, 540, 270, 540, 540, 540, 33, 270, 540, 33, 270, 33, 270, 33, 33, 270, 540, 540, 33, 33, 33, 540, 540, 540, 270, 33, 33, 33, 33, 33, 540, 33, 270, 33, 540, 540, 33, 540, 33, 270, 270, 540, 33, 33, 33, 540, 540, 270, 540, 270, 540, 540, 270, 270, 33, 540, 270, 270, 270, 540, 270, 33, 270, 540, 540, 270, 540, 270, 33, 540, 270, 33, 270, 270, 33, 270, 540, 33, 270, 540, 33, 270, 540, 540, 270, 33, 540, 270, 33, 33, 270, 540, 540, 540, 33, 540, 33, 540, 33, 270, 33, 540, 540, 270, 540, 33, 540, 540, 540, 33, 540, 540, 540, 270, 270, 270, 270, 270, 270, 33, 540, 270, 540, 33, 540, 270, 33, 270, 33, 33, 270, 270, 270, 540, 270, 33, 33]
Prompts retrieved: 53952 . Total input tokens: 11959790 . Total output tokens: 10819341
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 1.7600199333392084,
    "estimated_duration": 3599.6409403575326,
    "input_throughput": 1260.877702860329,
    "output_throughput": 1105.4605350734682,
    "total_throughput": 2366.3382379337972,
    "itl": 24.709115269537055,
    "ttft": 6946.849088007287,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5122,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.675818224421846,
    "arrivals": 18247,
    "finished_requests": 18212,
    "scheduler_time": 0.0031290153801112395
}
#Debug simulation 
Total elapsed time: 1.7601121459156275. Arrivals time: 0.05412291456013918 Scheduler time: 1.2740706196054816 Scheduler overhead time: 0.12537053925916553 Adapter cache time: 0.12626648182049394 Engine time: 0.11926206247881055 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_192_slots_96_rate_0.05-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_192_slots_96_rate_0.05-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 270, 270, 270, 270, 540, 270, 33, 540, 33, 270, 270, 33, 540, 540, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 540, 270, 33, 270, 540, 540, 270, 540, 33, 270, 270, 540, 270, 33, 33, 270, 540, 33, 270, 33, 540, 540, 270, 540, 540, 540, 33, 270, 540, 33, 270, 33, 270, 33, 33, 270, 540, 540, 33, 33, 33, 540, 540, 540, 270, 33, 33, 33, 33, 33, 540, 33, 270, 33, 540, 540, 33, 540, 33, 270, 270, 540, 33, 33, 33, 540, 540, 270, 540, 270, 540, 540, 270, 270, 33, 540, 270, 270, 270, 540, 270, 33, 270, 540, 540, 270, 540, 270, 33, 540, 270, 33, 270, 270, 33, 270, 540, 33, 270, 540, 33, 270, 540, 540, 270, 33, 540, 270, 33, 33, 270, 540, 540, 540, 33, 540, 33, 540, 33, 270, 33, 540, 540, 270, 540, 33, 540, 540, 540, 33, 540, 540, 540, 270, 270, 270, 270, 270, 270, 33, 540, 270, 540, 33, 540, 270, 33, 270, 33, 33, 270, 270, 270, 540, 270, 33, 33]
Prompts retrieved: 53952 . Total input tokens: 11959790 . Total output tokens: 10819341
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.7556370389647782,
    "estimated_duration": 3599.6267252115645,
    "input_throughput": 1260.8826821434498,
    "output_throughput": 1105.4649006046934,
    "total_throughput": 2366.347582748143,
    "itl": 24.721144617142865,
    "ttft": 6946.834634878031,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5124,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.68450028871506,
    "arrivals": 18247,
    "finished_requests": 18212,
    "scheduler_time": 0.003138772968211791
}
#Debug simulation 
Total elapsed time: 1.7557297046296299. Arrivals time: 0.05496952682733536 Scheduler time: 1.2668021209537983 Scheduler overhead time: 0.12532506370916963 Adapter cache time: 0.12531078839674592 Engine time: 0.1220462885685265 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-32/adapters_192_slots_96_rate_0.05-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-32/adapters_192_slots_96_rate_0.05-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 270, 270, 270, 270, 540, 270, 33, 540, 33, 270, 270, 33, 540, 540, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 540, 270, 33, 270, 540, 540, 270, 540, 33, 270, 270, 540, 270, 33, 33, 270, 540, 33, 270, 33, 540, 540, 270, 540, 540, 540, 33, 270, 540, 33, 270, 33, 270, 33, 33, 270, 540, 540, 33, 33, 33, 540, 540, 540, 270, 33, 33, 33, 33, 33, 540, 33, 270, 33, 540, 540, 33, 540, 33, 270, 270, 540, 33, 33, 33, 540, 540, 270, 540, 270, 540, 540, 270, 270, 33, 540, 270, 270, 270, 540, 270, 33, 270, 540, 540, 270, 540, 270, 33, 540, 270, 33, 270, 270, 33, 270, 540, 33, 270, 540, 33, 270, 540, 540, 270, 33, 540, 270, 33, 33, 270, 540, 540, 540, 33, 540, 33, 540, 33, 270, 33, 540, 540, 270, 540, 33, 540, 540, 540, 33, 540, 540, 540, 270, 270, 270, 270, 270, 270, 33, 540, 270, 540, 33, 540, 270, 33, 270, 33, 33, 270, 270, 270, 540, 270, 33, 33]
Prompts retrieved: 53952 . Total input tokens: 11959790 . Total output tokens: 10819341
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.7630023350939155,
    "estimated_duration": 3599.6465482405647,
    "input_throughput": 1260.8757385411714,
    "output_throughput": 1105.458812878443,
    "total_throughput": 2366.3345514196144,
    "itl": 24.72034139903743,
    "ttft": 6946.991774267698,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5124,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.720722717827748,
    "arrivals": 18247,
    "finished_requests": 18212,
    "scheduler_time": 0.0031443606262672105
}
#Debug simulation 
Total elapsed time: 1.7631117338314652. Arrivals time: 0.05422562826424837 Scheduler time: 1.2742778393439949 Scheduler overhead time: 0.12637285329401493 Adapter cache time: 0.1260767155326903 Engine time: 0.12052676267921925 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_192_slots_96_rate_0.05-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_192_slots_96_rate_0.05-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 270, 270, 270, 270, 540, 270, 33, 540, 33, 270, 270, 33, 540, 540, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 540, 270, 33, 270, 540, 540, 270, 540, 33, 270, 270, 540, 270, 33, 33, 270, 540, 33, 270, 33, 540, 540, 270, 540, 540, 540, 33, 270, 540, 33, 270, 33, 270, 33, 33, 270, 540, 540, 33, 33, 33, 540, 540, 540, 270, 33, 33, 33, 33, 33, 540, 33, 270, 33, 540, 540, 33, 540, 33, 270, 270, 540, 33, 33, 33, 540, 540, 270, 540, 270, 540, 540, 270, 270, 33, 540, 270, 270, 270, 540, 270, 33, 270, 540, 540, 270, 540, 270, 33, 540, 270, 33, 270, 270, 33, 270, 540, 33, 270, 540, 33, 270, 540, 540, 270, 33, 540, 270, 33, 33, 270, 540, 540, 540, 33, 540, 33, 540, 33, 270, 33, 540, 540, 270, 540, 33, 540, 540, 540, 33, 540, 540, 540, 270, 270, 270, 270, 270, 270, 33, 540, 270, 540, 33, 540, 270, 33, 270, 33, 33, 270, 270, 270, 540, 270, 33, 33]
Prompts retrieved: 53952 . Total input tokens: 11959790 . Total output tokens: 10819341
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 1.7470768401399255,
    "estimated_duration": 3599.6380919309686,
    "input_throughput": 1260.878700604394,
    "output_throughput": 1105.4614098345062,
    "total_throughput": 2366.3401104389,
    "itl": 24.71262003588847,
    "ttft": 6946.856850042829,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5123,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.978726290703365,
    "arrivals": 18247,
    "finished_requests": 18212,
    "scheduler_time": 0.0031193829140145706
}
#Debug simulation 
Total elapsed time: 1.7471705013886094. Arrivals time: 0.054066982585936785 Scheduler time: 1.2591670956462622 Scheduler overhead time: 0.12804457545280457 Adapter cache time: 0.1253228592686355 Engine time: 0.11882541095837951 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-32/adapters_192_slots_96_rate_0.05-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-32/adapters_192_slots_96_rate_0.05-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 270, 270, 270, 270, 540, 270, 33, 540, 33, 270, 270, 33, 540, 540, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 540, 270, 33, 270, 540, 540, 270, 540, 33, 270, 270, 540, 270, 33, 33, 270, 540, 33, 270, 33, 540, 540, 270, 540, 540, 540, 33, 270, 540, 33, 270, 33, 270, 33, 33, 270, 540, 540, 33, 33, 33, 540, 540, 540, 270, 33, 33, 33, 33, 33, 540, 33, 270, 33, 540, 540, 33, 540, 33, 270, 270, 540, 33, 33, 33, 540, 540, 270, 540, 270, 540, 540, 270, 270, 33, 540, 270, 270, 270, 540, 270, 33, 270, 540, 540, 270, 540, 270, 33, 540, 270, 33, 270, 270, 33, 270, 540, 33, 270, 540, 33, 270, 540, 540, 270, 33, 540, 270, 33, 33, 270, 540, 540, 540, 33, 540, 33, 540, 33, 270, 33, 540, 540, 270, 540, 33, 540, 540, 540, 33, 540, 540, 540, 270, 270, 270, 270, 270, 270, 33, 540, 270, 540, 33, 540, 270, 33, 270, 33, 33, 270, 270, 270, 540, 270, 33, 33]
Prompts retrieved: 53952 . Total input tokens: 11959790 . Total output tokens: 10819341
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 1.7707136757671833,
    "estimated_duration": 3599.636770283569,
    "input_throughput": 1260.8791635502862,
    "output_throughput": 1105.4618157171801,
    "total_throughput": 2366.340979267466,
    "itl": 24.72168412917048,
    "ttft": 6946.919686874854,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5124,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.93748223174239,
    "arrivals": 18247,
    "finished_requests": 18212,
    "scheduler_time": 0.0031299744881241485
}
#Debug simulation 
Total elapsed time: 1.770813558716327. Arrivals time: 0.05533699132502079 Scheduler time: 1.2819160516373813 Scheduler overhead time: 0.12536585191264749 Adapter cache time: 0.12547966931015253 Engine time: 0.12134841224178672 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_192_slots_96_rate_0.05-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_192_slots_96_rate_0.05-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 270, 270, 270, 270, 540, 270, 33, 540, 33, 270, 270, 33, 540, 540, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 540, 270, 33, 270, 540, 540, 270, 540, 33, 270, 270, 540, 270, 33, 33, 270, 540, 33, 270, 33, 540, 540, 270, 540, 540, 540, 33, 270, 540, 33, 270, 33, 270, 33, 33, 270, 540, 540, 33, 33, 33, 540, 540, 540, 270, 33, 33, 33, 33, 33, 540, 33, 270, 33, 540, 540, 33, 540, 33, 270, 270, 540, 33, 33, 33, 540, 540, 270, 540, 270, 540, 540, 270, 270, 33, 540, 270, 270, 270, 540, 270, 33, 270, 540, 540, 270, 540, 270, 33, 540, 270, 33, 270, 270, 33, 270, 540, 33, 270, 540, 33, 270, 540, 540, 270, 33, 540, 270, 33, 33, 270, 540, 540, 540, 33, 540, 33, 540, 33, 270, 33, 540, 540, 270, 540, 33, 540, 540, 540, 33, 540, 540, 540, 270, 270, 270, 270, 270, 270, 33, 540, 270, 540, 33, 540, 270, 33, 270, 33, 33, 270, 270, 270, 540, 270, 33, 33]
Prompts retrieved: 53952 . Total input tokens: 11959790 . Total output tokens: 10819341
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 1.7837316100485623,
    "estimated_duration": 3599.629977669061,
    "input_throughput": 1260.8815428687583,
    "output_throughput": 1105.4639017582492,
    "total_throughput": 2366.3454446270075,
    "itl": 24.705109527142277,
    "ttft": 6946.831240181317,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5123,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.31802766078551,
    "arrivals": 18247,
    "finished_requests": 18212,
    "scheduler_time": 0.003098199765795414
}
#Debug simulation 
Total elapsed time: 1.783825219143182. Arrivals time: 0.05465287482365966 Scheduler time: 1.2965909261256456 Scheduler overhead time: 0.12488617328926921 Adapter cache time: 0.12506014993414283 Engine time: 0.12168780714273453 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-32/adapters_192_slots_96_rate_0.05-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-32/adapters_192_slots_96_rate_0.05-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 270, 270, 270, 270, 540, 270, 33, 540, 33, 270, 270, 33, 540, 540, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 540, 270, 33, 270, 540, 540, 270, 540, 33, 270, 270, 540, 270, 33, 33, 270, 540, 33, 270, 33, 540, 540, 270, 540, 540, 540, 33, 270, 540, 33, 270, 33, 270, 33, 33, 270, 540, 540, 33, 33, 33, 540, 540, 540, 270, 33, 33, 33, 33, 33, 540, 33, 270, 33, 540, 540, 33, 540, 33, 270, 270, 540, 33, 33, 33, 540, 540, 270, 540, 270, 540, 540, 270, 270, 33, 540, 270, 270, 270, 540, 270, 33, 270, 540, 540, 270, 540, 270, 33, 540, 270, 33, 270, 270, 33, 270, 540, 33, 270, 540, 33, 270, 540, 540, 270, 33, 540, 270, 33, 33, 270, 540, 540, 540, 33, 540, 33, 540, 33, 270, 33, 540, 540, 270, 540, 33, 540, 540, 540, 33, 540, 540, 540, 270, 270, 270, 270, 270, 270, 33, 540, 270, 540, 33, 540, 270, 33, 270, 33, 33, 270, 270, 270, 540, 270, 33, 33]
Prompts retrieved: 53952 . Total input tokens: 11959790 . Total output tokens: 10819341
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.8104825839400291,
    "estimated_duration": 3599.6437353131637,
    "input_throughput": 1260.8767238475446,
    "output_throughput": 1105.4596767348728,
    "total_throughput": 2366.3364005824174,
    "itl": 24.724113735476294,
    "ttft": 6946.878204168485,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5122,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.133475816621125,
    "arrivals": 18247,
    "finished_requests": 18212,
    "scheduler_time": 0.0031443606262672097
}
#Debug simulation 
Total elapsed time: 1.8105754642747343. Arrivals time: 0.055449196603149176 Scheduler time: 1.319019142538309 Scheduler overhead time: 0.1256238827481866 Adapter cache time: 0.12634492199867964 Engine time: 0.12277015065774322 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_192_slots_96_rate_0.05-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_192_slots_96_rate_0.05-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [64 64 64]
Adapter prompts. [540, 66, 540, 66, 540, 66, 540, 66, 66, 66, 135, 135, 135, 135, 540, 135, 66, 540, 66, 135, 135, 66, 540, 540, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 540, 135, 66, 135, 540, 540, 135, 540, 66, 135, 135, 540, 135, 66, 66, 135, 540, 66, 135, 66, 540, 540, 135, 540, 540, 540, 66, 135, 540, 66, 135, 66, 135, 66, 66, 135, 540, 540, 66, 66, 66, 540, 540, 540, 135, 66, 66, 66, 66, 66, 540, 66, 135, 66, 540, 540, 66, 540, 66, 135, 135, 540, 66, 66, 66, 540, 540, 135, 540, 135, 540, 540, 135, 135, 66, 540, 135, 135, 135, 540, 135, 66, 135, 540, 540, 135, 540, 135, 66, 540, 135, 66, 135, 135, 66, 135, 540, 66, 135, 540, 66, 135, 540, 540, 135, 66, 540, 135, 66, 66, 135, 540, 540, 540, 66, 540, 66, 540, 66, 135, 66, 540, 540, 135, 540, 66, 540, 540, 540, 66, 540, 540, 540, 135, 135, 135, 135, 135, 135, 66, 540, 135, 540, 66, 540, 135, 66, 135, 66, 66, 135, 135, 135, 540, 135, 66, 66]
Prompts retrieved: 47424 . Total input tokens: 10486917 . Total output tokens: 9511922
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 1.6349120191298425,
    "estimated_duration": 3600.002963129572,
    "input_throughput": 1105.3913123839761,
    "output_throughput": 992.6905718136696,
    "total_throughput": 2098.0818841976456,
    "itl": 23.632068508778314,
    "ttft": 4967.337919050721,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4415,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.512053389461942,
    "arrivals": 16073,
    "finished_requests": 16051,
    "scheduler_time": 0.00011483934318730341
}
#Debug simulation 
Total elapsed time: 1.635009699035436. Arrivals time: 0.04999971576035023 Scheduler time: 1.1521018450148404 Scheduler overhead time: 0.1289007356390357 Adapter cache time: 0.11460048705339432 Engine time: 0.12623266829177737 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_192_slots_96_rate_0.05-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_192_slots_96_rate_0.05-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [64 64 64]
Adapter prompts. [540, 66, 540, 66, 540, 66, 540, 66, 66, 66, 135, 135, 135, 135, 540, 135, 66, 540, 66, 135, 135, 66, 540, 540, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 540, 135, 66, 135, 540, 540, 135, 540, 66, 135, 135, 540, 135, 66, 66, 135, 540, 66, 135, 66, 540, 540, 135, 540, 540, 540, 66, 135, 540, 66, 135, 66, 135, 66, 66, 135, 540, 540, 66, 66, 66, 540, 540, 540, 135, 66, 66, 66, 66, 66, 540, 66, 135, 66, 540, 540, 66, 540, 66, 135, 135, 540, 66, 66, 66, 540, 540, 135, 540, 135, 540, 540, 135, 135, 66, 540, 135, 135, 135, 540, 135, 66, 135, 540, 540, 135, 540, 135, 66, 540, 135, 66, 135, 135, 66, 135, 540, 66, 135, 540, 66, 135, 540, 540, 135, 66, 540, 135, 66, 66, 135, 540, 540, 540, 66, 540, 66, 540, 66, 135, 66, 540, 540, 135, 540, 66, 540, 540, 540, 66, 540, 540, 540, 135, 135, 135, 135, 135, 135, 66, 540, 135, 540, 66, 540, 135, 66, 135, 66, 66, 135, 135, 135, 540, 135, 66, 66]
Prompts retrieved: 47424 . Total input tokens: 10486917 . Total output tokens: 9511922
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.673010224942118,
    "estimated_duration": 3600.004094988388,
    "input_throughput": 1105.3909648435654,
    "output_throughput": 992.6902597069205,
    "total_throughput": 2098.081224550486,
    "itl": 23.639833027169445,
    "ttft": 4967.47058779433,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4419,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.39509850942145,
    "arrivals": 16073,
    "finished_requests": 16051,
    "scheduler_time": 0.00011650731520535622
}
#Debug simulation 
Total elapsed time: 1.6731047290377319. Arrivals time: 0.051637561060488224 Scheduler time: 1.179541489109397 Scheduler overhead time: 0.13443244015797973 Adapter cache time: 0.11521970853209496 Engine time: 0.12639801669865847 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-32/adapters_192_slots_96_rate_0.05-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-32/adapters_192_slots_96_rate_0.05-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [64 64 64]
Adapter prompts. [540, 66, 540, 66, 540, 66, 540, 66, 66, 66, 135, 135, 135, 135, 540, 135, 66, 540, 66, 135, 135, 66, 540, 540, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 540, 135, 66, 135, 540, 540, 135, 540, 66, 135, 135, 540, 135, 66, 66, 135, 540, 66, 135, 66, 540, 540, 135, 540, 540, 540, 66, 135, 540, 66, 135, 66, 135, 66, 66, 135, 540, 540, 66, 66, 66, 540, 540, 540, 135, 66, 66, 66, 66, 66, 540, 66, 135, 66, 540, 540, 66, 540, 66, 135, 135, 540, 66, 66, 66, 540, 540, 135, 540, 135, 540, 540, 135, 135, 66, 540, 135, 135, 135, 540, 135, 66, 135, 540, 540, 135, 540, 135, 66, 540, 135, 66, 135, 135, 66, 135, 540, 66, 135, 540, 66, 135, 540, 540, 135, 66, 540, 135, 66, 66, 135, 540, 540, 540, 66, 540, 66, 540, 66, 135, 66, 540, 540, 135, 540, 66, 540, 540, 540, 66, 540, 540, 540, 135, 135, 135, 135, 135, 135, 66, 540, 135, 540, 66, 540, 135, 66, 135, 66, 66, 135, 135, 135, 540, 135, 66, 66]
Prompts retrieved: 47424 . Total input tokens: 10486917 . Total output tokens: 9511922
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.6449920223094523,
    "estimated_duration": 3600.0179578486386,
    "input_throughput": 1105.3867082313352,
    "output_throughput": 992.6864370797825,
    "total_throughput": 2098.0731453111175,
    "itl": 23.63975611867285,
    "ttft": 4967.42633551554,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4419,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.425641289370846,
    "arrivals": 16073,
    "finished_requests": 16051,
    "scheduler_time": 0.00011888415122855272
}
#Debug simulation 
Total elapsed time: 1.6450816839933395. Arrivals time: 0.050070874858647585 Scheduler time: 1.1628715484403074 Scheduler overhead time: 0.12978149764239788 Adapter cache time: 0.11491710040718317 Engine time: 0.1241558357141912 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_192_slots_96_rate_0.05-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_192_slots_96_rate_0.05-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [64 64 64]
Adapter prompts. [540, 66, 540, 66, 540, 66, 540, 66, 66, 66, 135, 135, 135, 135, 540, 135, 66, 540, 66, 135, 135, 66, 540, 540, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 540, 135, 66, 135, 540, 540, 135, 540, 66, 135, 135, 540, 135, 66, 66, 135, 540, 66, 135, 66, 540, 540, 135, 540, 540, 540, 66, 135, 540, 66, 135, 66, 135, 66, 66, 135, 540, 540, 66, 66, 66, 540, 540, 540, 135, 66, 66, 66, 66, 66, 540, 66, 135, 66, 540, 540, 66, 540, 66, 135, 135, 540, 66, 66, 66, 540, 540, 135, 540, 135, 540, 540, 135, 135, 66, 540, 135, 135, 135, 540, 135, 66, 135, 540, 540, 135, 540, 135, 66, 540, 135, 66, 135, 135, 66, 135, 540, 66, 135, 540, 66, 135, 540, 540, 135, 66, 540, 135, 66, 66, 135, 540, 540, 540, 66, 540, 66, 540, 66, 135, 66, 540, 540, 135, 540, 66, 540, 540, 540, 66, 540, 540, 540, 135, 135, 135, 135, 135, 135, 66, 540, 135, 540, 66, 540, 135, 66, 135, 66, 66, 135, 135, 135, 540, 135, 66, 66]
Prompts retrieved: 47424 . Total input tokens: 10486917 . Total output tokens: 9511922
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 1.655997599940747,
    "estimated_duration": 3600.014434736552,
    "input_throughput": 1105.3877900051286,
    "output_throughput": 992.6874085607719,
    "total_throughput": 2098.075198565901,
    "itl": 23.634640581415038,
    "ttft": 4967.298250866762,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4416,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.785493240429593,
    "arrivals": 16073,
    "finished_requests": 16051,
    "scheduler_time": 0.00011567332919632981
}
#Debug simulation 
Total elapsed time: 1.656117966864258. Arrivals time: 0.05033728899434209 Scheduler time: 1.1680395021103323 Scheduler overhead time: 0.13167703663930297 Adapter cache time: 0.11444722255691886 Engine time: 0.12773798825219274 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-32/adapters_192_slots_96_rate_0.05-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-32/adapters_192_slots_96_rate_0.05-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [64 64 64]
Adapter prompts. [540, 66, 540, 66, 540, 66, 540, 66, 66, 66, 135, 135, 135, 135, 540, 135, 66, 540, 66, 135, 135, 66, 540, 540, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 540, 135, 66, 135, 540, 540, 135, 540, 66, 135, 135, 540, 135, 66, 66, 135, 540, 66, 135, 66, 540, 540, 135, 540, 540, 540, 66, 135, 540, 66, 135, 66, 135, 66, 66, 135, 540, 540, 66, 66, 66, 540, 540, 540, 135, 66, 66, 66, 66, 66, 540, 66, 135, 66, 540, 540, 66, 540, 66, 135, 135, 540, 66, 66, 66, 540, 540, 135, 540, 135, 540, 540, 135, 135, 66, 540, 135, 135, 135, 540, 135, 66, 135, 540, 540, 135, 540, 135, 66, 540, 135, 66, 135, 135, 66, 135, 540, 66, 135, 540, 66, 135, 540, 540, 135, 66, 540, 135, 66, 66, 135, 540, 540, 540, 66, 540, 66, 540, 66, 135, 66, 540, 540, 135, 540, 66, 540, 540, 540, 66, 540, 540, 540, 135, 135, 135, 135, 135, 135, 66, 540, 135, 540, 66, 540, 135, 66, 135, 66, 66, 135, 135, 135, 540, 135, 66, 66]
Prompts retrieved: 47424 . Total input tokens: 10486917 . Total output tokens: 9511922
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 1.6128788851201534,
    "estimated_duration": 3600.000956512338,
    "input_throughput": 1105.3919285219395,
    "output_throughput": 992.6911251329698,
    "total_throughput": 2098.0830536549092,
    "itl": 23.64188093507747,
    "ttft": 4967.363153763723,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4416,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.60069430386538,
    "arrivals": 16073,
    "finished_requests": 16051,
    "scheduler_time": 0.00012376294527882844
}
#Debug simulation 
Total elapsed time: 1.6129889520816505. Arrivals time: 0.04947966057807207 Scheduler time: 1.1365942871198058 Scheduler overhead time: 0.12901112204417586 Adapter cache time: 0.11274939496070147 Engine time: 0.1221453296020627 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_192_slots_96_rate_0.05-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_192_slots_96_rate_0.05-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [64 64 64]
Adapter prompts. [540, 66, 540, 66, 540, 66, 540, 66, 66, 66, 135, 135, 135, 135, 540, 135, 66, 540, 66, 135, 135, 66, 540, 540, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 540, 135, 66, 135, 540, 540, 135, 540, 66, 135, 135, 540, 135, 66, 66, 135, 540, 66, 135, 66, 540, 540, 135, 540, 540, 540, 66, 135, 540, 66, 135, 66, 135, 66, 66, 135, 540, 540, 66, 66, 66, 540, 540, 540, 135, 66, 66, 66, 66, 66, 540, 66, 135, 66, 540, 540, 66, 540, 66, 135, 135, 540, 66, 66, 66, 540, 540, 135, 540, 135, 540, 540, 135, 135, 66, 540, 135, 135, 135, 540, 135, 66, 135, 540, 540, 135, 540, 135, 66, 540, 135, 66, 135, 135, 66, 135, 540, 66, 135, 540, 66, 135, 540, 540, 135, 66, 540, 135, 66, 66, 135, 540, 540, 540, 66, 540, 66, 540, 66, 135, 66, 540, 540, 135, 540, 66, 540, 540, 540, 66, 540, 540, 540, 135, 135, 135, 135, 135, 135, 66, 540, 135, 540, 66, 540, 135, 66, 135, 66, 66, 135, 135, 135, 540, 135, 66, 66]
Prompts retrieved: 47424 . Total input tokens: 10486917 . Total output tokens: 9511922
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 1.661735569126904,
    "estimated_duration": 3600.0077264415954,
    "input_throughput": 1105.3898497971904,
    "output_throughput": 992.689258345673,
    "total_throughput": 2098.0791081428633,
    "itl": 23.62956095911035,
    "ttft": 4967.266972097961,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4417,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.207052152584023,
    "arrivals": 16073,
    "finished_requests": 16051,
    "scheduler_time": 0.000114005357178277
}
#Debug simulation 
Total elapsed time: 1.6618259949609637. Arrivals time: 0.05018257861956954 Scheduler time: 1.1777277286164463 Scheduler overhead time: 0.13064472610130906 Adapter cache time: 0.11426549311727285 Engine time: 0.12538061616942286 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-32/adapters_192_slots_96_rate_0.05-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-32/adapters_192_slots_96_rate_0.05-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [64 64 64]
Adapter prompts. [540, 66, 540, 66, 540, 66, 540, 66, 66, 66, 135, 135, 135, 135, 540, 135, 66, 540, 66, 135, 135, 66, 540, 540, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 540, 135, 66, 135, 540, 540, 135, 540, 66, 135, 135, 540, 135, 66, 66, 135, 540, 66, 135, 66, 540, 540, 135, 540, 540, 540, 66, 135, 540, 66, 135, 66, 135, 66, 66, 135, 540, 540, 66, 66, 66, 540, 540, 540, 135, 66, 66, 66, 66, 66, 540, 66, 135, 66, 540, 540, 66, 540, 66, 135, 135, 540, 66, 66, 66, 540, 540, 135, 540, 135, 540, 540, 135, 135, 66, 540, 135, 135, 135, 540, 135, 66, 135, 540, 540, 135, 540, 135, 66, 540, 135, 66, 135, 135, 66, 135, 540, 66, 135, 540, 66, 135, 540, 540, 135, 66, 540, 135, 66, 66, 135, 540, 540, 540, 66, 540, 66, 540, 66, 135, 66, 540, 540, 135, 540, 66, 540, 540, 540, 66, 540, 540, 540, 135, 135, 135, 135, 135, 135, 66, 540, 135, 540, 66, 540, 135, 66, 135, 66, 66, 135, 135, 135, 540, 135, 66, 66]
Prompts retrieved: 47424 . Total input tokens: 10486917 . Total output tokens: 9511922
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.6456288532353938,
    "estimated_duration": 3600.0109551449546,
    "input_throughput": 1105.388858418007,
    "output_throughput": 992.6883680430649,
    "total_throughput": 2098.077226461072,
    "itl": 23.6426728581908,
    "ttft": 4967.350092753766,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4417,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.78268546078253,
    "arrivals": 16073,
    "finished_requests": 16051,
    "scheduler_time": 0.00011888415122855272
}
#Debug simulation 
Total elapsed time: 1.6457322472706437. Arrivals time: 0.04955255566164851 Scheduler time: 1.1647301716729999 Scheduler overhead time: 0.12932084361091256 Adapter cache time: 0.11420175014063716 Engine time: 0.12488127313554287 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_192_slots_96_rate_0.05-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_192_slots_96_rate_0.05-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 135, 135, 135, 135, 540, 135, 33, 540, 33, 135, 135, 33, 540, 540, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 540, 135, 33, 135, 540, 540, 135, 540, 33, 135, 135, 540, 135, 33, 33, 135, 540, 33, 135, 33, 540, 540, 135, 540, 540, 540, 33, 135, 540, 33, 135, 33, 135, 33, 33, 135, 540, 540, 33, 33, 33, 540, 540, 540, 135, 33, 33, 33, 33, 33, 540, 33, 135, 33, 540, 540, 33, 540, 33, 135, 135, 540, 33, 33, 33, 540, 540, 135, 540, 135, 540, 540, 135, 135, 33, 540, 135, 135, 135, 540, 135, 33, 135, 540, 540, 135, 540, 135, 33, 540, 135, 33, 135, 135, 33, 135, 540, 33, 135, 540, 33, 135, 540, 540, 135, 33, 540, 135, 33, 33, 135, 540, 540, 540, 33, 540, 33, 540, 33, 135, 33, 540, 540, 135, 540, 33, 540, 540, 540, 33, 540, 540, 540, 135, 135, 135, 135, 135, 135, 33, 540, 135, 540, 33, 540, 135, 33, 135, 33, 33, 135, 135, 135, 540, 135, 33, 33]
Prompts retrieved: 45312 . Total input tokens: 10004990 . Total output tokens: 9089958
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 1.59805553779006,
    "estimated_duration": 3599.997715149504,
    "input_throughput": 1038.5912147293477,
    "output_throughput": 944.1775436957025,
    "total_throughput": 1982.7687584250502,
    "itl": 23.22437009008154,
    "ttft": 4253.767406071103,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3421,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.469928571993561,
    "arrivals": 15374,
    "finished_requests": 15356,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5981461289338768. Arrivals time: 0.048418247140944004 Scheduler time: 1.1176814120262861 Scheduler overhead time: 0.131109232082963 Adapter cache time: 0.10787541326135397 Engine time: 0.12860257644206285 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_192_slots_96_rate_0.05-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_192_slots_96_rate_0.05-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 135, 135, 135, 135, 540, 135, 33, 540, 33, 135, 135, 33, 540, 540, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 540, 135, 33, 135, 540, 540, 135, 540, 33, 135, 135, 540, 135, 33, 33, 135, 540, 33, 135, 33, 540, 540, 135, 540, 540, 540, 33, 135, 540, 33, 135, 33, 135, 33, 33, 135, 540, 540, 33, 33, 33, 540, 540, 540, 135, 33, 33, 33, 33, 33, 540, 33, 135, 33, 540, 540, 33, 540, 33, 135, 135, 540, 33, 33, 33, 540, 540, 135, 540, 135, 540, 540, 135, 135, 33, 540, 135, 135, 135, 540, 135, 33, 135, 540, 540, 135, 540, 135, 33, 540, 135, 33, 135, 135, 33, 135, 540, 33, 135, 540, 33, 135, 540, 540, 135, 33, 540, 135, 33, 33, 135, 540, 540, 540, 33, 540, 33, 540, 33, 135, 33, 540, 540, 135, 540, 33, 540, 540, 540, 33, 540, 540, 540, 135, 135, 135, 135, 135, 135, 33, 540, 135, 540, 33, 540, 135, 33, 135, 33, 33, 135, 135, 135, 540, 135, 33, 33]
Prompts retrieved: 45312 . Total input tokens: 10004990 . Total output tokens: 9089958
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.577119367197156,
    "estimated_duration": 3599.9911959849956,
    "input_throughput": 1038.593095496999,
    "output_throughput": 944.1792534911986,
    "total_throughput": 1982.7723489881976,
    "itl": 23.22991585693118,
    "ttft": 4253.851604783623,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3420,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.148580237603971,
    "arrivals": 15374,
    "finished_requests": 15356,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5772082470357418. Arrivals time: 0.04943410726264119 Scheduler time: 1.0938727613538504 Scheduler overhead time: 0.13368160696700215 Adapter cache time: 0.10838509490713477 Engine time: 0.12722052494063973 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-32/adapters_192_slots_96_rate_0.05-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-32/adapters_192_slots_96_rate_0.05-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 135, 135, 135, 135, 540, 135, 33, 540, 33, 135, 135, 33, 540, 540, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 540, 135, 33, 135, 540, 540, 135, 540, 33, 135, 135, 540, 135, 33, 33, 135, 540, 33, 135, 33, 540, 540, 135, 540, 540, 540, 33, 135, 540, 33, 135, 33, 135, 33, 33, 135, 540, 540, 33, 33, 33, 540, 540, 540, 135, 33, 33, 33, 33, 33, 540, 33, 135, 33, 540, 540, 33, 540, 33, 135, 135, 540, 33, 33, 33, 540, 540, 135, 540, 135, 540, 540, 135, 135, 33, 540, 135, 135, 135, 540, 135, 33, 135, 540, 540, 135, 540, 135, 33, 540, 135, 33, 135, 135, 33, 135, 540, 33, 135, 540, 33, 135, 540, 540, 135, 33, 540, 135, 33, 33, 135, 540, 540, 540, 33, 540, 33, 540, 33, 135, 33, 540, 540, 135, 540, 33, 540, 540, 540, 33, 540, 540, 540, 135, 135, 135, 135, 135, 135, 33, 540, 135, 540, 33, 540, 135, 33, 135, 33, 33, 135, 135, 135, 540, 135, 33, 33]
Prompts retrieved: 45312 . Total input tokens: 10004990 . Total output tokens: 9089958
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.5768146398477256,
    "estimated_duration": 3600.000231536822,
    "input_throughput": 1038.5904887577942,
    "output_throughput": 944.176883718968,
    "total_throughput": 1982.7673724767621,
    "itl": 23.230906140586104,
    "ttft": 4253.886237371785,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3421,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.174057319275432,
    "arrivals": 15374,
    "finished_requests": 15356,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5769073609262705. Arrivals time: 0.04838061612099409 Scheduler time: 1.098220132291317 Scheduler overhead time: 0.13156492030248046 Adapter cache time: 0.10805121390148997 Engine time: 0.1263710013590753 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-16/adapters_192_slots_96_rate_0.05-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-16/adapters_192_slots_96_rate_0.05-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 135, 135, 135, 135, 540, 135, 33, 540, 33, 135, 135, 33, 540, 540, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 540, 135, 33, 135, 540, 540, 135, 540, 33, 135, 135, 540, 135, 33, 33, 135, 540, 33, 135, 33, 540, 540, 135, 540, 540, 540, 33, 135, 540, 33, 135, 33, 135, 33, 33, 135, 540, 540, 33, 33, 33, 540, 540, 540, 135, 33, 33, 33, 33, 33, 540, 33, 135, 33, 540, 540, 33, 540, 33, 135, 135, 540, 33, 33, 33, 540, 540, 135, 540, 135, 540, 540, 135, 135, 33, 540, 135, 135, 135, 540, 135, 33, 135, 540, 540, 135, 540, 135, 33, 540, 135, 33, 135, 135, 33, 135, 540, 33, 135, 540, 33, 135, 540, 540, 135, 33, 540, 135, 33, 33, 135, 540, 540, 540, 33, 540, 33, 540, 33, 135, 33, 540, 540, 135, 540, 33, 540, 540, 540, 33, 540, 540, 540, 135, 135, 135, 135, 135, 135, 33, 540, 135, 540, 33, 540, 135, 33, 135, 33, 33, 135, 135, 135, 540, 135, 33, 33]
Prompts retrieved: 45312 . Total input tokens: 10004990 . Total output tokens: 9089958
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 1.574471476022154,
    "estimated_duration": 3599.9941529933267,
    "input_throughput": 1038.592242404381,
    "output_throughput": 944.178477949406,
    "total_throughput": 1982.770720353787,
    "itl": 23.22702766911743,
    "ttft": 4253.783957665066,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3420,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.67542685885012,
    "arrivals": 15374,
    "finished_requests": 15356,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5745600387454033. Arrivals time: 0.04772998811677098 Scheduler time: 1.0970790130086243 Scheduler overhead time: 0.13168586464598775 Adapter cache time: 0.10760026844218373 Engine time: 0.12606921838596463 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-32/adapters_192_slots_96_rate_0.05-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-32/adapters_192_slots_96_rate_0.05-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 135, 135, 135, 135, 540, 135, 33, 540, 33, 135, 135, 33, 540, 540, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 540, 135, 33, 135, 540, 540, 135, 540, 33, 135, 135, 540, 135, 33, 33, 135, 540, 33, 135, 33, 540, 540, 135, 540, 540, 540, 33, 135, 540, 33, 135, 33, 135, 33, 33, 135, 540, 540, 33, 33, 33, 540, 540, 540, 135, 33, 33, 33, 33, 33, 540, 33, 135, 33, 540, 540, 33, 540, 33, 135, 135, 540, 33, 33, 33, 540, 540, 135, 540, 135, 540, 540, 135, 135, 33, 540, 135, 135, 135, 540, 135, 33, 135, 540, 540, 135, 540, 135, 33, 540, 135, 33, 135, 135, 33, 135, 540, 33, 135, 540, 33, 135, 540, 540, 135, 33, 540, 135, 33, 33, 135, 540, 540, 540, 33, 540, 33, 540, 33, 135, 33, 540, 540, 135, 540, 33, 540, 540, 540, 33, 540, 540, 540, 135, 135, 135, 135, 135, 135, 33, 540, 135, 540, 33, 540, 135, 33, 135, 33, 33, 135, 135, 135, 540, 135, 33, 33]
Prompts retrieved: 45312 . Total input tokens: 10004990 . Total output tokens: 9089958
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 1.6071644150651991,
    "estimated_duration": 3599.983921396116,
    "input_throughput": 1038.5951942113122,
    "output_throughput": 944.1811614208026,
    "total_throughput": 1982.7763556321147,
    "itl": 23.231399392875396,
    "ttft": 4253.870413291192,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3420,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.316425191386886,
    "arrivals": 15374,
    "finished_requests": 15356,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6072583701461554. Arrivals time: 0.048314787447452545 Scheduler time: 1.1280003655701876 Scheduler overhead time: 0.13188842870295048 Adapter cache time: 0.10786761995404959 Engine time: 0.12678175885230303 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-16/adapters_192_slots_96_rate_0.05-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-16/adapters_192_slots_96_rate_0.05-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 135, 135, 135, 135, 540, 135, 33, 540, 33, 135, 135, 33, 540, 540, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 540, 135, 33, 135, 540, 540, 135, 540, 33, 135, 135, 540, 135, 33, 33, 135, 540, 33, 135, 33, 540, 540, 135, 540, 540, 540, 33, 135, 540, 33, 135, 33, 135, 33, 33, 135, 540, 540, 33, 33, 33, 540, 540, 540, 135, 33, 33, 33, 33, 33, 540, 33, 135, 33, 540, 540, 33, 540, 33, 135, 135, 540, 33, 33, 33, 540, 540, 135, 540, 135, 540, 540, 135, 135, 33, 540, 135, 135, 135, 540, 135, 33, 135, 540, 540, 135, 540, 135, 33, 540, 135, 33, 135, 135, 33, 135, 540, 33, 135, 540, 33, 135, 540, 540, 135, 33, 540, 135, 33, 33, 135, 540, 540, 540, 33, 540, 33, 540, 33, 135, 33, 540, 540, 135, 540, 33, 540, 540, 540, 33, 540, 540, 540, 135, 135, 135, 135, 135, 135, 33, 540, 135, 540, 33, 540, 135, 33, 135, 33, 33, 135, 135, 135, 540, 135, 33, 33]
Prompts retrieved: 45312 . Total input tokens: 10004990 . Total output tokens: 9089958
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 1.5713245649822056,
    "estimated_duration": 3599.993633073429,
    "input_throughput": 1038.5923924004167,
    "output_throughput": 944.1786143099743,
    "total_throughput": 1982.7710067103908,
    "itl": 23.221924481401548,
    "ttft": 4253.735620277537,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3420,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.225972008565774,
    "arrivals": 15374,
    "finished_requests": 15356,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.571440084837377. Arrivals time: 0.04849733738228679 Scheduler time: 1.0915080728009343 Scheduler overhead time: 0.13107590656727552 Adapter cache time: 0.10811560787260532 Engine time: 0.1281203948892653 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-32/adapters_192_slots_96_rate_0.05-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-32/adapters_192_slots_96_rate_0.05-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 135, 135, 135, 135, 540, 135, 33, 540, 33, 135, 135, 33, 540, 540, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 540, 135, 33, 135, 540, 540, 135, 540, 33, 135, 135, 540, 135, 33, 33, 135, 540, 33, 135, 33, 540, 540, 135, 540, 540, 540, 33, 135, 540, 33, 135, 33, 135, 33, 33, 135, 540, 540, 33, 33, 33, 540, 540, 540, 135, 33, 33, 33, 33, 33, 540, 33, 135, 33, 540, 540, 33, 540, 33, 135, 135, 540, 33, 33, 33, 540, 540, 135, 540, 135, 540, 540, 135, 135, 33, 540, 135, 135, 135, 540, 135, 33, 135, 540, 540, 135, 540, 135, 33, 540, 135, 33, 135, 135, 33, 135, 540, 33, 135, 540, 33, 135, 540, 540, 135, 33, 540, 135, 33, 33, 135, 540, 540, 540, 33, 540, 33, 540, 33, 135, 33, 540, 540, 135, 540, 33, 540, 540, 540, 33, 540, 540, 540, 135, 135, 135, 135, 135, 135, 33, 540, 135, 540, 33, 540, 135, 33, 135, 33, 33, 135, 135, 135, 540, 135, 33, 33]
Prompts retrieved: 45312 . Total input tokens: 10004990 . Total output tokens: 9089958
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.6128229987807572,
    "estimated_duration": 3599.9980228404715,
    "input_throughput": 1038.5911259612058,
    "output_throughput": 944.1774629970743,
    "total_throughput": 1982.7685889582801,
    "itl": 23.233129741553316,
    "ttft": 4253.8756466004525,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3421,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.457797875291918,
    "arrivals": 15374,
    "finished_requests": 15356,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6129160937853158. Arrivals time: 0.04788876324892044 Scheduler time: 1.1197020299732685 Scheduler overhead time: 0.13397201616317034 Adapter cache time: 0.11036474583670497 Engine time: 0.13132234243676066 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-8/adapters_192_slots_96_rate_0.05-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-8/adapters_192_slots_96_rate_0.05-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 66, 66, 66, 66, 540, 66, 33, 540, 33, 66, 66, 33, 540, 540, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 540, 66, 33, 66, 540, 540, 66, 540, 33, 66, 66, 540, 66, 33, 33, 66, 540, 33, 66, 33, 540, 540, 66, 540, 540, 540, 33, 66, 540, 33, 66, 33, 66, 33, 33, 66, 540, 540, 33, 33, 33, 540, 540, 540, 66, 33, 33, 33, 33, 33, 540, 33, 66, 33, 540, 540, 33, 540, 33, 66, 66, 540, 33, 33, 33, 540, 540, 66, 540, 66, 540, 540, 66, 66, 33, 540, 66, 66, 66, 540, 66, 33, 66, 540, 540, 66, 540, 66, 33, 540, 66, 33, 66, 66, 33, 66, 540, 33, 66, 540, 33, 66, 540, 540, 66, 33, 540, 66, 33, 33, 66, 540, 540, 540, 33, 540, 33, 540, 33, 66, 33, 540, 540, 66, 540, 33, 540, 540, 540, 33, 540, 540, 540, 66, 66, 66, 66, 66, 66, 33, 540, 66, 540, 33, 540, 66, 33, 66, 33, 33, 66, 66, 66, 540, 66, 33, 33]
Prompts retrieved: 40896 . Total input tokens: 9009721 . Total output tokens: 8220936
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 1.5083090709522367,
    "estimated_duration": 3599.9037924488175,
    "input_throughput": 935.0610999829543,
    "output_throughput": 853.1564111358587,
    "total_throughput": 1788.2175111188128,
    "itl": 22.35361867872005,
    "ttft": 6525.103598115657,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2032,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.218911095671536,
    "arrivals": 13872,
    "finished_requests": 13847,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5083986888639629. Arrivals time: 0.04505784856155515 Scheduler time: 1.0327344052493572 Scheduler overhead time: 0.13550855312496424 Adapter cache time: 0.09766481723636389 Engine time: 0.13104320177808404 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-16/adapters_192_slots_96_rate_0.05-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-16/adapters_192_slots_96_rate_0.05-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 66, 66, 66, 66, 540, 66, 33, 540, 33, 66, 66, 33, 540, 540, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 540, 66, 33, 66, 540, 540, 66, 540, 33, 66, 66, 540, 66, 33, 33, 66, 540, 33, 66, 33, 540, 540, 66, 540, 540, 540, 33, 66, 540, 33, 66, 33, 66, 33, 33, 66, 540, 540, 33, 33, 33, 540, 540, 540, 66, 33, 33, 33, 33, 33, 540, 33, 66, 33, 540, 540, 33, 540, 33, 66, 66, 540, 33, 33, 33, 540, 540, 66, 540, 66, 540, 540, 66, 66, 33, 540, 66, 66, 66, 540, 66, 33, 66, 540, 540, 66, 540, 66, 33, 540, 66, 33, 66, 66, 33, 66, 540, 33, 66, 540, 33, 66, 540, 540, 66, 33, 540, 66, 33, 33, 66, 540, 540, 540, 33, 540, 33, 540, 33, 66, 33, 540, 540, 66, 540, 33, 540, 540, 540, 33, 540, 540, 540, 66, 66, 66, 66, 66, 66, 33, 540, 66, 540, 33, 540, 66, 33, 66, 33, 33, 66, 66, 66, 540, 66, 33, 33]
Prompts retrieved: 40896 . Total input tokens: 9009721 . Total output tokens: 8220936
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.4924951177090406,
    "estimated_duration": 3599.916073914108,
    "input_throughput": 935.0579099306841,
    "output_throughput": 853.1535005094341,
    "total_throughput": 1788.2114104401182,
    "itl": 22.357649586311602,
    "ttft": 6525.209917380313,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2033,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.631193120067244,
    "arrivals": 13872,
    "finished_requests": 13847,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.492582500912249. Arrivals time: 0.044819827657192945 Scheduler time: 1.0191240720450878 Scheduler overhead time: 0.1353983199223876 Adapter cache time: 0.09739090548828244 Engine time: 0.1299148742109537 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-32/adapters_192_slots_96_rate_0.05-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-32/adapters_192_slots_96_rate_0.05-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 66, 66, 66, 66, 540, 66, 33, 540, 33, 66, 66, 33, 540, 540, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 540, 66, 33, 66, 540, 540, 66, 540, 33, 66, 66, 540, 66, 33, 33, 66, 540, 33, 66, 33, 540, 540, 66, 540, 540, 540, 33, 66, 540, 33, 66, 33, 66, 33, 33, 66, 540, 540, 33, 33, 33, 540, 540, 540, 66, 33, 33, 33, 33, 33, 540, 33, 66, 33, 540, 540, 33, 540, 33, 66, 66, 540, 33, 33, 33, 540, 540, 66, 540, 66, 540, 540, 66, 66, 33, 540, 66, 66, 66, 540, 66, 33, 66, 540, 540, 66, 540, 66, 33, 540, 66, 33, 66, 66, 33, 66, 540, 33, 66, 540, 33, 66, 540, 540, 66, 33, 540, 66, 33, 33, 66, 540, 540, 540, 33, 540, 33, 540, 33, 66, 33, 540, 540, 66, 540, 33, 540, 540, 540, 33, 540, 540, 540, 66, 66, 66, 66, 66, 66, 33, 540, 66, 540, 33, 540, 66, 33, 66, 33, 33, 66, 66, 66, 540, 66, 33, 33]
Prompts retrieved: 40896 . Total input tokens: 9009721 . Total output tokens: 8220936
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.4650944112800062,
    "estimated_duration": 3599.9050542238365,
    "input_throughput": 935.0607722418835,
    "output_throughput": 853.1561121025701,
    "total_throughput": 1788.2168843444535,
    "itl": 22.357472293201667,
    "ttft": 6525.243915854321,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2032,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.640051665808954,
    "arrivals": 13872,
    "finished_requests": 13847,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4651811830699444. Arrivals time: 0.044274551793932915 Scheduler time: 0.9923872384242713 Scheduler overhead time: 0.1346519310027361 Adapter cache time: 0.0973410583101213 Engine time: 0.13086859695613384 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-16/adapters_192_slots_96_rate_0.05-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-16/adapters_192_slots_96_rate_0.05-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 66, 66, 66, 66, 540, 66, 33, 540, 33, 66, 66, 33, 540, 540, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 540, 66, 33, 66, 540, 540, 66, 540, 33, 66, 66, 540, 66, 33, 33, 66, 540, 33, 66, 33, 540, 540, 66, 540, 540, 540, 33, 66, 540, 33, 66, 33, 66, 33, 33, 66, 540, 540, 33, 33, 33, 540, 540, 540, 66, 33, 33, 33, 33, 33, 540, 33, 66, 33, 540, 540, 33, 540, 33, 66, 66, 540, 33, 33, 33, 540, 540, 66, 540, 66, 540, 540, 66, 66, 33, 540, 66, 66, 66, 540, 66, 33, 66, 540, 540, 66, 540, 66, 33, 540, 66, 33, 66, 66, 33, 66, 540, 33, 66, 540, 33, 66, 540, 540, 66, 33, 540, 66, 33, 33, 66, 540, 540, 540, 33, 540, 33, 540, 33, 66, 33, 540, 540, 66, 540, 33, 540, 540, 540, 33, 540, 540, 540, 66, 66, 66, 66, 66, 66, 33, 540, 66, 540, 33, 540, 66, 33, 66, 33, 33, 66, 66, 66, 540, 66, 33, 33]
Prompts retrieved: 40896 . Total input tokens: 9009721 . Total output tokens: 8220936
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 1.5007165125571191,
    "estimated_duration": 3599.8962901438144,
    "input_throughput": 934.9099887167989,
    "output_throughput": 853.157633570967,
    "total_throughput": 1788.067622287766,
    "itl": 22.35575695902943,
    "ttft": 6784.664988953765,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2032,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.343820728137889,
    "arrivals": 13872,
    "finished_requests": 13846,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5008090916089714. Arrivals time: 0.0456320415250957 Scheduler time: 1.0240220865234733 Scheduler overhead time: 0.1352864494547248 Adapter cache time: 0.09765007626265287 Engine time: 0.13174402620643377 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-32/adapters_192_slots_96_rate_0.05-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-32/adapters_192_slots_96_rate_0.05-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 66, 66, 66, 66, 540, 66, 33, 540, 33, 66, 66, 33, 540, 540, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 540, 66, 33, 66, 540, 540, 66, 540, 33, 66, 66, 540, 66, 33, 33, 66, 540, 33, 66, 33, 540, 540, 66, 540, 540, 540, 33, 66, 540, 33, 66, 33, 66, 33, 33, 66, 540, 540, 33, 33, 33, 540, 540, 540, 66, 33, 33, 33, 33, 33, 540, 33, 66, 33, 540, 540, 33, 540, 33, 66, 66, 540, 33, 33, 33, 540, 540, 66, 540, 66, 540, 540, 66, 66, 33, 540, 66, 66, 66, 540, 66, 33, 66, 540, 540, 66, 540, 66, 33, 540, 66, 33, 66, 66, 33, 66, 540, 33, 66, 540, 33, 66, 540, 540, 66, 33, 540, 66, 33, 33, 66, 540, 540, 540, 33, 540, 33, 540, 33, 66, 33, 540, 540, 66, 540, 33, 540, 540, 540, 33, 540, 540, 540, 66, 66, 66, 66, 66, 66, 33, 540, 66, 540, 33, 540, 66, 33, 66, 33, 33, 66, 66, 66, 540, 66, 33, 33]
Prompts retrieved: 40896 . Total input tokens: 9009721 . Total output tokens: 8220936
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 1.5023448658175766,
    "estimated_duration": 3599.8974820548938,
    "input_throughput": 934.9096791719913,
    "output_throughput": 853.157351094024,
    "total_throughput": 1788.0670302660153,
    "itl": 22.35912761038633,
    "ttft": 6784.787476373507,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2032,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.727324793580799,
    "arrivals": 13872,
    "finished_requests": 13846,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5024345209822059. Arrivals time: 0.04486024426296353 Scheduler time: 1.0284840571694076 Scheduler overhead time: 0.13507718918845057 Adapter cache time: 0.09732842911034822 Engine time: 0.13059915229678154 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-16/adapters_192_slots_96_rate_0.05-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-16/adapters_192_slots_96_rate_0.05-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 66, 66, 66, 66, 540, 66, 33, 540, 33, 66, 66, 33, 540, 540, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 540, 66, 33, 66, 540, 540, 66, 540, 33, 66, 66, 540, 66, 33, 33, 66, 540, 33, 66, 33, 540, 540, 66, 540, 540, 540, 33, 66, 540, 33, 66, 33, 66, 33, 33, 66, 540, 540, 33, 33, 33, 540, 540, 540, 66, 33, 33, 33, 33, 33, 540, 33, 66, 33, 540, 540, 33, 540, 33, 66, 66, 540, 33, 33, 33, 540, 540, 66, 540, 66, 540, 540, 66, 66, 33, 540, 66, 66, 66, 540, 66, 33, 66, 540, 540, 66, 540, 66, 33, 540, 66, 33, 66, 66, 33, 66, 540, 33, 66, 540, 33, 66, 540, 540, 66, 33, 540, 66, 33, 33, 66, 540, 540, 540, 33, 540, 33, 540, 33, 66, 33, 540, 540, 66, 540, 33, 540, 540, 540, 33, 540, 540, 540, 66, 66, 66, 66, 66, 66, 33, 540, 66, 540, 33, 540, 66, 33, 66, 33, 33, 66, 66, 66, 540, 66, 33, 33]
Prompts retrieved: 40896 . Total input tokens: 9009721 . Total output tokens: 8220936
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 1.5156479650177062,
    "estimated_duration": 3599.916612627883,
    "input_throughput": 935.0577700028384,
    "output_throughput": 853.1533728382706,
    "total_throughput": 1788.211142841109,
    "itl": 22.353683836378043,
    "ttft": 6525.032968398083,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2032,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.075782199241042,
    "arrivals": 13872,
    "finished_requests": 13847,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.515762290917337. Arrivals time: 0.04517489252611995 Scheduler time: 1.0389382396824658 Scheduler overhead time: 0.13601821893826127 Adapter cache time: 0.09811499016359448 Engine time: 0.13105738814920187 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-32/adapters_192_slots_96_rate_0.05-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-32/adapters_192_slots_96_rate_0.05-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 66, 66, 66, 66, 540, 66, 33, 540, 33, 66, 66, 33, 540, 540, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 540, 66, 33, 66, 540, 540, 66, 540, 33, 66, 66, 540, 66, 33, 33, 66, 540, 33, 66, 33, 540, 540, 66, 540, 540, 540, 33, 66, 540, 33, 66, 33, 66, 33, 33, 66, 540, 540, 33, 33, 33, 540, 540, 540, 66, 33, 33, 33, 33, 33, 540, 33, 66, 33, 540, 540, 33, 540, 33, 66, 66, 540, 33, 33, 33, 540, 540, 66, 540, 66, 540, 540, 66, 66, 33, 540, 66, 66, 66, 540, 66, 33, 66, 540, 540, 66, 540, 66, 33, 540, 66, 33, 66, 66, 33, 66, 540, 33, 66, 540, 33, 66, 540, 540, 66, 33, 540, 66, 33, 33, 66, 540, 540, 540, 33, 540, 33, 540, 33, 66, 33, 540, 540, 66, 540, 33, 540, 540, 540, 33, 540, 540, 540, 66, 66, 66, 66, 66, 66, 33, 540, 66, 540, 33, 540, 66, 33, 66, 33, 33, 66, 66, 66, 540, 66, 33, 33]
Prompts retrieved: 40896 . Total input tokens: 9009721 . Total output tokens: 8220936
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.5049603218212724,
    "estimated_duration": 3599.9067571645624,
    "input_throughput": 935.0603299101294,
    "output_throughput": 853.1557085159255,
    "total_throughput": 1788.216038426055,
    "itl": 22.359166779197576,
    "ttft": 6525.254243340348,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2032,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.809945031255268,
    "arrivals": 13872,
    "finished_requests": 13847,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5050555509515107. Arrivals time: 0.04455651808530092 Scheduler time: 1.0318104773759842 Scheduler overhead time: 0.13492410397157073 Adapter cache time: 0.09715341916307807 Engine time: 0.13016303395852447 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-8/adapters_192_slots_96_rate_0.025-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-8/adapters_192_slots_96_rate_0.025-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [64 64 64]
Adapter prompts. [270, 66, 270, 66, 270, 66, 270, 66, 66, 66, 135, 135, 135, 135, 270, 135, 66, 270, 66, 135, 135, 66, 270, 270, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 270, 135, 66, 135, 270, 270, 135, 270, 66, 135, 135, 270, 135, 66, 66, 135, 270, 66, 135, 66, 270, 270, 135, 270, 270, 270, 66, 135, 270, 66, 135, 66, 135, 66, 66, 135, 270, 270, 66, 66, 66, 270, 270, 270, 135, 66, 66, 66, 66, 66, 270, 66, 135, 66, 270, 270, 66, 270, 66, 135, 135, 270, 66, 66, 66, 270, 270, 135, 270, 135, 270, 270, 135, 135, 66, 270, 135, 135, 135, 270, 135, 66, 135, 270, 270, 135, 270, 135, 66, 270, 135, 66, 135, 135, 66, 135, 270, 66, 135, 270, 66, 135, 270, 270, 135, 66, 270, 135, 66, 66, 135, 270, 270, 270, 66, 270, 66, 270, 66, 135, 66, 270, 270, 135, 270, 66, 270, 270, 270, 66, 270, 270, 270, 135, 135, 135, 135, 135, 135, 66, 270, 135, 270, 66, 270, 135, 66, 135, 66, 66, 135, 135, 135, 270, 135, 66, 66]
Prompts retrieved: 30144 . Total input tokens: 6607829 . Total output tokens: 6040768
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 1.2261914960108697,
    "estimated_duration": 3599.2365147520063,
    "input_throughput": 696.3593500252907,
    "output_throughput": 615.3749526939907,
    "total_throughput": 1311.7343027192815,
    "itl": 20.86854169913182,
    "ttft": 4637.361608755971,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4038,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.358249509999588,
    "arrivals": 10170,
    "finished_requests": 10157,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.226266642101109. Arrivals time: 0.03653299482539296 Scheduler time: 0.755813688505441 Scheduler overhead time: 0.1401602099649608 Adapter cache time: 0.08755429880693555 Engine time: 0.13684814190492034 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-16/adapters_192_slots_96_rate_0.025-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-16/adapters_192_slots_96_rate_0.025-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [64 64 64]
Adapter prompts. [270, 66, 270, 66, 270, 66, 270, 66, 66, 66, 135, 135, 135, 135, 270, 135, 66, 270, 66, 135, 135, 66, 270, 270, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 270, 135, 66, 135, 270, 270, 135, 270, 66, 135, 135, 270, 135, 66, 66, 135, 270, 66, 135, 66, 270, 270, 135, 270, 270, 270, 66, 135, 270, 66, 135, 66, 135, 66, 66, 135, 270, 270, 66, 66, 66, 270, 270, 270, 135, 66, 66, 66, 66, 66, 270, 66, 135, 66, 270, 270, 66, 270, 66, 135, 135, 270, 66, 66, 66, 270, 270, 135, 270, 135, 270, 270, 135, 135, 66, 270, 135, 135, 135, 270, 135, 66, 135, 270, 270, 135, 270, 135, 66, 270, 135, 66, 135, 135, 66, 135, 270, 66, 135, 270, 66, 135, 270, 270, 135, 66, 270, 135, 66, 66, 135, 270, 270, 270, 66, 270, 66, 270, 66, 135, 66, 270, 270, 135, 270, 66, 270, 270, 270, 66, 270, 270, 270, 135, 135, 135, 135, 135, 135, 66, 270, 135, 270, 66, 270, 135, 66, 135, 66, 66, 135, 135, 135, 270, 135, 66, 66]
Prompts retrieved: 30144 . Total input tokens: 6607829 . Total output tokens: 6040768
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.2485313639044762,
    "estimated_duration": 3599.2413242331436,
    "input_throughput": 696.3584195160926,
    "output_throughput": 615.3741304000791,
    "total_throughput": 1311.7325499161718,
    "itl": 20.873543606107905,
    "ttft": 4637.4042776023925,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4037,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.155653610979792,
    "arrivals": 10170,
    "finished_requests": 10157,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2486087968572974. Arrivals time: 0.03696599509567022 Scheduler time: 0.7755198646336794 Scheduler overhead time: 0.14086262695491314 Adapter cache time: 0.08874704875051975 Engine time: 0.1368706114590168 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-32/adapters_192_slots_96_rate_0.025-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-32/adapters_192_slots_96_rate_0.025-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [64 64 64]
Adapter prompts. [270, 66, 270, 66, 270, 66, 270, 66, 66, 66, 135, 135, 135, 135, 270, 135, 66, 270, 66, 135, 135, 66, 270, 270, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 270, 135, 66, 135, 270, 270, 135, 270, 66, 135, 135, 270, 135, 66, 66, 135, 270, 66, 135, 66, 270, 270, 135, 270, 270, 270, 66, 135, 270, 66, 135, 66, 135, 66, 66, 135, 270, 270, 66, 66, 66, 270, 270, 270, 135, 66, 66, 66, 66, 66, 270, 66, 135, 66, 270, 270, 66, 270, 66, 135, 135, 270, 66, 66, 66, 270, 270, 135, 270, 135, 270, 270, 135, 135, 66, 270, 135, 135, 135, 270, 135, 66, 135, 270, 270, 135, 270, 135, 66, 270, 135, 66, 135, 135, 66, 135, 270, 66, 135, 270, 66, 135, 270, 270, 135, 66, 270, 135, 66, 66, 135, 270, 270, 270, 66, 270, 66, 270, 66, 135, 66, 270, 270, 135, 270, 66, 270, 270, 270, 66, 270, 270, 270, 135, 135, 135, 135, 135, 135, 66, 270, 135, 270, 66, 270, 135, 66, 135, 66, 66, 135, 135, 135, 270, 135, 66, 66]
Prompts retrieved: 30144 . Total input tokens: 6607829 . Total output tokens: 6040768
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.2428802149370313,
    "estimated_duration": 3599.230255270769,
    "input_throughput": 696.3605610754256,
    "output_throughput": 615.3760229028125,
    "total_throughput": 1311.736583978238,
    "itl": 20.874521815493136,
    "ttft": 4637.342996246918,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4037,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.182077690455117,
    "arrivals": 10170,
    "finished_requests": 10157,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2429785528220236. Arrivals time: 0.037334068678319454 Scheduler time: 0.7670363090001047 Scheduler overhead time: 0.14185669226571918 Adapter cache time: 0.08933877758681774 Engine time: 0.13754774862900376 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-16/adapters_192_slots_96_rate_0.025-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-16/adapters_192_slots_96_rate_0.025-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [64 64 64]
Adapter prompts. [270, 66, 270, 66, 270, 66, 270, 66, 66, 66, 135, 135, 135, 135, 270, 135, 66, 270, 66, 135, 135, 66, 270, 270, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 270, 135, 66, 135, 270, 270, 135, 270, 66, 135, 135, 270, 135, 66, 66, 135, 270, 66, 135, 66, 270, 270, 135, 270, 270, 270, 66, 135, 270, 66, 135, 66, 135, 66, 66, 135, 270, 270, 66, 66, 66, 270, 270, 270, 135, 66, 66, 66, 66, 66, 270, 66, 135, 66, 270, 270, 66, 270, 66, 135, 135, 270, 66, 66, 66, 270, 270, 135, 270, 135, 270, 270, 135, 135, 66, 270, 135, 135, 135, 270, 135, 66, 135, 270, 270, 135, 270, 135, 66, 270, 135, 66, 135, 135, 66, 135, 270, 66, 135, 270, 66, 135, 270, 270, 135, 66, 270, 135, 66, 66, 135, 270, 270, 270, 66, 270, 66, 270, 66, 135, 66, 270, 270, 135, 270, 66, 270, 270, 270, 66, 270, 270, 270, 135, 135, 135, 135, 135, 135, 66, 270, 135, 270, 66, 270, 135, 66, 135, 66, 66, 135, 135, 135, 270, 135, 66, 66]
Prompts retrieved: 30144 . Total input tokens: 6607829 . Total output tokens: 6040768
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 1.232367835007608,
    "estimated_duration": 3599.2288407075157,
    "input_throughput": 696.3608347579572,
    "output_throughput": 615.3762647569282,
    "total_throughput": 1311.7370995148854,
    "itl": 20.869806455729513,
    "ttft": 4637.40849416795,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4038,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.616029078386042,
    "arrivals": 10170,
    "finished_requests": 10157,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.232456092722714. Arrivals time: 0.036828496027737856 Scheduler time: 0.7593190255574882 Scheduler overhead time: 0.14145628176629543 Adapter cache time: 0.08845178876072168 Engine time: 0.13647375954315066 
