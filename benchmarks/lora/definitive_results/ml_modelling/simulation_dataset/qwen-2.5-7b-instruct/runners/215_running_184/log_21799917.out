INFO 06-01 00:47:20 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:47:20 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_16-16-16/adapters_384_slots_96_rate_1.6-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_16-16-16/adapters_384_slots_96_rate_1.6-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 4320, 270, 17280, 17280, 270, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 270, 17280, 270, 17280, 4320, 4320, 4320, 270, 270, 4320, 270, 17280, 270, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 17280, 270, 17280, 17280, 17280, 17280, 270, 4320, 4320, 4320, 17280, 4320, 270, 4320, 270, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 270, 270, 17280, 4320, 4320, 270, 270, 270, 4320, 270, 4320, 270, 17280, 270, 4320, 17280, 270, 17280, 4320, 270, 17280, 17280, 17280, 17280, 4320, 270, 4320, 17280, 17280, 4320, 270, 270, 17280, 4320, 4320, 270, 270, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 270, 4320, 4320, 4320, 4320, 270, 270, 17280, 270, 17280, 270, 270, 270, 4320, 4320, 17280, 270, 270, 17280, 270, 17280, 4320, 270, 17280, 4320, 4320, 270, 17280, 17280, 17280, 270, 4320, 17280, 270, 17280, 4320, 4320, 17280, 17280, 270, 4320, 17280, 270, 4320, 4320, 270, 4320, 270, 4320, 17280, 17280, 4320, 270, 17280, 270, 17280, 4320, 4320, 4320, 4320, 4320, 270, 270, 17280, 270, 17280, 270, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 270, 270, 270, 270, 270, 4320, 270, 270, 4320, 17280, 17280, 270, 270, 17280, 270, 270, 270, 4320, 270, 4320, 17280, 17280, 4320, 4320, 270, 17280, 4320, 17280, 270, 4320, 4320, 270, 270, 4320, 270, 17280, 17280, 270, 17280, 17280, 270, 4320, 17280, 270, 270, 4320, 4320, 270, 270, 17280, 17280, 17280, 17280, 4320, 270, 4320, 4320, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 17280, 4320, 4320, 4320, 17280, 270, 4320, 4320, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 4320, 270, 17280, 17280, 17280, 4320, 270, 17280, 17280, 4320, 4320, 17280, 17280, 270, 17280, 17280, 4320, 270, 17280, 4320, 4320, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 4320, 17280, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 17280, 270, 270, 270, 4320, 270, 4320, 4320, 270, 17280, 4320, 17280, 270, 17280, 270, 4320, 4320, 4320, 4320, 270, 4320, 17280, 17280, 270, 17280, 17280, 270, 17280, 4320, 17280, 4320, 4320, 4320, 270, 4320, 270, 270, 17280, 270, 4320, 270, 270, 4320, 17280, 4320, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2799360 . Total input tokens: 623655065 . Total output tokens: 559758541
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 48.367291011847556,
    "estimated_duration": 3600.0378597242006,
    "input_throughput": 5321.857365541085,
    "output_throughput": 4676.103601113146,
    "total_throughput": 9997.960966654231,
    "itl": 181.92207224465676,
    "ttft": 2111754.65933776,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 591,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.76711972428716,
    "arrivals": 931969,
    "finished_requests": 77464,
    "scheduler_time": 137.26472750471623
}
#Debug simulation 
Total elapsed time: 48.36752504389733. Arrivals time: 0.39934562100097537 Scheduler time: 47.83728884765878 Scheduler overhead time: 0.04724887479096651 Adapter cache time: 0.017564729787409306 Engine time: 0.047965231351554394 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_16-16-32/adapters_384_slots_96_rate_1.6-0.4-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_16-16-32/adapters_384_slots_96_rate_1.6-0.4-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 4320, 270, 17280, 17280, 270, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 270, 17280, 270, 17280, 4320, 4320, 4320, 270, 270, 4320, 270, 17280, 270, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 17280, 270, 17280, 17280, 17280, 17280, 270, 4320, 4320, 4320, 17280, 4320, 270, 4320, 270, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 270, 270, 17280, 4320, 4320, 270, 270, 270, 4320, 270, 4320, 270, 17280, 270, 4320, 17280, 270, 17280, 4320, 270, 17280, 17280, 17280, 17280, 4320, 270, 4320, 17280, 17280, 4320, 270, 270, 17280, 4320, 4320, 270, 270, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 270, 4320, 4320, 4320, 4320, 270, 270, 17280, 270, 17280, 270, 270, 270, 4320, 4320, 17280, 270, 270, 17280, 270, 17280, 4320, 270, 17280, 4320, 4320, 270, 17280, 17280, 17280, 270, 4320, 17280, 270, 17280, 4320, 4320, 17280, 17280, 270, 4320, 17280, 270, 4320, 4320, 270, 4320, 270, 4320, 17280, 17280, 4320, 270, 17280, 270, 17280, 4320, 4320, 4320, 4320, 4320, 270, 270, 17280, 270, 17280, 270, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 270, 270, 270, 270, 270, 4320, 270, 270, 4320, 17280, 17280, 270, 270, 17280, 270, 270, 270, 4320, 270, 4320, 17280, 17280, 4320, 4320, 270, 17280, 4320, 17280, 270, 4320, 4320, 270, 270, 4320, 270, 17280, 17280, 270, 17280, 17280, 270, 4320, 17280, 270, 270, 4320, 4320, 270, 270, 17280, 17280, 17280, 17280, 4320, 270, 4320, 4320, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 17280, 4320, 4320, 4320, 17280, 270, 4320, 4320, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 4320, 270, 17280, 17280, 17280, 4320, 270, 17280, 17280, 4320, 4320, 17280, 17280, 270, 17280, 17280, 4320, 270, 17280, 4320, 4320, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 4320, 17280, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 17280, 270, 270, 270, 4320, 270, 4320, 4320, 270, 17280, 4320, 17280, 270, 17280, 270, 4320, 4320, 4320, 4320, 270, 4320, 17280, 17280, 270, 17280, 17280, 270, 17280, 4320, 17280, 4320, 4320, 4320, 270, 4320, 270, 270, 17280, 270, 4320, 270, 270, 4320, 17280, 4320, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2799360 . Total input tokens: 623655065 . Total output tokens: 559758541
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 49.423777997959405,
    "estimated_duration": 3600.0497682663504,
    "input_throughput": 5325.3233244139965,
    "output_throughput": 4675.802581503256,
    "total_throughput": 10001.125905917253,
    "itl": 181.08510429037682,
    "ttft": 2111780.113221687,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 577,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9325138637796007,
    "arrivals": 931969,
    "finished_requests": 77552,
    "scheduler_time": 137.3232557206566
}
#Debug simulation 
Total elapsed time: 49.42398142488673. Arrivals time: 0.39986751694232225 Scheduler time: 48.89137453585863 Scheduler overhead time: 0.048812298104166985 Adapter cache time: 0.01774027943611145 Engine time: 0.04797413060441613 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-8/adapters_384_slots_96_rate_1.6-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-8/adapters_384_slots_96_rate_1.6-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 4320, 135, 17280, 17280, 135, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 135, 17280, 135, 17280, 4320, 4320, 4320, 135, 135, 4320, 135, 17280, 135, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 17280, 135, 17280, 17280, 17280, 17280, 135, 4320, 4320, 4320, 17280, 4320, 135, 4320, 135, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 135, 135, 17280, 4320, 4320, 135, 135, 135, 4320, 135, 4320, 135, 17280, 135, 4320, 17280, 135, 17280, 4320, 135, 17280, 17280, 17280, 17280, 4320, 135, 4320, 17280, 17280, 4320, 135, 135, 17280, 4320, 4320, 135, 135, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 135, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 17280, 135, 135, 135, 4320, 4320, 17280, 135, 135, 17280, 135, 17280, 4320, 135, 17280, 4320, 4320, 135, 17280, 17280, 17280, 135, 4320, 17280, 135, 17280, 4320, 4320, 17280, 17280, 135, 4320, 17280, 135, 4320, 4320, 135, 4320, 135, 4320, 17280, 17280, 4320, 135, 17280, 135, 17280, 4320, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 17280, 135, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 135, 135, 135, 135, 135, 4320, 135, 135, 4320, 17280, 17280, 135, 135, 17280, 135, 135, 135, 4320, 135, 4320, 17280, 17280, 4320, 4320, 135, 17280, 4320, 17280, 135, 4320, 4320, 135, 135, 4320, 135, 17280, 17280, 135, 17280, 17280, 135, 4320, 17280, 135, 135, 4320, 4320, 135, 135, 17280, 17280, 17280, 17280, 4320, 135, 4320, 4320, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 17280, 4320, 4320, 4320, 17280, 135, 4320, 4320, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 4320, 135, 17280, 17280, 17280, 4320, 135, 17280, 17280, 4320, 4320, 17280, 17280, 135, 17280, 17280, 4320, 135, 17280, 4320, 4320, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 4320, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 17280, 135, 135, 135, 4320, 135, 4320, 4320, 135, 17280, 4320, 17280, 135, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 17280, 17280, 135, 17280, 17280, 135, 17280, 4320, 17280, 4320, 4320, 4320, 135, 4320, 135, 135, 17280, 135, 4320, 135, 135, 4320, 17280, 4320, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2782080 . Total input tokens: 619810953 . Total output tokens: 556306045
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 47.873316530138254,
    "estimated_duration": 3600.1936264975166,
    "input_throughput": 5288.9896976248465,
    "output_throughput": 4692.067358730894,
    "total_throughput": 9981.05705635574,
    "itl": 183.69711781065058,
    "ttft": 2112949.5925515257,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 524,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6036955778207826,
    "arrivals": 926257,
    "finished_requests": 77146,
    "scheduler_time": 136.59367293210775
}
#Debug simulation 
Total elapsed time: 47.87351109320298. Arrivals time: 0.4021101384423673 Scheduler time: 47.341568851377815 Scheduler overhead time: 0.047349617816507816 Adapter cache time: 0.016687151044607162 Engine time: 0.04754073964431882 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-16/adapters_384_slots_96_rate_1.6-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-16/adapters_384_slots_96_rate_1.6-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 4320, 135, 17280, 17280, 135, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 135, 17280, 135, 17280, 4320, 4320, 4320, 135, 135, 4320, 135, 17280, 135, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 17280, 135, 17280, 17280, 17280, 17280, 135, 4320, 4320, 4320, 17280, 4320, 135, 4320, 135, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 135, 135, 17280, 4320, 4320, 135, 135, 135, 4320, 135, 4320, 135, 17280, 135, 4320, 17280, 135, 17280, 4320, 135, 17280, 17280, 17280, 17280, 4320, 135, 4320, 17280, 17280, 4320, 135, 135, 17280, 4320, 4320, 135, 135, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 135, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 17280, 135, 135, 135, 4320, 4320, 17280, 135, 135, 17280, 135, 17280, 4320, 135, 17280, 4320, 4320, 135, 17280, 17280, 17280, 135, 4320, 17280, 135, 17280, 4320, 4320, 17280, 17280, 135, 4320, 17280, 135, 4320, 4320, 135, 4320, 135, 4320, 17280, 17280, 4320, 135, 17280, 135, 17280, 4320, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 17280, 135, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 135, 135, 135, 135, 135, 4320, 135, 135, 4320, 17280, 17280, 135, 135, 17280, 135, 135, 135, 4320, 135, 4320, 17280, 17280, 4320, 4320, 135, 17280, 4320, 17280, 135, 4320, 4320, 135, 135, 4320, 135, 17280, 17280, 135, 17280, 17280, 135, 4320, 17280, 135, 135, 4320, 4320, 135, 135, 17280, 17280, 17280, 17280, 4320, 135, 4320, 4320, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 17280, 4320, 4320, 4320, 17280, 135, 4320, 4320, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 4320, 135, 17280, 17280, 17280, 4320, 135, 17280, 17280, 4320, 4320, 17280, 17280, 135, 17280, 17280, 4320, 135, 17280, 4320, 4320, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 4320, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 17280, 135, 135, 135, 4320, 135, 4320, 4320, 135, 17280, 4320, 17280, 135, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 17280, 17280, 135, 17280, 17280, 135, 17280, 4320, 17280, 4320, 4320, 4320, 135, 4320, 135, 135, 17280, 135, 4320, 135, 135, 4320, 17280, 4320, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2782080 . Total input tokens: 619810953 . Total output tokens: 556306045
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 47.99662273004651,
    "estimated_duration": 3600.0932829324215,
    "input_throughput": 5288.785179613749,
    "output_throughput": 4691.955089075139,
    "total_throughput": 9980.740268688889,
    "itl": 183.70153298334466,
    "ttft": 2112994.8805606305,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 524,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7093861206644272,
    "arrivals": 926257,
    "finished_requests": 77140,
    "scheduler_time": 136.58640021408058
}
#Debug simulation 
Total elapsed time: 47.99681159527972. Arrivals time: 0.4025595742277801 Scheduler time: 47.46172810252756 Scheduler overhead time: 0.048823566641658545 Adapter cache time: 0.017309081740677357 Engine time: 0.04817003104835749 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-32/adapters_384_slots_96_rate_1.6-0.4-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-32/adapters_384_slots_96_rate_1.6-0.4-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 4320, 135, 17280, 17280, 135, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 135, 17280, 135, 17280, 4320, 4320, 4320, 135, 135, 4320, 135, 17280, 135, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 17280, 135, 17280, 17280, 17280, 17280, 135, 4320, 4320, 4320, 17280, 4320, 135, 4320, 135, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 135, 135, 17280, 4320, 4320, 135, 135, 135, 4320, 135, 4320, 135, 17280, 135, 4320, 17280, 135, 17280, 4320, 135, 17280, 17280, 17280, 17280, 4320, 135, 4320, 17280, 17280, 4320, 135, 135, 17280, 4320, 4320, 135, 135, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 135, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 17280, 135, 135, 135, 4320, 4320, 17280, 135, 135, 17280, 135, 17280, 4320, 135, 17280, 4320, 4320, 135, 17280, 17280, 17280, 135, 4320, 17280, 135, 17280, 4320, 4320, 17280, 17280, 135, 4320, 17280, 135, 4320, 4320, 135, 4320, 135, 4320, 17280, 17280, 4320, 135, 17280, 135, 17280, 4320, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 17280, 135, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 135, 135, 135, 135, 135, 4320, 135, 135, 4320, 17280, 17280, 135, 135, 17280, 135, 135, 135, 4320, 135, 4320, 17280, 17280, 4320, 4320, 135, 17280, 4320, 17280, 135, 4320, 4320, 135, 135, 4320, 135, 17280, 17280, 135, 17280, 17280, 135, 4320, 17280, 135, 135, 4320, 4320, 135, 135, 17280, 17280, 17280, 17280, 4320, 135, 4320, 4320, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 17280, 4320, 4320, 4320, 17280, 135, 4320, 4320, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 4320, 135, 17280, 17280, 17280, 4320, 135, 17280, 17280, 4320, 4320, 17280, 17280, 135, 17280, 17280, 4320, 135, 17280, 4320, 4320, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 4320, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 17280, 135, 135, 135, 4320, 135, 4320, 4320, 135, 17280, 4320, 17280, 135, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 17280, 17280, 135, 17280, 17280, 135, 17280, 4320, 17280, 4320, 4320, 4320, 135, 4320, 135, 135, 17280, 135, 4320, 135, 135, 4320, 17280, 4320, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2782080 . Total input tokens: 619810953 . Total output tokens: 556306045
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 66.60651326784864,
    "estimated_duration": 3600.1042770645627,
    "input_throughput": 5262.836446351139,
    "output_throughput": 4669.572519634692,
    "total_throughput": 9932.408965985831,
    "itl": 180.50660974039744,
    "ttft": 2120654.538611729,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 574,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8761456095986184,
    "arrivals": 926257,
    "finished_requests": 76712,
    "scheduler_time": 137.73163301794034
}
#Debug simulation 
Total elapsed time: 66.60669512487948. Arrivals time: 0.49004142777994275 Scheduler time: 65.97718441253528 Scheduler overhead time: 0.05186036229133606 Adapter cache time: 0.018097869120538235 Engine time: 0.050342322792857885 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-16/adapters_384_slots_96_rate_1.6-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-16/adapters_384_slots_96_rate_1.6-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 4320, 135, 17280, 17280, 135, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 135, 17280, 135, 17280, 4320, 4320, 4320, 135, 135, 4320, 135, 17280, 135, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 17280, 135, 17280, 17280, 17280, 17280, 135, 4320, 4320, 4320, 17280, 4320, 135, 4320, 135, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 135, 135, 17280, 4320, 4320, 135, 135, 135, 4320, 135, 4320, 135, 17280, 135, 4320, 17280, 135, 17280, 4320, 135, 17280, 17280, 17280, 17280, 4320, 135, 4320, 17280, 17280, 4320, 135, 135, 17280, 4320, 4320, 135, 135, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 135, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 17280, 135, 135, 135, 4320, 4320, 17280, 135, 135, 17280, 135, 17280, 4320, 135, 17280, 4320, 4320, 135, 17280, 17280, 17280, 135, 4320, 17280, 135, 17280, 4320, 4320, 17280, 17280, 135, 4320, 17280, 135, 4320, 4320, 135, 4320, 135, 4320, 17280, 17280, 4320, 135, 17280, 135, 17280, 4320, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 17280, 135, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 135, 135, 135, 135, 135, 4320, 135, 135, 4320, 17280, 17280, 135, 135, 17280, 135, 135, 135, 4320, 135, 4320, 17280, 17280, 4320, 4320, 135, 17280, 4320, 17280, 135, 4320, 4320, 135, 135, 4320, 135, 17280, 17280, 135, 17280, 17280, 135, 4320, 17280, 135, 135, 4320, 4320, 135, 135, 17280, 17280, 17280, 17280, 4320, 135, 4320, 4320, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 17280, 4320, 4320, 4320, 17280, 135, 4320, 4320, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 4320, 135, 17280, 17280, 17280, 4320, 135, 17280, 17280, 4320, 4320, 17280, 17280, 135, 17280, 17280, 4320, 135, 17280, 4320, 4320, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 4320, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 17280, 135, 135, 135, 4320, 135, 4320, 4320, 135, 17280, 4320, 17280, 135, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 17280, 17280, 135, 17280, 17280, 135, 17280, 4320, 17280, 4320, 4320, 4320, 135, 4320, 135, 135, 17280, 135, 4320, 135, 135, 4320, 17280, 4320, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2782080 . Total input tokens: 619810953 . Total output tokens: 556306045
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 48.06027769483626,
    "estimated_duration": 3600.020976261732,
    "input_throughput": 5288.891405230448,
    "output_throughput": 4692.0493273181255,
    "total_throughput": 9980.940732548574,
    "itl": 183.69838927740406,
    "ttft": 2112959.653834706,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 524,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6374733446189125,
    "arrivals": 926257,
    "finished_requests": 77140,
    "scheduler_time": 136.58600631942042
}
#Debug simulation 
Total elapsed time: 48.060447164811194. Arrivals time: 0.38691843720152974 Scheduler time: 47.54160738084465 Scheduler overhead time: 0.048865452874451876 Adapter cache time: 0.017162814736366272 Engine time: 0.047734083607792854 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-32/adapters_384_slots_96_rate_1.6-0.4-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-32/adapters_384_slots_96_rate_1.6-0.4-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 4320, 135, 17280, 17280, 135, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 135, 17280, 135, 17280, 4320, 4320, 4320, 135, 135, 4320, 135, 17280, 135, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 17280, 135, 17280, 17280, 17280, 17280, 135, 4320, 4320, 4320, 17280, 4320, 135, 4320, 135, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 135, 135, 17280, 4320, 4320, 135, 135, 135, 4320, 135, 4320, 135, 17280, 135, 4320, 17280, 135, 17280, 4320, 135, 17280, 17280, 17280, 17280, 4320, 135, 4320, 17280, 17280, 4320, 135, 135, 17280, 4320, 4320, 135, 135, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 135, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 17280, 135, 135, 135, 4320, 4320, 17280, 135, 135, 17280, 135, 17280, 4320, 135, 17280, 4320, 4320, 135, 17280, 17280, 17280, 135, 4320, 17280, 135, 17280, 4320, 4320, 17280, 17280, 135, 4320, 17280, 135, 4320, 4320, 135, 4320, 135, 4320, 17280, 17280, 4320, 135, 17280, 135, 17280, 4320, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 17280, 135, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 135, 135, 135, 135, 135, 4320, 135, 135, 4320, 17280, 17280, 135, 135, 17280, 135, 135, 135, 4320, 135, 4320, 17280, 17280, 4320, 4320, 135, 17280, 4320, 17280, 135, 4320, 4320, 135, 135, 4320, 135, 17280, 17280, 135, 17280, 17280, 135, 4320, 17280, 135, 135, 4320, 4320, 135, 135, 17280, 17280, 17280, 17280, 4320, 135, 4320, 4320, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 17280, 4320, 4320, 4320, 17280, 135, 4320, 4320, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 4320, 135, 17280, 17280, 17280, 4320, 135, 17280, 17280, 4320, 4320, 17280, 17280, 135, 17280, 17280, 4320, 135, 17280, 4320, 4320, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 4320, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 17280, 135, 135, 135, 4320, 135, 4320, 4320, 135, 17280, 4320, 17280, 135, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 17280, 17280, 135, 17280, 17280, 135, 17280, 4320, 17280, 4320, 4320, 4320, 135, 4320, 135, 135, 17280, 135, 4320, 135, 135, 4320, 17280, 4320, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2782080 . Total input tokens: 619810953 . Total output tokens: 556306045
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 66.55155219091102,
    "estimated_duration": 3600.1292986954977,
    "input_throughput": 5262.799868567314,
    "output_throughput": 4669.540065155834,
    "total_throughput": 9932.339933723148,
    "itl": 180.5076795120264,
    "ttft": 2120661.6569868936,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 574,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9010448593087528,
    "arrivals": 926257,
    "finished_requests": 76712,
    "scheduler_time": 137.73175539920115
}
#Debug simulation 
Total elapsed time: 66.55173545284197. Arrivals time: 0.42079443810507655 Scheduler time: 65.99119405634701 Scheduler overhead time: 0.05191456247121096 Adapter cache time: 0.01804867247119546 Engine time: 0.05082028452306986 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-16/adapters_384_slots_96_rate_1.6-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-16/adapters_384_slots_96_rate_1.6-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 4320, 135, 17280, 17280, 135, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 135, 17280, 135, 17280, 4320, 4320, 4320, 135, 135, 4320, 135, 17280, 135, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 17280, 135, 17280, 17280, 17280, 17280, 135, 4320, 4320, 4320, 17280, 4320, 135, 4320, 135, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 135, 135, 17280, 4320, 4320, 135, 135, 135, 4320, 135, 4320, 135, 17280, 135, 4320, 17280, 135, 17280, 4320, 135, 17280, 17280, 17280, 17280, 4320, 135, 4320, 17280, 17280, 4320, 135, 135, 17280, 4320, 4320, 135, 135, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 135, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 17280, 135, 135, 135, 4320, 4320, 17280, 135, 135, 17280, 135, 17280, 4320, 135, 17280, 4320, 4320, 135, 17280, 17280, 17280, 135, 4320, 17280, 135, 17280, 4320, 4320, 17280, 17280, 135, 4320, 17280, 135, 4320, 4320, 135, 4320, 135, 4320, 17280, 17280, 4320, 135, 17280, 135, 17280, 4320, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 17280, 135, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 135, 135, 135, 135, 135, 4320, 135, 135, 4320, 17280, 17280, 135, 135, 17280, 135, 135, 135, 4320, 135, 4320, 17280, 17280, 4320, 4320, 135, 17280, 4320, 17280, 135, 4320, 4320, 135, 135, 4320, 135, 17280, 17280, 135, 17280, 17280, 135, 4320, 17280, 135, 135, 4320, 4320, 135, 135, 17280, 17280, 17280, 17280, 4320, 135, 4320, 4320, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 17280, 4320, 4320, 4320, 17280, 135, 4320, 4320, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 4320, 135, 17280, 17280, 17280, 4320, 135, 17280, 17280, 4320, 4320, 17280, 17280, 135, 17280, 17280, 4320, 135, 17280, 4320, 4320, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 4320, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 17280, 135, 135, 135, 4320, 135, 4320, 4320, 135, 17280, 4320, 17280, 135, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 17280, 17280, 135, 17280, 17280, 135, 17280, 4320, 17280, 4320, 4320, 4320, 135, 4320, 135, 135, 17280, 135, 4320, 135, 135, 4320, 17280, 4320, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2782080 . Total input tokens: 619810953 . Total output tokens: 556306045
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 48.47786823939532,
    "estimated_duration": 3600.1565186450093,
    "input_throughput": 5289.044212768451,
    "output_throughput": 4692.115721223635,
    "total_throughput": 9981.159933992087,
    "itl": 183.6955182863693,
    "ttft": 2112931.406543526,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 524,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5667863545287213,
    "arrivals": 926257,
    "finished_requests": 77146,
    "scheduler_time": 136.59347430283626
}
#Debug simulation 
Total elapsed time: 48.47806278243661. Arrivals time: 0.3978161825798452 Scheduler time: 47.949005441274494 Scheduler overhead time: 0.048955424688756466 Adapter cache time: 0.016658222302794456 Engine time: 0.04749803617596626 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-32/adapters_384_slots_96_rate_1.6-0.4-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-32/adapters_384_slots_96_rate_1.6-0.4-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 4320, 135, 17280, 17280, 135, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 135, 17280, 135, 17280, 4320, 4320, 4320, 135, 135, 4320, 135, 17280, 135, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 17280, 135, 17280, 17280, 17280, 17280, 135, 4320, 4320, 4320, 17280, 4320, 135, 4320, 135, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 135, 135, 17280, 4320, 4320, 135, 135, 135, 4320, 135, 4320, 135, 17280, 135, 4320, 17280, 135, 17280, 4320, 135, 17280, 17280, 17280, 17280, 4320, 135, 4320, 17280, 17280, 4320, 135, 135, 17280, 4320, 4320, 135, 135, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 135, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 17280, 135, 135, 135, 4320, 4320, 17280, 135, 135, 17280, 135, 17280, 4320, 135, 17280, 4320, 4320, 135, 17280, 17280, 17280, 135, 4320, 17280, 135, 17280, 4320, 4320, 17280, 17280, 135, 4320, 17280, 135, 4320, 4320, 135, 4320, 135, 4320, 17280, 17280, 4320, 135, 17280, 135, 17280, 4320, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 17280, 135, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 135, 135, 135, 135, 135, 4320, 135, 135, 4320, 17280, 17280, 135, 135, 17280, 135, 135, 135, 4320, 135, 4320, 17280, 17280, 4320, 4320, 135, 17280, 4320, 17280, 135, 4320, 4320, 135, 135, 4320, 135, 17280, 17280, 135, 17280, 17280, 135, 4320, 17280, 135, 135, 4320, 4320, 135, 135, 17280, 17280, 17280, 17280, 4320, 135, 4320, 4320, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 17280, 4320, 4320, 4320, 17280, 135, 4320, 4320, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 4320, 135, 17280, 17280, 17280, 4320, 135, 17280, 17280, 4320, 4320, 17280, 17280, 135, 17280, 17280, 4320, 135, 17280, 4320, 4320, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 4320, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 17280, 135, 135, 135, 4320, 135, 4320, 4320, 135, 17280, 4320, 17280, 135, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 17280, 17280, 135, 17280, 17280, 135, 17280, 4320, 17280, 4320, 4320, 4320, 135, 4320, 135, 135, 17280, 135, 4320, 135, 135, 4320, 17280, 4320, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2782080 . Total input tokens: 619810953 . Total output tokens: 556306045
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 67.05841934122145,
    "estimated_duration": 3600.152698662376,
    "input_throughput": 5262.765661867509,
    "output_throughput": 4669.509714475736,
    "total_throughput": 9932.275376343245,
    "itl": 180.50863221311366,
    "ttft": 2120668.9426969867,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 574,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9243093097954949,
    "arrivals": 926257,
    "finished_requests": 76712,
    "scheduler_time": 137.73189091562347
}
#Debug simulation 
Total elapsed time: 67.05860238708556. Arrivals time: 0.48141276417300105 Scheduler time: 66.43843813892454 Scheduler overhead time: 0.05120491283014417 Adapter cache time: 0.017863243352621794 Engine time: 0.05060106888413429 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-8/adapters_384_slots_96_rate_1.6-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-8/adapters_384_slots_96_rate_1.6-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 4320, 66, 17280, 17280, 66, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 66, 17280, 66, 17280, 4320, 4320, 4320, 66, 66, 4320, 66, 17280, 66, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 17280, 66, 17280, 17280, 17280, 17280, 66, 4320, 4320, 4320, 17280, 4320, 66, 4320, 66, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 66, 66, 17280, 4320, 4320, 66, 66, 66, 4320, 66, 4320, 66, 17280, 66, 4320, 17280, 66, 17280, 4320, 66, 17280, 17280, 17280, 17280, 4320, 66, 4320, 17280, 17280, 4320, 66, 66, 17280, 4320, 4320, 66, 66, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 66, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 17280, 66, 66, 66, 4320, 4320, 17280, 66, 66, 17280, 66, 17280, 4320, 66, 17280, 4320, 4320, 66, 17280, 17280, 17280, 66, 4320, 17280, 66, 17280, 4320, 4320, 17280, 17280, 66, 4320, 17280, 66, 4320, 4320, 66, 4320, 66, 4320, 17280, 17280, 4320, 66, 17280, 66, 17280, 4320, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 17280, 66, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 66, 66, 66, 66, 66, 4320, 66, 66, 4320, 17280, 17280, 66, 66, 17280, 66, 66, 66, 4320, 66, 4320, 17280, 17280, 4320, 4320, 66, 17280, 4320, 17280, 66, 4320, 4320, 66, 66, 4320, 66, 17280, 17280, 66, 17280, 17280, 66, 4320, 17280, 66, 66, 4320, 4320, 66, 66, 17280, 17280, 17280, 17280, 4320, 66, 4320, 4320, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 17280, 4320, 4320, 4320, 17280, 66, 4320, 4320, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 4320, 66, 17280, 17280, 17280, 4320, 66, 17280, 17280, 4320, 4320, 17280, 17280, 66, 17280, 17280, 4320, 66, 17280, 4320, 4320, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 4320, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 17280, 66, 66, 66, 4320, 66, 4320, 4320, 66, 17280, 4320, 17280, 66, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 17280, 17280, 66, 17280, 17280, 66, 17280, 4320, 17280, 4320, 4320, 4320, 66, 4320, 66, 66, 17280, 66, 4320, 66, 66, 4320, 17280, 4320, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2773248 . Total input tokens: 617853364 . Total output tokens: 554535687
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 48.21083860564977,
    "estimated_duration": 3600.0794644579746,
    "input_throughput": 5334.492527067435,
    "output_throughput": 4684.213269869853,
    "total_throughput": 10018.705796937289,
    "itl": 182.32353516101037,
    "ttft": 2115769.5148468646,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 500,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.530243871966394,
    "arrivals": 923309,
    "finished_requests": 77627,
    "scheduler_time": 137.0094326314155
}
#Debug simulation 
Total elapsed time: 48.21102335397154. Arrivals time: 0.46064791921526194 Scheduler time: 47.621276467107236 Scheduler overhead time: 0.048154180869460106 Adapter cache time: 0.015655404422432184 Engine time: 0.047094376757740974 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-16/adapters_384_slots_96_rate_1.6-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-16/adapters_384_slots_96_rate_1.6-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 4320, 66, 17280, 17280, 66, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 66, 17280, 66, 17280, 4320, 4320, 4320, 66, 66, 4320, 66, 17280, 66, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 17280, 66, 17280, 17280, 17280, 17280, 66, 4320, 4320, 4320, 17280, 4320, 66, 4320, 66, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 66, 66, 17280, 4320, 4320, 66, 66, 66, 4320, 66, 4320, 66, 17280, 66, 4320, 17280, 66, 17280, 4320, 66, 17280, 17280, 17280, 17280, 4320, 66, 4320, 17280, 17280, 4320, 66, 66, 17280, 4320, 4320, 66, 66, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 66, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 17280, 66, 66, 66, 4320, 4320, 17280, 66, 66, 17280, 66, 17280, 4320, 66, 17280, 4320, 4320, 66, 17280, 17280, 17280, 66, 4320, 17280, 66, 17280, 4320, 4320, 17280, 17280, 66, 4320, 17280, 66, 4320, 4320, 66, 4320, 66, 4320, 17280, 17280, 4320, 66, 17280, 66, 17280, 4320, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 17280, 66, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 66, 66, 66, 66, 66, 4320, 66, 66, 4320, 17280, 17280, 66, 66, 17280, 66, 66, 66, 4320, 66, 4320, 17280, 17280, 4320, 4320, 66, 17280, 4320, 17280, 66, 4320, 4320, 66, 66, 4320, 66, 17280, 17280, 66, 17280, 17280, 66, 4320, 17280, 66, 66, 4320, 4320, 66, 66, 17280, 17280, 17280, 17280, 4320, 66, 4320, 4320, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 17280, 4320, 4320, 4320, 17280, 66, 4320, 4320, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 4320, 66, 17280, 17280, 17280, 4320, 66, 17280, 17280, 4320, 4320, 17280, 17280, 66, 17280, 17280, 4320, 66, 17280, 4320, 4320, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 4320, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 17280, 66, 66, 66, 4320, 66, 4320, 4320, 66, 17280, 4320, 17280, 66, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 17280, 17280, 66, 17280, 17280, 66, 17280, 4320, 17280, 4320, 4320, 4320, 66, 4320, 66, 66, 17280, 66, 4320, 66, 66, 4320, 17280, 4320, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2773248 . Total input tokens: 617853364 . Total output tokens: 554535687
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 48.00206553703174,
    "estimated_duration": 3600.1854647273967,
    "input_throughput": 5334.335463590945,
    "output_throughput": 4684.07535256712,
    "total_throughput": 10018.410816158064,
    "itl": 182.3281348199166,
    "ttft": 2115820.302579035,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 500,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6355819369945743,
    "arrivals": 923309,
    "finished_requests": 77627,
    "scheduler_time": 137.01009483577707
}
#Debug simulation 
Total elapsed time: 48.00224932190031. Arrivals time: 0.4133804524317384 Scheduler time: 47.458911614026874 Scheduler overhead time: 0.0485921218059957 Adapter cache time: 0.015630335547029972 Engine time: 0.0474576773121953 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-32/adapters_384_slots_96_rate_1.6-0.4-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-32/adapters_384_slots_96_rate_1.6-0.4-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 4320, 66, 17280, 17280, 66, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 66, 17280, 66, 17280, 4320, 4320, 4320, 66, 66, 4320, 66, 17280, 66, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 17280, 66, 17280, 17280, 17280, 17280, 66, 4320, 4320, 4320, 17280, 4320, 66, 4320, 66, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 66, 66, 17280, 4320, 4320, 66, 66, 66, 4320, 66, 4320, 66, 17280, 66, 4320, 17280, 66, 17280, 4320, 66, 17280, 17280, 17280, 17280, 4320, 66, 4320, 17280, 17280, 4320, 66, 66, 17280, 4320, 4320, 66, 66, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 66, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 17280, 66, 66, 66, 4320, 4320, 17280, 66, 66, 17280, 66, 17280, 4320, 66, 17280, 4320, 4320, 66, 17280, 17280, 17280, 66, 4320, 17280, 66, 17280, 4320, 4320, 17280, 17280, 66, 4320, 17280, 66, 4320, 4320, 66, 4320, 66, 4320, 17280, 17280, 4320, 66, 17280, 66, 17280, 4320, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 17280, 66, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 66, 66, 66, 66, 66, 4320, 66, 66, 4320, 17280, 17280, 66, 66, 17280, 66, 66, 66, 4320, 66, 4320, 17280, 17280, 4320, 4320, 66, 17280, 4320, 17280, 66, 4320, 4320, 66, 66, 4320, 66, 17280, 17280, 66, 17280, 17280, 66, 4320, 17280, 66, 66, 4320, 4320, 66, 66, 17280, 17280, 17280, 17280, 4320, 66, 4320, 4320, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 17280, 4320, 4320, 4320, 17280, 66, 4320, 4320, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 4320, 66, 17280, 17280, 17280, 4320, 66, 17280, 17280, 4320, 4320, 17280, 17280, 66, 17280, 17280, 4320, 66, 17280, 4320, 4320, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 4320, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 17280, 66, 66, 66, 4320, 66, 4320, 4320, 66, 17280, 4320, 17280, 66, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 17280, 17280, 66, 17280, 17280, 66, 17280, 4320, 17280, 4320, 4320, 4320, 66, 4320, 66, 66, 17280, 66, 4320, 66, 66, 4320, 17280, 4320, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2773248 . Total input tokens: 617853364 . Total output tokens: 554535687
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 77.72100576432422,
    "estimated_duration": 3600.073835131144,
    "input_throughput": 5349.058069887754,
    "output_throughput": 4704.597676503771,
    "total_throughput": 10053.655746391525,
    "itl": 178.70562932108825,
    "ttft": 2122088.526960052,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 529,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.727383599095057,
    "arrivals": 923309,
    "finished_requests": 77927,
    "scheduler_time": 138.76867506939072
}
#Debug simulation 
Total elapsed time: 77.72117672115564. Arrivals time: 0.4297717036679387 Scheduler time: 77.15050792507827 Scheduler overhead time: 0.05275605246424675 Adapter cache time: 0.017331937327980995 Engine time: 0.05146542517468333 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-16/adapters_384_slots_96_rate_1.6-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-16/adapters_384_slots_96_rate_1.6-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 4320, 66, 17280, 17280, 66, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 66, 17280, 66, 17280, 4320, 4320, 4320, 66, 66, 4320, 66, 17280, 66, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 17280, 66, 17280, 17280, 17280, 17280, 66, 4320, 4320, 4320, 17280, 4320, 66, 4320, 66, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 66, 66, 17280, 4320, 4320, 66, 66, 66, 4320, 66, 4320, 66, 17280, 66, 4320, 17280, 66, 17280, 4320, 66, 17280, 17280, 17280, 17280, 4320, 66, 4320, 17280, 17280, 4320, 66, 66, 17280, 4320, 4320, 66, 66, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 66, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 17280, 66, 66, 66, 4320, 4320, 17280, 66, 66, 17280, 66, 17280, 4320, 66, 17280, 4320, 4320, 66, 17280, 17280, 17280, 66, 4320, 17280, 66, 17280, 4320, 4320, 17280, 17280, 66, 4320, 17280, 66, 4320, 4320, 66, 4320, 66, 4320, 17280, 17280, 4320, 66, 17280, 66, 17280, 4320, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 17280, 66, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 66, 66, 66, 66, 66, 4320, 66, 66, 4320, 17280, 17280, 66, 66, 17280, 66, 66, 66, 4320, 66, 4320, 17280, 17280, 4320, 4320, 66, 17280, 4320, 17280, 66, 4320, 4320, 66, 66, 4320, 66, 17280, 17280, 66, 17280, 17280, 66, 4320, 17280, 66, 66, 4320, 4320, 66, 66, 17280, 17280, 17280, 17280, 4320, 66, 4320, 4320, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 17280, 4320, 4320, 4320, 17280, 66, 4320, 4320, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 4320, 66, 17280, 17280, 17280, 4320, 66, 17280, 17280, 4320, 4320, 17280, 17280, 66, 17280, 17280, 4320, 66, 17280, 4320, 4320, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 4320, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 17280, 66, 66, 66, 4320, 66, 4320, 4320, 66, 17280, 4320, 17280, 66, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 17280, 17280, 66, 17280, 17280, 66, 17280, 4320, 17280, 4320, 4320, 4320, 66, 4320, 66, 66, 17280, 66, 4320, 66, 66, 4320, 17280, 4320, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2773248 . Total input tokens: 617853364 . Total output tokens: 554535687
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 47.74363103322685,
    "estimated_duration": 3600.1163859721073,
    "input_throughput": 5334.437818408016,
    "output_throughput": 4684.1652302433795,
    "total_throughput": 10018.603048651396,
    "itl": 182.3251392659861,
    "ttft": 2115787.142569251,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 500,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5669379234965837,
    "arrivals": 923309,
    "finished_requests": 77627,
    "scheduler_time": 137.00966009396834
}
#Debug simulation 
Total elapsed time: 47.743816915899515. Arrivals time: 0.46954964846372604 Scheduler time: 47.14639187930152 Scheduler overhead time: 0.047756390646100044 Adapter cache time: 0.01575430715456605 Engine time: 0.046336003579199314 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-32/adapters_384_slots_96_rate_1.6-0.4-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-32/adapters_384_slots_96_rate_1.6-0.4-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 4320, 66, 17280, 17280, 66, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 66, 17280, 66, 17280, 4320, 4320, 4320, 66, 66, 4320, 66, 17280, 66, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 17280, 66, 17280, 17280, 17280, 17280, 66, 4320, 4320, 4320, 17280, 4320, 66, 4320, 66, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 66, 66, 17280, 4320, 4320, 66, 66, 66, 4320, 66, 4320, 66, 17280, 66, 4320, 17280, 66, 17280, 4320, 66, 17280, 17280, 17280, 17280, 4320, 66, 4320, 17280, 17280, 4320, 66, 66, 17280, 4320, 4320, 66, 66, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 66, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 17280, 66, 66, 66, 4320, 4320, 17280, 66, 66, 17280, 66, 17280, 4320, 66, 17280, 4320, 4320, 66, 17280, 17280, 17280, 66, 4320, 17280, 66, 17280, 4320, 4320, 17280, 17280, 66, 4320, 17280, 66, 4320, 4320, 66, 4320, 66, 4320, 17280, 17280, 4320, 66, 17280, 66, 17280, 4320, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 17280, 66, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 66, 66, 66, 66, 66, 4320, 66, 66, 4320, 17280, 17280, 66, 66, 17280, 66, 66, 66, 4320, 66, 4320, 17280, 17280, 4320, 4320, 66, 17280, 4320, 17280, 66, 4320, 4320, 66, 66, 4320, 66, 17280, 17280, 66, 17280, 17280, 66, 4320, 17280, 66, 66, 4320, 4320, 66, 66, 17280, 17280, 17280, 17280, 4320, 66, 4320, 4320, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 17280, 4320, 4320, 4320, 17280, 66, 4320, 4320, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 4320, 66, 17280, 17280, 17280, 4320, 66, 17280, 17280, 4320, 4320, 17280, 17280, 66, 17280, 17280, 4320, 66, 17280, 4320, 4320, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 4320, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 17280, 66, 66, 66, 4320, 66, 4320, 4320, 66, 17280, 4320, 17280, 66, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 17280, 17280, 66, 17280, 17280, 66, 17280, 4320, 17280, 4320, 4320, 4320, 66, 4320, 66, 66, 17280, 66, 4320, 66, 66, 4320, 17280, 4320, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2773248 . Total input tokens: 617853364 . Total output tokens: 554535687
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 78.0598978549242,
    "estimated_duration": 3600.0968632829417,
    "input_throughput": 5349.023854441368,
    "output_throughput": 4704.56758337196,
    "total_throughput": 10053.591437813328,
    "itl": 178.70662089469116,
    "ttft": 2122095.6062554456,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 529,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7502707882225543,
    "arrivals": 923309,
    "finished_requests": 77927,
    "scheduler_time": 138.76881603209952
}
#Debug simulation 
Total elapsed time: 78.06007487885654. Arrivals time: 0.4422494978643954 Scheduler time: 77.47667445009574 Scheduler overhead time: 0.05314452340826392 Adapter cache time: 0.017415526323020458 Engine time: 0.05149838142096996 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-16/adapters_384_slots_96_rate_1.6-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-16/adapters_384_slots_96_rate_1.6-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 4320, 66, 17280, 17280, 66, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 66, 17280, 66, 17280, 4320, 4320, 4320, 66, 66, 4320, 66, 17280, 66, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 17280, 66, 17280, 17280, 17280, 17280, 66, 4320, 4320, 4320, 17280, 4320, 66, 4320, 66, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 66, 66, 17280, 4320, 4320, 66, 66, 66, 4320, 66, 4320, 66, 17280, 66, 4320, 17280, 66, 17280, 4320, 66, 17280, 17280, 17280, 17280, 4320, 66, 4320, 17280, 17280, 4320, 66, 66, 17280, 4320, 4320, 66, 66, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 66, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 17280, 66, 66, 66, 4320, 4320, 17280, 66, 66, 17280, 66, 17280, 4320, 66, 17280, 4320, 4320, 66, 17280, 17280, 17280, 66, 4320, 17280, 66, 17280, 4320, 4320, 17280, 17280, 66, 4320, 17280, 66, 4320, 4320, 66, 4320, 66, 4320, 17280, 17280, 4320, 66, 17280, 66, 17280, 4320, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 17280, 66, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 66, 66, 66, 66, 66, 4320, 66, 66, 4320, 17280, 17280, 66, 66, 17280, 66, 66, 66, 4320, 66, 4320, 17280, 17280, 4320, 4320, 66, 17280, 4320, 17280, 66, 4320, 4320, 66, 66, 4320, 66, 17280, 17280, 66, 17280, 17280, 66, 4320, 17280, 66, 66, 4320, 4320, 66, 66, 17280, 17280, 17280, 17280, 4320, 66, 4320, 4320, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 17280, 4320, 4320, 4320, 17280, 66, 4320, 4320, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 4320, 66, 17280, 17280, 17280, 4320, 66, 17280, 17280, 4320, 4320, 17280, 17280, 66, 17280, 17280, 4320, 66, 17280, 4320, 4320, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 4320, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 17280, 66, 66, 66, 4320, 66, 4320, 4320, 66, 17280, 4320, 17280, 66, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 17280, 17280, 66, 17280, 17280, 66, 17280, 4320, 17280, 4320, 4320, 4320, 66, 4320, 66, 66, 17280, 66, 4320, 66, 66, 4320, 17280, 4320, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2773248 . Total input tokens: 617853364 . Total output tokens: 554535687
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 48.02265255199745,
    "estimated_duration": 3600.0440315663204,
    "input_throughput": 5334.54503100741,
    "output_throughput": 4684.259373534092,
    "total_throughput": 10018.804404541503,
    "itl": 182.3220182873598,
    "ttft": 2115752.477225528,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 500,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4950251474510716,
    "arrivals": 923309,
    "finished_requests": 77627,
    "scheduler_time": 137.00921846420908
}
#Debug simulation 
Total elapsed time: 48.02284072898328. Arrivals time: 0.4769516298547387 Scheduler time: 47.41639841301367 Scheduler overhead time: 0.04815684398636222 Adapter cache time: 0.01580979349091649 Engine time: 0.04727375088259578 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-32/adapters_384_slots_96_rate_1.6-0.4-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-32/adapters_384_slots_96_rate_1.6-0.4-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 4320, 66, 17280, 17280, 66, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 66, 17280, 66, 17280, 4320, 4320, 4320, 66, 66, 4320, 66, 17280, 66, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 17280, 66, 17280, 17280, 17280, 17280, 66, 4320, 4320, 4320, 17280, 4320, 66, 4320, 66, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 66, 66, 17280, 4320, 4320, 66, 66, 66, 4320, 66, 4320, 66, 17280, 66, 4320, 17280, 66, 17280, 4320, 66, 17280, 17280, 17280, 17280, 4320, 66, 4320, 17280, 17280, 4320, 66, 66, 17280, 4320, 4320, 66, 66, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 66, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 17280, 66, 66, 66, 4320, 4320, 17280, 66, 66, 17280, 66, 17280, 4320, 66, 17280, 4320, 4320, 66, 17280, 17280, 17280, 66, 4320, 17280, 66, 17280, 4320, 4320, 17280, 17280, 66, 4320, 17280, 66, 4320, 4320, 66, 4320, 66, 4320, 17280, 17280, 4320, 66, 17280, 66, 17280, 4320, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 17280, 66, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 66, 66, 66, 66, 66, 4320, 66, 66, 4320, 17280, 17280, 66, 66, 17280, 66, 66, 66, 4320, 66, 4320, 17280, 17280, 4320, 4320, 66, 17280, 4320, 17280, 66, 4320, 4320, 66, 66, 4320, 66, 17280, 17280, 66, 17280, 17280, 66, 4320, 17280, 66, 66, 4320, 4320, 66, 66, 17280, 17280, 17280, 17280, 4320, 66, 4320, 4320, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 17280, 4320, 4320, 4320, 17280, 66, 4320, 4320, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 4320, 66, 17280, 17280, 17280, 4320, 66, 17280, 17280, 4320, 4320, 17280, 17280, 66, 17280, 17280, 4320, 66, 17280, 4320, 4320, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 4320, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 17280, 66, 66, 66, 4320, 66, 4320, 4320, 66, 17280, 4320, 17280, 66, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 17280, 17280, 66, 17280, 17280, 66, 17280, 4320, 17280, 4320, 4320, 4320, 66, 4320, 66, 66, 17280, 66, 4320, 66, 66, 4320, 17280, 4320, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2773248 . Total input tokens: 617853364 . Total output tokens: 554535687
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 77.78027121303603,
    "estimated_duration": 3600.117880655646,
    "input_throughput": 5348.992627011689,
    "output_throughput": 4704.540118257319,
    "total_throughput": 10053.532745269009,
    "itl": 178.7075030159412,
    "ttft": 2122103.0028782873,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 529,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7711459167674157,
    "arrivals": 923309,
    "finished_requests": 77927,
    "scheduler_time": 138.7689582762875
}
#Debug simulation 
Total elapsed time: 77.78044798085466. Arrivals time: 0.4775698664598167 Scheduler time: 77.16098663955927 Scheduler overhead time: 0.05324236722663045 Adapter cache time: 0.01720945769920945 Engine time: 0.051677831914275885 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-8/adapters_384_slots_96_rate_1.6-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-8/adapters_384_slots_96_rate_1.6-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 4320, 33, 17280, 17280, 33, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 33, 17280, 33, 17280, 4320, 4320, 4320, 33, 33, 4320, 33, 17280, 33, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 17280, 33, 17280, 17280, 17280, 17280, 33, 4320, 4320, 4320, 17280, 4320, 33, 4320, 33, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 33, 33, 17280, 4320, 4320, 33, 33, 33, 4320, 33, 4320, 33, 17280, 33, 4320, 17280, 33, 17280, 4320, 33, 17280, 17280, 17280, 17280, 4320, 33, 4320, 17280, 17280, 4320, 33, 33, 17280, 4320, 4320, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 33, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 17280, 33, 33, 33, 4320, 4320, 17280, 33, 33, 17280, 33, 17280, 4320, 33, 17280, 4320, 4320, 33, 17280, 17280, 17280, 33, 4320, 17280, 33, 17280, 4320, 4320, 17280, 17280, 33, 4320, 17280, 33, 4320, 4320, 33, 4320, 33, 4320, 17280, 17280, 4320, 33, 17280, 33, 17280, 4320, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 17280, 33, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 33, 33, 33, 33, 33, 4320, 33, 33, 4320, 17280, 17280, 33, 33, 17280, 33, 33, 33, 4320, 33, 4320, 17280, 17280, 4320, 4320, 33, 17280, 4320, 17280, 33, 4320, 4320, 33, 33, 4320, 33, 17280, 17280, 33, 17280, 17280, 33, 4320, 17280, 33, 33, 4320, 4320, 33, 33, 17280, 17280, 17280, 17280, 4320, 33, 4320, 4320, 33, 33, 33, 33, 33, 33, 33, 33, 4320, 17280, 4320, 4320, 4320, 17280, 33, 4320, 4320, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 4320, 33, 17280, 17280, 17280, 4320, 33, 17280, 17280, 4320, 4320, 17280, 17280, 33, 17280, 17280, 4320, 33, 17280, 4320, 4320, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 4320, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 17280, 33, 33, 33, 4320, 33, 4320, 4320, 33, 17280, 4320, 17280, 33, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 17280, 17280, 33, 17280, 17280, 33, 17280, 4320, 17280, 4320, 4320, 4320, 33, 4320, 33, 33, 17280, 33, 4320, 33, 33, 4320, 17280, 4320, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2769024 . Total input tokens: 616944113 . Total output tokens: 553679964
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 76.67958896281198,
    "estimated_duration": 3600.1897324604,
    "input_throughput": 5307.171127045639,
    "output_throughput": 4698.212943471875,
    "total_throughput": 10005.384070517515,
    "itl": 182.09432744104765,
    "ttft": 2117999.4062204654,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 471,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.441489727392341,
    "arrivals": 921853,
    "finished_requests": 77275,
    "scheduler_time": 137.40453820721206
}
#Debug simulation 
Total elapsed time: 76.6797673497349. Arrivals time: 0.42800272395834327 Scheduler time: 76.11293303407729 Scheduler overhead time: 0.05251735961064696 Adapter cache time: 0.015990115702152252 Engine time: 0.05152974929660559 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-16/adapters_384_slots_96_rate_1.6-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-16/adapters_384_slots_96_rate_1.6-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 4320, 33, 17280, 17280, 33, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 33, 17280, 33, 17280, 4320, 4320, 4320, 33, 33, 4320, 33, 17280, 33, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 17280, 33, 17280, 17280, 17280, 17280, 33, 4320, 4320, 4320, 17280, 4320, 33, 4320, 33, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 33, 33, 17280, 4320, 4320, 33, 33, 33, 4320, 33, 4320, 33, 17280, 33, 4320, 17280, 33, 17280, 4320, 33, 17280, 17280, 17280, 17280, 4320, 33, 4320, 17280, 17280, 4320, 33, 33, 17280, 4320, 4320, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 33, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 17280, 33, 33, 33, 4320, 4320, 17280, 33, 33, 17280, 33, 17280, 4320, 33, 17280, 4320, 4320, 33, 17280, 17280, 17280, 33, 4320, 17280, 33, 17280, 4320, 4320, 17280, 17280, 33, 4320, 17280, 33, 4320, 4320, 33, 4320, 33, 4320, 17280, 17280, 4320, 33, 17280, 33, 17280, 4320, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 17280, 33, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 33, 33, 33, 33, 33, 4320, 33, 33, 4320, 17280, 17280, 33, 33, 17280, 33, 33, 33, 4320, 33, 4320, 17280, 17280, 4320, 4320, 33, 17280, 4320, 17280, 33, 4320, 4320, 33, 33, 4320, 33, 17280, 17280, 33, 17280, 17280, 33, 4320, 17280, 33, 33, 4320, 4320, 33, 33, 17280, 17280, 17280, 17280, 4320, 33, 4320, 4320, 33, 33, 33, 33, 33, 33, 33, 33, 4320, 17280, 4320, 4320, 4320, 17280, 33, 4320, 4320, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 4320, 33, 17280, 17280, 17280, 4320, 33, 17280, 17280, 4320, 4320, 17280, 17280, 33, 17280, 17280, 4320, 33, 17280, 4320, 4320, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 4320, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 17280, 33, 33, 33, 4320, 33, 4320, 4320, 33, 17280, 4320, 17280, 33, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 17280, 17280, 33, 17280, 17280, 33, 17280, 4320, 17280, 4320, 4320, 4320, 33, 4320, 33, 33, 17280, 33, 4320, 33, 33, 4320, 17280, 4320, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2769024 . Total input tokens: 616944113 . Total output tokens: 553679964
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 78.51783116720617,
    "estimated_duration": 3600.1979107128386,
    "input_throughput": 5312.653769140413,
    "output_throughput": 4696.809569741663,
    "total_throughput": 10009.463338882075,
    "itl": 182.10893017301603,
    "ttft": 2117629.3687517378,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 462,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5080677849613184,
    "arrivals": 921853,
    "finished_requests": 77299,
    "scheduler_time": 137.34106972497054
}
#Debug simulation 
Total elapsed time: 78.51799991820008. Arrivals time: 0.43533462658524513 Scheduler time: 77.94212107453495 Scheduler overhead time: 0.0531262937001884 Adapter cache time: 0.01614962797611952 Engine time: 0.05167177552357316 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-32/adapters_384_slots_96_rate_1.6-0.4-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-32/adapters_384_slots_96_rate_1.6-0.4-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 4320, 33, 17280, 17280, 33, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 33, 17280, 33, 17280, 4320, 4320, 4320, 33, 33, 4320, 33, 17280, 33, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 17280, 33, 17280, 17280, 17280, 17280, 33, 4320, 4320, 4320, 17280, 4320, 33, 4320, 33, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 33, 33, 17280, 4320, 4320, 33, 33, 33, 4320, 33, 4320, 33, 17280, 33, 4320, 17280, 33, 17280, 4320, 33, 17280, 17280, 17280, 17280, 4320, 33, 4320, 17280, 17280, 4320, 33, 33, 17280, 4320, 4320, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 33, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 17280, 33, 33, 33, 4320, 4320, 17280, 33, 33, 17280, 33, 17280, 4320, 33, 17280, 4320, 4320, 33, 17280, 17280, 17280, 33, 4320, 17280, 33, 17280, 4320, 4320, 17280, 17280, 33, 4320, 17280, 33, 4320, 4320, 33, 4320, 33, 4320, 17280, 17280, 4320, 33, 17280, 33, 17280, 4320, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 17280, 33, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 33, 33, 33, 33, 33, 4320, 33, 33, 4320, 17280, 17280, 33, 33, 17280, 33, 33, 33, 4320, 33, 4320, 17280, 17280, 4320, 4320, 33, 17280, 4320, 17280, 33, 4320, 4320, 33, 33, 4320, 33, 17280, 17280, 33, 17280, 17280, 33, 4320, 17280, 33, 33, 4320, 4320, 33, 33, 17280, 17280, 17280, 17280, 4320, 33, 4320, 4320, 33, 33, 33, 33, 33, 33, 33, 33, 4320, 17280, 4320, 4320, 4320, 17280, 33, 4320, 4320, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 4320, 33, 17280, 17280, 17280, 4320, 33, 17280, 17280, 4320, 4320, 17280, 17280, 33, 17280, 17280, 4320, 33, 17280, 4320, 4320, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 4320, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 17280, 33, 33, 33, 4320, 33, 4320, 4320, 33, 17280, 4320, 17280, 33, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 17280, 17280, 33, 17280, 17280, 33, 17280, 4320, 17280, 4320, 4320, 4320, 33, 4320, 33, 33, 17280, 33, 4320, 33, 33, 4320, 17280, 4320, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2769024 . Total input tokens: 616944113 . Total output tokens: 553679964
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 62.40742620266974,
    "estimated_duration": 3600.155778792108,
    "input_throughput": 5292.427653336901,
    "output_throughput": 4685.332534599204,
    "total_throughput": 9977.760187936106,
    "itl": 180.3844939354458,
    "ttft": 2120808.476152729,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 598,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9535742793977382,
    "arrivals": 921853,
    "finished_requests": 76957,
    "scheduler_time": 137.79096210012472
}
#Debug simulation 
Total elapsed time: 62.4076012019068. Arrivals time: 0.47635759552940726 Scheduler time: 61.7947707218118 Scheduler overhead time: 0.05062699783593416 Adapter cache time: 0.017807224299758673 Engine time: 0.049559501465409994 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-16/adapters_384_slots_96_rate_1.6-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-16/adapters_384_slots_96_rate_1.6-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 4320, 33, 17280, 17280, 33, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 33, 17280, 33, 17280, 4320, 4320, 4320, 33, 33, 4320, 33, 17280, 33, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 17280, 33, 17280, 17280, 17280, 17280, 33, 4320, 4320, 4320, 17280, 4320, 33, 4320, 33, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 33, 33, 17280, 4320, 4320, 33, 33, 33, 4320, 33, 4320, 33, 17280, 33, 4320, 17280, 33, 17280, 4320, 33, 17280, 17280, 17280, 17280, 4320, 33, 4320, 17280, 17280, 4320, 33, 33, 17280, 4320, 4320, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 33, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 17280, 33, 33, 33, 4320, 4320, 17280, 33, 33, 17280, 33, 17280, 4320, 33, 17280, 4320, 4320, 33, 17280, 17280, 17280, 33, 4320, 17280, 33, 17280, 4320, 4320, 17280, 17280, 33, 4320, 17280, 33, 4320, 4320, 33, 4320, 33, 4320, 17280, 17280, 4320, 33, 17280, 33, 17280, 4320, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 17280, 33, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 33, 33, 33, 33, 33, 4320, 33, 33, 4320, 17280, 17280, 33, 33, 17280, 33, 33, 33, 4320, 33, 4320, 17280, 17280, 4320, 4320, 33, 17280, 4320, 17280, 33, 4320, 4320, 33, 33, 4320, 33, 17280, 17280, 33, 17280, 17280, 33, 4320, 17280, 33, 33, 4320, 4320, 33, 33, 17280, 17280, 17280, 17280, 4320, 33, 4320, 4320, 33, 33, 33, 33, 33, 33, 33, 33, 4320, 17280, 4320, 4320, 4320, 17280, 33, 4320, 4320, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 4320, 33, 17280, 17280, 17280, 4320, 33, 17280, 17280, 4320, 4320, 17280, 17280, 33, 17280, 17280, 4320, 33, 17280, 4320, 4320, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 4320, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 17280, 33, 33, 33, 4320, 33, 4320, 4320, 33, 17280, 4320, 17280, 33, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 17280, 17280, 33, 17280, 17280, 33, 17280, 4320, 17280, 4320, 4320, 4320, 33, 4320, 33, 33, 17280, 33, 4320, 33, 33, 4320, 17280, 4320, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2769024 . Total input tokens: 616944113 . Total output tokens: 553679964
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 77.15215530898422,
    "estimated_duration": 3600.0178921389233,
    "input_throughput": 5307.166956508757,
    "output_throughput": 4698.0866503280495,
    "total_throughput": 10005.253606836806,
    "itl": 182.09466953719516,
    "ttft": 2118008.7278054045,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 471,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4749147258046973,
    "arrivals": 921853,
    "finished_requests": 77271,
    "scheduler_time": 137.39687668137105
}
#Debug simulation 
Total elapsed time: 77.15233535412699. Arrivals time: 0.43874806305393577 Scheduler time: 76.57359414780512 Scheduler overhead time: 0.05300481105223298 Adapter cache time: 0.016265988815575838 Engine time: 0.05120851844549179 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-32/adapters_384_slots_96_rate_1.6-0.4-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-32/adapters_384_slots_96_rate_1.6-0.4-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 4320, 33, 17280, 17280, 33, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 33, 17280, 33, 17280, 4320, 4320, 4320, 33, 33, 4320, 33, 17280, 33, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 17280, 33, 17280, 17280, 17280, 17280, 33, 4320, 4320, 4320, 17280, 4320, 33, 4320, 33, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 33, 33, 17280, 4320, 4320, 33, 33, 33, 4320, 33, 4320, 33, 17280, 33, 4320, 17280, 33, 17280, 4320, 33, 17280, 17280, 17280, 17280, 4320, 33, 4320, 17280, 17280, 4320, 33, 33, 17280, 4320, 4320, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 33, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 17280, 33, 33, 33, 4320, 4320, 17280, 33, 33, 17280, 33, 17280, 4320, 33, 17280, 4320, 4320, 33, 17280, 17280, 17280, 33, 4320, 17280, 33, 17280, 4320, 4320, 17280, 17280, 33, 4320, 17280, 33, 4320, 4320, 33, 4320, 33, 4320, 17280, 17280, 4320, 33, 17280, 33, 17280, 4320, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 17280, 33, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 33, 33, 33, 33, 33, 4320, 33, 33, 4320, 17280, 17280, 33, 33, 17280, 33, 33, 33, 4320, 33, 4320, 17280, 17280, 4320, 4320, 33, 17280, 4320, 17280, 33, 4320, 4320, 33, 33, 4320, 33, 17280, 17280, 33, 17280, 17280, 33, 4320, 17280, 33, 33, 4320, 4320, 33, 33, 17280, 17280, 17280, 17280, 4320, 33, 4320, 4320, 33, 33, 33, 33, 33, 33, 33, 33, 4320, 17280, 4320, 4320, 4320, 17280, 33, 4320, 4320, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 4320, 33, 17280, 17280, 17280, 4320, 33, 17280, 17280, 4320, 4320, 17280, 17280, 33, 17280, 17280, 4320, 33, 17280, 4320, 4320, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 4320, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 17280, 33, 33, 33, 4320, 33, 4320, 4320, 33, 17280, 4320, 17280, 33, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 17280, 17280, 33, 17280, 17280, 33, 17280, 4320, 17280, 4320, 4320, 4320, 33, 4320, 33, 33, 17280, 33, 4320, 33, 33, 4320, 17280, 4320, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2769024 . Total input tokens: 616944113 . Total output tokens: 553679964
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 62.15227805683389,
    "estimated_duration": 3600.180824931336,
    "input_throughput": 5292.390834386325,
    "output_throughput": 4685.299939155615,
    "total_throughput": 9977.69077354194,
    "itl": 180.38557168131965,
    "ttft": 2120815.9181363005,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 598,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9784735291078723,
    "arrivals": 921853,
    "finished_requests": 76957,
    "scheduler_time": 137.79110898967468
}
#Debug simulation 
Total elapsed time: 62.152459249831736. Arrivals time: 0.42899443162605166 Scheduler time: 61.586858219932765 Scheduler overhead time: 0.05089843785390258 Adapter cache time: 0.017690086737275124 Engine time: 0.04923775605857372 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-16/adapters_384_slots_96_rate_1.6-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-16/adapters_384_slots_96_rate_1.6-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 4320, 33, 17280, 17280, 33, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 33, 17280, 33, 17280, 4320, 4320, 4320, 33, 33, 4320, 33, 17280, 33, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 17280, 33, 17280, 17280, 17280, 17280, 33, 4320, 4320, 4320, 17280, 4320, 33, 4320, 33, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 33, 33, 17280, 4320, 4320, 33, 33, 33, 4320, 33, 4320, 33, 17280, 33, 4320, 17280, 33, 17280, 4320, 33, 17280, 17280, 17280, 17280, 4320, 33, 4320, 17280, 17280, 4320, 33, 33, 17280, 4320, 4320, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 33, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 17280, 33, 33, 33, 4320, 4320, 17280, 33, 33, 17280, 33, 17280, 4320, 33, 17280, 4320, 4320, 33, 17280, 17280, 17280, 33, 4320, 17280, 33, 17280, 4320, 4320, 17280, 17280, 33, 4320, 17280, 33, 4320, 4320, 33, 4320, 33, 4320, 17280, 17280, 4320, 33, 17280, 33, 17280, 4320, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 17280, 33, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 33, 33, 33, 33, 33, 4320, 33, 33, 4320, 17280, 17280, 33, 33, 17280, 33, 33, 33, 4320, 33, 4320, 17280, 17280, 4320, 4320, 33, 17280, 4320, 17280, 33, 4320, 4320, 33, 33, 4320, 33, 17280, 17280, 33, 17280, 17280, 33, 4320, 17280, 33, 33, 4320, 4320, 33, 33, 17280, 17280, 17280, 17280, 4320, 33, 4320, 4320, 33, 33, 33, 33, 33, 33, 33, 33, 4320, 17280, 4320, 4320, 4320, 17280, 33, 4320, 4320, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 4320, 33, 17280, 17280, 17280, 4320, 33, 17280, 17280, 4320, 4320, 17280, 17280, 33, 17280, 17280, 4320, 33, 17280, 4320, 4320, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 4320, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 17280, 33, 33, 33, 4320, 33, 4320, 4320, 33, 17280, 4320, 17280, 33, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 17280, 17280, 33, 17280, 17280, 33, 17280, 4320, 17280, 4320, 4320, 4320, 33, 4320, 33, 33, 17280, 33, 4320, 33, 33, 4320, 17280, 4320, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2769024 . Total input tokens: 616944113 . Total output tokens: 553679964
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 76.95148910116404,
    "estimated_duration": 3600.1563491427123,
    "input_throughput": 5307.220339069389,
    "output_throughput": 4698.2565087840585,
    "total_throughput": 10005.476847853448,
    "itl": 182.09292436861097,
    "ttft": 2117988.680404766,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 471,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4083136888989116,
    "arrivals": 921853,
    "finished_requests": 77275,
    "scheduler_time": 137.40433092795618
}
#Debug simulation 
Total elapsed time: 76.9516657050699. Arrivals time: 0.4327168553136289 Scheduler time: 76.38083384139463 Scheduler overhead time: 0.05217283312231302 Adapter cache time: 0.01612770091742277 Engine time: 0.051100708078593016 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-32/adapters_384_slots_96_rate_1.6-0.4-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-32/adapters_384_slots_96_rate_1.6-0.4-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 4320, 33, 17280, 17280, 33, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 33, 17280, 33, 17280, 4320, 4320, 4320, 33, 33, 4320, 33, 17280, 33, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 17280, 33, 17280, 17280, 17280, 17280, 33, 4320, 4320, 4320, 17280, 4320, 33, 4320, 33, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 33, 33, 17280, 4320, 4320, 33, 33, 33, 4320, 33, 4320, 33, 17280, 33, 4320, 17280, 33, 17280, 4320, 33, 17280, 17280, 17280, 17280, 4320, 33, 4320, 17280, 17280, 4320, 33, 33, 17280, 4320, 4320, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 33, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 17280, 33, 33, 33, 4320, 4320, 17280, 33, 33, 17280, 33, 17280, 4320, 33, 17280, 4320, 4320, 33, 17280, 17280, 17280, 33, 4320, 17280, 33, 17280, 4320, 4320, 17280, 17280, 33, 4320, 17280, 33, 4320, 4320, 33, 4320, 33, 4320, 17280, 17280, 4320, 33, 17280, 33, 17280, 4320, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 17280, 33, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 33, 33, 33, 33, 33, 4320, 33, 33, 4320, 17280, 17280, 33, 33, 17280, 33, 33, 33, 4320, 33, 4320, 17280, 17280, 4320, 4320, 33, 17280, 4320, 17280, 33, 4320, 4320, 33, 33, 4320, 33, 17280, 17280, 33, 17280, 17280, 33, 4320, 17280, 33, 33, 4320, 4320, 33, 33, 17280, 17280, 17280, 17280, 4320, 33, 4320, 4320, 33, 33, 33, 33, 33, 33, 33, 33, 4320, 17280, 4320, 4320, 4320, 17280, 33, 4320, 4320, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 4320, 33, 17280, 17280, 17280, 4320, 33, 17280, 17280, 4320, 4320, 17280, 17280, 33, 17280, 17280, 4320, 33, 17280, 4320, 4320, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 4320, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 17280, 33, 33, 33, 4320, 33, 4320, 4320, 33, 17280, 4320, 17280, 33, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 17280, 17280, 33, 17280, 17280, 33, 17280, 4320, 17280, 4320, 4320, 4320, 33, 4320, 33, 33, 17280, 33, 4320, 33, 33, 4320, 17280, 4320, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2769024 . Total input tokens: 616944113 . Total output tokens: 553679964
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 62.2623490341939,
    "estimated_duration": 3600.008359244546,
    "input_throughput": 5292.505210737411,
    "output_throughput": 4685.2832873808975,
    "total_throughput": 9977.788498118309,
    "itl": 180.38618316335823,
    "ttft": 2120761.952308636,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 598,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0033727788180067,
    "arrivals": 921853,
    "finished_requests": 76954,
    "scheduler_time": 137.78357541807182
}
#Debug simulation 
Total elapsed time: 62.262530740350485. Arrivals time: 0.4248236403800547 Scheduler time: 61.701540753711015 Scheduler overhead time: 0.05074815731495619 Adapter cache time: 0.017603835090994835 Engine time: 0.04942404478788376 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-8/adapters_384_slots_96_rate_1.6-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-8/adapters_384_slots_96_rate_1.6-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 17280, 1080, 540, 17280, 17280, 540, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 540, 17280, 540, 17280, 1080, 1080, 1080, 540, 540, 1080, 540, 17280, 540, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 17280, 540, 17280, 17280, 17280, 17280, 540, 1080, 1080, 1080, 17280, 1080, 540, 1080, 540, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 540, 540, 17280, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 17280, 540, 1080, 17280, 540, 17280, 1080, 540, 17280, 17280, 17280, 17280, 1080, 540, 1080, 17280, 17280, 1080, 540, 540, 17280, 1080, 1080, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 540, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 17280, 540, 540, 540, 1080, 1080, 17280, 540, 540, 17280, 540, 17280, 1080, 540, 17280, 1080, 1080, 540, 17280, 17280, 17280, 540, 1080, 17280, 540, 17280, 1080, 1080, 17280, 17280, 540, 1080, 17280, 540, 1080, 1080, 540, 1080, 540, 1080, 17280, 17280, 1080, 540, 17280, 540, 17280, 1080, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 17280, 540, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 17280, 17280, 540, 540, 17280, 540, 540, 540, 1080, 540, 1080, 17280, 17280, 1080, 1080, 540, 17280, 1080, 17280, 540, 1080, 1080, 540, 540, 1080, 540, 17280, 17280, 540, 17280, 17280, 540, 1080, 17280, 540, 540, 1080, 1080, 540, 540, 17280, 17280, 17280, 17280, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 17280, 1080, 1080, 1080, 17280, 540, 1080, 1080, 17280, 17280, 540, 17280, 17280, 540, 17280, 540, 540, 1080, 540, 17280, 17280, 17280, 1080, 540, 17280, 17280, 1080, 1080, 17280, 17280, 540, 17280, 17280, 1080, 540, 17280, 1080, 1080, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 17280, 540, 1080, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 17280, 540, 540, 540, 1080, 540, 1080, 1080, 540, 17280, 1080, 17280, 540, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 17280, 17280, 540, 17280, 17280, 540, 17280, 1080, 17280, 1080, 1080, 1080, 540, 1080, 540, 540, 17280, 540, 1080, 540, 540, 1080, 17280, 1080, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2419200 . Total input tokens: 538837550 . Total output tokens: 483773560
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 78.2734351423569,
    "estimated_duration": 3600.1726771945036,
    "input_throughput": 5329.9865646870185,
    "output_throughput": 4681.54488998957,
    "total_throughput": 10011.53145467659,
    "itl": 182.5371402818997,
    "ttft": 2099919.798005654,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 584,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7873248424567543,
    "arrivals": 805539,
    "finished_requests": 77357,
    "scheduler_time": 136.8556407885552
}
#Debug simulation 
Total elapsed time: 78.27360200695693. Arrivals time: 0.4238233803771436 Scheduler time: 77.71049590641633 Scheduler overhead time: 0.0517296539619565 Adapter cache time: 0.01805183757096529 Engine time: 0.050562246702611446 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-16/adapters_384_slots_96_rate_1.6-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-16/adapters_384_slots_96_rate_1.6-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 17280, 1080, 540, 17280, 17280, 540, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 540, 17280, 540, 17280, 1080, 1080, 1080, 540, 540, 1080, 540, 17280, 540, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 17280, 540, 17280, 17280, 17280, 17280, 540, 1080, 1080, 1080, 17280, 1080, 540, 1080, 540, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 540, 540, 17280, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 17280, 540, 1080, 17280, 540, 17280, 1080, 540, 17280, 17280, 17280, 17280, 1080, 540, 1080, 17280, 17280, 1080, 540, 540, 17280, 1080, 1080, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 540, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 17280, 540, 540, 540, 1080, 1080, 17280, 540, 540, 17280, 540, 17280, 1080, 540, 17280, 1080, 1080, 540, 17280, 17280, 17280, 540, 1080, 17280, 540, 17280, 1080, 1080, 17280, 17280, 540, 1080, 17280, 540, 1080, 1080, 540, 1080, 540, 1080, 17280, 17280, 1080, 540, 17280, 540, 17280, 1080, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 17280, 540, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 17280, 17280, 540, 540, 17280, 540, 540, 540, 1080, 540, 1080, 17280, 17280, 1080, 1080, 540, 17280, 1080, 17280, 540, 1080, 1080, 540, 540, 1080, 540, 17280, 17280, 540, 17280, 17280, 540, 1080, 17280, 540, 540, 1080, 1080, 540, 540, 17280, 17280, 17280, 17280, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 17280, 1080, 1080, 1080, 17280, 540, 1080, 1080, 17280, 17280, 540, 17280, 17280, 540, 17280, 540, 540, 1080, 540, 17280, 17280, 17280, 1080, 540, 17280, 17280, 1080, 1080, 17280, 17280, 540, 17280, 17280, 1080, 540, 17280, 1080, 1080, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 17280, 540, 1080, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 17280, 540, 540, 540, 1080, 540, 1080, 1080, 540, 17280, 1080, 17280, 540, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 17280, 17280, 540, 17280, 17280, 540, 17280, 1080, 17280, 1080, 1080, 1080, 540, 1080, 540, 540, 17280, 540, 1080, 540, 540, 1080, 17280, 1080, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2419200 . Total input tokens: 538837550 . Total output tokens: 483773560
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 77.95955203520134,
    "estimated_duration": 3600.0874733549726,
    "input_throughput": 5329.96382505065,
    "output_throughput": 4681.236532370859,
    "total_throughput": 10011.200357421509,
    "itl": 182.54175086338694,
    "ttft": 2099924.531246943,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 584,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9067673323699328,
    "arrivals": 805539,
    "finished_requests": 77351,
    "scheduler_time": 136.84850066455164
}
#Debug simulation 
Total elapsed time: 77.95971817616373. Arrivals time: 0.4165066471323371 Scheduler time: 77.40288217738271 Scheduler overhead time: 0.05200638994574547 Adapter cache time: 0.018056286964565516 Engine time: 0.050595871172845364 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-32/adapters_384_slots_96_rate_1.6-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-32/adapters_384_slots_96_rate_1.6-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 17280, 1080, 540, 17280, 17280, 540, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 540, 17280, 540, 17280, 1080, 1080, 1080, 540, 540, 1080, 540, 17280, 540, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 17280, 540, 17280, 17280, 17280, 17280, 540, 1080, 1080, 1080, 17280, 1080, 540, 1080, 540, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 540, 540, 17280, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 17280, 540, 1080, 17280, 540, 17280, 1080, 540, 17280, 17280, 17280, 17280, 1080, 540, 1080, 17280, 17280, 1080, 540, 540, 17280, 1080, 1080, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 540, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 17280, 540, 540, 540, 1080, 1080, 17280, 540, 540, 17280, 540, 17280, 1080, 540, 17280, 1080, 1080, 540, 17280, 17280, 17280, 540, 1080, 17280, 540, 17280, 1080, 1080, 17280, 17280, 540, 1080, 17280, 540, 1080, 1080, 540, 1080, 540, 1080, 17280, 17280, 1080, 540, 17280, 540, 17280, 1080, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 17280, 540, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 17280, 17280, 540, 540, 17280, 540, 540, 540, 1080, 540, 1080, 17280, 17280, 1080, 1080, 540, 17280, 1080, 17280, 540, 1080, 1080, 540, 540, 1080, 540, 17280, 17280, 540, 17280, 17280, 540, 1080, 17280, 540, 540, 1080, 1080, 540, 540, 17280, 17280, 17280, 17280, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 17280, 1080, 1080, 1080, 17280, 540, 1080, 1080, 17280, 17280, 540, 17280, 17280, 540, 17280, 540, 540, 1080, 540, 17280, 17280, 17280, 1080, 540, 17280, 17280, 1080, 1080, 17280, 17280, 540, 17280, 17280, 1080, 540, 17280, 1080, 1080, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 17280, 540, 1080, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 17280, 540, 540, 540, 1080, 540, 1080, 1080, 540, 17280, 1080, 17280, 540, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 17280, 17280, 540, 17280, 17280, 540, 17280, 1080, 17280, 1080, 1080, 1080, 540, 1080, 540, 540, 17280, 540, 1080, 540, 540, 1080, 17280, 1080, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2419200 . Total input tokens: 538837550 . Total output tokens: 483773560
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 77.31088189408183,
    "estimated_duration": 3600.0086988118014,
    "input_throughput": 5315.3316008140955,
    "output_throughput": 4671.2978792385775,
    "total_throughput": 9986.629480052672,
    "itl": 180.76189590793425,
    "ttft": 2101168.1260987725,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 593,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9390311801433684,
    "arrivals": 805539,
    "finished_requests": 77156,
    "scheduler_time": 137.35604092856795
}
#Debug simulation 
Total elapsed time: 77.31105175474659. Arrivals time: 0.45874561462551355 Scheduler time: 76.71132497442886 Scheduler overhead time: 0.05250857165083289 Adapter cache time: 0.01828538067638874 Engine time: 0.051116539631038904 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-16-16/adapters_384_slots_96_rate_1.6-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-16-16/adapters_384_slots_96_rate_1.6-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 17280, 1080, 540, 17280, 17280, 540, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 540, 17280, 540, 17280, 1080, 1080, 1080, 540, 540, 1080, 540, 17280, 540, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 17280, 540, 17280, 17280, 17280, 17280, 540, 1080, 1080, 1080, 17280, 1080, 540, 1080, 540, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 540, 540, 17280, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 17280, 540, 1080, 17280, 540, 17280, 1080, 540, 17280, 17280, 17280, 17280, 1080, 540, 1080, 17280, 17280, 1080, 540, 540, 17280, 1080, 1080, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 540, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 17280, 540, 540, 540, 1080, 1080, 17280, 540, 540, 17280, 540, 17280, 1080, 540, 17280, 1080, 1080, 540, 17280, 17280, 17280, 540, 1080, 17280, 540, 17280, 1080, 1080, 17280, 17280, 540, 1080, 17280, 540, 1080, 1080, 540, 1080, 540, 1080, 17280, 17280, 1080, 540, 17280, 540, 17280, 1080, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 17280, 540, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 17280, 17280, 540, 540, 17280, 540, 540, 540, 1080, 540, 1080, 17280, 17280, 1080, 1080, 540, 17280, 1080, 17280, 540, 1080, 1080, 540, 540, 1080, 540, 17280, 17280, 540, 17280, 17280, 540, 1080, 17280, 540, 540, 1080, 1080, 540, 540, 17280, 17280, 17280, 17280, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 17280, 1080, 1080, 1080, 17280, 540, 1080, 1080, 17280, 17280, 540, 17280, 17280, 540, 17280, 540, 540, 1080, 540, 17280, 17280, 17280, 1080, 540, 17280, 17280, 1080, 1080, 17280, 17280, 540, 17280, 17280, 1080, 540, 17280, 1080, 1080, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 17280, 540, 1080, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 17280, 540, 540, 540, 1080, 540, 1080, 1080, 540, 17280, 1080, 17280, 540, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 17280, 17280, 540, 17280, 17280, 540, 17280, 1080, 17280, 1080, 1080, 1080, 540, 1080, 540, 540, 17280, 540, 1080, 540, 540, 1080, 17280, 1080, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2419200 . Total input tokens: 538837550 . Total output tokens: 483773560
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 77.92313697887585,
    "estimated_duration": 3600.0988154645884,
    "input_throughput": 5329.064834995142,
    "output_throughput": 4681.4106678416465,
    "total_throughput": 10010.475502836787,
    "itl": 182.54537820247413,
    "ttft": 2099829.329526581,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 583,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8228754090238246,
    "arrivals": 805539,
    "finished_requests": 77337,
    "scheduler_time": 136.8503075880666
}
#Debug simulation 
Total elapsed time: 77.9233084958978. Arrivals time: 0.47288727667182684 Scheduler time: 77.30926415976137 Scheduler overhead time: 0.052783893421292305 Adapter cache time: 0.01820377679541707 Engine time: 0.05097919097170234 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-16-32/adapters_384_slots_96_rate_1.6-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-16-32/adapters_384_slots_96_rate_1.6-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 17280, 1080, 540, 17280, 17280, 540, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 540, 17280, 540, 17280, 1080, 1080, 1080, 540, 540, 1080, 540, 17280, 540, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 17280, 540, 17280, 17280, 17280, 17280, 540, 1080, 1080, 1080, 17280, 1080, 540, 1080, 540, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 540, 540, 17280, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 17280, 540, 1080, 17280, 540, 17280, 1080, 540, 17280, 17280, 17280, 17280, 1080, 540, 1080, 17280, 17280, 1080, 540, 540, 17280, 1080, 1080, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 540, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 17280, 540, 540, 540, 1080, 1080, 17280, 540, 540, 17280, 540, 17280, 1080, 540, 17280, 1080, 1080, 540, 17280, 17280, 17280, 540, 1080, 17280, 540, 17280, 1080, 1080, 17280, 17280, 540, 1080, 17280, 540, 1080, 1080, 540, 1080, 540, 1080, 17280, 17280, 1080, 540, 17280, 540, 17280, 1080, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 17280, 540, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 17280, 17280, 540, 540, 17280, 540, 540, 540, 1080, 540, 1080, 17280, 17280, 1080, 1080, 540, 17280, 1080, 17280, 540, 1080, 1080, 540, 540, 1080, 540, 17280, 17280, 540, 17280, 17280, 540, 1080, 17280, 540, 540, 1080, 1080, 540, 540, 17280, 17280, 17280, 17280, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 17280, 1080, 1080, 1080, 17280, 540, 1080, 1080, 17280, 17280, 540, 17280, 17280, 540, 17280, 540, 540, 1080, 540, 17280, 17280, 17280, 1080, 540, 17280, 17280, 1080, 1080, 17280, 17280, 540, 17280, 17280, 1080, 540, 17280, 1080, 1080, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 17280, 540, 1080, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 17280, 540, 540, 540, 1080, 540, 1080, 1080, 540, 17280, 1080, 17280, 540, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 17280, 17280, 540, 17280, 17280, 540, 17280, 1080, 17280, 1080, 1080, 1080, 540, 1080, 540, 540, 17280, 540, 1080, 540, 540, 1080, 17280, 1080, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2419200 . Total input tokens: 538837550 . Total output tokens: 483773560
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 77.86087842611596,
    "estimated_duration": 3600.03398684749,
    "input_throughput": 5315.294263862358,
    "output_throughput": 4671.265066229614,
    "total_throughput": 9986.559330091972,
    "itl": 180.76295098007193,
    "ttft": 2101174.408831738,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 593,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9641819374263316,
    "arrivals": 805539,
    "finished_requests": 77156,
    "scheduler_time": 137.35617820702413
}
#Debug simulation 
Total elapsed time: 77.86104807490483. Arrivals time: 0.4280873453244567 Scheduler time: 77.29271372454241 Scheduler overhead time: 0.05197222623974085 Adapter cache time: 0.018406194169074297 Engine time: 0.05061366455629468 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_16-16-16/adapters_384_slots_96_rate_1.6-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_16-16-16/adapters_384_slots_96_rate_1.6-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 17280, 1080, 540, 17280, 17280, 540, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 540, 17280, 540, 17280, 1080, 1080, 1080, 540, 540, 1080, 540, 17280, 540, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 17280, 540, 17280, 17280, 17280, 17280, 540, 1080, 1080, 1080, 17280, 1080, 540, 1080, 540, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 540, 540, 17280, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 17280, 540, 1080, 17280, 540, 17280, 1080, 540, 17280, 17280, 17280, 17280, 1080, 540, 1080, 17280, 17280, 1080, 540, 540, 17280, 1080, 1080, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 540, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 17280, 540, 540, 540, 1080, 1080, 17280, 540, 540, 17280, 540, 17280, 1080, 540, 17280, 1080, 1080, 540, 17280, 17280, 17280, 540, 1080, 17280, 540, 17280, 1080, 1080, 17280, 17280, 540, 1080, 17280, 540, 1080, 1080, 540, 1080, 540, 1080, 17280, 17280, 1080, 540, 17280, 540, 17280, 1080, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 17280, 540, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 17280, 17280, 540, 540, 17280, 540, 540, 540, 1080, 540, 1080, 17280, 17280, 1080, 1080, 540, 17280, 1080, 17280, 540, 1080, 1080, 540, 540, 1080, 540, 17280, 17280, 540, 17280, 17280, 540, 1080, 17280, 540, 540, 1080, 1080, 540, 540, 17280, 17280, 17280, 17280, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 17280, 1080, 1080, 1080, 17280, 540, 1080, 1080, 17280, 17280, 540, 17280, 17280, 540, 17280, 540, 540, 1080, 540, 17280, 17280, 17280, 1080, 540, 17280, 17280, 1080, 1080, 17280, 17280, 540, 17280, 17280, 1080, 540, 17280, 1080, 1080, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 17280, 540, 1080, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 17280, 540, 540, 540, 1080, 540, 1080, 1080, 540, 17280, 1080, 17280, 540, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 17280, 17280, 540, 17280, 17280, 540, 17280, 1080, 17280, 1080, 1080, 1080, 540, 1080, 540, 540, 17280, 540, 1080, 540, 540, 1080, 17280, 1080, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2419200 . Total input tokens: 538837550 . Total output tokens: 483773560
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 78.66323572676629,
    "estimated_duration": 3600.1313230719843,
    "input_throughput": 5330.047789375132,
    "output_throughput": 4681.598666133713,
    "total_throughput": 10011.646455508844,
    "itl": 182.53537905037498,
    "ttft": 2099909.4592220266,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 584,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7461893722228454,
    "arrivals": 805539,
    "finished_requests": 77357,
    "scheduler_time": 136.85542213617165
}
#Debug simulation 
Total elapsed time: 78.6634194101207. Arrivals time: 0.46879764134064317 Scheduler time: 78.05326033942401 Scheduler overhead time: 0.05203679343685508 Adapter cache time: 0.01819738745689392 Engine time: 0.0518696466460824 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_16-16-32/adapters_384_slots_96_rate_1.6-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_16-16-32/adapters_384_slots_96_rate_1.6-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 17280, 1080, 540, 17280, 17280, 540, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 540, 17280, 540, 17280, 1080, 1080, 1080, 540, 540, 1080, 540, 17280, 540, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 17280, 540, 17280, 17280, 17280, 17280, 540, 1080, 1080, 1080, 17280, 1080, 540, 1080, 540, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 540, 540, 17280, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 17280, 540, 1080, 17280, 540, 17280, 1080, 540, 17280, 17280, 17280, 17280, 1080, 540, 1080, 17280, 17280, 1080, 540, 540, 17280, 1080, 1080, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 540, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 17280, 540, 540, 540, 1080, 1080, 17280, 540, 540, 17280, 540, 17280, 1080, 540, 17280, 1080, 1080, 540, 17280, 17280, 17280, 540, 1080, 17280, 540, 17280, 1080, 1080, 17280, 17280, 540, 1080, 17280, 540, 1080, 1080, 540, 1080, 540, 1080, 17280, 17280, 1080, 540, 17280, 540, 17280, 1080, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 17280, 540, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 17280, 17280, 540, 540, 17280, 540, 540, 540, 1080, 540, 1080, 17280, 17280, 1080, 1080, 540, 17280, 1080, 17280, 540, 1080, 1080, 540, 540, 1080, 540, 17280, 17280, 540, 17280, 17280, 540, 1080, 17280, 540, 540, 1080, 1080, 540, 540, 17280, 17280, 17280, 17280, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 17280, 1080, 1080, 1080, 17280, 540, 1080, 1080, 17280, 17280, 540, 17280, 17280, 540, 17280, 540, 540, 1080, 540, 17280, 17280, 17280, 1080, 540, 17280, 17280, 1080, 1080, 17280, 17280, 540, 17280, 17280, 1080, 540, 17280, 1080, 1080, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 17280, 540, 1080, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 17280, 540, 540, 540, 1080, 540, 1080, 1080, 540, 17280, 1080, 17280, 540, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 17280, 17280, 540, 17280, 17280, 540, 17280, 1080, 17280, 1080, 1080, 1080, 540, 1080, 540, 540, 17280, 540, 1080, 540, 540, 1080, 17280, 1080, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2419200 . Total input tokens: 538837550 . Total output tokens: 483773560
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 77.43695078790188,
    "estimated_duration": 3600.059019210798,
    "input_throughput": 5315.257304919077,
    "output_throughput": 4671.232585427599,
    "total_throughput": 9986.489890346675,
    "itl": 180.76400693602005,
    "ttft": 2101180.801732156,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 593,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.989081187136466,
    "arrivals": 805539,
    "finished_requests": 77156,
    "scheduler_time": 137.356311320673
}
#Debug simulation 
Total elapsed time: 77.43712165206671. Arrivals time: 0.4693998107686639 Scheduler time: 76.82614394277334 Scheduler overhead time: 0.05261608865112066 Adapter cache time: 0.018402588088065386 Engine time: 0.05145769380033016 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-8/adapters_384_slots_96_rate_1.6-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-8/adapters_384_slots_96_rate_1.6-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 1080, 270, 17280, 17280, 270, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 270, 17280, 270, 17280, 1080, 1080, 1080, 270, 270, 1080, 270, 17280, 270, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 17280, 270, 17280, 17280, 17280, 17280, 270, 1080, 1080, 1080, 17280, 1080, 270, 1080, 270, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 270, 270, 17280, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 17280, 270, 1080, 17280, 270, 17280, 1080, 270, 17280, 17280, 17280, 17280, 1080, 270, 1080, 17280, 17280, 1080, 270, 270, 17280, 1080, 1080, 270, 270, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 270, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 17280, 270, 270, 270, 1080, 1080, 17280, 270, 270, 17280, 270, 17280, 1080, 270, 17280, 1080, 1080, 270, 17280, 17280, 17280, 270, 1080, 17280, 270, 17280, 1080, 1080, 17280, 17280, 270, 1080, 17280, 270, 1080, 1080, 270, 1080, 270, 1080, 17280, 17280, 1080, 270, 17280, 270, 17280, 1080, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 17280, 270, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 17280, 17280, 270, 270, 17280, 270, 270, 270, 1080, 270, 1080, 17280, 17280, 1080, 1080, 270, 17280, 1080, 17280, 270, 1080, 1080, 270, 270, 1080, 270, 17280, 17280, 270, 17280, 17280, 270, 1080, 17280, 270, 270, 1080, 1080, 270, 270, 17280, 17280, 17280, 17280, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 17280, 1080, 1080, 1080, 17280, 270, 1080, 1080, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 1080, 270, 17280, 17280, 17280, 1080, 270, 17280, 17280, 1080, 1080, 17280, 17280, 270, 17280, 17280, 1080, 270, 17280, 1080, 1080, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 1080, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 17280, 270, 270, 270, 1080, 270, 1080, 1080, 270, 17280, 1080, 17280, 270, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 17280, 17280, 270, 17280, 17280, 270, 17280, 1080, 17280, 1080, 1080, 1080, 270, 1080, 270, 270, 17280, 270, 1080, 270, 270, 1080, 17280, 1080, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2384640 . Total input tokens: 531075915 . Total output tokens: 476856170
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 80.73548249108717,
    "estimated_duration": 3600.017132926029,
    "input_throughput": 5293.2814751666765,
    "output_throughput": 4688.702408002354,
    "total_throughput": 9981.98388316903,
    "itl": 183.7090267554976,
    "ttft": 2095537.9809502957,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 582,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7812038669688885,
    "arrivals": 794133,
    "finished_requests": 77176,
    "scheduler_time": 136.38267628832781
}
#Debug simulation 
Total elapsed time: 80.73567042080685. Arrivals time: 0.40428583277389407 Scheduler time: 80.19159427378327 Scheduler overhead time: 0.05227043945342302 Adapter cache time: 0.017769209574908018 Engine time: 0.05091466475278139 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-16/adapters_384_slots_96_rate_1.6-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-16/adapters_384_slots_96_rate_1.6-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 1080, 270, 17280, 17280, 270, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 270, 17280, 270, 17280, 1080, 1080, 1080, 270, 270, 1080, 270, 17280, 270, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 17280, 270, 17280, 17280, 17280, 17280, 270, 1080, 1080, 1080, 17280, 1080, 270, 1080, 270, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 270, 270, 17280, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 17280, 270, 1080, 17280, 270, 17280, 1080, 270, 17280, 17280, 17280, 17280, 1080, 270, 1080, 17280, 17280, 1080, 270, 270, 17280, 1080, 1080, 270, 270, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 270, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 17280, 270, 270, 270, 1080, 1080, 17280, 270, 270, 17280, 270, 17280, 1080, 270, 17280, 1080, 1080, 270, 17280, 17280, 17280, 270, 1080, 17280, 270, 17280, 1080, 1080, 17280, 17280, 270, 1080, 17280, 270, 1080, 1080, 270, 1080, 270, 1080, 17280, 17280, 1080, 270, 17280, 270, 17280, 1080, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 17280, 270, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 17280, 17280, 270, 270, 17280, 270, 270, 270, 1080, 270, 1080, 17280, 17280, 1080, 1080, 270, 17280, 1080, 17280, 270, 1080, 1080, 270, 270, 1080, 270, 17280, 17280, 270, 17280, 17280, 270, 1080, 17280, 270, 270, 1080, 1080, 270, 270, 17280, 17280, 17280, 17280, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 17280, 1080, 1080, 1080, 17280, 270, 1080, 1080, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 1080, 270, 17280, 17280, 17280, 1080, 270, 17280, 17280, 1080, 1080, 17280, 17280, 270, 17280, 17280, 1080, 270, 17280, 1080, 1080, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 1080, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 17280, 270, 270, 270, 1080, 270, 1080, 1080, 270, 17280, 1080, 17280, 270, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 17280, 17280, 270, 17280, 17280, 270, 17280, 1080, 17280, 1080, 1080, 1080, 270, 1080, 270, 270, 17280, 270, 1080, 270, 270, 1080, 17280, 1080, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2384640 . Total input tokens: 531075915 . Total output tokens: 476856170
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 80.87128898920491,
    "estimated_duration": 3600.148232037864,
    "input_throughput": 5292.712347350812,
    "output_throughput": 4688.450005972553,
    "total_throughput": 9981.162353323365,
    "itl": 183.7159501363688,
    "ttft": 2095522.8218276603,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 578,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.882289505505473,
    "arrivals": 794133,
    "finished_requests": 77172,
    "scheduler_time": 136.3842583764814
}
#Debug simulation 
Total elapsed time: 80.87146612815559. Arrivals time: 0.42311514681205153 Scheduler time: 80.30889172945172 Scheduler overhead time: 0.05200999975204468 Adapter cache time: 0.017742889001965523 Engine time: 0.050058833323419094 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-32/adapters_384_slots_96_rate_1.6-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-32/adapters_384_slots_96_rate_1.6-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 1080, 270, 17280, 17280, 270, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 270, 17280, 270, 17280, 1080, 1080, 1080, 270, 270, 1080, 270, 17280, 270, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 17280, 270, 17280, 17280, 17280, 17280, 270, 1080, 1080, 1080, 17280, 1080, 270, 1080, 270, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 270, 270, 17280, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 17280, 270, 1080, 17280, 270, 17280, 1080, 270, 17280, 17280, 17280, 17280, 1080, 270, 1080, 17280, 17280, 1080, 270, 270, 17280, 1080, 1080, 270, 270, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 270, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 17280, 270, 270, 270, 1080, 1080, 17280, 270, 270, 17280, 270, 17280, 1080, 270, 17280, 1080, 1080, 270, 17280, 17280, 17280, 270, 1080, 17280, 270, 17280, 1080, 1080, 17280, 17280, 270, 1080, 17280, 270, 1080, 1080, 270, 1080, 270, 1080, 17280, 17280, 1080, 270, 17280, 270, 17280, 1080, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 17280, 270, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 17280, 17280, 270, 270, 17280, 270, 270, 270, 1080, 270, 1080, 17280, 17280, 1080, 1080, 270, 17280, 1080, 17280, 270, 1080, 1080, 270, 270, 1080, 270, 17280, 17280, 270, 17280, 17280, 270, 1080, 17280, 270, 270, 1080, 1080, 270, 270, 17280, 17280, 17280, 17280, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 17280, 1080, 1080, 1080, 17280, 270, 1080, 1080, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 1080, 270, 17280, 17280, 17280, 1080, 270, 17280, 17280, 1080, 1080, 17280, 17280, 270, 17280, 17280, 1080, 270, 17280, 1080, 1080, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 1080, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 17280, 270, 270, 270, 1080, 270, 1080, 1080, 270, 17280, 1080, 17280, 270, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 17280, 17280, 270, 17280, 17280, 270, 17280, 1080, 17280, 1080, 1080, 1080, 270, 1080, 270, 270, 17280, 270, 1080, 270, 270, 1080, 17280, 1080, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2384640 . Total input tokens: 531075915 . Total output tokens: 476856170
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 79.80366253200918,
    "estimated_duration": 3600.063142880159,
    "input_throughput": 5281.240146468428,
    "output_throughput": 4677.588512108096,
    "total_throughput": 9958.828658576525,
    "itl": 181.694094071607,
    "ttft": 2096863.5271041603,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 592,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.931603443864745,
    "arrivals": 794133,
    "finished_requests": 76986,
    "scheduler_time": 136.95540537688512
}
#Debug simulation 
Total elapsed time: 79.80383274005726. Arrivals time: 0.45789913833141327 Scheduler time: 79.2074587289244 Scheduler overhead time: 0.051515521947294474 Adapter cache time: 0.017771644052118063 Engine time: 0.05006708297878504 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-16-16/adapters_384_slots_96_rate_1.6-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-16-16/adapters_384_slots_96_rate_1.6-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 1080, 270, 17280, 17280, 270, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 270, 17280, 270, 17280, 1080, 1080, 1080, 270, 270, 1080, 270, 17280, 270, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 17280, 270, 17280, 17280, 17280, 17280, 270, 1080, 1080, 1080, 17280, 1080, 270, 1080, 270, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 270, 270, 17280, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 17280, 270, 1080, 17280, 270, 17280, 1080, 270, 17280, 17280, 17280, 17280, 1080, 270, 1080, 17280, 17280, 1080, 270, 270, 17280, 1080, 1080, 270, 270, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 270, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 17280, 270, 270, 270, 1080, 1080, 17280, 270, 270, 17280, 270, 17280, 1080, 270, 17280, 1080, 1080, 270, 17280, 17280, 17280, 270, 1080, 17280, 270, 17280, 1080, 1080, 17280, 17280, 270, 1080, 17280, 270, 1080, 1080, 270, 1080, 270, 1080, 17280, 17280, 1080, 270, 17280, 270, 17280, 1080, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 17280, 270, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 17280, 17280, 270, 270, 17280, 270, 270, 270, 1080, 270, 1080, 17280, 17280, 1080, 1080, 270, 17280, 1080, 17280, 270, 1080, 1080, 270, 270, 1080, 270, 17280, 17280, 270, 17280, 17280, 270, 1080, 17280, 270, 270, 1080, 1080, 270, 270, 17280, 17280, 17280, 17280, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 17280, 1080, 1080, 1080, 17280, 270, 1080, 1080, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 1080, 270, 17280, 17280, 17280, 1080, 270, 17280, 17280, 1080, 1080, 17280, 17280, 270, 17280, 17280, 1080, 270, 17280, 1080, 1080, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 1080, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 17280, 270, 270, 270, 1080, 270, 1080, 1080, 270, 17280, 1080, 17280, 270, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 17280, 17280, 270, 17280, 17280, 270, 17280, 1080, 17280, 1080, 1080, 1080, 270, 1080, 270, 270, 17280, 270, 1080, 270, 270, 1080, 17280, 1080, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2384640 . Total input tokens: 531075915 . Total output tokens: 476856170
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 81.5822721729055,
    "estimated_duration": 3600.052011671577,
    "input_throughput": 5293.230191736024,
    "output_throughput": 4688.65698197581,
    "total_throughput": 9981.887173711833,
    "itl": 183.71044344383648,
    "ttft": 2095548.7224996295,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 582,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8157994055445186,
    "arrivals": 794133,
    "finished_requests": 77176,
    "scheduler_time": 136.38295949522455
}
#Debug simulation 
Total elapsed time: 81.58244638796896. Arrivals time: 0.4146727118641138 Scheduler time: 81.02854812843725 Scheduler overhead time: 0.05197741882875562 Adapter cache time: 0.01771414652466774 Engine time: 0.050513569731265306 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-16-32/adapters_384_slots_96_rate_1.6-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-16-32/adapters_384_slots_96_rate_1.6-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 1080, 270, 17280, 17280, 270, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 270, 17280, 270, 17280, 1080, 1080, 1080, 270, 270, 1080, 270, 17280, 270, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 17280, 270, 17280, 17280, 17280, 17280, 270, 1080, 1080, 1080, 17280, 1080, 270, 1080, 270, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 270, 270, 17280, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 17280, 270, 1080, 17280, 270, 17280, 1080, 270, 17280, 17280, 17280, 17280, 1080, 270, 1080, 17280, 17280, 1080, 270, 270, 17280, 1080, 1080, 270, 270, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 270, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 17280, 270, 270, 270, 1080, 1080, 17280, 270, 270, 17280, 270, 17280, 1080, 270, 17280, 1080, 1080, 270, 17280, 17280, 17280, 270, 1080, 17280, 270, 17280, 1080, 1080, 17280, 17280, 270, 1080, 17280, 270, 1080, 1080, 270, 1080, 270, 1080, 17280, 17280, 1080, 270, 17280, 270, 17280, 1080, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 17280, 270, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 17280, 17280, 270, 270, 17280, 270, 270, 270, 1080, 270, 1080, 17280, 17280, 1080, 1080, 270, 17280, 1080, 17280, 270, 1080, 1080, 270, 270, 1080, 270, 17280, 17280, 270, 17280, 17280, 270, 1080, 17280, 270, 270, 1080, 1080, 270, 270, 17280, 17280, 17280, 17280, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 17280, 1080, 1080, 1080, 17280, 270, 1080, 1080, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 1080, 270, 17280, 17280, 17280, 1080, 270, 17280, 17280, 1080, 1080, 17280, 17280, 270, 17280, 17280, 1080, 270, 17280, 1080, 1080, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 1080, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 17280, 270, 270, 270, 1080, 270, 1080, 1080, 270, 17280, 1080, 17280, 270, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 17280, 17280, 270, 17280, 17280, 270, 17280, 1080, 17280, 1080, 1080, 1080, 270, 1080, 270, 270, 17280, 270, 1080, 270, 270, 1080, 17280, 1080, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2384640 . Total input tokens: 531075915 . Total output tokens: 476856170
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 79.71303495578468,
    "estimated_duration": 3600.088039558219,
    "input_throughput": 5281.203623657252,
    "output_throughput": 4677.55616389494,
    "total_throughput": 9958.759787552193,
    "itl": 181.69517975626044,
    "ttft": 2096868.9672345608,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 592,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9563769397884638,
    "arrivals": 794133,
    "finished_requests": 76986,
    "scheduler_time": 136.95552855907042
}
#Debug simulation 
Total elapsed time: 79.71320466976613. Arrivals time: 0.40921223582699895 Scheduler time: 79.16474806005135 Scheduler overhead time: 0.05135295772925019 Adapter cache time: 0.017763668205589056 Engine time: 0.050722071435302496 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_16-16-16/adapters_384_slots_96_rate_1.6-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_16-16-16/adapters_384_slots_96_rate_1.6-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 1080, 270, 17280, 17280, 270, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 270, 17280, 270, 17280, 1080, 1080, 1080, 270, 270, 1080, 270, 17280, 270, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 17280, 270, 17280, 17280, 17280, 17280, 270, 1080, 1080, 1080, 17280, 1080, 270, 1080, 270, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 270, 270, 17280, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 17280, 270, 1080, 17280, 270, 17280, 1080, 270, 17280, 17280, 17280, 17280, 1080, 270, 1080, 17280, 17280, 1080, 270, 270, 17280, 1080, 1080, 270, 270, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 270, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 17280, 270, 270, 270, 1080, 1080, 17280, 270, 270, 17280, 270, 17280, 1080, 270, 17280, 1080, 1080, 270, 17280, 17280, 17280, 270, 1080, 17280, 270, 17280, 1080, 1080, 17280, 17280, 270, 1080, 17280, 270, 1080, 1080, 270, 1080, 270, 1080, 17280, 17280, 1080, 270, 17280, 270, 17280, 1080, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 17280, 270, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 17280, 17280, 270, 270, 17280, 270, 270, 270, 1080, 270, 1080, 17280, 17280, 1080, 1080, 270, 17280, 1080, 17280, 270, 1080, 1080, 270, 270, 1080, 270, 17280, 17280, 270, 17280, 17280, 270, 1080, 17280, 270, 270, 1080, 1080, 270, 270, 17280, 17280, 17280, 17280, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 17280, 1080, 1080, 1080, 17280, 270, 1080, 1080, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 1080, 270, 17280, 17280, 17280, 1080, 270, 17280, 17280, 1080, 1080, 17280, 17280, 270, 17280, 17280, 1080, 270, 17280, 1080, 1080, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 1080, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 17280, 270, 270, 270, 1080, 270, 1080, 1080, 270, 17280, 1080, 17280, 270, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 17280, 17280, 270, 17280, 17280, 270, 17280, 1080, 17280, 1080, 1080, 1080, 270, 1080, 270, 270, 17280, 270, 1080, 270, 270, 1080, 17280, 1080, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2384640 . Total input tokens: 531075915 . Total output tokens: 476856170
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 81.40073795197532,
    "estimated_duration": 3600.1850796958834,
    "input_throughput": 5293.034546326629,
    "output_throughput": 4688.483682462749,
    "total_throughput": 9981.518228789379,
    "itl": 183.7072531294533,
    "ttft": 2095586.4744544192,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 582,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7402092716330413,
    "arrivals": 794133,
    "finished_requests": 77176,
    "scheduler_time": 136.39037570096377
}
#Debug simulation 
Total elapsed time: 81.40091485762969. Arrivals time: 0.4579037204384804 Scheduler time: 80.80412869993597 Scheduler overhead time: 0.05154211074113846 Adapter cache time: 0.017328619491308928 Engine time: 0.05090376455336809 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_16-16-32/adapters_384_slots_96_rate_1.6-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_16-16-32/adapters_384_slots_96_rate_1.6-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 1080, 270, 17280, 17280, 270, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 270, 17280, 270, 17280, 1080, 1080, 1080, 270, 270, 1080, 270, 17280, 270, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 17280, 270, 17280, 17280, 17280, 17280, 270, 1080, 1080, 1080, 17280, 1080, 270, 1080, 270, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 270, 270, 17280, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 17280, 270, 1080, 17280, 270, 17280, 1080, 270, 17280, 17280, 17280, 17280, 1080, 270, 1080, 17280, 17280, 1080, 270, 270, 17280, 1080, 1080, 270, 270, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 270, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 17280, 270, 270, 270, 1080, 1080, 17280, 270, 270, 17280, 270, 17280, 1080, 270, 17280, 1080, 1080, 270, 17280, 17280, 17280, 270, 1080, 17280, 270, 17280, 1080, 1080, 17280, 17280, 270, 1080, 17280, 270, 1080, 1080, 270, 1080, 270, 1080, 17280, 17280, 1080, 270, 17280, 270, 17280, 1080, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 17280, 270, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 17280, 17280, 270, 270, 17280, 270, 270, 270, 1080, 270, 1080, 17280, 17280, 1080, 1080, 270, 17280, 1080, 17280, 270, 1080, 1080, 270, 270, 1080, 270, 17280, 17280, 270, 17280, 17280, 270, 1080, 17280, 270, 270, 1080, 1080, 270, 270, 17280, 17280, 17280, 17280, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 17280, 1080, 1080, 1080, 17280, 270, 1080, 1080, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 1080, 270, 17280, 17280, 17280, 1080, 270, 17280, 17280, 1080, 1080, 17280, 17280, 270, 17280, 17280, 1080, 270, 17280, 1080, 1080, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 1080, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 17280, 270, 270, 270, 1080, 270, 1080, 1080, 270, 17280, 1080, 17280, 270, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 17280, 17280, 270, 17280, 17280, 270, 17280, 1080, 17280, 1080, 1080, 1080, 270, 1080, 270, 270, 17280, 270, 1080, 270, 270, 1080, 17280, 1080, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2384640 . Total input tokens: 531075915 . Total output tokens: 476856170
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 80.35444920370355,
    "estimated_duration": 3600.111831042899,
    "input_throughput": 5281.168722609451,
    "output_throughput": 4677.525252075798,
    "total_throughput": 9958.69397468525,
    "itl": 181.6961871181207,
    "ttft": 2096875.2155423108,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 592,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9800186516344498,
    "arrivals": 794133,
    "finished_requests": 76986,
    "scheduler_time": 136.95567833194852
}
#Debug simulation 
Total elapsed time: 80.35461729904637. Arrivals time: 0.395947000477463 Scheduler time: 79.81925162859261 Scheduler overhead time: 0.05143871018663049 Adapter cache time: 0.01805437868461013 Engine time: 0.05080449488013983 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-8/adapters_384_slots_96_rate_1.6-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-8/adapters_384_slots_96_rate_1.6-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 1080, 135, 17280, 17280, 135, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 135, 17280, 135, 17280, 1080, 1080, 1080, 135, 135, 1080, 135, 17280, 135, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 17280, 135, 17280, 17280, 17280, 17280, 135, 1080, 1080, 1080, 17280, 1080, 135, 1080, 135, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 135, 135, 17280, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 17280, 135, 1080, 17280, 135, 17280, 1080, 135, 17280, 17280, 17280, 17280, 1080, 135, 1080, 17280, 17280, 1080, 135, 135, 17280, 1080, 1080, 135, 135, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 135, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 17280, 135, 135, 135, 1080, 1080, 17280, 135, 135, 17280, 135, 17280, 1080, 135, 17280, 1080, 1080, 135, 17280, 17280, 17280, 135, 1080, 17280, 135, 17280, 1080, 1080, 17280, 17280, 135, 1080, 17280, 135, 1080, 1080, 135, 1080, 135, 1080, 17280, 17280, 1080, 135, 17280, 135, 17280, 1080, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 17280, 135, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 17280, 17280, 135, 135, 17280, 135, 135, 135, 1080, 135, 1080, 17280, 17280, 1080, 1080, 135, 17280, 1080, 17280, 135, 1080, 1080, 135, 135, 1080, 135, 17280, 17280, 135, 17280, 17280, 135, 1080, 17280, 135, 135, 1080, 1080, 135, 135, 17280, 17280, 17280, 17280, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 17280, 1080, 1080, 1080, 17280, 135, 1080, 1080, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 1080, 135, 17280, 17280, 17280, 1080, 135, 17280, 17280, 1080, 1080, 17280, 17280, 135, 17280, 17280, 1080, 135, 17280, 1080, 1080, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 1080, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 17280, 135, 135, 135, 1080, 135, 1080, 1080, 135, 17280, 1080, 17280, 135, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 17280, 17280, 135, 17280, 17280, 135, 17280, 1080, 17280, 1080, 1080, 1080, 135, 1080, 135, 135, 17280, 135, 1080, 135, 135, 1080, 17280, 1080, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2367360 . Total input tokens: 527217306 . Total output tokens: 473385958
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 85.16424853913486,
    "estimated_duration": 3600.1315703014893,
    "input_throughput": 5299.954356502066,
    "output_throughput": 4681.2516906399205,
    "total_throughput": 9981.206047141986,
    "itl": 182.36838534388397,
    "ttft": 2092016.8860444888,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 538,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6465424062358427,
    "arrivals": 788332,
    "finished_requests": 77278,
    "scheduler_time": 136.85935865264048
}
#Debug simulation 
Total elapsed time: 85.16441901074722. Arrivals time: 0.4008976202458143 Scheduler time: 84.62351524969563 Scheduler overhead time: 0.051907338201999664 Adapter cache time: 0.017067420296370983 Engine time: 0.05154574383050203 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-16/adapters_384_slots_96_rate_1.6-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-16/adapters_384_slots_96_rate_1.6-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 1080, 135, 17280, 17280, 135, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 135, 17280, 135, 17280, 1080, 1080, 1080, 135, 135, 1080, 135, 17280, 135, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 17280, 135, 17280, 17280, 17280, 17280, 135, 1080, 1080, 1080, 17280, 1080, 135, 1080, 135, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 135, 135, 17280, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 17280, 135, 1080, 17280, 135, 17280, 1080, 135, 17280, 17280, 17280, 17280, 1080, 135, 1080, 17280, 17280, 1080, 135, 135, 17280, 1080, 1080, 135, 135, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 135, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 17280, 135, 135, 135, 1080, 1080, 17280, 135, 135, 17280, 135, 17280, 1080, 135, 17280, 1080, 1080, 135, 17280, 17280, 17280, 135, 1080, 17280, 135, 17280, 1080, 1080, 17280, 17280, 135, 1080, 17280, 135, 1080, 1080, 135, 1080, 135, 1080, 17280, 17280, 1080, 135, 17280, 135, 17280, 1080, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 17280, 135, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 17280, 17280, 135, 135, 17280, 135, 135, 135, 1080, 135, 1080, 17280, 17280, 1080, 1080, 135, 17280, 1080, 17280, 135, 1080, 1080, 135, 135, 1080, 135, 17280, 17280, 135, 17280, 17280, 135, 1080, 17280, 135, 135, 1080, 1080, 135, 135, 17280, 17280, 17280, 17280, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 17280, 1080, 1080, 1080, 17280, 135, 1080, 1080, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 1080, 135, 17280, 17280, 17280, 1080, 135, 17280, 17280, 1080, 1080, 17280, 17280, 135, 17280, 17280, 1080, 135, 17280, 1080, 1080, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 1080, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 17280, 135, 135, 135, 1080, 135, 1080, 1080, 135, 17280, 1080, 17280, 135, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 17280, 17280, 135, 17280, 17280, 135, 17280, 1080, 17280, 1080, 1080, 1080, 135, 1080, 135, 135, 17280, 135, 1080, 135, 135, 1080, 17280, 1080, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2367360 . Total input tokens: 527217306 . Total output tokens: 473385958
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 84.69118627300486,
    "estimated_duration": 3600.039953399705,
    "input_throughput": 5299.876736640654,
    "output_throughput": 4681.2069360744945,
    "total_throughput": 9981.083672715149,
    "itl": 182.37226098392424,
    "ttft": 2092024.1059685072,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 538,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7549241826590196,
    "arrivals": 788332,
    "finished_requests": 77275,
    "scheduler_time": 136.85233338511125
}
#Debug simulation 
Total elapsed time: 84.69135934766382. Arrivals time: 0.39340111752972007 Scheduler time: 84.15748088713735 Scheduler overhead time: 0.052197236102074385 Adapter cache time: 0.017194837797433138 Engine time: 0.051525612361729145 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-32/adapters_384_slots_96_rate_1.6-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-32/adapters_384_slots_96_rate_1.6-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 1080, 135, 17280, 17280, 135, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 135, 17280, 135, 17280, 1080, 1080, 1080, 135, 135, 1080, 135, 17280, 135, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 17280, 135, 17280, 17280, 17280, 17280, 135, 1080, 1080, 1080, 17280, 1080, 135, 1080, 135, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 135, 135, 17280, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 17280, 135, 1080, 17280, 135, 17280, 1080, 135, 17280, 17280, 17280, 17280, 1080, 135, 1080, 17280, 17280, 1080, 135, 135, 17280, 1080, 1080, 135, 135, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 135, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 17280, 135, 135, 135, 1080, 1080, 17280, 135, 135, 17280, 135, 17280, 1080, 135, 17280, 1080, 1080, 135, 17280, 17280, 17280, 135, 1080, 17280, 135, 17280, 1080, 1080, 17280, 17280, 135, 1080, 17280, 135, 1080, 1080, 135, 1080, 135, 1080, 17280, 17280, 1080, 135, 17280, 135, 17280, 1080, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 17280, 135, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 17280, 17280, 135, 135, 17280, 135, 135, 135, 1080, 135, 1080, 17280, 17280, 1080, 1080, 135, 17280, 1080, 17280, 135, 1080, 1080, 135, 135, 1080, 135, 17280, 17280, 135, 17280, 17280, 135, 1080, 17280, 135, 135, 1080, 1080, 135, 135, 17280, 17280, 17280, 17280, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 17280, 1080, 1080, 1080, 17280, 135, 1080, 1080, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 1080, 135, 17280, 17280, 17280, 1080, 135, 17280, 17280, 1080, 1080, 17280, 17280, 135, 17280, 17280, 1080, 135, 17280, 1080, 1080, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 1080, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 17280, 135, 135, 135, 1080, 135, 1080, 1080, 135, 17280, 1080, 17280, 135, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 17280, 17280, 135, 17280, 17280, 135, 17280, 1080, 17280, 1080, 1080, 1080, 135, 1080, 135, 135, 17280, 135, 1080, 135, 135, 1080, 17280, 1080, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2367360 . Total input tokens: 527217306 . Total output tokens: 473385958
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 84.01229186309502,
    "estimated_duration": 3600.14698974832,
    "input_throughput": 5289.090154991466,
    "output_throughput": 4671.615644553378,
    "total_throughput": 9960.705799544843,
    "itl": 180.7698798992917,
    "ttft": 2092924.9703016335,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 535,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7483426921442258,
    "arrivals": 788332,
    "finished_requests": 77118,
    "scheduler_time": 137.31240723735272
}
#Debug simulation 
Total elapsed time: 84.01246180431917. Arrivals time: 0.40376833407208323 Scheduler time: 83.4692158526741 Scheduler overhead time: 0.051889460533857346 Adapter cache time: 0.016897710971534252 Engine time: 0.05154975829645991 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-16/adapters_384_slots_96_rate_1.6-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-16/adapters_384_slots_96_rate_1.6-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 1080, 135, 17280, 17280, 135, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 135, 17280, 135, 17280, 1080, 1080, 1080, 135, 135, 1080, 135, 17280, 135, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 17280, 135, 17280, 17280, 17280, 17280, 135, 1080, 1080, 1080, 17280, 1080, 135, 1080, 135, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 135, 135, 17280, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 17280, 135, 1080, 17280, 135, 17280, 1080, 135, 17280, 17280, 17280, 17280, 1080, 135, 1080, 17280, 17280, 1080, 135, 135, 17280, 1080, 1080, 135, 135, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 135, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 17280, 135, 135, 135, 1080, 1080, 17280, 135, 135, 17280, 135, 17280, 1080, 135, 17280, 1080, 1080, 135, 17280, 17280, 17280, 135, 1080, 17280, 135, 17280, 1080, 1080, 17280, 17280, 135, 1080, 17280, 135, 1080, 1080, 135, 1080, 135, 1080, 17280, 17280, 1080, 135, 17280, 135, 17280, 1080, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 17280, 135, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 17280, 17280, 135, 135, 17280, 135, 135, 135, 1080, 135, 1080, 17280, 17280, 1080, 1080, 135, 17280, 1080, 17280, 135, 1080, 1080, 135, 135, 1080, 135, 17280, 17280, 135, 17280, 17280, 135, 1080, 17280, 135, 135, 1080, 1080, 135, 135, 17280, 17280, 17280, 17280, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 17280, 1080, 1080, 1080, 17280, 135, 1080, 1080, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 1080, 135, 17280, 17280, 17280, 1080, 135, 17280, 17280, 1080, 1080, 17280, 17280, 135, 17280, 17280, 1080, 135, 17280, 1080, 1080, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 1080, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 17280, 135, 135, 135, 1080, 135, 1080, 1080, 135, 17280, 1080, 17280, 135, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 17280, 17280, 135, 17280, 17280, 135, 17280, 1080, 17280, 1080, 1080, 1080, 135, 1080, 135, 135, 17280, 135, 1080, 135, 135, 1080, 17280, 1080, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2367360 . Total input tokens: 527217306 . Total output tokens: 473385958
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 84.54725142894313,
    "estimated_duration": 3600.1654661860402,
    "input_throughput": 5299.90445695087,
    "output_throughput": 4681.207616230467,
    "total_throughput": 9981.112073181337,
    "itl": 182.36972183506415,
    "ttft": 2092027.363861493,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 538,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6801512393844218,
    "arrivals": 788332,
    "finished_requests": 77278,
    "scheduler_time": 136.85964570397476
}
#Debug simulation 
Total elapsed time: 84.54742176597938. Arrivals time: 0.41928967321291566 Scheduler time: 83.98838720051572 Scheduler overhead time: 0.051768370904028416 Adapter cache time: 0.016707612667232752 Engine time: 0.05162281030789018 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-32/adapters_384_slots_96_rate_1.6-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-32/adapters_384_slots_96_rate_1.6-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 1080, 135, 17280, 17280, 135, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 135, 17280, 135, 17280, 1080, 1080, 1080, 135, 135, 1080, 135, 17280, 135, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 17280, 135, 17280, 17280, 17280, 17280, 135, 1080, 1080, 1080, 17280, 1080, 135, 1080, 135, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 135, 135, 17280, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 17280, 135, 1080, 17280, 135, 17280, 1080, 135, 17280, 17280, 17280, 17280, 1080, 135, 1080, 17280, 17280, 1080, 135, 135, 17280, 1080, 1080, 135, 135, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 135, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 17280, 135, 135, 135, 1080, 1080, 17280, 135, 135, 17280, 135, 17280, 1080, 135, 17280, 1080, 1080, 135, 17280, 17280, 17280, 135, 1080, 17280, 135, 17280, 1080, 1080, 17280, 17280, 135, 1080, 17280, 135, 1080, 1080, 135, 1080, 135, 1080, 17280, 17280, 1080, 135, 17280, 135, 17280, 1080, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 17280, 135, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 17280, 17280, 135, 135, 17280, 135, 135, 135, 1080, 135, 1080, 17280, 17280, 1080, 1080, 135, 17280, 1080, 17280, 135, 1080, 1080, 135, 135, 1080, 135, 17280, 17280, 135, 17280, 17280, 135, 1080, 17280, 135, 135, 1080, 1080, 135, 135, 17280, 17280, 17280, 17280, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 17280, 1080, 1080, 1080, 17280, 135, 1080, 1080, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 1080, 135, 17280, 17280, 17280, 1080, 135, 17280, 17280, 1080, 1080, 17280, 17280, 135, 17280, 17280, 1080, 135, 17280, 1080, 1080, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 1080, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 17280, 135, 135, 135, 1080, 135, 1080, 1080, 135, 17280, 1080, 17280, 135, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 17280, 17280, 135, 17280, 17280, 135, 17280, 1080, 17280, 1080, 1080, 1080, 135, 1080, 135, 135, 17280, 135, 1080, 135, 135, 1080, 17280, 1080, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2367360 . Total input tokens: 527217306 . Total output tokens: 473385958
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 83.94132883427665,
    "estimated_duration": 3600.170012453824,
    "input_throughput": 5289.056331820726,
    "output_throughput": 4671.585770066662,
    "total_throughput": 9960.642101887388,
    "itl": 180.7708498760469,
    "ttft": 2092930.4164884356,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 535,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7712298812717235,
    "arrivals": 788332,
    "finished_requests": 77118,
    "scheduler_time": 137.31254275377503
}
#Debug simulation 
Total elapsed time: 83.94149432796985. Arrivals time: 0.4121456816792488 Scheduler time: 83.39034777740017 Scheduler overhead time: 0.05150930676609278 Adapter cache time: 0.017116406466811895 Engine time: 0.05132419057190418 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-16/adapters_384_slots_96_rate_1.6-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-16/adapters_384_slots_96_rate_1.6-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 1080, 135, 17280, 17280, 135, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 135, 17280, 135, 17280, 1080, 1080, 1080, 135, 135, 1080, 135, 17280, 135, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 17280, 135, 17280, 17280, 17280, 17280, 135, 1080, 1080, 1080, 17280, 1080, 135, 1080, 135, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 135, 135, 17280, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 17280, 135, 1080, 17280, 135, 17280, 1080, 135, 17280, 17280, 17280, 17280, 1080, 135, 1080, 17280, 17280, 1080, 135, 135, 17280, 1080, 1080, 135, 135, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 135, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 17280, 135, 135, 135, 1080, 1080, 17280, 135, 135, 17280, 135, 17280, 1080, 135, 17280, 1080, 1080, 135, 17280, 17280, 17280, 135, 1080, 17280, 135, 17280, 1080, 1080, 17280, 17280, 135, 1080, 17280, 135, 1080, 1080, 135, 1080, 135, 1080, 17280, 17280, 1080, 135, 17280, 135, 17280, 1080, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 17280, 135, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 17280, 17280, 135, 135, 17280, 135, 135, 135, 1080, 135, 1080, 17280, 17280, 1080, 1080, 135, 17280, 1080, 17280, 135, 1080, 1080, 135, 135, 1080, 135, 17280, 17280, 135, 17280, 17280, 135, 1080, 17280, 135, 135, 1080, 1080, 135, 135, 17280, 17280, 17280, 17280, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 17280, 1080, 1080, 1080, 17280, 135, 1080, 1080, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 1080, 135, 17280, 17280, 17280, 1080, 135, 17280, 17280, 1080, 1080, 17280, 17280, 135, 17280, 17280, 1080, 135, 17280, 1080, 1080, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 1080, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 17280, 135, 135, 135, 1080, 135, 1080, 1080, 135, 17280, 1080, 17280, 135, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 17280, 17280, 135, 17280, 17280, 135, 17280, 1080, 17280, 1080, 1080, 1080, 135, 1080, 135, 135, 17280, 135, 1080, 135, 135, 1080, 17280, 1080, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2367360 . Total input tokens: 527217306 . Total output tokens: 473385958
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 85.20565278455615,
    "estimated_duration": 3600.0934572627243,
    "input_throughput": 5300.010465424859,
    "output_throughput": 4681.301249555341,
    "total_throughput": 9981.3117149802,
    "itl": 182.3667846725878,
    "ttft": 2092007.8455025433,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 538,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6086470586573502,
    "arrivals": 788332,
    "finished_requests": 77278,
    "scheduler_time": 136.85914096136634
}
#Debug simulation 
Total elapsed time: 85.20582024473697. Arrivals time: 0.41755325719714165 Scheduler time: 84.64930594572797 Scheduler overhead time: 0.051759228110313416 Adapter cache time: 0.017151826061308384 Engine time: 0.05122235603630543 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-32/adapters_384_slots_96_rate_1.6-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-32/adapters_384_slots_96_rate_1.6-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 1080, 135, 17280, 17280, 135, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 135, 17280, 135, 17280, 1080, 1080, 1080, 135, 135, 1080, 135, 17280, 135, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 17280, 135, 17280, 17280, 17280, 17280, 135, 1080, 1080, 1080, 17280, 1080, 135, 1080, 135, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 135, 135, 17280, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 17280, 135, 1080, 17280, 135, 17280, 1080, 135, 17280, 17280, 17280, 17280, 1080, 135, 1080, 17280, 17280, 1080, 135, 135, 17280, 1080, 1080, 135, 135, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 135, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 17280, 135, 135, 135, 1080, 1080, 17280, 135, 135, 17280, 135, 17280, 1080, 135, 17280, 1080, 1080, 135, 17280, 17280, 17280, 135, 1080, 17280, 135, 17280, 1080, 1080, 17280, 17280, 135, 1080, 17280, 135, 1080, 1080, 135, 1080, 135, 1080, 17280, 17280, 1080, 135, 17280, 135, 17280, 1080, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 17280, 135, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 17280, 17280, 135, 135, 17280, 135, 135, 135, 1080, 135, 1080, 17280, 17280, 1080, 1080, 135, 17280, 1080, 17280, 135, 1080, 1080, 135, 135, 1080, 135, 17280, 17280, 135, 17280, 17280, 135, 1080, 17280, 135, 135, 1080, 1080, 135, 135, 17280, 17280, 17280, 17280, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 17280, 1080, 1080, 1080, 17280, 135, 1080, 1080, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 1080, 135, 17280, 17280, 17280, 1080, 135, 17280, 17280, 1080, 1080, 17280, 17280, 135, 17280, 17280, 1080, 135, 17280, 1080, 1080, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 1080, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 17280, 135, 135, 135, 1080, 135, 1080, 1080, 135, 17280, 1080, 17280, 135, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 17280, 17280, 135, 17280, 17280, 135, 17280, 1080, 17280, 1080, 1080, 1080, 135, 1080, 135, 135, 17280, 135, 1080, 135, 135, 1080, 17280, 1080, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2367360 . Total input tokens: 527217306 . Total output tokens: 473385958
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 83.57537855394185,
    "estimated_duration": 3600.1920570012117,
    "input_throughput": 5289.023946089327,
    "output_throughput": 4671.557165205517,
    "total_throughput": 9960.581111294845,
    "itl": 180.7717128057971,
    "ttft": 2092936.4023286076,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 535,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7931110401079031,
    "arrivals": 788332,
    "finished_requests": 77118,
    "scheduler_time": 137.3127061423693
}
#Debug simulation 
Total elapsed time: 83.57554477779195. Arrivals time: 0.40845187846571207 Scheduler time: 83.02918442478403 Scheduler overhead time: 0.05134112387895584 Adapter cache time: 0.01635179203003645 Engine time: 0.05140389269217849 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-8/adapters_384_slots_96_rate_1.6-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-8/adapters_384_slots_96_rate_1.6-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 1080, 66, 17280, 17280, 66, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 66, 17280, 66, 17280, 1080, 1080, 1080, 66, 66, 1080, 66, 17280, 66, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 17280, 66, 17280, 17280, 17280, 17280, 66, 1080, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 66, 66, 17280, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 17280, 66, 1080, 17280, 66, 17280, 1080, 66, 17280, 17280, 17280, 17280, 1080, 66, 1080, 17280, 17280, 1080, 66, 66, 17280, 1080, 1080, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 66, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 17280, 66, 66, 66, 1080, 1080, 17280, 66, 66, 17280, 66, 17280, 1080, 66, 17280, 1080, 1080, 66, 17280, 17280, 17280, 66, 1080, 17280, 66, 17280, 1080, 1080, 17280, 17280, 66, 1080, 17280, 66, 1080, 1080, 66, 1080, 66, 1080, 17280, 17280, 1080, 66, 17280, 66, 17280, 1080, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 17280, 66, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 17280, 17280, 66, 66, 17280, 66, 66, 66, 1080, 66, 1080, 17280, 17280, 1080, 1080, 66, 17280, 1080, 17280, 66, 1080, 1080, 66, 66, 1080, 66, 17280, 17280, 66, 17280, 17280, 66, 1080, 17280, 66, 66, 1080, 1080, 66, 66, 17280, 17280, 17280, 17280, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 17280, 1080, 1080, 1080, 17280, 66, 1080, 1080, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 1080, 66, 17280, 17280, 17280, 1080, 66, 17280, 17280, 1080, 1080, 17280, 17280, 66, 17280, 17280, 1080, 66, 17280, 1080, 1080, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 1080, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 17280, 66, 66, 66, 1080, 66, 1080, 1080, 66, 17280, 1080, 17280, 66, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 17280, 17280, 66, 17280, 17280, 66, 17280, 1080, 17280, 1080, 1080, 1080, 66, 1080, 66, 66, 17280, 66, 1080, 66, 66, 1080, 17280, 1080, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2358528 . Total input tokens: 525253595 . Total output tokens: 471618938
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 67.27852497482672,
    "estimated_duration": 3600.083042930679,
    "input_throughput": 5310.055010408297,
    "output_throughput": 4687.448816809124,
    "total_throughput": 9997.50382721742,
    "itl": 183.26560034354947,
    "ttft": 2095454.374308122,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 662,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.026042886483517,
    "arrivals": 785377,
    "finished_requests": 77426,
    "scheduler_time": 136.4479350568973
}
#Debug simulation 
Total elapsed time: 67.27870407095179. Arrivals time: 0.3842152478173375 Scheduler time: 66.7595141902566 Scheduler overhead time: 0.04918195027858019 Adapter cache time: 0.01852780394256115 Engine time: 0.04888868471607566 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-16/adapters_384_slots_96_rate_1.6-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-16/adapters_384_slots_96_rate_1.6-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 1080, 66, 17280, 17280, 66, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 66, 17280, 66, 17280, 1080, 1080, 1080, 66, 66, 1080, 66, 17280, 66, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 17280, 66, 17280, 17280, 17280, 17280, 66, 1080, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 66, 66, 17280, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 17280, 66, 1080, 17280, 66, 17280, 1080, 66, 17280, 17280, 17280, 17280, 1080, 66, 1080, 17280, 17280, 1080, 66, 66, 17280, 1080, 1080, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 66, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 17280, 66, 66, 66, 1080, 1080, 17280, 66, 66, 17280, 66, 17280, 1080, 66, 17280, 1080, 1080, 66, 17280, 17280, 17280, 66, 1080, 17280, 66, 17280, 1080, 1080, 17280, 17280, 66, 1080, 17280, 66, 1080, 1080, 66, 1080, 66, 1080, 17280, 17280, 1080, 66, 17280, 66, 17280, 1080, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 17280, 66, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 17280, 17280, 66, 66, 17280, 66, 66, 66, 1080, 66, 1080, 17280, 17280, 1080, 1080, 66, 17280, 1080, 17280, 66, 1080, 1080, 66, 66, 1080, 66, 17280, 17280, 66, 17280, 17280, 66, 1080, 17280, 66, 66, 1080, 1080, 66, 66, 17280, 17280, 17280, 17280, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 17280, 1080, 1080, 1080, 17280, 66, 1080, 1080, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 1080, 66, 17280, 17280, 17280, 1080, 66, 17280, 17280, 1080, 1080, 17280, 17280, 66, 17280, 17280, 1080, 66, 17280, 1080, 1080, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 1080, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 17280, 66, 66, 66, 1080, 66, 1080, 1080, 66, 17280, 1080, 17280, 66, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 17280, 17280, 66, 17280, 17280, 66, 17280, 1080, 17280, 1080, 1080, 1080, 66, 1080, 66, 66, 17280, 66, 1080, 66, 66, 1080, 17280, 1080, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2358528 . Total input tokens: 525253595 . Total output tokens: 471618938
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 67.81534237088636,
    "estimated_duration": 3600.01541697151,
    "input_throughput": 5311.365587452238,
    "output_throughput": 4686.945205972025,
    "total_throughput": 9998.310793424263,
    "itl": 183.2486436090466,
    "ttft": 2095506.774169627,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 659,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1449133453145657,
    "arrivals": 785377,
    "finished_requests": 77423,
    "scheduler_time": 136.44509429734748
}
#Debug simulation 
Total elapsed time: 67.8154980931431. Arrivals time: 0.39187755063176155 Scheduler time: 67.28846878837794 Scheduler overhead time: 0.049499273765832186 Adapter cache time: 0.018275621812790632 Engine time: 0.04870752291753888 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-32/adapters_384_slots_96_rate_1.6-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-32/adapters_384_slots_96_rate_1.6-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 1080, 66, 17280, 17280, 66, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 66, 17280, 66, 17280, 1080, 1080, 1080, 66, 66, 1080, 66, 17280, 66, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 17280, 66, 17280, 17280, 17280, 17280, 66, 1080, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 66, 66, 17280, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 17280, 66, 1080, 17280, 66, 17280, 1080, 66, 17280, 17280, 17280, 17280, 1080, 66, 1080, 17280, 17280, 1080, 66, 66, 17280, 1080, 1080, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 66, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 17280, 66, 66, 66, 1080, 1080, 17280, 66, 66, 17280, 66, 17280, 1080, 66, 17280, 1080, 1080, 66, 17280, 17280, 17280, 66, 1080, 17280, 66, 17280, 1080, 1080, 17280, 17280, 66, 1080, 17280, 66, 1080, 1080, 66, 1080, 66, 1080, 17280, 17280, 1080, 66, 17280, 66, 17280, 1080, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 17280, 66, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 17280, 17280, 66, 66, 17280, 66, 66, 66, 1080, 66, 1080, 17280, 17280, 1080, 1080, 66, 17280, 1080, 17280, 66, 1080, 1080, 66, 66, 1080, 66, 17280, 17280, 66, 17280, 17280, 66, 1080, 17280, 66, 66, 1080, 1080, 66, 66, 17280, 17280, 17280, 17280, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 17280, 1080, 1080, 1080, 17280, 66, 1080, 1080, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 1080, 66, 17280, 17280, 17280, 1080, 66, 17280, 17280, 1080, 1080, 17280, 17280, 66, 17280, 17280, 1080, 66, 17280, 1080, 1080, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 1080, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 17280, 66, 66, 66, 1080, 66, 1080, 1080, 66, 17280, 1080, 17280, 66, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 17280, 17280, 66, 17280, 17280, 66, 17280, 1080, 17280, 1080, 1080, 1080, 66, 1080, 66, 66, 17280, 66, 1080, 66, 66, 1080, 17280, 1080, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2358528 . Total input tokens: 525253595 . Total output tokens: 471618938
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 65.58362193824723,
    "estimated_duration": 3600.163018994005,
    "input_throughput": 5298.145083810651,
    "output_throughput": 4675.234124454526,
    "total_throughput": 9973.379208265176,
    "itl": 181.49214391693536,
    "ttft": 2096692.776309134,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 644,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0996466013416737,
    "arrivals": 785377,
    "finished_requests": 77243,
    "scheduler_time": 136.94727931716434
}
#Debug simulation 
Total elapsed time: 65.58378005214036. Arrivals time: 0.32292074896395206 Scheduler time: 65.13530692318454 Scheduler overhead time: 0.04638394480571151 Adapter cache time: 0.01646196562796831 Engine time: 0.04520237632095814 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-16/adapters_384_slots_96_rate_1.6-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-16/adapters_384_slots_96_rate_1.6-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 1080, 66, 17280, 17280, 66, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 66, 17280, 66, 17280, 1080, 1080, 1080, 66, 66, 1080, 66, 17280, 66, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 17280, 66, 17280, 17280, 17280, 17280, 66, 1080, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 66, 66, 17280, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 17280, 66, 1080, 17280, 66, 17280, 1080, 66, 17280, 17280, 17280, 17280, 1080, 66, 1080, 17280, 17280, 1080, 66, 66, 17280, 1080, 1080, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 66, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 17280, 66, 66, 66, 1080, 1080, 17280, 66, 66, 17280, 66, 17280, 1080, 66, 17280, 1080, 1080, 66, 17280, 17280, 17280, 66, 1080, 17280, 66, 17280, 1080, 1080, 17280, 17280, 66, 1080, 17280, 66, 1080, 1080, 66, 1080, 66, 1080, 17280, 17280, 1080, 66, 17280, 66, 17280, 1080, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 17280, 66, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 17280, 17280, 66, 66, 17280, 66, 66, 66, 1080, 66, 1080, 17280, 17280, 1080, 1080, 66, 17280, 1080, 17280, 66, 1080, 1080, 66, 66, 1080, 66, 17280, 17280, 66, 17280, 17280, 66, 1080, 17280, 66, 66, 1080, 1080, 66, 66, 17280, 17280, 17280, 17280, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 17280, 1080, 1080, 1080, 17280, 66, 1080, 1080, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 1080, 66, 17280, 17280, 17280, 1080, 66, 17280, 17280, 1080, 1080, 17280, 17280, 66, 17280, 17280, 1080, 66, 17280, 1080, 1080, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 1080, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 17280, 66, 66, 66, 1080, 66, 1080, 1080, 66, 17280, 1080, 17280, 66, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 17280, 17280, 66, 17280, 17280, 66, 17280, 1080, 17280, 1080, 1080, 1080, 66, 1080, 66, 66, 17280, 66, 1080, 66, 66, 1080, 17280, 1080, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2358528 . Total input tokens: 525253595 . Total output tokens: 471618938
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 66.38543599611148,
    "estimated_duration": 3600.0513245854686,
    "input_throughput": 5311.0337259432235,
    "output_throughput": 4686.856235846262,
    "total_throughput": 9997.889961789486,
    "itl": 183.24247446515614,
    "ttft": 2095545.9328436037,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 658,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.053258110918088,
    "arrivals": 785377,
    "finished_requests": 77423,
    "scheduler_time": 136.44999257517352
}
#Debug simulation 
Total elapsed time: 66.38558748783544. Arrivals time: 0.63776720687747 Scheduler time: 65.61977884965017 Scheduler overhead time: 0.047098209615796804 Adapter cache time: 0.017277339939028025 Engine time: 0.04581320146098733 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-32/adapters_384_slots_96_rate_1.6-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-32/adapters_384_slots_96_rate_1.6-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 1080, 66, 17280, 17280, 66, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 66, 17280, 66, 17280, 1080, 1080, 1080, 66, 66, 1080, 66, 17280, 66, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 17280, 66, 17280, 17280, 17280, 17280, 66, 1080, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 66, 66, 17280, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 17280, 66, 1080, 17280, 66, 17280, 1080, 66, 17280, 17280, 17280, 17280, 1080, 66, 1080, 17280, 17280, 1080, 66, 66, 17280, 1080, 1080, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 66, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 17280, 66, 66, 66, 1080, 1080, 17280, 66, 66, 17280, 66, 17280, 1080, 66, 17280, 1080, 1080, 66, 17280, 17280, 17280, 66, 1080, 17280, 66, 17280, 1080, 1080, 17280, 17280, 66, 1080, 17280, 66, 1080, 1080, 66, 1080, 66, 1080, 17280, 17280, 1080, 66, 17280, 66, 17280, 1080, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 17280, 66, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 17280, 17280, 66, 66, 17280, 66, 66, 66, 1080, 66, 1080, 17280, 17280, 1080, 1080, 66, 17280, 1080, 17280, 66, 1080, 1080, 66, 66, 1080, 66, 17280, 17280, 66, 17280, 17280, 66, 1080, 17280, 66, 66, 1080, 1080, 66, 66, 17280, 17280, 17280, 17280, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 17280, 1080, 1080, 1080, 17280, 66, 1080, 1080, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 1080, 66, 17280, 17280, 17280, 1080, 66, 17280, 17280, 1080, 1080, 17280, 17280, 66, 17280, 17280, 1080, 66, 17280, 1080, 1080, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 1080, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 17280, 66, 66, 66, 1080, 66, 1080, 1080, 66, 17280, 1080, 17280, 66, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 17280, 17280, 66, 17280, 17280, 66, 17280, 1080, 17280, 1080, 1080, 1080, 66, 1080, 66, 66, 17280, 66, 1080, 66, 66, 1080, 17280, 1080, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2358528 . Total input tokens: 525253595 . Total output tokens: 471618938
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 65.62291143508628,
    "estimated_duration": 3600.1895277250255,
    "input_throughput": 5298.106072780301,
    "output_throughput": 4675.199700010227,
    "total_throughput": 9973.305772790527,
    "itl": 181.49333777005148,
    "ttft": 2096698.657196297,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 644,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.126054896488789,
    "arrivals": 785377,
    "finished_requests": 77243,
    "scheduler_time": 136.94737975309437
}
#Debug simulation 
Total elapsed time: 65.62307722913101. Arrivals time: 0.3436218099668622 Scheduler time: 65.1521800677292 Scheduler overhead time: 0.04672012524679303 Adapter cache time: 0.01707264268770814 Engine time: 0.04596345825120807 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-16/adapters_384_slots_96_rate_1.6-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-16/adapters_384_slots_96_rate_1.6-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 1080, 66, 17280, 17280, 66, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 66, 17280, 66, 17280, 1080, 1080, 1080, 66, 66, 1080, 66, 17280, 66, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 17280, 66, 17280, 17280, 17280, 17280, 66, 1080, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 66, 66, 17280, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 17280, 66, 1080, 17280, 66, 17280, 1080, 66, 17280, 17280, 17280, 17280, 1080, 66, 1080, 17280, 17280, 1080, 66, 66, 17280, 1080, 1080, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 66, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 17280, 66, 66, 66, 1080, 1080, 17280, 66, 66, 17280, 66, 17280, 1080, 66, 17280, 1080, 1080, 66, 17280, 17280, 17280, 66, 1080, 17280, 66, 17280, 1080, 1080, 17280, 17280, 66, 1080, 17280, 66, 1080, 1080, 66, 1080, 66, 1080, 17280, 17280, 1080, 66, 17280, 66, 17280, 1080, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 17280, 66, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 17280, 17280, 66, 66, 17280, 66, 66, 66, 1080, 66, 1080, 17280, 17280, 1080, 1080, 66, 17280, 1080, 17280, 66, 1080, 1080, 66, 66, 1080, 66, 17280, 17280, 66, 17280, 17280, 66, 1080, 17280, 66, 66, 1080, 1080, 66, 66, 17280, 17280, 17280, 17280, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 17280, 1080, 1080, 1080, 17280, 66, 1080, 1080, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 1080, 66, 17280, 17280, 17280, 1080, 66, 17280, 17280, 1080, 1080, 17280, 17280, 66, 17280, 17280, 1080, 66, 17280, 1080, 1080, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 1080, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 17280, 66, 66, 66, 1080, 66, 1080, 1080, 66, 17280, 1080, 17280, 66, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 17280, 17280, 66, 17280, 17280, 66, 17280, 1080, 17280, 1080, 1080, 1080, 66, 1080, 66, 66, 17280, 66, 1080, 66, 66, 1080, 17280, 1080, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2358528 . Total input tokens: 525253595 . Total output tokens: 471618938
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 66.41842783102766,
    "estimated_duration": 3600.035750398474,
    "input_throughput": 5310.124766923232,
    "output_throughput": 4687.510394343209,
    "total_throughput": 9997.63516126644,
    "itl": 183.2635673431147,
    "ttft": 2095443.913710968,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 662,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9794132952252068,
    "arrivals": 785377,
    "finished_requests": 77426,
    "scheduler_time": 136.44771956802612
}
#Debug simulation 
Total elapsed time: 66.41858879011124. Arrivals time: 0.6463715150021017 Scheduler time: 65.64425846235827 Scheduler overhead time: 0.046874263789504766 Adapter cache time: 0.01735760597512126 Engine time: 0.04545821063220501 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-32/adapters_384_slots_96_rate_1.6-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-32/adapters_384_slots_96_rate_1.6-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 1080, 66, 17280, 17280, 66, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 66, 17280, 66, 17280, 1080, 1080, 1080, 66, 66, 1080, 66, 17280, 66, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 17280, 66, 17280, 17280, 17280, 17280, 66, 1080, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 66, 66, 17280, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 17280, 66, 1080, 17280, 66, 17280, 1080, 66, 17280, 17280, 17280, 17280, 1080, 66, 1080, 17280, 17280, 1080, 66, 66, 17280, 1080, 1080, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 66, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 17280, 66, 66, 66, 1080, 1080, 17280, 66, 66, 17280, 66, 17280, 1080, 66, 17280, 1080, 1080, 66, 17280, 17280, 17280, 66, 1080, 17280, 66, 17280, 1080, 1080, 17280, 17280, 66, 1080, 17280, 66, 1080, 1080, 66, 1080, 66, 1080, 17280, 17280, 1080, 66, 17280, 66, 17280, 1080, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 17280, 66, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 17280, 17280, 66, 66, 17280, 66, 66, 66, 1080, 66, 1080, 17280, 17280, 1080, 1080, 66, 17280, 1080, 17280, 66, 1080, 1080, 66, 66, 1080, 66, 17280, 17280, 66, 17280, 17280, 66, 1080, 17280, 66, 66, 1080, 1080, 66, 66, 17280, 17280, 17280, 17280, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 17280, 1080, 1080, 1080, 17280, 66, 1080, 1080, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 1080, 66, 17280, 17280, 17280, 1080, 66, 17280, 17280, 1080, 1080, 17280, 17280, 66, 17280, 17280, 1080, 66, 17280, 1080, 1080, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 1080, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 17280, 66, 66, 66, 1080, 66, 1080, 1080, 66, 17280, 1080, 17280, 66, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 17280, 17280, 66, 17280, 17280, 66, 17280, 1080, 17280, 1080, 1080, 1080, 66, 1080, 66, 66, 17280, 66, 1080, 66, 66, 1080, 17280, 1080, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2358528 . Total input tokens: 525253595 . Total output tokens: 471618938
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 65.66172578092664,
    "estimated_duration": 3600.0158285851776,
    "input_throughput": 5297.641707174166,
    "output_throughput": 4675.018055855137,
    "total_throughput": 9972.659763029304,
    "itl": 181.49409735094721,
    "ttft": 2096617.144863289,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 644,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.151708668917418,
    "arrivals": 785377,
    "finished_requests": 77236,
    "scheduler_time": 136.93984265575088
}
#Debug simulation 
Total elapsed time: 65.661892559845. Arrivals time: 0.6536401095800102 Scheduler time: 64.87991425581276 Scheduler overhead time: 0.04703440656885505 Adapter cache time: 0.017154944594949484 Engine time: 0.04619242949411273 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-8/adapters_384_slots_96_rate_1.6-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-8/adapters_384_slots_96_rate_1.6-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 1080, 33, 17280, 17280, 33, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 33, 17280, 33, 17280, 1080, 1080, 1080, 33, 33, 1080, 33, 17280, 33, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 17280, 33, 17280, 17280, 17280, 17280, 33, 1080, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 33, 33, 17280, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 17280, 33, 1080, 17280, 33, 17280, 1080, 33, 17280, 17280, 17280, 17280, 1080, 33, 1080, 17280, 17280, 1080, 33, 33, 17280, 1080, 1080, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 33, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 17280, 33, 33, 33, 1080, 1080, 17280, 33, 33, 17280, 33, 17280, 1080, 33, 17280, 1080, 1080, 33, 17280, 17280, 17280, 33, 1080, 17280, 33, 17280, 1080, 1080, 17280, 17280, 33, 1080, 17280, 33, 1080, 1080, 33, 1080, 33, 1080, 17280, 17280, 1080, 33, 17280, 33, 17280, 1080, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 17280, 33, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 17280, 17280, 33, 33, 17280, 33, 33, 33, 1080, 33, 1080, 17280, 17280, 1080, 1080, 33, 17280, 1080, 17280, 33, 1080, 1080, 33, 33, 1080, 33, 17280, 17280, 33, 17280, 17280, 33, 1080, 17280, 33, 33, 1080, 1080, 33, 33, 17280, 17280, 17280, 17280, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 17280, 1080, 1080, 1080, 17280, 33, 1080, 1080, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 1080, 33, 17280, 17280, 17280, 1080, 33, 17280, 17280, 1080, 1080, 17280, 17280, 33, 17280, 17280, 1080, 33, 17280, 1080, 1080, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 1080, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 17280, 33, 33, 33, 1080, 33, 1080, 1080, 33, 17280, 1080, 17280, 33, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 17280, 17280, 33, 17280, 17280, 33, 17280, 1080, 17280, 1080, 1080, 1080, 33, 1080, 33, 33, 17280, 33, 1080, 33, 33, 1080, 17280, 1080, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2354304 . Total input tokens: 524297978 . Total output tokens: 470757468
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 78.58135576406494,
    "estimated_duration": 3600.0471982621107,
    "input_throughput": 5318.322773446597,
    "output_throughput": 4688.583529723788,
    "total_throughput": 10006.906303170384,
    "itl": 182.64393318791602,
    "ttft": 2090427.8170666334,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 503,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5394253351981926,
    "arrivals": 784050,
    "finished_requests": 77845,
    "scheduler_time": 136.48485754341007
}
#Debug simulation 
Total elapsed time: 78.58150912774727. Arrivals time: 0.3588514910079539 Scheduler time: 78.09112011408433 Scheduler overhead time: 0.04946355940774083 Adapter cache time: 0.015216090250760317 Engine time: 0.048514626920223236 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-16/adapters_384_slots_96_rate_1.6-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-16/adapters_384_slots_96_rate_1.6-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 1080, 33, 17280, 17280, 33, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 33, 17280, 33, 17280, 1080, 1080, 1080, 33, 33, 1080, 33, 17280, 33, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 17280, 33, 17280, 17280, 17280, 17280, 33, 1080, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 33, 33, 17280, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 17280, 33, 1080, 17280, 33, 17280, 1080, 33, 17280, 17280, 17280, 17280, 1080, 33, 1080, 17280, 17280, 1080, 33, 33, 17280, 1080, 1080, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 33, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 17280, 33, 33, 33, 1080, 1080, 17280, 33, 33, 17280, 33, 17280, 1080, 33, 17280, 1080, 1080, 33, 17280, 17280, 17280, 33, 1080, 17280, 33, 17280, 1080, 1080, 17280, 17280, 33, 1080, 17280, 33, 1080, 1080, 33, 1080, 33, 1080, 17280, 17280, 1080, 33, 17280, 33, 17280, 1080, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 17280, 33, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 17280, 17280, 33, 33, 17280, 33, 33, 33, 1080, 33, 1080, 17280, 17280, 1080, 1080, 33, 17280, 1080, 17280, 33, 1080, 1080, 33, 33, 1080, 33, 17280, 17280, 33, 17280, 17280, 33, 1080, 17280, 33, 33, 1080, 1080, 33, 33, 17280, 17280, 17280, 17280, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 17280, 1080, 1080, 1080, 17280, 33, 1080, 1080, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 1080, 33, 17280, 17280, 17280, 1080, 33, 17280, 17280, 1080, 1080, 17280, 17280, 33, 17280, 17280, 1080, 33, 17280, 1080, 1080, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 1080, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 17280, 33, 33, 33, 1080, 33, 1080, 1080, 33, 17280, 1080, 17280, 33, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 17280, 17280, 33, 17280, 17280, 33, 17280, 1080, 17280, 1080, 1080, 1080, 33, 1080, 33, 33, 17280, 33, 1080, 33, 33, 1080, 17280, 1080, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2354304 . Total input tokens: 524297978 . Total output tokens: 470757468
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 78.67204081779346,
    "estimated_duration": 3600.060678441493,
    "input_throughput": 5317.273710032857,
    "output_throughput": 4687.980705732507,
    "total_throughput": 10005.254415765363,
    "itl": 182.6517762144656,
    "ttft": 2090535.8842049276,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 497,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6188484750594982,
    "arrivals": 784050,
    "finished_requests": 77828,
    "scheduler_time": 136.48101754072698
}
#Debug simulation 
Total elapsed time: 78.67220958089456. Arrivals time: 0.3444895031861961 Scheduler time: 78.19925087643787 Scheduler overhead time: 0.04870612872764468 Adapter cache time: 0.0146826789714396 Engine time: 0.04719220940023661 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-32/adapters_384_slots_96_rate_1.6-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-32/adapters_384_slots_96_rate_1.6-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 1080, 33, 17280, 17280, 33, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 33, 17280, 33, 17280, 1080, 1080, 1080, 33, 33, 1080, 33, 17280, 33, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 17280, 33, 17280, 17280, 17280, 17280, 33, 1080, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 33, 33, 17280, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 17280, 33, 1080, 17280, 33, 17280, 1080, 33, 17280, 17280, 17280, 17280, 1080, 33, 1080, 17280, 17280, 1080, 33, 33, 17280, 1080, 1080, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 33, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 17280, 33, 33, 33, 1080, 1080, 17280, 33, 33, 17280, 33, 17280, 1080, 33, 17280, 1080, 1080, 33, 17280, 17280, 17280, 33, 1080, 17280, 33, 17280, 1080, 1080, 17280, 17280, 33, 1080, 17280, 33, 1080, 1080, 33, 1080, 33, 1080, 17280, 17280, 1080, 33, 17280, 33, 17280, 1080, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 17280, 33, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 17280, 17280, 33, 33, 17280, 33, 33, 33, 1080, 33, 1080, 17280, 17280, 1080, 1080, 33, 17280, 1080, 17280, 33, 1080, 1080, 33, 33, 1080, 33, 17280, 17280, 33, 17280, 17280, 33, 1080, 17280, 33, 33, 1080, 1080, 33, 33, 17280, 17280, 17280, 17280, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 17280, 1080, 1080, 1080, 17280, 33, 1080, 1080, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 1080, 33, 17280, 17280, 17280, 1080, 33, 17280, 17280, 1080, 1080, 17280, 17280, 33, 17280, 17280, 1080, 33, 17280, 1080, 1080, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 1080, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 17280, 33, 33, 33, 1080, 33, 1080, 1080, 33, 17280, 1080, 17280, 33, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 17280, 17280, 33, 17280, 17280, 33, 17280, 1080, 17280, 1080, 1080, 1080, 33, 1080, 33, 33, 17280, 33, 1080, 33, 33, 1080, 17280, 1080, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2354304 . Total input tokens: 524297978 . Total output tokens: 470757468
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 46.93310819193721,
    "estimated_duration": 3600.0546136196103,
    "input_throughput": 5306.5769968395725,
    "output_throughput": 4678.99235091433,
    "total_throughput": 9985.569347753903,
    "itl": 180.64459506196295,
    "ttft": 2094901.3394035082,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 721,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3569303823262433,
    "arrivals": 784050,
    "finished_requests": 77593,
    "scheduler_time": 137.05229777270685
}
#Debug simulation 
Total elapsed time: 46.93326736986637. Arrivals time: 0.31538491090759635 Scheduler time: 46.49551395745948 Scheduler overhead time: 0.04429581994190812 Adapter cache time: 0.017655684612691402 Engine time: 0.04351729620248079 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-16/adapters_384_slots_96_rate_1.6-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-16/adapters_384_slots_96_rate_1.6-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 1080, 33, 17280, 17280, 33, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 33, 17280, 33, 17280, 1080, 1080, 1080, 33, 33, 1080, 33, 17280, 33, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 17280, 33, 17280, 17280, 17280, 17280, 33, 1080, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 33, 33, 17280, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 17280, 33, 1080, 17280, 33, 17280, 1080, 33, 17280, 17280, 17280, 17280, 1080, 33, 1080, 17280, 17280, 1080, 33, 33, 17280, 1080, 1080, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 33, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 17280, 33, 33, 33, 1080, 1080, 17280, 33, 33, 17280, 33, 17280, 1080, 33, 17280, 1080, 1080, 33, 17280, 17280, 17280, 33, 1080, 17280, 33, 17280, 1080, 1080, 17280, 17280, 33, 1080, 17280, 33, 1080, 1080, 33, 1080, 33, 1080, 17280, 17280, 1080, 33, 17280, 33, 17280, 1080, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 17280, 33, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 17280, 17280, 33, 33, 17280, 33, 33, 33, 1080, 33, 1080, 17280, 17280, 1080, 1080, 33, 17280, 1080, 17280, 33, 1080, 1080, 33, 33, 1080, 33, 17280, 17280, 33, 17280, 17280, 33, 1080, 17280, 33, 33, 1080, 1080, 33, 33, 17280, 17280, 17280, 17280, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 17280, 1080, 1080, 1080, 17280, 33, 1080, 1080, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 1080, 33, 17280, 17280, 17280, 1080, 33, 17280, 17280, 1080, 1080, 17280, 17280, 33, 17280, 17280, 1080, 33, 17280, 1080, 1080, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 1080, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 17280, 33, 33, 33, 1080, 33, 1080, 1080, 33, 17280, 1080, 17280, 33, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 17280, 17280, 33, 17280, 17280, 33, 17280, 1080, 17280, 1080, 1080, 1080, 33, 1080, 33, 33, 17280, 33, 1080, 33, 33, 1080, 17280, 1080, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2354304 . Total input tokens: 524297978 . Total output tokens: 470757468
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 78.69309837790206,
    "estimated_duration": 3600.0831394889265,
    "input_throughput": 5318.269678271382,
    "output_throughput": 4688.536721514767,
    "total_throughput": 10006.806399786148,
    "itl": 182.64537965768585,
    "ttft": 2090438.3055170546,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 503,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5750908837444084,
    "arrivals": 784050,
    "finished_requests": 77845,
    "scheduler_time": 136.4851332216167
}
#Debug simulation 
Total elapsed time: 78.69324745889753. Arrivals time: 0.3464462314732373 Scheduler time: 78.2162271537818 Scheduler overhead time: 0.049157596193253994 Adapter cache time: 0.015457938890904188 Engine time: 0.047981610987335443 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-32/adapters_384_slots_96_rate_1.6-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-32/adapters_384_slots_96_rate_1.6-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 1080, 33, 17280, 17280, 33, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 33, 17280, 33, 17280, 1080, 1080, 1080, 33, 33, 1080, 33, 17280, 33, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 17280, 33, 17280, 17280, 17280, 17280, 33, 1080, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 33, 33, 17280, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 17280, 33, 1080, 17280, 33, 17280, 1080, 33, 17280, 17280, 17280, 17280, 1080, 33, 1080, 17280, 17280, 1080, 33, 33, 17280, 1080, 1080, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 33, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 17280, 33, 33, 33, 1080, 1080, 17280, 33, 33, 17280, 33, 17280, 1080, 33, 17280, 1080, 1080, 33, 17280, 17280, 17280, 33, 1080, 17280, 33, 17280, 1080, 1080, 17280, 17280, 33, 1080, 17280, 33, 1080, 1080, 33, 1080, 33, 1080, 17280, 17280, 1080, 33, 17280, 33, 17280, 1080, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 17280, 33, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 17280, 17280, 33, 33, 17280, 33, 33, 33, 1080, 33, 1080, 17280, 17280, 1080, 1080, 33, 17280, 1080, 17280, 33, 1080, 1080, 33, 33, 1080, 33, 17280, 17280, 33, 17280, 17280, 33, 1080, 17280, 33, 33, 1080, 1080, 33, 33, 17280, 17280, 17280, 17280, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 17280, 1080, 1080, 1080, 17280, 33, 1080, 1080, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 1080, 33, 17280, 17280, 17280, 1080, 33, 17280, 17280, 1080, 1080, 17280, 17280, 33, 17280, 17280, 1080, 33, 17280, 1080, 1080, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 1080, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 17280, 33, 33, 33, 1080, 33, 1080, 1080, 33, 17280, 1080, 17280, 33, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 17280, 17280, 33, 17280, 17280, 33, 17280, 1080, 17280, 1080, 1080, 1080, 33, 1080, 33, 33, 17280, 33, 1080, 33, 33, 1080, 17280, 1080, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2354304 . Total input tokens: 524297978 . Total output tokens: 470757468
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 47.98392125405371,
    "estimated_duration": 3600.0841651099718,
    "input_throughput": 5306.53343750824,
    "output_throughput": 4678.95394314634,
    "total_throughput": 9985.48738065458,
    "itl": 180.64590743474082,
    "ttft": 2094909.347366607,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 721,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.386356768347328,
    "arrivals": 784050,
    "finished_requests": 77593,
    "scheduler_time": 137.0524228771109
}
#Debug simulation 
Total elapsed time: 47.98408105690032. Arrivals time: 0.32894838182255626 Scheduler time: 47.531479180790484 Scheduler overhead time: 0.04504403658211231 Adapter cache time: 0.01788799511268735 Engine time: 0.043309406377375126 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-16/adapters_384_slots_96_rate_1.6-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-16/adapters_384_slots_96_rate_1.6-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 1080, 33, 17280, 17280, 33, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 33, 17280, 33, 17280, 1080, 1080, 1080, 33, 33, 1080, 33, 17280, 33, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 17280, 33, 17280, 17280, 17280, 17280, 33, 1080, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 33, 33, 17280, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 17280, 33, 1080, 17280, 33, 17280, 1080, 33, 17280, 17280, 17280, 17280, 1080, 33, 1080, 17280, 17280, 1080, 33, 33, 17280, 1080, 1080, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 33, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 17280, 33, 33, 33, 1080, 1080, 17280, 33, 33, 17280, 33, 17280, 1080, 33, 17280, 1080, 1080, 33, 17280, 17280, 17280, 33, 1080, 17280, 33, 17280, 1080, 1080, 17280, 17280, 33, 1080, 17280, 33, 1080, 1080, 33, 1080, 33, 1080, 17280, 17280, 1080, 33, 17280, 33, 17280, 1080, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 17280, 33, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 17280, 17280, 33, 33, 17280, 33, 33, 33, 1080, 33, 1080, 17280, 17280, 1080, 1080, 33, 17280, 1080, 17280, 33, 1080, 1080, 33, 33, 1080, 33, 17280, 17280, 33, 17280, 17280, 33, 1080, 17280, 33, 33, 1080, 1080, 33, 33, 17280, 17280, 17280, 17280, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 17280, 1080, 1080, 1080, 17280, 33, 1080, 1080, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 1080, 33, 17280, 17280, 17280, 1080, 33, 17280, 17280, 1080, 1080, 17280, 17280, 33, 17280, 17280, 1080, 33, 17280, 1080, 1080, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 1080, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 17280, 33, 33, 33, 1080, 33, 1080, 1080, 33, 17280, 1080, 17280, 33, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 17280, 17280, 33, 17280, 17280, 33, 17280, 1080, 17280, 1080, 1080, 1080, 33, 1080, 33, 33, 17280, 33, 1080, 33, 33, 1080, 17280, 1080, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2354304 . Total input tokens: 524297978 . Total output tokens: 470757468
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 78.42409942811355,
    "estimated_duration": 3600.0115617470005,
    "input_throughput": 5318.3754195247075,
    "output_throughput": 4688.629942013009,
    "total_throughput": 10007.005361537716,
    "itl": 182.64246850601438,
    "ttft": 2090419.3820308214,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 503,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5039952983357778,
    "arrivals": 784050,
    "finished_requests": 77845,
    "scheduler_time": 136.48465106507868
}
#Debug simulation 
Total elapsed time: 78.42425243090838. Arrivals time: 0.35547906486317515 Scheduler time: 77.93976461561397 Scheduler overhead time: 0.048641675151884556 Adapter cache time: 0.015046003740280867 Engine time: 0.0476071247830987 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-32/adapters_384_slots_96_rate_1.6-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-32/adapters_384_slots_96_rate_1.6-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 1080, 33, 17280, 17280, 33, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 33, 17280, 33, 17280, 1080, 1080, 1080, 33, 33, 1080, 33, 17280, 33, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 17280, 33, 17280, 17280, 17280, 17280, 33, 1080, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 33, 33, 17280, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 17280, 33, 1080, 17280, 33, 17280, 1080, 33, 17280, 17280, 17280, 17280, 1080, 33, 1080, 17280, 17280, 1080, 33, 33, 17280, 1080, 1080, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 33, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 17280, 33, 33, 33, 1080, 1080, 17280, 33, 33, 17280, 33, 17280, 1080, 33, 17280, 1080, 1080, 33, 17280, 17280, 17280, 33, 1080, 17280, 33, 17280, 1080, 1080, 17280, 17280, 33, 1080, 17280, 33, 1080, 1080, 33, 1080, 33, 1080, 17280, 17280, 1080, 33, 17280, 33, 17280, 1080, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 17280, 33, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 17280, 17280, 33, 33, 17280, 33, 33, 33, 1080, 33, 1080, 17280, 17280, 1080, 1080, 33, 17280, 1080, 17280, 33, 1080, 1080, 33, 33, 1080, 33, 17280, 17280, 33, 17280, 17280, 33, 1080, 17280, 33, 33, 1080, 1080, 33, 33, 17280, 17280, 17280, 17280, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 17280, 1080, 1080, 1080, 17280, 33, 1080, 1080, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 1080, 33, 17280, 17280, 17280, 1080, 33, 17280, 17280, 1080, 1080, 17280, 17280, 33, 17280, 17280, 1080, 33, 17280, 1080, 1080, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 1080, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 17280, 33, 33, 33, 1080, 33, 1080, 1080, 33, 17280, 1080, 17280, 33, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 17280, 17280, 33, 17280, 17280, 33, 17280, 1080, 17280, 1080, 1080, 1080, 33, 1080, 33, 33, 17280, 33, 1080, 33, 33, 1080, 17280, 1080, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2354304 . Total input tokens: 524297978 . Total output tokens: 470757468
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 46.68515510065481,
    "estimated_duration": 3600.1154968560822,
    "input_throughput": 5306.487254834785,
    "output_throughput": 4678.913222286929,
    "total_throughput": 9985.400477121713,
    "itl": 180.64727671471314,
    "ttft": 2094918.5070502004,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 721,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4175437073782198,
    "arrivals": 784050,
    "finished_requests": 77593,
    "scheduler_time": 137.0525676842572
}
#Debug simulation 
Total elapsed time: 46.685306258965284. Arrivals time: 0.32671107025817037 Scheduler time: 46.23504096921533 Scheduler overhead time: 0.04456544388085604 Adapter cache time: 0.017775104381144047 Engine time: 0.04371542111039162 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-8/adapters_384_slots_96_rate_1.6-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-8/adapters_384_slots_96_rate_1.6-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 540, 270, 17280, 17280, 270, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 270, 17280, 270, 17280, 540, 540, 540, 270, 270, 540, 270, 17280, 270, 17280, 540, 17280, 540, 270, 540, 17280, 540, 17280, 270, 17280, 17280, 17280, 17280, 270, 540, 540, 540, 17280, 540, 270, 540, 270, 17280, 540, 17280, 17280, 540, 17280, 17280, 270, 270, 17280, 540, 540, 270, 270, 270, 540, 270, 540, 270, 17280, 270, 540, 17280, 270, 17280, 540, 270, 17280, 17280, 17280, 17280, 540, 270, 540, 17280, 17280, 540, 270, 270, 17280, 540, 540, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 270, 540, 540, 540, 540, 270, 270, 17280, 270, 17280, 270, 270, 270, 540, 540, 17280, 270, 270, 17280, 270, 17280, 540, 270, 17280, 540, 540, 270, 17280, 17280, 17280, 270, 540, 17280, 270, 17280, 540, 540, 17280, 17280, 270, 540, 17280, 270, 540, 540, 270, 540, 270, 540, 17280, 17280, 540, 270, 17280, 270, 17280, 540, 540, 540, 540, 540, 270, 270, 17280, 270, 17280, 270, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 270, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 270, 270, 270, 270, 270, 540, 270, 270, 540, 17280, 17280, 270, 270, 17280, 270, 270, 270, 540, 270, 540, 17280, 17280, 540, 540, 270, 17280, 540, 17280, 270, 540, 540, 270, 270, 540, 270, 17280, 17280, 270, 17280, 17280, 270, 540, 17280, 270, 270, 540, 540, 270, 270, 17280, 17280, 17280, 17280, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 17280, 540, 540, 540, 17280, 270, 540, 540, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 540, 270, 17280, 17280, 17280, 540, 270, 17280, 17280, 540, 540, 17280, 17280, 270, 17280, 17280, 540, 270, 17280, 540, 540, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 540, 17280, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 17280, 270, 270, 270, 540, 270, 540, 540, 270, 17280, 540, 17280, 270, 17280, 270, 540, 540, 540, 540, 270, 540, 17280, 17280, 270, 17280, 17280, 270, 17280, 540, 17280, 540, 540, 540, 270, 540, 270, 270, 17280, 270, 540, 270, 270, 540, 17280, 540, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2315520 . Total input tokens: 515609097 . Total output tokens: 462994603
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 86.86922365380451,
    "estimated_duration": 3600.178152576145,
    "input_throughput": 5358.293723935928,
    "output_throughput": 4678.180713903929,
    "total_throughput": 10036.474437839857,
    "itl": 181.4508811174121,
    "ttft": 2079820.2096308582,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 543,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.661844844955507,
    "arrivals": 771112,
    "finished_requests": 77897,
    "scheduler_time": 136.92769579858344
}
#Debug simulation 
Total elapsed time: 86.869359690696. Arrivals time: 0.3489696360193193 Scheduler time: 86.38571886718273 Scheduler overhead time: 0.050386722199618816 Adapter cache time: 0.015744490083307028 Engine time: 0.050336002837866545 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-16/adapters_384_slots_96_rate_1.6-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-16/adapters_384_slots_96_rate_1.6-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 540, 270, 17280, 17280, 270, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 270, 17280, 270, 17280, 540, 540, 540, 270, 270, 540, 270, 17280, 270, 17280, 540, 17280, 540, 270, 540, 17280, 540, 17280, 270, 17280, 17280, 17280, 17280, 270, 540, 540, 540, 17280, 540, 270, 540, 270, 17280, 540, 17280, 17280, 540, 17280, 17280, 270, 270, 17280, 540, 540, 270, 270, 270, 540, 270, 540, 270, 17280, 270, 540, 17280, 270, 17280, 540, 270, 17280, 17280, 17280, 17280, 540, 270, 540, 17280, 17280, 540, 270, 270, 17280, 540, 540, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 270, 540, 540, 540, 540, 270, 270, 17280, 270, 17280, 270, 270, 270, 540, 540, 17280, 270, 270, 17280, 270, 17280, 540, 270, 17280, 540, 540, 270, 17280, 17280, 17280, 270, 540, 17280, 270, 17280, 540, 540, 17280, 17280, 270, 540, 17280, 270, 540, 540, 270, 540, 270, 540, 17280, 17280, 540, 270, 17280, 270, 17280, 540, 540, 540, 540, 540, 270, 270, 17280, 270, 17280, 270, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 270, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 270, 270, 270, 270, 270, 540, 270, 270, 540, 17280, 17280, 270, 270, 17280, 270, 270, 270, 540, 270, 540, 17280, 17280, 540, 540, 270, 17280, 540, 17280, 270, 540, 540, 270, 270, 540, 270, 17280, 17280, 270, 17280, 17280, 270, 540, 17280, 270, 270, 540, 540, 270, 270, 17280, 17280, 17280, 17280, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 17280, 540, 540, 540, 17280, 270, 540, 540, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 540, 270, 17280, 17280, 17280, 540, 270, 17280, 17280, 540, 540, 17280, 17280, 270, 17280, 17280, 540, 270, 17280, 540, 540, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 540, 17280, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 17280, 270, 270, 270, 540, 270, 540, 540, 270, 17280, 540, 17280, 270, 17280, 270, 540, 540, 540, 540, 270, 540, 17280, 17280, 270, 17280, 17280, 270, 17280, 540, 17280, 540, 540, 540, 270, 540, 270, 270, 17280, 270, 540, 270, 270, 540, 17280, 540, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2315520 . Total input tokens: 515609097 . Total output tokens: 462994603
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 86.43686710484326,
    "estimated_duration": 3600.1228474898285,
    "input_throughput": 5358.249653466722,
    "output_throughput": 4677.9328688026335,
    "total_throughput": 10036.182522269355,
    "itl": 181.37587987975553,
    "ttft": 2079836.5824131016,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 550,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7961165253375708,
    "arrivals": 771112,
    "finished_requests": 77915,
    "scheduler_time": 136.9762881287689
}
#Debug simulation 
Total elapsed time: 86.43701450293884. Arrivals time: 0.3534314245916903 Scheduler time: 85.95090698590502 Scheduler overhead time: 0.04958966746926308 Adapter cache time: 0.015592249110341072 Engine time: 0.049045590218156576 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-32/adapters_384_slots_96_rate_1.6-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-32/adapters_384_slots_96_rate_1.6-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 540, 270, 17280, 17280, 270, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 270, 17280, 270, 17280, 540, 540, 540, 270, 270, 540, 270, 17280, 270, 17280, 540, 17280, 540, 270, 540, 17280, 540, 17280, 270, 17280, 17280, 17280, 17280, 270, 540, 540, 540, 17280, 540, 270, 540, 270, 17280, 540, 17280, 17280, 540, 17280, 17280, 270, 270, 17280, 540, 540, 270, 270, 270, 540, 270, 540, 270, 17280, 270, 540, 17280, 270, 17280, 540, 270, 17280, 17280, 17280, 17280, 540, 270, 540, 17280, 17280, 540, 270, 270, 17280, 540, 540, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 270, 540, 540, 540, 540, 270, 270, 17280, 270, 17280, 270, 270, 270, 540, 540, 17280, 270, 270, 17280, 270, 17280, 540, 270, 17280, 540, 540, 270, 17280, 17280, 17280, 270, 540, 17280, 270, 17280, 540, 540, 17280, 17280, 270, 540, 17280, 270, 540, 540, 270, 540, 270, 540, 17280, 17280, 540, 270, 17280, 270, 17280, 540, 540, 540, 540, 540, 270, 270, 17280, 270, 17280, 270, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 270, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 270, 270, 270, 270, 270, 540, 270, 270, 540, 17280, 17280, 270, 270, 17280, 270, 270, 270, 540, 270, 540, 17280, 17280, 540, 540, 270, 17280, 540, 17280, 270, 540, 540, 270, 270, 540, 270, 17280, 17280, 270, 17280, 17280, 270, 540, 17280, 270, 270, 540, 540, 270, 270, 17280, 17280, 17280, 17280, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 17280, 540, 540, 540, 17280, 270, 540, 540, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 540, 270, 17280, 17280, 17280, 540, 270, 17280, 17280, 540, 540, 17280, 17280, 270, 17280, 17280, 540, 270, 17280, 540, 540, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 540, 17280, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 17280, 270, 270, 270, 540, 270, 540, 540, 270, 17280, 540, 17280, 270, 17280, 270, 540, 540, 540, 540, 270, 540, 17280, 17280, 270, 17280, 17280, 270, 17280, 540, 17280, 540, 540, 540, 270, 540, 270, 270, 17280, 270, 540, 270, 270, 540, 17280, 540, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2315520 . Total input tokens: 515609097 . Total output tokens: 462994603
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 85.58305157907307,
    "estimated_duration": 3600.15709546415,
    "input_throughput": 5347.012502385867,
    "output_throughput": 4668.649326768626,
    "total_throughput": 10015.661829154495,
    "itl": 179.92214119278862,
    "ttft": 2081272.7694665818,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 564,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8443614311330134,
    "arrivals": 771112,
    "finished_requests": 77757,
    "scheduler_time": 137.39045809736305
}
#Debug simulation 
Total elapsed time: 85.58320136880502. Arrivals time: 0.3566002664156258 Scheduler time: 85.09254590189084 Scheduler overhead time: 0.05038102623075247 Adapter cache time: 0.01563171437010169 Engine time: 0.049682126846164465 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-16-16/adapters_384_slots_96_rate_1.6-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-16-16/adapters_384_slots_96_rate_1.6-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 540, 270, 17280, 17280, 270, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 270, 17280, 270, 17280, 540, 540, 540, 270, 270, 540, 270, 17280, 270, 17280, 540, 17280, 540, 270, 540, 17280, 540, 17280, 270, 17280, 17280, 17280, 17280, 270, 540, 540, 540, 17280, 540, 270, 540, 270, 17280, 540, 17280, 17280, 540, 17280, 17280, 270, 270, 17280, 540, 540, 270, 270, 270, 540, 270, 540, 270, 17280, 270, 540, 17280, 270, 17280, 540, 270, 17280, 17280, 17280, 17280, 540, 270, 540, 17280, 17280, 540, 270, 270, 17280, 540, 540, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 270, 540, 540, 540, 540, 270, 270, 17280, 270, 17280, 270, 270, 270, 540, 540, 17280, 270, 270, 17280, 270, 17280, 540, 270, 17280, 540, 540, 270, 17280, 17280, 17280, 270, 540, 17280, 270, 17280, 540, 540, 17280, 17280, 270, 540, 17280, 270, 540, 540, 270, 540, 270, 540, 17280, 17280, 540, 270, 17280, 270, 17280, 540, 540, 540, 540, 540, 270, 270, 17280, 270, 17280, 270, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 270, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 270, 270, 270, 270, 270, 540, 270, 270, 540, 17280, 17280, 270, 270, 17280, 270, 270, 270, 540, 270, 540, 17280, 17280, 540, 540, 270, 17280, 540, 17280, 270, 540, 540, 270, 270, 540, 270, 17280, 17280, 270, 17280, 17280, 270, 540, 17280, 270, 270, 540, 540, 270, 270, 17280, 17280, 17280, 17280, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 17280, 540, 540, 540, 17280, 270, 540, 540, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 540, 270, 17280, 17280, 17280, 540, 270, 17280, 17280, 540, 540, 17280, 17280, 270, 17280, 17280, 540, 270, 17280, 540, 540, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 540, 17280, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 17280, 270, 270, 270, 540, 270, 540, 540, 270, 17280, 540, 17280, 270, 17280, 270, 540, 540, 540, 540, 270, 540, 17280, 17280, 270, 17280, 17280, 270, 17280, 540, 17280, 540, 540, 540, 270, 540, 270, 270, 17280, 270, 540, 270, 270, 540, 17280, 540, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2315520 . Total input tokens: 515609097 . Total output tokens: 462994603
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 86.45844743726775,
    "estimated_duration": 3600.01671387491,
    "input_throughput": 5357.926791189399,
    "output_throughput": 4677.885504001901,
    "total_throughput": 10035.8122951913,
    "itl": 181.4520271489009,
    "ttft": 2079828.0868616416,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 543,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6983702534064558,
    "arrivals": 771112,
    "finished_requests": 77889,
    "scheduler_time": 136.92075951404215
}
#Debug simulation 
Total elapsed time: 86.45858293119818. Arrivals time: 0.3622431829571724 Scheduler time: 85.96239069057629 Scheduler overhead time: 0.05049815494567156 Adapter cache time: 0.015844606794416904 Engine time: 0.049326575361192226 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-16-32/adapters_384_slots_96_rate_1.6-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-16-32/adapters_384_slots_96_rate_1.6-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 540, 270, 17280, 17280, 270, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 270, 17280, 270, 17280, 540, 540, 540, 270, 270, 540, 270, 17280, 270, 17280, 540, 17280, 540, 270, 540, 17280, 540, 17280, 270, 17280, 17280, 17280, 17280, 270, 540, 540, 540, 17280, 540, 270, 540, 270, 17280, 540, 17280, 17280, 540, 17280, 17280, 270, 270, 17280, 540, 540, 270, 270, 270, 540, 270, 540, 270, 17280, 270, 540, 17280, 270, 17280, 540, 270, 17280, 17280, 17280, 17280, 540, 270, 540, 17280, 17280, 540, 270, 270, 17280, 540, 540, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 270, 540, 540, 540, 540, 270, 270, 17280, 270, 17280, 270, 270, 270, 540, 540, 17280, 270, 270, 17280, 270, 17280, 540, 270, 17280, 540, 540, 270, 17280, 17280, 17280, 270, 540, 17280, 270, 17280, 540, 540, 17280, 17280, 270, 540, 17280, 270, 540, 540, 270, 540, 270, 540, 17280, 17280, 540, 270, 17280, 270, 17280, 540, 540, 540, 540, 540, 270, 270, 17280, 270, 17280, 270, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 270, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 270, 270, 270, 270, 270, 540, 270, 270, 540, 17280, 17280, 270, 270, 17280, 270, 270, 270, 540, 270, 540, 17280, 17280, 540, 540, 270, 17280, 540, 17280, 270, 540, 540, 270, 270, 540, 270, 17280, 17280, 270, 17280, 17280, 270, 540, 17280, 270, 270, 540, 540, 270, 270, 17280, 17280, 17280, 17280, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 17280, 540, 540, 540, 17280, 270, 540, 540, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 540, 270, 17280, 17280, 17280, 540, 270, 17280, 17280, 540, 540, 17280, 17280, 270, 17280, 17280, 540, 270, 17280, 540, 540, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 540, 17280, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 17280, 270, 270, 270, 540, 270, 540, 540, 270, 17280, 540, 17280, 270, 17280, 270, 540, 540, 540, 540, 270, 540, 17280, 17280, 270, 17280, 17280, 270, 17280, 540, 17280, 540, 540, 540, 270, 540, 270, 270, 17280, 270, 540, 270, 270, 540, 17280, 540, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2315520 . Total input tokens: 515609097 . Total output tokens: 462994603
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 85.2715013907291,
    "estimated_duration": 3600.181092002785,
    "input_throughput": 5346.976862569753,
    "output_throughput": 4668.618208493996,
    "total_throughput": 10015.595071063748,
    "itl": 179.9231710491161,
    "ttft": 2081277.3325871322,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 564,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8682546505518296,
    "arrivals": 771112,
    "finished_requests": 77757,
    "scheduler_time": 137.3905614166212
}
#Debug simulation 
Total elapsed time: 85.27165055088699. Arrivals time: 0.3590217661112547 Scheduler time: 84.77621135115623 Scheduler overhead time: 0.05127712106332183 Adapter cache time: 0.015946891624480486 Engine time: 0.05015759356319904 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_16-16-16/adapters_384_slots_96_rate_1.6-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_16-16-16/adapters_384_slots_96_rate_1.6-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 540, 270, 17280, 17280, 270, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 270, 17280, 270, 17280, 540, 540, 540, 270, 270, 540, 270, 17280, 270, 17280, 540, 17280, 540, 270, 540, 17280, 540, 17280, 270, 17280, 17280, 17280, 17280, 270, 540, 540, 540, 17280, 540, 270, 540, 270, 17280, 540, 17280, 17280, 540, 17280, 17280, 270, 270, 17280, 540, 540, 270, 270, 270, 540, 270, 540, 270, 17280, 270, 540, 17280, 270, 17280, 540, 270, 17280, 17280, 17280, 17280, 540, 270, 540, 17280, 17280, 540, 270, 270, 17280, 540, 540, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 270, 540, 540, 540, 540, 270, 270, 17280, 270, 17280, 270, 270, 270, 540, 540, 17280, 270, 270, 17280, 270, 17280, 540, 270, 17280, 540, 540, 270, 17280, 17280, 17280, 270, 540, 17280, 270, 17280, 540, 540, 17280, 17280, 270, 540, 17280, 270, 540, 540, 270, 540, 270, 540, 17280, 17280, 540, 270, 17280, 270, 17280, 540, 540, 540, 540, 540, 270, 270, 17280, 270, 17280, 270, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 270, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 270, 270, 270, 270, 270, 540, 270, 270, 540, 17280, 17280, 270, 270, 17280, 270, 270, 270, 540, 270, 540, 17280, 17280, 540, 540, 270, 17280, 540, 17280, 270, 540, 540, 270, 270, 540, 270, 17280, 17280, 270, 17280, 17280, 270, 540, 17280, 270, 270, 540, 540, 270, 270, 17280, 17280, 17280, 17280, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 17280, 540, 540, 540, 17280, 270, 540, 540, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 540, 270, 17280, 17280, 17280, 540, 270, 17280, 17280, 540, 540, 17280, 17280, 270, 17280, 17280, 540, 270, 17280, 540, 540, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 540, 17280, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 17280, 270, 270, 270, 540, 270, 540, 540, 270, 17280, 540, 17280, 270, 17280, 270, 540, 540, 540, 540, 270, 540, 17280, 17280, 270, 17280, 17280, 270, 17280, 540, 17280, 540, 540, 540, 270, 540, 270, 270, 17280, 270, 540, 270, 270, 540, 17280, 540, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2315520 . Total input tokens: 515609097 . Total output tokens: 462994603
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 86.70280931890011,
    "estimated_duration": 3600.1396953593844,
    "input_throughput": 5358.350962010181,
    "output_throughput": 4678.230686911919,
    "total_throughput": 10036.581648922102,
    "itl": 181.44926621020744,
    "ttft": 2079812.0482512277,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 543,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6235973101318606,
    "arrivals": 771112,
    "finished_requests": 77897,
    "scheduler_time": 136.92748611655412
}
#Debug simulation 
Total elapsed time: 86.7029505558312. Arrivals time: 0.35475287213921547 Scheduler time: 86.21527468180284 Scheduler overhead time: 0.05058457748964429 Adapter cache time: 0.015510743483901024 Engine time: 0.04846161883324385 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_16-16-32/adapters_384_slots_96_rate_1.6-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_16-16-32/adapters_384_slots_96_rate_1.6-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 540, 270, 17280, 17280, 270, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 270, 17280, 270, 17280, 540, 540, 540, 270, 270, 540, 270, 17280, 270, 17280, 540, 17280, 540, 270, 540, 17280, 540, 17280, 270, 17280, 17280, 17280, 17280, 270, 540, 540, 540, 17280, 540, 270, 540, 270, 17280, 540, 17280, 17280, 540, 17280, 17280, 270, 270, 17280, 540, 540, 270, 270, 270, 540, 270, 540, 270, 17280, 270, 540, 17280, 270, 17280, 540, 270, 17280, 17280, 17280, 17280, 540, 270, 540, 17280, 17280, 540, 270, 270, 17280, 540, 540, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 270, 540, 540, 540, 540, 270, 270, 17280, 270, 17280, 270, 270, 270, 540, 540, 17280, 270, 270, 17280, 270, 17280, 540, 270, 17280, 540, 540, 270, 17280, 17280, 17280, 270, 540, 17280, 270, 17280, 540, 540, 17280, 17280, 270, 540, 17280, 270, 540, 540, 270, 540, 270, 540, 17280, 17280, 540, 270, 17280, 270, 17280, 540, 540, 540, 540, 540, 270, 270, 17280, 270, 17280, 270, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 270, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 270, 270, 270, 270, 270, 540, 270, 270, 540, 17280, 17280, 270, 270, 17280, 270, 270, 270, 540, 270, 540, 17280, 17280, 540, 540, 270, 17280, 540, 17280, 270, 540, 540, 270, 270, 540, 270, 17280, 17280, 270, 17280, 17280, 270, 540, 17280, 270, 270, 540, 540, 270, 270, 17280, 17280, 17280, 17280, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 17280, 540, 540, 540, 17280, 270, 540, 540, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 540, 270, 17280, 17280, 17280, 540, 270, 17280, 17280, 540, 540, 17280, 17280, 270, 17280, 17280, 540, 270, 17280, 540, 540, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 540, 17280, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 17280, 270, 270, 270, 540, 270, 540, 540, 270, 17280, 540, 17280, 270, 17280, 270, 540, 540, 540, 540, 270, 540, 17280, 17280, 270, 17280, 17280, 270, 17280, 540, 17280, 540, 540, 540, 270, 540, 270, 270, 17280, 270, 540, 270, 270, 540, 17280, 540, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2315520 . Total input tokens: 515609097 . Total output tokens: 462994603
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 86.15662209969014,
    "estimated_duration": 3600.0014226400162,
    "input_throughput": 5346.882053697675,
    "output_throughput": 4668.137044144844,
    "total_throughput": 10015.019097842518,
    "itl": 179.92216866842404,
    "ttft": 2081257.6063578236,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 564,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8920221161842308,
    "arrivals": 771112,
    "finished_requests": 77750,
    "scheduler_time": 137.38290930317638
}
#Debug simulation 
Total elapsed time: 86.15677556861192. Arrivals time: 0.3566653858870268 Scheduler time: 85.6663110521622 Scheduler overhead time: 0.05055550765246153 Adapter cache time: 0.01578220585361123 Engine time: 0.04917465569451451 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-8/adapters_384_slots_96_rate_1.6-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-8/adapters_384_slots_96_rate_1.6-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 540, 135, 17280, 17280, 135, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 135, 17280, 135, 17280, 540, 540, 540, 135, 135, 540, 135, 17280, 135, 17280, 540, 17280, 540, 135, 540, 17280, 540, 17280, 135, 17280, 17280, 17280, 17280, 135, 540, 540, 540, 17280, 540, 135, 540, 135, 17280, 540, 17280, 17280, 540, 17280, 17280, 135, 135, 17280, 540, 540, 135, 135, 135, 540, 135, 540, 135, 17280, 135, 540, 17280, 135, 17280, 540, 135, 17280, 17280, 17280, 17280, 540, 135, 540, 17280, 17280, 540, 135, 135, 17280, 540, 540, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 135, 540, 540, 540, 540, 135, 135, 17280, 135, 17280, 135, 135, 135, 540, 540, 17280, 135, 135, 17280, 135, 17280, 540, 135, 17280, 540, 540, 135, 17280, 17280, 17280, 135, 540, 17280, 135, 17280, 540, 540, 17280, 17280, 135, 540, 17280, 135, 540, 540, 135, 540, 135, 540, 17280, 17280, 540, 135, 17280, 135, 17280, 540, 540, 540, 540, 540, 135, 135, 17280, 135, 17280, 135, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 135, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 135, 135, 135, 135, 135, 540, 135, 135, 540, 17280, 17280, 135, 135, 17280, 135, 135, 135, 540, 135, 540, 17280, 17280, 540, 540, 135, 17280, 540, 17280, 135, 540, 540, 135, 135, 540, 135, 17280, 17280, 135, 17280, 17280, 135, 540, 17280, 135, 135, 540, 540, 135, 135, 17280, 17280, 17280, 17280, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 17280, 540, 540, 540, 17280, 135, 540, 540, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 540, 135, 17280, 17280, 17280, 540, 135, 17280, 17280, 540, 540, 17280, 17280, 135, 17280, 17280, 540, 135, 17280, 540, 540, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 540, 17280, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 17280, 135, 135, 135, 540, 135, 540, 540, 135, 17280, 540, 17280, 135, 17280, 135, 540, 540, 540, 540, 135, 540, 17280, 17280, 135, 17280, 17280, 135, 17280, 540, 17280, 540, 540, 540, 135, 540, 135, 135, 17280, 135, 540, 135, 135, 540, 17280, 540, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2298240 . Total input tokens: 511762382 . Total output tokens: 459532329
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 54.45688437996432,
    "estimated_duration": 3600.0963912248726,
    "input_throughput": 5290.248074030073,
    "output_throughput": 4691.868262519787,
    "total_throughput": 9982.116336549861,
    "itl": 183.9061194606547,
    "ttft": 2099439.362490506,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 964,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.950310185151241,
    "arrivals": 765327,
    "finished_requests": 76848,
    "scheduler_time": 136.3604550791368
}
#Debug simulation 
Total elapsed time: 54.45703289611265. Arrivals time: 0.3278718004003167 Scheduler time: 53.99950440181419 Scheduler overhead time: 0.04623481910675764 Adapter cache time: 0.02112944843247533 Engine time: 0.045115644577890635 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-16/adapters_384_slots_96_rate_1.6-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-16/adapters_384_slots_96_rate_1.6-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 540, 135, 17280, 17280, 135, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 135, 17280, 135, 17280, 540, 540, 540, 135, 135, 540, 135, 17280, 135, 17280, 540, 17280, 540, 135, 540, 17280, 540, 17280, 135, 17280, 17280, 17280, 17280, 135, 540, 540, 540, 17280, 540, 135, 540, 135, 17280, 540, 17280, 17280, 540, 17280, 17280, 135, 135, 17280, 540, 540, 135, 135, 135, 540, 135, 540, 135, 17280, 135, 540, 17280, 135, 17280, 540, 135, 17280, 17280, 17280, 17280, 540, 135, 540, 17280, 17280, 540, 135, 135, 17280, 540, 540, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 135, 540, 540, 540, 540, 135, 135, 17280, 135, 17280, 135, 135, 135, 540, 540, 17280, 135, 135, 17280, 135, 17280, 540, 135, 17280, 540, 540, 135, 17280, 17280, 17280, 135, 540, 17280, 135, 17280, 540, 540, 17280, 17280, 135, 540, 17280, 135, 540, 540, 135, 540, 135, 540, 17280, 17280, 540, 135, 17280, 135, 17280, 540, 540, 540, 540, 540, 135, 135, 17280, 135, 17280, 135, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 135, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 135, 135, 135, 135, 135, 540, 135, 135, 540, 17280, 17280, 135, 135, 17280, 135, 135, 135, 540, 135, 540, 17280, 17280, 540, 540, 135, 17280, 540, 17280, 135, 540, 540, 135, 135, 540, 135, 17280, 17280, 135, 17280, 17280, 135, 540, 17280, 135, 135, 540, 540, 135, 135, 17280, 17280, 17280, 17280, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 17280, 540, 540, 540, 17280, 135, 540, 540, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 540, 135, 17280, 17280, 17280, 540, 135, 17280, 17280, 540, 540, 17280, 17280, 135, 17280, 17280, 540, 135, 17280, 540, 540, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 540, 17280, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 17280, 135, 135, 135, 540, 135, 540, 540, 135, 17280, 540, 17280, 135, 17280, 135, 540, 540, 540, 540, 135, 540, 17280, 17280, 135, 17280, 17280, 135, 17280, 540, 17280, 540, 540, 540, 135, 540, 135, 135, 17280, 135, 540, 135, 135, 540, 17280, 540, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2298240 . Total input tokens: 511762382 . Total output tokens: 459532329
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 54.81514753680676,
    "estimated_duration": 3600.1811649296583,
    "input_throughput": 5289.008838079413,
    "output_throughput": 4694.74485468851,
    "total_throughput": 9983.753692767923,
    "itl": 184.00024948487683,
    "ttft": 2098956.5810530246,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 969,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.162128502109559,
    "arrivals": 765327,
    "finished_requests": 76859,
    "scheduler_time": 136.34395459910613
}
#Debug simulation 
Total elapsed time: 54.81529295211658. Arrivals time: 0.3316867910325527 Scheduler time: 54.353766507003456 Scheduler overhead time: 0.04605095041915774 Adapter cache time: 0.021433529909700155 Engine time: 0.045102796982973814 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-32/adapters_384_slots_96_rate_1.6-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-32/adapters_384_slots_96_rate_1.6-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 540, 135, 17280, 17280, 135, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 135, 17280, 135, 17280, 540, 540, 540, 135, 135, 540, 135, 17280, 135, 17280, 540, 17280, 540, 135, 540, 17280, 540, 17280, 135, 17280, 17280, 17280, 17280, 135, 540, 540, 540, 17280, 540, 135, 540, 135, 17280, 540, 17280, 17280, 540, 17280, 17280, 135, 135, 17280, 540, 540, 135, 135, 135, 540, 135, 540, 135, 17280, 135, 540, 17280, 135, 17280, 540, 135, 17280, 17280, 17280, 17280, 540, 135, 540, 17280, 17280, 540, 135, 135, 17280, 540, 540, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 135, 540, 540, 540, 540, 135, 135, 17280, 135, 17280, 135, 135, 135, 540, 540, 17280, 135, 135, 17280, 135, 17280, 540, 135, 17280, 540, 540, 135, 17280, 17280, 17280, 135, 540, 17280, 135, 17280, 540, 540, 17280, 17280, 135, 540, 17280, 135, 540, 540, 135, 540, 135, 540, 17280, 17280, 540, 135, 17280, 135, 17280, 540, 540, 540, 540, 540, 135, 135, 17280, 135, 17280, 135, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 135, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 135, 135, 135, 135, 135, 540, 135, 135, 540, 17280, 17280, 135, 135, 17280, 135, 135, 135, 540, 135, 540, 17280, 17280, 540, 540, 135, 17280, 540, 17280, 135, 540, 540, 135, 135, 540, 135, 17280, 17280, 135, 17280, 17280, 135, 540, 17280, 135, 135, 540, 540, 135, 135, 17280, 17280, 17280, 17280, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 17280, 540, 540, 540, 17280, 135, 540, 540, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 540, 135, 17280, 17280, 17280, 540, 135, 17280, 17280, 540, 540, 17280, 17280, 135, 17280, 17280, 540, 135, 17280, 540, 540, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 540, 17280, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 17280, 135, 135, 135, 540, 135, 540, 540, 135, 17280, 540, 17280, 135, 17280, 135, 540, 540, 540, 540, 135, 540, 17280, 17280, 135, 17280, 17280, 135, 17280, 540, 17280, 540, 540, 540, 135, 540, 135, 135, 17280, 135, 540, 135, 135, 540, 17280, 540, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2298240 . Total input tokens: 511762382 . Total output tokens: 459532329
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 54.13683761889115,
    "estimated_duration": 3600.1175416128103,
    "input_throughput": 5274.493896522401,
    "output_throughput": 4679.677761980118,
    "total_throughput": 9954.171658502519,
    "itl": 181.82467267607325,
    "ttft": 2101098.1404132117,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 968,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.16466262206432,
    "arrivals": 765327,
    "finished_requests": 76627,
    "scheduler_time": 136.94193308674522
}
#Debug simulation 
Total elapsed time: 54.13699245499447. Arrivals time: 0.38231361098587513 Scheduler time: 53.62432452570647 Scheduler overhead time: 0.04645383544266224 Adapter cache time: 0.021326399873942137 Engine time: 0.045311765279620886 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-16/adapters_384_slots_96_rate_1.6-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-16/adapters_384_slots_96_rate_1.6-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 540, 135, 17280, 17280, 135, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 135, 17280, 135, 17280, 540, 540, 540, 135, 135, 540, 135, 17280, 135, 17280, 540, 17280, 540, 135, 540, 17280, 540, 17280, 135, 17280, 17280, 17280, 17280, 135, 540, 540, 540, 17280, 540, 135, 540, 135, 17280, 540, 17280, 17280, 540, 17280, 17280, 135, 135, 17280, 540, 540, 135, 135, 135, 540, 135, 540, 135, 17280, 135, 540, 17280, 135, 17280, 540, 135, 17280, 17280, 17280, 17280, 540, 135, 540, 17280, 17280, 540, 135, 135, 17280, 540, 540, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 135, 540, 540, 540, 540, 135, 135, 17280, 135, 17280, 135, 135, 135, 540, 540, 17280, 135, 135, 17280, 135, 17280, 540, 135, 17280, 540, 540, 135, 17280, 17280, 17280, 135, 540, 17280, 135, 17280, 540, 540, 17280, 17280, 135, 540, 17280, 135, 540, 540, 135, 540, 135, 540, 17280, 17280, 540, 135, 17280, 135, 17280, 540, 540, 540, 540, 540, 135, 135, 17280, 135, 17280, 135, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 135, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 135, 135, 135, 135, 135, 540, 135, 135, 540, 17280, 17280, 135, 135, 17280, 135, 135, 135, 540, 135, 540, 17280, 17280, 540, 540, 135, 17280, 540, 17280, 135, 540, 540, 135, 135, 540, 135, 17280, 17280, 135, 17280, 17280, 135, 540, 17280, 135, 135, 540, 540, 135, 135, 17280, 17280, 17280, 17280, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 17280, 540, 540, 540, 17280, 135, 540, 540, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 540, 135, 17280, 17280, 17280, 540, 135, 17280, 17280, 540, 540, 17280, 17280, 135, 17280, 17280, 540, 135, 17280, 540, 540, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 540, 17280, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 17280, 135, 135, 135, 540, 135, 540, 540, 135, 17280, 540, 17280, 135, 17280, 135, 540, 540, 540, 540, 135, 540, 17280, 17280, 135, 17280, 17280, 135, 17280, 540, 17280, 540, 540, 540, 135, 540, 135, 135, 17280, 135, 540, 135, 135, 540, 17280, 540, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2298240 . Total input tokens: 511762382 . Total output tokens: 459532329
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 54.042433275375515,
    "estimated_duration": 3600.1534325848543,
    "input_throughput": 5290.116201054748,
    "output_throughput": 4691.862532056646,
    "total_throughput": 9981.978733111395,
    "itl": 183.91447065899104,
    "ttft": 2099515.791216228,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 961,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0025544540281093,
    "arrivals": 765327,
    "finished_requests": 76851,
    "scheduler_time": 136.35842979099755
}
#Debug simulation 
Total elapsed time: 54.04257609322667. Arrivals time: 0.3293169611133635 Scheduler time: 53.58361009415239 Scheduler overhead time: 0.046169647946953773 Adapter cache time: 0.02099719177931547 Engine time: 0.04513979982584715 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-32/adapters_384_slots_96_rate_1.6-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-32/adapters_384_slots_96_rate_1.6-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 540, 135, 17280, 17280, 135, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 135, 17280, 135, 17280, 540, 540, 540, 135, 135, 540, 135, 17280, 135, 17280, 540, 17280, 540, 135, 540, 17280, 540, 17280, 135, 17280, 17280, 17280, 17280, 135, 540, 540, 540, 17280, 540, 135, 540, 135, 17280, 540, 17280, 17280, 540, 17280, 17280, 135, 135, 17280, 540, 540, 135, 135, 135, 540, 135, 540, 135, 17280, 135, 540, 17280, 135, 17280, 540, 135, 17280, 17280, 17280, 17280, 540, 135, 540, 17280, 17280, 540, 135, 135, 17280, 540, 540, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 135, 540, 540, 540, 540, 135, 135, 17280, 135, 17280, 135, 135, 135, 540, 540, 17280, 135, 135, 17280, 135, 17280, 540, 135, 17280, 540, 540, 135, 17280, 17280, 17280, 135, 540, 17280, 135, 17280, 540, 540, 17280, 17280, 135, 540, 17280, 135, 540, 540, 135, 540, 135, 540, 17280, 17280, 540, 135, 17280, 135, 17280, 540, 540, 540, 540, 540, 135, 135, 17280, 135, 17280, 135, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 135, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 135, 135, 135, 135, 135, 540, 135, 135, 540, 17280, 17280, 135, 135, 17280, 135, 135, 135, 540, 135, 540, 17280, 17280, 540, 540, 135, 17280, 540, 17280, 135, 540, 540, 135, 135, 540, 135, 17280, 17280, 135, 17280, 17280, 135, 540, 17280, 135, 135, 540, 540, 135, 135, 17280, 17280, 17280, 17280, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 17280, 540, 540, 540, 17280, 135, 540, 540, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 540, 135, 17280, 17280, 17280, 540, 135, 17280, 17280, 540, 540, 17280, 17280, 135, 17280, 17280, 540, 135, 17280, 540, 540, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 540, 17280, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 17280, 135, 135, 135, 540, 135, 540, 540, 135, 17280, 540, 17280, 135, 17280, 135, 540, 540, 540, 540, 135, 540, 17280, 17280, 135, 17280, 17280, 135, 17280, 540, 17280, 540, 540, 540, 135, 540, 135, 135, 17280, 135, 540, 135, 135, 540, 17280, 540, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2298240 . Total input tokens: 511762382 . Total output tokens: 459532329
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 53.5605858778581,
    "estimated_duration": 3600.1660343410367,
    "input_throughput": 5274.422851299315,
    "output_throughput": 4679.614728681172,
    "total_throughput": 9954.037579980488,
    "itl": 181.82655312372802,
    "ttft": 2101111.7170030214,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 968,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2055326026491793,
    "arrivals": 765327,
    "finished_requests": 76627,
    "scheduler_time": 136.9425801181883
}
#Debug simulation 
Total elapsed time: 53.560725612565875. Arrivals time: 0.37745606154203415 Scheduler time: 53.05288647534326 Scheduler overhead time: 0.046204558573663235 Adapter cache time: 0.021190956234931946 Engine time: 0.045427761040627956 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-16/adapters_384_slots_96_rate_1.6-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-16/adapters_384_slots_96_rate_1.6-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 540, 135, 17280, 17280, 135, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 135, 17280, 135, 17280, 540, 540, 540, 135, 135, 540, 135, 17280, 135, 17280, 540, 17280, 540, 135, 540, 17280, 540, 17280, 135, 17280, 17280, 17280, 17280, 135, 540, 540, 540, 17280, 540, 135, 540, 135, 17280, 540, 17280, 17280, 540, 17280, 17280, 135, 135, 17280, 540, 540, 135, 135, 135, 540, 135, 540, 135, 17280, 135, 540, 17280, 135, 17280, 540, 135, 17280, 17280, 17280, 17280, 540, 135, 540, 17280, 17280, 540, 135, 135, 17280, 540, 540, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 135, 540, 540, 540, 540, 135, 135, 17280, 135, 17280, 135, 135, 135, 540, 540, 17280, 135, 135, 17280, 135, 17280, 540, 135, 17280, 540, 540, 135, 17280, 17280, 17280, 135, 540, 17280, 135, 17280, 540, 540, 17280, 17280, 135, 540, 17280, 135, 540, 540, 135, 540, 135, 540, 17280, 17280, 540, 135, 17280, 135, 17280, 540, 540, 540, 540, 540, 135, 135, 17280, 135, 17280, 135, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 135, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 135, 135, 135, 135, 135, 540, 135, 135, 540, 17280, 17280, 135, 135, 17280, 135, 135, 135, 540, 135, 540, 17280, 17280, 540, 540, 135, 17280, 540, 17280, 135, 540, 540, 135, 135, 540, 135, 17280, 17280, 135, 17280, 17280, 135, 540, 17280, 135, 135, 540, 540, 135, 135, 17280, 17280, 17280, 17280, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 17280, 540, 540, 540, 17280, 135, 540, 540, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 540, 135, 17280, 17280, 17280, 540, 135, 17280, 17280, 540, 540, 17280, 17280, 135, 17280, 17280, 540, 135, 17280, 540, 540, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 540, 17280, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 17280, 135, 135, 135, 540, 135, 540, 540, 135, 17280, 540, 17280, 135, 17280, 135, 540, 540, 540, 540, 135, 540, 17280, 17280, 135, 17280, 17280, 135, 17280, 540, 17280, 540, 540, 540, 135, 540, 135, 135, 17280, 135, 540, 135, 135, 540, 17280, 540, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2298240 . Total input tokens: 511762382 . Total output tokens: 459532329
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 54.266476998105645,
    "estimated_duration": 3600.028298583793,
    "input_throughput": 5290.348136288881,
    "output_throughput": 4691.957006739303,
    "total_throughput": 9982.305143028185,
    "itl": 183.9028863956413,
    "ttft": 2099424.4474125085,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 964,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.882408484285632,
    "arrivals": 765327,
    "finished_requests": 76848,
    "scheduler_time": 136.36026413874035
}
#Debug simulation 
Total elapsed time: 54.26662585325539. Arrivals time: 0.3432716568931937 Scheduler time: 53.79168674023822 Scheduler overhead time: 0.04672637255862355 Adapter cache time: 0.02107597002759576 Engine time: 0.046038956847041845 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-32/adapters_384_slots_96_rate_1.6-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-32/adapters_384_slots_96_rate_1.6-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 540, 135, 17280, 17280, 135, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 135, 17280, 135, 17280, 540, 540, 540, 135, 135, 540, 135, 17280, 135, 17280, 540, 17280, 540, 135, 540, 17280, 540, 17280, 135, 17280, 17280, 17280, 17280, 135, 540, 540, 540, 17280, 540, 135, 540, 135, 17280, 540, 17280, 17280, 540, 17280, 17280, 135, 135, 17280, 540, 540, 135, 135, 135, 540, 135, 540, 135, 17280, 135, 540, 17280, 135, 17280, 540, 135, 17280, 17280, 17280, 17280, 540, 135, 540, 17280, 17280, 540, 135, 135, 17280, 540, 540, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 135, 540, 540, 540, 540, 135, 135, 17280, 135, 17280, 135, 135, 135, 540, 540, 17280, 135, 135, 17280, 135, 17280, 540, 135, 17280, 540, 540, 135, 17280, 17280, 17280, 135, 540, 17280, 135, 17280, 540, 540, 17280, 17280, 135, 540, 17280, 135, 540, 540, 135, 540, 135, 540, 17280, 17280, 540, 135, 17280, 135, 17280, 540, 540, 540, 540, 540, 135, 135, 17280, 135, 17280, 135, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 135, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 135, 135, 135, 135, 135, 540, 135, 135, 540, 17280, 17280, 135, 135, 17280, 135, 135, 135, 540, 135, 540, 17280, 17280, 540, 540, 135, 17280, 540, 17280, 135, 540, 540, 135, 135, 540, 135, 17280, 17280, 135, 17280, 17280, 135, 540, 17280, 135, 135, 540, 540, 135, 135, 17280, 17280, 17280, 17280, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 17280, 540, 540, 540, 17280, 135, 540, 540, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 540, 135, 17280, 17280, 17280, 540, 135, 17280, 17280, 540, 540, 17280, 17280, 135, 17280, 17280, 540, 135, 17280, 540, 540, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 540, 17280, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 17280, 135, 135, 135, 540, 135, 540, 540, 135, 17280, 540, 17280, 135, 17280, 135, 540, 540, 540, 540, 135, 540, 17280, 17280, 135, 17280, 17280, 135, 17280, 540, 17280, 540, 540, 540, 135, 540, 135, 135, 17280, 135, 540, 135, 135, 540, 17280, 540, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2298240 . Total input tokens: 511762382 . Total output tokens: 459532329
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 53.923748071771115,
    "estimated_duration": 3600.010316385215,
    "input_throughput": 5274.365996557948,
    "output_throughput": 4679.407423730678,
    "total_throughput": 9953.773420288626,
    "itl": 181.82760972273255,
    "ttft": 2101067.788591398,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 968,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2461510756612193,
    "arrivals": 765327,
    "finished_requests": 76622,
    "scheduler_time": 136.9350828293009
}
#Debug simulation 
Total elapsed time: 53.92389591410756. Arrivals time: 0.3871569000184536 Scheduler time: 53.40691169677302 Scheduler overhead time: 0.04581236932426691 Adapter cache time: 0.021238521207123995 Engine time: 0.04514735797420144 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-8/adapters_384_slots_96_rate_1.6-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-8/adapters_384_slots_96_rate_1.6-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 540, 66, 17280, 17280, 66, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 66, 17280, 66, 17280, 540, 540, 540, 66, 66, 540, 66, 17280, 66, 17280, 540, 17280, 540, 66, 540, 17280, 540, 17280, 66, 17280, 17280, 17280, 17280, 66, 540, 540, 540, 17280, 540, 66, 540, 66, 17280, 540, 17280, 17280, 540, 17280, 17280, 66, 66, 17280, 540, 540, 66, 66, 66, 540, 66, 540, 66, 17280, 66, 540, 17280, 66, 17280, 540, 66, 17280, 17280, 17280, 17280, 540, 66, 540, 17280, 17280, 540, 66, 66, 17280, 540, 540, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 66, 540, 540, 540, 540, 66, 66, 17280, 66, 17280, 66, 66, 66, 540, 540, 17280, 66, 66, 17280, 66, 17280, 540, 66, 17280, 540, 540, 66, 17280, 17280, 17280, 66, 540, 17280, 66, 17280, 540, 540, 17280, 17280, 66, 540, 17280, 66, 540, 540, 66, 540, 66, 540, 17280, 17280, 540, 66, 17280, 66, 17280, 540, 540, 540, 540, 540, 66, 66, 17280, 66, 17280, 66, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 66, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 66, 66, 66, 66, 66, 540, 66, 66, 540, 17280, 17280, 66, 66, 17280, 66, 66, 66, 540, 66, 540, 17280, 17280, 540, 540, 66, 17280, 540, 17280, 66, 540, 540, 66, 66, 540, 66, 17280, 17280, 66, 17280, 17280, 66, 540, 17280, 66, 66, 540, 540, 66, 66, 17280, 17280, 17280, 17280, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 17280, 540, 540, 540, 17280, 66, 540, 540, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 540, 66, 17280, 17280, 17280, 540, 66, 17280, 17280, 540, 540, 17280, 17280, 66, 17280, 17280, 540, 66, 17280, 540, 540, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 540, 17280, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 17280, 66, 66, 66, 540, 66, 540, 540, 66, 17280, 540, 17280, 66, 17280, 66, 540, 540, 540, 540, 66, 540, 17280, 17280, 66, 17280, 17280, 66, 17280, 540, 17280, 540, 540, 540, 66, 540, 66, 66, 17280, 66, 540, 66, 66, 540, 17280, 540, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2289408 . Total input tokens: 509793012 . Total output tokens: 457761006
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 48.49431029520929,
    "estimated_duration": 3600.1624052353454,
    "input_throughput": 5313.161143003928,
    "output_throughput": 4688.254056387948,
    "total_throughput": 10001.415199391877,
    "itl": 183.40723584600056,
    "ttft": 2087802.3748524443,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 957,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.928886770943711,
    "arrivals": 762451,
    "finished_requests": 77560,
    "scheduler_time": 136.4343053344314
}
#Debug simulation 
Total elapsed time: 48.49446079786867. Arrivals time: 0.33674395363777876 Scheduler time: 48.02969323191792 Scheduler overhead time: 0.045382565818727016 Adapter cache time: 0.020582244265824556 Engine time: 0.044550884049385786 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-16/adapters_384_slots_96_rate_1.6-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-16/adapters_384_slots_96_rate_1.6-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 540, 66, 17280, 17280, 66, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 66, 17280, 66, 17280, 540, 540, 540, 66, 66, 540, 66, 17280, 66, 17280, 540, 17280, 540, 66, 540, 17280, 540, 17280, 66, 17280, 17280, 17280, 17280, 66, 540, 540, 540, 17280, 540, 66, 540, 66, 17280, 540, 17280, 17280, 540, 17280, 17280, 66, 66, 17280, 540, 540, 66, 66, 66, 540, 66, 540, 66, 17280, 66, 540, 17280, 66, 17280, 540, 66, 17280, 17280, 17280, 17280, 540, 66, 540, 17280, 17280, 540, 66, 66, 17280, 540, 540, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 66, 540, 540, 540, 540, 66, 66, 17280, 66, 17280, 66, 66, 66, 540, 540, 17280, 66, 66, 17280, 66, 17280, 540, 66, 17280, 540, 540, 66, 17280, 17280, 17280, 66, 540, 17280, 66, 17280, 540, 540, 17280, 17280, 66, 540, 17280, 66, 540, 540, 66, 540, 66, 540, 17280, 17280, 540, 66, 17280, 66, 17280, 540, 540, 540, 540, 540, 66, 66, 17280, 66, 17280, 66, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 66, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 66, 66, 66, 66, 66, 540, 66, 66, 540, 17280, 17280, 66, 66, 17280, 66, 66, 66, 540, 66, 540, 17280, 17280, 540, 540, 66, 17280, 540, 17280, 66, 540, 540, 66, 66, 540, 66, 17280, 17280, 66, 17280, 17280, 66, 540, 17280, 66, 66, 540, 540, 66, 66, 17280, 17280, 17280, 17280, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 17280, 540, 540, 540, 17280, 66, 540, 540, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 540, 66, 17280, 17280, 17280, 540, 66, 17280, 17280, 540, 540, 17280, 17280, 66, 17280, 17280, 540, 66, 17280, 540, 540, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 540, 17280, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 17280, 66, 66, 66, 540, 66, 540, 540, 66, 17280, 540, 17280, 66, 17280, 66, 540, 540, 540, 540, 66, 540, 17280, 17280, 66, 17280, 17280, 66, 17280, 540, 17280, 540, 540, 540, 66, 540, 66, 66, 17280, 66, 540, 66, 66, 540, 17280, 540, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2289408 . Total input tokens: 509793012 . Total output tokens: 457761006
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 48.45425702771172,
    "estimated_duration": 3600.1843770949095,
    "input_throughput": 5314.415039887167,
    "output_throughput": 4688.005455325896,
    "total_throughput": 10002.420495213064,
    "itl": 183.40331761373875,
    "ttft": 2087862.3441606928,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 962,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.141606745363684,
    "arrivals": 762451,
    "finished_requests": 77549,
    "scheduler_time": 136.43032301972488
}
#Debug simulation 
Total elapsed time: 48.45440787496045. Arrivals time: 0.3326155166141689 Scheduler time: 47.993656773585826 Scheduler overhead time: 0.045578654389828444 Adapter cache time: 0.020761791616678238 Engine time: 0.04449967946857214 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-32/adapters_384_slots_96_rate_1.6-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-32/adapters_384_slots_96_rate_1.6-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 540, 66, 17280, 17280, 66, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 66, 17280, 66, 17280, 540, 540, 540, 66, 66, 540, 66, 17280, 66, 17280, 540, 17280, 540, 66, 540, 17280, 540, 17280, 66, 17280, 17280, 17280, 17280, 66, 540, 540, 540, 17280, 540, 66, 540, 66, 17280, 540, 17280, 17280, 540, 17280, 17280, 66, 66, 17280, 540, 540, 66, 66, 66, 540, 66, 540, 66, 17280, 66, 540, 17280, 66, 17280, 540, 66, 17280, 17280, 17280, 17280, 540, 66, 540, 17280, 17280, 540, 66, 66, 17280, 540, 540, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 66, 540, 540, 540, 540, 66, 66, 17280, 66, 17280, 66, 66, 66, 540, 540, 17280, 66, 66, 17280, 66, 17280, 540, 66, 17280, 540, 540, 66, 17280, 17280, 17280, 66, 540, 17280, 66, 17280, 540, 540, 17280, 17280, 66, 540, 17280, 66, 540, 540, 66, 540, 66, 540, 17280, 17280, 540, 66, 17280, 66, 17280, 540, 540, 540, 540, 540, 66, 66, 17280, 66, 17280, 66, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 66, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 66, 66, 66, 66, 66, 540, 66, 66, 540, 17280, 17280, 66, 66, 17280, 66, 66, 66, 540, 66, 540, 17280, 17280, 540, 540, 66, 17280, 540, 17280, 66, 540, 540, 66, 66, 540, 66, 17280, 17280, 66, 17280, 17280, 66, 540, 17280, 66, 66, 540, 540, 66, 66, 17280, 17280, 17280, 17280, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 17280, 540, 540, 540, 17280, 66, 540, 540, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 540, 66, 17280, 17280, 17280, 540, 66, 17280, 17280, 540, 540, 17280, 17280, 66, 17280, 17280, 540, 66, 17280, 540, 540, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 540, 17280, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 17280, 66, 66, 66, 540, 66, 540, 540, 66, 17280, 540, 17280, 66, 17280, 66, 540, 540, 540, 540, 66, 540, 17280, 17280, 66, 17280, 17280, 66, 17280, 540, 17280, 540, 540, 540, 66, 540, 66, 66, 17280, 66, 540, 66, 66, 540, 17280, 540, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2289408 . Total input tokens: 509793012 . Total output tokens: 457761006
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 46.8841188843362,
    "estimated_duration": 3600.0788782945833,
    "input_throughput": 5302.702703292801,
    "output_throughput": 4676.285039614191,
    "total_throughput": 9978.987742906993,
    "itl": 181.72414633695206,
    "ttft": 2089099.1710587437,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 954,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1203671207092394,
    "arrivals": 762451,
    "finished_requests": 77361,
    "scheduler_time": 136.89011387813596
}
#Debug simulation 
Total elapsed time: 46.884268107358366. Arrivals time: 0.33817166090011597 Scheduler time: 46.416118043940514 Scheduler overhead time: 0.04627267783507705 Adapter cache time: 0.021405021660029888 Engine time: 0.04472632193937898 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-16/adapters_384_slots_96_rate_1.6-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-16/adapters_384_slots_96_rate_1.6-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 540, 66, 17280, 17280, 66, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 66, 17280, 66, 17280, 540, 540, 540, 66, 66, 540, 66, 17280, 66, 17280, 540, 17280, 540, 66, 540, 17280, 540, 17280, 66, 17280, 17280, 17280, 17280, 66, 540, 540, 540, 17280, 540, 66, 540, 66, 17280, 540, 17280, 17280, 540, 17280, 17280, 66, 66, 17280, 540, 540, 66, 66, 66, 540, 66, 540, 66, 17280, 66, 540, 17280, 66, 17280, 540, 66, 17280, 17280, 17280, 17280, 540, 66, 540, 17280, 17280, 540, 66, 66, 17280, 540, 540, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 66, 540, 540, 540, 540, 66, 66, 17280, 66, 17280, 66, 66, 66, 540, 540, 17280, 66, 66, 17280, 66, 17280, 540, 66, 17280, 540, 540, 66, 17280, 17280, 17280, 66, 540, 17280, 66, 17280, 540, 540, 17280, 17280, 66, 540, 17280, 66, 540, 540, 66, 540, 66, 540, 17280, 17280, 540, 66, 17280, 66, 17280, 540, 540, 540, 540, 540, 66, 66, 17280, 66, 17280, 66, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 66, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 66, 66, 66, 66, 66, 540, 66, 66, 540, 17280, 17280, 66, 66, 17280, 66, 66, 66, 540, 66, 540, 17280, 17280, 540, 540, 66, 17280, 540, 17280, 66, 540, 540, 66, 66, 540, 66, 17280, 17280, 66, 17280, 17280, 66, 540, 17280, 66, 66, 540, 540, 66, 66, 17280, 17280, 17280, 17280, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 17280, 540, 540, 540, 17280, 66, 540, 540, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 540, 66, 17280, 17280, 17280, 540, 66, 17280, 17280, 540, 540, 17280, 17280, 66, 17280, 17280, 540, 66, 17280, 540, 540, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 540, 17280, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 17280, 66, 66, 66, 540, 66, 540, 540, 66, 17280, 540, 17280, 66, 17280, 66, 540, 540, 540, 540, 66, 540, 17280, 17280, 66, 17280, 17280, 66, 17280, 540, 17280, 540, 540, 540, 66, 540, 66, 66, 17280, 66, 540, 66, 66, 540, 17280, 540, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2289408 . Total input tokens: 509793012 . Total output tokens: 457761006
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 48.362200546078384,
    "estimated_duration": 3600.0241342696822,
    "input_throughput": 5313.273824449063,
    "output_throughput": 4688.323847424419,
    "total_throughput": 10001.597671873482,
    "itl": 183.4107585779944,
    "ttft": 2087757.039735451,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 957,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9914114434853807,
    "arrivals": 762451,
    "finished_requests": 77557,
    "scheduler_time": 136.42681384848248
}
#Debug simulation 
Total elapsed time: 48.36234914697707. Arrivals time: 0.3370492234826088 Scheduler time: 47.89619583962485 Scheduler overhead time: 0.0460855164565146 Adapter cache time: 0.021235010586678982 Engine time: 0.04466302692890167 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-32/adapters_384_slots_96_rate_1.6-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-32/adapters_384_slots_96_rate_1.6-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 540, 66, 17280, 17280, 66, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 66, 17280, 66, 17280, 540, 540, 540, 66, 66, 540, 66, 17280, 66, 17280, 540, 17280, 540, 66, 540, 17280, 540, 17280, 66, 17280, 17280, 17280, 17280, 66, 540, 540, 540, 17280, 540, 66, 540, 66, 17280, 540, 17280, 17280, 540, 17280, 17280, 66, 66, 17280, 540, 540, 66, 66, 66, 540, 66, 540, 66, 17280, 66, 540, 17280, 66, 17280, 540, 66, 17280, 17280, 17280, 17280, 540, 66, 540, 17280, 17280, 540, 66, 66, 17280, 540, 540, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 66, 540, 540, 540, 540, 66, 66, 17280, 66, 17280, 66, 66, 66, 540, 540, 17280, 66, 66, 17280, 66, 17280, 540, 66, 17280, 540, 540, 66, 17280, 17280, 17280, 66, 540, 17280, 66, 17280, 540, 540, 17280, 17280, 66, 540, 17280, 66, 540, 540, 66, 540, 66, 540, 17280, 17280, 540, 66, 17280, 66, 17280, 540, 540, 540, 540, 540, 66, 66, 17280, 66, 17280, 66, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 66, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 66, 66, 66, 66, 66, 540, 66, 66, 540, 17280, 17280, 66, 66, 17280, 66, 66, 66, 540, 66, 540, 17280, 17280, 540, 540, 66, 17280, 540, 17280, 66, 540, 540, 66, 66, 540, 66, 17280, 17280, 66, 17280, 17280, 66, 540, 17280, 66, 66, 540, 540, 66, 66, 17280, 17280, 17280, 17280, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 17280, 540, 540, 540, 17280, 66, 540, 540, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 540, 66, 17280, 17280, 17280, 540, 66, 17280, 17280, 540, 540, 17280, 17280, 66, 17280, 17280, 540, 66, 17280, 540, 540, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 540, 17280, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 17280, 66, 66, 66, 540, 66, 540, 540, 66, 17280, 540, 17280, 66, 17280, 66, 540, 540, 540, 540, 66, 540, 17280, 17280, 66, 17280, 17280, 66, 17280, 540, 17280, 540, 540, 540, 66, 540, 66, 66, 17280, 66, 540, 66, 66, 540, 17280, 540, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2289408 . Total input tokens: 509793012 . Total output tokens: 457761006
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 47.21508303517476,
    "estimated_duration": 3600.1198708165234,
    "input_throughput": 5302.642324426344,
    "output_throughput": 4676.231793410187,
    "total_throughput": 9978.87411783653,
    "itl": 181.72603138607732,
    "ttft": 2089108.4744255778,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 954,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1612371012941,
    "arrivals": 762451,
    "finished_requests": 77361,
    "scheduler_time": 136.89023641958167
}
#Debug simulation 
Total elapsed time: 47.21522463904694. Arrivals time: 0.6053332695737481 Scheduler time: 46.47909873910248 Scheduler overhead time: 0.04667975194752216 Adapter cache time: 0.021436783485114574 Engine time: 0.045420244336128235 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-16/adapters_384_slots_96_rate_1.6-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-16/adapters_384_slots_96_rate_1.6-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 540, 66, 17280, 17280, 66, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 66, 17280, 66, 17280, 540, 540, 540, 66, 66, 540, 66, 17280, 66, 17280, 540, 17280, 540, 66, 540, 17280, 540, 17280, 66, 17280, 17280, 17280, 17280, 66, 540, 540, 540, 17280, 540, 66, 540, 66, 17280, 540, 17280, 17280, 540, 17280, 17280, 66, 66, 17280, 540, 540, 66, 66, 66, 540, 66, 540, 66, 17280, 66, 540, 17280, 66, 17280, 540, 66, 17280, 17280, 17280, 17280, 540, 66, 540, 17280, 17280, 540, 66, 66, 17280, 540, 540, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 66, 540, 540, 540, 540, 66, 66, 17280, 66, 17280, 66, 66, 66, 540, 540, 17280, 66, 66, 17280, 66, 17280, 540, 66, 17280, 540, 540, 66, 17280, 17280, 17280, 66, 540, 17280, 66, 17280, 540, 540, 17280, 17280, 66, 540, 17280, 66, 540, 540, 66, 540, 66, 540, 17280, 17280, 540, 66, 17280, 66, 17280, 540, 540, 540, 540, 540, 66, 66, 17280, 66, 17280, 66, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 66, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 66, 66, 66, 66, 66, 540, 66, 66, 540, 17280, 17280, 66, 66, 17280, 66, 66, 66, 540, 66, 540, 17280, 17280, 540, 540, 66, 17280, 540, 17280, 66, 540, 540, 66, 66, 540, 66, 17280, 17280, 66, 17280, 17280, 66, 540, 17280, 66, 66, 540, 540, 66, 66, 17280, 17280, 17280, 17280, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 17280, 540, 540, 540, 17280, 66, 540, 540, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 540, 66, 17280, 17280, 17280, 540, 66, 17280, 17280, 540, 540, 17280, 17280, 66, 17280, 17280, 540, 66, 17280, 540, 540, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 540, 17280, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 17280, 66, 66, 66, 540, 66, 540, 540, 66, 17280, 540, 17280, 66, 17280, 66, 540, 540, 540, 540, 66, 540, 17280, 17280, 66, 17280, 17280, 66, 17280, 540, 17280, 540, 540, 540, 66, 540, 66, 66, 17280, 66, 540, 66, 66, 540, 17280, 540, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2289408 . Total input tokens: 509793012 . Total output tokens: 457761006
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 48.724476103205234,
    "estimated_duration": 3600.094805015667,
    "input_throughput": 5313.260910060049,
    "output_throughput": 4688.342089348546,
    "total_throughput": 10001.602999408597,
    "itl": 183.40407487826354,
    "ttft": 2087786.624808668,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 957,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8614781322213174,
    "arrivals": 762451,
    "finished_requests": 77560,
    "scheduler_time": 136.43411375329535
}
#Debug simulation 
Total elapsed time: 48.724625000264496. Arrivals time: 0.34425169322639704 Scheduler time: 48.250422954559326 Scheduler overhead time: 0.04632497113198042 Adapter cache time: 0.020952297374606133 Engine time: 0.04529839567840099 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-32/adapters_384_slots_96_rate_1.6-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-32/adapters_384_slots_96_rate_1.6-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 540, 66, 17280, 17280, 66, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 66, 17280, 66, 17280, 540, 540, 540, 66, 66, 540, 66, 17280, 66, 17280, 540, 17280, 540, 66, 540, 17280, 540, 17280, 66, 17280, 17280, 17280, 17280, 66, 540, 540, 540, 17280, 540, 66, 540, 66, 17280, 540, 17280, 17280, 540, 17280, 17280, 66, 66, 17280, 540, 540, 66, 66, 66, 540, 66, 540, 66, 17280, 66, 540, 17280, 66, 17280, 540, 66, 17280, 17280, 17280, 17280, 540, 66, 540, 17280, 17280, 540, 66, 66, 17280, 540, 540, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 66, 540, 540, 540, 540, 66, 66, 17280, 66, 17280, 66, 66, 66, 540, 540, 17280, 66, 66, 17280, 66, 17280, 540, 66, 17280, 540, 540, 66, 17280, 17280, 17280, 66, 540, 17280, 66, 17280, 540, 540, 17280, 17280, 66, 540, 17280, 66, 540, 540, 66, 540, 66, 540, 17280, 17280, 540, 66, 17280, 66, 17280, 540, 540, 540, 540, 540, 66, 66, 17280, 66, 17280, 66, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 66, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 66, 66, 66, 66, 66, 540, 66, 66, 540, 17280, 17280, 66, 66, 17280, 66, 66, 66, 540, 66, 540, 17280, 17280, 540, 540, 66, 17280, 540, 17280, 66, 540, 540, 66, 66, 540, 66, 17280, 17280, 66, 17280, 17280, 66, 540, 17280, 66, 66, 540, 540, 66, 66, 17280, 17280, 17280, 17280, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 17280, 540, 540, 540, 17280, 66, 540, 540, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 540, 66, 17280, 17280, 17280, 540, 66, 17280, 17280, 540, 540, 17280, 17280, 66, 17280, 17280, 540, 66, 17280, 540, 540, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 540, 17280, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 17280, 66, 66, 66, 540, 66, 540, 540, 66, 17280, 540, 17280, 66, 17280, 66, 540, 540, 540, 540, 66, 540, 17280, 17280, 66, 17280, 17280, 66, 17280, 540, 17280, 540, 540, 540, 66, 540, 66, 66, 17280, 66, 540, 66, 66, 540, 17280, 540, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2289408 . Total input tokens: 509793012 . Total output tokens: 457761006
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 47.12310156505555,
    "estimated_duration": 3600.1599923526846,
    "input_throughput": 5302.583229787156,
    "output_throughput": 4676.1796797254065,
    "total_throughput": 9978.762909512563,
    "itl": 181.72786103070482,
    "ttft": 2089118.087952444,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 954,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2012268053740622,
    "arrivals": 762451,
    "finished_requests": 77361,
    "scheduler_time": 136.89036825175137
}
#Debug simulation 
Total elapsed time: 47.123230427037925. Arrivals time: 0.34160504303872585 Scheduler time: 46.648919684346765 Scheduler overhead time: 0.04816698795184493 Adapter cache time: 0.020936754066497087 Engine time: 0.045793385710567236 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-8/adapters_384_slots_96_rate_1.6-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-8/adapters_384_slots_96_rate_1.6-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 540, 33, 17280, 17280, 33, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 33, 17280, 33, 17280, 540, 540, 540, 33, 33, 540, 33, 17280, 33, 17280, 540, 17280, 540, 33, 540, 17280, 540, 17280, 33, 17280, 17280, 17280, 17280, 33, 540, 540, 540, 17280, 540, 33, 540, 33, 17280, 540, 17280, 17280, 540, 17280, 17280, 33, 33, 17280, 540, 540, 33, 33, 33, 540, 33, 540, 33, 17280, 33, 540, 17280, 33, 17280, 540, 33, 17280, 17280, 17280, 17280, 540, 33, 540, 17280, 17280, 540, 33, 33, 17280, 540, 540, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 33, 540, 540, 540, 540, 33, 33, 17280, 33, 17280, 33, 33, 33, 540, 540, 17280, 33, 33, 17280, 33, 17280, 540, 33, 17280, 540, 540, 33, 17280, 17280, 17280, 33, 540, 17280, 33, 17280, 540, 540, 17280, 17280, 33, 540, 17280, 33, 540, 540, 33, 540, 33, 540, 17280, 17280, 540, 33, 17280, 33, 17280, 540, 540, 540, 540, 540, 33, 33, 17280, 33, 17280, 33, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 33, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 33, 33, 33, 33, 33, 540, 33, 33, 540, 17280, 17280, 33, 33, 17280, 33, 33, 33, 540, 33, 540, 17280, 17280, 540, 540, 33, 17280, 540, 17280, 33, 540, 540, 33, 33, 540, 33, 17280, 17280, 33, 17280, 17280, 33, 540, 17280, 33, 33, 540, 540, 33, 33, 17280, 17280, 17280, 17280, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 17280, 540, 540, 540, 17280, 33, 540, 540, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 540, 33, 17280, 17280, 17280, 540, 33, 17280, 17280, 540, 540, 17280, 17280, 33, 17280, 17280, 540, 33, 17280, 540, 540, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 540, 17280, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 17280, 33, 33, 33, 540, 33, 540, 540, 33, 17280, 540, 17280, 33, 17280, 33, 540, 540, 540, 540, 33, 540, 17280, 17280, 33, 17280, 17280, 33, 17280, 540, 17280, 540, 540, 540, 33, 540, 33, 33, 17280, 33, 540, 33, 33, 540, 17280, 540, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2285184 . Total input tokens: 508844357 . Total output tokens: 456900888
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 48.802497470751405,
    "estimated_duration": 3600.2092974381185,
    "input_throughput": 5304.797699842135,
    "output_throughput": 4686.143111736683,
    "total_throughput": 9990.940811578817,
    "itl": 183.09713779843753,
    "ttft": 2089412.36390835,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 888,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7177131166123436,
    "arrivals": 761080,
    "finished_requests": 77453,
    "scheduler_time": 136.37161641205213
}
#Debug simulation 
Total elapsed time: 48.80262767104432. Arrivals time: 0.37630768585950136 Scheduler time: 48.297015625052154 Scheduler overhead time: 0.04659078503027558 Adapter cache time: 0.019700384698808193 Engine time: 0.045711638405919075 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-16/adapters_384_slots_96_rate_1.6-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-16/adapters_384_slots_96_rate_1.6-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 540, 33, 17280, 17280, 33, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 33, 17280, 33, 17280, 540, 540, 540, 33, 33, 540, 33, 17280, 33, 17280, 540, 17280, 540, 33, 540, 17280, 540, 17280, 33, 17280, 17280, 17280, 17280, 33, 540, 540, 540, 17280, 540, 33, 540, 33, 17280, 540, 17280, 17280, 540, 17280, 17280, 33, 33, 17280, 540, 540, 33, 33, 33, 540, 33, 540, 33, 17280, 33, 540, 17280, 33, 17280, 540, 33, 17280, 17280, 17280, 17280, 540, 33, 540, 17280, 17280, 540, 33, 33, 17280, 540, 540, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 33, 540, 540, 540, 540, 33, 33, 17280, 33, 17280, 33, 33, 33, 540, 540, 17280, 33, 33, 17280, 33, 17280, 540, 33, 17280, 540, 540, 33, 17280, 17280, 17280, 33, 540, 17280, 33, 17280, 540, 540, 17280, 17280, 33, 540, 17280, 33, 540, 540, 33, 540, 33, 540, 17280, 17280, 540, 33, 17280, 33, 17280, 540, 540, 540, 540, 540, 33, 33, 17280, 33, 17280, 33, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 33, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 33, 33, 33, 33, 33, 540, 33, 33, 540, 17280, 17280, 33, 33, 17280, 33, 33, 33, 540, 33, 540, 17280, 17280, 540, 540, 33, 17280, 540, 17280, 33, 540, 540, 33, 33, 540, 33, 17280, 17280, 33, 17280, 17280, 33, 540, 17280, 33, 33, 540, 540, 33, 33, 17280, 17280, 17280, 17280, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 17280, 540, 540, 540, 17280, 33, 540, 540, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 540, 33, 17280, 17280, 17280, 540, 33, 17280, 17280, 540, 540, 17280, 17280, 33, 17280, 17280, 540, 33, 17280, 540, 540, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 540, 17280, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 17280, 33, 33, 33, 540, 33, 540, 540, 33, 17280, 540, 17280, 33, 17280, 33, 540, 540, 540, 540, 33, 540, 17280, 17280, 33, 17280, 17280, 33, 17280, 540, 17280, 540, 540, 540, 33, 540, 33, 33, 17280, 33, 540, 33, 33, 540, 17280, 540, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2285184 . Total input tokens: 508844357 . Total output tokens: 456900888
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 48.529777561314404,
    "estimated_duration": 3600.1749433600585,
    "input_throughput": 5304.645552078667,
    "output_throughput": 4686.119220710526,
    "total_throughput": 9990.764772789193,
    "itl": 183.1058277476971,
    "ttft": 2089366.0018785154,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 888,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.892558541886978,
    "arrivals": 761080,
    "finished_requests": 77450,
    "scheduler_time": 136.36432034442754
}
#Debug simulation 
Total elapsed time: 48.52989614196122. Arrivals time: 0.33075495809316635 Scheduler time: 48.07083093142137 Scheduler overhead time: 0.0459363111294806 Adapter cache time: 0.01989674847573042 Engine time: 0.04485054826363921 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-32/adapters_384_slots_96_rate_1.6-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-32/adapters_384_slots_96_rate_1.6-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 540, 33, 17280, 17280, 33, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 33, 17280, 33, 17280, 540, 540, 540, 33, 33, 540, 33, 17280, 33, 17280, 540, 17280, 540, 33, 540, 17280, 540, 17280, 33, 17280, 17280, 17280, 17280, 33, 540, 540, 540, 17280, 540, 33, 540, 33, 17280, 540, 17280, 17280, 540, 17280, 17280, 33, 33, 17280, 540, 540, 33, 33, 33, 540, 33, 540, 33, 17280, 33, 540, 17280, 33, 17280, 540, 33, 17280, 17280, 17280, 17280, 540, 33, 540, 17280, 17280, 540, 33, 33, 17280, 540, 540, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 33, 540, 540, 540, 540, 33, 33, 17280, 33, 17280, 33, 33, 33, 540, 540, 17280, 33, 33, 17280, 33, 17280, 540, 33, 17280, 540, 540, 33, 17280, 17280, 17280, 33, 540, 17280, 33, 17280, 540, 540, 17280, 17280, 33, 540, 17280, 33, 540, 540, 33, 540, 33, 540, 17280, 17280, 540, 33, 17280, 33, 17280, 540, 540, 540, 540, 540, 33, 33, 17280, 33, 17280, 33, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 33, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 33, 33, 33, 33, 33, 540, 33, 33, 540, 17280, 17280, 33, 33, 17280, 33, 33, 33, 540, 33, 540, 17280, 17280, 540, 540, 33, 17280, 540, 17280, 33, 540, 540, 33, 33, 540, 33, 17280, 17280, 33, 17280, 17280, 33, 540, 17280, 33, 33, 540, 540, 33, 33, 17280, 17280, 17280, 17280, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 17280, 540, 540, 540, 17280, 33, 540, 540, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 540, 33, 17280, 17280, 17280, 540, 33, 17280, 17280, 540, 540, 17280, 17280, 33, 17280, 17280, 540, 33, 17280, 540, 540, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 540, 17280, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 17280, 33, 33, 33, 540, 33, 540, 540, 33, 17280, 540, 17280, 33, 17280, 33, 540, 540, 540, 540, 33, 540, 17280, 17280, 33, 17280, 17280, 33, 17280, 540, 17280, 540, 540, 540, 33, 540, 33, 33, 17280, 33, 540, 33, 33, 540, 17280, 540, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2285184 . Total input tokens: 508844357 . Total output tokens: 456900888
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 55.32096030469984,
    "estimated_duration": 3600.054694157709,
    "input_throughput": 5294.337341855127,
    "output_throughput": 4674.790087859355,
    "total_throughput": 9969.127429714483,
    "itl": 181.1843279454087,
    "ttft": 2090650.2616844974,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 896,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.924619920290984,
    "arrivals": 761080,
    "finished_requests": 77292,
    "scheduler_time": 136.89273386312152
}
#Debug simulation 
Total elapsed time: 55.321100326720625. Arrivals time: 0.39513489650562406 Scheduler time: 54.794170814566314 Scheduler overhead time: 0.047369105741381645 Adapter cache time: 0.02004853030666709 Engine time: 0.04674626048654318 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-16/adapters_384_slots_96_rate_1.6-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-16/adapters_384_slots_96_rate_1.6-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 540, 33, 17280, 17280, 33, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 33, 17280, 33, 17280, 540, 540, 540, 33, 33, 540, 33, 17280, 33, 17280, 540, 17280, 540, 33, 540, 17280, 540, 17280, 33, 17280, 17280, 17280, 17280, 33, 540, 540, 540, 17280, 540, 33, 540, 33, 17280, 540, 17280, 17280, 540, 17280, 17280, 33, 33, 17280, 540, 540, 33, 33, 33, 540, 33, 540, 33, 17280, 33, 540, 17280, 33, 17280, 540, 33, 17280, 17280, 17280, 17280, 540, 33, 540, 17280, 17280, 540, 33, 33, 17280, 540, 540, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 33, 540, 540, 540, 540, 33, 33, 17280, 33, 17280, 33, 33, 33, 540, 540, 17280, 33, 33, 17280, 33, 17280, 540, 33, 17280, 540, 540, 33, 17280, 17280, 17280, 33, 540, 17280, 33, 17280, 540, 540, 17280, 17280, 33, 540, 17280, 33, 540, 540, 33, 540, 33, 540, 17280, 17280, 540, 33, 17280, 33, 17280, 540, 540, 540, 540, 540, 33, 33, 17280, 33, 17280, 33, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 33, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 33, 33, 33, 33, 33, 540, 33, 33, 540, 17280, 17280, 33, 33, 17280, 33, 33, 33, 540, 33, 540, 17280, 17280, 540, 540, 33, 17280, 540, 17280, 33, 540, 540, 33, 33, 540, 33, 17280, 17280, 33, 17280, 17280, 33, 540, 17280, 33, 33, 540, 540, 33, 33, 17280, 17280, 17280, 17280, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 17280, 540, 540, 540, 17280, 33, 540, 540, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 540, 33, 17280, 17280, 17280, 540, 33, 17280, 17280, 540, 540, 17280, 17280, 33, 17280, 17280, 540, 33, 17280, 540, 540, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 540, 17280, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 17280, 33, 33, 33, 540, 33, 540, 540, 33, 17280, 540, 17280, 33, 17280, 33, 540, 540, 540, 540, 33, 540, 17280, 17280, 33, 17280, 17280, 33, 17280, 540, 17280, 540, 540, 540, 33, 540, 33, 33, 17280, 33, 540, 33, 33, 540, 17280, 540, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2285184 . Total input tokens: 508844357 . Total output tokens: 456900888
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 48.579372900072485,
    "estimated_duration": 3600.0560409647865,
    "input_throughput": 5304.820753535265,
    "output_throughput": 4686.273993523375,
    "total_throughput": 9991.09474705864,
    "itl": 183.10025796876135,
    "ttft": 2089336.9187851495,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 888,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.774065899539245,
    "arrivals": 761080,
    "finished_requests": 77450,
    "scheduler_time": 136.36391059146266
}
#Debug simulation 
Total elapsed time: 48.5795239652507. Arrivals time: 0.3535554613918066 Scheduler time: 48.0983424782753 Scheduler overhead time: 0.04574819654226303 Adapter cache time: 0.020018039271235466 Engine time: 0.04463648283854127 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-32/adapters_384_slots_96_rate_1.6-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-32/adapters_384_slots_96_rate_1.6-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 540, 33, 17280, 17280, 33, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 33, 17280, 33, 17280, 540, 540, 540, 33, 33, 540, 33, 17280, 33, 17280, 540, 17280, 540, 33, 540, 17280, 540, 17280, 33, 17280, 17280, 17280, 17280, 33, 540, 540, 540, 17280, 540, 33, 540, 33, 17280, 540, 17280, 17280, 540, 17280, 17280, 33, 33, 17280, 540, 540, 33, 33, 33, 540, 33, 540, 33, 17280, 33, 540, 17280, 33, 17280, 540, 33, 17280, 17280, 17280, 17280, 540, 33, 540, 17280, 17280, 540, 33, 33, 17280, 540, 540, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 33, 540, 540, 540, 540, 33, 33, 17280, 33, 17280, 33, 33, 33, 540, 540, 17280, 33, 33, 17280, 33, 17280, 540, 33, 17280, 540, 540, 33, 17280, 17280, 17280, 33, 540, 17280, 33, 17280, 540, 540, 17280, 17280, 33, 540, 17280, 33, 540, 540, 33, 540, 33, 540, 17280, 17280, 540, 33, 17280, 33, 17280, 540, 540, 540, 540, 540, 33, 33, 17280, 33, 17280, 33, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 33, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 33, 33, 33, 33, 33, 540, 33, 33, 540, 17280, 17280, 33, 33, 17280, 33, 33, 33, 540, 33, 540, 17280, 17280, 540, 540, 33, 17280, 540, 17280, 33, 540, 540, 33, 33, 540, 33, 17280, 17280, 33, 17280, 17280, 33, 540, 17280, 33, 33, 540, 540, 33, 33, 17280, 17280, 17280, 17280, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 17280, 540, 540, 540, 17280, 33, 540, 540, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 540, 33, 17280, 17280, 17280, 540, 33, 17280, 17280, 540, 540, 17280, 17280, 33, 17280, 17280, 540, 33, 17280, 540, 540, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 540, 17280, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 17280, 33, 33, 33, 540, 33, 540, 540, 33, 17280, 540, 17280, 33, 17280, 33, 540, 540, 540, 540, 33, 540, 17280, 17280, 33, 17280, 17280, 33, 17280, 540, 17280, 540, 540, 540, 33, 540, 33, 33, 17280, 33, 540, 33, 33, 540, 17280, 540, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2285184 . Total input tokens: 508844357 . Total output tokens: 456900888
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 55.57082739286125,
    "estimated_duration": 3600.0915364843427,
    "input_throughput": 5294.283161092311,
    "output_throughput": 4674.742247369297,
    "total_throughput": 9969.025408461608,
    "itl": 181.18603050294163,
    "ttft": 2090657.8748412086,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 896,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9613400259241467,
    "arrivals": 761080,
    "finished_requests": 77292,
    "scheduler_time": 136.89285608419743
}
#Debug simulation 
Total elapsed time: 55.57097246777266. Arrivals time: 0.39339890191331506 Scheduler time: 55.04554306669161 Scheduler overhead time: 0.04721304401755333 Adapter cache time: 0.02039765240624547 Engine time: 0.04664039192721248 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-16/adapters_384_slots_96_rate_1.6-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-16/adapters_384_slots_96_rate_1.6-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 540, 33, 17280, 17280, 33, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 33, 17280, 33, 17280, 540, 540, 540, 33, 33, 540, 33, 17280, 33, 17280, 540, 17280, 540, 33, 540, 17280, 540, 17280, 33, 17280, 17280, 17280, 17280, 33, 540, 540, 540, 17280, 540, 33, 540, 33, 17280, 540, 17280, 17280, 540, 17280, 17280, 33, 33, 17280, 540, 540, 33, 33, 33, 540, 33, 540, 33, 17280, 33, 540, 17280, 33, 17280, 540, 33, 17280, 17280, 17280, 17280, 540, 33, 540, 17280, 17280, 540, 33, 33, 17280, 540, 540, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 33, 540, 540, 540, 540, 33, 33, 17280, 33, 17280, 33, 33, 33, 540, 540, 17280, 33, 33, 17280, 33, 17280, 540, 33, 17280, 540, 540, 33, 17280, 17280, 17280, 33, 540, 17280, 33, 17280, 540, 540, 17280, 17280, 33, 540, 17280, 33, 540, 540, 33, 540, 33, 540, 17280, 17280, 540, 33, 17280, 33, 17280, 540, 540, 540, 540, 540, 33, 33, 17280, 33, 17280, 33, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 33, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 33, 33, 33, 33, 33, 540, 33, 33, 540, 17280, 17280, 33, 33, 17280, 33, 33, 33, 540, 33, 540, 17280, 17280, 540, 540, 33, 17280, 540, 17280, 33, 540, 540, 33, 33, 540, 33, 17280, 17280, 33, 17280, 17280, 33, 540, 17280, 33, 33, 540, 540, 33, 33, 17280, 17280, 17280, 17280, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 17280, 540, 540, 540, 17280, 33, 540, 540, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 540, 33, 17280, 17280, 17280, 540, 33, 17280, 17280, 540, 540, 17280, 17280, 33, 17280, 17280, 540, 33, 17280, 540, 540, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 540, 17280, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 17280, 33, 33, 33, 540, 33, 540, 540, 33, 17280, 540, 17280, 33, 17280, 33, 540, 540, 540, 540, 33, 540, 17280, 17280, 33, 17280, 17280, 33, 17280, 540, 17280, 540, 540, 540, 33, 540, 33, 33, 17280, 33, 540, 33, 33, 540, 17280, 540, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2285184 . Total input tokens: 508844357 . Total output tokens: 456900888
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 48.8778162128292,
    "estimated_duration": 3600.1465352968935,
    "input_throughput": 5304.890179539599,
    "output_throughput": 4686.224806293528,
    "total_throughput": 9991.114985833126,
    "itl": 183.09417894640745,
    "ttft": 2089396.8660415239,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 888,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6551646618730746,
    "arrivals": 761080,
    "finished_requests": 77453,
    "scheduler_time": 136.37140272540037
}
#Debug simulation 
Total elapsed time: 48.87796724960208. Arrivals time: 0.34387242514640093 Scheduler time: 48.403539444785565 Scheduler overhead time: 0.046646567061543465 Adapter cache time: 0.019807639997452497 Engine time: 0.04656395083293319 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-32/adapters_384_slots_96_rate_1.6-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-32/adapters_384_slots_96_rate_1.6-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 540, 33, 17280, 17280, 33, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 33, 17280, 33, 17280, 540, 540, 540, 33, 33, 540, 33, 17280, 33, 17280, 540, 17280, 540, 33, 540, 17280, 540, 17280, 33, 17280, 17280, 17280, 17280, 33, 540, 540, 540, 17280, 540, 33, 540, 33, 17280, 540, 17280, 17280, 540, 17280, 17280, 33, 33, 17280, 540, 540, 33, 33, 33, 540, 33, 540, 33, 17280, 33, 540, 17280, 33, 17280, 540, 33, 17280, 17280, 17280, 17280, 540, 33, 540, 17280, 17280, 540, 33, 33, 17280, 540, 540, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 33, 540, 540, 540, 540, 33, 33, 17280, 33, 17280, 33, 33, 33, 540, 540, 17280, 33, 33, 17280, 33, 17280, 540, 33, 17280, 540, 540, 33, 17280, 17280, 17280, 33, 540, 17280, 33, 17280, 540, 540, 17280, 17280, 33, 540, 17280, 33, 540, 540, 33, 540, 33, 540, 17280, 17280, 540, 33, 17280, 33, 17280, 540, 540, 540, 540, 540, 33, 33, 17280, 33, 17280, 33, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 33, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 33, 33, 33, 33, 33, 540, 33, 33, 540, 17280, 17280, 33, 33, 17280, 33, 33, 33, 540, 33, 540, 17280, 17280, 540, 540, 33, 17280, 540, 17280, 33, 540, 540, 33, 33, 540, 33, 17280, 17280, 33, 17280, 17280, 33, 540, 17280, 33, 33, 540, 540, 33, 33, 17280, 17280, 17280, 17280, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 17280, 540, 540, 540, 17280, 33, 540, 540, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 540, 33, 17280, 17280, 17280, 540, 33, 17280, 17280, 540, 540, 17280, 17280, 33, 17280, 17280, 540, 33, 17280, 540, 540, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 540, 17280, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 17280, 33, 33, 33, 540, 33, 540, 540, 33, 17280, 540, 17280, 33, 17280, 33, 540, 540, 540, 540, 33, 540, 17280, 17280, 33, 17280, 17280, 33, 17280, 540, 17280, 540, 540, 540, 33, 540, 33, 33, 17280, 33, 540, 33, 33, 540, 17280, 540, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2285184 . Total input tokens: 508844357 . Total output tokens: 456900888
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 55.88128308206797,
    "estimated_duration": 3600.1286488999945,
    "input_throughput": 5294.2285842545325,
    "output_throughput": 4674.6940571532605,
    "total_throughput": 9968.922641407793,
    "itl": 181.18771583894585,
    "ttft": 2090665.8856016388,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 896,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9983116391301436,
    "arrivals": 761080,
    "finished_requests": 77292,
    "scheduler_time": 136.89299688672133
}
#Debug simulation 
Total elapsed time: 55.88142690900713. Arrivals time: 0.4010690776631236 Scheduler time: 55.34680313477293 Scheduler overhead time: 0.0479230722412467 Adapter cache time: 0.02040715329349041 Engine time: 0.04739503329619765 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-8/adapters_384_slots_96_rate_1.6-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-8/adapters_384_slots_96_rate_1.6-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 270, 135, 17280, 17280, 135, 270, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 135, 17280, 135, 17280, 270, 270, 270, 135, 135, 270, 135, 17280, 135, 17280, 270, 17280, 270, 135, 270, 17280, 270, 17280, 135, 17280, 17280, 17280, 17280, 135, 270, 270, 270, 17280, 270, 135, 270, 135, 17280, 270, 17280, 17280, 270, 17280, 17280, 135, 135, 17280, 270, 270, 135, 135, 135, 270, 135, 270, 135, 17280, 135, 270, 17280, 135, 17280, 270, 135, 17280, 17280, 17280, 17280, 270, 135, 270, 17280, 17280, 270, 135, 135, 17280, 270, 270, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 270, 17280, 17280, 135, 270, 270, 270, 270, 135, 135, 17280, 135, 17280, 135, 135, 135, 270, 270, 17280, 135, 135, 17280, 135, 17280, 270, 135, 17280, 270, 270, 135, 17280, 17280, 17280, 135, 270, 17280, 135, 17280, 270, 270, 17280, 17280, 135, 270, 17280, 135, 270, 270, 135, 270, 135, 270, 17280, 17280, 270, 135, 17280, 135, 17280, 270, 270, 270, 270, 270, 135, 135, 17280, 135, 17280, 135, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 135, 270, 270, 270, 270, 270, 270, 270, 270, 17280, 135, 135, 135, 135, 135, 270, 135, 135, 270, 17280, 17280, 135, 135, 17280, 135, 135, 135, 270, 135, 270, 17280, 17280, 270, 270, 135, 17280, 270, 17280, 135, 270, 270, 135, 135, 270, 135, 17280, 17280, 135, 17280, 17280, 135, 270, 17280, 135, 135, 270, 270, 135, 135, 17280, 17280, 17280, 17280, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 17280, 270, 270, 270, 17280, 135, 270, 270, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 270, 135, 17280, 17280, 17280, 270, 135, 17280, 17280, 270, 270, 17280, 17280, 135, 17280, 17280, 270, 135, 17280, 270, 270, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 270, 17280, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 17280, 135, 135, 135, 270, 135, 270, 270, 135, 17280, 270, 17280, 135, 17280, 135, 270, 270, 270, 270, 135, 270, 17280, 17280, 135, 17280, 17280, 135, 17280, 270, 17280, 270, 270, 270, 135, 270, 135, 135, 17280, 135, 270, 135, 135, 270, 17280, 270, 17280, 135, 17280, 17280, 270, 17280, 270, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2263680 . Total input tokens: 504023803 . Total output tokens: 452587319
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 92.84246674366295,
    "estimated_duration": 3600.172513393649,
    "input_throughput": 5327.244994135351,
    "output_throughput": 4686.253488474224,
    "total_throughput": 10013.498482609575,
    "itl": 182.83725849239892,
    "ttft": 2065531.583516748,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 390,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1935902201337794,
    "arrivals": 753814,
    "finished_requests": 77819,
    "scheduler_time": 136.53053513824855
}
#Debug simulation 
Total elapsed time: 92.84261371800676. Arrivals time: 0.39505006931722164 Scheduler time: 92.30854579713196 Scheduler overhead time: 0.05300792679190636 Adapter cache time: 0.014086996670812368 Engine time: 0.05269414698705077 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-16/adapters_384_slots_96_rate_1.6-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-16/adapters_384_slots_96_rate_1.6-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 270, 135, 17280, 17280, 135, 270, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 135, 17280, 135, 17280, 270, 270, 270, 135, 135, 270, 135, 17280, 135, 17280, 270, 17280, 270, 135, 270, 17280, 270, 17280, 135, 17280, 17280, 17280, 17280, 135, 270, 270, 270, 17280, 270, 135, 270, 135, 17280, 270, 17280, 17280, 270, 17280, 17280, 135, 135, 17280, 270, 270, 135, 135, 135, 270, 135, 270, 135, 17280, 135, 270, 17280, 135, 17280, 270, 135, 17280, 17280, 17280, 17280, 270, 135, 270, 17280, 17280, 270, 135, 135, 17280, 270, 270, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 270, 17280, 17280, 135, 270, 270, 270, 270, 135, 135, 17280, 135, 17280, 135, 135, 135, 270, 270, 17280, 135, 135, 17280, 135, 17280, 270, 135, 17280, 270, 270, 135, 17280, 17280, 17280, 135, 270, 17280, 135, 17280, 270, 270, 17280, 17280, 135, 270, 17280, 135, 270, 270, 135, 270, 135, 270, 17280, 17280, 270, 135, 17280, 135, 17280, 270, 270, 270, 270, 270, 135, 135, 17280, 135, 17280, 135, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 135, 270, 270, 270, 270, 270, 270, 270, 270, 17280, 135, 135, 135, 135, 135, 270, 135, 135, 270, 17280, 17280, 135, 135, 17280, 135, 135, 135, 270, 135, 270, 17280, 17280, 270, 270, 135, 17280, 270, 17280, 135, 270, 270, 135, 135, 270, 135, 17280, 17280, 135, 17280, 17280, 135, 270, 17280, 135, 135, 270, 270, 135, 135, 17280, 17280, 17280, 17280, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 17280, 270, 270, 270, 17280, 135, 270, 270, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 270, 135, 17280, 17280, 17280, 270, 135, 17280, 17280, 270, 270, 17280, 17280, 135, 17280, 17280, 270, 135, 17280, 270, 270, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 270, 17280, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 17280, 135, 135, 135, 270, 135, 270, 270, 135, 17280, 270, 17280, 135, 17280, 135, 270, 270, 270, 270, 135, 270, 17280, 17280, 135, 17280, 17280, 135, 17280, 270, 17280, 270, 270, 270, 135, 270, 135, 135, 17280, 135, 270, 135, 135, 270, 17280, 270, 17280, 135, 17280, 17280, 270, 17280, 270, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2263680 . Total input tokens: 504023803 . Total output tokens: 452587319
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 93.26033915765584,
    "estimated_duration": 3600.008341771738,
    "input_throughput": 5328.337375618297,
    "output_throughput": 4686.453307410069,
    "total_throughput": 10014.790683028366,
    "itl": 182.83348739987403,
    "ttft": 2065611.082050644,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 388,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.268825869127183,
    "arrivals": 753814,
    "finished_requests": 77826,
    "scheduler_time": 136.5230410938383
}
#Debug simulation 
Total elapsed time: 93.26047777477652. Arrivals time: 0.38334019342437387 Scheduler time: 92.73861268116161 Scheduler overhead time: 0.053206440061330795 Adapter cache time: 0.014137068763375282 Engine time: 0.05247372621670365 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-32/adapters_384_slots_96_rate_1.6-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-32/adapters_384_slots_96_rate_1.6-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 270, 135, 17280, 17280, 135, 270, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 135, 17280, 135, 17280, 270, 270, 270, 135, 135, 270, 135, 17280, 135, 17280, 270, 17280, 270, 135, 270, 17280, 270, 17280, 135, 17280, 17280, 17280, 17280, 135, 270, 270, 270, 17280, 270, 135, 270, 135, 17280, 270, 17280, 17280, 270, 17280, 17280, 135, 135, 17280, 270, 270, 135, 135, 135, 270, 135, 270, 135, 17280, 135, 270, 17280, 135, 17280, 270, 135, 17280, 17280, 17280, 17280, 270, 135, 270, 17280, 17280, 270, 135, 135, 17280, 270, 270, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 270, 17280, 17280, 135, 270, 270, 270, 270, 135, 135, 17280, 135, 17280, 135, 135, 135, 270, 270, 17280, 135, 135, 17280, 135, 17280, 270, 135, 17280, 270, 270, 135, 17280, 17280, 17280, 135, 270, 17280, 135, 17280, 270, 270, 17280, 17280, 135, 270, 17280, 135, 270, 270, 135, 270, 135, 270, 17280, 17280, 270, 135, 17280, 135, 17280, 270, 270, 270, 270, 270, 135, 135, 17280, 135, 17280, 135, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 135, 270, 270, 270, 270, 270, 270, 270, 270, 17280, 135, 135, 135, 135, 135, 270, 135, 135, 270, 17280, 17280, 135, 135, 17280, 135, 135, 135, 270, 135, 270, 17280, 17280, 270, 270, 135, 17280, 270, 17280, 135, 270, 270, 135, 135, 270, 135, 17280, 17280, 135, 17280, 17280, 135, 270, 17280, 135, 135, 270, 270, 135, 135, 17280, 17280, 17280, 17280, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 17280, 270, 270, 270, 17280, 135, 270, 270, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 270, 135, 17280, 17280, 17280, 270, 135, 17280, 17280, 270, 270, 17280, 17280, 135, 17280, 17280, 270, 135, 17280, 270, 270, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 270, 17280, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 17280, 135, 135, 135, 270, 135, 270, 270, 135, 17280, 270, 17280, 135, 17280, 135, 270, 270, 270, 270, 135, 270, 17280, 17280, 135, 17280, 17280, 135, 17280, 270, 17280, 270, 270, 270, 135, 270, 135, 135, 17280, 135, 270, 135, 135, 270, 17280, 270, 17280, 135, 17280, 17280, 270, 17280, 270, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2263680 . Total input tokens: 504023803 . Total output tokens: 452587319
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 91.63664906006306,
    "estimated_duration": 3600.1218754296087,
    "input_throughput": 5317.335263189007,
    "output_throughput": 4676.811669880149,
    "total_throughput": 9994.146933069156,
    "itl": 181.1688673747259,
    "ttft": 2066103.156052202,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 389,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2736366657167746,
    "arrivals": 753814,
    "finished_requests": 77648,
    "scheduler_time": 137.00112587947032
}
#Debug simulation 
Total elapsed time: 91.63679074496031. Arrivals time: 0.3815394835546613 Scheduler time: 91.117662449833 Scheduler overhead time: 0.05327562289312482 Adapter cache time: 0.013616437092423439 Engine time: 0.05196765484288335 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-16/adapters_384_slots_96_rate_1.6-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-16/adapters_384_slots_96_rate_1.6-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 270, 135, 17280, 17280, 135, 270, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 135, 17280, 135, 17280, 270, 270, 270, 135, 135, 270, 135, 17280, 135, 17280, 270, 17280, 270, 135, 270, 17280, 270, 17280, 135, 17280, 17280, 17280, 17280, 135, 270, 270, 270, 17280, 270, 135, 270, 135, 17280, 270, 17280, 17280, 270, 17280, 17280, 135, 135, 17280, 270, 270, 135, 135, 135, 270, 135, 270, 135, 17280, 135, 270, 17280, 135, 17280, 270, 135, 17280, 17280, 17280, 17280, 270, 135, 270, 17280, 17280, 270, 135, 135, 17280, 270, 270, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 270, 17280, 17280, 135, 270, 270, 270, 270, 135, 135, 17280, 135, 17280, 135, 135, 135, 270, 270, 17280, 135, 135, 17280, 135, 17280, 270, 135, 17280, 270, 270, 135, 17280, 17280, 17280, 135, 270, 17280, 135, 17280, 270, 270, 17280, 17280, 135, 270, 17280, 135, 270, 270, 135, 270, 135, 270, 17280, 17280, 270, 135, 17280, 135, 17280, 270, 270, 270, 270, 270, 135, 135, 17280, 135, 17280, 135, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 135, 270, 270, 270, 270, 270, 270, 270, 270, 17280, 135, 135, 135, 135, 135, 270, 135, 135, 270, 17280, 17280, 135, 135, 17280, 135, 135, 135, 270, 135, 270, 17280, 17280, 270, 270, 135, 17280, 270, 17280, 135, 270, 270, 135, 135, 270, 135, 17280, 17280, 135, 17280, 17280, 135, 270, 17280, 135, 135, 270, 270, 135, 135, 17280, 17280, 17280, 17280, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 17280, 270, 270, 270, 17280, 135, 270, 270, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 270, 135, 17280, 17280, 17280, 270, 135, 17280, 17280, 270, 270, 17280, 17280, 135, 17280, 17280, 270, 135, 17280, 270, 270, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 270, 17280, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 17280, 135, 135, 135, 270, 135, 270, 270, 135, 17280, 270, 17280, 135, 17280, 135, 270, 270, 270, 270, 135, 270, 17280, 17280, 135, 17280, 17280, 135, 17280, 270, 17280, 270, 270, 270, 135, 270, 135, 135, 17280, 135, 270, 135, 135, 270, 17280, 270, 17280, 135, 17280, 17280, 270, 17280, 270, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2263680 . Total input tokens: 504023803 . Total output tokens: 452587319
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 93.05882477201521,
    "estimated_duration": 3600.202623978549,
    "input_throughput": 5327.200439292351,
    "output_throughput": 4686.214294615359,
    "total_throughput": 10013.41473390771,
    "itl": 182.838382458028,
    "ttft": 2065540.5456577565,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 390,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2200541970459742,
    "arrivals": 753814,
    "finished_requests": 77819,
    "scheduler_time": 136.53083404549577
}
#Debug simulation 
Total elapsed time: 93.05896522570401. Arrivals time: 0.42260953644290566 Scheduler time: 92.4971259101294 Scheduler overhead time: 0.053616772405803204 Adapter cache time: 0.013857399579137564 Engine time: 0.05278679123148322 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-32/adapters_384_slots_96_rate_1.6-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-32/adapters_384_slots_96_rate_1.6-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 270, 135, 17280, 17280, 135, 270, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 135, 17280, 135, 17280, 270, 270, 270, 135, 135, 270, 135, 17280, 135, 17280, 270, 17280, 270, 135, 270, 17280, 270, 17280, 135, 17280, 17280, 17280, 17280, 135, 270, 270, 270, 17280, 270, 135, 270, 135, 17280, 270, 17280, 17280, 270, 17280, 17280, 135, 135, 17280, 270, 270, 135, 135, 135, 270, 135, 270, 135, 17280, 135, 270, 17280, 135, 17280, 270, 135, 17280, 17280, 17280, 17280, 270, 135, 270, 17280, 17280, 270, 135, 135, 17280, 270, 270, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 270, 17280, 17280, 135, 270, 270, 270, 270, 135, 135, 17280, 135, 17280, 135, 135, 135, 270, 270, 17280, 135, 135, 17280, 135, 17280, 270, 135, 17280, 270, 270, 135, 17280, 17280, 17280, 135, 270, 17280, 135, 17280, 270, 270, 17280, 17280, 135, 270, 17280, 135, 270, 270, 135, 270, 135, 270, 17280, 17280, 270, 135, 17280, 135, 17280, 270, 270, 270, 270, 270, 135, 135, 17280, 135, 17280, 135, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 135, 270, 270, 270, 270, 270, 270, 270, 270, 17280, 135, 135, 135, 135, 135, 270, 135, 135, 270, 17280, 17280, 135, 135, 17280, 135, 135, 135, 270, 135, 270, 17280, 17280, 270, 270, 135, 17280, 270, 17280, 135, 270, 270, 135, 135, 270, 135, 17280, 17280, 135, 17280, 17280, 135, 270, 17280, 135, 135, 270, 270, 135, 135, 17280, 17280, 17280, 17280, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 17280, 270, 270, 270, 17280, 135, 270, 270, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 270, 135, 17280, 17280, 17280, 270, 135, 17280, 17280, 270, 270, 17280, 17280, 135, 17280, 17280, 270, 135, 17280, 270, 270, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 270, 17280, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 17280, 135, 135, 135, 270, 135, 270, 270, 135, 17280, 270, 17280, 135, 17280, 135, 270, 270, 270, 270, 135, 270, 17280, 17280, 135, 17280, 17280, 135, 17280, 270, 17280, 270, 270, 270, 135, 270, 135, 135, 17280, 135, 270, 135, 135, 270, 17280, 270, 17280, 135, 17280, 17280, 270, 17280, 270, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2263680 . Total input tokens: 504023803 . Total output tokens: 452587319
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 91.77948850393295,
    "estimated_duration": 3600.139098083206,
    "input_throughput": 5317.309825665399,
    "output_throughput": 4676.789296548136,
    "total_throughput": 9994.099122213536,
    "itl": 181.16950784545625,
    "ttft": 2066107.157930141,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 389,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2907391806691926,
    "arrivals": 753814,
    "finished_requests": 77648,
    "scheduler_time": 137.00124601814258
}
#Debug simulation 
Total elapsed time: 91.77962663397193. Arrivals time: 0.36406284803524613 Scheduler time: 91.2785746040754 Scheduler overhead time: 0.052305970806628466 Adapter cache time: 0.014019099995493889 Engine time: 0.051680962555110455 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-16/adapters_384_slots_96_rate_1.6-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-16/adapters_384_slots_96_rate_1.6-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 270, 135, 17280, 17280, 135, 270, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 135, 17280, 135, 17280, 270, 270, 270, 135, 135, 270, 135, 17280, 135, 17280, 270, 17280, 270, 135, 270, 17280, 270, 17280, 135, 17280, 17280, 17280, 17280, 135, 270, 270, 270, 17280, 270, 135, 270, 135, 17280, 270, 17280, 17280, 270, 17280, 17280, 135, 135, 17280, 270, 270, 135, 135, 135, 270, 135, 270, 135, 17280, 135, 270, 17280, 135, 17280, 270, 135, 17280, 17280, 17280, 17280, 270, 135, 270, 17280, 17280, 270, 135, 135, 17280, 270, 270, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 270, 17280, 17280, 135, 270, 270, 270, 270, 135, 135, 17280, 135, 17280, 135, 135, 135, 270, 270, 17280, 135, 135, 17280, 135, 17280, 270, 135, 17280, 270, 270, 135, 17280, 17280, 17280, 135, 270, 17280, 135, 17280, 270, 270, 17280, 17280, 135, 270, 17280, 135, 270, 270, 135, 270, 135, 270, 17280, 17280, 270, 135, 17280, 135, 17280, 270, 270, 270, 270, 270, 135, 135, 17280, 135, 17280, 135, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 135, 270, 270, 270, 270, 270, 270, 270, 270, 17280, 135, 135, 135, 135, 135, 270, 135, 135, 270, 17280, 17280, 135, 135, 17280, 135, 135, 135, 270, 135, 270, 17280, 17280, 270, 270, 135, 17280, 270, 17280, 135, 270, 270, 135, 135, 270, 135, 17280, 17280, 135, 17280, 17280, 135, 270, 17280, 135, 135, 270, 270, 135, 135, 17280, 17280, 17280, 17280, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 17280, 270, 270, 270, 17280, 135, 270, 270, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 270, 135, 17280, 17280, 17280, 270, 135, 17280, 17280, 270, 270, 17280, 17280, 135, 17280, 17280, 270, 135, 17280, 270, 270, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 270, 17280, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 17280, 135, 135, 135, 270, 135, 270, 270, 135, 17280, 270, 17280, 135, 17280, 135, 270, 270, 270, 270, 135, 270, 17280, 17280, 135, 17280, 17280, 135, 17280, 270, 17280, 270, 270, 270, 135, 270, 135, 135, 17280, 135, 270, 135, 135, 270, 17280, 270, 17280, 135, 17280, 17280, 270, 17280, 270, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2263680 . Total input tokens: 504023803 . Total output tokens: 452587319
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 93.05365060409531,
    "estimated_duration": 3600.1441319557352,
    "input_throughput": 5327.286991029783,
    "output_throughput": 4686.290432165241,
    "total_throughput": 10013.577423195025,
    "itl": 182.83614063137497,
    "ttft": 2065524.2511320442,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 390,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.166119615011844,
    "arrivals": 753814,
    "finished_requests": 77819,
    "scheduler_time": 136.53030082737317
}
#Debug simulation 
Total elapsed time: 93.0538091128692. Arrivals time: 0.3733035740442574 Scheduler time: 92.54298650939018 Scheduler overhead time: 0.05278807505965233 Adapter cache time: 0.014047150500118732 Engine time: 0.05184037610888481 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-32/adapters_384_slots_96_rate_1.6-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-32/adapters_384_slots_96_rate_1.6-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 270, 135, 17280, 17280, 135, 270, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 135, 17280, 135, 17280, 270, 270, 270, 135, 135, 270, 135, 17280, 135, 17280, 270, 17280, 270, 135, 270, 17280, 270, 17280, 135, 17280, 17280, 17280, 17280, 135, 270, 270, 270, 17280, 270, 135, 270, 135, 17280, 270, 17280, 17280, 270, 17280, 17280, 135, 135, 17280, 270, 270, 135, 135, 135, 270, 135, 270, 135, 17280, 135, 270, 17280, 135, 17280, 270, 135, 17280, 17280, 17280, 17280, 270, 135, 270, 17280, 17280, 270, 135, 135, 17280, 270, 270, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 270, 17280, 17280, 135, 270, 270, 270, 270, 135, 135, 17280, 135, 17280, 135, 135, 135, 270, 270, 17280, 135, 135, 17280, 135, 17280, 270, 135, 17280, 270, 270, 135, 17280, 17280, 17280, 135, 270, 17280, 135, 17280, 270, 270, 17280, 17280, 135, 270, 17280, 135, 270, 270, 135, 270, 135, 270, 17280, 17280, 270, 135, 17280, 135, 17280, 270, 270, 270, 270, 270, 135, 135, 17280, 135, 17280, 135, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 135, 270, 270, 270, 270, 270, 270, 270, 270, 17280, 135, 135, 135, 135, 135, 270, 135, 135, 270, 17280, 17280, 135, 135, 17280, 135, 135, 135, 270, 135, 270, 17280, 17280, 270, 270, 135, 17280, 270, 17280, 135, 270, 270, 135, 135, 270, 135, 17280, 17280, 135, 17280, 17280, 135, 270, 17280, 135, 135, 270, 270, 135, 135, 17280, 17280, 17280, 17280, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 17280, 270, 270, 270, 17280, 135, 270, 270, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 270, 135, 17280, 17280, 17280, 270, 135, 17280, 17280, 270, 270, 17280, 17280, 135, 17280, 17280, 270, 135, 17280, 270, 270, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 270, 17280, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 17280, 135, 135, 135, 270, 135, 270, 270, 135, 17280, 270, 17280, 135, 17280, 135, 270, 270, 270, 270, 135, 270, 17280, 17280, 135, 17280, 17280, 135, 17280, 270, 17280, 270, 270, 270, 135, 270, 135, 135, 17280, 135, 270, 135, 135, 270, 17280, 270, 17280, 135, 17280, 17280, 270, 17280, 270, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2263680 . Total input tokens: 504023803 . Total output tokens: 452587319
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 95.33240919979289,
    "estimated_duration": 3600.1421697104365,
    "input_throughput": 5317.575556061936,
    "output_throughput": 4676.879469277807,
    "total_throughput": 9994.455025339743,
    "itl": 181.18296417401334,
    "ttft": 2066186.3993896528,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 390,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3105936930328623,
    "arrivals": 753814,
    "finished_requests": 77655,
    "scheduler_time": 136.99582119165825
}
#Debug simulation 
Total elapsed time: 95.3325530202128. Arrivals time: 0.366398714017123 Scheduler time: 94.82782215671614 Scheduler overhead time: 0.053211502730846405 Adapter cache time: 0.013799196109175682 Engine time: 0.05257308064028621 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-8/adapters_384_slots_96_rate_1.6-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-8/adapters_384_slots_96_rate_1.6-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 270, 66, 17280, 17280, 66, 270, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 66, 17280, 66, 17280, 270, 270, 270, 66, 66, 270, 66, 17280, 66, 17280, 270, 17280, 270, 66, 270, 17280, 270, 17280, 66, 17280, 17280, 17280, 17280, 66, 270, 270, 270, 17280, 270, 66, 270, 66, 17280, 270, 17280, 17280, 270, 17280, 17280, 66, 66, 17280, 270, 270, 66, 66, 66, 270, 66, 270, 66, 17280, 66, 270, 17280, 66, 17280, 270, 66, 17280, 17280, 17280, 17280, 270, 66, 270, 17280, 17280, 270, 66, 66, 17280, 270, 270, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 270, 17280, 17280, 66, 270, 270, 270, 270, 66, 66, 17280, 66, 17280, 66, 66, 66, 270, 270, 17280, 66, 66, 17280, 66, 17280, 270, 66, 17280, 270, 270, 66, 17280, 17280, 17280, 66, 270, 17280, 66, 17280, 270, 270, 17280, 17280, 66, 270, 17280, 66, 270, 270, 66, 270, 66, 270, 17280, 17280, 270, 66, 17280, 66, 17280, 270, 270, 270, 270, 270, 66, 66, 17280, 66, 17280, 66, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 66, 270, 270, 270, 270, 270, 270, 270, 270, 17280, 66, 66, 66, 66, 66, 270, 66, 66, 270, 17280, 17280, 66, 66, 17280, 66, 66, 66, 270, 66, 270, 17280, 17280, 270, 270, 66, 17280, 270, 17280, 66, 270, 270, 66, 66, 270, 66, 17280, 17280, 66, 17280, 17280, 66, 270, 17280, 66, 66, 270, 270, 66, 66, 17280, 17280, 17280, 17280, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 17280, 270, 270, 270, 17280, 66, 270, 270, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 270, 66, 17280, 17280, 17280, 270, 66, 17280, 17280, 270, 270, 17280, 17280, 66, 17280, 17280, 270, 66, 17280, 270, 270, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 270, 17280, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 17280, 66, 66, 66, 270, 66, 270, 270, 66, 17280, 270, 17280, 66, 17280, 66, 270, 270, 270, 270, 66, 270, 17280, 17280, 66, 17280, 17280, 66, 17280, 270, 17280, 270, 270, 270, 66, 270, 66, 66, 17280, 66, 270, 66, 66, 270, 17280, 270, 17280, 66, 17280, 17280, 270, 17280, 270, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2254848 . Total input tokens: 502040347 . Total output tokens: 450803971
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 44.920393178239465,
    "estimated_duration": 3600.0594158185722,
    "input_throughput": 5312.8667587979335,
    "output_throughput": 4692.143947896244,
    "total_throughput": 10005.010706694176,
    "itl": 182.9960998881521,
    "ttft": 2080894.0743744797,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 796,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4361482441705204,
    "arrivals": 750842,
    "finished_requests": 77475,
    "scheduler_time": 136.52605927627326
}
#Debug simulation 
Total elapsed time: 44.920543493237346. Arrivals time: 0.33481976902112365 Scheduler time: 44.45534088881686 Scheduler overhead time: 0.04824364138767123 Adapter cache time: 0.01769428141415119 Engine time: 0.04671815223991871 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-16/adapters_384_slots_96_rate_1.6-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-16/adapters_384_slots_96_rate_1.6-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 270, 66, 17280, 17280, 66, 270, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 66, 17280, 66, 17280, 270, 270, 270, 66, 66, 270, 66, 17280, 66, 17280, 270, 17280, 270, 66, 270, 17280, 270, 17280, 66, 17280, 17280, 17280, 17280, 66, 270, 270, 270, 17280, 270, 66, 270, 66, 17280, 270, 17280, 17280, 270, 17280, 17280, 66, 66, 17280, 270, 270, 66, 66, 66, 270, 66, 270, 66, 17280, 66, 270, 17280, 66, 17280, 270, 66, 17280, 17280, 17280, 17280, 270, 66, 270, 17280, 17280, 270, 66, 66, 17280, 270, 270, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 270, 17280, 17280, 66, 270, 270, 270, 270, 66, 66, 17280, 66, 17280, 66, 66, 66, 270, 270, 17280, 66, 66, 17280, 66, 17280, 270, 66, 17280, 270, 270, 66, 17280, 17280, 17280, 66, 270, 17280, 66, 17280, 270, 270, 17280, 17280, 66, 270, 17280, 66, 270, 270, 66, 270, 66, 270, 17280, 17280, 270, 66, 17280, 66, 17280, 270, 270, 270, 270, 270, 66, 66, 17280, 66, 17280, 66, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 66, 270, 270, 270, 270, 270, 270, 270, 270, 17280, 66, 66, 66, 66, 66, 270, 66, 66, 270, 17280, 17280, 66, 66, 17280, 66, 66, 66, 270, 66, 270, 17280, 17280, 270, 270, 66, 17280, 270, 17280, 66, 270, 270, 66, 66, 270, 66, 17280, 17280, 66, 17280, 17280, 66, 270, 17280, 66, 66, 270, 270, 66, 66, 17280, 17280, 17280, 17280, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 17280, 270, 270, 270, 17280, 66, 270, 270, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 270, 66, 17280, 17280, 17280, 270, 66, 17280, 17280, 270, 270, 17280, 17280, 66, 17280, 17280, 270, 66, 17280, 270, 270, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 270, 17280, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 17280, 66, 66, 66, 270, 66, 270, 270, 66, 17280, 270, 17280, 66, 17280, 66, 270, 270, 270, 270, 66, 270, 17280, 17280, 66, 17280, 17280, 66, 17280, 270, 17280, 270, 270, 270, 66, 270, 66, 66, 17280, 66, 270, 66, 66, 270, 17280, 270, 17280, 66, 17280, 17280, 270, 17280, 270, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2254848 . Total input tokens: 502040347 . Total output tokens: 450803971
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 44.28656244697049,
    "estimated_duration": 3600.0624139577744,
    "input_throughput": 5312.820390514578,
    "output_throughput": 4692.558366350075,
    "total_throughput": 10005.378756864653,
    "itl": 182.99730072103392,
    "ttft": 2081132.8833206957,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 802,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.616210236558696,
    "arrivals": 750842,
    "finished_requests": 77472,
    "scheduler_time": 136.53967679606478
}
#Debug simulation 
Total elapsed time: 44.28673020703718. Arrivals time: 0.35354985017329454 Scheduler time: 43.801139870192856 Scheduler overhead time: 0.048400324303656816 Adapter cache time: 0.01817573793232441 Engine time: 0.04771457286551595 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-32/adapters_384_slots_96_rate_1.6-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-32/adapters_384_slots_96_rate_1.6-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 270, 66, 17280, 17280, 66, 270, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 66, 17280, 66, 17280, 270, 270, 270, 66, 66, 270, 66, 17280, 66, 17280, 270, 17280, 270, 66, 270, 17280, 270, 17280, 66, 17280, 17280, 17280, 17280, 66, 270, 270, 270, 17280, 270, 66, 270, 66, 17280, 270, 17280, 17280, 270, 17280, 17280, 66, 66, 17280, 270, 270, 66, 66, 66, 270, 66, 270, 66, 17280, 66, 270, 17280, 66, 17280, 270, 66, 17280, 17280, 17280, 17280, 270, 66, 270, 17280, 17280, 270, 66, 66, 17280, 270, 270, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 270, 17280, 17280, 66, 270, 270, 270, 270, 66, 66, 17280, 66, 17280, 66, 66, 66, 270, 270, 17280, 66, 66, 17280, 66, 17280, 270, 66, 17280, 270, 270, 66, 17280, 17280, 17280, 66, 270, 17280, 66, 17280, 270, 270, 17280, 17280, 66, 270, 17280, 66, 270, 270, 66, 270, 66, 270, 17280, 17280, 270, 66, 17280, 66, 17280, 270, 270, 270, 270, 270, 66, 66, 17280, 66, 17280, 66, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 66, 270, 270, 270, 270, 270, 270, 270, 270, 17280, 66, 66, 66, 66, 66, 270, 66, 66, 270, 17280, 17280, 66, 66, 17280, 66, 66, 66, 270, 66, 270, 17280, 17280, 270, 270, 66, 17280, 270, 17280, 66, 270, 270, 66, 66, 270, 66, 17280, 17280, 66, 17280, 17280, 66, 270, 17280, 66, 66, 270, 270, 66, 66, 17280, 17280, 17280, 17280, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 17280, 270, 270, 270, 17280, 66, 270, 270, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 270, 66, 17280, 17280, 17280, 270, 66, 17280, 17280, 270, 270, 17280, 17280, 66, 17280, 17280, 270, 66, 17280, 270, 270, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 270, 17280, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 17280, 66, 66, 66, 270, 66, 270, 270, 66, 17280, 270, 17280, 66, 17280, 66, 270, 270, 270, 270, 66, 270, 17280, 17280, 66, 17280, 17280, 66, 17280, 270, 17280, 270, 270, 270, 66, 270, 66, 66, 17280, 66, 270, 66, 66, 270, 17280, 270, 17280, 66, 17280, 17280, 270, 17280, 270, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2254848 . Total input tokens: 502040347 . Total output tokens: 450803971
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 43.648191255982965,
    "estimated_duration": 3600.043156449102,
    "input_throughput": 5288.583267645941,
    "output_throughput": 4683.687741296773,
    "total_throughput": 9972.271008942715,
    "itl": 181.0881295289537,
    "ttft": 2081893.6539464958,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 810,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.648038409538555,
    "arrivals": 750842,
    "finished_requests": 77200,
    "scheduler_time": 137.1538785966566
}
#Debug simulation 
Total elapsed time: 43.64835434220731. Arrivals time: 0.3574341149069369 Scheduler time: 43.15925137978047 Scheduler overhead time: 0.04809951689094305 Adapter cache time: 0.018570436164736748 Engine time: 0.0469876891002059 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-16/adapters_384_slots_96_rate_1.6-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-16/adapters_384_slots_96_rate_1.6-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 270, 66, 17280, 17280, 66, 270, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 66, 17280, 66, 17280, 270, 270, 270, 66, 66, 270, 66, 17280, 66, 17280, 270, 17280, 270, 66, 270, 17280, 270, 17280, 66, 17280, 17280, 17280, 17280, 66, 270, 270, 270, 17280, 270, 66, 270, 66, 17280, 270, 17280, 17280, 270, 17280, 17280, 66, 66, 17280, 270, 270, 66, 66, 66, 270, 66, 270, 66, 17280, 66, 270, 17280, 66, 17280, 270, 66, 17280, 17280, 17280, 17280, 270, 66, 270, 17280, 17280, 270, 66, 66, 17280, 270, 270, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 270, 17280, 17280, 66, 270, 270, 270, 270, 66, 66, 17280, 66, 17280, 66, 66, 66, 270, 270, 17280, 66, 66, 17280, 66, 17280, 270, 66, 17280, 270, 270, 66, 17280, 17280, 17280, 66, 270, 17280, 66, 17280, 270, 270, 17280, 17280, 66, 270, 17280, 66, 270, 270, 66, 270, 66, 270, 17280, 17280, 270, 66, 17280, 66, 17280, 270, 270, 270, 270, 270, 66, 66, 17280, 66, 17280, 66, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 66, 270, 270, 270, 270, 270, 270, 270, 270, 17280, 66, 66, 66, 66, 66, 270, 66, 66, 270, 17280, 17280, 66, 66, 17280, 66, 66, 66, 270, 66, 270, 17280, 17280, 270, 270, 66, 17280, 270, 17280, 66, 270, 270, 66, 66, 270, 66, 17280, 17280, 66, 17280, 17280, 66, 270, 17280, 66, 66, 270, 270, 66, 66, 17280, 17280, 17280, 17280, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 17280, 270, 270, 270, 17280, 66, 270, 270, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 270, 66, 17280, 17280, 17280, 270, 66, 17280, 17280, 270, 270, 17280, 17280, 66, 17280, 17280, 270, 66, 17280, 270, 270, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 270, 17280, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 17280, 66, 66, 66, 270, 66, 270, 270, 66, 17280, 270, 17280, 66, 17280, 66, 270, 270, 270, 270, 66, 270, 17280, 17280, 66, 17280, 17280, 66, 17280, 270, 17280, 270, 270, 270, 66, 270, 66, 66, 17280, 66, 270, 66, 66, 270, 17280, 270, 17280, 66, 17280, 17280, 270, 17280, 270, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2254848 . Total input tokens: 502040347 . Total output tokens: 450803971
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 44.163798334077,
    "estimated_duration": 3600.158108528765,
    "input_throughput": 5312.91999501004,
    "output_throughput": 4692.716400420561,
    "total_throughput": 10005.6363954306,
    "itl": 182.99308049783525,
    "ttft": 2081102.8490514527,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 802,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5083410724904165,
    "arrivals": 750842,
    "finished_requests": 77476,
    "scheduler_time": 136.54712507450782
}
#Debug simulation 
Total elapsed time: 44.163964551873505. Arrivals time: 0.3382599405013025 Scheduler time: 43.69503591163084 Scheduler overhead time: 0.047383020631968975 Adapter cache time: 0.01785618392750621 Engine time: 0.047454251907765865 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-32/adapters_384_slots_96_rate_1.6-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-32/adapters_384_slots_96_rate_1.6-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 270, 66, 17280, 17280, 66, 270, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 66, 17280, 66, 17280, 270, 270, 270, 66, 66, 270, 66, 17280, 66, 17280, 270, 17280, 270, 66, 270, 17280, 270, 17280, 66, 17280, 17280, 17280, 17280, 66, 270, 270, 270, 17280, 270, 66, 270, 66, 17280, 270, 17280, 17280, 270, 17280, 17280, 66, 66, 17280, 270, 270, 66, 66, 66, 270, 66, 270, 66, 17280, 66, 270, 17280, 66, 17280, 270, 66, 17280, 17280, 17280, 17280, 270, 66, 270, 17280, 17280, 270, 66, 66, 17280, 270, 270, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 270, 17280, 17280, 66, 270, 270, 270, 270, 66, 66, 17280, 66, 17280, 66, 66, 66, 270, 270, 17280, 66, 66, 17280, 66, 17280, 270, 66, 17280, 270, 270, 66, 17280, 17280, 17280, 66, 270, 17280, 66, 17280, 270, 270, 17280, 17280, 66, 270, 17280, 66, 270, 270, 66, 270, 66, 270, 17280, 17280, 270, 66, 17280, 66, 17280, 270, 270, 270, 270, 270, 66, 66, 17280, 66, 17280, 66, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 66, 270, 270, 270, 270, 270, 270, 270, 270, 17280, 66, 66, 66, 66, 66, 270, 66, 66, 270, 17280, 17280, 66, 66, 17280, 66, 66, 66, 270, 66, 270, 17280, 17280, 270, 270, 66, 17280, 270, 17280, 66, 270, 270, 66, 66, 270, 66, 17280, 17280, 66, 17280, 17280, 66, 270, 17280, 66, 66, 270, 270, 66, 66, 17280, 17280, 17280, 17280, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 17280, 270, 270, 270, 17280, 66, 270, 270, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 270, 66, 17280, 17280, 17280, 270, 66, 17280, 17280, 270, 270, 17280, 17280, 66, 17280, 17280, 270, 66, 17280, 270, 270, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 270, 17280, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 17280, 66, 66, 66, 270, 66, 270, 270, 66, 17280, 270, 17280, 66, 17280, 66, 270, 270, 270, 270, 66, 270, 17280, 17280, 66, 17280, 17280, 66, 17280, 270, 17280, 270, 270, 270, 66, 270, 66, 66, 17280, 66, 270, 66, 66, 270, 17280, 270, 17280, 66, 17280, 17280, 270, 17280, 270, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2254848 . Total input tokens: 502040347 . Total output tokens: 450803971
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 43.503261893987656,
    "estimated_duration": 3600.0774747297096,
    "input_throughput": 5288.532853429617,
    "output_throughput": 4683.643093338135,
    "total_throughput": 9972.175946767753,
    "itl": 181.08973308222366,
    "ttft": 2081906.7012428876,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 810,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.682243439443411,
    "arrivals": 750842,
    "finished_requests": 77200,
    "scheduler_time": 137.1539918473783
}
#Debug simulation 
Total elapsed time: 43.50340047292411. Arrivals time: 0.34253777051344514 Scheduler time: 43.0290784239769 Scheduler overhead time: 0.04855485260486603 Adapter cache time: 0.018418055959045887 Engine time: 0.04728502221405506 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-16/adapters_384_slots_96_rate_1.6-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-16/adapters_384_slots_96_rate_1.6-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 270, 66, 17280, 17280, 66, 270, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 66, 17280, 66, 17280, 270, 270, 270, 66, 66, 270, 66, 17280, 66, 17280, 270, 17280, 270, 66, 270, 17280, 270, 17280, 66, 17280, 17280, 17280, 17280, 66, 270, 270, 270, 17280, 270, 66, 270, 66, 17280, 270, 17280, 17280, 270, 17280, 17280, 66, 66, 17280, 270, 270, 66, 66, 66, 270, 66, 270, 66, 17280, 66, 270, 17280, 66, 17280, 270, 66, 17280, 17280, 17280, 17280, 270, 66, 270, 17280, 17280, 270, 66, 66, 17280, 270, 270, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 270, 17280, 17280, 66, 270, 270, 270, 270, 66, 66, 17280, 66, 17280, 66, 66, 66, 270, 270, 17280, 66, 66, 17280, 66, 17280, 270, 66, 17280, 270, 270, 66, 17280, 17280, 17280, 66, 270, 17280, 66, 17280, 270, 270, 17280, 17280, 66, 270, 17280, 66, 270, 270, 66, 270, 66, 270, 17280, 17280, 270, 66, 17280, 66, 17280, 270, 270, 270, 270, 270, 66, 66, 17280, 66, 17280, 66, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 66, 270, 270, 270, 270, 270, 270, 270, 270, 17280, 66, 66, 66, 66, 66, 270, 66, 66, 270, 17280, 17280, 66, 66, 17280, 66, 66, 66, 270, 66, 270, 17280, 17280, 270, 270, 66, 17280, 270, 17280, 66, 270, 270, 66, 66, 270, 66, 17280, 17280, 66, 17280, 17280, 66, 270, 17280, 66, 66, 270, 270, 66, 66, 17280, 17280, 17280, 17280, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 17280, 270, 270, 270, 17280, 66, 270, 270, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 270, 66, 17280, 17280, 17280, 270, 66, 17280, 17280, 270, 270, 17280, 17280, 66, 17280, 17280, 270, 66, 17280, 270, 270, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 270, 17280, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 17280, 66, 66, 66, 270, 66, 270, 270, 66, 17280, 270, 17280, 66, 17280, 66, 270, 270, 270, 270, 66, 270, 17280, 17280, 66, 17280, 17280, 66, 17280, 270, 17280, 270, 270, 270, 66, 270, 66, 66, 17280, 66, 270, 66, 66, 270, 17280, 270, 17280, 66, 17280, 17280, 270, 17280, 270, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2254848 . Total input tokens: 502040347 . Total output tokens: 450803971
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 44.91122244205326,
    "estimated_duration": 3600.0031521836972,
    "input_throughput": 5312.949792390634,
    "output_throughput": 4692.217280352552,
    "total_throughput": 10005.167072743185,
    "itl": 182.99350569220255,
    "ttft": 2080872.4273930225,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 796,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3800800347420843,
    "arrivals": 750842,
    "finished_requests": 77475,
    "scheduler_time": 136.5258638506997
}
#Debug simulation 
Total elapsed time: 44.91137716686353. Arrivals time: 0.35163645166903734 Scheduler time: 44.42841114336625 Scheduler overhead time: 0.04800942959263921 Adapter cache time: 0.018296681344509125 Engine time: 0.047010931186378 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-32/adapters_384_slots_96_rate_1.6-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-32/adapters_384_slots_96_rate_1.6-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 270, 66, 17280, 17280, 66, 270, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 66, 17280, 66, 17280, 270, 270, 270, 66, 66, 270, 66, 17280, 66, 17280, 270, 17280, 270, 66, 270, 17280, 270, 17280, 66, 17280, 17280, 17280, 17280, 66, 270, 270, 270, 17280, 270, 66, 270, 66, 17280, 270, 17280, 17280, 270, 17280, 17280, 66, 66, 17280, 270, 270, 66, 66, 66, 270, 66, 270, 66, 17280, 66, 270, 17280, 66, 17280, 270, 66, 17280, 17280, 17280, 17280, 270, 66, 270, 17280, 17280, 270, 66, 66, 17280, 270, 270, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 270, 17280, 17280, 66, 270, 270, 270, 270, 66, 66, 17280, 66, 17280, 66, 66, 66, 270, 270, 17280, 66, 66, 17280, 66, 17280, 270, 66, 17280, 270, 270, 66, 17280, 17280, 17280, 66, 270, 17280, 66, 17280, 270, 270, 17280, 17280, 66, 270, 17280, 66, 270, 270, 66, 270, 66, 270, 17280, 17280, 270, 66, 17280, 66, 17280, 270, 270, 270, 270, 270, 66, 66, 17280, 66, 17280, 66, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 66, 270, 270, 270, 270, 270, 270, 270, 270, 17280, 66, 66, 66, 66, 66, 270, 66, 66, 270, 17280, 17280, 66, 66, 17280, 66, 66, 66, 270, 66, 270, 17280, 17280, 270, 270, 66, 17280, 270, 17280, 66, 270, 270, 66, 66, 270, 66, 17280, 17280, 66, 17280, 17280, 66, 270, 17280, 66, 66, 270, 270, 66, 66, 17280, 17280, 17280, 17280, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 17280, 270, 270, 270, 17280, 66, 270, 270, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 270, 66, 17280, 17280, 17280, 270, 66, 17280, 17280, 270, 270, 17280, 17280, 66, 17280, 17280, 270, 66, 17280, 270, 270, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 270, 17280, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 17280, 66, 66, 66, 270, 66, 270, 270, 66, 17280, 270, 17280, 66, 17280, 66, 270, 270, 270, 270, 66, 270, 17280, 17280, 66, 17280, 17280, 66, 17280, 270, 17280, 270, 270, 270, 66, 270, 66, 66, 17280, 66, 270, 66, 66, 270, 17280, 270, 17280, 66, 17280, 17280, 270, 17280, 270, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2254848 . Total input tokens: 502040347 . Total output tokens: 450803971
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 43.51863204501569,
    "estimated_duration": 3600.111576423052,
    "input_throughput": 5288.482758336237,
    "output_throughput": 4683.598728001922,
    "total_throughput": 9972.081486338158,
    "itl": 181.09126925816165,
    "ttft": 2081920.1609133207,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 810,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7161969617754407,
    "arrivals": 750842,
    "finished_requests": 77200,
    "scheduler_time": 137.15414001840745
}
#Debug simulation 
Total elapsed time: 43.51877197017893. Arrivals time: 0.33559636771678925 Scheduler time: 43.05141074350104 Scheduler overhead time: 0.04751214664429426 Adapter cache time: 0.01840931223705411 Engine time: 0.048062887974083424 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-8/adapters_384_slots_96_rate_1.6-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-8/adapters_384_slots_96_rate_1.6-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 270, 33, 17280, 17280, 33, 270, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 33, 17280, 33, 17280, 270, 270, 270, 33, 33, 270, 33, 17280, 33, 17280, 270, 17280, 270, 33, 270, 17280, 270, 17280, 33, 17280, 17280, 17280, 17280, 33, 270, 270, 270, 17280, 270, 33, 270, 33, 17280, 270, 17280, 17280, 270, 17280, 17280, 33, 33, 17280, 270, 270, 33, 33, 33, 270, 33, 270, 33, 17280, 33, 270, 17280, 33, 17280, 270, 33, 17280, 17280, 17280, 17280, 270, 33, 270, 17280, 17280, 270, 33, 33, 17280, 270, 270, 33, 33, 17280, 270, 17280, 270, 17280, 17280, 270, 17280, 17280, 33, 270, 270, 270, 270, 33, 33, 17280, 33, 17280, 33, 33, 33, 270, 270, 17280, 33, 33, 17280, 33, 17280, 270, 33, 17280, 270, 270, 33, 17280, 17280, 17280, 33, 270, 17280, 33, 17280, 270, 270, 17280, 17280, 33, 270, 17280, 33, 270, 270, 33, 270, 33, 270, 17280, 17280, 270, 33, 17280, 33, 17280, 270, 270, 270, 270, 270, 33, 33, 17280, 33, 17280, 33, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 33, 270, 270, 270, 270, 270, 270, 270, 270, 17280, 33, 33, 33, 33, 33, 270, 33, 33, 270, 17280, 17280, 33, 33, 17280, 33, 33, 33, 270, 33, 270, 17280, 17280, 270, 270, 33, 17280, 270, 17280, 33, 270, 270, 33, 33, 270, 33, 17280, 17280, 33, 17280, 17280, 33, 270, 17280, 33, 33, 270, 270, 33, 33, 17280, 17280, 17280, 17280, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 17280, 270, 270, 270, 17280, 33, 270, 270, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 270, 33, 17280, 17280, 17280, 270, 33, 17280, 17280, 270, 270, 17280, 17280, 33, 17280, 17280, 270, 33, 17280, 270, 270, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 270, 17280, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 17280, 33, 33, 33, 270, 33, 270, 270, 33, 17280, 270, 17280, 33, 17280, 33, 270, 270, 270, 270, 33, 270, 17280, 17280, 33, 17280, 17280, 33, 17280, 270, 17280, 270, 270, 270, 33, 270, 33, 33, 17280, 33, 270, 33, 33, 270, 17280, 270, 17280, 33, 17280, 17280, 270, 17280, 270, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2250624 . Total input tokens: 501116837 . Total output tokens: 449955359
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 95.09984487993643,
    "estimated_duration": 3600.1616854810604,
    "input_throughput": 5304.64175456835,
    "output_throughput": 4697.390138948793,
    "total_throughput": 10002.031893517144,
    "itl": 183.1393010245888,
    "ttft": 2066077.4127901732,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 409,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2517394872685037,
    "arrivals": 749452,
    "finished_requests": 77428,
    "scheduler_time": 136.62504127771626
}
#Debug simulation 
Total elapsed time: 95.09998160460964. Arrivals time: 0.37355760810896754 Scheduler time: 94.58724143262953 Scheduler overhead time: 0.05363857559859753 Adapter cache time: 0.014040551148355007 Engine time: 0.052664282731711864 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-16/adapters_384_slots_96_rate_1.6-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-16/adapters_384_slots_96_rate_1.6-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 270, 33, 17280, 17280, 33, 270, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 33, 17280, 33, 17280, 270, 270, 270, 33, 33, 270, 33, 17280, 33, 17280, 270, 17280, 270, 33, 270, 17280, 270, 17280, 33, 17280, 17280, 17280, 17280, 33, 270, 270, 270, 17280, 270, 33, 270, 33, 17280, 270, 17280, 17280, 270, 17280, 17280, 33, 33, 17280, 270, 270, 33, 33, 33, 270, 33, 270, 33, 17280, 33, 270, 17280, 33, 17280, 270, 33, 17280, 17280, 17280, 17280, 270, 33, 270, 17280, 17280, 270, 33, 33, 17280, 270, 270, 33, 33, 17280, 270, 17280, 270, 17280, 17280, 270, 17280, 17280, 33, 270, 270, 270, 270, 33, 33, 17280, 33, 17280, 33, 33, 33, 270, 270, 17280, 33, 33, 17280, 33, 17280, 270, 33, 17280, 270, 270, 33, 17280, 17280, 17280, 33, 270, 17280, 33, 17280, 270, 270, 17280, 17280, 33, 270, 17280, 33, 270, 270, 33, 270, 33, 270, 17280, 17280, 270, 33, 17280, 33, 17280, 270, 270, 270, 270, 270, 33, 33, 17280, 33, 17280, 33, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 33, 270, 270, 270, 270, 270, 270, 270, 270, 17280, 33, 33, 33, 33, 33, 270, 33, 33, 270, 17280, 17280, 33, 33, 17280, 33, 33, 33, 270, 33, 270, 17280, 17280, 270, 270, 33, 17280, 270, 17280, 33, 270, 270, 33, 33, 270, 33, 17280, 17280, 33, 17280, 17280, 33, 270, 17280, 33, 33, 270, 270, 33, 33, 17280, 17280, 17280, 17280, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 17280, 270, 270, 270, 17280, 33, 270, 270, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 270, 33, 17280, 17280, 17280, 270, 33, 17280, 17280, 270, 270, 17280, 17280, 33, 17280, 17280, 270, 33, 17280, 270, 270, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 270, 17280, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 17280, 33, 33, 33, 270, 33, 270, 270, 33, 17280, 270, 17280, 33, 17280, 33, 270, 270, 270, 270, 33, 270, 17280, 17280, 33, 17280, 17280, 33, 17280, 270, 17280, 270, 270, 270, 33, 270, 33, 33, 17280, 33, 270, 33, 33, 270, 17280, 270, 17280, 33, 17280, 17280, 270, 17280, 270, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2250624 . Total input tokens: 501116837 . Total output tokens: 449955359
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 94.34085611300543,
    "estimated_duration": 3600.1930862747736,
    "input_throughput": 5302.963908459349,
    "output_throughput": 4695.727866499697,
    "total_throughput": 9998.691774959045,
    "itl": 183.17148288362094,
    "ttft": 2065857.1953781934,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 409,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3336599019123292,
    "arrivals": 749452,
    "finished_requests": 77406,
    "scheduler_time": 136.59428564862625
}
#Debug simulation 
Total elapsed time: 94.34098929725587. Arrivals time: 0.3776294752024114 Scheduler time: 93.82665973342955 Scheduler overhead time: 0.05208746716380119 Adapter cache time: 0.01441303500905633 Engine time: 0.051054255571216345 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-32/adapters_384_slots_96_rate_1.6-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-32/adapters_384_slots_96_rate_1.6-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 270, 33, 17280, 17280, 33, 270, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 33, 17280, 33, 17280, 270, 270, 270, 33, 33, 270, 33, 17280, 33, 17280, 270, 17280, 270, 33, 270, 17280, 270, 17280, 33, 17280, 17280, 17280, 17280, 33, 270, 270, 270, 17280, 270, 33, 270, 33, 17280, 270, 17280, 17280, 270, 17280, 17280, 33, 33, 17280, 270, 270, 33, 33, 33, 270, 33, 270, 33, 17280, 33, 270, 17280, 33, 17280, 270, 33, 17280, 17280, 17280, 17280, 270, 33, 270, 17280, 17280, 270, 33, 33, 17280, 270, 270, 33, 33, 17280, 270, 17280, 270, 17280, 17280, 270, 17280, 17280, 33, 270, 270, 270, 270, 33, 33, 17280, 33, 17280, 33, 33, 33, 270, 270, 17280, 33, 33, 17280, 33, 17280, 270, 33, 17280, 270, 270, 33, 17280, 17280, 17280, 33, 270, 17280, 33, 17280, 270, 270, 17280, 17280, 33, 270, 17280, 33, 270, 270, 33, 270, 33, 270, 17280, 17280, 270, 33, 17280, 33, 17280, 270, 270, 270, 270, 270, 33, 33, 17280, 33, 17280, 33, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 33, 270, 270, 270, 270, 270, 270, 270, 270, 17280, 33, 33, 33, 33, 33, 270, 33, 33, 270, 17280, 17280, 33, 33, 17280, 33, 33, 33, 270, 33, 270, 17280, 17280, 270, 270, 33, 17280, 270, 17280, 33, 270, 270, 33, 33, 270, 33, 17280, 17280, 33, 17280, 17280, 33, 270, 17280, 33, 33, 270, 270, 33, 33, 17280, 17280, 17280, 17280, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 17280, 270, 270, 270, 17280, 33, 270, 270, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 270, 33, 17280, 17280, 17280, 270, 33, 17280, 17280, 270, 270, 17280, 17280, 33, 17280, 17280, 270, 33, 17280, 270, 270, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 270, 17280, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 17280, 33, 33, 33, 270, 33, 270, 270, 33, 17280, 270, 17280, 33, 17280, 33, 270, 270, 270, 270, 33, 270, 17280, 17280, 33, 17280, 17280, 33, 17280, 270, 17280, 270, 270, 270, 33, 270, 33, 33, 17280, 33, 270, 33, 33, 270, 17280, 270, 17280, 33, 17280, 17280, 270, 17280, 270, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2250624 . Total input tokens: 501116837 . Total output tokens: 449955359
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 93.4405327104032,
    "estimated_duration": 3600.0184449820163,
    "input_throughput": 5291.576221381044,
    "output_throughput": 4685.511548839929,
    "total_throughput": 9977.087770220973,
    "itl": 181.323489956858,
    "ttft": 2066703.6806478223,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 400,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.306778125558056,
    "arrivals": 749452,
    "finished_requests": 77229,
    "scheduler_time": 137.1120973337678
}
#Debug simulation 
Total elapsed time: 93.44066311232746. Arrivals time: 0.6522709354758263 Scheduler time: 92.65090621635318 Scheduler overhead time: 0.05221675569191575 Adapter cache time: 0.014123859349638224 Engine time: 0.05169988563284278 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-16/adapters_384_slots_96_rate_1.6-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-16/adapters_384_slots_96_rate_1.6-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 270, 33, 17280, 17280, 33, 270, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 33, 17280, 33, 17280, 270, 270, 270, 33, 33, 270, 33, 17280, 33, 17280, 270, 17280, 270, 33, 270, 17280, 270, 17280, 33, 17280, 17280, 17280, 17280, 33, 270, 270, 270, 17280, 270, 33, 270, 33, 17280, 270, 17280, 17280, 270, 17280, 17280, 33, 33, 17280, 270, 270, 33, 33, 33, 270, 33, 270, 33, 17280, 33, 270, 17280, 33, 17280, 270, 33, 17280, 17280, 17280, 17280, 270, 33, 270, 17280, 17280, 270, 33, 33, 17280, 270, 270, 33, 33, 17280, 270, 17280, 270, 17280, 17280, 270, 17280, 17280, 33, 270, 270, 270, 270, 33, 33, 17280, 33, 17280, 33, 33, 33, 270, 270, 17280, 33, 33, 17280, 33, 17280, 270, 33, 17280, 270, 270, 33, 17280, 17280, 17280, 33, 270, 17280, 33, 17280, 270, 270, 17280, 17280, 33, 270, 17280, 33, 270, 270, 33, 270, 33, 270, 17280, 17280, 270, 33, 17280, 33, 17280, 270, 270, 270, 270, 270, 33, 33, 17280, 33, 17280, 33, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 33, 270, 270, 270, 270, 270, 270, 270, 270, 17280, 33, 33, 33, 33, 33, 270, 33, 33, 270, 17280, 17280, 33, 33, 17280, 33, 33, 33, 270, 33, 270, 17280, 17280, 270, 270, 33, 17280, 270, 17280, 33, 270, 270, 33, 33, 270, 33, 17280, 17280, 33, 17280, 17280, 33, 270, 17280, 33, 33, 270, 270, 33, 33, 17280, 17280, 17280, 17280, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 17280, 270, 270, 270, 17280, 33, 270, 270, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 270, 33, 17280, 17280, 17280, 270, 33, 17280, 17280, 270, 270, 17280, 17280, 33, 17280, 17280, 270, 33, 17280, 270, 270, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 270, 17280, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 17280, 33, 33, 33, 270, 33, 270, 270, 33, 17280, 270, 17280, 33, 17280, 33, 270, 270, 270, 270, 33, 270, 17280, 17280, 33, 17280, 17280, 33, 17280, 270, 17280, 270, 270, 270, 33, 270, 33, 33, 17280, 33, 270, 33, 33, 270, 17280, 270, 17280, 33, 17280, 17280, 270, 17280, 270, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2250624 . Total input tokens: 501116837 . Total output tokens: 449955359
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 94.79647811921313,
    "estimated_duration": 3600.179847240443,
    "input_throughput": 5304.614994342126,
    "output_throughput": 4697.3664421133435,
    "total_throughput": 10001.98143645547,
    "itl": 183.14023307030848,
    "ttft": 2066086.8958514812,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 409,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2756393666937926,
    "arrivals": 749452,
    "finished_requests": 77428,
    "scheduler_time": 136.6251779930159
}
#Debug simulation 
Total elapsed time: 94.79660724010319. Arrivals time: 0.3874339913018048 Scheduler time: 94.27204655157402 Scheduler overhead time: 0.05185425607487559 Adapter cache time: 0.014451518189162016 Engine time: 0.05163805279880762 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-32/adapters_384_slots_96_rate_1.6-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-32/adapters_384_slots_96_rate_1.6-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 270, 33, 17280, 17280, 33, 270, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 33, 17280, 33, 17280, 270, 270, 270, 33, 33, 270, 33, 17280, 33, 17280, 270, 17280, 270, 33, 270, 17280, 270, 17280, 33, 17280, 17280, 17280, 17280, 33, 270, 270, 270, 17280, 270, 33, 270, 33, 17280, 270, 17280, 17280, 270, 17280, 17280, 33, 33, 17280, 270, 270, 33, 33, 33, 270, 33, 270, 33, 17280, 33, 270, 17280, 33, 17280, 270, 33, 17280, 17280, 17280, 17280, 270, 33, 270, 17280, 17280, 270, 33, 33, 17280, 270, 270, 33, 33, 17280, 270, 17280, 270, 17280, 17280, 270, 17280, 17280, 33, 270, 270, 270, 270, 33, 33, 17280, 33, 17280, 33, 33, 33, 270, 270, 17280, 33, 33, 17280, 33, 17280, 270, 33, 17280, 270, 270, 33, 17280, 17280, 17280, 33, 270, 17280, 33, 17280, 270, 270, 17280, 17280, 33, 270, 17280, 33, 270, 270, 33, 270, 33, 270, 17280, 17280, 270, 33, 17280, 33, 17280, 270, 270, 270, 270, 270, 33, 33, 17280, 33, 17280, 33, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 33, 270, 270, 270, 270, 270, 270, 270, 270, 17280, 33, 33, 33, 33, 33, 270, 33, 33, 270, 17280, 17280, 33, 33, 17280, 33, 33, 33, 270, 33, 270, 17280, 17280, 270, 270, 33, 17280, 270, 17280, 33, 270, 270, 33, 33, 270, 33, 17280, 17280, 33, 17280, 17280, 33, 270, 17280, 33, 33, 270, 270, 33, 33, 17280, 17280, 17280, 17280, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 17280, 270, 270, 270, 17280, 33, 270, 270, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 270, 33, 17280, 17280, 17280, 270, 33, 17280, 17280, 270, 270, 17280, 17280, 33, 17280, 17280, 270, 33, 17280, 270, 270, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 270, 17280, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 17280, 33, 33, 33, 270, 33, 270, 270, 33, 17280, 270, 17280, 33, 17280, 33, 270, 270, 270, 270, 33, 270, 17280, 17280, 33, 17280, 17280, 33, 17280, 270, 17280, 270, 270, 270, 33, 270, 33, 33, 17280, 33, 270, 33, 33, 270, 17280, 270, 17280, 33, 17280, 17280, 270, 17280, 270, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2250624 . Total input tokens: 501116837 . Total output tokens: 449955359
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 93.51665722485632,
    "estimated_duration": 3600.079325149079,
    "input_throughput": 5291.869783789026,
    "output_throughput": 4685.770916812076,
    "total_throughput": 9977.640700601101,
    "itl": 181.2961502179402,
    "ttft": 2066772.3894885809,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 400,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.324132148083304,
    "arrivals": 749452,
    "finished_requests": 77234,
    "scheduler_time": 137.12991460013308
}
#Debug simulation 
Total elapsed time: 93.51679440401495. Arrivals time: 0.38219815865159035 Scheduler time: 92.99853644147515 Scheduler overhead time: 0.05190851539373398 Adapter cache time: 0.014072761870920658 Engine time: 0.05102973897010088 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-16/adapters_384_slots_96_rate_1.6-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-16/adapters_384_slots_96_rate_1.6-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 270, 33, 17280, 17280, 33, 270, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 33, 17280, 33, 17280, 270, 270, 270, 33, 33, 270, 33, 17280, 33, 17280, 270, 17280, 270, 33, 270, 17280, 270, 17280, 33, 17280, 17280, 17280, 17280, 33, 270, 270, 270, 17280, 270, 33, 270, 33, 17280, 270, 17280, 17280, 270, 17280, 17280, 33, 33, 17280, 270, 270, 33, 33, 33, 270, 33, 270, 33, 17280, 33, 270, 17280, 33, 17280, 270, 33, 17280, 17280, 17280, 17280, 270, 33, 270, 17280, 17280, 270, 33, 33, 17280, 270, 270, 33, 33, 17280, 270, 17280, 270, 17280, 17280, 270, 17280, 17280, 33, 270, 270, 270, 270, 33, 33, 17280, 33, 17280, 33, 33, 33, 270, 270, 17280, 33, 33, 17280, 33, 17280, 270, 33, 17280, 270, 270, 33, 17280, 17280, 17280, 33, 270, 17280, 33, 17280, 270, 270, 17280, 17280, 33, 270, 17280, 33, 270, 270, 33, 270, 33, 270, 17280, 17280, 270, 33, 17280, 33, 17280, 270, 270, 270, 270, 270, 33, 33, 17280, 33, 17280, 33, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 33, 270, 270, 270, 270, 270, 270, 270, 270, 17280, 33, 33, 33, 33, 33, 270, 33, 33, 270, 17280, 17280, 33, 33, 17280, 33, 33, 33, 270, 33, 270, 17280, 17280, 270, 270, 33, 17280, 270, 17280, 33, 270, 270, 33, 33, 270, 33, 17280, 17280, 33, 17280, 17280, 33, 270, 17280, 33, 33, 270, 270, 33, 33, 17280, 17280, 17280, 17280, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 17280, 270, 270, 270, 17280, 33, 270, 270, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 270, 33, 17280, 17280, 17280, 270, 33, 17280, 17280, 270, 270, 17280, 17280, 33, 17280, 17280, 270, 33, 17280, 270, 270, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 270, 17280, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 17280, 33, 33, 33, 270, 33, 270, 270, 33, 17280, 270, 17280, 33, 17280, 33, 270, 270, 270, 270, 33, 270, 17280, 17280, 33, 17280, 17280, 33, 17280, 270, 17280, 270, 270, 270, 33, 270, 33, 33, 17280, 33, 270, 33, 33, 270, 17280, 270, 17280, 33, 17280, 17280, 270, 17280, 270, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2250624 . Total input tokens: 501116837 . Total output tokens: 449955359
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 95.10884675197303,
    "estimated_duration": 3600.1058010378065,
    "input_throughput": 5304.7240985236385,
    "output_throughput": 4697.4630565371,
    "total_throughput": 10002.18715506074,
    "itl": 183.1392445660626,
    "ttft": 2066075.8657468492,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 407,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2169504700251792,
    "arrivals": 749452,
    "finished_requests": 77428,
    "scheduler_time": 136.62334774719133
}
#Debug simulation 
Total elapsed time: 95.10897688707337. Arrivals time: 0.6630965862423182 Scheduler time: 94.30909641413018 Scheduler overhead time: 0.05217117536813021 Adapter cache time: 0.014288077130913734 Engine time: 0.05158550012856722 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-32/adapters_384_slots_96_rate_1.6-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-32/adapters_384_slots_96_rate_1.6-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 270, 33, 17280, 17280, 33, 270, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 33, 17280, 33, 17280, 270, 270, 270, 33, 33, 270, 33, 17280, 33, 17280, 270, 17280, 270, 33, 270, 17280, 270, 17280, 33, 17280, 17280, 17280, 17280, 33, 270, 270, 270, 17280, 270, 33, 270, 33, 17280, 270, 17280, 17280, 270, 17280, 17280, 33, 33, 17280, 270, 270, 33, 33, 33, 270, 33, 270, 33, 17280, 33, 270, 17280, 33, 17280, 270, 33, 17280, 17280, 17280, 17280, 270, 33, 270, 17280, 17280, 270, 33, 33, 17280, 270, 270, 33, 33, 17280, 270, 17280, 270, 17280, 17280, 270, 17280, 17280, 33, 270, 270, 270, 270, 33, 33, 17280, 33, 17280, 33, 33, 33, 270, 270, 17280, 33, 33, 17280, 33, 17280, 270, 33, 17280, 270, 270, 33, 17280, 17280, 17280, 33, 270, 17280, 33, 17280, 270, 270, 17280, 17280, 33, 270, 17280, 33, 270, 270, 33, 270, 33, 270, 17280, 17280, 270, 33, 17280, 33, 17280, 270, 270, 270, 270, 270, 33, 33, 17280, 33, 17280, 33, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 33, 270, 270, 270, 270, 270, 270, 270, 270, 17280, 33, 33, 33, 33, 33, 270, 33, 33, 270, 17280, 17280, 33, 33, 17280, 33, 33, 33, 270, 33, 270, 17280, 17280, 270, 270, 33, 17280, 270, 17280, 33, 270, 270, 33, 33, 270, 33, 17280, 17280, 33, 17280, 17280, 33, 270, 17280, 33, 33, 270, 270, 33, 33, 17280, 17280, 17280, 17280, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 17280, 270, 270, 270, 17280, 33, 270, 270, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 270, 33, 17280, 17280, 17280, 270, 33, 17280, 17280, 270, 270, 17280, 17280, 33, 17280, 17280, 270, 33, 17280, 270, 270, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 270, 17280, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 17280, 33, 33, 33, 270, 33, 270, 270, 33, 17280, 270, 17280, 33, 17280, 33, 270, 270, 270, 270, 33, 270, 17280, 17280, 33, 17280, 17280, 33, 17280, 270, 17280, 270, 270, 270, 33, 270, 33, 33, 17280, 33, 270, 33, 33, 270, 17280, 270, 17280, 33, 17280, 17280, 270, 17280, 270, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2250624 . Total input tokens: 501116837 . Total output tokens: 449955359
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 93.6238969238475,
    "estimated_duration": 3600.0584379059896,
    "input_throughput": 5291.517437444847,
    "output_throughput": 4685.4594976551,
    "total_throughput": 9976.976935099947,
    "itl": 181.32322010091494,
    "ttft": 2066716.2784406745,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 400,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.340102878957989,
    "arrivals": 749452,
    "finished_requests": 77229,
    "scheduler_time": 137.11284776205184
}
#Debug simulation 
Total elapsed time: 93.62403310509399. Arrivals time: 0.38427659776061773 Scheduler time: 93.10097980266437 Scheduler overhead time: 0.05336882546544075 Adapter cache time: 0.014279501046985388 Engine time: 0.05179406423121691 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-8/adapters_384_slots_96_rate_1.6-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-8/adapters_384_slots_96_rate_1.6-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 135, 66, 17280, 17280, 66, 135, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 66, 17280, 66, 17280, 135, 135, 135, 66, 66, 135, 66, 17280, 66, 17280, 135, 17280, 135, 66, 135, 17280, 135, 17280, 66, 17280, 17280, 17280, 17280, 66, 135, 135, 135, 17280, 135, 66, 135, 66, 17280, 135, 17280, 17280, 135, 17280, 17280, 66, 66, 17280, 135, 135, 66, 66, 66, 135, 66, 135, 66, 17280, 66, 135, 17280, 66, 17280, 135, 66, 17280, 17280, 17280, 17280, 135, 66, 135, 17280, 17280, 135, 66, 66, 17280, 135, 135, 66, 66, 17280, 135, 17280, 135, 17280, 17280, 135, 17280, 17280, 66, 135, 135, 135, 135, 66, 66, 17280, 66, 17280, 66, 66, 66, 135, 135, 17280, 66, 66, 17280, 66, 17280, 135, 66, 17280, 135, 135, 66, 17280, 17280, 17280, 66, 135, 17280, 66, 17280, 135, 135, 17280, 17280, 66, 135, 17280, 66, 135, 135, 66, 135, 66, 135, 17280, 17280, 135, 66, 17280, 66, 17280, 135, 135, 135, 135, 135, 66, 66, 17280, 66, 17280, 66, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 66, 135, 135, 135, 135, 135, 135, 135, 135, 17280, 66, 66, 66, 66, 66, 135, 66, 66, 135, 17280, 17280, 66, 66, 17280, 66, 66, 66, 135, 66, 135, 17280, 17280, 135, 135, 66, 17280, 135, 17280, 66, 135, 135, 66, 66, 135, 66, 17280, 17280, 66, 17280, 17280, 66, 135, 17280, 66, 66, 135, 135, 66, 66, 17280, 17280, 17280, 17280, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 17280, 135, 135, 135, 17280, 66, 135, 135, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 135, 66, 17280, 17280, 17280, 135, 66, 17280, 17280, 135, 135, 17280, 17280, 66, 17280, 17280, 135, 66, 17280, 135, 135, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 135, 17280, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 17280, 66, 66, 66, 135, 66, 135, 135, 66, 17280, 135, 17280, 66, 17280, 66, 135, 135, 135, 135, 66, 135, 17280, 17280, 66, 17280, 17280, 66, 17280, 135, 17280, 135, 135, 135, 66, 135, 66, 66, 17280, 66, 135, 66, 66, 135, 17280, 135, 17280, 66, 17280, 17280, 135, 17280, 135, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2237568 . Total input tokens: 498215820 . Total output tokens: 447347921
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 45.5350563316606,
    "estimated_duration": 3600.108691257359,
    "input_throughput": 5376.6590567129815,
    "output_throughput": 4754.639781173304,
    "total_throughput": 10131.298837886286,
    "itl": 181.19631841771812,
    "ttft": 2088601.4599668733,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 754,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3076077589253403,
    "arrivals": 745115,
    "finished_requests": 78285,
    "scheduler_time": 138.2230582096795
}
#Debug simulation 
Total elapsed time: 45.53519831970334. Arrivals time: 0.3571258676238358 Scheduler time: 45.04892070451751 Scheduler overhead time: 0.046755493618547916 Adapter cache time: 0.017526533920317888 Engine time: 0.046937421429902315 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-16/adapters_384_slots_96_rate_1.6-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-16/adapters_384_slots_96_rate_1.6-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 135, 66, 17280, 17280, 66, 135, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 66, 17280, 66, 17280, 135, 135, 135, 66, 66, 135, 66, 17280, 66, 17280, 135, 17280, 135, 66, 135, 17280, 135, 17280, 66, 17280, 17280, 17280, 17280, 66, 135, 135, 135, 17280, 135, 66, 135, 66, 17280, 135, 17280, 17280, 135, 17280, 17280, 66, 66, 17280, 135, 135, 66, 66, 66, 135, 66, 135, 66, 17280, 66, 135, 17280, 66, 17280, 135, 66, 17280, 17280, 17280, 17280, 135, 66, 135, 17280, 17280, 135, 66, 66, 17280, 135, 135, 66, 66, 17280, 135, 17280, 135, 17280, 17280, 135, 17280, 17280, 66, 135, 135, 135, 135, 66, 66, 17280, 66, 17280, 66, 66, 66, 135, 135, 17280, 66, 66, 17280, 66, 17280, 135, 66, 17280, 135, 135, 66, 17280, 17280, 17280, 66, 135, 17280, 66, 17280, 135, 135, 17280, 17280, 66, 135, 17280, 66, 135, 135, 66, 135, 66, 135, 17280, 17280, 135, 66, 17280, 66, 17280, 135, 135, 135, 135, 135, 66, 66, 17280, 66, 17280, 66, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 66, 135, 135, 135, 135, 135, 135, 135, 135, 17280, 66, 66, 66, 66, 66, 135, 66, 66, 135, 17280, 17280, 66, 66, 17280, 66, 66, 66, 135, 66, 135, 17280, 17280, 135, 135, 66, 17280, 135, 17280, 66, 135, 135, 66, 66, 135, 66, 17280, 17280, 66, 17280, 17280, 66, 135, 17280, 66, 66, 135, 135, 66, 66, 17280, 17280, 17280, 17280, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 17280, 135, 135, 135, 17280, 66, 135, 135, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 135, 66, 17280, 17280, 17280, 135, 66, 17280, 17280, 135, 135, 17280, 17280, 66, 17280, 17280, 135, 66, 17280, 135, 135, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 135, 17280, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 17280, 66, 66, 66, 135, 66, 135, 135, 66, 17280, 135, 17280, 66, 17280, 66, 135, 135, 135, 135, 66, 135, 17280, 17280, 66, 17280, 17280, 66, 17280, 135, 17280, 135, 135, 135, 66, 135, 66, 66, 17280, 66, 135, 66, 66, 135, 17280, 135, 17280, 66, 17280, 17280, 135, 17280, 135, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2237568 . Total input tokens: 498215820 . Total output tokens: 447347921
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 45.00827028695494,
    "estimated_duration": 3600.0191136026574,
    "input_throughput": 5368.750939952158,
    "output_throughput": 4748.687565409092,
    "total_throughput": 10117.43850536125,
    "itl": 181.5176214652389,
    "ttft": 2088669.432140639,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 756,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.461915514937141,
    "arrivals": 745115,
    "finished_requests": 78183,
    "scheduler_time": 137.99279316599834
}
#Debug simulation 
Total elapsed time: 45.00843278504908. Arrivals time: 0.34517474472522736 Scheduler time: 44.53363686660305 Scheduler overhead time: 0.04721605917438865 Adapter cache time: 0.017993731424212456 Engine time: 0.04681729944422841 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-32/adapters_384_slots_96_rate_1.6-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-32/adapters_384_slots_96_rate_1.6-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 135, 66, 17280, 17280, 66, 135, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 66, 17280, 66, 17280, 135, 135, 135, 66, 66, 135, 66, 17280, 66, 17280, 135, 17280, 135, 66, 135, 17280, 135, 17280, 66, 17280, 17280, 17280, 17280, 66, 135, 135, 135, 17280, 135, 66, 135, 66, 17280, 135, 17280, 17280, 135, 17280, 17280, 66, 66, 17280, 135, 135, 66, 66, 66, 135, 66, 135, 66, 17280, 66, 135, 17280, 66, 17280, 135, 66, 17280, 17280, 17280, 17280, 135, 66, 135, 17280, 17280, 135, 66, 66, 17280, 135, 135, 66, 66, 17280, 135, 17280, 135, 17280, 17280, 135, 17280, 17280, 66, 135, 135, 135, 135, 66, 66, 17280, 66, 17280, 66, 66, 66, 135, 135, 17280, 66, 66, 17280, 66, 17280, 135, 66, 17280, 135, 135, 66, 17280, 17280, 17280, 66, 135, 17280, 66, 17280, 135, 135, 17280, 17280, 66, 135, 17280, 66, 135, 135, 66, 135, 66, 135, 17280, 17280, 135, 66, 17280, 66, 17280, 135, 135, 135, 135, 135, 66, 66, 17280, 66, 17280, 66, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 66, 135, 135, 135, 135, 135, 135, 135, 135, 17280, 66, 66, 66, 66, 66, 135, 66, 66, 135, 17280, 17280, 66, 66, 17280, 66, 66, 66, 135, 66, 135, 17280, 17280, 135, 135, 66, 17280, 135, 17280, 66, 135, 135, 66, 66, 135, 66, 17280, 17280, 66, 17280, 17280, 66, 135, 17280, 66, 66, 135, 135, 66, 66, 17280, 17280, 17280, 17280, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 17280, 135, 135, 135, 17280, 66, 135, 135, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 135, 66, 17280, 17280, 17280, 135, 66, 17280, 17280, 135, 135, 17280, 17280, 66, 17280, 17280, 135, 66, 17280, 135, 135, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 135, 17280, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 17280, 66, 66, 66, 135, 66, 135, 135, 66, 17280, 135, 17280, 66, 17280, 66, 135, 135, 135, 135, 66, 135, 17280, 17280, 66, 17280, 17280, 66, 17280, 135, 17280, 135, 135, 135, 66, 135, 66, 66, 17280, 66, 135, 66, 66, 135, 17280, 135, 17280, 66, 17280, 17280, 135, 17280, 135, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2237568 . Total input tokens: 498215820 . Total output tokens: 447347921
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 44.6395412189886,
    "estimated_duration": 3600.0591841677824,
    "input_throughput": 5349.035950488565,
    "output_throughput": 4736.108249270761,
    "total_throughput": 10085.144199759325,
    "itl": 179.76594339255547,
    "ttft": 2089595.439653469,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 749,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.444846890047187,
    "arrivals": 745115,
    "finished_requests": 77894,
    "scheduler_time": 138.46536782412252
}
#Debug simulation 
Total elapsed time: 44.63968255510554. Arrivals time: 0.35448021348565817 Scheduler time: 44.15405612811446 Scheduler overhead time: 0.0475756679661572 Adapter cache time: 0.018072375562041998 Engine time: 0.047717719338834286 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-16/adapters_384_slots_96_rate_1.6-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-16/adapters_384_slots_96_rate_1.6-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 135, 66, 17280, 17280, 66, 135, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 66, 17280, 66, 17280, 135, 135, 135, 66, 66, 135, 66, 17280, 66, 17280, 135, 17280, 135, 66, 135, 17280, 135, 17280, 66, 17280, 17280, 17280, 17280, 66, 135, 135, 135, 17280, 135, 66, 135, 66, 17280, 135, 17280, 17280, 135, 17280, 17280, 66, 66, 17280, 135, 135, 66, 66, 66, 135, 66, 135, 66, 17280, 66, 135, 17280, 66, 17280, 135, 66, 17280, 17280, 17280, 17280, 135, 66, 135, 17280, 17280, 135, 66, 66, 17280, 135, 135, 66, 66, 17280, 135, 17280, 135, 17280, 17280, 135, 17280, 17280, 66, 135, 135, 135, 135, 66, 66, 17280, 66, 17280, 66, 66, 66, 135, 135, 17280, 66, 66, 17280, 66, 17280, 135, 66, 17280, 135, 135, 66, 17280, 17280, 17280, 66, 135, 17280, 66, 17280, 135, 135, 17280, 17280, 66, 135, 17280, 66, 135, 135, 66, 135, 66, 135, 17280, 17280, 135, 66, 17280, 66, 17280, 135, 135, 135, 135, 135, 66, 66, 17280, 66, 17280, 66, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 66, 135, 135, 135, 135, 135, 135, 135, 135, 17280, 66, 66, 66, 66, 66, 135, 66, 66, 135, 17280, 17280, 66, 66, 17280, 66, 66, 66, 135, 66, 135, 17280, 17280, 135, 135, 66, 17280, 135, 17280, 66, 135, 135, 66, 66, 135, 66, 17280, 17280, 66, 17280, 17280, 66, 135, 17280, 66, 66, 135, 135, 66, 66, 17280, 17280, 17280, 17280, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 17280, 135, 135, 135, 17280, 66, 135, 135, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 135, 66, 17280, 17280, 17280, 135, 66, 17280, 17280, 135, 135, 17280, 17280, 66, 17280, 17280, 135, 66, 17280, 135, 135, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 135, 17280, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 17280, 66, 66, 66, 135, 66, 135, 135, 66, 17280, 135, 17280, 66, 17280, 66, 135, 135, 135, 135, 66, 135, 17280, 17280, 66, 17280, 17280, 66, 17280, 135, 17280, 135, 135, 135, 66, 135, 66, 66, 17280, 66, 135, 66, 66, 135, 17280, 135, 17280, 66, 17280, 17280, 135, 17280, 135, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2237568 . Total input tokens: 498215820 . Total output tokens: 447347921
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 45.635554861743,
    "estimated_duration": 3600.130822034289,
    "input_throughput": 5367.986874732503,
    "output_throughput": 4748.960758692441,
    "total_throughput": 10116.947633424945,
    "itl": 181.46432204486987,
    "ttft": 2088193.877636474,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 750,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.351224075881747,
    "arrivals": 745115,
    "finished_requests": 78203,
    "scheduler_time": 138.04199834609997
}
#Debug simulation 
Total elapsed time: 45.63571176491678. Arrivals time: 0.35049848165363073 Scheduler time: 45.15567754022777 Scheduler overhead time: 0.047019192948937416 Adapter cache time: 0.017516530118882656 Engine time: 0.04709055460989475 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-32/adapters_384_slots_96_rate_1.6-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-32/adapters_384_slots_96_rate_1.6-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 135, 66, 17280, 17280, 66, 135, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 66, 17280, 66, 17280, 135, 135, 135, 66, 66, 135, 66, 17280, 66, 17280, 135, 17280, 135, 66, 135, 17280, 135, 17280, 66, 17280, 17280, 17280, 17280, 66, 135, 135, 135, 17280, 135, 66, 135, 66, 17280, 135, 17280, 17280, 135, 17280, 17280, 66, 66, 17280, 135, 135, 66, 66, 66, 135, 66, 135, 66, 17280, 66, 135, 17280, 66, 17280, 135, 66, 17280, 17280, 17280, 17280, 135, 66, 135, 17280, 17280, 135, 66, 66, 17280, 135, 135, 66, 66, 17280, 135, 17280, 135, 17280, 17280, 135, 17280, 17280, 66, 135, 135, 135, 135, 66, 66, 17280, 66, 17280, 66, 66, 66, 135, 135, 17280, 66, 66, 17280, 66, 17280, 135, 66, 17280, 135, 135, 66, 17280, 17280, 17280, 66, 135, 17280, 66, 17280, 135, 135, 17280, 17280, 66, 135, 17280, 66, 135, 135, 66, 135, 66, 135, 17280, 17280, 135, 66, 17280, 66, 17280, 135, 135, 135, 135, 135, 66, 66, 17280, 66, 17280, 66, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 66, 135, 135, 135, 135, 135, 135, 135, 135, 17280, 66, 66, 66, 66, 66, 135, 66, 66, 135, 17280, 17280, 66, 66, 17280, 66, 66, 66, 135, 66, 135, 17280, 17280, 135, 135, 66, 17280, 135, 17280, 66, 135, 135, 66, 66, 135, 66, 17280, 17280, 66, 17280, 17280, 66, 135, 17280, 66, 66, 135, 135, 66, 66, 17280, 17280, 17280, 17280, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 17280, 135, 135, 135, 17280, 66, 135, 135, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 135, 66, 17280, 17280, 17280, 135, 66, 17280, 17280, 135, 135, 17280, 17280, 66, 17280, 17280, 135, 66, 17280, 135, 135, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 135, 17280, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 17280, 66, 66, 66, 135, 66, 135, 135, 66, 17280, 135, 17280, 66, 17280, 66, 135, 135, 135, 135, 66, 135, 17280, 17280, 66, 17280, 17280, 66, 17280, 135, 17280, 135, 135, 135, 66, 135, 66, 66, 17280, 66, 135, 66, 66, 135, 17280, 135, 17280, 66, 17280, 17280, 135, 17280, 135, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2237568 . Total input tokens: 498215820 . Total output tokens: 447347921
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 44.31026037875563,
    "estimated_duration": 3600.0872186034653,
    "input_throughput": 5348.994296718749,
    "output_throughput": 4736.071368463703,
    "total_throughput": 10085.065665182452,
    "itl": 179.76720475220844,
    "ttft": 2089604.3084183366,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 749,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4727642306312925,
    "arrivals": 745115,
    "finished_requests": 77894,
    "scheduler_time": 138.46548491928178
}
#Debug simulation 
Total elapsed time: 44.31039889296517. Arrivals time: 0.3304239194840193 Scheduler time: 43.84988839644939 Scheduler overhead time: 0.04748519463464618 Adapter cache time: 0.01774585759267211 Engine time: 0.04727355344220996 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-16/adapters_384_slots_96_rate_1.6-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-16/adapters_384_slots_96_rate_1.6-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 135, 66, 17280, 17280, 66, 135, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 66, 17280, 66, 17280, 135, 135, 135, 66, 66, 135, 66, 17280, 66, 17280, 135, 17280, 135, 66, 135, 17280, 135, 17280, 66, 17280, 17280, 17280, 17280, 66, 135, 135, 135, 17280, 135, 66, 135, 66, 17280, 135, 17280, 17280, 135, 17280, 17280, 66, 66, 17280, 135, 135, 66, 66, 66, 135, 66, 135, 66, 17280, 66, 135, 17280, 66, 17280, 135, 66, 17280, 17280, 17280, 17280, 135, 66, 135, 17280, 17280, 135, 66, 66, 17280, 135, 135, 66, 66, 17280, 135, 17280, 135, 17280, 17280, 135, 17280, 17280, 66, 135, 135, 135, 135, 66, 66, 17280, 66, 17280, 66, 66, 66, 135, 135, 17280, 66, 66, 17280, 66, 17280, 135, 66, 17280, 135, 135, 66, 17280, 17280, 17280, 66, 135, 17280, 66, 17280, 135, 135, 17280, 17280, 66, 135, 17280, 66, 135, 135, 66, 135, 66, 135, 17280, 17280, 135, 66, 17280, 66, 17280, 135, 135, 135, 135, 135, 66, 66, 17280, 66, 17280, 66, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 66, 135, 135, 135, 135, 135, 135, 135, 135, 17280, 66, 66, 66, 66, 66, 135, 66, 66, 135, 17280, 17280, 66, 66, 17280, 66, 66, 66, 135, 66, 135, 17280, 17280, 135, 135, 66, 17280, 135, 17280, 66, 135, 135, 66, 66, 135, 66, 17280, 17280, 66, 17280, 17280, 66, 135, 17280, 66, 66, 135, 135, 66, 66, 17280, 17280, 17280, 17280, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 17280, 135, 135, 135, 17280, 66, 135, 135, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 135, 66, 17280, 17280, 17280, 135, 66, 17280, 17280, 135, 135, 17280, 17280, 66, 17280, 17280, 135, 66, 17280, 135, 135, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 135, 17280, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 17280, 66, 66, 66, 135, 66, 135, 135, 66, 17280, 135, 17280, 66, 17280, 66, 135, 135, 135, 135, 66, 135, 17280, 17280, 66, 17280, 17280, 66, 17280, 135, 17280, 135, 135, 135, 66, 135, 66, 66, 17280, 66, 135, 66, 66, 135, 17280, 135, 17280, 66, 17280, 17280, 135, 17280, 135, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2237568 . Total input tokens: 498215820 . Total output tokens: 447347921
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 45.509943768847734,
    "estimated_duration": 3600.055383112023,
    "input_throughput": 5376.738672077724,
    "output_throughput": 4754.710185931427,
    "total_throughput": 10131.448858009151,
    "itl": 181.19391040049865,
    "ttft": 2088584.8277579702,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 754,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2544979223561974,
    "arrivals": 745115,
    "finished_requests": 78285,
    "scheduler_time": 138.22285990077782
}
#Debug simulation 
Total elapsed time: 45.510087395086884. Arrivals time: 0.3472834350541234 Scheduler time: 45.03346982225776 Scheduler overhead time: 0.04706497862935066 Adapter cache time: 0.017581449821591377 Engine time: 0.04705538135021925 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-32/adapters_384_slots_96_rate_1.6-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-32/adapters_384_slots_96_rate_1.6-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 135, 66, 17280, 17280, 66, 135, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 66, 17280, 66, 17280, 135, 135, 135, 66, 66, 135, 66, 17280, 66, 17280, 135, 17280, 135, 66, 135, 17280, 135, 17280, 66, 17280, 17280, 17280, 17280, 66, 135, 135, 135, 17280, 135, 66, 135, 66, 17280, 135, 17280, 17280, 135, 17280, 17280, 66, 66, 17280, 135, 135, 66, 66, 66, 135, 66, 135, 66, 17280, 66, 135, 17280, 66, 17280, 135, 66, 17280, 17280, 17280, 17280, 135, 66, 135, 17280, 17280, 135, 66, 66, 17280, 135, 135, 66, 66, 17280, 135, 17280, 135, 17280, 17280, 135, 17280, 17280, 66, 135, 135, 135, 135, 66, 66, 17280, 66, 17280, 66, 66, 66, 135, 135, 17280, 66, 66, 17280, 66, 17280, 135, 66, 17280, 135, 135, 66, 17280, 17280, 17280, 66, 135, 17280, 66, 17280, 135, 135, 17280, 17280, 66, 135, 17280, 66, 135, 135, 66, 135, 66, 135, 17280, 17280, 135, 66, 17280, 66, 17280, 135, 135, 135, 135, 135, 66, 66, 17280, 66, 17280, 66, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 66, 135, 135, 135, 135, 135, 135, 135, 135, 17280, 66, 66, 66, 66, 66, 135, 66, 66, 135, 17280, 17280, 66, 66, 17280, 66, 66, 66, 135, 66, 135, 17280, 17280, 135, 135, 66, 17280, 135, 17280, 66, 135, 135, 66, 66, 135, 66, 17280, 17280, 66, 17280, 17280, 66, 135, 17280, 66, 66, 135, 135, 66, 66, 17280, 17280, 17280, 17280, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 17280, 135, 135, 135, 17280, 66, 135, 135, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 135, 66, 17280, 17280, 17280, 135, 66, 17280, 17280, 135, 135, 17280, 17280, 66, 17280, 17280, 135, 66, 17280, 135, 135, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 135, 17280, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 17280, 66, 66, 66, 135, 66, 135, 135, 66, 17280, 135, 17280, 66, 17280, 66, 135, 135, 135, 135, 66, 135, 17280, 17280, 66, 17280, 17280, 66, 17280, 135, 17280, 135, 135, 135, 66, 135, 66, 66, 17280, 66, 135, 66, 66, 135, 17280, 135, 17280, 66, 17280, 17280, 135, 17280, 135, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2237568 . Total input tokens: 498215820 . Total output tokens: 447347921
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 44.341741741169244,
    "estimated_duration": 3600.121061580859,
    "input_throughput": 5348.944013439391,
    "output_throughput": 4736.026846973032,
    "total_throughput": 10084.970860412423,
    "itl": 179.76870984907083,
    "ttft": 2089614.9364456406,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 749,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5064662453904876,
    "arrivals": 745115,
    "finished_requests": 77894,
    "scheduler_time": 138.46562588199058
}
#Debug simulation 
Total elapsed time: 44.34188577206805. Arrivals time: 0.35563660226762295 Scheduler time: 43.85532370163128 Scheduler overhead time: 0.04787039803341031 Adapter cache time: 0.01789245894178748 Engine time: 0.047228341456502676 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-8/adapters_384_slots_96_rate_1.6-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-8/adapters_384_slots_96_rate_1.6-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 135, 33, 17280, 17280, 33, 135, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 33, 17280, 33, 17280, 135, 135, 135, 33, 33, 135, 33, 17280, 33, 17280, 135, 17280, 135, 33, 135, 17280, 135, 17280, 33, 17280, 17280, 17280, 17280, 33, 135, 135, 135, 17280, 135, 33, 135, 33, 17280, 135, 17280, 17280, 135, 17280, 17280, 33, 33, 17280, 135, 135, 33, 33, 33, 135, 33, 135, 33, 17280, 33, 135, 17280, 33, 17280, 135, 33, 17280, 17280, 17280, 17280, 135, 33, 135, 17280, 17280, 135, 33, 33, 17280, 135, 135, 33, 33, 17280, 135, 17280, 135, 17280, 17280, 135, 17280, 17280, 33, 135, 135, 135, 135, 33, 33, 17280, 33, 17280, 33, 33, 33, 135, 135, 17280, 33, 33, 17280, 33, 17280, 135, 33, 17280, 135, 135, 33, 17280, 17280, 17280, 33, 135, 17280, 33, 17280, 135, 135, 17280, 17280, 33, 135, 17280, 33, 135, 135, 33, 135, 33, 135, 17280, 17280, 135, 33, 17280, 33, 17280, 135, 135, 135, 135, 135, 33, 33, 17280, 33, 17280, 33, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 33, 135, 135, 135, 135, 135, 135, 135, 135, 17280, 33, 33, 33, 33, 33, 135, 33, 33, 135, 17280, 17280, 33, 33, 17280, 33, 33, 33, 135, 33, 135, 17280, 17280, 135, 135, 33, 17280, 135, 17280, 33, 135, 135, 33, 33, 135, 33, 17280, 17280, 33, 17280, 17280, 33, 135, 17280, 33, 33, 135, 135, 33, 33, 17280, 17280, 17280, 17280, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 17280, 135, 135, 135, 17280, 33, 135, 135, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 135, 33, 17280, 17280, 17280, 135, 33, 17280, 17280, 135, 135, 17280, 17280, 33, 17280, 17280, 135, 33, 17280, 135, 135, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 135, 17280, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 17280, 33, 33, 33, 135, 33, 135, 135, 33, 17280, 135, 17280, 33, 17280, 33, 135, 135, 135, 135, 33, 135, 17280, 17280, 33, 17280, 17280, 33, 17280, 135, 17280, 135, 135, 135, 33, 135, 33, 33, 17280, 33, 135, 33, 33, 135, 17280, 135, 17280, 33, 17280, 17280, 135, 17280, 135, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2233344 . Total input tokens: 497296390 . Total output tokens: 446494462
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 48.71642415225506,
    "estimated_duration": 3600.108982834855,
    "input_throughput": 5391.033741627789,
    "output_throughput": 4737.4382501526525,
    "total_throughput": 10128.471991780441,
    "itl": 181.25810479521346,
    "ttft": 2065296.14230086,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 483,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4782155803195354,
    "arrivals": 743719,
    "finished_requests": 78319,
    "scheduler_time": 138.03009762330697
}
#Debug simulation 
Total elapsed time: 48.71659068996087. Arrivals time: 0.3602271038107574 Scheduler time: 48.22594975447282 Scheduler overhead time: 0.0492605846375227 Adapter cache time: 0.01431700587272644 Engine time: 0.04860381782054901 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-16/adapters_384_slots_96_rate_1.6-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-16/adapters_384_slots_96_rate_1.6-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 135, 33, 17280, 17280, 33, 135, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 33, 17280, 33, 17280, 135, 135, 135, 33, 33, 135, 33, 17280, 33, 17280, 135, 17280, 135, 33, 135, 17280, 135, 17280, 33, 17280, 17280, 17280, 17280, 33, 135, 135, 135, 17280, 135, 33, 135, 33, 17280, 135, 17280, 17280, 135, 17280, 17280, 33, 33, 17280, 135, 135, 33, 33, 33, 135, 33, 135, 33, 17280, 33, 135, 17280, 33, 17280, 135, 33, 17280, 17280, 17280, 17280, 135, 33, 135, 17280, 17280, 135, 33, 33, 17280, 135, 135, 33, 33, 17280, 135, 17280, 135, 17280, 17280, 135, 17280, 17280, 33, 135, 135, 135, 135, 33, 33, 17280, 33, 17280, 33, 33, 33, 135, 135, 17280, 33, 33, 17280, 33, 17280, 135, 33, 17280, 135, 135, 33, 17280, 17280, 17280, 33, 135, 17280, 33, 17280, 135, 135, 17280, 17280, 33, 135, 17280, 33, 135, 135, 33, 135, 33, 135, 17280, 17280, 135, 33, 17280, 33, 17280, 135, 135, 135, 135, 135, 33, 33, 17280, 33, 17280, 33, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 33, 135, 135, 135, 135, 135, 135, 135, 135, 17280, 33, 33, 33, 33, 33, 135, 33, 33, 135, 17280, 17280, 33, 33, 17280, 33, 33, 33, 135, 33, 135, 17280, 17280, 135, 135, 33, 17280, 135, 17280, 33, 135, 135, 33, 33, 135, 33, 17280, 17280, 33, 17280, 17280, 33, 135, 17280, 33, 33, 135, 135, 33, 33, 17280, 17280, 17280, 17280, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 17280, 135, 135, 135, 17280, 33, 135, 135, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 135, 33, 17280, 17280, 17280, 135, 33, 17280, 17280, 135, 135, 17280, 17280, 33, 17280, 17280, 135, 33, 17280, 135, 135, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 135, 17280, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 17280, 33, 33, 33, 135, 33, 135, 135, 33, 17280, 135, 17280, 33, 17280, 33, 135, 135, 135, 135, 33, 135, 17280, 17280, 33, 17280, 17280, 33, 17280, 135, 17280, 135, 135, 135, 33, 135, 33, 33, 17280, 33, 135, 33, 33, 135, 17280, 135, 17280, 33, 17280, 17280, 135, 17280, 135, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2233344 . Total input tokens: 497296390 . Total output tokens: 446494462
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 48.465528981760144,
    "estimated_duration": 3600.162357776829,
    "input_throughput": 5393.449536534391,
    "output_throughput": 4738.7071205685725,
    "total_throughput": 10132.156657102963,
    "itl": 181.185093266101,
    "ttft": 2065451.133086222,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 485,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5858280387497565,
    "arrivals": 743719,
    "finished_requests": 78365,
    "scheduler_time": 138.07109112594907
}
#Debug simulation 
Total elapsed time: 48.465690278913826. Arrivals time: 0.3621845147572458 Scheduler time: 47.97194957500324 Scheduler overhead time: 0.04971084417775273 Adapter cache time: 0.014146183617413044 Engine time: 0.04944544332101941 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-32/adapters_384_slots_96_rate_1.6-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-32/adapters_384_slots_96_rate_1.6-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 135, 33, 17280, 17280, 33, 135, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 33, 17280, 33, 17280, 135, 135, 135, 33, 33, 135, 33, 17280, 33, 17280, 135, 17280, 135, 33, 135, 17280, 135, 17280, 33, 17280, 17280, 17280, 17280, 33, 135, 135, 135, 17280, 135, 33, 135, 33, 17280, 135, 17280, 17280, 135, 17280, 17280, 33, 33, 17280, 135, 135, 33, 33, 33, 135, 33, 135, 33, 17280, 33, 135, 17280, 33, 17280, 135, 33, 17280, 17280, 17280, 17280, 135, 33, 135, 17280, 17280, 135, 33, 33, 17280, 135, 135, 33, 33, 17280, 135, 17280, 135, 17280, 17280, 135, 17280, 17280, 33, 135, 135, 135, 135, 33, 33, 17280, 33, 17280, 33, 33, 33, 135, 135, 17280, 33, 33, 17280, 33, 17280, 135, 33, 17280, 135, 135, 33, 17280, 17280, 17280, 33, 135, 17280, 33, 17280, 135, 135, 17280, 17280, 33, 135, 17280, 33, 135, 135, 33, 135, 33, 135, 17280, 17280, 135, 33, 17280, 33, 17280, 135, 135, 135, 135, 135, 33, 33, 17280, 33, 17280, 33, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 33, 135, 135, 135, 135, 135, 135, 135, 135, 17280, 33, 33, 33, 33, 33, 135, 33, 33, 135, 17280, 17280, 33, 33, 17280, 33, 33, 33, 135, 33, 135, 17280, 17280, 135, 135, 33, 17280, 135, 17280, 33, 135, 135, 33, 33, 135, 33, 17280, 17280, 33, 17280, 17280, 33, 135, 17280, 33, 33, 135, 135, 33, 33, 17280, 17280, 17280, 17280, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 17280, 135, 135, 135, 17280, 33, 135, 135, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 135, 33, 17280, 17280, 17280, 135, 33, 17280, 17280, 135, 135, 17280, 17280, 33, 17280, 17280, 135, 33, 17280, 135, 135, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 135, 17280, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 17280, 33, 33, 33, 135, 33, 135, 135, 33, 17280, 135, 17280, 33, 17280, 33, 135, 135, 135, 135, 33, 135, 17280, 17280, 33, 17280, 17280, 33, 17280, 135, 17280, 135, 135, 135, 33, 135, 33, 33, 17280, 33, 135, 33, 33, 135, 17280, 135, 17280, 33, 17280, 17280, 135, 17280, 135, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2233344 . Total input tokens: 497296390 . Total output tokens: 446494462
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 48.04814650816843,
    "estimated_duration": 3600.154398018157,
    "input_throughput": 5382.236664812695,
    "output_throughput": 4730.818769710471,
    "total_throughput": 10113.055434523167,
    "itl": 179.74467919707118,
    "ttft": 2065612.6225729208,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 486,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5907790811918772,
    "arrivals": 743719,
    "finished_requests": 78195,
    "scheduler_time": 138.50828387317324
}
#Debug simulation 
Total elapsed time: 48.0483132423833. Arrivals time: 0.3494954309426248 Scheduler time: 47.56780711514875 Scheduler overhead time: 0.049700831063091755 Adapter cache time: 0.014283645898103714 Engine time: 0.048896076157689095 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-16/adapters_384_slots_96_rate_1.6-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-16/adapters_384_slots_96_rate_1.6-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 135, 33, 17280, 17280, 33, 135, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 33, 17280, 33, 17280, 135, 135, 135, 33, 33, 135, 33, 17280, 33, 17280, 135, 17280, 135, 33, 135, 17280, 135, 17280, 33, 17280, 17280, 17280, 17280, 33, 135, 135, 135, 17280, 135, 33, 135, 33, 17280, 135, 17280, 17280, 135, 17280, 17280, 33, 33, 17280, 135, 135, 33, 33, 33, 135, 33, 135, 33, 17280, 33, 135, 17280, 33, 17280, 135, 33, 17280, 17280, 17280, 17280, 135, 33, 135, 17280, 17280, 135, 33, 33, 17280, 135, 135, 33, 33, 17280, 135, 17280, 135, 17280, 17280, 135, 17280, 17280, 33, 135, 135, 135, 135, 33, 33, 17280, 33, 17280, 33, 33, 33, 135, 135, 17280, 33, 33, 17280, 33, 17280, 135, 33, 17280, 135, 135, 33, 17280, 17280, 17280, 33, 135, 17280, 33, 17280, 135, 135, 17280, 17280, 33, 135, 17280, 33, 135, 135, 33, 135, 33, 135, 17280, 17280, 135, 33, 17280, 33, 17280, 135, 135, 135, 135, 135, 33, 33, 17280, 33, 17280, 33, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 33, 135, 135, 135, 135, 135, 135, 135, 135, 17280, 33, 33, 33, 33, 33, 135, 33, 33, 135, 17280, 17280, 33, 33, 17280, 33, 33, 33, 135, 33, 135, 17280, 17280, 135, 135, 33, 17280, 135, 17280, 33, 135, 135, 33, 33, 135, 33, 17280, 17280, 33, 17280, 17280, 33, 135, 17280, 33, 33, 135, 135, 33, 33, 17280, 17280, 17280, 17280, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 17280, 135, 135, 135, 17280, 33, 135, 135, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 135, 33, 17280, 17280, 17280, 135, 33, 17280, 17280, 135, 135, 17280, 17280, 33, 17280, 17280, 135, 33, 17280, 135, 135, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 135, 17280, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 17280, 33, 33, 33, 135, 33, 135, 135, 33, 17280, 135, 17280, 33, 17280, 33, 135, 135, 135, 135, 33, 135, 17280, 17280, 33, 17280, 17280, 33, 17280, 135, 17280, 135, 135, 135, 33, 135, 33, 33, 17280, 33, 135, 33, 33, 135, 17280, 135, 17280, 33, 17280, 17280, 135, 17280, 135, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2233344 . Total input tokens: 497296390 . Total output tokens: 446494462
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 48.415928367991,
    "estimated_duration": 3600.164229917206,
    "input_throughput": 5390.951012378216,
    "output_throughput": 4737.365550791061,
    "total_throughput": 10128.316563169277,
    "itl": 181.2589660833203,
    "ttft": 2065314.9856118266,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 483,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5152898778463664,
    "arrivals": 743719,
    "finished_requests": 78319,
    "scheduler_time": 138.03110295765836
}
#Debug simulation 
Total elapsed time: 48.41609682701528. Arrivals time: 0.35525421844795346 Scheduler time: 47.92980060027912 Scheduler overhead time: 0.049558158963918686 Adapter cache time: 0.014190357644110918 Engine time: 0.04890052508562803 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-32/adapters_384_slots_96_rate_1.6-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-32/adapters_384_slots_96_rate_1.6-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 135, 33, 17280, 17280, 33, 135, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 33, 17280, 33, 17280, 135, 135, 135, 33, 33, 135, 33, 17280, 33, 17280, 135, 17280, 135, 33, 135, 17280, 135, 17280, 33, 17280, 17280, 17280, 17280, 33, 135, 135, 135, 17280, 135, 33, 135, 33, 17280, 135, 17280, 17280, 135, 17280, 17280, 33, 33, 17280, 135, 135, 33, 33, 33, 135, 33, 135, 33, 17280, 33, 135, 17280, 33, 17280, 135, 33, 17280, 17280, 17280, 17280, 135, 33, 135, 17280, 17280, 135, 33, 33, 17280, 135, 135, 33, 33, 17280, 135, 17280, 135, 17280, 17280, 135, 17280, 17280, 33, 135, 135, 135, 135, 33, 33, 17280, 33, 17280, 33, 33, 33, 135, 135, 17280, 33, 33, 17280, 33, 17280, 135, 33, 17280, 135, 135, 33, 17280, 17280, 17280, 33, 135, 17280, 33, 17280, 135, 135, 17280, 17280, 33, 135, 17280, 33, 135, 135, 33, 135, 33, 135, 17280, 17280, 135, 33, 17280, 33, 17280, 135, 135, 135, 135, 135, 33, 33, 17280, 33, 17280, 33, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 33, 135, 135, 135, 135, 135, 135, 135, 135, 17280, 33, 33, 33, 33, 33, 135, 33, 33, 135, 17280, 17280, 33, 33, 17280, 33, 33, 33, 135, 33, 135, 17280, 17280, 135, 135, 33, 17280, 135, 17280, 33, 135, 135, 33, 33, 135, 33, 17280, 17280, 33, 17280, 17280, 33, 135, 17280, 33, 33, 135, 135, 33, 33, 17280, 17280, 17280, 17280, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 17280, 135, 135, 135, 17280, 33, 135, 135, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 135, 33, 17280, 17280, 17280, 135, 33, 17280, 17280, 135, 135, 17280, 17280, 33, 17280, 17280, 135, 33, 17280, 135, 135, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 135, 17280, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 17280, 33, 33, 33, 135, 33, 135, 135, 33, 17280, 135, 17280, 33, 17280, 33, 135, 135, 135, 135, 33, 135, 17280, 17280, 33, 17280, 17280, 33, 17280, 135, 17280, 135, 135, 135, 33, 135, 33, 33, 17280, 33, 135, 33, 33, 135, 17280, 135, 17280, 33, 17280, 17280, 135, 17280, 135, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2233344 . Total input tokens: 497296390 . Total output tokens: 446494462
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 48.05068374238908,
    "estimated_duration": 3600.1744156363725,
    "input_throughput": 5382.206738607389,
    "output_throughput": 4730.792465505995,
    "total_throughput": 10112.999204113383,
    "itl": 179.74547816990952,
    "ttft": 2065622.6267814573,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 486,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6103966718725908,
    "arrivals": 743719,
    "finished_requests": 78195,
    "scheduler_time": 138.50840753591325
}
#Debug simulation 
Total elapsed time: 48.05083854217082. Arrivals time: 0.35685445042327046 Scheduler time: 47.563210078980774 Scheduler overhead time: 0.049453429877758026 Adapter cache time: 0.014457790181040764 Engine time: 0.04854117799550295 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-16/adapters_384_slots_96_rate_1.6-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-16/adapters_384_slots_96_rate_1.6-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 135, 33, 17280, 17280, 33, 135, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 33, 17280, 33, 17280, 135, 135, 135, 33, 33, 135, 33, 17280, 33, 17280, 135, 17280, 135, 33, 135, 17280, 135, 17280, 33, 17280, 17280, 17280, 17280, 33, 135, 135, 135, 17280, 135, 33, 135, 33, 17280, 135, 17280, 17280, 135, 17280, 17280, 33, 33, 17280, 135, 135, 33, 33, 33, 135, 33, 135, 33, 17280, 33, 135, 17280, 33, 17280, 135, 33, 17280, 17280, 17280, 17280, 135, 33, 135, 17280, 17280, 135, 33, 33, 17280, 135, 135, 33, 33, 17280, 135, 17280, 135, 17280, 17280, 135, 17280, 17280, 33, 135, 135, 135, 135, 33, 33, 17280, 33, 17280, 33, 33, 33, 135, 135, 17280, 33, 33, 17280, 33, 17280, 135, 33, 17280, 135, 135, 33, 17280, 17280, 17280, 33, 135, 17280, 33, 17280, 135, 135, 17280, 17280, 33, 135, 17280, 33, 135, 135, 33, 135, 33, 135, 17280, 17280, 135, 33, 17280, 33, 17280, 135, 135, 135, 135, 135, 33, 33, 17280, 33, 17280, 33, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 33, 135, 135, 135, 135, 135, 135, 135, 135, 17280, 33, 33, 33, 33, 33, 135, 33, 33, 135, 17280, 17280, 33, 33, 17280, 33, 33, 33, 135, 33, 135, 17280, 17280, 135, 135, 33, 17280, 135, 17280, 33, 135, 135, 33, 33, 135, 33, 17280, 17280, 33, 17280, 17280, 33, 135, 17280, 33, 33, 135, 135, 33, 33, 17280, 17280, 17280, 17280, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 17280, 135, 135, 135, 17280, 33, 135, 135, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 135, 33, 17280, 17280, 17280, 135, 33, 17280, 17280, 135, 135, 17280, 17280, 33, 17280, 17280, 135, 33, 17280, 135, 135, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 135, 17280, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 17280, 33, 33, 33, 135, 33, 135, 135, 33, 17280, 135, 17280, 33, 17280, 33, 135, 135, 135, 135, 33, 135, 17280, 17280, 33, 17280, 17280, 33, 17280, 135, 17280, 135, 135, 135, 33, 135, 33, 33, 17280, 33, 135, 33, 33, 135, 17280, 135, 17280, 33, 17280, 17280, 135, 17280, 135, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2233344 . Total input tokens: 497296390 . Total output tokens: 446494462
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 65.66505658021197,
    "estimated_duration": 3600.02503979668,
    "input_throughput": 5495.109278772479,
    "output_throughput": 4840.41133252344,
    "total_throughput": 10335.520611295919,
    "itl": 177.7905268593713,
    "ttft": 2100059.1658565323,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 751,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.245527771471491,
    "arrivals": 743719,
    "finished_requests": 79908,
    "scheduler_time": 140.80684209395616
}
#Debug simulation 
Total elapsed time: 65.66520053427666. Arrivals time: 0.3699081731028855 Scheduler time: 65.16000033775344 Scheduler overhead time: 0.04967726860195398 Adapter cache time: 0.018247482366859913 Engine time: 0.048865319695323706 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-32/adapters_384_slots_96_rate_1.6-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-32/adapters_384_slots_96_rate_1.6-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 135, 33, 17280, 17280, 33, 135, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 33, 17280, 33, 17280, 135, 135, 135, 33, 33, 135, 33, 17280, 33, 17280, 135, 17280, 135, 33, 135, 17280, 135, 17280, 33, 17280, 17280, 17280, 17280, 33, 135, 135, 135, 17280, 135, 33, 135, 33, 17280, 135, 17280, 17280, 135, 17280, 17280, 33, 33, 17280, 135, 135, 33, 33, 33, 135, 33, 135, 33, 17280, 33, 135, 17280, 33, 17280, 135, 33, 17280, 17280, 17280, 17280, 135, 33, 135, 17280, 17280, 135, 33, 33, 17280, 135, 135, 33, 33, 17280, 135, 17280, 135, 17280, 17280, 135, 17280, 17280, 33, 135, 135, 135, 135, 33, 33, 17280, 33, 17280, 33, 33, 33, 135, 135, 17280, 33, 33, 17280, 33, 17280, 135, 33, 17280, 135, 135, 33, 17280, 17280, 17280, 33, 135, 17280, 33, 17280, 135, 135, 17280, 17280, 33, 135, 17280, 33, 135, 135, 33, 135, 33, 135, 17280, 17280, 135, 33, 17280, 33, 17280, 135, 135, 135, 135, 135, 33, 33, 17280, 33, 17280, 33, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 33, 135, 135, 135, 135, 135, 135, 135, 135, 17280, 33, 33, 33, 33, 33, 135, 33, 33, 135, 17280, 17280, 33, 33, 17280, 33, 33, 33, 135, 33, 135, 17280, 17280, 135, 135, 33, 17280, 135, 17280, 33, 135, 135, 33, 33, 135, 33, 17280, 17280, 33, 17280, 17280, 33, 135, 17280, 33, 33, 135, 135, 33, 33, 17280, 17280, 17280, 17280, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 17280, 135, 135, 135, 17280, 33, 135, 135, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 135, 33, 17280, 17280, 17280, 135, 33, 17280, 17280, 135, 135, 17280, 17280, 33, 17280, 17280, 135, 33, 17280, 135, 135, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 135, 17280, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 17280, 33, 33, 33, 135, 33, 135, 135, 33, 17280, 135, 17280, 33, 17280, 33, 135, 135, 135, 135, 33, 135, 17280, 17280, 33, 17280, 17280, 33, 17280, 135, 17280, 135, 135, 135, 33, 135, 33, 33, 17280, 33, 135, 33, 33, 135, 17280, 135, 17280, 33, 17280, 17280, 135, 17280, 135, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2233344 . Total input tokens: 497296390 . Total output tokens: 446494462
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 48.25851212767884,
    "estimated_duration": 3600.196556143208,
    "input_throughput": 5382.173639085396,
    "output_throughput": 4730.7633720547665,
    "total_throughput": 10112.937011140162,
    "itl": 179.74641312647566,
    "ttft": 2065633.7613529554,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 486,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6324035844951854,
    "arrivals": 743719,
    "finished_requests": 78195,
    "scheduler_time": 138.50854113011678
}
#Debug simulation 
Total elapsed time: 48.25868497882038. Arrivals time: 0.3679136959835887 Scheduler time: 47.75723463809118 Scheduler overhead time: 0.050426488276571035 Adapter cache time: 0.014726901426911354 Engine time: 0.049920523539185524 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-8/adapters_384_slots_96_rate_1.6-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-8/adapters_384_slots_96_rate_1.6-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 66, 33, 17280, 17280, 33, 66, 17280, 17280, 17280, 17280, 66, 66, 66, 66, 17280, 17280, 66, 66, 33, 17280, 33, 17280, 66, 66, 66, 33, 33, 66, 33, 17280, 33, 17280, 66, 17280, 66, 33, 66, 17280, 66, 17280, 33, 17280, 17280, 17280, 17280, 33, 66, 66, 66, 17280, 66, 33, 66, 33, 17280, 66, 17280, 17280, 66, 17280, 17280, 33, 33, 17280, 66, 66, 33, 33, 33, 66, 33, 66, 33, 17280, 33, 66, 17280, 33, 17280, 66, 33, 17280, 17280, 17280, 17280, 66, 33, 66, 17280, 17280, 66, 33, 33, 17280, 66, 66, 33, 33, 17280, 66, 17280, 66, 17280, 17280, 66, 17280, 17280, 33, 66, 66, 66, 66, 33, 33, 17280, 33, 17280, 33, 33, 33, 66, 66, 17280, 33, 33, 17280, 33, 17280, 66, 33, 17280, 66, 66, 33, 17280, 17280, 17280, 33, 66, 17280, 33, 17280, 66, 66, 17280, 17280, 33, 66, 17280, 33, 66, 66, 33, 66, 33, 66, 17280, 17280, 66, 33, 17280, 33, 17280, 66, 66, 66, 66, 66, 33, 33, 17280, 33, 17280, 33, 66, 17280, 66, 17280, 66, 17280, 66, 17280, 33, 66, 66, 66, 66, 66, 66, 66, 66, 17280, 33, 33, 33, 33, 33, 66, 33, 33, 66, 17280, 17280, 33, 33, 17280, 33, 33, 33, 66, 33, 66, 17280, 17280, 66, 66, 33, 17280, 66, 17280, 33, 66, 66, 33, 33, 66, 33, 17280, 17280, 33, 17280, 17280, 33, 66, 17280, 33, 33, 66, 66, 33, 33, 17280, 17280, 17280, 17280, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 17280, 66, 66, 66, 17280, 33, 66, 66, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 66, 33, 17280, 17280, 17280, 66, 33, 17280, 17280, 66, 66, 17280, 17280, 33, 17280, 17280, 66, 33, 17280, 66, 66, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 66, 17280, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 17280, 33, 33, 33, 66, 33, 66, 66, 33, 17280, 66, 17280, 33, 17280, 33, 66, 66, 66, 66, 33, 66, 17280, 17280, 33, 17280, 17280, 33, 17280, 66, 17280, 66, 66, 66, 33, 66, 33, 33, 17280, 33, 66, 33, 33, 66, 17280, 66, 17280, 33, 17280, 17280, 66, 17280, 66, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2224512 . Total input tokens: 495337016 . Total output tokens: 444733421
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 46.39389359531924,
    "estimated_duration": 3600.0654566700755,
    "input_throughput": 5496.652002073161,
    "output_throughput": 4830.103565973459,
    "total_throughput": 10326.75556804662,
    "itl": 177.34585504907298,
    "ttft": 2073772.2729805624,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 459,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4047638744651467,
    "arrivals": 740875,
    "finished_requests": 80055,
    "scheduler_time": 140.7199481561583
}
#Debug simulation 
Total elapsed time: 46.39406343596056. Arrivals time: 0.3720341585576534 Scheduler time: 45.891175858676434 Scheduler overhead time: 0.04912100872024894 Adapter cache time: 0.013811728451400995 Engine time: 0.049582444597035646 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-16/adapters_384_slots_96_rate_1.6-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-16/adapters_384_slots_96_rate_1.6-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 66, 33, 17280, 17280, 33, 66, 17280, 17280, 17280, 17280, 66, 66, 66, 66, 17280, 17280, 66, 66, 33, 17280, 33, 17280, 66, 66, 66, 33, 33, 66, 33, 17280, 33, 17280, 66, 17280, 66, 33, 66, 17280, 66, 17280, 33, 17280, 17280, 17280, 17280, 33, 66, 66, 66, 17280, 66, 33, 66, 33, 17280, 66, 17280, 17280, 66, 17280, 17280, 33, 33, 17280, 66, 66, 33, 33, 33, 66, 33, 66, 33, 17280, 33, 66, 17280, 33, 17280, 66, 33, 17280, 17280, 17280, 17280, 66, 33, 66, 17280, 17280, 66, 33, 33, 17280, 66, 66, 33, 33, 17280, 66, 17280, 66, 17280, 17280, 66, 17280, 17280, 33, 66, 66, 66, 66, 33, 33, 17280, 33, 17280, 33, 33, 33, 66, 66, 17280, 33, 33, 17280, 33, 17280, 66, 33, 17280, 66, 66, 33, 17280, 17280, 17280, 33, 66, 17280, 33, 17280, 66, 66, 17280, 17280, 33, 66, 17280, 33, 66, 66, 33, 66, 33, 66, 17280, 17280, 66, 33, 17280, 33, 17280, 66, 66, 66, 66, 66, 33, 33, 17280, 33, 17280, 33, 66, 17280, 66, 17280, 66, 17280, 66, 17280, 33, 66, 66, 66, 66, 66, 66, 66, 66, 17280, 33, 33, 33, 33, 33, 66, 33, 33, 66, 17280, 17280, 33, 33, 17280, 33, 33, 33, 66, 33, 66, 17280, 17280, 66, 66, 33, 17280, 66, 17280, 33, 66, 66, 33, 33, 66, 33, 17280, 17280, 33, 17280, 17280, 33, 66, 17280, 33, 33, 66, 66, 33, 33, 17280, 17280, 17280, 17280, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 17280, 66, 66, 66, 17280, 33, 66, 66, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 66, 33, 17280, 17280, 17280, 66, 33, 17280, 17280, 66, 66, 17280, 17280, 33, 17280, 17280, 66, 33, 17280, 66, 66, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 66, 17280, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 17280, 33, 33, 33, 66, 33, 66, 66, 33, 17280, 66, 17280, 33, 17280, 33, 66, 66, 66, 66, 33, 66, 17280, 17280, 33, 17280, 17280, 33, 17280, 66, 17280, 66, 66, 66, 33, 66, 33, 33, 17280, 33, 66, 33, 33, 66, 17280, 66, 17280, 33, 17280, 17280, 66, 17280, 66, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2224512 . Total input tokens: 495337016 . Total output tokens: 444733421
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 46.369380274321884,
    "estimated_duration": 3600.0333283893674,
    "input_throughput": 5494.904962129968,
    "output_throughput": 4828.1730791021355,
    "total_throughput": 10323.078041232104,
    "itl": 177.399214958869,
    "ttft": 2074042.0397541306,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 458,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.496516179100151,
    "arrivals": 740875,
    "finished_requests": 80026,
    "scheduler_time": 140.67306569214847
}
#Debug simulation 
Total elapsed time: 46.36954902531579. Arrivals time: 0.6311417482793331 Scheduler time: 45.60979460645467 Scheduler overhead time: 0.04859550204128027 Adapter cache time: 0.01369966845959425 Engine time: 0.04805968701839447 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-32/adapters_384_slots_96_rate_1.6-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-32/adapters_384_slots_96_rate_1.6-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 66, 33, 17280, 17280, 33, 66, 17280, 17280, 17280, 17280, 66, 66, 66, 66, 17280, 17280, 66, 66, 33, 17280, 33, 17280, 66, 66, 66, 33, 33, 66, 33, 17280, 33, 17280, 66, 17280, 66, 33, 66, 17280, 66, 17280, 33, 17280, 17280, 17280, 17280, 33, 66, 66, 66, 17280, 66, 33, 66, 33, 17280, 66, 17280, 17280, 66, 17280, 17280, 33, 33, 17280, 66, 66, 33, 33, 33, 66, 33, 66, 33, 17280, 33, 66, 17280, 33, 17280, 66, 33, 17280, 17280, 17280, 17280, 66, 33, 66, 17280, 17280, 66, 33, 33, 17280, 66, 66, 33, 33, 17280, 66, 17280, 66, 17280, 17280, 66, 17280, 17280, 33, 66, 66, 66, 66, 33, 33, 17280, 33, 17280, 33, 33, 33, 66, 66, 17280, 33, 33, 17280, 33, 17280, 66, 33, 17280, 66, 66, 33, 17280, 17280, 17280, 33, 66, 17280, 33, 17280, 66, 66, 17280, 17280, 33, 66, 17280, 33, 66, 66, 33, 66, 33, 66, 17280, 17280, 66, 33, 17280, 33, 17280, 66, 66, 66, 66, 66, 33, 33, 17280, 33, 17280, 33, 66, 17280, 66, 17280, 66, 17280, 66, 17280, 33, 66, 66, 66, 66, 66, 66, 66, 66, 17280, 33, 33, 33, 33, 33, 66, 33, 33, 66, 17280, 17280, 33, 33, 17280, 33, 33, 33, 66, 33, 66, 17280, 17280, 66, 66, 33, 17280, 66, 17280, 33, 66, 66, 33, 33, 66, 33, 17280, 17280, 33, 17280, 17280, 33, 66, 17280, 33, 33, 66, 66, 33, 33, 17280, 17280, 17280, 17280, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 17280, 66, 66, 66, 17280, 33, 66, 66, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 66, 33, 17280, 17280, 17280, 66, 33, 17280, 17280, 66, 66, 17280, 17280, 33, 17280, 17280, 66, 33, 17280, 66, 66, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 66, 17280, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 17280, 33, 33, 33, 66, 33, 66, 66, 33, 17280, 66, 17280, 33, 17280, 33, 66, 66, 66, 66, 33, 66, 17280, 17280, 33, 17280, 17280, 33, 17280, 66, 17280, 66, 66, 66, 33, 66, 33, 33, 17280, 33, 66, 33, 33, 66, 17280, 66, 17280, 33, 17280, 17280, 66, 17280, 66, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2224512 . Total input tokens: 495337016 . Total output tokens: 444733421
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 46.10588904796168,
    "estimated_duration": 3600.1979411466964,
    "input_throughput": 5482.751871613189,
    "output_throughput": 4819.573335590935,
    "total_throughput": 10302.325207204123,
    "itl": 175.73636127731243,
    "ttft": 2074744.3463061296,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 459,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5021963698789567,
    "arrivals": 740875,
    "finished_requests": 79862,
    "scheduler_time": 141.22551475136345
}
#Debug simulation 
Total elapsed time: 46.10604217695072. Arrivals time: 0.36363188875839114 Scheduler time: 45.6119006187655 Scheduler overhead time: 0.0486388374119997 Adapter cache time: 0.013803897891193628 Engine time: 0.049716778099536896 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-16/adapters_384_slots_96_rate_1.6-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-16/adapters_384_slots_96_rate_1.6-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 66, 33, 17280, 17280, 33, 66, 17280, 17280, 17280, 17280, 66, 66, 66, 66, 17280, 17280, 66, 66, 33, 17280, 33, 17280, 66, 66, 66, 33, 33, 66, 33, 17280, 33, 17280, 66, 17280, 66, 33, 66, 17280, 66, 17280, 33, 17280, 17280, 17280, 17280, 33, 66, 66, 66, 17280, 66, 33, 66, 33, 17280, 66, 17280, 17280, 66, 17280, 17280, 33, 33, 17280, 66, 66, 33, 33, 33, 66, 33, 66, 33, 17280, 33, 66, 17280, 33, 17280, 66, 33, 17280, 17280, 17280, 17280, 66, 33, 66, 17280, 17280, 66, 33, 33, 17280, 66, 66, 33, 33, 17280, 66, 17280, 66, 17280, 17280, 66, 17280, 17280, 33, 66, 66, 66, 66, 33, 33, 17280, 33, 17280, 33, 33, 33, 66, 66, 17280, 33, 33, 17280, 33, 17280, 66, 33, 17280, 66, 66, 33, 17280, 17280, 17280, 33, 66, 17280, 33, 17280, 66, 66, 17280, 17280, 33, 66, 17280, 33, 66, 66, 33, 66, 33, 66, 17280, 17280, 66, 33, 17280, 33, 17280, 66, 66, 66, 66, 66, 33, 33, 17280, 33, 17280, 33, 66, 17280, 66, 17280, 66, 17280, 66, 17280, 33, 66, 66, 66, 66, 66, 66, 66, 66, 17280, 33, 33, 33, 33, 33, 66, 33, 33, 66, 17280, 17280, 33, 33, 17280, 33, 33, 33, 66, 33, 66, 17280, 17280, 66, 66, 33, 17280, 66, 17280, 33, 66, 66, 33, 33, 66, 33, 17280, 17280, 33, 17280, 17280, 33, 66, 17280, 33, 33, 66, 66, 33, 33, 17280, 17280, 17280, 17280, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 17280, 66, 66, 66, 17280, 33, 66, 66, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 66, 33, 17280, 17280, 17280, 66, 33, 17280, 17280, 66, 66, 17280, 17280, 33, 17280, 17280, 66, 33, 17280, 66, 66, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 66, 17280, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 17280, 33, 33, 33, 66, 33, 66, 66, 33, 17280, 66, 17280, 33, 17280, 33, 66, 66, 66, 66, 33, 66, 17280, 17280, 33, 17280, 17280, 33, 17280, 66, 17280, 66, 66, 66, 33, 66, 33, 33, 17280, 33, 66, 33, 33, 66, 17280, 66, 17280, 33, 17280, 17280, 66, 17280, 66, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2224512 . Total input tokens: 495337016 . Total output tokens: 444733421
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 46.12228519376367,
    "estimated_duration": 3600.099166824047,
    "input_throughput": 5496.60053321724,
    "output_throughput": 4830.058338459615,
    "total_throughput": 10326.658871676855,
    "itl": 177.34719190322576,
    "ttft": 2073786.8489891726,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 459,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4382169316289912,
    "arrivals": 740875,
    "finished_requests": 80055,
    "scheduler_time": 140.72020525291694
}
#Debug simulation 
Total elapsed time: 46.12242991896346. Arrivals time: 0.3615481681190431 Scheduler time: 45.63186120754108 Scheduler overhead time: 0.04848954128101468 Adapter cache time: 0.01372002623975277 Engine time: 0.04881208250299096 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-32/adapters_384_slots_96_rate_1.6-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-32/adapters_384_slots_96_rate_1.6-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 66, 33, 17280, 17280, 33, 66, 17280, 17280, 17280, 17280, 66, 66, 66, 66, 17280, 17280, 66, 66, 33, 17280, 33, 17280, 66, 66, 66, 33, 33, 66, 33, 17280, 33, 17280, 66, 17280, 66, 33, 66, 17280, 66, 17280, 33, 17280, 17280, 17280, 17280, 33, 66, 66, 66, 17280, 66, 33, 66, 33, 17280, 66, 17280, 17280, 66, 17280, 17280, 33, 33, 17280, 66, 66, 33, 33, 33, 66, 33, 66, 33, 17280, 33, 66, 17280, 33, 17280, 66, 33, 17280, 17280, 17280, 17280, 66, 33, 66, 17280, 17280, 66, 33, 33, 17280, 66, 66, 33, 33, 17280, 66, 17280, 66, 17280, 17280, 66, 17280, 17280, 33, 66, 66, 66, 66, 33, 33, 17280, 33, 17280, 33, 33, 33, 66, 66, 17280, 33, 33, 17280, 33, 17280, 66, 33, 17280, 66, 66, 33, 17280, 17280, 17280, 33, 66, 17280, 33, 17280, 66, 66, 17280, 17280, 33, 66, 17280, 33, 66, 66, 33, 66, 33, 66, 17280, 17280, 66, 33, 17280, 33, 17280, 66, 66, 66, 66, 66, 33, 33, 17280, 33, 17280, 33, 66, 17280, 66, 17280, 66, 17280, 66, 17280, 33, 66, 66, 66, 66, 66, 66, 66, 66, 17280, 33, 33, 33, 33, 33, 66, 33, 33, 66, 17280, 17280, 33, 33, 17280, 33, 33, 33, 66, 33, 66, 17280, 17280, 66, 66, 33, 17280, 66, 17280, 33, 66, 66, 33, 33, 66, 33, 17280, 17280, 33, 17280, 17280, 33, 66, 17280, 33, 33, 66, 66, 33, 33, 17280, 17280, 17280, 17280, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 17280, 66, 66, 66, 17280, 33, 66, 66, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 66, 33, 17280, 17280, 17280, 66, 33, 17280, 17280, 66, 66, 17280, 17280, 33, 17280, 17280, 66, 33, 17280, 66, 66, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 66, 17280, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 17280, 33, 33, 33, 66, 33, 66, 66, 33, 17280, 66, 17280, 33, 17280, 33, 66, 66, 66, 66, 33, 66, 17280, 17280, 33, 17280, 17280, 33, 17280, 66, 17280, 66, 66, 66, 33, 66, 33, 33, 17280, 33, 66, 33, 33, 66, 17280, 66, 17280, 33, 17280, 17280, 66, 17280, 66, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2224512 . Total input tokens: 495337016 . Total output tokens: 444733421
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 45.444381026085466,
    "estimated_duration": 3600.0144278480616,
    "input_throughput": 5482.870526104753,
    "output_throughput": 4819.507906908941,
    "total_throughput": 10302.378433013693,
    "itl": 175.7356890160944,
    "ttft": 2074727.2313525009,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 459,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5213109454140117,
    "arrivals": 740875,
    "finished_requests": 79858,
    "scheduler_time": 141.2178447379535
}
#Debug simulation 
Total elapsed time: 45.44451744901016. Arrivals time: 0.35252329241484404 Scheduler time: 44.96257390640676 Scheduler overhead time: 0.048236110247671604 Adapter cache time: 0.013670083601027727 Engine time: 0.04869653983041644 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-16/adapters_384_slots_96_rate_1.6-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-16/adapters_384_slots_96_rate_1.6-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 66, 33, 17280, 17280, 33, 66, 17280, 17280, 17280, 17280, 66, 66, 66, 66, 17280, 17280, 66, 66, 33, 17280, 33, 17280, 66, 66, 66, 33, 33, 66, 33, 17280, 33, 17280, 66, 17280, 66, 33, 66, 17280, 66, 17280, 33, 17280, 17280, 17280, 17280, 33, 66, 66, 66, 17280, 66, 33, 66, 33, 17280, 66, 17280, 17280, 66, 17280, 17280, 33, 33, 17280, 66, 66, 33, 33, 33, 66, 33, 66, 33, 17280, 33, 66, 17280, 33, 17280, 66, 33, 17280, 17280, 17280, 17280, 66, 33, 66, 17280, 17280, 66, 33, 33, 17280, 66, 66, 33, 33, 17280, 66, 17280, 66, 17280, 17280, 66, 17280, 17280, 33, 66, 66, 66, 66, 33, 33, 17280, 33, 17280, 33, 33, 33, 66, 66, 17280, 33, 33, 17280, 33, 17280, 66, 33, 17280, 66, 66, 33, 17280, 17280, 17280, 33, 66, 17280, 33, 17280, 66, 66, 17280, 17280, 33, 66, 17280, 33, 66, 66, 33, 66, 33, 66, 17280, 17280, 66, 33, 17280, 33, 17280, 66, 66, 66, 66, 66, 33, 33, 17280, 33, 17280, 33, 66, 17280, 66, 17280, 66, 17280, 66, 17280, 33, 66, 66, 66, 66, 66, 66, 66, 66, 17280, 33, 33, 33, 33, 33, 66, 33, 33, 66, 17280, 17280, 33, 33, 17280, 33, 33, 33, 66, 33, 66, 17280, 17280, 66, 66, 33, 17280, 66, 17280, 33, 66, 66, 33, 33, 66, 33, 17280, 17280, 33, 17280, 17280, 33, 66, 17280, 33, 33, 66, 66, 33, 33, 17280, 17280, 17280, 17280, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 17280, 66, 66, 66, 17280, 33, 66, 66, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 66, 33, 17280, 17280, 17280, 66, 33, 17280, 17280, 66, 66, 17280, 17280, 33, 17280, 17280, 66, 33, 17280, 66, 66, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 66, 17280, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 17280, 33, 33, 33, 66, 33, 66, 66, 33, 17280, 66, 17280, 33, 17280, 33, 66, 66, 66, 66, 33, 66, 17280, 17280, 33, 17280, 17280, 33, 17280, 66, 17280, 66, 66, 66, 33, 66, 33, 33, 17280, 33, 66, 33, 33, 66, 17280, 66, 17280, 33, 17280, 17280, 66, 17280, 66, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2224512 . Total input tokens: 495337016 . Total output tokens: 444733421
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 46.25314090400934,
    "estimated_duration": 3600.0329213249215,
    "input_throughput": 5496.701678138349,
    "output_throughput": 4830.147218098337,
    "total_throughput": 10326.848896236686,
    "itl": 177.34450738148035,
    "ttft": 2073758.9540985522,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 459,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3724330853600868,
    "arrivals": 740875,
    "finished_requests": 80055,
    "scheduler_time": 140.71974360004563
}
#Debug simulation 
Total elapsed time: 46.25330508407205. Arrivals time: 0.35920988488942385 Scheduler time: 45.76522535458207 Scheduler overhead time: 0.04896029969677329 Adapter cache time: 0.013468888588249683 Engine time: 0.048362084198743105 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-32/adapters_384_slots_96_rate_1.6-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-32/adapters_384_slots_96_rate_1.6-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 66, 33, 17280, 17280, 33, 66, 17280, 17280, 17280, 17280, 66, 66, 66, 66, 17280, 17280, 66, 66, 33, 17280, 33, 17280, 66, 66, 66, 33, 33, 66, 33, 17280, 33, 17280, 66, 17280, 66, 33, 66, 17280, 66, 17280, 33, 17280, 17280, 17280, 17280, 33, 66, 66, 66, 17280, 66, 33, 66, 33, 17280, 66, 17280, 17280, 66, 17280, 17280, 33, 33, 17280, 66, 66, 33, 33, 33, 66, 33, 66, 33, 17280, 33, 66, 17280, 33, 17280, 66, 33, 17280, 17280, 17280, 17280, 66, 33, 66, 17280, 17280, 66, 33, 33, 17280, 66, 66, 33, 33, 17280, 66, 17280, 66, 17280, 17280, 66, 17280, 17280, 33, 66, 66, 66, 66, 33, 33, 17280, 33, 17280, 33, 33, 33, 66, 66, 17280, 33, 33, 17280, 33, 17280, 66, 33, 17280, 66, 66, 33, 17280, 17280, 17280, 33, 66, 17280, 33, 17280, 66, 66, 17280, 17280, 33, 66, 17280, 33, 66, 66, 33, 66, 33, 66, 17280, 17280, 66, 33, 17280, 33, 17280, 66, 66, 66, 66, 66, 33, 33, 17280, 33, 17280, 33, 66, 17280, 66, 17280, 66, 17280, 66, 17280, 33, 66, 66, 66, 66, 66, 66, 66, 66, 17280, 33, 33, 33, 33, 33, 66, 33, 33, 66, 17280, 17280, 33, 33, 17280, 33, 33, 33, 66, 33, 66, 17280, 17280, 66, 66, 33, 17280, 66, 17280, 33, 66, 66, 33, 33, 66, 33, 17280, 17280, 33, 17280, 17280, 33, 66, 17280, 33, 33, 66, 66, 33, 33, 17280, 17280, 17280, 17280, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 17280, 66, 66, 66, 17280, 33, 66, 66, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 66, 33, 17280, 17280, 17280, 66, 33, 17280, 17280, 66, 66, 17280, 17280, 33, 17280, 17280, 66, 33, 17280, 66, 66, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 66, 17280, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 17280, 33, 33, 33, 66, 33, 66, 66, 33, 17280, 66, 17280, 33, 17280, 33, 66, 66, 66, 66, 33, 66, 17280, 17280, 33, 17280, 17280, 33, 17280, 66, 17280, 66, 66, 66, 33, 66, 33, 33, 17280, 33, 66, 33, 33, 66, 17280, 66, 17280, 33, 17280, 17280, 66, 17280, 66, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2224512 . Total input tokens: 495337016 . Total output tokens: 444733421
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 45.77396753896028,
    "estimated_duration": 3600.0346898971316,
    "input_throughput": 5482.839666904435,
    "output_throughput": 4819.48078130763,
    "total_throughput": 10302.320448212065,
    "itl": 175.73650763836102,
    "ttft": 2074735.7541068608,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 459,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.541431551240384,
    "arrivals": 740875,
    "finished_requests": 79858,
    "scheduler_time": 141.217986181217
}
#Debug simulation 
Total elapsed time: 45.77410071482882. Arrivals time: 0.35501979710534215 Scheduler time: 45.29086722014472 Scheduler overhead time: 0.04858049238100648 Adapter cache time: 0.013670398853719234 Engine time: 0.04807282472029328 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-8/adapters_384_slots_96_rate_0.8-0.4-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-8/adapters_384_slots_96_rate_0.8-0.4-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 8640, 4320, 1080, 8640, 8640, 1080, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 1080, 8640, 1080, 8640, 4320, 4320, 4320, 1080, 1080, 4320, 1080, 8640, 1080, 8640, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 8640, 1080, 8640, 8640, 8640, 8640, 1080, 4320, 4320, 4320, 8640, 4320, 1080, 4320, 1080, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 1080, 1080, 8640, 4320, 4320, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 8640, 1080, 4320, 8640, 1080, 8640, 4320, 1080, 8640, 8640, 8640, 8640, 4320, 1080, 4320, 8640, 8640, 4320, 1080, 1080, 8640, 4320, 4320, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 8640, 1080, 8640, 1080, 1080, 1080, 4320, 4320, 8640, 1080, 1080, 8640, 1080, 8640, 4320, 1080, 8640, 4320, 4320, 1080, 8640, 8640, 8640, 1080, 4320, 8640, 1080, 8640, 4320, 4320, 8640, 8640, 1080, 4320, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 4320, 8640, 8640, 4320, 1080, 8640, 1080, 8640, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 8640, 1080, 8640, 1080, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 1080, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 1080, 4320, 8640, 8640, 1080, 1080, 8640, 1080, 1080, 1080, 4320, 1080, 4320, 8640, 8640, 4320, 4320, 1080, 8640, 4320, 8640, 1080, 4320, 4320, 1080, 1080, 4320, 1080, 8640, 8640, 1080, 8640, 8640, 1080, 4320, 8640, 1080, 1080, 4320, 4320, 1080, 1080, 8640, 8640, 8640, 8640, 4320, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 8640, 4320, 4320, 4320, 8640, 1080, 4320, 4320, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 1080, 1080, 4320, 1080, 8640, 8640, 8640, 4320, 1080, 8640, 8640, 4320, 4320, 8640, 8640, 1080, 8640, 8640, 4320, 1080, 8640, 4320, 4320, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 8640, 1080, 4320, 8640, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 8640, 1080, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 8640, 4320, 8640, 1080, 8640, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 4320, 8640, 4320, 4320, 4320, 1080, 4320, 1080, 1080, 8640, 1080, 4320, 1080, 1080, 4320, 8640, 4320, 8640, 1080, 8640, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 1080]
Prompts retrieved: 1797120 . Total input tokens: 400222001 . Total output tokens: 359316789
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 62.124211837071925,
    "estimated_duration": 3600.189732997539,
    "input_throughput": 5283.627644858072,
    "output_throughput": 4678.7320250411685,
    "total_throughput": 9962.35966989924,
    "itl": 182.45643750242652,
    "ttft": 2061051.4941832272,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 712,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.17906727368016,
    "arrivals": 599139,
    "finished_requests": 76936,
    "scheduler_time": 136.3946735514695
}
#Debug simulation 
Total elapsed time: 62.12436289899051. Arrivals time: 0.38629463594406843 Scheduler time: 61.60595707129687 Scheduler overhead time: 0.04755589226260781 Adapter cache time: 0.019467684905976057 Engine time: 0.047262104228138924 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-16/adapters_384_slots_96_rate_0.8-0.4-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-16/adapters_384_slots_96_rate_0.8-0.4-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 8640, 4320, 1080, 8640, 8640, 1080, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 1080, 8640, 1080, 8640, 4320, 4320, 4320, 1080, 1080, 4320, 1080, 8640, 1080, 8640, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 8640, 1080, 8640, 8640, 8640, 8640, 1080, 4320, 4320, 4320, 8640, 4320, 1080, 4320, 1080, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 1080, 1080, 8640, 4320, 4320, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 8640, 1080, 4320, 8640, 1080, 8640, 4320, 1080, 8640, 8640, 8640, 8640, 4320, 1080, 4320, 8640, 8640, 4320, 1080, 1080, 8640, 4320, 4320, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 8640, 1080, 8640, 1080, 1080, 1080, 4320, 4320, 8640, 1080, 1080, 8640, 1080, 8640, 4320, 1080, 8640, 4320, 4320, 1080, 8640, 8640, 8640, 1080, 4320, 8640, 1080, 8640, 4320, 4320, 8640, 8640, 1080, 4320, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 4320, 8640, 8640, 4320, 1080, 8640, 1080, 8640, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 8640, 1080, 8640, 1080, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 1080, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 1080, 4320, 8640, 8640, 1080, 1080, 8640, 1080, 1080, 1080, 4320, 1080, 4320, 8640, 8640, 4320, 4320, 1080, 8640, 4320, 8640, 1080, 4320, 4320, 1080, 1080, 4320, 1080, 8640, 8640, 1080, 8640, 8640, 1080, 4320, 8640, 1080, 1080, 4320, 4320, 1080, 1080, 8640, 8640, 8640, 8640, 4320, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 8640, 4320, 4320, 4320, 8640, 1080, 4320, 4320, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 1080, 1080, 4320, 1080, 8640, 8640, 8640, 4320, 1080, 8640, 8640, 4320, 4320, 8640, 8640, 1080, 8640, 8640, 4320, 1080, 8640, 4320, 4320, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 8640, 1080, 4320, 8640, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 8640, 1080, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 8640, 4320, 8640, 1080, 8640, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 4320, 8640, 4320, 4320, 4320, 1080, 4320, 1080, 1080, 8640, 1080, 4320, 1080, 1080, 4320, 8640, 4320, 8640, 1080, 8640, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 1080]
Prompts retrieved: 1797120 . Total input tokens: 400222001 . Total output tokens: 359316789
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 67.45943922828883,
    "estimated_duration": 3600.0290493081625,
    "input_throughput": 5290.294811276599,
    "output_throughput": 4682.115829937335,
    "total_throughput": 9972.410641213934,
    "itl": 182.9728539639597,
    "ttft": 2054773.5787055518,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 589,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9225347744813241,
    "arrivals": 599139,
    "finished_requests": 76970,
    "scheduler_time": 136.1991579035005
}
#Debug simulation 
Total elapsed time: 67.4595970143564. Arrivals time: 0.39132145745679736 Scheduler time: 66.93447240162641 Scheduler overhead time: 0.04901920445263386 Adapter cache time: 0.01751658832654357 Engine time: 0.04910800140351057 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-32/adapters_384_slots_96_rate_0.8-0.4-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-32/adapters_384_slots_96_rate_0.8-0.4-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 8640, 4320, 1080, 8640, 8640, 1080, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 1080, 8640, 1080, 8640, 4320, 4320, 4320, 1080, 1080, 4320, 1080, 8640, 1080, 8640, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 8640, 1080, 8640, 8640, 8640, 8640, 1080, 4320, 4320, 4320, 8640, 4320, 1080, 4320, 1080, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 1080, 1080, 8640, 4320, 4320, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 8640, 1080, 4320, 8640, 1080, 8640, 4320, 1080, 8640, 8640, 8640, 8640, 4320, 1080, 4320, 8640, 8640, 4320, 1080, 1080, 8640, 4320, 4320, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 8640, 1080, 8640, 1080, 1080, 1080, 4320, 4320, 8640, 1080, 1080, 8640, 1080, 8640, 4320, 1080, 8640, 4320, 4320, 1080, 8640, 8640, 8640, 1080, 4320, 8640, 1080, 8640, 4320, 4320, 8640, 8640, 1080, 4320, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 4320, 8640, 8640, 4320, 1080, 8640, 1080, 8640, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 8640, 1080, 8640, 1080, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 1080, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 1080, 4320, 8640, 8640, 1080, 1080, 8640, 1080, 1080, 1080, 4320, 1080, 4320, 8640, 8640, 4320, 4320, 1080, 8640, 4320, 8640, 1080, 4320, 4320, 1080, 1080, 4320, 1080, 8640, 8640, 1080, 8640, 8640, 1080, 4320, 8640, 1080, 1080, 4320, 4320, 1080, 1080, 8640, 8640, 8640, 8640, 4320, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 8640, 4320, 4320, 4320, 8640, 1080, 4320, 4320, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 1080, 1080, 4320, 1080, 8640, 8640, 8640, 4320, 1080, 8640, 8640, 4320, 4320, 8640, 8640, 1080, 8640, 8640, 4320, 1080, 8640, 4320, 4320, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 8640, 1080, 4320, 8640, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 8640, 1080, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 8640, 4320, 8640, 1080, 8640, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 4320, 8640, 4320, 4320, 4320, 1080, 4320, 1080, 1080, 8640, 1080, 4320, 1080, 1080, 4320, 8640, 4320, 8640, 1080, 8640, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 1080]
Prompts retrieved: 1797120 . Total input tokens: 400222001 . Total output tokens: 359316789
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 63.990881889127195,
    "estimated_duration": 3600.1196949916657,
    "input_throughput": 5268.54343937137,
    "output_throughput": 4665.588764553253,
    "total_throughput": 9934.132203924624,
    "itl": 180.237154832002,
    "ttft": 2060519.8747847318,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 716,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3420500355772655,
    "arrivals": 599139,
    "finished_requests": 76660,
    "scheduler_time": 137.04265686880885
}
#Debug simulation 
Total elapsed time: 63.99103618878871. Arrivals time: 0.38613875582814217 Scheduler time: 63.47162718558684 Scheduler overhead time: 0.04799733683466911 Adapter cache time: 0.019325840286910534 Engine time: 0.0479251598007977 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-16-16/adapters_384_slots_96_rate_0.8-0.4-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-16-16/adapters_384_slots_96_rate_0.8-0.4-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 8640, 4320, 1080, 8640, 8640, 1080, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 1080, 8640, 1080, 8640, 4320, 4320, 4320, 1080, 1080, 4320, 1080, 8640, 1080, 8640, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 8640, 1080, 8640, 8640, 8640, 8640, 1080, 4320, 4320, 4320, 8640, 4320, 1080, 4320, 1080, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 1080, 1080, 8640, 4320, 4320, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 8640, 1080, 4320, 8640, 1080, 8640, 4320, 1080, 8640, 8640, 8640, 8640, 4320, 1080, 4320, 8640, 8640, 4320, 1080, 1080, 8640, 4320, 4320, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 8640, 1080, 8640, 1080, 1080, 1080, 4320, 4320, 8640, 1080, 1080, 8640, 1080, 8640, 4320, 1080, 8640, 4320, 4320, 1080, 8640, 8640, 8640, 1080, 4320, 8640, 1080, 8640, 4320, 4320, 8640, 8640, 1080, 4320, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 4320, 8640, 8640, 4320, 1080, 8640, 1080, 8640, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 8640, 1080, 8640, 1080, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 1080, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 1080, 4320, 8640, 8640, 1080, 1080, 8640, 1080, 1080, 1080, 4320, 1080, 4320, 8640, 8640, 4320, 4320, 1080, 8640, 4320, 8640, 1080, 4320, 4320, 1080, 1080, 4320, 1080, 8640, 8640, 1080, 8640, 8640, 1080, 4320, 8640, 1080, 1080, 4320, 4320, 1080, 1080, 8640, 8640, 8640, 8640, 4320, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 8640, 4320, 4320, 4320, 8640, 1080, 4320, 4320, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 1080, 1080, 4320, 1080, 8640, 8640, 8640, 4320, 1080, 8640, 8640, 4320, 4320, 8640, 8640, 1080, 8640, 8640, 4320, 1080, 8640, 4320, 4320, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 8640, 1080, 4320, 8640, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 8640, 1080, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 8640, 4320, 8640, 1080, 8640, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 4320, 8640, 4320, 4320, 4320, 1080, 4320, 1080, 1080, 8640, 1080, 4320, 1080, 1080, 4320, 8640, 4320, 8640, 1080, 8640, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 1080]
Prompts retrieved: 1797120 . Total input tokens: 400222001 . Total output tokens: 359316789
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 68.1318478169851,
    "estimated_duration": 3600.171460192078,
    "input_throughput": 5289.816390851546,
    "output_throughput": 4682.276715537498,
    "total_throughput": 9972.093106389044,
    "itl": 182.97403338702398,
    "ttft": 2054612.3520932524,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 587,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8389215633878382,
    "arrivals": 599139,
    "finished_requests": 76963,
    "scheduler_time": 136.20391582172718
}
#Debug simulation 
Total elapsed time: 68.1320103132166. Arrivals time: 0.4000204959884286 Scheduler time: 67.59720385726541 Scheduler overhead time: 0.049657593946903944 Adapter cache time: 0.017509715165942907 Engine time: 0.049153818748891354 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-16-32/adapters_384_slots_96_rate_0.8-0.4-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-16-32/adapters_384_slots_96_rate_0.8-0.4-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 8640, 4320, 1080, 8640, 8640, 1080, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 1080, 8640, 1080, 8640, 4320, 4320, 4320, 1080, 1080, 4320, 1080, 8640, 1080, 8640, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 8640, 1080, 8640, 8640, 8640, 8640, 1080, 4320, 4320, 4320, 8640, 4320, 1080, 4320, 1080, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 1080, 1080, 8640, 4320, 4320, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 8640, 1080, 4320, 8640, 1080, 8640, 4320, 1080, 8640, 8640, 8640, 8640, 4320, 1080, 4320, 8640, 8640, 4320, 1080, 1080, 8640, 4320, 4320, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 8640, 1080, 8640, 1080, 1080, 1080, 4320, 4320, 8640, 1080, 1080, 8640, 1080, 8640, 4320, 1080, 8640, 4320, 4320, 1080, 8640, 8640, 8640, 1080, 4320, 8640, 1080, 8640, 4320, 4320, 8640, 8640, 1080, 4320, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 4320, 8640, 8640, 4320, 1080, 8640, 1080, 8640, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 8640, 1080, 8640, 1080, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 1080, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 1080, 4320, 8640, 8640, 1080, 1080, 8640, 1080, 1080, 1080, 4320, 1080, 4320, 8640, 8640, 4320, 4320, 1080, 8640, 4320, 8640, 1080, 4320, 4320, 1080, 1080, 4320, 1080, 8640, 8640, 1080, 8640, 8640, 1080, 4320, 8640, 1080, 1080, 4320, 4320, 1080, 1080, 8640, 8640, 8640, 8640, 4320, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 8640, 4320, 4320, 4320, 8640, 1080, 4320, 4320, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 1080, 1080, 4320, 1080, 8640, 8640, 8640, 4320, 1080, 8640, 8640, 4320, 4320, 8640, 8640, 1080, 8640, 8640, 4320, 1080, 8640, 4320, 4320, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 8640, 1080, 4320, 8640, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 8640, 1080, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 8640, 4320, 8640, 1080, 8640, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 4320, 8640, 4320, 4320, 4320, 1080, 4320, 1080, 1080, 8640, 1080, 4320, 1080, 1080, 4320, 8640, 4320, 8640, 1080, 8640, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 1080]
Prompts retrieved: 1797120 . Total input tokens: 400222001 . Total output tokens: 359316789
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 63.853639368433505,
    "estimated_duration": 3600.097569970866,
    "input_throughput": 5267.8272272919185,
    "output_throughput": 4662.142809683857,
    "total_throughput": 9929.970036975776,
    "itl": 179.8927312744112,
    "ttft": 2059602.5408393894,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 694,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.298494278080763,
    "arrivals": 599139,
    "finished_requests": 76594,
    "scheduler_time": 137.22260588292554
}
#Debug simulation 
Total elapsed time: 63.85378201911226. Arrivals time: 0.3947335463017225 Scheduler time: 63.32544815214351 Scheduler overhead time: 0.04894247651100159 Adapter cache time: 0.018949883058667183 Engine time: 0.04787963069975376 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_16-16-16/adapters_384_slots_96_rate_0.8-0.4-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_16-16-16/adapters_384_slots_96_rate_0.8-0.4-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 8640, 4320, 1080, 8640, 8640, 1080, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 1080, 8640, 1080, 8640, 4320, 4320, 4320, 1080, 1080, 4320, 1080, 8640, 1080, 8640, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 8640, 1080, 8640, 8640, 8640, 8640, 1080, 4320, 4320, 4320, 8640, 4320, 1080, 4320, 1080, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 1080, 1080, 8640, 4320, 4320, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 8640, 1080, 4320, 8640, 1080, 8640, 4320, 1080, 8640, 8640, 8640, 8640, 4320, 1080, 4320, 8640, 8640, 4320, 1080, 1080, 8640, 4320, 4320, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 8640, 1080, 8640, 1080, 1080, 1080, 4320, 4320, 8640, 1080, 1080, 8640, 1080, 8640, 4320, 1080, 8640, 4320, 4320, 1080, 8640, 8640, 8640, 1080, 4320, 8640, 1080, 8640, 4320, 4320, 8640, 8640, 1080, 4320, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 4320, 8640, 8640, 4320, 1080, 8640, 1080, 8640, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 8640, 1080, 8640, 1080, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 1080, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 1080, 4320, 8640, 8640, 1080, 1080, 8640, 1080, 1080, 1080, 4320, 1080, 4320, 8640, 8640, 4320, 4320, 1080, 8640, 4320, 8640, 1080, 4320, 4320, 1080, 1080, 4320, 1080, 8640, 8640, 1080, 8640, 8640, 1080, 4320, 8640, 1080, 1080, 4320, 4320, 1080, 1080, 8640, 8640, 8640, 8640, 4320, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 8640, 4320, 4320, 4320, 8640, 1080, 4320, 4320, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 1080, 1080, 4320, 1080, 8640, 8640, 8640, 4320, 1080, 8640, 8640, 4320, 4320, 8640, 8640, 1080, 8640, 8640, 4320, 1080, 8640, 4320, 4320, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 8640, 1080, 4320, 8640, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 8640, 1080, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 8640, 4320, 8640, 1080, 8640, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 4320, 8640, 4320, 4320, 4320, 1080, 4320, 1080, 1080, 8640, 1080, 4320, 1080, 1080, 4320, 8640, 4320, 8640, 1080, 8640, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 1080]
Prompts retrieved: 1797120 . Total input tokens: 400222001 . Total output tokens: 359316789
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 66.39791816426441,
    "estimated_duration": 3600.0593324259935,
    "input_throughput": 5284.515682462322,
    "output_throughput": 4684.129188680991,
    "total_throughput": 9968.644871143313,
    "itl": 183.0244846361128,
    "ttft": 2057058.6142622123,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 584,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7461893722228454,
    "arrivals": 599139,
    "finished_requests": 76973,
    "scheduler_time": 136.21962001693495
}
#Debug simulation 
Total elapsed time: 66.39807597827166. Arrivals time: 0.40119305765256286 Scheduler time: 65.86256337165833 Scheduler overhead time: 0.04905075440183282 Adapter cache time: 0.01770237134769559 Engine time: 0.04941901937127113 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_16-16-32/adapters_384_slots_96_rate_0.8-0.4-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_16-16-32/adapters_384_slots_96_rate_0.8-0.4-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 8640, 4320, 1080, 8640, 8640, 1080, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 1080, 8640, 1080, 8640, 4320, 4320, 4320, 1080, 1080, 4320, 1080, 8640, 1080, 8640, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 8640, 1080, 8640, 8640, 8640, 8640, 1080, 4320, 4320, 4320, 8640, 4320, 1080, 4320, 1080, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 1080, 1080, 8640, 4320, 4320, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 8640, 1080, 4320, 8640, 1080, 8640, 4320, 1080, 8640, 8640, 8640, 8640, 4320, 1080, 4320, 8640, 8640, 4320, 1080, 1080, 8640, 4320, 4320, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 8640, 1080, 8640, 1080, 1080, 1080, 4320, 4320, 8640, 1080, 1080, 8640, 1080, 8640, 4320, 1080, 8640, 4320, 4320, 1080, 8640, 8640, 8640, 1080, 4320, 8640, 1080, 8640, 4320, 4320, 8640, 8640, 1080, 4320, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 4320, 8640, 8640, 4320, 1080, 8640, 1080, 8640, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 8640, 1080, 8640, 1080, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 1080, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 1080, 4320, 8640, 8640, 1080, 1080, 8640, 1080, 1080, 1080, 4320, 1080, 4320, 8640, 8640, 4320, 4320, 1080, 8640, 4320, 8640, 1080, 4320, 4320, 1080, 1080, 4320, 1080, 8640, 8640, 1080, 8640, 8640, 1080, 4320, 8640, 1080, 1080, 4320, 4320, 1080, 1080, 8640, 8640, 8640, 8640, 4320, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 8640, 4320, 4320, 4320, 8640, 1080, 4320, 4320, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 1080, 1080, 4320, 1080, 8640, 8640, 8640, 4320, 1080, 8640, 8640, 4320, 4320, 8640, 8640, 1080, 8640, 8640, 4320, 1080, 8640, 4320, 4320, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 8640, 1080, 4320, 8640, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 8640, 1080, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 8640, 4320, 8640, 1080, 8640, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 4320, 8640, 4320, 4320, 4320, 1080, 4320, 1080, 1080, 8640, 1080, 4320, 1080, 1080, 4320, 8640, 4320, 8640, 1080, 8640, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 8640, 8640, 1080, 1080, 1080]
Prompts retrieved: 1797120 . Total input tokens: 400222001 . Total output tokens: 359316789
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 64.80737737705931,
    "estimated_duration": 3600.118094050458,
    "input_throughput": 5269.107708257899,
    "output_throughput": 4659.821861878311,
    "total_throughput": 9928.92957013621,
    "itl": 179.70719330491963,
    "ttft": 2060013.4335730318,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 691,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3183671201393072,
    "arrivals": 599139,
    "finished_requests": 76606,
    "scheduler_time": 137.28867736643136
}
#Debug simulation 
Total elapsed time: 64.8075284329243. Arrivals time: 0.3926317193545401 Scheduler time: 64.27970416750759 Scheduler overhead time: 0.04895247193053365 Adapter cache time: 0.019052640069276094 Engine time: 0.048953779973089695 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-8/adapters_384_slots_96_rate_0.8-0.4-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-8/adapters_384_slots_96_rate_0.8-0.4-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 8640, 4320, 540, 8640, 8640, 540, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 540, 8640, 540, 8640, 4320, 4320, 4320, 540, 540, 4320, 540, 8640, 540, 8640, 4320, 8640, 4320, 540, 4320, 8640, 4320, 8640, 540, 8640, 8640, 8640, 8640, 540, 4320, 4320, 4320, 8640, 4320, 540, 4320, 540, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 540, 540, 8640, 4320, 4320, 540, 540, 540, 4320, 540, 4320, 540, 8640, 540, 4320, 8640, 540, 8640, 4320, 540, 8640, 8640, 8640, 8640, 4320, 540, 4320, 8640, 8640, 4320, 540, 540, 8640, 4320, 4320, 540, 540, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 540, 4320, 4320, 4320, 4320, 540, 540, 8640, 540, 8640, 540, 540, 540, 4320, 4320, 8640, 540, 540, 8640, 540, 8640, 4320, 540, 8640, 4320, 4320, 540, 8640, 8640, 8640, 540, 4320, 8640, 540, 8640, 4320, 4320, 8640, 8640, 540, 4320, 8640, 540, 4320, 4320, 540, 4320, 540, 4320, 8640, 8640, 4320, 540, 8640, 540, 8640, 4320, 4320, 4320, 4320, 4320, 540, 540, 8640, 540, 8640, 540, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 540, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 540, 540, 540, 540, 540, 4320, 540, 540, 4320, 8640, 8640, 540, 540, 8640, 540, 540, 540, 4320, 540, 4320, 8640, 8640, 4320, 4320, 540, 8640, 4320, 8640, 540, 4320, 4320, 540, 540, 4320, 540, 8640, 8640, 540, 8640, 8640, 540, 4320, 8640, 540, 540, 4320, 4320, 540, 540, 8640, 8640, 8640, 8640, 4320, 540, 4320, 4320, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 8640, 4320, 4320, 4320, 8640, 540, 4320, 4320, 8640, 8640, 540, 8640, 8640, 540, 8640, 540, 540, 4320, 540, 8640, 8640, 8640, 4320, 540, 8640, 8640, 4320, 4320, 8640, 8640, 540, 8640, 8640, 4320, 540, 8640, 4320, 4320, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 540, 8640, 540, 4320, 8640, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 8640, 540, 540, 540, 4320, 540, 4320, 4320, 540, 8640, 4320, 8640, 540, 8640, 540, 4320, 4320, 4320, 4320, 540, 4320, 8640, 8640, 540, 8640, 8640, 540, 8640, 4320, 8640, 4320, 4320, 4320, 540, 4320, 540, 540, 8640, 540, 4320, 540, 540, 4320, 8640, 4320, 8640, 540, 8640, 8640, 4320, 8640, 4320, 540, 8640, 540, 8640, 8640, 540, 540, 540]
Prompts retrieved: 1728000 . Total input tokens: 384871152 . Total output tokens: 345423401
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 58.950263348873705,
    "estimated_duration": 3600.0837591495206,
    "input_throughput": 5311.565307724223,
    "output_throughput": 4687.154279984399,
    "total_throughput": 9998.719587708621,
    "itl": 183.0661801246676,
    "ttft": 2042688.2417450405,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 727,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.224974589839153,
    "arrivals": 576120,
    "finished_requests": 77542,
    "scheduler_time": 135.87825074613255
}
#Debug simulation 
Total elapsed time: 58.9504236606881. Arrivals time: 0.39494600472971797 Scheduler time: 58.42058970313519 Scheduler overhead time: 0.048909376841038465 Adapter cache time: 0.0197067828848958 Engine time: 0.0481146196834743 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-16/adapters_384_slots_96_rate_0.8-0.4-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-16/adapters_384_slots_96_rate_0.8-0.4-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 8640, 4320, 540, 8640, 8640, 540, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 540, 8640, 540, 8640, 4320, 4320, 4320, 540, 540, 4320, 540, 8640, 540, 8640, 4320, 8640, 4320, 540, 4320, 8640, 4320, 8640, 540, 8640, 8640, 8640, 8640, 540, 4320, 4320, 4320, 8640, 4320, 540, 4320, 540, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 540, 540, 8640, 4320, 4320, 540, 540, 540, 4320, 540, 4320, 540, 8640, 540, 4320, 8640, 540, 8640, 4320, 540, 8640, 8640, 8640, 8640, 4320, 540, 4320, 8640, 8640, 4320, 540, 540, 8640, 4320, 4320, 540, 540, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 540, 4320, 4320, 4320, 4320, 540, 540, 8640, 540, 8640, 540, 540, 540, 4320, 4320, 8640, 540, 540, 8640, 540, 8640, 4320, 540, 8640, 4320, 4320, 540, 8640, 8640, 8640, 540, 4320, 8640, 540, 8640, 4320, 4320, 8640, 8640, 540, 4320, 8640, 540, 4320, 4320, 540, 4320, 540, 4320, 8640, 8640, 4320, 540, 8640, 540, 8640, 4320, 4320, 4320, 4320, 4320, 540, 540, 8640, 540, 8640, 540, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 540, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 540, 540, 540, 540, 540, 4320, 540, 540, 4320, 8640, 8640, 540, 540, 8640, 540, 540, 540, 4320, 540, 4320, 8640, 8640, 4320, 4320, 540, 8640, 4320, 8640, 540, 4320, 4320, 540, 540, 4320, 540, 8640, 8640, 540, 8640, 8640, 540, 4320, 8640, 540, 540, 4320, 4320, 540, 540, 8640, 8640, 8640, 8640, 4320, 540, 4320, 4320, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 8640, 4320, 4320, 4320, 8640, 540, 4320, 4320, 8640, 8640, 540, 8640, 8640, 540, 8640, 540, 540, 4320, 540, 8640, 8640, 8640, 4320, 540, 8640, 8640, 4320, 4320, 8640, 8640, 540, 8640, 8640, 4320, 540, 8640, 4320, 4320, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 540, 8640, 540, 4320, 8640, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 8640, 540, 540, 540, 4320, 540, 4320, 4320, 540, 8640, 4320, 8640, 540, 8640, 540, 4320, 4320, 4320, 4320, 540, 4320, 8640, 8640, 540, 8640, 8640, 540, 8640, 4320, 8640, 4320, 4320, 4320, 540, 4320, 540, 540, 8640, 540, 4320, 540, 540, 4320, 8640, 4320, 8640, 540, 8640, 8640, 4320, 8640, 4320, 540, 8640, 540, 8640, 8640, 540, 540, 540]
Prompts retrieved: 1728000 . Total input tokens: 384871152 . Total output tokens: 345423401
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 67.1650688238442,
    "estimated_duration": 3600.138735849803,
    "input_throughput": 5308.64291692045,
    "output_throughput": 4681.480141909493,
    "total_throughput": 9990.123058829942,
    "itl": 182.35495162686365,
    "ttft": 2033794.0120721173,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 682,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2247165756952074,
    "arrivals": 576120,
    "finished_requests": 77483,
    "scheduler_time": 136.16329673947428
}
#Debug simulation 
Total elapsed time: 67.16522119194269. Arrivals time: 0.4326899638399482 Scheduler time: 66.59719291329384 Scheduler overhead time: 0.04944851156324148 Adapter cache time: 0.018966644536703825 Engine time: 0.04910748731344938 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-32/adapters_384_slots_96_rate_0.8-0.4-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-32/adapters_384_slots_96_rate_0.8-0.4-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 8640, 4320, 540, 8640, 8640, 540, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 540, 8640, 540, 8640, 4320, 4320, 4320, 540, 540, 4320, 540, 8640, 540, 8640, 4320, 8640, 4320, 540, 4320, 8640, 4320, 8640, 540, 8640, 8640, 8640, 8640, 540, 4320, 4320, 4320, 8640, 4320, 540, 4320, 540, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 540, 540, 8640, 4320, 4320, 540, 540, 540, 4320, 540, 4320, 540, 8640, 540, 4320, 8640, 540, 8640, 4320, 540, 8640, 8640, 8640, 8640, 4320, 540, 4320, 8640, 8640, 4320, 540, 540, 8640, 4320, 4320, 540, 540, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 540, 4320, 4320, 4320, 4320, 540, 540, 8640, 540, 8640, 540, 540, 540, 4320, 4320, 8640, 540, 540, 8640, 540, 8640, 4320, 540, 8640, 4320, 4320, 540, 8640, 8640, 8640, 540, 4320, 8640, 540, 8640, 4320, 4320, 8640, 8640, 540, 4320, 8640, 540, 4320, 4320, 540, 4320, 540, 4320, 8640, 8640, 4320, 540, 8640, 540, 8640, 4320, 4320, 4320, 4320, 4320, 540, 540, 8640, 540, 8640, 540, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 540, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 540, 540, 540, 540, 540, 4320, 540, 540, 4320, 8640, 8640, 540, 540, 8640, 540, 540, 540, 4320, 540, 4320, 8640, 8640, 4320, 4320, 540, 8640, 4320, 8640, 540, 4320, 4320, 540, 540, 4320, 540, 8640, 8640, 540, 8640, 8640, 540, 4320, 8640, 540, 540, 4320, 4320, 540, 540, 8640, 8640, 8640, 8640, 4320, 540, 4320, 4320, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 8640, 4320, 4320, 4320, 8640, 540, 4320, 4320, 8640, 8640, 540, 8640, 8640, 540, 8640, 540, 540, 4320, 540, 8640, 8640, 8640, 4320, 540, 8640, 8640, 4320, 4320, 8640, 8640, 540, 8640, 8640, 4320, 540, 8640, 4320, 4320, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 540, 8640, 540, 4320, 8640, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 8640, 540, 540, 540, 4320, 540, 4320, 4320, 540, 8640, 4320, 8640, 540, 8640, 540, 4320, 4320, 4320, 4320, 540, 4320, 8640, 8640, 540, 8640, 8640, 540, 8640, 4320, 8640, 4320, 4320, 4320, 540, 4320, 540, 540, 8640, 540, 4320, 540, 540, 4320, 8640, 4320, 8640, 540, 8640, 8640, 4320, 8640, 4320, 540, 8640, 540, 8640, 8640, 540, 540, 540]
Prompts retrieved: 1728000 . Total input tokens: 384871152 . Total output tokens: 345423401
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 67.33240831224248,
    "estimated_duration": 3600.0449029186307,
    "input_throughput": 5299.322790261098,
    "output_throughput": 4670.445078717961,
    "total_throughput": 9969.76786897906,
    "itl": 180.59408394392986,
    "ttft": 2036818.2618356578,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 575,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8781773859635111,
    "arrivals": 576120,
    "finished_requests": 77292,
    "scheduler_time": 136.7041137999656
}
#Debug simulation 
Total elapsed time: 67.33256606105715. Arrivals time: 0.3954888810403645 Scheduler time: 66.8000727398321 Scheduler overhead time: 0.04976579453796148 Adapter cache time: 0.017677030991762877 Engine time: 0.050784976687282324 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-16-16/adapters_384_slots_96_rate_0.8-0.4-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-16-16/adapters_384_slots_96_rate_0.8-0.4-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 8640, 4320, 540, 8640, 8640, 540, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 540, 8640, 540, 8640, 4320, 4320, 4320, 540, 540, 4320, 540, 8640, 540, 8640, 4320, 8640, 4320, 540, 4320, 8640, 4320, 8640, 540, 8640, 8640, 8640, 8640, 540, 4320, 4320, 4320, 8640, 4320, 540, 4320, 540, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 540, 540, 8640, 4320, 4320, 540, 540, 540, 4320, 540, 4320, 540, 8640, 540, 4320, 8640, 540, 8640, 4320, 540, 8640, 8640, 8640, 8640, 4320, 540, 4320, 8640, 8640, 4320, 540, 540, 8640, 4320, 4320, 540, 540, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 540, 4320, 4320, 4320, 4320, 540, 540, 8640, 540, 8640, 540, 540, 540, 4320, 4320, 8640, 540, 540, 8640, 540, 8640, 4320, 540, 8640, 4320, 4320, 540, 8640, 8640, 8640, 540, 4320, 8640, 540, 8640, 4320, 4320, 8640, 8640, 540, 4320, 8640, 540, 4320, 4320, 540, 4320, 540, 4320, 8640, 8640, 4320, 540, 8640, 540, 8640, 4320, 4320, 4320, 4320, 4320, 540, 540, 8640, 540, 8640, 540, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 540, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 540, 540, 540, 540, 540, 4320, 540, 540, 4320, 8640, 8640, 540, 540, 8640, 540, 540, 540, 4320, 540, 4320, 8640, 8640, 4320, 4320, 540, 8640, 4320, 8640, 540, 4320, 4320, 540, 540, 4320, 540, 8640, 8640, 540, 8640, 8640, 540, 4320, 8640, 540, 540, 4320, 4320, 540, 540, 8640, 8640, 8640, 8640, 4320, 540, 4320, 4320, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 8640, 4320, 4320, 4320, 8640, 540, 4320, 4320, 8640, 8640, 540, 8640, 8640, 540, 8640, 540, 540, 4320, 540, 8640, 8640, 8640, 4320, 540, 8640, 8640, 4320, 4320, 8640, 8640, 540, 8640, 8640, 4320, 540, 8640, 4320, 4320, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 540, 8640, 540, 4320, 8640, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 8640, 540, 540, 540, 4320, 540, 4320, 4320, 540, 8640, 4320, 8640, 540, 8640, 540, 4320, 4320, 4320, 4320, 540, 4320, 8640, 8640, 540, 8640, 8640, 540, 8640, 4320, 8640, 4320, 4320, 4320, 540, 4320, 540, 540, 8640, 540, 4320, 540, 540, 4320, 8640, 4320, 8640, 540, 8640, 8640, 4320, 8640, 4320, 540, 8640, 540, 8640, 8640, 540, 540, 540]
Prompts retrieved: 1728000 . Total input tokens: 384871152 . Total output tokens: 345423401
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 58.64152706740424,
    "estimated_duration": 3600.088700689631,
    "input_throughput": 5305.611496833699,
    "output_throughput": 4679.210541888335,
    "total_throughput": 9984.822038722034,
    "itl": 182.24774725899294,
    "ttft": 2045279.8344882631,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 681,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1289753881143243,
    "arrivals": 576120,
    "finished_requests": 77419,
    "scheduler_time": 136.21644802108494
}
#Debug simulation 
Total elapsed time: 58.64168668119237. Arrivals time: 0.6283904938027263 Scheduler time: 57.87806700123474 Scheduler overhead time: 0.04972532484680414 Adapter cache time: 0.019203453790396452 Engine time: 0.04825176578015089 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-16-32/adapters_384_slots_96_rate_0.8-0.4-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-16-32/adapters_384_slots_96_rate_0.8-0.4-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 8640, 4320, 540, 8640, 8640, 540, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 540, 8640, 540, 8640, 4320, 4320, 4320, 540, 540, 4320, 540, 8640, 540, 8640, 4320, 8640, 4320, 540, 4320, 8640, 4320, 8640, 540, 8640, 8640, 8640, 8640, 540, 4320, 4320, 4320, 8640, 4320, 540, 4320, 540, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 540, 540, 8640, 4320, 4320, 540, 540, 540, 4320, 540, 4320, 540, 8640, 540, 4320, 8640, 540, 8640, 4320, 540, 8640, 8640, 8640, 8640, 4320, 540, 4320, 8640, 8640, 4320, 540, 540, 8640, 4320, 4320, 540, 540, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 540, 4320, 4320, 4320, 4320, 540, 540, 8640, 540, 8640, 540, 540, 540, 4320, 4320, 8640, 540, 540, 8640, 540, 8640, 4320, 540, 8640, 4320, 4320, 540, 8640, 8640, 8640, 540, 4320, 8640, 540, 8640, 4320, 4320, 8640, 8640, 540, 4320, 8640, 540, 4320, 4320, 540, 4320, 540, 4320, 8640, 8640, 4320, 540, 8640, 540, 8640, 4320, 4320, 4320, 4320, 4320, 540, 540, 8640, 540, 8640, 540, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 540, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 540, 540, 540, 540, 540, 4320, 540, 540, 4320, 8640, 8640, 540, 540, 8640, 540, 540, 540, 4320, 540, 4320, 8640, 8640, 4320, 4320, 540, 8640, 4320, 8640, 540, 4320, 4320, 540, 540, 4320, 540, 8640, 8640, 540, 8640, 8640, 540, 4320, 8640, 540, 540, 4320, 4320, 540, 540, 8640, 8640, 8640, 8640, 4320, 540, 4320, 4320, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 8640, 4320, 4320, 4320, 8640, 540, 4320, 4320, 8640, 8640, 540, 8640, 8640, 540, 8640, 540, 540, 4320, 540, 8640, 8640, 8640, 4320, 540, 8640, 8640, 4320, 4320, 8640, 8640, 540, 8640, 8640, 4320, 540, 8640, 4320, 4320, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 540, 8640, 540, 4320, 8640, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 8640, 540, 540, 540, 4320, 540, 4320, 4320, 540, 8640, 4320, 8640, 540, 8640, 540, 4320, 4320, 4320, 4320, 540, 4320, 8640, 8640, 540, 8640, 8640, 540, 8640, 4320, 8640, 4320, 4320, 4320, 540, 4320, 540, 540, 8640, 540, 4320, 540, 540, 4320, 8640, 4320, 8640, 540, 8640, 8640, 4320, 8640, 4320, 540, 8640, 540, 8640, 8640, 540, 540, 540]
Prompts retrieved: 1728000 . Total input tokens: 384871152 . Total output tokens: 345423401
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 64.50851714937016,
    "estimated_duration": 3600.1978223937062,
    "input_throughput": 5294.086308659426,
    "output_throughput": 4671.901609233472,
    "total_throughput": 9965.987917892899,
    "itl": 180.44768780023918,
    "ttft": 2039964.0751078252,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 572,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.893071514815096,
    "arrivals": 576120,
    "finished_requests": 77327,
    "scheduler_time": 136.67902446316927
}
#Debug simulation 
Total elapsed time: 64.50867677619681. Arrivals time: 0.38540754141286016 Scheduler time: 63.9886137698777 Scheduler overhead time: 0.04941131127998233 Adapter cache time: 0.017562204506248236 Engine time: 0.04924043081700802 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_16-16-16/adapters_384_slots_96_rate_0.8-0.4-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_16-16-16/adapters_384_slots_96_rate_0.8-0.4-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 8640, 4320, 540, 8640, 8640, 540, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 540, 8640, 540, 8640, 4320, 4320, 4320, 540, 540, 4320, 540, 8640, 540, 8640, 4320, 8640, 4320, 540, 4320, 8640, 4320, 8640, 540, 8640, 8640, 8640, 8640, 540, 4320, 4320, 4320, 8640, 4320, 540, 4320, 540, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 540, 540, 8640, 4320, 4320, 540, 540, 540, 4320, 540, 4320, 540, 8640, 540, 4320, 8640, 540, 8640, 4320, 540, 8640, 8640, 8640, 8640, 4320, 540, 4320, 8640, 8640, 4320, 540, 540, 8640, 4320, 4320, 540, 540, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 540, 4320, 4320, 4320, 4320, 540, 540, 8640, 540, 8640, 540, 540, 540, 4320, 4320, 8640, 540, 540, 8640, 540, 8640, 4320, 540, 8640, 4320, 4320, 540, 8640, 8640, 8640, 540, 4320, 8640, 540, 8640, 4320, 4320, 8640, 8640, 540, 4320, 8640, 540, 4320, 4320, 540, 4320, 540, 4320, 8640, 8640, 4320, 540, 8640, 540, 8640, 4320, 4320, 4320, 4320, 4320, 540, 540, 8640, 540, 8640, 540, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 540, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 540, 540, 540, 540, 540, 4320, 540, 540, 4320, 8640, 8640, 540, 540, 8640, 540, 540, 540, 4320, 540, 4320, 8640, 8640, 4320, 4320, 540, 8640, 4320, 8640, 540, 4320, 4320, 540, 540, 4320, 540, 8640, 8640, 540, 8640, 8640, 540, 4320, 8640, 540, 540, 4320, 4320, 540, 540, 8640, 8640, 8640, 8640, 4320, 540, 4320, 4320, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 8640, 4320, 4320, 4320, 8640, 540, 4320, 4320, 8640, 8640, 540, 8640, 8640, 540, 8640, 540, 540, 4320, 540, 8640, 8640, 8640, 4320, 540, 8640, 8640, 4320, 4320, 8640, 8640, 540, 8640, 8640, 4320, 540, 8640, 4320, 4320, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 540, 8640, 540, 4320, 8640, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 8640, 540, 540, 540, 4320, 540, 4320, 4320, 540, 8640, 4320, 8640, 540, 8640, 540, 4320, 4320, 4320, 4320, 540, 4320, 8640, 8640, 540, 8640, 8640, 540, 8640, 4320, 8640, 4320, 4320, 4320, 540, 4320, 540, 540, 8640, 540, 4320, 540, 540, 4320, 8640, 4320, 8640, 540, 8640, 8640, 4320, 8640, 4320, 540, 8640, 540, 8640, 8640, 540, 540, 540]
Prompts retrieved: 1728000 . Total input tokens: 384871152 . Total output tokens: 345423401
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 67.77805183688179,
    "estimated_duration": 3600.064963396771,
    "input_throughput": 5310.164453799908,
    "output_throughput": 4681.116360772367,
    "total_throughput": 9991.280814572276,
    "itl": 182.24947733968705,
    "ttft": 2035820.529397949,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 546,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6325674610165668,
    "arrivals": 576120,
    "finished_requests": 77530,
    "scheduler_time": 136.21659524465852
}
#Debug simulation 
Total elapsed time: 67.77820901200175. Arrivals time: 0.3937543723732233 Scheduler time: 67.24928089929745 Scheduler overhead time: 0.05000578751787543 Adapter cache time: 0.01729154121130705 Engine time: 0.0496189733967185 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_16-16-32/adapters_384_slots_96_rate_0.8-0.4-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_16-16-32/adapters_384_slots_96_rate_0.8-0.4-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 8640, 4320, 540, 8640, 8640, 540, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 540, 8640, 540, 8640, 4320, 4320, 4320, 540, 540, 4320, 540, 8640, 540, 8640, 4320, 8640, 4320, 540, 4320, 8640, 4320, 8640, 540, 8640, 8640, 8640, 8640, 540, 4320, 4320, 4320, 8640, 4320, 540, 4320, 540, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 540, 540, 8640, 4320, 4320, 540, 540, 540, 4320, 540, 4320, 540, 8640, 540, 4320, 8640, 540, 8640, 4320, 540, 8640, 8640, 8640, 8640, 4320, 540, 4320, 8640, 8640, 4320, 540, 540, 8640, 4320, 4320, 540, 540, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 540, 4320, 4320, 4320, 4320, 540, 540, 8640, 540, 8640, 540, 540, 540, 4320, 4320, 8640, 540, 540, 8640, 540, 8640, 4320, 540, 8640, 4320, 4320, 540, 8640, 8640, 8640, 540, 4320, 8640, 540, 8640, 4320, 4320, 8640, 8640, 540, 4320, 8640, 540, 4320, 4320, 540, 4320, 540, 4320, 8640, 8640, 4320, 540, 8640, 540, 8640, 4320, 4320, 4320, 4320, 4320, 540, 540, 8640, 540, 8640, 540, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 540, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 540, 540, 540, 540, 540, 4320, 540, 540, 4320, 8640, 8640, 540, 540, 8640, 540, 540, 540, 4320, 540, 4320, 8640, 8640, 4320, 4320, 540, 8640, 4320, 8640, 540, 4320, 4320, 540, 540, 4320, 540, 8640, 8640, 540, 8640, 8640, 540, 4320, 8640, 540, 540, 4320, 4320, 540, 540, 8640, 8640, 8640, 8640, 4320, 540, 4320, 4320, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 8640, 4320, 4320, 4320, 8640, 540, 4320, 4320, 8640, 8640, 540, 8640, 8640, 540, 8640, 540, 540, 4320, 540, 8640, 8640, 8640, 4320, 540, 8640, 8640, 4320, 4320, 8640, 8640, 540, 8640, 8640, 4320, 540, 8640, 4320, 4320, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 540, 8640, 540, 4320, 8640, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 8640, 540, 540, 540, 4320, 540, 4320, 4320, 540, 8640, 4320, 8640, 540, 8640, 540, 4320, 4320, 4320, 4320, 540, 4320, 8640, 8640, 540, 8640, 8640, 540, 8640, 4320, 8640, 4320, 4320, 4320, 540, 4320, 540, 540, 8640, 540, 4320, 540, 540, 4320, 8640, 4320, 8640, 540, 8640, 8640, 4320, 8640, 4320, 540, 8640, 540, 8640, 8640, 540, 540, 540]
Prompts retrieved: 1728000 . Total input tokens: 384871152 . Total output tokens: 345423401
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 68.91011097980663,
    "estimated_duration": 3600.084237148382,
    "input_throughput": 5296.542176219664,
    "output_throughput": 4672.382892163616,
    "total_throughput": 9968.92506838328,
    "itl": 180.7135834104411,
    "ttft": 2035239.2994448477,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 570,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.910283229276534,
    "arrivals": 576120,
    "finished_requests": 77280,
    "scheduler_time": 136.65366567987016
}
#Debug simulation 
Total elapsed time: 68.91027121199295. Arrivals time: 0.39855321403592825 Scheduler time: 68.3755440665409 Scheduler overhead time: 0.05030710203573108 Adapter cache time: 0.017597310710698366 Engine time: 0.05019661923870444 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-8/adapters_384_slots_96_rate_0.8-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-8/adapters_384_slots_96_rate_0.8-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 8640, 4320, 270, 8640, 8640, 270, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 270, 8640, 270, 8640, 4320, 4320, 4320, 270, 270, 4320, 270, 8640, 270, 8640, 4320, 8640, 4320, 270, 4320, 8640, 4320, 8640, 270, 8640, 8640, 8640, 8640, 270, 4320, 4320, 4320, 8640, 4320, 270, 4320, 270, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 270, 270, 8640, 4320, 4320, 270, 270, 270, 4320, 270, 4320, 270, 8640, 270, 4320, 8640, 270, 8640, 4320, 270, 8640, 8640, 8640, 8640, 4320, 270, 4320, 8640, 8640, 4320, 270, 270, 8640, 4320, 4320, 270, 270, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 270, 4320, 4320, 4320, 4320, 270, 270, 8640, 270, 8640, 270, 270, 270, 4320, 4320, 8640, 270, 270, 8640, 270, 8640, 4320, 270, 8640, 4320, 4320, 270, 8640, 8640, 8640, 270, 4320, 8640, 270, 8640, 4320, 4320, 8640, 8640, 270, 4320, 8640, 270, 4320, 4320, 270, 4320, 270, 4320, 8640, 8640, 4320, 270, 8640, 270, 8640, 4320, 4320, 4320, 4320, 4320, 270, 270, 8640, 270, 8640, 270, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 270, 270, 270, 270, 270, 4320, 270, 270, 4320, 8640, 8640, 270, 270, 8640, 270, 270, 270, 4320, 270, 4320, 8640, 8640, 4320, 4320, 270, 8640, 4320, 8640, 270, 4320, 4320, 270, 270, 4320, 270, 8640, 8640, 270, 8640, 8640, 270, 4320, 8640, 270, 270, 4320, 4320, 270, 270, 8640, 8640, 8640, 8640, 4320, 270, 4320, 4320, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 8640, 4320, 4320, 4320, 8640, 270, 4320, 4320, 8640, 8640, 270, 8640, 8640, 270, 8640, 270, 270, 4320, 270, 8640, 8640, 8640, 4320, 270, 8640, 8640, 4320, 4320, 8640, 8640, 270, 8640, 8640, 4320, 270, 8640, 4320, 4320, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 270, 8640, 270, 4320, 8640, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 8640, 270, 270, 270, 4320, 270, 4320, 4320, 270, 8640, 4320, 8640, 270, 8640, 270, 4320, 4320, 4320, 4320, 270, 4320, 8640, 8640, 270, 8640, 8640, 270, 8640, 4320, 8640, 4320, 4320, 4320, 270, 4320, 270, 270, 8640, 270, 4320, 270, 270, 4320, 8640, 4320, 8640, 270, 8640, 8640, 4320, 8640, 4320, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1693440 . Total input tokens: 377107671 . Total output tokens: 338540164
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 64.4647043258883,
    "estimated_duration": 3600.117490255107,
    "input_throughput": 5318.385594866584,
    "output_throughput": 4683.676031585614,
    "total_throughput": 10002.061626452198,
    "itl": 182.31096829513083,
    "ttft": 2043255.0581929972,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 760,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3259706853889375,
    "arrivals": 564654,
    "finished_requests": 77236,
    "scheduler_time": 136.15040815590842
}
#Debug simulation 
Total elapsed time: 64.46486949361861. Arrivals time: 0.3804818750359118 Scheduler time: 63.9489362584427 Scheduler overhead time: 0.048940985929220915 Adapter cache time: 0.019923682790249586 Engine time: 0.04845241829752922 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-16/adapters_384_slots_96_rate_0.8-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-16/adapters_384_slots_96_rate_0.8-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 8640, 4320, 270, 8640, 8640, 270, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 270, 8640, 270, 8640, 4320, 4320, 4320, 270, 270, 4320, 270, 8640, 270, 8640, 4320, 8640, 4320, 270, 4320, 8640, 4320, 8640, 270, 8640, 8640, 8640, 8640, 270, 4320, 4320, 4320, 8640, 4320, 270, 4320, 270, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 270, 270, 8640, 4320, 4320, 270, 270, 270, 4320, 270, 4320, 270, 8640, 270, 4320, 8640, 270, 8640, 4320, 270, 8640, 8640, 8640, 8640, 4320, 270, 4320, 8640, 8640, 4320, 270, 270, 8640, 4320, 4320, 270, 270, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 270, 4320, 4320, 4320, 4320, 270, 270, 8640, 270, 8640, 270, 270, 270, 4320, 4320, 8640, 270, 270, 8640, 270, 8640, 4320, 270, 8640, 4320, 4320, 270, 8640, 8640, 8640, 270, 4320, 8640, 270, 8640, 4320, 4320, 8640, 8640, 270, 4320, 8640, 270, 4320, 4320, 270, 4320, 270, 4320, 8640, 8640, 4320, 270, 8640, 270, 8640, 4320, 4320, 4320, 4320, 4320, 270, 270, 8640, 270, 8640, 270, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 270, 270, 270, 270, 270, 4320, 270, 270, 4320, 8640, 8640, 270, 270, 8640, 270, 270, 270, 4320, 270, 4320, 8640, 8640, 4320, 4320, 270, 8640, 4320, 8640, 270, 4320, 4320, 270, 270, 4320, 270, 8640, 8640, 270, 8640, 8640, 270, 4320, 8640, 270, 270, 4320, 4320, 270, 270, 8640, 8640, 8640, 8640, 4320, 270, 4320, 4320, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 8640, 4320, 4320, 4320, 8640, 270, 4320, 4320, 8640, 8640, 270, 8640, 8640, 270, 8640, 270, 270, 4320, 270, 8640, 8640, 8640, 4320, 270, 8640, 8640, 4320, 4320, 8640, 8640, 270, 8640, 8640, 4320, 270, 8640, 4320, 4320, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 270, 8640, 270, 4320, 8640, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 8640, 270, 270, 270, 4320, 270, 4320, 4320, 270, 8640, 4320, 8640, 270, 8640, 270, 4320, 4320, 4320, 4320, 270, 4320, 8640, 8640, 270, 8640, 8640, 270, 8640, 4320, 8640, 4320, 4320, 4320, 270, 4320, 270, 270, 8640, 270, 4320, 270, 270, 4320, 8640, 4320, 8640, 270, 8640, 8640, 4320, 8640, 4320, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1693440 . Total input tokens: 377107671 . Total output tokens: 338540164
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 63.673027305398136,
    "estimated_duration": 3600.034107736668,
    "input_throughput": 5313.41326986094,
    "output_throughput": 4683.536181994786,
    "total_throughput": 9996.949451855726,
    "itl": 182.30718822197665,
    "ttft": 2044280.3349877903,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 734,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.395725813130854,
    "arrivals": 564654,
    "finished_requests": 77192,
    "scheduler_time": 136.15308105886916
}
#Debug simulation 
Total elapsed time: 63.67318325815722. Arrivals time: 0.38763815350830555 Scheduler time: 63.150660016573966 Scheduler overhead time: 0.04841590533033013 Adapter cache time: 0.019408035557717085 Engine time: 0.048472356516867876 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-32/adapters_384_slots_96_rate_0.8-0.4-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-32/adapters_384_slots_96_rate_0.8-0.4-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 8640, 4320, 270, 8640, 8640, 270, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 270, 8640, 270, 8640, 4320, 4320, 4320, 270, 270, 4320, 270, 8640, 270, 8640, 4320, 8640, 4320, 270, 4320, 8640, 4320, 8640, 270, 8640, 8640, 8640, 8640, 270, 4320, 4320, 4320, 8640, 4320, 270, 4320, 270, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 270, 270, 8640, 4320, 4320, 270, 270, 270, 4320, 270, 4320, 270, 8640, 270, 4320, 8640, 270, 8640, 4320, 270, 8640, 8640, 8640, 8640, 4320, 270, 4320, 8640, 8640, 4320, 270, 270, 8640, 4320, 4320, 270, 270, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 270, 4320, 4320, 4320, 4320, 270, 270, 8640, 270, 8640, 270, 270, 270, 4320, 4320, 8640, 270, 270, 8640, 270, 8640, 4320, 270, 8640, 4320, 4320, 270, 8640, 8640, 8640, 270, 4320, 8640, 270, 8640, 4320, 4320, 8640, 8640, 270, 4320, 8640, 270, 4320, 4320, 270, 4320, 270, 4320, 8640, 8640, 4320, 270, 8640, 270, 8640, 4320, 4320, 4320, 4320, 4320, 270, 270, 8640, 270, 8640, 270, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 270, 270, 270, 270, 270, 4320, 270, 270, 4320, 8640, 8640, 270, 270, 8640, 270, 270, 270, 4320, 270, 4320, 8640, 8640, 4320, 4320, 270, 8640, 4320, 8640, 270, 4320, 4320, 270, 270, 4320, 270, 8640, 8640, 270, 8640, 8640, 270, 4320, 8640, 270, 270, 4320, 4320, 270, 270, 8640, 8640, 8640, 8640, 4320, 270, 4320, 4320, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 8640, 4320, 4320, 4320, 8640, 270, 4320, 4320, 8640, 8640, 270, 8640, 8640, 270, 8640, 270, 270, 4320, 270, 8640, 8640, 8640, 4320, 270, 8640, 8640, 4320, 4320, 8640, 8640, 270, 8640, 8640, 4320, 270, 8640, 4320, 4320, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 270, 8640, 270, 4320, 8640, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 8640, 270, 270, 270, 4320, 270, 4320, 4320, 270, 8640, 4320, 8640, 270, 8640, 270, 4320, 4320, 4320, 4320, 270, 4320, 8640, 8640, 270, 8640, 8640, 270, 8640, 4320, 8640, 4320, 4320, 4320, 270, 4320, 270, 270, 8640, 270, 4320, 270, 270, 4320, 8640, 4320, 8640, 270, 8640, 8640, 4320, 8640, 4320, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1693440 . Total input tokens: 377107671 . Total output tokens: 338540164
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 64.41925003519282,
    "estimated_duration": 3600.167946107435,
    "input_throughput": 5294.952703695656,
    "output_throughput": 4667.474198854653,
    "total_throughput": 9962.426902550309,
    "itl": 180.0881746491145,
    "ttft": 2045390.2537425125,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 744,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4299665432982116,
    "arrivals": 564654,
    "finished_requests": 76933,
    "scheduler_time": 136.78675448786512
}
#Debug simulation 
Total elapsed time: 64.41941469814628. Arrivals time: 0.6341666369698942 Scheduler time: 63.65051278332248 Scheduler overhead time: 0.04890613444149494 Adapter cache time: 0.01960384426638484 Engine time: 0.04840145260095596 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-16-16/adapters_384_slots_96_rate_0.8-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-16-16/adapters_384_slots_96_rate_0.8-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 8640, 4320, 270, 8640, 8640, 270, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 270, 8640, 270, 8640, 4320, 4320, 4320, 270, 270, 4320, 270, 8640, 270, 8640, 4320, 8640, 4320, 270, 4320, 8640, 4320, 8640, 270, 8640, 8640, 8640, 8640, 270, 4320, 4320, 4320, 8640, 4320, 270, 4320, 270, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 270, 270, 8640, 4320, 4320, 270, 270, 270, 4320, 270, 4320, 270, 8640, 270, 4320, 8640, 270, 8640, 4320, 270, 8640, 8640, 8640, 8640, 4320, 270, 4320, 8640, 8640, 4320, 270, 270, 8640, 4320, 4320, 270, 270, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 270, 4320, 4320, 4320, 4320, 270, 270, 8640, 270, 8640, 270, 270, 270, 4320, 4320, 8640, 270, 270, 8640, 270, 8640, 4320, 270, 8640, 4320, 4320, 270, 8640, 8640, 8640, 270, 4320, 8640, 270, 8640, 4320, 4320, 8640, 8640, 270, 4320, 8640, 270, 4320, 4320, 270, 4320, 270, 4320, 8640, 8640, 4320, 270, 8640, 270, 8640, 4320, 4320, 4320, 4320, 4320, 270, 270, 8640, 270, 8640, 270, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 270, 270, 270, 270, 270, 4320, 270, 270, 4320, 8640, 8640, 270, 270, 8640, 270, 270, 270, 4320, 270, 4320, 8640, 8640, 4320, 4320, 270, 8640, 4320, 8640, 270, 4320, 4320, 270, 270, 4320, 270, 8640, 8640, 270, 8640, 8640, 270, 4320, 8640, 270, 270, 4320, 4320, 270, 270, 8640, 8640, 8640, 8640, 4320, 270, 4320, 4320, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 8640, 4320, 4320, 4320, 8640, 270, 4320, 4320, 8640, 8640, 270, 8640, 8640, 270, 8640, 270, 270, 4320, 270, 8640, 8640, 8640, 4320, 270, 8640, 8640, 4320, 4320, 8640, 8640, 270, 8640, 8640, 4320, 270, 8640, 4320, 4320, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 270, 8640, 270, 4320, 8640, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 8640, 270, 270, 270, 4320, 270, 4320, 4320, 270, 8640, 4320, 8640, 270, 8640, 270, 4320, 4320, 4320, 4320, 270, 4320, 8640, 8640, 270, 8640, 8640, 270, 8640, 4320, 8640, 4320, 4320, 4320, 270, 4320, 270, 270, 8640, 270, 4320, 270, 270, 4320, 8640, 4320, 8640, 270, 8640, 8640, 4320, 8640, 4320, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1693440 . Total input tokens: 377107671 . Total output tokens: 338540164
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 64.77272789599374,
    "estimated_duration": 3600.0353912424184,
    "input_throughput": 5313.825260311679,
    "output_throughput": 4682.459522761088,
    "total_throughput": 9996.284783072766,
    "itl": 182.43771307365702,
    "ttft": 2043262.5787911925,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 755,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.36045399289809,
    "arrivals": 564654,
    "finished_requests": 77214,
    "scheduler_time": 136.12513978539076
}
#Debug simulation 
Total elapsed time: 64.77288772678003. Arrivals time: 0.37968165101483464 Scheduler time: 64.25841700471938 Scheduler overhead time: 0.04838158190250397 Adapter cache time: 0.019831794314086437 Engine time: 0.048656494822353125 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-16-32/adapters_384_slots_96_rate_0.8-0.4-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-16-32/adapters_384_slots_96_rate_0.8-0.4-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 8640, 4320, 270, 8640, 8640, 270, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 270, 8640, 270, 8640, 4320, 4320, 4320, 270, 270, 4320, 270, 8640, 270, 8640, 4320, 8640, 4320, 270, 4320, 8640, 4320, 8640, 270, 8640, 8640, 8640, 8640, 270, 4320, 4320, 4320, 8640, 4320, 270, 4320, 270, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 270, 270, 8640, 4320, 4320, 270, 270, 270, 4320, 270, 4320, 270, 8640, 270, 4320, 8640, 270, 8640, 4320, 270, 8640, 8640, 8640, 8640, 4320, 270, 4320, 8640, 8640, 4320, 270, 270, 8640, 4320, 4320, 270, 270, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 270, 4320, 4320, 4320, 4320, 270, 270, 8640, 270, 8640, 270, 270, 270, 4320, 4320, 8640, 270, 270, 8640, 270, 8640, 4320, 270, 8640, 4320, 4320, 270, 8640, 8640, 8640, 270, 4320, 8640, 270, 8640, 4320, 4320, 8640, 8640, 270, 4320, 8640, 270, 4320, 4320, 270, 4320, 270, 4320, 8640, 8640, 4320, 270, 8640, 270, 8640, 4320, 4320, 4320, 4320, 4320, 270, 270, 8640, 270, 8640, 270, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 270, 270, 270, 270, 270, 4320, 270, 270, 4320, 8640, 8640, 270, 270, 8640, 270, 270, 270, 4320, 270, 4320, 8640, 8640, 4320, 4320, 270, 8640, 4320, 8640, 270, 4320, 4320, 270, 270, 4320, 270, 8640, 8640, 270, 8640, 8640, 270, 4320, 8640, 270, 270, 4320, 4320, 270, 270, 8640, 8640, 8640, 8640, 4320, 270, 4320, 4320, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 8640, 4320, 4320, 4320, 8640, 270, 4320, 4320, 8640, 8640, 270, 8640, 8640, 270, 8640, 270, 270, 4320, 270, 8640, 8640, 8640, 4320, 270, 8640, 8640, 4320, 4320, 8640, 8640, 270, 8640, 8640, 4320, 270, 8640, 4320, 4320, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 270, 8640, 270, 4320, 8640, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 8640, 270, 270, 270, 4320, 270, 4320, 4320, 270, 8640, 4320, 8640, 270, 8640, 270, 4320, 4320, 4320, 4320, 270, 4320, 8640, 8640, 270, 8640, 8640, 270, 8640, 4320, 8640, 4320, 4320, 4320, 270, 4320, 270, 270, 8640, 270, 4320, 270, 270, 4320, 8640, 4320, 8640, 270, 8640, 8640, 4320, 8640, 4320, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1693440 . Total input tokens: 377107671 . Total output tokens: 338540164
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 63.475631868001074,
    "estimated_duration": 3600.054852960865,
    "input_throughput": 5302.216988249735,
    "output_throughput": 4667.11305417508,
    "total_throughput": 9969.330042424815,
    "itl": 180.10081411809568,
    "ttft": 2046189.0107353616,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 782,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5896969189122334,
    "arrivals": 564654,
    "finished_requests": 76983,
    "scheduler_time": 136.801109310258
}
#Debug simulation 
Total elapsed time: 63.47578601911664. Arrivals time: 0.370155462063849 Scheduler time: 62.9707046574913 Scheduler overhead time: 0.04880994884297252 Adapter cache time: 0.01983953220769763 Engine time: 0.04805241106078029 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_16-16-16/adapters_384_slots_96_rate_0.8-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_16-16-16/adapters_384_slots_96_rate_0.8-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 8640, 4320, 270, 8640, 8640, 270, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 270, 8640, 270, 8640, 4320, 4320, 4320, 270, 270, 4320, 270, 8640, 270, 8640, 4320, 8640, 4320, 270, 4320, 8640, 4320, 8640, 270, 8640, 8640, 8640, 8640, 270, 4320, 4320, 4320, 8640, 4320, 270, 4320, 270, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 270, 270, 8640, 4320, 4320, 270, 270, 270, 4320, 270, 4320, 270, 8640, 270, 4320, 8640, 270, 8640, 4320, 270, 8640, 8640, 8640, 8640, 4320, 270, 4320, 8640, 8640, 4320, 270, 270, 8640, 4320, 4320, 270, 270, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 270, 4320, 4320, 4320, 4320, 270, 270, 8640, 270, 8640, 270, 270, 270, 4320, 4320, 8640, 270, 270, 8640, 270, 8640, 4320, 270, 8640, 4320, 4320, 270, 8640, 8640, 8640, 270, 4320, 8640, 270, 8640, 4320, 4320, 8640, 8640, 270, 4320, 8640, 270, 4320, 4320, 270, 4320, 270, 4320, 8640, 8640, 4320, 270, 8640, 270, 8640, 4320, 4320, 4320, 4320, 4320, 270, 270, 8640, 270, 8640, 270, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 270, 270, 270, 270, 270, 4320, 270, 270, 4320, 8640, 8640, 270, 270, 8640, 270, 270, 270, 4320, 270, 4320, 8640, 8640, 4320, 4320, 270, 8640, 4320, 8640, 270, 4320, 4320, 270, 270, 4320, 270, 8640, 8640, 270, 8640, 8640, 270, 4320, 8640, 270, 270, 4320, 4320, 270, 270, 8640, 8640, 8640, 8640, 4320, 270, 4320, 4320, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 8640, 4320, 4320, 4320, 8640, 270, 4320, 4320, 8640, 8640, 270, 8640, 8640, 270, 8640, 270, 270, 4320, 270, 8640, 8640, 8640, 4320, 270, 8640, 8640, 4320, 4320, 8640, 8640, 270, 8640, 8640, 4320, 270, 8640, 4320, 4320, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 270, 8640, 270, 4320, 8640, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 8640, 270, 270, 270, 4320, 270, 4320, 4320, 270, 8640, 4320, 8640, 270, 8640, 270, 4320, 4320, 4320, 4320, 270, 4320, 8640, 8640, 270, 8640, 8640, 270, 8640, 4320, 8640, 4320, 4320, 4320, 270, 4320, 270, 270, 8640, 270, 4320, 270, 270, 4320, 8640, 4320, 8640, 270, 8640, 8640, 4320, 8640, 4320, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1693440 . Total input tokens: 377107671 . Total output tokens: 338540164
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 64.29357748897746,
    "estimated_duration": 3600.0616955010964,
    "input_throughput": 5318.468020680666,
    "output_throughput": 4683.748620494958,
    "total_throughput": 10002.216641175624,
    "itl": 182.30896949538132,
    "ttft": 2043236.3650072585,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 760,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.27243822412561,
    "arrivals": 564654,
    "finished_requests": 77236,
    "scheduler_time": 136.15006103523797
}
#Debug simulation 
Total elapsed time: 64.29373685782775. Arrivals time: 0.37443366972729564 Scheduler time: 63.78495269874111 Scheduler overhead time: 0.04865650832653046 Adapter cache time: 0.019620421342551708 Engine time: 0.04799648467451334 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_16-16-32/adapters_384_slots_96_rate_0.8-0.4-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_16-16-32/adapters_384_slots_96_rate_0.8-0.4-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 8640, 4320, 270, 8640, 8640, 270, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 270, 8640, 270, 8640, 4320, 4320, 4320, 270, 270, 4320, 270, 8640, 270, 8640, 4320, 8640, 4320, 270, 4320, 8640, 4320, 8640, 270, 8640, 8640, 8640, 8640, 270, 4320, 4320, 4320, 8640, 4320, 270, 4320, 270, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 270, 270, 8640, 4320, 4320, 270, 270, 270, 4320, 270, 4320, 270, 8640, 270, 4320, 8640, 270, 8640, 4320, 270, 8640, 8640, 8640, 8640, 4320, 270, 4320, 8640, 8640, 4320, 270, 270, 8640, 4320, 4320, 270, 270, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 270, 4320, 4320, 4320, 4320, 270, 270, 8640, 270, 8640, 270, 270, 270, 4320, 4320, 8640, 270, 270, 8640, 270, 8640, 4320, 270, 8640, 4320, 4320, 270, 8640, 8640, 8640, 270, 4320, 8640, 270, 8640, 4320, 4320, 8640, 8640, 270, 4320, 8640, 270, 4320, 4320, 270, 4320, 270, 4320, 8640, 8640, 4320, 270, 8640, 270, 8640, 4320, 4320, 4320, 4320, 4320, 270, 270, 8640, 270, 8640, 270, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 270, 270, 270, 270, 270, 4320, 270, 270, 4320, 8640, 8640, 270, 270, 8640, 270, 270, 270, 4320, 270, 4320, 8640, 8640, 4320, 4320, 270, 8640, 4320, 8640, 270, 4320, 4320, 270, 270, 4320, 270, 8640, 8640, 270, 8640, 8640, 270, 4320, 8640, 270, 270, 4320, 4320, 270, 270, 8640, 8640, 8640, 8640, 4320, 270, 4320, 4320, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 8640, 4320, 4320, 4320, 8640, 270, 4320, 4320, 8640, 8640, 270, 8640, 8640, 270, 8640, 270, 270, 4320, 270, 8640, 8640, 8640, 4320, 270, 8640, 8640, 4320, 4320, 8640, 8640, 270, 8640, 8640, 4320, 270, 8640, 4320, 4320, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 270, 8640, 270, 4320, 8640, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 8640, 270, 270, 270, 4320, 270, 4320, 4320, 270, 8640, 4320, 8640, 270, 8640, 270, 4320, 4320, 4320, 4320, 270, 4320, 8640, 8640, 270, 8640, 8640, 270, 8640, 4320, 8640, 4320, 4320, 4320, 270, 4320, 270, 270, 8640, 270, 4320, 270, 270, 4320, 8640, 4320, 8640, 270, 8640, 8640, 4320, 8640, 4320, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1693440 . Total input tokens: 377107671 . Total output tokens: 338540164
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 63.98427964327857,
    "estimated_duration": 3600.0524339586555,
    "input_throughput": 5294.92565724639,
    "output_throughput": 4667.702292747491,
    "total_throughput": 9962.627949993881,
    "itl": 180.0774528281847,
    "ttft": 2045696.8875468015,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 756,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5342528952658308,
    "arrivals": 564654,
    "finished_requests": 76907,
    "scheduler_time": 136.80867707575106
}
#Debug simulation 
Total elapsed time: 63.98443711409345. Arrivals time: 0.3653007880784571 Scheduler time: 63.48419721983373 Scheduler overhead time: 0.048674872145056725 Adapter cache time: 0.01969471015036106 Engine time: 0.048476186115294695 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-8/adapters_384_slots_96_rate_0.8-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-8/adapters_384_slots_96_rate_0.8-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 8640, 4320, 135, 8640, 8640, 135, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 135, 8640, 135, 8640, 4320, 4320, 4320, 135, 135, 4320, 135, 8640, 135, 8640, 4320, 8640, 4320, 135, 4320, 8640, 4320, 8640, 135, 8640, 8640, 8640, 8640, 135, 4320, 4320, 4320, 8640, 4320, 135, 4320, 135, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 135, 135, 8640, 4320, 4320, 135, 135, 135, 4320, 135, 4320, 135, 8640, 135, 4320, 8640, 135, 8640, 4320, 135, 8640, 8640, 8640, 8640, 4320, 135, 4320, 8640, 8640, 4320, 135, 135, 8640, 4320, 4320, 135, 135, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 135, 4320, 4320, 4320, 4320, 135, 135, 8640, 135, 8640, 135, 135, 135, 4320, 4320, 8640, 135, 135, 8640, 135, 8640, 4320, 135, 8640, 4320, 4320, 135, 8640, 8640, 8640, 135, 4320, 8640, 135, 8640, 4320, 4320, 8640, 8640, 135, 4320, 8640, 135, 4320, 4320, 135, 4320, 135, 4320, 8640, 8640, 4320, 135, 8640, 135, 8640, 4320, 4320, 4320, 4320, 4320, 135, 135, 8640, 135, 8640, 135, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 135, 135, 135, 135, 135, 4320, 135, 135, 4320, 8640, 8640, 135, 135, 8640, 135, 135, 135, 4320, 135, 4320, 8640, 8640, 4320, 4320, 135, 8640, 4320, 8640, 135, 4320, 4320, 135, 135, 4320, 135, 8640, 8640, 135, 8640, 8640, 135, 4320, 8640, 135, 135, 4320, 4320, 135, 135, 8640, 8640, 8640, 8640, 4320, 135, 4320, 4320, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 8640, 4320, 4320, 4320, 8640, 135, 4320, 4320, 8640, 8640, 135, 8640, 8640, 135, 8640, 135, 135, 4320, 135, 8640, 8640, 8640, 4320, 135, 8640, 8640, 4320, 4320, 8640, 8640, 135, 8640, 8640, 4320, 135, 8640, 4320, 4320, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 135, 8640, 135, 4320, 8640, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 8640, 135, 135, 135, 4320, 135, 4320, 4320, 135, 8640, 4320, 8640, 135, 8640, 135, 4320, 4320, 4320, 4320, 135, 4320, 8640, 8640, 135, 8640, 8640, 135, 8640, 4320, 8640, 4320, 4320, 4320, 135, 4320, 135, 135, 8640, 135, 4320, 135, 135, 4320, 8640, 4320, 8640, 135, 8640, 8640, 4320, 8640, 4320, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1676160 . Total input tokens: 373325048 . Total output tokens: 335079426
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 68.89341809693724,
    "estimated_duration": 3600.095314988475,
    "input_throughput": 5278.235251407735,
    "output_throughput": 4686.032875230696,
    "total_throughput": 9964.26812663843,
    "itl": 182.6807535125766,
    "ttft": 2037430.576299581,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 678,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.075010690386443,
    "arrivals": 558926,
    "finished_requests": 77080,
    "scheduler_time": 136.06184050469673
}
#Debug simulation 
Total elapsed time: 68.89357013488188. Arrivals time: 0.37702352413907647 Scheduler time: 68.38282662257552 Scheduler overhead time: 0.04971468774601817 Adapter cache time: 0.017815635539591312 Engine time: 0.04862198373302817 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-16/adapters_384_slots_96_rate_0.8-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-16/adapters_384_slots_96_rate_0.8-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 8640, 4320, 135, 8640, 8640, 135, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 135, 8640, 135, 8640, 4320, 4320, 4320, 135, 135, 4320, 135, 8640, 135, 8640, 4320, 8640, 4320, 135, 4320, 8640, 4320, 8640, 135, 8640, 8640, 8640, 8640, 135, 4320, 4320, 4320, 8640, 4320, 135, 4320, 135, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 135, 135, 8640, 4320, 4320, 135, 135, 135, 4320, 135, 4320, 135, 8640, 135, 4320, 8640, 135, 8640, 4320, 135, 8640, 8640, 8640, 8640, 4320, 135, 4320, 8640, 8640, 4320, 135, 135, 8640, 4320, 4320, 135, 135, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 135, 4320, 4320, 4320, 4320, 135, 135, 8640, 135, 8640, 135, 135, 135, 4320, 4320, 8640, 135, 135, 8640, 135, 8640, 4320, 135, 8640, 4320, 4320, 135, 8640, 8640, 8640, 135, 4320, 8640, 135, 8640, 4320, 4320, 8640, 8640, 135, 4320, 8640, 135, 4320, 4320, 135, 4320, 135, 4320, 8640, 8640, 4320, 135, 8640, 135, 8640, 4320, 4320, 4320, 4320, 4320, 135, 135, 8640, 135, 8640, 135, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 135, 135, 135, 135, 135, 4320, 135, 135, 4320, 8640, 8640, 135, 135, 8640, 135, 135, 135, 4320, 135, 4320, 8640, 8640, 4320, 4320, 135, 8640, 4320, 8640, 135, 4320, 4320, 135, 135, 4320, 135, 8640, 8640, 135, 8640, 8640, 135, 4320, 8640, 135, 135, 4320, 4320, 135, 135, 8640, 8640, 8640, 8640, 4320, 135, 4320, 4320, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 8640, 4320, 4320, 4320, 8640, 135, 4320, 4320, 8640, 8640, 135, 8640, 8640, 135, 8640, 135, 135, 4320, 135, 8640, 8640, 8640, 4320, 135, 8640, 8640, 4320, 4320, 8640, 8640, 135, 8640, 8640, 4320, 135, 8640, 4320, 4320, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 135, 8640, 135, 4320, 8640, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 8640, 135, 135, 135, 4320, 135, 4320, 4320, 135, 8640, 4320, 8640, 135, 8640, 135, 4320, 4320, 4320, 4320, 135, 4320, 8640, 8640, 135, 8640, 8640, 135, 8640, 4320, 8640, 4320, 4320, 4320, 135, 4320, 135, 135, 8640, 135, 4320, 135, 135, 4320, 8640, 4320, 8640, 135, 8640, 8640, 4320, 8640, 4320, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1676160 . Total input tokens: 373325048 . Total output tokens: 335079426
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 67.46265716291964,
    "estimated_duration": 3600.1837542345443,
    "input_throughput": 5271.842576834071,
    "output_throughput": 4681.629091897166,
    "total_throughput": 9953.471668731238,
    "itl": 182.52243876939332,
    "ttft": 2040550.379753443,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 728,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3765597254061195,
    "arrivals": 558926,
    "finished_requests": 76984,
    "scheduler_time": 136.15491014123566
}
#Debug simulation 
Total elapsed time: 67.4628038178198. Arrivals time: 0.3814467922784388 Scheduler time: 66.9454511073418 Scheduler overhead time: 0.049774018581956625 Adapter cache time: 0.01899656979367137 Engine time: 0.04883362306281924 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-32/adapters_384_slots_96_rate_0.8-0.4-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-32/adapters_384_slots_96_rate_0.8-0.4-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 8640, 4320, 135, 8640, 8640, 135, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 135, 8640, 135, 8640, 4320, 4320, 4320, 135, 135, 4320, 135, 8640, 135, 8640, 4320, 8640, 4320, 135, 4320, 8640, 4320, 8640, 135, 8640, 8640, 8640, 8640, 135, 4320, 4320, 4320, 8640, 4320, 135, 4320, 135, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 135, 135, 8640, 4320, 4320, 135, 135, 135, 4320, 135, 4320, 135, 8640, 135, 4320, 8640, 135, 8640, 4320, 135, 8640, 8640, 8640, 8640, 4320, 135, 4320, 8640, 8640, 4320, 135, 135, 8640, 4320, 4320, 135, 135, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 135, 4320, 4320, 4320, 4320, 135, 135, 8640, 135, 8640, 135, 135, 135, 4320, 4320, 8640, 135, 135, 8640, 135, 8640, 4320, 135, 8640, 4320, 4320, 135, 8640, 8640, 8640, 135, 4320, 8640, 135, 8640, 4320, 4320, 8640, 8640, 135, 4320, 8640, 135, 4320, 4320, 135, 4320, 135, 4320, 8640, 8640, 4320, 135, 8640, 135, 8640, 4320, 4320, 4320, 4320, 4320, 135, 135, 8640, 135, 8640, 135, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 135, 135, 135, 135, 135, 4320, 135, 135, 4320, 8640, 8640, 135, 135, 8640, 135, 135, 135, 4320, 135, 4320, 8640, 8640, 4320, 4320, 135, 8640, 4320, 8640, 135, 4320, 4320, 135, 135, 4320, 135, 8640, 8640, 135, 8640, 8640, 135, 4320, 8640, 135, 135, 4320, 4320, 135, 135, 8640, 8640, 8640, 8640, 4320, 135, 4320, 4320, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 8640, 4320, 4320, 4320, 8640, 135, 4320, 4320, 8640, 8640, 135, 8640, 8640, 135, 8640, 135, 135, 4320, 135, 8640, 8640, 8640, 4320, 135, 8640, 8640, 4320, 4320, 8640, 8640, 135, 8640, 8640, 4320, 135, 8640, 4320, 4320, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 135, 8640, 135, 4320, 8640, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 8640, 135, 135, 135, 4320, 135, 4320, 4320, 135, 8640, 4320, 8640, 135, 8640, 135, 4320, 4320, 4320, 4320, 135, 4320, 8640, 8640, 135, 8640, 8640, 135, 8640, 4320, 8640, 4320, 4320, 4320, 135, 4320, 135, 135, 8640, 135, 4320, 135, 135, 4320, 8640, 4320, 8640, 135, 8640, 8640, 4320, 8640, 4320, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1676160 . Total input tokens: 373325048 . Total output tokens: 335079426
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 60.063540626782924,
    "estimated_duration": 3600.0951190249457,
    "input_throughput": 5272.810682052555,
    "output_throughput": 4677.996120436202,
    "total_throughput": 9950.806802488756,
    "itl": 181.16089118642046,
    "ttft": 2042821.7255845459,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 787,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5743277535773714,
    "arrivals": 558926,
    "finished_requests": 76975,
    "scheduler_time": 136.40303738089165
}
#Debug simulation 
Total elapsed time: 60.063684675842524. Arrivals time: 0.3671541763469577 Scheduler time: 59.562271332368255 Scheduler overhead time: 0.048809278290718794 Adapter cache time: 0.0194288264028728 Engine time: 0.04820845415815711 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-16/adapters_384_slots_96_rate_0.8-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-16/adapters_384_slots_96_rate_0.8-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 8640, 4320, 135, 8640, 8640, 135, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 135, 8640, 135, 8640, 4320, 4320, 4320, 135, 135, 4320, 135, 8640, 135, 8640, 4320, 8640, 4320, 135, 4320, 8640, 4320, 8640, 135, 8640, 8640, 8640, 8640, 135, 4320, 4320, 4320, 8640, 4320, 135, 4320, 135, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 135, 135, 8640, 4320, 4320, 135, 135, 135, 4320, 135, 4320, 135, 8640, 135, 4320, 8640, 135, 8640, 4320, 135, 8640, 8640, 8640, 8640, 4320, 135, 4320, 8640, 8640, 4320, 135, 135, 8640, 4320, 4320, 135, 135, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 135, 4320, 4320, 4320, 4320, 135, 135, 8640, 135, 8640, 135, 135, 135, 4320, 4320, 8640, 135, 135, 8640, 135, 8640, 4320, 135, 8640, 4320, 4320, 135, 8640, 8640, 8640, 135, 4320, 8640, 135, 8640, 4320, 4320, 8640, 8640, 135, 4320, 8640, 135, 4320, 4320, 135, 4320, 135, 4320, 8640, 8640, 4320, 135, 8640, 135, 8640, 4320, 4320, 4320, 4320, 4320, 135, 135, 8640, 135, 8640, 135, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 135, 135, 135, 135, 135, 4320, 135, 135, 4320, 8640, 8640, 135, 135, 8640, 135, 135, 135, 4320, 135, 4320, 8640, 8640, 4320, 4320, 135, 8640, 4320, 8640, 135, 4320, 4320, 135, 135, 4320, 135, 8640, 8640, 135, 8640, 8640, 135, 4320, 8640, 135, 135, 4320, 4320, 135, 135, 8640, 8640, 8640, 8640, 4320, 135, 4320, 4320, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 8640, 4320, 4320, 4320, 8640, 135, 4320, 4320, 8640, 8640, 135, 8640, 8640, 135, 8640, 135, 135, 4320, 135, 8640, 8640, 8640, 4320, 135, 8640, 8640, 4320, 4320, 8640, 8640, 135, 8640, 8640, 4320, 135, 8640, 4320, 4320, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 135, 8640, 135, 4320, 8640, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 8640, 135, 135, 135, 4320, 135, 4320, 4320, 135, 8640, 4320, 8640, 135, 8640, 135, 4320, 4320, 4320, 4320, 135, 4320, 8640, 8640, 135, 8640, 8640, 135, 8640, 4320, 8640, 4320, 4320, 4320, 135, 4320, 135, 135, 8640, 135, 4320, 135, 135, 4320, 8640, 4320, 8640, 135, 8640, 8640, 4320, 8640, 4320, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1676160 . Total input tokens: 373325048 . Total output tokens: 335079426
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 64.57317184843123,
    "estimated_duration": 3600.1113381962964,
    "input_throughput": 5293.350179982943,
    "output_throughput": 4685.722305591708,
    "total_throughput": 9979.072485574652,
    "itl": 182.94257729997727,
    "ttft": 2040166.0714960464,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 665,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0799087974405697,
    "arrivals": 558926,
    "finished_requests": 77222,
    "scheduler_time": 135.9322114474326
}
#Debug simulation 
Total elapsed time: 64.57332420535386. Arrivals time: 0.37268772535026073 Scheduler time: 64.06702545005828 Scheduler overhead time: 0.04935606848448515 Adapter cache time: 0.017915503587573767 Engine time: 0.048424807377159595 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-32/adapters_384_slots_96_rate_0.8-0.4-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-32/adapters_384_slots_96_rate_0.8-0.4-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 8640, 4320, 135, 8640, 8640, 135, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 135, 8640, 135, 8640, 4320, 4320, 4320, 135, 135, 4320, 135, 8640, 135, 8640, 4320, 8640, 4320, 135, 4320, 8640, 4320, 8640, 135, 8640, 8640, 8640, 8640, 135, 4320, 4320, 4320, 8640, 4320, 135, 4320, 135, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 135, 135, 8640, 4320, 4320, 135, 135, 135, 4320, 135, 4320, 135, 8640, 135, 4320, 8640, 135, 8640, 4320, 135, 8640, 8640, 8640, 8640, 4320, 135, 4320, 8640, 8640, 4320, 135, 135, 8640, 4320, 4320, 135, 135, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 135, 4320, 4320, 4320, 4320, 135, 135, 8640, 135, 8640, 135, 135, 135, 4320, 4320, 8640, 135, 135, 8640, 135, 8640, 4320, 135, 8640, 4320, 4320, 135, 8640, 8640, 8640, 135, 4320, 8640, 135, 8640, 4320, 4320, 8640, 8640, 135, 4320, 8640, 135, 4320, 4320, 135, 4320, 135, 4320, 8640, 8640, 4320, 135, 8640, 135, 8640, 4320, 4320, 4320, 4320, 4320, 135, 135, 8640, 135, 8640, 135, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 135, 135, 135, 135, 135, 4320, 135, 135, 4320, 8640, 8640, 135, 135, 8640, 135, 135, 135, 4320, 135, 4320, 8640, 8640, 4320, 4320, 135, 8640, 4320, 8640, 135, 4320, 4320, 135, 135, 4320, 135, 8640, 8640, 135, 8640, 8640, 135, 4320, 8640, 135, 135, 4320, 4320, 135, 135, 8640, 8640, 8640, 8640, 4320, 135, 4320, 4320, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 8640, 4320, 4320, 4320, 8640, 135, 4320, 4320, 8640, 8640, 135, 8640, 8640, 135, 8640, 135, 135, 4320, 135, 8640, 8640, 8640, 4320, 135, 8640, 8640, 4320, 4320, 8640, 8640, 135, 8640, 8640, 4320, 135, 8640, 4320, 4320, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 135, 8640, 135, 4320, 8640, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 8640, 135, 135, 135, 4320, 135, 4320, 4320, 135, 8640, 4320, 8640, 135, 8640, 135, 4320, 4320, 4320, 4320, 135, 4320, 8640, 8640, 135, 8640, 8640, 135, 8640, 4320, 8640, 4320, 4320, 4320, 135, 4320, 135, 135, 8640, 135, 4320, 135, 135, 4320, 8640, 4320, 8640, 135, 8640, 8640, 4320, 8640, 4320, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1676160 . Total input tokens: 373325048 . Total output tokens: 335079426
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 60.12543458910659,
    "estimated_duration": 3600.1294811093626,
    "input_throughput": 5272.760354761073,
    "output_throughput": 4677.951470459461,
    "total_throughput": 9950.711825220535,
    "itl": 181.16196613462387,
    "ttft": 2042833.425957174,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 787,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6079040145501504,
    "arrivals": 558926,
    "finished_requests": 76975,
    "scheduler_time": 136.40321426464521
}
#Debug simulation 
Total elapsed time: 60.12558260001242. Arrivals time: 0.37451300770044327 Scheduler time: 59.61686485726386 Scheduler overhead time: 0.04831260908395052 Adapter cache time: 0.019548471551388502 Engine time: 0.04825879447162151 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-16/adapters_384_slots_96_rate_0.8-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-16/adapters_384_slots_96_rate_0.8-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 8640, 4320, 135, 8640, 8640, 135, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 135, 8640, 135, 8640, 4320, 4320, 4320, 135, 135, 4320, 135, 8640, 135, 8640, 4320, 8640, 4320, 135, 4320, 8640, 4320, 8640, 135, 8640, 8640, 8640, 8640, 135, 4320, 4320, 4320, 8640, 4320, 135, 4320, 135, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 135, 135, 8640, 4320, 4320, 135, 135, 135, 4320, 135, 4320, 135, 8640, 135, 4320, 8640, 135, 8640, 4320, 135, 8640, 8640, 8640, 8640, 4320, 135, 4320, 8640, 8640, 4320, 135, 135, 8640, 4320, 4320, 135, 135, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 135, 4320, 4320, 4320, 4320, 135, 135, 8640, 135, 8640, 135, 135, 135, 4320, 4320, 8640, 135, 135, 8640, 135, 8640, 4320, 135, 8640, 4320, 4320, 135, 8640, 8640, 8640, 135, 4320, 8640, 135, 8640, 4320, 4320, 8640, 8640, 135, 4320, 8640, 135, 4320, 4320, 135, 4320, 135, 4320, 8640, 8640, 4320, 135, 8640, 135, 8640, 4320, 4320, 4320, 4320, 4320, 135, 135, 8640, 135, 8640, 135, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 135, 135, 135, 135, 135, 4320, 135, 135, 4320, 8640, 8640, 135, 135, 8640, 135, 135, 135, 4320, 135, 4320, 8640, 8640, 4320, 4320, 135, 8640, 4320, 8640, 135, 4320, 4320, 135, 135, 4320, 135, 8640, 8640, 135, 8640, 8640, 135, 4320, 8640, 135, 135, 4320, 4320, 135, 135, 8640, 8640, 8640, 8640, 4320, 135, 4320, 4320, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 8640, 4320, 4320, 4320, 8640, 135, 4320, 4320, 8640, 8640, 135, 8640, 8640, 135, 8640, 135, 135, 4320, 135, 8640, 8640, 8640, 4320, 135, 8640, 8640, 4320, 4320, 8640, 8640, 135, 8640, 8640, 4320, 135, 8640, 4320, 4320, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 135, 8640, 135, 4320, 8640, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 8640, 135, 135, 135, 4320, 135, 4320, 4320, 135, 8640, 4320, 8640, 135, 8640, 135, 4320, 4320, 4320, 4320, 135, 4320, 8640, 8640, 135, 8640, 8640, 135, 8640, 4320, 8640, 4320, 4320, 4320, 135, 4320, 135, 135, 8640, 135, 4320, 135, 135, 4320, 8640, 4320, 8640, 135, 8640, 8640, 4320, 8640, 4320, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1676160 . Total input tokens: 373325048 . Total output tokens: 335079426
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 68.04098223056644,
    "estimated_duration": 3600.1783515567067,
    "input_throughput": 5275.496418611483,
    "output_throughput": 4685.358433063815,
    "total_throughput": 9960.854851675298,
    "itl": 182.68810277915566,
    "ttft": 2039021.756053742,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 717,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.143866061444821,
    "arrivals": 558926,
    "finished_requests": 77033,
    "scheduler_time": 136.05853158464873
}
#Debug simulation 
Total elapsed time: 68.04113004077226. Arrivals time: 0.3968385639600456 Scheduler time: 67.50873023923486 Scheduler overhead time: 0.049866505432873964 Adapter cache time: 0.018590154591947794 Engine time: 0.04899687832221389 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-32/adapters_384_slots_96_rate_0.8-0.4-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-32/adapters_384_slots_96_rate_0.8-0.4-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 8640, 4320, 135, 8640, 8640, 135, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 135, 8640, 135, 8640, 4320, 4320, 4320, 135, 135, 4320, 135, 8640, 135, 8640, 4320, 8640, 4320, 135, 4320, 8640, 4320, 8640, 135, 8640, 8640, 8640, 8640, 135, 4320, 4320, 4320, 8640, 4320, 135, 4320, 135, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 135, 135, 8640, 4320, 4320, 135, 135, 135, 4320, 135, 4320, 135, 8640, 135, 4320, 8640, 135, 8640, 4320, 135, 8640, 8640, 8640, 8640, 4320, 135, 4320, 8640, 8640, 4320, 135, 135, 8640, 4320, 4320, 135, 135, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 135, 4320, 4320, 4320, 4320, 135, 135, 8640, 135, 8640, 135, 135, 135, 4320, 4320, 8640, 135, 135, 8640, 135, 8640, 4320, 135, 8640, 4320, 4320, 135, 8640, 8640, 8640, 135, 4320, 8640, 135, 8640, 4320, 4320, 8640, 8640, 135, 4320, 8640, 135, 4320, 4320, 135, 4320, 135, 4320, 8640, 8640, 4320, 135, 8640, 135, 8640, 4320, 4320, 4320, 4320, 4320, 135, 135, 8640, 135, 8640, 135, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 135, 135, 135, 135, 135, 4320, 135, 135, 4320, 8640, 8640, 135, 135, 8640, 135, 135, 135, 4320, 135, 4320, 8640, 8640, 4320, 4320, 135, 8640, 4320, 8640, 135, 4320, 4320, 135, 135, 4320, 135, 8640, 8640, 135, 8640, 8640, 135, 4320, 8640, 135, 135, 4320, 4320, 135, 135, 8640, 8640, 8640, 8640, 4320, 135, 4320, 4320, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 8640, 4320, 4320, 4320, 8640, 135, 4320, 4320, 8640, 8640, 135, 8640, 8640, 135, 8640, 135, 135, 4320, 135, 8640, 8640, 8640, 4320, 135, 8640, 8640, 4320, 4320, 8640, 8640, 135, 8640, 8640, 4320, 135, 8640, 4320, 4320, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 135, 8640, 135, 4320, 8640, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 8640, 135, 135, 135, 4320, 135, 4320, 4320, 135, 8640, 4320, 8640, 135, 8640, 135, 4320, 4320, 4320, 4320, 135, 4320, 8640, 8640, 135, 8640, 8640, 135, 8640, 4320, 8640, 4320, 4320, 4320, 135, 4320, 135, 135, 8640, 135, 4320, 135, 135, 4320, 8640, 4320, 8640, 135, 8640, 8640, 4320, 8640, 4320, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1676160 . Total input tokens: 373325048 . Total output tokens: 335079426
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 60.13129303092137,
    "estimated_duration": 3600.1610335471573,
    "input_throughput": 5272.7141433717625,
    "output_throughput": 4677.910472078721,
    "total_throughput": 9950.624615450484,
    "itl": 181.16233342830554,
    "ttft": 2042842.8447920596,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 787,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.64110301416369,
    "arrivals": 558926,
    "finished_requests": 76975,
    "scheduler_time": 136.40371752373107
}
#Debug simulation 
Total elapsed time: 60.1314488411881. Arrivals time: 0.3790325685404241 Scheduler time: 59.61833098297939 Scheduler overhead time: 0.04854405578225851 Adapter cache time: 0.01969843776896596 Engine time: 0.04763017548248172 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-8/adapters_384_slots_96_rate_0.8-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-8/adapters_384_slots_96_rate_0.8-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 8640, 4320, 66, 8640, 8640, 66, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 66, 8640, 66, 8640, 4320, 4320, 4320, 66, 66, 4320, 66, 8640, 66, 8640, 4320, 8640, 4320, 66, 4320, 8640, 4320, 8640, 66, 8640, 8640, 8640, 8640, 66, 4320, 4320, 4320, 8640, 4320, 66, 4320, 66, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 66, 66, 8640, 4320, 4320, 66, 66, 66, 4320, 66, 4320, 66, 8640, 66, 4320, 8640, 66, 8640, 4320, 66, 8640, 8640, 8640, 8640, 4320, 66, 4320, 8640, 8640, 4320, 66, 66, 8640, 4320, 4320, 66, 66, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 66, 4320, 4320, 4320, 4320, 66, 66, 8640, 66, 8640, 66, 66, 66, 4320, 4320, 8640, 66, 66, 8640, 66, 8640, 4320, 66, 8640, 4320, 4320, 66, 8640, 8640, 8640, 66, 4320, 8640, 66, 8640, 4320, 4320, 8640, 8640, 66, 4320, 8640, 66, 4320, 4320, 66, 4320, 66, 4320, 8640, 8640, 4320, 66, 8640, 66, 8640, 4320, 4320, 4320, 4320, 4320, 66, 66, 8640, 66, 8640, 66, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 66, 66, 66, 66, 66, 4320, 66, 66, 4320, 8640, 8640, 66, 66, 8640, 66, 66, 66, 4320, 66, 4320, 8640, 8640, 4320, 4320, 66, 8640, 4320, 8640, 66, 4320, 4320, 66, 66, 4320, 66, 8640, 8640, 66, 8640, 8640, 66, 4320, 8640, 66, 66, 4320, 4320, 66, 66, 8640, 8640, 8640, 8640, 4320, 66, 4320, 4320, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 8640, 4320, 4320, 4320, 8640, 66, 4320, 4320, 8640, 8640, 66, 8640, 8640, 66, 8640, 66, 66, 4320, 66, 8640, 8640, 8640, 4320, 66, 8640, 8640, 4320, 4320, 8640, 8640, 66, 8640, 8640, 4320, 66, 8640, 4320, 4320, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 66, 8640, 66, 4320, 8640, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 8640, 66, 66, 66, 4320, 66, 4320, 4320, 66, 8640, 4320, 8640, 66, 8640, 66, 4320, 4320, 4320, 4320, 66, 4320, 8640, 8640, 66, 8640, 8640, 66, 8640, 4320, 8640, 4320, 4320, 4320, 66, 4320, 66, 66, 8640, 66, 4320, 66, 66, 4320, 8640, 4320, 8640, 66, 8640, 8640, 4320, 8640, 4320, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1667328 . Total input tokens: 371334482 . Total output tokens: 333329261
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 74.08681092876941,
    "estimated_duration": 3600.0589575754216,
    "input_throughput": 5362.872727229641,
    "output_throughput": 4682.814975717468,
    "total_throughput": 10045.687702947109,
    "itl": 181.05606734133656,
    "ttft": 2030033.9080089612,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 605,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8515950850793443,
    "arrivals": 556060,
    "finished_requests": 77729,
    "scheduler_time": 136.56844114880522
}
#Debug simulation 
Total elapsed time: 74.08695897972211. Arrivals time: 0.39192466624081135 Scheduler time: 73.5587307754904 Scheduler overhead time: 0.0507966042496264 Adapter cache time: 0.017580698244273663 Engine time: 0.05003038654103875 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-16/adapters_384_slots_96_rate_0.8-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-16/adapters_384_slots_96_rate_0.8-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 8640, 4320, 66, 8640, 8640, 66, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 66, 8640, 66, 8640, 4320, 4320, 4320, 66, 66, 4320, 66, 8640, 66, 8640, 4320, 8640, 4320, 66, 4320, 8640, 4320, 8640, 66, 8640, 8640, 8640, 8640, 66, 4320, 4320, 4320, 8640, 4320, 66, 4320, 66, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 66, 66, 8640, 4320, 4320, 66, 66, 66, 4320, 66, 4320, 66, 8640, 66, 4320, 8640, 66, 8640, 4320, 66, 8640, 8640, 8640, 8640, 4320, 66, 4320, 8640, 8640, 4320, 66, 66, 8640, 4320, 4320, 66, 66, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 66, 4320, 4320, 4320, 4320, 66, 66, 8640, 66, 8640, 66, 66, 66, 4320, 4320, 8640, 66, 66, 8640, 66, 8640, 4320, 66, 8640, 4320, 4320, 66, 8640, 8640, 8640, 66, 4320, 8640, 66, 8640, 4320, 4320, 8640, 8640, 66, 4320, 8640, 66, 4320, 4320, 66, 4320, 66, 4320, 8640, 8640, 4320, 66, 8640, 66, 8640, 4320, 4320, 4320, 4320, 4320, 66, 66, 8640, 66, 8640, 66, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 66, 66, 66, 66, 66, 4320, 66, 66, 4320, 8640, 8640, 66, 66, 8640, 66, 66, 66, 4320, 66, 4320, 8640, 8640, 4320, 4320, 66, 8640, 4320, 8640, 66, 4320, 4320, 66, 66, 4320, 66, 8640, 8640, 66, 8640, 8640, 66, 4320, 8640, 66, 66, 4320, 4320, 66, 66, 8640, 8640, 8640, 8640, 4320, 66, 4320, 4320, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 8640, 4320, 4320, 4320, 8640, 66, 4320, 4320, 8640, 8640, 66, 8640, 8640, 66, 8640, 66, 66, 4320, 66, 8640, 8640, 8640, 4320, 66, 8640, 8640, 4320, 4320, 8640, 8640, 66, 8640, 8640, 4320, 66, 8640, 4320, 4320, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 66, 8640, 66, 4320, 8640, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 8640, 66, 66, 66, 4320, 66, 4320, 4320, 66, 8640, 4320, 8640, 66, 8640, 66, 4320, 4320, 4320, 4320, 66, 4320, 8640, 8640, 66, 8640, 8640, 66, 8640, 4320, 8640, 4320, 4320, 4320, 66, 4320, 66, 66, 8640, 66, 4320, 66, 66, 4320, 8640, 4320, 8640, 66, 8640, 8640, 4320, 8640, 4320, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1667328 . Total input tokens: 371334482 . Total output tokens: 333329261
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 72.82550421589985,
    "estimated_duration": 3600.1681069376646,
    "input_throughput": 5366.840499132988,
    "output_throughput": 4690.985392447513,
    "total_throughput": 10057.8258915805,
    "itl": 180.85177078135283,
    "ttft": 2030391.8626109988,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 523,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.70271871250356,
    "arrivals": 556060,
    "finished_requests": 77858,
    "scheduler_time": 136.7544587718194
}
#Debug simulation 
Total elapsed time: 72.82565726293251. Arrivals time: 0.3852843241766095 Scheduler time: 72.30348806269467 Scheduler overhead time: 0.05124735599383712 Adapter cache time: 0.01623874856159091 Engine time: 0.05075586121529341 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-32/adapters_384_slots_96_rate_0.8-0.4-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-32/adapters_384_slots_96_rate_0.8-0.4-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 8640, 4320, 66, 8640, 8640, 66, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 66, 8640, 66, 8640, 4320, 4320, 4320, 66, 66, 4320, 66, 8640, 66, 8640, 4320, 8640, 4320, 66, 4320, 8640, 4320, 8640, 66, 8640, 8640, 8640, 8640, 66, 4320, 4320, 4320, 8640, 4320, 66, 4320, 66, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 66, 66, 8640, 4320, 4320, 66, 66, 66, 4320, 66, 4320, 66, 8640, 66, 4320, 8640, 66, 8640, 4320, 66, 8640, 8640, 8640, 8640, 4320, 66, 4320, 8640, 8640, 4320, 66, 66, 8640, 4320, 4320, 66, 66, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 66, 4320, 4320, 4320, 4320, 66, 66, 8640, 66, 8640, 66, 66, 66, 4320, 4320, 8640, 66, 66, 8640, 66, 8640, 4320, 66, 8640, 4320, 4320, 66, 8640, 8640, 8640, 66, 4320, 8640, 66, 8640, 4320, 4320, 8640, 8640, 66, 4320, 8640, 66, 4320, 4320, 66, 4320, 66, 4320, 8640, 8640, 4320, 66, 8640, 66, 8640, 4320, 4320, 4320, 4320, 4320, 66, 66, 8640, 66, 8640, 66, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 66, 66, 66, 66, 66, 4320, 66, 66, 4320, 8640, 8640, 66, 66, 8640, 66, 66, 66, 4320, 66, 4320, 8640, 8640, 4320, 4320, 66, 8640, 4320, 8640, 66, 4320, 4320, 66, 66, 4320, 66, 8640, 8640, 66, 8640, 8640, 66, 4320, 8640, 66, 66, 4320, 4320, 66, 66, 8640, 8640, 8640, 8640, 4320, 66, 4320, 4320, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 8640, 4320, 4320, 4320, 8640, 66, 4320, 4320, 8640, 8640, 66, 8640, 8640, 66, 8640, 66, 66, 4320, 66, 8640, 8640, 8640, 4320, 66, 8640, 8640, 4320, 4320, 8640, 8640, 66, 8640, 8640, 4320, 66, 8640, 4320, 4320, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 66, 8640, 66, 4320, 8640, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 8640, 66, 66, 66, 4320, 66, 4320, 4320, 66, 8640, 4320, 8640, 66, 8640, 66, 4320, 4320, 4320, 4320, 66, 4320, 8640, 8640, 66, 8640, 8640, 66, 8640, 4320, 8640, 4320, 4320, 4320, 66, 4320, 66, 66, 8640, 66, 4320, 66, 66, 4320, 8640, 4320, 8640, 66, 8640, 8640, 4320, 8640, 4320, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1667328 . Total input tokens: 371334482 . Total output tokens: 333329261
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 64.44917991012335,
    "estimated_duration": 3600.179299451754,
    "input_throughput": 5358.213687562066,
    "output_throughput": 4701.96192800115,
    "total_throughput": 10060.175615563217,
    "itl": 179.33664452370795,
    "ttft": 2036881.2759909504,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 678,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.213580914530907,
    "arrivals": 556060,
    "finished_requests": 77840,
    "scheduler_time": 137.41193941986484
}
#Debug simulation 
Total elapsed time: 64.44933163933456. Arrivals time: 0.3790709082968533 Scheduler time: 63.93451460869983 Scheduler overhead time: 0.05002071475610137 Adapter cache time: 0.01813092827796936 Engine time: 0.049447334837168455 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-16/adapters_384_slots_96_rate_0.8-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-16/adapters_384_slots_96_rate_0.8-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 8640, 4320, 66, 8640, 8640, 66, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 66, 8640, 66, 8640, 4320, 4320, 4320, 66, 66, 4320, 66, 8640, 66, 8640, 4320, 8640, 4320, 66, 4320, 8640, 4320, 8640, 66, 8640, 8640, 8640, 8640, 66, 4320, 4320, 4320, 8640, 4320, 66, 4320, 66, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 66, 66, 8640, 4320, 4320, 66, 66, 66, 4320, 66, 4320, 66, 8640, 66, 4320, 8640, 66, 8640, 4320, 66, 8640, 8640, 8640, 8640, 4320, 66, 4320, 8640, 8640, 4320, 66, 66, 8640, 4320, 4320, 66, 66, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 66, 4320, 4320, 4320, 4320, 66, 66, 8640, 66, 8640, 66, 66, 66, 4320, 4320, 8640, 66, 66, 8640, 66, 8640, 4320, 66, 8640, 4320, 4320, 66, 8640, 8640, 8640, 66, 4320, 8640, 66, 8640, 4320, 4320, 8640, 8640, 66, 4320, 8640, 66, 4320, 4320, 66, 4320, 66, 4320, 8640, 8640, 4320, 66, 8640, 66, 8640, 4320, 4320, 4320, 4320, 4320, 66, 66, 8640, 66, 8640, 66, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 66, 66, 66, 66, 66, 4320, 66, 66, 4320, 8640, 8640, 66, 66, 8640, 66, 66, 66, 4320, 66, 4320, 8640, 8640, 4320, 4320, 66, 8640, 4320, 8640, 66, 4320, 4320, 66, 66, 4320, 66, 8640, 8640, 66, 8640, 8640, 66, 4320, 8640, 66, 66, 4320, 4320, 66, 66, 8640, 8640, 8640, 8640, 4320, 66, 4320, 4320, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 8640, 4320, 4320, 4320, 8640, 66, 4320, 4320, 8640, 8640, 66, 8640, 8640, 66, 8640, 66, 66, 4320, 66, 8640, 8640, 8640, 4320, 66, 8640, 8640, 4320, 4320, 8640, 8640, 66, 8640, 8640, 4320, 66, 8640, 4320, 4320, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 66, 8640, 66, 4320, 8640, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 8640, 66, 66, 66, 4320, 66, 4320, 4320, 66, 8640, 4320, 8640, 66, 8640, 66, 4320, 4320, 4320, 4320, 66, 4320, 8640, 8640, 66, 8640, 8640, 66, 8640, 4320, 8640, 4320, 4320, 4320, 66, 4320, 66, 66, 8640, 66, 4320, 66, 66, 4320, 8640, 4320, 8640, 66, 8640, 8640, 4320, 8640, 4320, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1667328 . Total input tokens: 371334482 . Total output tokens: 333329261
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 68.51195691665635,
    "estimated_duration": 3600.133096304501,
    "input_throughput": 5349.866097942441,
    "output_throughput": 4685.510104422333,
    "total_throughput": 10035.376202364774,
    "itl": 181.21983403046028,
    "ttft": 2033338.6874572497,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 527,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6464434955036178,
    "arrivals": 556060,
    "finished_requests": 77619,
    "scheduler_time": 136.52326889554297
}
#Debug simulation 
Total elapsed time: 68.512104567606. Arrivals time: 0.41449807584285736 Scheduler time: 67.96093495981768 Scheduler overhead time: 0.05157482856884599 Adapter cache time: 0.016041382681578398 Engine time: 0.05021333508193493 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-32/adapters_384_slots_96_rate_0.8-0.4-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-32/adapters_384_slots_96_rate_0.8-0.4-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 8640, 4320, 66, 8640, 8640, 66, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 66, 8640, 66, 8640, 4320, 4320, 4320, 66, 66, 4320, 66, 8640, 66, 8640, 4320, 8640, 4320, 66, 4320, 8640, 4320, 8640, 66, 8640, 8640, 8640, 8640, 66, 4320, 4320, 4320, 8640, 4320, 66, 4320, 66, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 66, 66, 8640, 4320, 4320, 66, 66, 66, 4320, 66, 4320, 66, 8640, 66, 4320, 8640, 66, 8640, 4320, 66, 8640, 8640, 8640, 8640, 4320, 66, 4320, 8640, 8640, 4320, 66, 66, 8640, 4320, 4320, 66, 66, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 66, 4320, 4320, 4320, 4320, 66, 66, 8640, 66, 8640, 66, 66, 66, 4320, 4320, 8640, 66, 66, 8640, 66, 8640, 4320, 66, 8640, 4320, 4320, 66, 8640, 8640, 8640, 66, 4320, 8640, 66, 8640, 4320, 4320, 8640, 8640, 66, 4320, 8640, 66, 4320, 4320, 66, 4320, 66, 4320, 8640, 8640, 4320, 66, 8640, 66, 8640, 4320, 4320, 4320, 4320, 4320, 66, 66, 8640, 66, 8640, 66, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 66, 66, 66, 66, 66, 4320, 66, 66, 4320, 8640, 8640, 66, 66, 8640, 66, 66, 66, 4320, 66, 4320, 8640, 8640, 4320, 4320, 66, 8640, 4320, 8640, 66, 4320, 4320, 66, 66, 4320, 66, 8640, 8640, 66, 8640, 8640, 66, 4320, 8640, 66, 66, 4320, 4320, 66, 66, 8640, 8640, 8640, 8640, 4320, 66, 4320, 4320, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 8640, 4320, 4320, 4320, 8640, 66, 4320, 4320, 8640, 8640, 66, 8640, 8640, 66, 8640, 66, 66, 4320, 66, 8640, 8640, 8640, 4320, 66, 8640, 8640, 4320, 4320, 8640, 8640, 66, 8640, 8640, 4320, 66, 8640, 4320, 4320, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 66, 8640, 66, 4320, 8640, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 8640, 66, 66, 66, 4320, 66, 4320, 4320, 66, 8640, 4320, 8640, 66, 8640, 66, 4320, 4320, 4320, 4320, 66, 4320, 8640, 8640, 66, 8640, 8640, 66, 8640, 4320, 8640, 4320, 4320, 4320, 66, 4320, 66, 66, 8640, 66, 4320, 66, 66, 4320, 8640, 4320, 8640, 66, 8640, 8640, 4320, 8640, 4320, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1667328 . Total input tokens: 371334482 . Total output tokens: 333329261
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 72.76147285522893,
    "estimated_duration": 3600.1561244227883,
    "input_throughput": 5348.737480957817,
    "output_throughput": 4684.661836076357,
    "total_throughput": 10033.399317034173,
    "itl": 179.74241879469125,
    "ttft": 2031228.8882282504,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 520,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.719260848257694,
    "arrivals": 556060,
    "finished_requests": 77646,
    "scheduler_time": 137.03575953762677
}
#Debug simulation 
Total elapsed time: 72.7616278110072. Arrivals time: 0.39148725382983685 Scheduler time: 72.23271406954154 Scheduler overhead time: 0.05175010906532407 Adapter cache time: 0.01576183456927538 Engine time: 0.0512351025827229 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-16/adapters_384_slots_96_rate_0.8-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-16/adapters_384_slots_96_rate_0.8-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 8640, 4320, 66, 8640, 8640, 66, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 66, 8640, 66, 8640, 4320, 4320, 4320, 66, 66, 4320, 66, 8640, 66, 8640, 4320, 8640, 4320, 66, 4320, 8640, 4320, 8640, 66, 8640, 8640, 8640, 8640, 66, 4320, 4320, 4320, 8640, 4320, 66, 4320, 66, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 66, 66, 8640, 4320, 4320, 66, 66, 66, 4320, 66, 4320, 66, 8640, 66, 4320, 8640, 66, 8640, 4320, 66, 8640, 8640, 8640, 8640, 4320, 66, 4320, 8640, 8640, 4320, 66, 66, 8640, 4320, 4320, 66, 66, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 66, 4320, 4320, 4320, 4320, 66, 66, 8640, 66, 8640, 66, 66, 66, 4320, 4320, 8640, 66, 66, 8640, 66, 8640, 4320, 66, 8640, 4320, 4320, 66, 8640, 8640, 8640, 66, 4320, 8640, 66, 8640, 4320, 4320, 8640, 8640, 66, 4320, 8640, 66, 4320, 4320, 66, 4320, 66, 4320, 8640, 8640, 4320, 66, 8640, 66, 8640, 4320, 4320, 4320, 4320, 4320, 66, 66, 8640, 66, 8640, 66, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 66, 66, 66, 66, 66, 4320, 66, 66, 4320, 8640, 8640, 66, 66, 8640, 66, 66, 66, 4320, 66, 4320, 8640, 8640, 4320, 4320, 66, 8640, 4320, 8640, 66, 4320, 4320, 66, 66, 4320, 66, 8640, 8640, 66, 8640, 8640, 66, 4320, 8640, 66, 66, 4320, 4320, 66, 66, 8640, 8640, 8640, 8640, 4320, 66, 4320, 4320, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 8640, 4320, 4320, 4320, 8640, 66, 4320, 4320, 8640, 8640, 66, 8640, 8640, 66, 8640, 66, 66, 4320, 66, 8640, 8640, 8640, 4320, 66, 8640, 8640, 4320, 4320, 8640, 8640, 66, 8640, 8640, 4320, 66, 8640, 4320, 4320, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 66, 8640, 66, 4320, 8640, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 8640, 66, 66, 66, 4320, 66, 4320, 4320, 66, 8640, 4320, 8640, 66, 8640, 66, 4320, 4320, 4320, 4320, 66, 4320, 8640, 8640, 66, 8640, 8640, 66, 8640, 4320, 8640, 4320, 4320, 4320, 66, 4320, 66, 66, 8640, 66, 4320, 66, 66, 4320, 8640, 4320, 8640, 66, 8640, 8640, 4320, 8640, 4320, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1667328 . Total input tokens: 371334482 . Total output tokens: 333329261
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 73.97499289503321,
    "estimated_duration": 3600.0470879410436,
    "input_throughput": 5366.160088491701,
    "output_throughput": 4684.57039256265,
    "total_throughput": 10050.73048105435,
    "itl": 180.95864914725956,
    "ttft": 2030327.6278682542,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 603,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8030003278259847,
    "arrivals": 556060,
    "finished_requests": 77772,
    "scheduler_time": 136.6178183129808
}
#Debug simulation 
Total elapsed time: 73.97513964027166. Arrivals time: 0.3904577987268567 Scheduler time: 73.44865525141358 Scheduler overhead time: 0.050345759838819504 Adapter cache time: 0.01741176936775446 Engine time: 0.04999107448384166 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-32/adapters_384_slots_96_rate_0.8-0.4-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-32/adapters_384_slots_96_rate_0.8-0.4-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 8640, 4320, 66, 8640, 8640, 66, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 66, 8640, 66, 8640, 4320, 4320, 4320, 66, 66, 4320, 66, 8640, 66, 8640, 4320, 8640, 4320, 66, 4320, 8640, 4320, 8640, 66, 8640, 8640, 8640, 8640, 66, 4320, 4320, 4320, 8640, 4320, 66, 4320, 66, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 66, 66, 8640, 4320, 4320, 66, 66, 66, 4320, 66, 4320, 66, 8640, 66, 4320, 8640, 66, 8640, 4320, 66, 8640, 8640, 8640, 8640, 4320, 66, 4320, 8640, 8640, 4320, 66, 66, 8640, 4320, 4320, 66, 66, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 66, 4320, 4320, 4320, 4320, 66, 66, 8640, 66, 8640, 66, 66, 66, 4320, 4320, 8640, 66, 66, 8640, 66, 8640, 4320, 66, 8640, 4320, 4320, 66, 8640, 8640, 8640, 66, 4320, 8640, 66, 8640, 4320, 4320, 8640, 8640, 66, 4320, 8640, 66, 4320, 4320, 66, 4320, 66, 4320, 8640, 8640, 4320, 66, 8640, 66, 8640, 4320, 4320, 4320, 4320, 4320, 66, 66, 8640, 66, 8640, 66, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 66, 66, 66, 66, 66, 4320, 66, 66, 4320, 8640, 8640, 66, 66, 8640, 66, 66, 66, 4320, 66, 4320, 8640, 8640, 4320, 4320, 66, 8640, 4320, 8640, 66, 4320, 4320, 66, 66, 4320, 66, 8640, 8640, 66, 8640, 8640, 66, 4320, 8640, 66, 66, 4320, 4320, 66, 66, 8640, 8640, 8640, 8640, 4320, 66, 4320, 4320, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 8640, 4320, 4320, 4320, 8640, 66, 4320, 4320, 8640, 8640, 66, 8640, 8640, 66, 8640, 66, 66, 4320, 66, 8640, 8640, 8640, 4320, 66, 8640, 8640, 4320, 4320, 8640, 8640, 66, 8640, 8640, 4320, 66, 8640, 4320, 4320, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 66, 8640, 66, 4320, 8640, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 8640, 66, 66, 66, 4320, 66, 4320, 4320, 66, 8640, 4320, 8640, 66, 8640, 66, 4320, 4320, 4320, 4320, 66, 4320, 8640, 8640, 66, 8640, 8640, 66, 8640, 4320, 8640, 4320, 4320, 4320, 66, 4320, 66, 66, 8640, 66, 4320, 66, 66, 4320, 8640, 4320, 8640, 66, 8640, 8640, 4320, 8640, 4320, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1667328 . Total input tokens: 371334482 . Total output tokens: 333329261
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 72.02316471002996,
    "estimated_duration": 3600.106956673871,
    "input_throughput": 5346.8741989222435,
    "output_throughput": 4685.630511262646,
    "total_throughput": 10032.50471018489,
    "itl": 179.47362051303713,
    "ttft": 2031458.64140263,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 524,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7531503148376923,
    "arrivals": 556060,
    "finished_requests": 77665,
    "scheduler_time": 137.19070417694655
}
#Debug simulation 
Total elapsed time: 72.02332371426746. Arrivals time: 0.3996081738732755 Scheduler time: 71.48636031057686 Scheduler overhead time: 0.0506203300319612 Adapter cache time: 0.01644236547872424 Engine time: 0.050558613147586584 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-8/adapters_384_slots_96_rate_0.8-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-8/adapters_384_slots_96_rate_0.8-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 4320, 33, 8640, 8640, 33, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 33, 8640, 33, 8640, 4320, 4320, 4320, 33, 33, 4320, 33, 8640, 33, 8640, 4320, 8640, 4320, 33, 4320, 8640, 4320, 8640, 33, 8640, 8640, 8640, 8640, 33, 4320, 4320, 4320, 8640, 4320, 33, 4320, 33, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 33, 33, 8640, 4320, 4320, 33, 33, 33, 4320, 33, 4320, 33, 8640, 33, 4320, 8640, 33, 8640, 4320, 33, 8640, 8640, 8640, 8640, 4320, 33, 4320, 8640, 8640, 4320, 33, 33, 8640, 4320, 4320, 33, 33, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 33, 4320, 4320, 4320, 4320, 33, 33, 8640, 33, 8640, 33, 33, 33, 4320, 4320, 8640, 33, 33, 8640, 33, 8640, 4320, 33, 8640, 4320, 4320, 33, 8640, 8640, 8640, 33, 4320, 8640, 33, 8640, 4320, 4320, 8640, 8640, 33, 4320, 8640, 33, 4320, 4320, 33, 4320, 33, 4320, 8640, 8640, 4320, 33, 8640, 33, 8640, 4320, 4320, 4320, 4320, 4320, 33, 33, 8640, 33, 8640, 33, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 33, 33, 33, 33, 33, 4320, 33, 33, 4320, 8640, 8640, 33, 33, 8640, 33, 33, 33, 4320, 33, 4320, 8640, 8640, 4320, 4320, 33, 8640, 4320, 8640, 33, 4320, 4320, 33, 33, 4320, 33, 8640, 8640, 33, 8640, 8640, 33, 4320, 8640, 33, 33, 4320, 4320, 33, 33, 8640, 8640, 8640, 8640, 4320, 33, 4320, 4320, 33, 33, 33, 33, 33, 33, 33, 33, 4320, 8640, 4320, 4320, 4320, 8640, 33, 4320, 4320, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 4320, 33, 8640, 8640, 8640, 4320, 33, 8640, 8640, 4320, 4320, 8640, 8640, 33, 8640, 8640, 4320, 33, 8640, 4320, 4320, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 4320, 8640, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 8640, 33, 33, 33, 4320, 33, 4320, 4320, 33, 8640, 4320, 8640, 33, 8640, 33, 4320, 4320, 4320, 4320, 33, 4320, 8640, 8640, 33, 8640, 8640, 33, 8640, 4320, 8640, 4320, 4320, 4320, 33, 4320, 33, 33, 8640, 33, 4320, 33, 33, 4320, 8640, 4320, 8640, 33, 8640, 8640, 4320, 8640, 4320, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1663104 . Total input tokens: 370407110 . Total output tokens: 332473527
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 63.263098889030516,
    "estimated_duration": 3600.045964042821,
    "input_throughput": 5353.4369262210785,
    "output_throughput": 4727.247699051204,
    "total_throughput": 10080.684625272283,
    "itl": 180.19220464854803,
    "ttft": 2039903.133804297,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 536,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.640421430747977,
    "arrivals": 554588,
    "finished_requests": 77651,
    "scheduler_time": 137.68890409926314
}
#Debug simulation 
Total elapsed time: 63.263246812392026. Arrivals time: 0.3869108990766108 Scheduler time: 62.74407154601067 Scheduler overhead time: 0.050165554974228144 Adapter cache time: 0.015704278368502855 Engine time: 0.04800941934809089 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-16/adapters_384_slots_96_rate_0.8-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-16/adapters_384_slots_96_rate_0.8-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 4320, 33, 8640, 8640, 33, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 33, 8640, 33, 8640, 4320, 4320, 4320, 33, 33, 4320, 33, 8640, 33, 8640, 4320, 8640, 4320, 33, 4320, 8640, 4320, 8640, 33, 8640, 8640, 8640, 8640, 33, 4320, 4320, 4320, 8640, 4320, 33, 4320, 33, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 33, 33, 8640, 4320, 4320, 33, 33, 33, 4320, 33, 4320, 33, 8640, 33, 4320, 8640, 33, 8640, 4320, 33, 8640, 8640, 8640, 8640, 4320, 33, 4320, 8640, 8640, 4320, 33, 33, 8640, 4320, 4320, 33, 33, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 33, 4320, 4320, 4320, 4320, 33, 33, 8640, 33, 8640, 33, 33, 33, 4320, 4320, 8640, 33, 33, 8640, 33, 8640, 4320, 33, 8640, 4320, 4320, 33, 8640, 8640, 8640, 33, 4320, 8640, 33, 8640, 4320, 4320, 8640, 8640, 33, 4320, 8640, 33, 4320, 4320, 33, 4320, 33, 4320, 8640, 8640, 4320, 33, 8640, 33, 8640, 4320, 4320, 4320, 4320, 4320, 33, 33, 8640, 33, 8640, 33, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 33, 33, 33, 33, 33, 4320, 33, 33, 4320, 8640, 8640, 33, 33, 8640, 33, 33, 33, 4320, 33, 4320, 8640, 8640, 4320, 4320, 33, 8640, 4320, 8640, 33, 4320, 4320, 33, 33, 4320, 33, 8640, 8640, 33, 8640, 8640, 33, 4320, 8640, 33, 33, 4320, 4320, 33, 33, 8640, 8640, 8640, 8640, 4320, 33, 4320, 4320, 33, 33, 33, 33, 33, 33, 33, 33, 4320, 8640, 4320, 4320, 4320, 8640, 33, 4320, 4320, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 4320, 33, 8640, 8640, 8640, 4320, 33, 8640, 8640, 4320, 4320, 8640, 8640, 33, 8640, 8640, 4320, 33, 8640, 4320, 4320, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 4320, 8640, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 8640, 33, 33, 33, 4320, 33, 4320, 4320, 33, 8640, 4320, 8640, 33, 8640, 33, 4320, 4320, 4320, 4320, 33, 4320, 8640, 8640, 33, 8640, 8640, 33, 8640, 4320, 8640, 4320, 4320, 4320, 33, 4320, 33, 33, 8640, 33, 4320, 33, 33, 4320, 8640, 4320, 8640, 33, 8640, 8640, 4320, 8640, 4320, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1663104 . Total input tokens: 370407110 . Total output tokens: 332473527
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 62.98129407595843,
    "estimated_duration": 3600.057995486522,
    "input_throughput": 5343.780023577129,
    "output_throughput": 4722.006984696545,
    "total_throughput": 10065.787008273674,
    "itl": 180.51392329105215,
    "ttft": 2040450.5979260572,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 537,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7511169417272374,
    "arrivals": 554588,
    "finished_requests": 77449,
    "scheduler_time": 137.51687829673332
}
#Debug simulation 
Total elapsed time: 62.98145127110183. Arrivals time: 0.3883593697100878 Scheduler time: 62.46023881062865 Scheduler overhead time: 0.04946893407031894 Adapter cache time: 0.015945961233228445 Engine time: 0.04877931298688054 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-32/adapters_384_slots_96_rate_0.8-0.4-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-32/adapters_384_slots_96_rate_0.8-0.4-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 4320, 33, 8640, 8640, 33, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 33, 8640, 33, 8640, 4320, 4320, 4320, 33, 33, 4320, 33, 8640, 33, 8640, 4320, 8640, 4320, 33, 4320, 8640, 4320, 8640, 33, 8640, 8640, 8640, 8640, 33, 4320, 4320, 4320, 8640, 4320, 33, 4320, 33, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 33, 33, 8640, 4320, 4320, 33, 33, 33, 4320, 33, 4320, 33, 8640, 33, 4320, 8640, 33, 8640, 4320, 33, 8640, 8640, 8640, 8640, 4320, 33, 4320, 8640, 8640, 4320, 33, 33, 8640, 4320, 4320, 33, 33, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 33, 4320, 4320, 4320, 4320, 33, 33, 8640, 33, 8640, 33, 33, 33, 4320, 4320, 8640, 33, 33, 8640, 33, 8640, 4320, 33, 8640, 4320, 4320, 33, 8640, 8640, 8640, 33, 4320, 8640, 33, 8640, 4320, 4320, 8640, 8640, 33, 4320, 8640, 33, 4320, 4320, 33, 4320, 33, 4320, 8640, 8640, 4320, 33, 8640, 33, 8640, 4320, 4320, 4320, 4320, 4320, 33, 33, 8640, 33, 8640, 33, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 33, 33, 33, 33, 33, 4320, 33, 33, 4320, 8640, 8640, 33, 33, 8640, 33, 33, 33, 4320, 33, 4320, 8640, 8640, 4320, 4320, 33, 8640, 4320, 8640, 33, 4320, 4320, 33, 33, 4320, 33, 8640, 8640, 33, 8640, 8640, 33, 4320, 8640, 33, 33, 4320, 4320, 33, 33, 8640, 8640, 8640, 8640, 4320, 33, 4320, 4320, 33, 33, 33, 33, 33, 33, 33, 33, 4320, 8640, 4320, 4320, 4320, 8640, 33, 4320, 4320, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 4320, 33, 8640, 8640, 8640, 4320, 33, 8640, 8640, 4320, 4320, 8640, 8640, 33, 8640, 8640, 4320, 33, 8640, 4320, 4320, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 4320, 8640, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 8640, 33, 33, 33, 4320, 33, 4320, 4320, 33, 8640, 4320, 8640, 33, 8640, 33, 4320, 4320, 4320, 4320, 33, 4320, 8640, 8640, 33, 8640, 8640, 33, 8640, 4320, 8640, 4320, 4320, 4320, 33, 4320, 33, 33, 8640, 33, 4320, 33, 33, 4320, 8640, 4320, 8640, 33, 8640, 8640, 4320, 8640, 4320, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1663104 . Total input tokens: 370407110 . Total output tokens: 332473527
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 64.25612327922136,
    "estimated_duration": 3600.075755372775,
    "input_throughput": 5340.536507129468,
    "output_throughput": 4727.691347772107,
    "total_throughput": 10068.227854901575,
    "itl": 178.39509695864447,
    "ttft": 2043743.9207544269,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 553,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8075102488510422,
    "arrivals": 554588,
    "finished_requests": 77519,
    "scheduler_time": 138.36676005393534
}
#Debug simulation 
Total elapsed time: 64.25627759005874. Arrivals time: 0.4281417545862496 Scheduler time: 63.69536392344162 Scheduler overhead time: 0.049487849697470665 Adapter cache time: 0.016234096605330706 Engine time: 0.04878615494817495 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-16/adapters_384_slots_96_rate_0.8-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-16/adapters_384_slots_96_rate_0.8-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 4320, 33, 8640, 8640, 33, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 33, 8640, 33, 8640, 4320, 4320, 4320, 33, 33, 4320, 33, 8640, 33, 8640, 4320, 8640, 4320, 33, 4320, 8640, 4320, 8640, 33, 8640, 8640, 8640, 8640, 33, 4320, 4320, 4320, 8640, 4320, 33, 4320, 33, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 33, 33, 8640, 4320, 4320, 33, 33, 33, 4320, 33, 4320, 33, 8640, 33, 4320, 8640, 33, 8640, 4320, 33, 8640, 8640, 8640, 8640, 4320, 33, 4320, 8640, 8640, 4320, 33, 33, 8640, 4320, 4320, 33, 33, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 33, 4320, 4320, 4320, 4320, 33, 33, 8640, 33, 8640, 33, 33, 33, 4320, 4320, 8640, 33, 33, 8640, 33, 8640, 4320, 33, 8640, 4320, 4320, 33, 8640, 8640, 8640, 33, 4320, 8640, 33, 8640, 4320, 4320, 8640, 8640, 33, 4320, 8640, 33, 4320, 4320, 33, 4320, 33, 4320, 8640, 8640, 4320, 33, 8640, 33, 8640, 4320, 4320, 4320, 4320, 4320, 33, 33, 8640, 33, 8640, 33, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 33, 33, 33, 33, 33, 4320, 33, 33, 4320, 8640, 8640, 33, 33, 8640, 33, 33, 33, 4320, 33, 4320, 8640, 8640, 4320, 4320, 33, 8640, 4320, 8640, 33, 4320, 4320, 33, 33, 4320, 33, 8640, 8640, 33, 8640, 8640, 33, 4320, 8640, 33, 33, 4320, 4320, 33, 33, 8640, 8640, 8640, 8640, 4320, 33, 4320, 4320, 33, 33, 33, 33, 33, 33, 33, 33, 4320, 8640, 4320, 4320, 4320, 8640, 33, 4320, 4320, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 4320, 33, 8640, 8640, 8640, 4320, 33, 8640, 8640, 4320, 4320, 8640, 8640, 33, 8640, 8640, 4320, 33, 8640, 4320, 4320, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 4320, 8640, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 8640, 33, 33, 33, 4320, 33, 4320, 4320, 33, 8640, 4320, 8640, 33, 8640, 33, 4320, 4320, 4320, 4320, 33, 4320, 8640, 8640, 33, 8640, 8640, 33, 8640, 4320, 8640, 4320, 4320, 4320, 33, 4320, 33, 33, 8640, 33, 4320, 33, 33, 4320, 8640, 4320, 8640, 33, 8640, 8640, 4320, 8640, 4320, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1663104 . Total input tokens: 370407110 . Total output tokens: 332473527
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 62.95921909529716,
    "estimated_duration": 3600.022389778195,
    "input_throughput": 5350.342835280737,
    "output_throughput": 4727.583097350848,
    "total_throughput": 10077.925932631584,
    "itl": 180.1658440245311,
    "ttft": 2039769.2552337942,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 528,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.655153880256687,
    "arrivals": 554588,
    "finished_requests": 77580,
    "scheduler_time": 137.6997760508088
}
#Debug simulation 
Total elapsed time: 62.959369586315006. Arrivals time: 0.39808151917532086 Scheduler time: 62.42895518243313 Scheduler overhead time: 0.04944272665306926 Adapter cache time: 0.015657593961805105 Engine time: 0.048521689139306545 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-32/adapters_384_slots_96_rate_0.8-0.4-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-32/adapters_384_slots_96_rate_0.8-0.4-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 4320, 33, 8640, 8640, 33, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 33, 8640, 33, 8640, 4320, 4320, 4320, 33, 33, 4320, 33, 8640, 33, 8640, 4320, 8640, 4320, 33, 4320, 8640, 4320, 8640, 33, 8640, 8640, 8640, 8640, 33, 4320, 4320, 4320, 8640, 4320, 33, 4320, 33, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 33, 33, 8640, 4320, 4320, 33, 33, 33, 4320, 33, 4320, 33, 8640, 33, 4320, 8640, 33, 8640, 4320, 33, 8640, 8640, 8640, 8640, 4320, 33, 4320, 8640, 8640, 4320, 33, 33, 8640, 4320, 4320, 33, 33, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 33, 4320, 4320, 4320, 4320, 33, 33, 8640, 33, 8640, 33, 33, 33, 4320, 4320, 8640, 33, 33, 8640, 33, 8640, 4320, 33, 8640, 4320, 4320, 33, 8640, 8640, 8640, 33, 4320, 8640, 33, 8640, 4320, 4320, 8640, 8640, 33, 4320, 8640, 33, 4320, 4320, 33, 4320, 33, 4320, 8640, 8640, 4320, 33, 8640, 33, 8640, 4320, 4320, 4320, 4320, 4320, 33, 33, 8640, 33, 8640, 33, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 33, 33, 33, 33, 33, 4320, 33, 33, 4320, 8640, 8640, 33, 33, 8640, 33, 33, 33, 4320, 33, 4320, 8640, 8640, 4320, 4320, 33, 8640, 4320, 8640, 33, 4320, 4320, 33, 33, 4320, 33, 8640, 8640, 33, 8640, 8640, 33, 4320, 8640, 33, 33, 4320, 4320, 33, 33, 8640, 8640, 8640, 8640, 4320, 33, 4320, 4320, 33, 33, 33, 33, 33, 33, 33, 33, 4320, 8640, 4320, 4320, 4320, 8640, 33, 4320, 4320, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 4320, 33, 8640, 8640, 8640, 4320, 33, 8640, 8640, 4320, 4320, 8640, 8640, 33, 8640, 8640, 4320, 33, 8640, 4320, 4320, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 4320, 8640, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 8640, 33, 33, 33, 4320, 33, 4320, 4320, 33, 8640, 4320, 8640, 33, 8640, 33, 4320, 4320, 4320, 4320, 33, 4320, 8640, 8640, 33, 8640, 8640, 33, 8640, 4320, 8640, 4320, 4320, 4320, 33, 4320, 33, 33, 8640, 33, 4320, 33, 33, 4320, 8640, 4320, 8640, 33, 8640, 8640, 4320, 8640, 4320, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1663104 . Total input tokens: 370407110 . Total output tokens: 332473527
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 64.2124840640463,
    "estimated_duration": 3600.1428122188813,
    "input_throughput": 5340.705911649546,
    "output_throughput": 4727.821058162281,
    "total_throughput": 10068.526969811826,
    "itl": 178.3442394298978,
    "ttft": 2043786.8249259328,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 552,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8264736426249193,
    "arrivals": 554588,
    "finished_requests": 77525,
    "scheduler_time": 138.39122025801498
}
#Debug simulation 
Total elapsed time: 64.21264035860077. Arrivals time: 0.41573392366990447 Scheduler time: 63.663409856148064 Scheduler overhead time: 0.04928441718220711 Adapter cache time: 0.01609216956421733 Engine time: 0.0492055038921535 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-16/adapters_384_slots_96_rate_0.8-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-16/adapters_384_slots_96_rate_0.8-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 4320, 33, 8640, 8640, 33, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 33, 8640, 33, 8640, 4320, 4320, 4320, 33, 33, 4320, 33, 8640, 33, 8640, 4320, 8640, 4320, 33, 4320, 8640, 4320, 8640, 33, 8640, 8640, 8640, 8640, 33, 4320, 4320, 4320, 8640, 4320, 33, 4320, 33, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 33, 33, 8640, 4320, 4320, 33, 33, 33, 4320, 33, 4320, 33, 8640, 33, 4320, 8640, 33, 8640, 4320, 33, 8640, 8640, 8640, 8640, 4320, 33, 4320, 8640, 8640, 4320, 33, 33, 8640, 4320, 4320, 33, 33, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 33, 4320, 4320, 4320, 4320, 33, 33, 8640, 33, 8640, 33, 33, 33, 4320, 4320, 8640, 33, 33, 8640, 33, 8640, 4320, 33, 8640, 4320, 4320, 33, 8640, 8640, 8640, 33, 4320, 8640, 33, 8640, 4320, 4320, 8640, 8640, 33, 4320, 8640, 33, 4320, 4320, 33, 4320, 33, 4320, 8640, 8640, 4320, 33, 8640, 33, 8640, 4320, 4320, 4320, 4320, 4320, 33, 33, 8640, 33, 8640, 33, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 33, 33, 33, 33, 33, 4320, 33, 33, 4320, 8640, 8640, 33, 33, 8640, 33, 33, 33, 4320, 33, 4320, 8640, 8640, 4320, 4320, 33, 8640, 4320, 8640, 33, 4320, 4320, 33, 33, 4320, 33, 8640, 8640, 33, 8640, 8640, 33, 4320, 8640, 33, 33, 4320, 4320, 33, 33, 8640, 8640, 8640, 8640, 4320, 33, 4320, 4320, 33, 33, 33, 33, 33, 33, 33, 33, 4320, 8640, 4320, 4320, 4320, 8640, 33, 4320, 4320, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 4320, 33, 8640, 8640, 8640, 4320, 33, 8640, 8640, 4320, 4320, 8640, 8640, 33, 8640, 8640, 4320, 33, 8640, 4320, 4320, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 4320, 8640, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 8640, 33, 33, 33, 4320, 33, 4320, 4320, 33, 8640, 4320, 8640, 33, 8640, 33, 4320, 4320, 4320, 4320, 33, 4320, 8640, 8640, 33, 8640, 8640, 33, 8640, 4320, 8640, 4320, 4320, 4320, 33, 4320, 33, 33, 8640, 33, 4320, 33, 33, 4320, 8640, 4320, 8640, 33, 8640, 8640, 4320, 8640, 4320, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1663104 . Total input tokens: 370407110 . Total output tokens: 332473527
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 62.85045796073973,
    "estimated_duration": 3600.1591450631418,
    "input_throughput": 5351.676196431612,
    "output_throughput": 4727.412126582949,
    "total_throughput": 10079.088323014561,
    "itl": 180.38041766415134,
    "ttft": 2039991.008213271,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 538,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6086470586573502,
    "arrivals": 554588,
    "finished_requests": 77581,
    "scheduler_time": 137.61236549469746
}
#Debug simulation 
Total elapsed time: 62.85061251698062. Arrivals time: 0.3924478148110211 Scheduler time: 62.32697847066447 Scheduler overhead time: 0.04929781472310424 Adapter cache time: 0.01586455386132002 Engine time: 0.04833524953573942 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-32/adapters_384_slots_96_rate_0.8-0.4-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-32/adapters_384_slots_96_rate_0.8-0.4-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 4320, 33, 8640, 8640, 33, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 33, 8640, 33, 8640, 4320, 4320, 4320, 33, 33, 4320, 33, 8640, 33, 8640, 4320, 8640, 4320, 33, 4320, 8640, 4320, 8640, 33, 8640, 8640, 8640, 8640, 33, 4320, 4320, 4320, 8640, 4320, 33, 4320, 33, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 33, 33, 8640, 4320, 4320, 33, 33, 33, 4320, 33, 4320, 33, 8640, 33, 4320, 8640, 33, 8640, 4320, 33, 8640, 8640, 8640, 8640, 4320, 33, 4320, 8640, 8640, 4320, 33, 33, 8640, 4320, 4320, 33, 33, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 8640, 8640, 33, 4320, 4320, 4320, 4320, 33, 33, 8640, 33, 8640, 33, 33, 33, 4320, 4320, 8640, 33, 33, 8640, 33, 8640, 4320, 33, 8640, 4320, 4320, 33, 8640, 8640, 8640, 33, 4320, 8640, 33, 8640, 4320, 4320, 8640, 8640, 33, 4320, 8640, 33, 4320, 4320, 33, 4320, 33, 4320, 8640, 8640, 4320, 33, 8640, 33, 8640, 4320, 4320, 4320, 4320, 4320, 33, 33, 8640, 33, 8640, 33, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 33, 33, 33, 33, 33, 4320, 33, 33, 4320, 8640, 8640, 33, 33, 8640, 33, 33, 33, 4320, 33, 4320, 8640, 8640, 4320, 4320, 33, 8640, 4320, 8640, 33, 4320, 4320, 33, 33, 4320, 33, 8640, 8640, 33, 8640, 8640, 33, 4320, 8640, 33, 33, 4320, 4320, 33, 33, 8640, 8640, 8640, 8640, 4320, 33, 4320, 4320, 33, 33, 33, 33, 33, 33, 33, 33, 4320, 8640, 4320, 4320, 4320, 8640, 33, 4320, 4320, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 4320, 33, 8640, 8640, 8640, 4320, 33, 8640, 8640, 4320, 4320, 8640, 8640, 33, 8640, 8640, 4320, 33, 8640, 4320, 4320, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 4320, 8640, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 8640, 33, 33, 33, 4320, 33, 4320, 4320, 33, 8640, 4320, 8640, 33, 8640, 33, 4320, 4320, 4320, 4320, 33, 4320, 8640, 8640, 33, 8640, 8640, 33, 8640, 4320, 8640, 4320, 4320, 4320, 33, 4320, 33, 33, 8640, 33, 4320, 33, 33, 4320, 8640, 4320, 8640, 33, 8640, 8640, 4320, 8640, 4320, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1663104 . Total input tokens: 370407110 . Total output tokens: 332473527
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 64.26008242927492,
    "estimated_duration": 3600.0019070723783,
    "input_throughput": 5339.140504964616,
    "output_throughput": 4727.645551121598,
    "total_throughput": 10066.786056086215,
    "itl": 178.3981769814377,
    "ttft": 2043919.7756148994,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 556,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8639699551463091,
    "arrivals": 554588,
    "finished_requests": 77508,
    "scheduler_time": 138.3625614927324
}
#Debug simulation 
Total elapsed time: 64.26023056637496. Arrivals time: 0.4114361251704395 Scheduler time: 63.71590323979035 Scheduler overhead time: 0.049109754618257284 Adapter cache time: 0.016091344878077507 Engine time: 0.049220678396523 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-8/adapters_384_slots_96_rate_0.8-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-8/adapters_384_slots_96_rate_0.8-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 8640, 1080, 540, 8640, 8640, 540, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 540, 8640, 540, 8640, 1080, 1080, 1080, 540, 540, 1080, 540, 8640, 540, 8640, 1080, 8640, 1080, 540, 1080, 8640, 1080, 8640, 540, 8640, 8640, 8640, 8640, 540, 1080, 1080, 1080, 8640, 1080, 540, 1080, 540, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 540, 540, 8640, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 8640, 540, 1080, 8640, 540, 8640, 1080, 540, 8640, 8640, 8640, 8640, 1080, 540, 1080, 8640, 8640, 1080, 540, 540, 8640, 1080, 1080, 540, 540, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 540, 1080, 1080, 1080, 1080, 540, 540, 8640, 540, 8640, 540, 540, 540, 1080, 1080, 8640, 540, 540, 8640, 540, 8640, 1080, 540, 8640, 1080, 1080, 540, 8640, 8640, 8640, 540, 1080, 8640, 540, 8640, 1080, 1080, 8640, 8640, 540, 1080, 8640, 540, 1080, 1080, 540, 1080, 540, 1080, 8640, 8640, 1080, 540, 8640, 540, 8640, 1080, 1080, 1080, 1080, 1080, 540, 540, 8640, 540, 8640, 540, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 8640, 8640, 540, 540, 8640, 540, 540, 540, 1080, 540, 1080, 8640, 8640, 1080, 1080, 540, 8640, 1080, 8640, 540, 1080, 1080, 540, 540, 1080, 540, 8640, 8640, 540, 8640, 8640, 540, 1080, 8640, 540, 540, 1080, 1080, 540, 540, 8640, 8640, 8640, 8640, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 8640, 1080, 1080, 1080, 8640, 540, 1080, 1080, 8640, 8640, 540, 8640, 8640, 540, 8640, 540, 540, 1080, 540, 8640, 8640, 8640, 1080, 540, 8640, 8640, 1080, 1080, 8640, 8640, 540, 8640, 8640, 1080, 540, 8640, 1080, 1080, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 540, 8640, 540, 1080, 8640, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 8640, 540, 540, 540, 1080, 540, 1080, 1080, 540, 8640, 1080, 8640, 540, 8640, 540, 1080, 1080, 1080, 1080, 540, 1080, 8640, 8640, 540, 8640, 8640, 540, 8640, 1080, 8640, 1080, 1080, 1080, 540, 1080, 540, 540, 8640, 540, 1080, 540, 540, 1080, 8640, 1080, 8640, 540, 8640, 8640, 1080, 8640, 1080, 540, 8640, 540, 8640, 8640, 540, 540, 540]
Prompts retrieved: 1313280 . Total input tokens: 292726781 . Total output tokens: 262474905
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 76.05442913016304,
    "estimated_duration": 3600.038548231196,
    "input_throughput": 5297.950770380233,
    "output_throughput": 4677.705467424494,
    "total_throughput": 9975.656237804726,
    "itl": 181.99420988340552,
    "ttft": 1989121.8650016645,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 707,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.163764834960496,
    "arrivals": 438250,
    "finished_requests": 77190,
    "scheduler_time": 135.61754648736004
}
#Debug simulation 
Total elapsed time: 76.05457963887602. Arrivals time: 0.3722218335606158 Scheduler time: 75.54350138222799 Scheduler overhead time: 0.05084473034366965 Adapter cache time: 0.02032187720760703 Engine time: 0.049261198844760656 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-16/adapters_384_slots_96_rate_0.8-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-16/adapters_384_slots_96_rate_0.8-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 8640, 1080, 540, 8640, 8640, 540, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 540, 8640, 540, 8640, 1080, 1080, 1080, 540, 540, 1080, 540, 8640, 540, 8640, 1080, 8640, 1080, 540, 1080, 8640, 1080, 8640, 540, 8640, 8640, 8640, 8640, 540, 1080, 1080, 1080, 8640, 1080, 540, 1080, 540, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 540, 540, 8640, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 8640, 540, 1080, 8640, 540, 8640, 1080, 540, 8640, 8640, 8640, 8640, 1080, 540, 1080, 8640, 8640, 1080, 540, 540, 8640, 1080, 1080, 540, 540, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 540, 1080, 1080, 1080, 1080, 540, 540, 8640, 540, 8640, 540, 540, 540, 1080, 1080, 8640, 540, 540, 8640, 540, 8640, 1080, 540, 8640, 1080, 1080, 540, 8640, 8640, 8640, 540, 1080, 8640, 540, 8640, 1080, 1080, 8640, 8640, 540, 1080, 8640, 540, 1080, 1080, 540, 1080, 540, 1080, 8640, 8640, 1080, 540, 8640, 540, 8640, 1080, 1080, 1080, 1080, 1080, 540, 540, 8640, 540, 8640, 540, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 8640, 8640, 540, 540, 8640, 540, 540, 540, 1080, 540, 1080, 8640, 8640, 1080, 1080, 540, 8640, 1080, 8640, 540, 1080, 1080, 540, 540, 1080, 540, 8640, 8640, 540, 8640, 8640, 540, 1080, 8640, 540, 540, 1080, 1080, 540, 540, 8640, 8640, 8640, 8640, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 8640, 1080, 1080, 1080, 8640, 540, 1080, 1080, 8640, 8640, 540, 8640, 8640, 540, 8640, 540, 540, 1080, 540, 8640, 8640, 8640, 1080, 540, 8640, 8640, 1080, 1080, 8640, 8640, 540, 8640, 8640, 1080, 540, 8640, 1080, 1080, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 540, 8640, 540, 1080, 8640, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 8640, 540, 540, 540, 1080, 540, 1080, 1080, 540, 8640, 1080, 8640, 540, 8640, 540, 1080, 1080, 1080, 1080, 540, 1080, 8640, 8640, 540, 8640, 8640, 540, 8640, 1080, 8640, 1080, 1080, 1080, 540, 1080, 540, 540, 8640, 540, 1080, 540, 540, 1080, 8640, 1080, 8640, 540, 8640, 8640, 1080, 8640, 1080, 540, 8640, 540, 8640, 8640, 540, 540, 540]
Prompts retrieved: 1313280 . Total input tokens: 292726781 . Total output tokens: 262474905
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 76.01740330969915,
    "estimated_duration": 3600.146105824731,
    "input_throughput": 5308.35900495267,
    "output_throughput": 4684.545989040217,
    "total_throughput": 9992.904993992888,
    "itl": 182.30624702047953,
    "ttft": 1990411.1292852312,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 680,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.219145070423843,
    "arrivals": 438250,
    "finished_requests": 77385,
    "scheduler_time": 135.49193757889063
}
#Debug simulation 
Total elapsed time: 76.01754383277148. Arrivals time: 0.37027114257216454 Scheduler time: 75.5079290587455 Scheduler overhead time: 0.05100491736084223 Adapter cache time: 0.01964470511302352 Engine time: 0.05022874986752868 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-32/adapters_384_slots_96_rate_0.8-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-32/adapters_384_slots_96_rate_0.8-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 8640, 1080, 540, 8640, 8640, 540, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 540, 8640, 540, 8640, 1080, 1080, 1080, 540, 540, 1080, 540, 8640, 540, 8640, 1080, 8640, 1080, 540, 1080, 8640, 1080, 8640, 540, 8640, 8640, 8640, 8640, 540, 1080, 1080, 1080, 8640, 1080, 540, 1080, 540, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 540, 540, 8640, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 8640, 540, 1080, 8640, 540, 8640, 1080, 540, 8640, 8640, 8640, 8640, 1080, 540, 1080, 8640, 8640, 1080, 540, 540, 8640, 1080, 1080, 540, 540, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 540, 1080, 1080, 1080, 1080, 540, 540, 8640, 540, 8640, 540, 540, 540, 1080, 1080, 8640, 540, 540, 8640, 540, 8640, 1080, 540, 8640, 1080, 1080, 540, 8640, 8640, 8640, 540, 1080, 8640, 540, 8640, 1080, 1080, 8640, 8640, 540, 1080, 8640, 540, 1080, 1080, 540, 1080, 540, 1080, 8640, 8640, 1080, 540, 8640, 540, 8640, 1080, 1080, 1080, 1080, 1080, 540, 540, 8640, 540, 8640, 540, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 8640, 8640, 540, 540, 8640, 540, 540, 540, 1080, 540, 1080, 8640, 8640, 1080, 1080, 540, 8640, 1080, 8640, 540, 1080, 1080, 540, 540, 1080, 540, 8640, 8640, 540, 8640, 8640, 540, 1080, 8640, 540, 540, 1080, 1080, 540, 540, 8640, 8640, 8640, 8640, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 8640, 1080, 1080, 1080, 8640, 540, 1080, 1080, 8640, 8640, 540, 8640, 8640, 540, 8640, 540, 540, 1080, 540, 8640, 8640, 8640, 1080, 540, 8640, 8640, 1080, 1080, 8640, 8640, 540, 8640, 8640, 1080, 540, 8640, 1080, 1080, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 540, 8640, 540, 1080, 8640, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 8640, 540, 540, 540, 1080, 540, 1080, 1080, 540, 8640, 1080, 8640, 540, 8640, 540, 1080, 1080, 1080, 1080, 540, 1080, 8640, 8640, 540, 8640, 8640, 540, 8640, 1080, 8640, 1080, 1080, 1080, 540, 1080, 540, 540, 8640, 540, 1080, 540, 540, 1080, 8640, 1080, 8640, 540, 8640, 8640, 1080, 8640, 1080, 540, 8640, 540, 8640, 8640, 540, 540, 540]
Prompts retrieved: 1313280 . Total input tokens: 292726781 . Total output tokens: 262474905
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 72.03118502208963,
    "estimated_duration": 3600.1812768800864,
    "input_throughput": 5281.584325242113,
    "output_throughput": 4663.069914787284,
    "total_throughput": 9944.654240029397,
    "itl": 180.110351913581,
    "ttft": 1992725.4831064823,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 765,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5006253890134333,
    "arrivals": 438250,
    "finished_requests": 76986,
    "scheduler_time": 136.19838753956196
}
#Debug simulation 
Total elapsed time: 72.03133004019037. Arrivals time: 0.3722680280916393 Scheduler time: 71.52129090530798 Scheduler overhead time: 0.04959451872855425 Adapter cache time: 0.02083656657487154 Engine time: 0.048998578917235136 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-16-16/adapters_384_slots_96_rate_0.8-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-16-16/adapters_384_slots_96_rate_0.8-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 8640, 1080, 540, 8640, 8640, 540, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 540, 8640, 540, 8640, 1080, 1080, 1080, 540, 540, 1080, 540, 8640, 540, 8640, 1080, 8640, 1080, 540, 1080, 8640, 1080, 8640, 540, 8640, 8640, 8640, 8640, 540, 1080, 1080, 1080, 8640, 1080, 540, 1080, 540, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 540, 540, 8640, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 8640, 540, 1080, 8640, 540, 8640, 1080, 540, 8640, 8640, 8640, 8640, 1080, 540, 1080, 8640, 8640, 1080, 540, 540, 8640, 1080, 1080, 540, 540, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 540, 1080, 1080, 1080, 1080, 540, 540, 8640, 540, 8640, 540, 540, 540, 1080, 1080, 8640, 540, 540, 8640, 540, 8640, 1080, 540, 8640, 1080, 1080, 540, 8640, 8640, 8640, 540, 1080, 8640, 540, 8640, 1080, 1080, 8640, 8640, 540, 1080, 8640, 540, 1080, 1080, 540, 1080, 540, 1080, 8640, 8640, 1080, 540, 8640, 540, 8640, 1080, 1080, 1080, 1080, 1080, 540, 540, 8640, 540, 8640, 540, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 8640, 8640, 540, 540, 8640, 540, 540, 540, 1080, 540, 1080, 8640, 8640, 1080, 1080, 540, 8640, 1080, 8640, 540, 1080, 1080, 540, 540, 1080, 540, 8640, 8640, 540, 8640, 8640, 540, 1080, 8640, 540, 540, 1080, 1080, 540, 540, 8640, 8640, 8640, 8640, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 8640, 1080, 1080, 1080, 8640, 540, 1080, 1080, 8640, 8640, 540, 8640, 8640, 540, 8640, 540, 540, 1080, 540, 8640, 8640, 8640, 1080, 540, 8640, 8640, 1080, 1080, 8640, 8640, 540, 8640, 8640, 1080, 540, 8640, 1080, 1080, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 540, 8640, 540, 1080, 8640, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 8640, 540, 540, 540, 1080, 540, 1080, 1080, 540, 8640, 1080, 8640, 540, 8640, 540, 1080, 1080, 1080, 1080, 540, 1080, 8640, 8640, 540, 8640, 8640, 540, 8640, 1080, 8640, 1080, 1080, 1080, 540, 1080, 540, 540, 8640, 540, 1080, 540, 540, 1080, 8640, 1080, 8640, 540, 8640, 8640, 1080, 8640, 1080, 540, 8640, 540, 8640, 8640, 540, 540, 540]
Prompts retrieved: 1313280 . Total input tokens: 292726781 . Total output tokens: 262474905
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 74.7434558160603,
    "estimated_duration": 3600.1860041781656,
    "input_throughput": 5294.130352676291,
    "output_throughput": 4681.367290590118,
    "total_throughput": 9975.497643266408,
    "itl": 182.5079669917027,
    "ttft": 1990203.3893825386,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 721,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2526633530948117,
    "arrivals": 438250,
    "finished_requests": 77234,
    "scheduler_time": 135.43127594039805
}
#Debug simulation 
Total elapsed time: 74.74359729886055. Arrivals time: 0.36245029186829925 Scheduler time: 74.24320621462539 Scheduler overhead time: 0.050097372848540545 Adapter cache time: 0.020400465466082096 Engine time: 0.04924904182553291 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-16-32/adapters_384_slots_96_rate_0.8-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-16-32/adapters_384_slots_96_rate_0.8-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 8640, 1080, 540, 8640, 8640, 540, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 540, 8640, 540, 8640, 1080, 1080, 1080, 540, 540, 1080, 540, 8640, 540, 8640, 1080, 8640, 1080, 540, 1080, 8640, 1080, 8640, 540, 8640, 8640, 8640, 8640, 540, 1080, 1080, 1080, 8640, 1080, 540, 1080, 540, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 540, 540, 8640, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 8640, 540, 1080, 8640, 540, 8640, 1080, 540, 8640, 8640, 8640, 8640, 1080, 540, 1080, 8640, 8640, 1080, 540, 540, 8640, 1080, 1080, 540, 540, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 540, 1080, 1080, 1080, 1080, 540, 540, 8640, 540, 8640, 540, 540, 540, 1080, 1080, 8640, 540, 540, 8640, 540, 8640, 1080, 540, 8640, 1080, 1080, 540, 8640, 8640, 8640, 540, 1080, 8640, 540, 8640, 1080, 1080, 8640, 8640, 540, 1080, 8640, 540, 1080, 1080, 540, 1080, 540, 1080, 8640, 8640, 1080, 540, 8640, 540, 8640, 1080, 1080, 1080, 1080, 1080, 540, 540, 8640, 540, 8640, 540, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 8640, 8640, 540, 540, 8640, 540, 540, 540, 1080, 540, 1080, 8640, 8640, 1080, 1080, 540, 8640, 1080, 8640, 540, 1080, 1080, 540, 540, 1080, 540, 8640, 8640, 540, 8640, 8640, 540, 1080, 8640, 540, 540, 1080, 1080, 540, 540, 8640, 8640, 8640, 8640, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 8640, 1080, 1080, 1080, 8640, 540, 1080, 1080, 8640, 8640, 540, 8640, 8640, 540, 8640, 540, 540, 1080, 540, 8640, 8640, 8640, 1080, 540, 8640, 8640, 1080, 1080, 8640, 8640, 540, 8640, 8640, 1080, 540, 8640, 1080, 1080, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 540, 8640, 540, 1080, 8640, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 8640, 540, 540, 540, 1080, 540, 1080, 1080, 540, 8640, 1080, 8640, 540, 8640, 540, 1080, 1080, 1080, 1080, 540, 1080, 8640, 8640, 540, 8640, 8640, 540, 8640, 1080, 8640, 1080, 1080, 1080, 540, 1080, 540, 540, 8640, 540, 1080, 540, 540, 1080, 8640, 1080, 8640, 540, 8640, 8640, 1080, 8640, 1080, 540, 8640, 540, 8640, 8640, 540, 540, 540]
Prompts retrieved: 1313280 . Total input tokens: 292726781 . Total output tokens: 262474905
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 72.66240637796,
    "estimated_duration": 3600.004953487364,
    "input_throughput": 5285.911893417286,
    "output_throughput": 4664.872747947718,
    "total_throughput": 9950.784641365004,
    "itl": 179.9700900351584,
    "ttft": 1993036.716796595,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 744,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4641429837234345,
    "arrivals": 438250,
    "finished_requests": 77028,
    "scheduler_time": 136.21718827803173
}
#Debug simulation 
Total elapsed time: 72.6625466500409. Arrivals time: 0.3640254591591656 Scheduler time: 72.15950569976121 Scheduler overhead time: 0.05069402977824211 Adapter cache time: 0.020679425448179245 Engine time: 0.04915013490244746 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_16-16-16/adapters_384_slots_96_rate_0.8-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_16-16-16/adapters_384_slots_96_rate_0.8-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 8640, 1080, 540, 8640, 8640, 540, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 540, 8640, 540, 8640, 1080, 1080, 1080, 540, 540, 1080, 540, 8640, 540, 8640, 1080, 8640, 1080, 540, 1080, 8640, 1080, 8640, 540, 8640, 8640, 8640, 8640, 540, 1080, 1080, 1080, 8640, 1080, 540, 1080, 540, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 540, 540, 8640, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 8640, 540, 1080, 8640, 540, 8640, 1080, 540, 8640, 8640, 8640, 8640, 1080, 540, 1080, 8640, 8640, 1080, 540, 540, 8640, 1080, 1080, 540, 540, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 540, 1080, 1080, 1080, 1080, 540, 540, 8640, 540, 8640, 540, 540, 540, 1080, 1080, 8640, 540, 540, 8640, 540, 8640, 1080, 540, 8640, 1080, 1080, 540, 8640, 8640, 8640, 540, 1080, 8640, 540, 8640, 1080, 1080, 8640, 8640, 540, 1080, 8640, 540, 1080, 1080, 540, 1080, 540, 1080, 8640, 8640, 1080, 540, 8640, 540, 8640, 1080, 1080, 1080, 1080, 1080, 540, 540, 8640, 540, 8640, 540, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 8640, 8640, 540, 540, 8640, 540, 540, 540, 1080, 540, 1080, 8640, 8640, 1080, 1080, 540, 8640, 1080, 8640, 540, 1080, 1080, 540, 540, 1080, 540, 8640, 8640, 540, 8640, 8640, 540, 1080, 8640, 540, 540, 1080, 1080, 540, 540, 8640, 8640, 8640, 8640, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 8640, 1080, 1080, 1080, 8640, 540, 1080, 1080, 8640, 8640, 540, 8640, 8640, 540, 8640, 540, 540, 1080, 540, 8640, 8640, 8640, 1080, 540, 8640, 8640, 1080, 1080, 8640, 8640, 540, 8640, 8640, 1080, 540, 8640, 1080, 1080, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 540, 8640, 540, 1080, 8640, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 8640, 540, 540, 540, 1080, 540, 1080, 1080, 540, 8640, 1080, 8640, 540, 8640, 540, 1080, 1080, 1080, 1080, 540, 1080, 8640, 8640, 540, 8640, 8640, 540, 8640, 1080, 8640, 1080, 1080, 1080, 540, 1080, 540, 540, 8640, 540, 1080, 540, 540, 1080, 8640, 1080, 8640, 540, 8640, 8640, 1080, 8640, 1080, 540, 8640, 540, 8640, 8640, 540, 540, 540]
Prompts retrieved: 1313280 . Total input tokens: 292726781 . Total output tokens: 262474905
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 75.29136049328372,
    "estimated_duration": 3600.1787669350238,
    "input_throughput": 5294.9540103612435,
    "output_throughput": 4682.988565690934,
    "total_throughput": 9977.942576052177,
    "itl": 182.5737340189129,
    "ttft": 1990074.5564720272,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 721,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.155826262624429,
    "arrivals": 438250,
    "finished_requests": 77257,
    "scheduler_time": 135.406277910181
}
#Debug simulation 
Total elapsed time: 75.29150286596268. Arrivals time: 0.36833328381180763 Scheduler time: 74.7831311239861 Scheduler overhead time: 0.05094825802370906 Adapter cache time: 0.02008154895156622 Engine time: 0.050233786925673485 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_16-16-32/adapters_384_slots_96_rate_0.8-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_16-16-32/adapters_384_slots_96_rate_0.8-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 8640, 1080, 540, 8640, 8640, 540, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 540, 8640, 540, 8640, 1080, 1080, 1080, 540, 540, 1080, 540, 8640, 540, 8640, 1080, 8640, 1080, 540, 1080, 8640, 1080, 8640, 540, 8640, 8640, 8640, 8640, 540, 1080, 1080, 1080, 8640, 1080, 540, 1080, 540, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 540, 540, 8640, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 8640, 540, 1080, 8640, 540, 8640, 1080, 540, 8640, 8640, 8640, 8640, 1080, 540, 1080, 8640, 8640, 1080, 540, 540, 8640, 1080, 1080, 540, 540, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 540, 1080, 1080, 1080, 1080, 540, 540, 8640, 540, 8640, 540, 540, 540, 1080, 1080, 8640, 540, 540, 8640, 540, 8640, 1080, 540, 8640, 1080, 1080, 540, 8640, 8640, 8640, 540, 1080, 8640, 540, 8640, 1080, 1080, 8640, 8640, 540, 1080, 8640, 540, 1080, 1080, 540, 1080, 540, 1080, 8640, 8640, 1080, 540, 8640, 540, 8640, 1080, 1080, 1080, 1080, 1080, 540, 540, 8640, 540, 8640, 540, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 8640, 8640, 540, 540, 8640, 540, 540, 540, 1080, 540, 1080, 8640, 8640, 1080, 1080, 540, 8640, 1080, 8640, 540, 1080, 1080, 540, 540, 1080, 540, 8640, 8640, 540, 8640, 8640, 540, 1080, 8640, 540, 540, 1080, 1080, 540, 540, 8640, 8640, 8640, 8640, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 8640, 1080, 1080, 1080, 8640, 540, 1080, 1080, 8640, 8640, 540, 8640, 8640, 540, 8640, 540, 540, 1080, 540, 8640, 8640, 8640, 1080, 540, 8640, 8640, 1080, 1080, 8640, 8640, 540, 8640, 8640, 1080, 540, 8640, 1080, 1080, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 540, 8640, 540, 1080, 8640, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 8640, 540, 540, 540, 1080, 540, 1080, 1080, 540, 8640, 1080, 8640, 540, 8640, 540, 1080, 1080, 1080, 1080, 540, 1080, 8640, 8640, 540, 8640, 8640, 540, 8640, 1080, 8640, 1080, 1080, 1080, 540, 1080, 540, 540, 8640, 540, 1080, 540, 540, 1080, 8640, 1080, 8640, 540, 8640, 8640, 1080, 8640, 1080, 540, 8640, 540, 8640, 8640, 540, 540, 540]
Prompts retrieved: 1313280 . Total input tokens: 292726781 . Total output tokens: 262474905
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 71.79136485606432,
    "estimated_duration": 3600.0174258913985,
    "input_throughput": 5281.365546527098,
    "output_throughput": 4662.9854842559325,
    "total_throughput": 9944.351030783031,
    "itl": 180.1168695716175,
    "ttft": 1992699.068147363,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 765,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.564885573871447,
    "arrivals": 438250,
    "finished_requests": 76982,
    "scheduler_time": 136.18909923772182
}
#Debug simulation 
Total elapsed time: 71.79150951793417. Arrivals time: 0.3584448453038931 Scheduler time: 71.29564875690266 Scheduler overhead time: 0.04958135029301047 Adapter cache time: 0.020914715714752674 Engine time: 0.04888210352510214 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-8/adapters_384_slots_96_rate_0.8-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-8/adapters_384_slots_96_rate_0.8-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 8640, 1080, 270, 8640, 8640, 270, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 270, 8640, 270, 8640, 1080, 1080, 1080, 270, 270, 1080, 270, 8640, 270, 8640, 1080, 8640, 1080, 270, 1080, 8640, 1080, 8640, 270, 8640, 8640, 8640, 8640, 270, 1080, 1080, 1080, 8640, 1080, 270, 1080, 270, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 270, 270, 8640, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 8640, 270, 1080, 8640, 270, 8640, 1080, 270, 8640, 8640, 8640, 8640, 1080, 270, 1080, 8640, 8640, 1080, 270, 270, 8640, 1080, 1080, 270, 270, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 270, 1080, 1080, 1080, 1080, 270, 270, 8640, 270, 8640, 270, 270, 270, 1080, 1080, 8640, 270, 270, 8640, 270, 8640, 1080, 270, 8640, 1080, 1080, 270, 8640, 8640, 8640, 270, 1080, 8640, 270, 8640, 1080, 1080, 8640, 8640, 270, 1080, 8640, 270, 1080, 1080, 270, 1080, 270, 1080, 8640, 8640, 1080, 270, 8640, 270, 8640, 1080, 1080, 1080, 1080, 1080, 270, 270, 8640, 270, 8640, 270, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 8640, 8640, 270, 270, 8640, 270, 270, 270, 1080, 270, 1080, 8640, 8640, 1080, 1080, 270, 8640, 1080, 8640, 270, 1080, 1080, 270, 270, 1080, 270, 8640, 8640, 270, 8640, 8640, 270, 1080, 8640, 270, 270, 1080, 1080, 270, 270, 8640, 8640, 8640, 8640, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 8640, 1080, 1080, 1080, 8640, 270, 1080, 1080, 8640, 8640, 270, 8640, 8640, 270, 8640, 270, 270, 1080, 270, 8640, 8640, 8640, 1080, 270, 8640, 8640, 1080, 1080, 8640, 8640, 270, 8640, 8640, 1080, 270, 8640, 1080, 1080, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 270, 8640, 270, 1080, 8640, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 8640, 270, 270, 270, 1080, 270, 1080, 1080, 270, 8640, 1080, 8640, 270, 8640, 270, 1080, 1080, 1080, 1080, 270, 1080, 8640, 8640, 270, 8640, 8640, 270, 8640, 1080, 8640, 1080, 1080, 1080, 270, 1080, 270, 270, 8640, 270, 1080, 270, 270, 1080, 8640, 1080, 8640, 270, 8640, 8640, 1080, 8640, 1080, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1278720 . Total input tokens: 285054963 . Total output tokens: 255557927
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 72.67435647686943,
    "estimated_duration": 3600.1533266212896,
    "input_throughput": 5300.568967130377,
    "output_throughput": 4681.4183927597205,
    "total_throughput": 9981.987359890098,
    "itl": 182.54962375273402,
    "ttft": 1986736.2253171506,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 583,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7842643547128214,
    "arrivals": 426621,
    "finished_requests": 77096,
    "scheduler_time": 135.46786447523056
}
#Debug simulation 
Total elapsed time: 72.67451953375712. Arrivals time: 0.37669876171275973 Scheduler time: 72.16263301717117 Scheduler overhead time: 0.04909540433436632 Adapter cache time: 0.018152488861232996 Engine time: 0.049521473702043295 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-16/adapters_384_slots_96_rate_0.8-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-16/adapters_384_slots_96_rate_0.8-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 8640, 1080, 270, 8640, 8640, 270, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 270, 8640, 270, 8640, 1080, 1080, 1080, 270, 270, 1080, 270, 8640, 270, 8640, 1080, 8640, 1080, 270, 1080, 8640, 1080, 8640, 270, 8640, 8640, 8640, 8640, 270, 1080, 1080, 1080, 8640, 1080, 270, 1080, 270, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 270, 270, 8640, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 8640, 270, 1080, 8640, 270, 8640, 1080, 270, 8640, 8640, 8640, 8640, 1080, 270, 1080, 8640, 8640, 1080, 270, 270, 8640, 1080, 1080, 270, 270, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 270, 1080, 1080, 1080, 1080, 270, 270, 8640, 270, 8640, 270, 270, 270, 1080, 1080, 8640, 270, 270, 8640, 270, 8640, 1080, 270, 8640, 1080, 1080, 270, 8640, 8640, 8640, 270, 1080, 8640, 270, 8640, 1080, 1080, 8640, 8640, 270, 1080, 8640, 270, 1080, 1080, 270, 1080, 270, 1080, 8640, 8640, 1080, 270, 8640, 270, 8640, 1080, 1080, 1080, 1080, 1080, 270, 270, 8640, 270, 8640, 270, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 8640, 8640, 270, 270, 8640, 270, 270, 270, 1080, 270, 1080, 8640, 8640, 1080, 1080, 270, 8640, 1080, 8640, 270, 1080, 1080, 270, 270, 1080, 270, 8640, 8640, 270, 8640, 8640, 270, 1080, 8640, 270, 270, 1080, 1080, 270, 270, 8640, 8640, 8640, 8640, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 8640, 1080, 1080, 1080, 8640, 270, 1080, 1080, 8640, 8640, 270, 8640, 8640, 270, 8640, 270, 270, 1080, 270, 8640, 8640, 8640, 1080, 270, 8640, 8640, 1080, 1080, 8640, 8640, 270, 8640, 8640, 1080, 270, 8640, 1080, 1080, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 270, 8640, 270, 1080, 8640, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 8640, 270, 270, 270, 1080, 270, 1080, 1080, 270, 8640, 1080, 8640, 270, 8640, 270, 1080, 1080, 1080, 1080, 270, 1080, 8640, 8640, 270, 8640, 8640, 270, 8640, 1080, 8640, 1080, 1080, 1080, 270, 1080, 270, 270, 8640, 270, 1080, 270, 270, 1080, 8640, 1080, 8640, 270, 8640, 8640, 1080, 8640, 1080, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1278720 . Total input tokens: 285054963 . Total output tokens: 255557927
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 72.50418779999018,
    "estimated_duration": 3600.000713740628,
    "input_throughput": 5298.988671637916,
    "output_throughput": 4681.114071916307,
    "total_throughput": 9980.102743554224,
    "itl": 182.56055250673245,
    "ttft": 1986424.7679123033,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 589,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9213089885260028,
    "arrivals": 426621,
    "finished_requests": 77074,
    "scheduler_time": 135.4568851690209
}
#Debug simulation 
Total elapsed time: 72.50433915480971. Arrivals time: 0.35881544509902596 Scheduler time: 72.0094025558792 Scheduler overhead time: 0.05015807645395398 Adapter cache time: 0.018257244490087032 Engine time: 0.04937456734478474 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-32/adapters_384_slots_96_rate_0.8-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-32/adapters_384_slots_96_rate_0.8-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 8640, 1080, 270, 8640, 8640, 270, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 270, 8640, 270, 8640, 1080, 1080, 1080, 270, 270, 1080, 270, 8640, 270, 8640, 1080, 8640, 1080, 270, 1080, 8640, 1080, 8640, 270, 8640, 8640, 8640, 8640, 270, 1080, 1080, 1080, 8640, 1080, 270, 1080, 270, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 270, 270, 8640, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 8640, 270, 1080, 8640, 270, 8640, 1080, 270, 8640, 8640, 8640, 8640, 1080, 270, 1080, 8640, 8640, 1080, 270, 270, 8640, 1080, 1080, 270, 270, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 270, 1080, 1080, 1080, 1080, 270, 270, 8640, 270, 8640, 270, 270, 270, 1080, 1080, 8640, 270, 270, 8640, 270, 8640, 1080, 270, 8640, 1080, 1080, 270, 8640, 8640, 8640, 270, 1080, 8640, 270, 8640, 1080, 1080, 8640, 8640, 270, 1080, 8640, 270, 1080, 1080, 270, 1080, 270, 1080, 8640, 8640, 1080, 270, 8640, 270, 8640, 1080, 1080, 1080, 1080, 1080, 270, 270, 8640, 270, 8640, 270, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 8640, 8640, 270, 270, 8640, 270, 270, 270, 1080, 270, 1080, 8640, 8640, 1080, 1080, 270, 8640, 1080, 8640, 270, 1080, 1080, 270, 270, 1080, 270, 8640, 8640, 270, 8640, 8640, 270, 1080, 8640, 270, 270, 1080, 1080, 270, 270, 8640, 8640, 8640, 8640, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 8640, 1080, 1080, 1080, 8640, 270, 1080, 1080, 8640, 8640, 270, 8640, 8640, 270, 8640, 270, 270, 1080, 270, 8640, 8640, 8640, 1080, 270, 8640, 8640, 1080, 1080, 8640, 8640, 270, 8640, 8640, 1080, 270, 8640, 1080, 1080, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 270, 8640, 270, 1080, 8640, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 8640, 270, 270, 270, 1080, 270, 1080, 1080, 270, 8640, 1080, 8640, 270, 8640, 270, 1080, 1080, 1080, 1080, 270, 1080, 8640, 8640, 270, 8640, 8640, 270, 8640, 1080, 8640, 1080, 1080, 1080, 270, 1080, 270, 270, 8640, 270, 1080, 270, 270, 1080, 8640, 1080, 8640, 270, 8640, 8640, 1080, 8640, 1080, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1278720 . Total input tokens: 285054963 . Total output tokens: 255557927
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 61.0876985732466,
    "estimated_duration": 3600.061435271686,
    "input_throughput": 5289.604731026732,
    "output_throughput": 4681.0476162688665,
    "total_throughput": 9970.6523472956,
    "itl": 181.5436358888147,
    "ttft": 1985713.2794010346,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 749,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4485566124878764,
    "arrivals": 426621,
    "finished_requests": 76989,
    "scheduler_time": 135.55590783204568
}
#Debug simulation 
Total elapsed time: 61.08784768823534. Arrivals time: 0.3586546154692769 Scheduler time: 60.592516283039004 Scheduler overhead time: 0.048627526499331 Adapter cache time: 0.021084962878376245 Engine time: 0.04869268508628011 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-16-16/adapters_384_slots_96_rate_0.8-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-16-16/adapters_384_slots_96_rate_0.8-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 8640, 1080, 270, 8640, 8640, 270, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 270, 8640, 270, 8640, 1080, 1080, 1080, 270, 270, 1080, 270, 8640, 270, 8640, 1080, 8640, 1080, 270, 1080, 8640, 1080, 8640, 270, 8640, 8640, 8640, 8640, 270, 1080, 1080, 1080, 8640, 1080, 270, 1080, 270, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 270, 270, 8640, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 8640, 270, 1080, 8640, 270, 8640, 1080, 270, 8640, 8640, 8640, 8640, 1080, 270, 1080, 8640, 8640, 1080, 270, 270, 8640, 1080, 1080, 270, 270, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 270, 1080, 1080, 1080, 1080, 270, 270, 8640, 270, 8640, 270, 270, 270, 1080, 1080, 8640, 270, 270, 8640, 270, 8640, 1080, 270, 8640, 1080, 1080, 270, 8640, 8640, 8640, 270, 1080, 8640, 270, 8640, 1080, 1080, 8640, 8640, 270, 1080, 8640, 270, 1080, 1080, 270, 1080, 270, 1080, 8640, 8640, 1080, 270, 8640, 270, 8640, 1080, 1080, 1080, 1080, 1080, 270, 270, 8640, 270, 8640, 270, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 8640, 8640, 270, 270, 8640, 270, 270, 270, 1080, 270, 1080, 8640, 8640, 1080, 1080, 270, 8640, 1080, 8640, 270, 1080, 1080, 270, 270, 1080, 270, 8640, 8640, 270, 8640, 8640, 270, 1080, 8640, 270, 270, 1080, 1080, 270, 270, 8640, 8640, 8640, 8640, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 8640, 1080, 1080, 1080, 8640, 270, 1080, 1080, 8640, 8640, 270, 8640, 8640, 270, 8640, 270, 270, 1080, 270, 8640, 8640, 8640, 1080, 270, 8640, 8640, 1080, 1080, 8640, 8640, 270, 8640, 8640, 1080, 270, 8640, 1080, 1080, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 270, 8640, 270, 1080, 8640, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 8640, 270, 270, 270, 1080, 270, 1080, 1080, 270, 8640, 1080, 8640, 270, 8640, 270, 1080, 1080, 1080, 1080, 270, 1080, 8640, 8640, 270, 8640, 8640, 270, 8640, 1080, 8640, 1080, 1080, 1080, 270, 1080, 270, 270, 8640, 270, 1080, 270, 270, 1080, 8640, 1080, 8640, 270, 8640, 8640, 1080, 8640, 1080, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1278720 . Total input tokens: 285054963 . Total output tokens: 255557927
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 72.7855916772969,
    "estimated_duration": 3600.120312178567,
    "input_throughput": 5299.1026259496175,
    "output_throughput": 4681.11216811026,
    "total_throughput": 9980.214794059877,
    "itl": 182.55602001576014,
    "ttft": 1986444.0554828155,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 589,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8404071154747976,
    "arrivals": 426621,
    "finished_requests": 77077,
    "scheduler_time": 135.46382181802048
}
#Debug simulation 
Total elapsed time: 72.78573733195662. Arrivals time: 0.3806810388341546 Scheduler time: 72.26896301517263 Scheduler overhead time: 0.04952692752704024 Adapter cache time: 0.01818040106445551 Engine time: 0.049522174056619406 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-16-32/adapters_384_slots_96_rate_0.8-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-16-32/adapters_384_slots_96_rate_0.8-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 8640, 1080, 270, 8640, 8640, 270, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 270, 8640, 270, 8640, 1080, 1080, 1080, 270, 270, 1080, 270, 8640, 270, 8640, 1080, 8640, 1080, 270, 1080, 8640, 1080, 8640, 270, 8640, 8640, 8640, 8640, 270, 1080, 1080, 1080, 8640, 1080, 270, 1080, 270, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 270, 270, 8640, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 8640, 270, 1080, 8640, 270, 8640, 1080, 270, 8640, 8640, 8640, 8640, 1080, 270, 1080, 8640, 8640, 1080, 270, 270, 8640, 1080, 1080, 270, 270, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 270, 1080, 1080, 1080, 1080, 270, 270, 8640, 270, 8640, 270, 270, 270, 1080, 1080, 8640, 270, 270, 8640, 270, 8640, 1080, 270, 8640, 1080, 1080, 270, 8640, 8640, 8640, 270, 1080, 8640, 270, 8640, 1080, 1080, 8640, 8640, 270, 1080, 8640, 270, 1080, 1080, 270, 1080, 270, 1080, 8640, 8640, 1080, 270, 8640, 270, 8640, 1080, 1080, 1080, 1080, 1080, 270, 270, 8640, 270, 8640, 270, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 8640, 8640, 270, 270, 8640, 270, 270, 270, 1080, 270, 1080, 8640, 8640, 1080, 1080, 270, 8640, 1080, 8640, 270, 1080, 1080, 270, 270, 1080, 270, 8640, 8640, 270, 8640, 8640, 270, 1080, 8640, 270, 270, 1080, 1080, 270, 270, 8640, 8640, 8640, 8640, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 8640, 1080, 1080, 1080, 8640, 270, 1080, 1080, 8640, 8640, 270, 8640, 8640, 270, 8640, 270, 270, 1080, 270, 8640, 8640, 8640, 1080, 270, 8640, 8640, 1080, 1080, 8640, 8640, 270, 8640, 8640, 1080, 270, 8640, 1080, 1080, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 270, 8640, 270, 1080, 8640, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 8640, 270, 270, 270, 1080, 270, 1080, 1080, 270, 8640, 1080, 8640, 270, 8640, 270, 1080, 1080, 1080, 1080, 270, 1080, 8640, 8640, 270, 8640, 8640, 270, 8640, 1080, 8640, 1080, 1080, 1080, 270, 1080, 270, 270, 8640, 270, 1080, 270, 270, 1080, 8640, 1080, 8640, 270, 8640, 8640, 1080, 8640, 1080, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1278720 . Total input tokens: 285054963 . Total output tokens: 255557927
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 60.72902886336669,
    "estimated_duration": 3600.097108511839,
    "input_throughput": 5289.552316512847,
    "output_throughput": 4681.001231926792,
    "total_throughput": 9970.553548439639,
    "itl": 181.54398694894397,
    "ttft": 1985724.5048477417,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 749,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.479995059091599,
    "arrivals": 426621,
    "finished_requests": 76989,
    "scheduler_time": 135.5564537818004
}
#Debug simulation 
Total elapsed time: 60.72916850214824. Arrivals time: 0.3619035487063229 Scheduler time: 60.230470372363925 Scheduler overhead time: 0.0493599777109921 Adapter cache time: 0.020466748625040054 Engine time: 0.0487256795167923 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_16-16-16/adapters_384_slots_96_rate_0.8-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_16-16-16/adapters_384_slots_96_rate_0.8-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 8640, 1080, 270, 8640, 8640, 270, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 270, 8640, 270, 8640, 1080, 1080, 1080, 270, 270, 1080, 270, 8640, 270, 8640, 1080, 8640, 1080, 270, 1080, 8640, 1080, 8640, 270, 8640, 8640, 8640, 8640, 270, 1080, 1080, 1080, 8640, 1080, 270, 1080, 270, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 270, 270, 8640, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 8640, 270, 1080, 8640, 270, 8640, 1080, 270, 8640, 8640, 8640, 8640, 1080, 270, 1080, 8640, 8640, 1080, 270, 270, 8640, 1080, 1080, 270, 270, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 270, 1080, 1080, 1080, 1080, 270, 270, 8640, 270, 8640, 270, 270, 270, 1080, 1080, 8640, 270, 270, 8640, 270, 8640, 1080, 270, 8640, 1080, 1080, 270, 8640, 8640, 8640, 270, 1080, 8640, 270, 8640, 1080, 1080, 8640, 8640, 270, 1080, 8640, 270, 1080, 1080, 270, 1080, 270, 1080, 8640, 8640, 1080, 270, 8640, 270, 8640, 1080, 1080, 1080, 1080, 1080, 270, 270, 8640, 270, 8640, 270, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 8640, 8640, 270, 270, 8640, 270, 270, 270, 1080, 270, 1080, 8640, 8640, 1080, 1080, 270, 8640, 1080, 8640, 270, 1080, 1080, 270, 270, 1080, 270, 8640, 8640, 270, 8640, 8640, 270, 1080, 8640, 270, 270, 1080, 1080, 270, 270, 8640, 8640, 8640, 8640, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 8640, 1080, 1080, 1080, 8640, 270, 1080, 1080, 8640, 8640, 270, 8640, 8640, 270, 8640, 270, 270, 1080, 270, 8640, 8640, 8640, 1080, 270, 8640, 8640, 1080, 1080, 8640, 8640, 270, 8640, 8640, 1080, 270, 8640, 1080, 1080, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 270, 8640, 270, 1080, 8640, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 8640, 270, 270, 270, 1080, 270, 1080, 1080, 270, 8640, 1080, 8640, 270, 8640, 270, 1080, 1080, 1080, 1080, 270, 1080, 8640, 8640, 270, 8640, 8640, 270, 8640, 1080, 8640, 1080, 1080, 1080, 270, 1080, 270, 270, 8640, 270, 1080, 270, 270, 1080, 8640, 1080, 8640, 270, 8640, 8640, 1080, 8640, 1080, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1278720 . Total input tokens: 285054963 . Total output tokens: 255557927
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 72.83343995688483,
    "estimated_duration": 3600.059036396367,
    "input_throughput": 5299.244764357124,
    "output_throughput": 4681.341286244527,
    "total_throughput": 9980.58605060165,
    "itl": 182.54845017250986,
    "ttft": 1986429.956858214,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 589,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7611396236973558,
    "arrivals": 426621,
    "finished_requests": 77078,
    "scheduler_time": 135.46474722739248
}
#Debug simulation 
Total elapsed time: 72.83357503684238. Arrivals time: 0.3589209537021816 Scheduler time: 72.33927074773237 Scheduler overhead time: 0.05017757974565029 Adapter cache time: 0.01809179363772273 Engine time: 0.04924349579960108 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_16-16-32/adapters_384_slots_96_rate_0.8-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_16-16-32/adapters_384_slots_96_rate_0.8-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 8640, 1080, 270, 8640, 8640, 270, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 270, 8640, 270, 8640, 1080, 1080, 1080, 270, 270, 1080, 270, 8640, 270, 8640, 1080, 8640, 1080, 270, 1080, 8640, 1080, 8640, 270, 8640, 8640, 8640, 8640, 270, 1080, 1080, 1080, 8640, 1080, 270, 1080, 270, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 270, 270, 8640, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 8640, 270, 1080, 8640, 270, 8640, 1080, 270, 8640, 8640, 8640, 8640, 1080, 270, 1080, 8640, 8640, 1080, 270, 270, 8640, 1080, 1080, 270, 270, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 270, 1080, 1080, 1080, 1080, 270, 270, 8640, 270, 8640, 270, 270, 270, 1080, 1080, 8640, 270, 270, 8640, 270, 8640, 1080, 270, 8640, 1080, 1080, 270, 8640, 8640, 8640, 270, 1080, 8640, 270, 8640, 1080, 1080, 8640, 8640, 270, 1080, 8640, 270, 1080, 1080, 270, 1080, 270, 1080, 8640, 8640, 1080, 270, 8640, 270, 8640, 1080, 1080, 1080, 1080, 1080, 270, 270, 8640, 270, 8640, 270, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 8640, 8640, 270, 270, 8640, 270, 270, 270, 1080, 270, 1080, 8640, 8640, 1080, 1080, 270, 8640, 1080, 8640, 270, 1080, 1080, 270, 270, 1080, 270, 8640, 8640, 270, 8640, 8640, 270, 1080, 8640, 270, 270, 1080, 1080, 270, 270, 8640, 8640, 8640, 8640, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 8640, 1080, 1080, 1080, 8640, 270, 1080, 1080, 8640, 8640, 270, 8640, 8640, 270, 8640, 270, 270, 1080, 270, 8640, 8640, 8640, 1080, 270, 8640, 8640, 1080, 1080, 8640, 8640, 270, 8640, 8640, 1080, 270, 8640, 1080, 1080, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 270, 8640, 270, 1080, 8640, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 8640, 270, 270, 270, 1080, 270, 1080, 1080, 270, 8640, 1080, 8640, 270, 8640, 270, 1080, 1080, 1080, 1080, 270, 1080, 8640, 8640, 270, 8640, 8640, 270, 8640, 1080, 8640, 1080, 1080, 1080, 270, 1080, 270, 270, 8640, 270, 1080, 270, 270, 1080, 8640, 1080, 8640, 270, 8640, 8640, 1080, 8640, 1080, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1278720 . Total input tokens: 285054963 . Total output tokens: 255557927
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 66.84333386085927,
    "estimated_duration": 3600.0266253897234,
    "input_throughput": 5181.503900122029,
    "output_throughput": 4592.104925949082,
    "total_throughput": 9773.608826071111,
    "itl": 170.38519626613882,
    "ttft": 1973933.5277621981,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 615,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.061131615899501,
    "arrivals": 426621,
    "finished_requests": 75478,
    "scheduler_time": 139.67517334477643
}
#Debug simulation 
Total elapsed time: 66.84346495382488. Arrivals time: 0.3681279383599758 Scheduler time: 66.33596178609878 Scheduler overhead time: 0.051278188824653625 Adapter cache time: 0.019061760511249304 Engine time: 0.05014797253534198 
