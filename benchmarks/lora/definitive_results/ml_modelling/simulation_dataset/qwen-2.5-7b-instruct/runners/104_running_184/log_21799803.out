INFO 06-01 00:47:08 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:47:09 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-16/adapters_192_slots_32_rate_0.4-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-16/adapters_192_slots_32_rate_0.4-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 540, 540, 540, 540, 4320, 540, 33, 4320, 33, 540, 540, 33, 4320, 4320, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 4320, 540, 33, 540, 4320, 4320, 540, 4320, 33, 540, 540, 4320, 540, 33, 33, 540, 4320, 33, 540, 33, 4320, 4320, 540, 4320, 4320, 4320, 33, 540, 4320, 33, 540, 33, 540, 33, 33, 540, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 540, 33, 33, 33, 33, 33, 4320, 33, 540, 33, 4320, 4320, 33, 4320, 33, 540, 540, 4320, 33, 33, 33, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 33, 4320, 540, 540, 540, 4320, 540, 33, 540, 4320, 4320, 540, 4320, 540, 33, 4320, 540, 33, 540, 540, 33, 540, 4320, 33, 540, 4320, 33, 540, 4320, 4320, 540, 33, 4320, 540, 33, 33, 540, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 540, 33, 4320, 4320, 540, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 540, 540, 540, 540, 540, 540, 33, 4320, 540, 4320, 33, 4320, 540, 33, 540, 33, 33, 540, 540, 540, 4320, 540, 33, 33]
Prompts retrieved: 313152 . Total input tokens: 69892023 . Total output tokens: 62596468
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 55.29238943802193,
    "estimated_duration": 3600.0480032820633,
    "input_throughput": 6577.210353421171,
    "output_throughput": 5784.9467509914975,
    "total_throughput": 12362.157104412669,
    "itl": 93.48253503735506,
    "ttft": 546733.3269832287,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 823,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.46081139270444,
    "arrivals": 104293,
    "finished_requests": 95122,
    "scheduler_time": 130.49511563109297
}
#Debug simulation 
Total elapsed time: 55.29260154301301. Arrivals time: 0.33292833529412746 Scheduler time: 54.72989020077512 Scheduler overhead time: 0.0890292264521122 Adapter cache time: 0.020514068193733692 Engine time: 0.08536151330918074 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-32/adapters_192_slots_32_rate_0.4-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-32/adapters_192_slots_32_rate_0.4-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 540, 540, 540, 540, 4320, 540, 33, 4320, 33, 540, 540, 33, 4320, 4320, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 4320, 540, 33, 540, 4320, 4320, 540, 4320, 33, 540, 540, 4320, 540, 33, 33, 540, 4320, 33, 540, 33, 4320, 4320, 540, 4320, 4320, 4320, 33, 540, 4320, 33, 540, 33, 540, 33, 33, 540, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 540, 33, 33, 33, 33, 33, 4320, 33, 540, 33, 4320, 4320, 33, 4320, 33, 540, 540, 4320, 33, 33, 33, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 33, 4320, 540, 540, 540, 4320, 540, 33, 540, 4320, 4320, 540, 4320, 540, 33, 4320, 540, 33, 540, 540, 33, 540, 4320, 33, 540, 4320, 33, 540, 4320, 4320, 540, 33, 4320, 540, 33, 33, 540, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 540, 33, 4320, 4320, 540, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 540, 540, 540, 540, 540, 540, 33, 4320, 540, 4320, 33, 4320, 540, 33, 540, 33, 33, 540, 540, 540, 4320, 540, 33, 33]
Prompts retrieved: 313152 . Total input tokens: 69892023 . Total output tokens: 62596468
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 60.863835270982236,
    "estimated_duration": 3600.086729418758,
    "input_throughput": 6545.398144839822,
    "output_throughput": 5722.951569926878,
    "total_throughput": 12268.3497147667,
    "itl": 92.19752331708199,
    "ttft": 580249.1763179083,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 777,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.601407800056055,
    "arrivals": 104293,
    "finished_requests": 94609,
    "scheduler_time": 133.39018976023627
}
#Debug simulation 
Total elapsed time: 60.86402462795377. Arrivals time: 0.34136853041127324 Scheduler time: 60.28930984204635 Scheduler overhead time: 0.08993245242163539 Adapter cache time: 0.021135868970304728 Engine time: 0.08676213584840298 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-8/adapters_192_slots_32_rate_0.4-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-8/adapters_192_slots_32_rate_0.4-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [64 64 64]
Adapter prompts. [4320, 135, 4320, 135, 4320, 135, 4320, 135, 135, 135, 270, 270, 270, 270, 4320, 270, 135, 4320, 135, 270, 270, 135, 4320, 4320, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 4320, 270, 135, 270, 4320, 4320, 270, 4320, 135, 270, 270, 4320, 270, 135, 135, 270, 4320, 135, 270, 135, 4320, 4320, 270, 4320, 4320, 4320, 135, 270, 4320, 135, 270, 135, 270, 135, 135, 270, 4320, 4320, 135, 135, 135, 4320, 4320, 4320, 270, 135, 135, 135, 135, 135, 4320, 135, 270, 135, 4320, 4320, 135, 4320, 135, 270, 270, 4320, 135, 135, 135, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 135, 4320, 270, 270, 270, 4320, 270, 135, 270, 4320, 4320, 270, 4320, 270, 135, 4320, 270, 135, 270, 270, 135, 270, 4320, 135, 270, 4320, 135, 270, 4320, 4320, 270, 135, 4320, 270, 135, 135, 270, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 270, 135, 4320, 4320, 270, 4320, 135, 4320, 4320, 4320, 135, 4320, 4320, 4320, 270, 270, 270, 270, 270, 270, 135, 4320, 270, 4320, 135, 4320, 270, 135, 270, 135, 135, 270, 270, 270, 4320, 270, 135, 135]
Prompts retrieved: 302400 . Total input tokens: 67494451 . Total output tokens: 60433434
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 59.577960167080164,
    "estimated_duration": 3600.0448130945706,
    "input_throughput": 6347.896258645733,
    "output_throughput": 5573.73950652344,
    "total_throughput": 11921.635765169172,
    "itl": 87.84538123904807,
    "ttft": 547741.6145999831,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 834,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.552446778439969,
    "arrivals": 100777,
    "finished_requests": 91732,
    "scheduler_time": 129.5998259132511
}
#Debug simulation 
Total elapsed time: 59.57813001610339. Arrivals time: 0.32775896741077304 Scheduler time: 59.00535658467561 Scheduler overhead time: 0.09573028236627579 Adapter cache time: 0.021838644053786993 Engine time: 0.09076810954138637 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-16/adapters_192_slots_32_rate_0.4-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-16/adapters_192_slots_32_rate_0.4-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [64 64 64]
Adapter prompts. [4320, 135, 4320, 135, 4320, 135, 4320, 135, 135, 135, 270, 270, 270, 270, 4320, 270, 135, 4320, 135, 270, 270, 135, 4320, 4320, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 4320, 270, 135, 270, 4320, 4320, 270, 4320, 135, 270, 270, 4320, 270, 135, 135, 270, 4320, 135, 270, 135, 4320, 4320, 270, 4320, 4320, 4320, 135, 270, 4320, 135, 270, 135, 270, 135, 135, 270, 4320, 4320, 135, 135, 135, 4320, 4320, 4320, 270, 135, 135, 135, 135, 135, 4320, 135, 270, 135, 4320, 4320, 135, 4320, 135, 270, 270, 4320, 135, 135, 135, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 135, 4320, 270, 270, 270, 4320, 270, 135, 270, 4320, 4320, 270, 4320, 270, 135, 4320, 270, 135, 270, 270, 135, 270, 4320, 135, 270, 4320, 135, 270, 4320, 4320, 270, 135, 4320, 270, 135, 135, 270, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 270, 135, 4320, 4320, 270, 4320, 135, 4320, 4320, 4320, 135, 4320, 4320, 4320, 270, 270, 270, 270, 270, 270, 135, 4320, 270, 4320, 135, 4320, 270, 135, 270, 135, 135, 270, 270, 270, 4320, 270, 135, 135]
Prompts retrieved: 302400 . Total input tokens: 67494451 . Total output tokens: 60433434
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 58.67721787421033,
    "estimated_duration": 3600.043652521755,
    "input_throughput": 6372.816336248956,
    "output_throughput": 5599.138217638096,
    "total_throughput": 11971.954553887052,
    "itl": 88.22455146763451,
    "ttft": 531865.2778709228,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 853,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.78341223306256,
    "arrivals": 100777,
    "finished_requests": 92106,
    "scheduler_time": 128.5522116365368
}
#Debug simulation 
Total elapsed time: 58.67738762078807. Arrivals time: 0.32836343348026276 Scheduler time: 58.11081728665158 Scheduler overhead time: 0.092233975417912 Adapter cache time: 0.021338277496397495 Engine time: 0.08854879392310977 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-32/adapters_192_slots_32_rate_0.4-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-32/adapters_192_slots_32_rate_0.4-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [64 64 64]
Adapter prompts. [4320, 135, 4320, 135, 4320, 135, 4320, 135, 135, 135, 270, 270, 270, 270, 4320, 270, 135, 4320, 135, 270, 270, 135, 4320, 4320, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 4320, 270, 135, 270, 4320, 4320, 270, 4320, 135, 270, 270, 4320, 270, 135, 135, 270, 4320, 135, 270, 135, 4320, 4320, 270, 4320, 4320, 4320, 135, 270, 4320, 135, 270, 135, 270, 135, 135, 270, 4320, 4320, 135, 135, 135, 4320, 4320, 4320, 270, 135, 135, 135, 135, 135, 4320, 135, 270, 135, 4320, 4320, 135, 4320, 135, 270, 270, 4320, 135, 135, 135, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 135, 4320, 270, 270, 270, 4320, 270, 135, 270, 4320, 4320, 270, 4320, 270, 135, 4320, 270, 135, 270, 270, 135, 270, 4320, 135, 270, 4320, 135, 270, 4320, 4320, 270, 135, 4320, 270, 135, 135, 270, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 270, 135, 4320, 4320, 270, 4320, 135, 4320, 4320, 4320, 135, 4320, 4320, 4320, 270, 270, 270, 270, 270, 270, 135, 4320, 270, 4320, 135, 4320, 270, 135, 270, 135, 135, 270, 270, 270, 4320, 270, 135, 135]
Prompts retrieved: 302400 . Total input tokens: 67494451 . Total output tokens: 60433434
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 57.162832472939044,
    "estimated_duration": 3600.065686383182,
    "input_throughput": 6393.441121660176,
    "output_throughput": 5597.487311473223,
    "total_throughput": 11990.928433133398,
    "itl": 89.5117045484188,
    "ttft": 534832.1050101359,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 854,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.791396168731135,
    "arrivals": 100777,
    "finished_requests": 92440,
    "scheduler_time": 129.64610587008127
}
#Debug simulation 
Total elapsed time: 57.16299023665488. Arrivals time: 0.3271158328279853 Scheduler time: 56.594996405765414 Scheduler overhead time: 0.09369535883888602 Adapter cache time: 0.021537531167268753 Engine time: 0.08970355009660125 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-16/adapters_192_slots_32_rate_0.4-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-16/adapters_192_slots_32_rate_0.4-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [64 64 64]
Adapter prompts. [4320, 135, 4320, 135, 4320, 135, 4320, 135, 135, 135, 270, 270, 270, 270, 4320, 270, 135, 4320, 135, 270, 270, 135, 4320, 4320, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 4320, 270, 135, 270, 4320, 4320, 270, 4320, 135, 270, 270, 4320, 270, 135, 135, 270, 4320, 135, 270, 135, 4320, 4320, 270, 4320, 4320, 4320, 135, 270, 4320, 135, 270, 135, 270, 135, 135, 270, 4320, 4320, 135, 135, 135, 4320, 4320, 4320, 270, 135, 135, 135, 135, 135, 4320, 135, 270, 135, 4320, 4320, 135, 4320, 135, 270, 270, 4320, 135, 135, 135, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 135, 4320, 270, 270, 270, 4320, 270, 135, 270, 4320, 4320, 270, 4320, 270, 135, 4320, 270, 135, 270, 270, 135, 270, 4320, 135, 270, 4320, 135, 270, 4320, 4320, 270, 135, 4320, 270, 135, 135, 270, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 270, 135, 4320, 4320, 270, 4320, 135, 4320, 4320, 4320, 135, 4320, 4320, 4320, 270, 270, 270, 270, 270, 270, 135, 4320, 270, 4320, 135, 4320, 270, 135, 270, 135, 135, 270, 270, 270, 4320, 270, 135, 135]
Prompts retrieved: 302400 . Total input tokens: 67494451 . Total output tokens: 60433434
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 53.25396038312465,
    "estimated_duration": 3600.105166858459,
    "input_throughput": 6428.931080420839,
    "output_throughput": 5622.48686131113,
    "total_throughput": 12051.41794173197,
    "itl": 90.78142590309915,
    "ttft": 502400.3070700274,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 924,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.889062425887649,
    "arrivals": 100777,
    "finished_requests": 92930,
    "scheduler_time": 126.5937178689564
}
#Debug simulation 
Total elapsed time: 53.25413126125932. Arrivals time: 0.31320941634476185 Scheduler time: 52.707045102491975 Scheduler overhead time: 0.08986993180587888 Adapter cache time: 0.021573735866695642 Engine time: 0.08701472263783216 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-32/adapters_192_slots_32_rate_0.4-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-32/adapters_192_slots_32_rate_0.4-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [64 64 64]
Adapter prompts. [4320, 135, 4320, 135, 4320, 135, 4320, 135, 135, 135, 270, 270, 270, 270, 4320, 270, 135, 4320, 135, 270, 270, 135, 4320, 4320, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 4320, 270, 135, 270, 4320, 4320, 270, 4320, 135, 270, 270, 4320, 270, 135, 135, 270, 4320, 135, 270, 135, 4320, 4320, 270, 4320, 4320, 4320, 135, 270, 4320, 135, 270, 135, 270, 135, 135, 270, 4320, 4320, 135, 135, 135, 4320, 4320, 4320, 270, 135, 135, 135, 135, 135, 4320, 135, 270, 135, 4320, 4320, 135, 4320, 135, 270, 270, 4320, 135, 135, 135, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 135, 4320, 270, 270, 270, 4320, 270, 135, 270, 4320, 4320, 270, 4320, 270, 135, 4320, 270, 135, 270, 270, 135, 270, 4320, 135, 270, 4320, 135, 270, 4320, 4320, 270, 135, 4320, 270, 135, 135, 270, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 270, 135, 4320, 4320, 270, 4320, 135, 4320, 4320, 4320, 135, 4320, 4320, 4320, 270, 270, 270, 270, 270, 270, 135, 4320, 270, 4320, 135, 4320, 270, 135, 270, 135, 135, 270, 270, 270, 4320, 270, 135, 135]
Prompts retrieved: 302400 . Total input tokens: 67494451 . Total output tokens: 60433434
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 60.23675292823464,
    "estimated_duration": 3600.0282749962416,
    "input_throughput": 6325.646706211988,
    "output_throughput": 5566.016005810654,
    "total_throughput": 11891.662712022642,
    "itl": 87.72597252696407,
    "ttft": 561070.3432008062,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 814,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.693028510995212,
    "arrivals": 100777,
    "finished_requests": 91385,
    "scheduler_time": 130.3299587504375
}
#Debug simulation 
Total elapsed time: 60.236910169012845. Arrivals time: 0.3227201192639768 Scheduler time: 59.67128831706941 Scheduler overhead time: 0.09433063212782145 Adapter cache time: 0.02177741238847375 Engine time: 0.08987015904858708 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-16/adapters_192_slots_32_rate_0.4-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-16/adapters_192_slots_32_rate_0.4-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [64 64 64]
Adapter prompts. [4320, 135, 4320, 135, 4320, 135, 4320, 135, 135, 135, 270, 270, 270, 270, 4320, 270, 135, 4320, 135, 270, 270, 135, 4320, 4320, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 4320, 270, 135, 270, 4320, 4320, 270, 4320, 135, 270, 270, 4320, 270, 135, 135, 270, 4320, 135, 270, 135, 4320, 4320, 270, 4320, 4320, 4320, 135, 270, 4320, 135, 270, 135, 270, 135, 135, 270, 4320, 4320, 135, 135, 135, 4320, 4320, 4320, 270, 135, 135, 135, 135, 135, 4320, 135, 270, 135, 4320, 4320, 135, 4320, 135, 270, 270, 4320, 135, 135, 135, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 135, 4320, 270, 270, 270, 4320, 270, 135, 270, 4320, 4320, 270, 4320, 270, 135, 4320, 270, 135, 270, 270, 135, 270, 4320, 135, 270, 4320, 135, 270, 4320, 4320, 270, 135, 4320, 270, 135, 135, 270, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 270, 135, 4320, 4320, 270, 4320, 135, 4320, 4320, 4320, 135, 4320, 4320, 4320, 270, 270, 270, 270, 270, 270, 135, 4320, 270, 4320, 135, 4320, 270, 135, 270, 135, 135, 270, 270, 270, 4320, 270, 135, 135]
Prompts retrieved: 302400 . Total input tokens: 67494451 . Total output tokens: 60433434
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 58.16793318325654,
    "estimated_duration": 3600.0233103125274,
    "input_throughput": 6313.4741197069825,
    "output_throughput": 5555.030419584672,
    "total_throughput": 11868.504539291655,
    "itl": 87.69847496089173,
    "ttft": 555951.0801288333,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 850,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.541542750666796,
    "arrivals": 100777,
    "finished_requests": 91339,
    "scheduler_time": 128.62596763481585
}
#Debug simulation 
Total elapsed time: 58.16819514008239. Arrivals time: 0.3331713546067476 Scheduler time: 57.59314701985568 Scheduler overhead time: 0.093728250823915 Adapter cache time: 0.021464546211063862 Engine time: 0.08977547474205494 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-32/adapters_192_slots_32_rate_0.4-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-32/adapters_192_slots_32_rate_0.4-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [64 64 64]
Adapter prompts. [4320, 135, 4320, 135, 4320, 135, 4320, 135, 135, 135, 270, 270, 270, 270, 4320, 270, 135, 4320, 135, 270, 270, 135, 4320, 4320, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 4320, 270, 135, 270, 4320, 4320, 270, 4320, 135, 270, 270, 4320, 270, 135, 135, 270, 4320, 135, 270, 135, 4320, 4320, 270, 4320, 4320, 4320, 135, 270, 4320, 135, 270, 135, 270, 135, 135, 270, 4320, 4320, 135, 135, 135, 4320, 4320, 4320, 270, 135, 135, 135, 135, 135, 4320, 135, 270, 135, 4320, 4320, 135, 4320, 135, 270, 270, 4320, 135, 135, 135, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 135, 4320, 270, 270, 270, 4320, 270, 135, 270, 4320, 4320, 270, 4320, 270, 135, 4320, 270, 135, 270, 270, 135, 270, 4320, 135, 270, 4320, 135, 270, 4320, 4320, 270, 135, 4320, 270, 135, 135, 270, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 270, 135, 4320, 4320, 270, 4320, 135, 4320, 4320, 4320, 135, 4320, 4320, 4320, 270, 270, 270, 270, 270, 270, 135, 4320, 270, 4320, 135, 4320, 270, 135, 270, 135, 135, 270, 270, 270, 4320, 270, 135, 135]
Prompts retrieved: 302400 . Total input tokens: 67494451 . Total output tokens: 60433434
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 64.56812512781471,
    "estimated_duration": 3600.1130375116986,
    "input_throughput": 6256.652712096073,
    "output_throughput": 5471.221540758634,
    "total_throughput": 11727.874252854706,
    "itl": 85.79938909803293,
    "ttft": 606325.6247029885,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 777,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.60372280646117,
    "arrivals": 100777,
    "finished_requests": 90396,
    "scheduler_time": 132.5409908393804
}
#Debug simulation 
Total elapsed time: 64.56828918587416. Arrivals time: 0.342088935431093 Scheduler time: 63.97550172219053 Scheduler overhead time: 0.0974564328789711 Adapter cache time: 0.022397118620574474 Engine time: 0.09318654565140605 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_192_slots_32_rate_0.4-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_192_slots_32_rate_0.4-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 270, 270, 270, 270, 4320, 270, 66, 4320, 66, 270, 270, 66, 4320, 4320, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 4320, 270, 66, 270, 4320, 4320, 270, 4320, 66, 270, 270, 4320, 270, 66, 66, 270, 4320, 66, 270, 66, 4320, 4320, 270, 4320, 4320, 4320, 66, 270, 4320, 66, 270, 66, 270, 66, 66, 270, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 270, 66, 66, 66, 66, 66, 4320, 66, 270, 66, 4320, 4320, 66, 4320, 66, 270, 270, 4320, 66, 66, 66, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 66, 4320, 270, 270, 270, 4320, 270, 66, 270, 4320, 4320, 270, 4320, 270, 66, 4320, 270, 66, 270, 270, 66, 270, 4320, 66, 270, 4320, 66, 270, 4320, 4320, 270, 66, 4320, 270, 66, 66, 270, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 270, 66, 4320, 4320, 270, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 270, 270, 270, 270, 270, 270, 66, 4320, 270, 4320, 66, 4320, 270, 66, 270, 66, 66, 270, 270, 270, 4320, 270, 66, 66]
Prompts retrieved: 297984 . Total input tokens: 66511279 . Total output tokens: 59553787
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 60.676741044037044,
    "estimated_duration": 3599.977789916814,
    "input_throughput": 6306.37251807173,
    "output_throughput": 5521.411841948976,
    "total_throughput": 11827.784360020707,
    "itl": 85.62833791236126,
    "ttft": 533959.6431323143,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 803,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4575716583780505,
    "arrivals": 99385,
    "finished_requests": 90641,
    "scheduler_time": 127.21964238578978
}
#Debug simulation 
Total elapsed time: 60.67690762504935. Arrivals time: 0.33413515938445926 Scheduler time: 60.092892698943615 Scheduler overhead time: 0.09766115713864565 Adapter cache time: 0.021601181011646986 Engine time: 0.09261118294671178 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_192_slots_32_rate_0.4-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_192_slots_32_rate_0.4-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 270, 270, 270, 270, 4320, 270, 66, 4320, 66, 270, 270, 66, 4320, 4320, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 4320, 270, 66, 270, 4320, 4320, 270, 4320, 66, 270, 270, 4320, 270, 66, 66, 270, 4320, 66, 270, 66, 4320, 4320, 270, 4320, 4320, 4320, 66, 270, 4320, 66, 270, 66, 270, 66, 66, 270, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 270, 66, 66, 66, 66, 66, 4320, 66, 270, 66, 4320, 4320, 66, 4320, 66, 270, 270, 4320, 66, 66, 66, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 66, 4320, 270, 270, 270, 4320, 270, 66, 270, 4320, 4320, 270, 4320, 270, 66, 4320, 270, 66, 270, 270, 66, 270, 4320, 66, 270, 4320, 66, 270, 4320, 4320, 270, 66, 4320, 270, 66, 66, 270, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 270, 66, 4320, 4320, 270, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 270, 270, 270, 270, 270, 270, 66, 4320, 270, 4320, 66, 4320, 270, 66, 270, 66, 66, 270, 270, 270, 4320, 270, 66, 66]
Prompts retrieved: 297984 . Total input tokens: 66511279 . Total output tokens: 59553787
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 62.709368736017495,
    "estimated_duration": 3599.9967922698697,
    "input_throughput": 6252.7983492471285,
    "output_throughput": 5484.946831730337,
    "total_throughput": 11737.745180977467,
    "itl": 84.92883334077052,
    "ttft": 544179.5505276134,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 776,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5331571897515155,
    "arrivals": 99385,
    "finished_requests": 89983,
    "scheduler_time": 127.08775954505187
}
#Debug simulation 
Total elapsed time: 62.70954402722418. Arrivals time: 0.34116475423797965 Scheduler time: 62.11557949287817 Scheduler overhead time: 0.09800518676638603 Adapter cache time: 0.022707441821694374 Engine time: 0.09373838640749454 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-32/adapters_192_slots_32_rate_0.4-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-32/adapters_192_slots_32_rate_0.4-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 270, 270, 270, 270, 4320, 270, 66, 4320, 66, 270, 270, 66, 4320, 4320, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 4320, 270, 66, 270, 4320, 4320, 270, 4320, 66, 270, 270, 4320, 270, 66, 66, 270, 4320, 66, 270, 66, 4320, 4320, 270, 4320, 4320, 4320, 66, 270, 4320, 66, 270, 66, 270, 66, 66, 270, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 270, 66, 66, 66, 66, 66, 4320, 66, 270, 66, 4320, 4320, 66, 4320, 66, 270, 270, 4320, 66, 66, 66, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 66, 4320, 270, 270, 270, 4320, 270, 66, 270, 4320, 4320, 270, 4320, 270, 66, 4320, 270, 66, 270, 270, 66, 270, 4320, 66, 270, 4320, 66, 270, 4320, 4320, 270, 66, 4320, 270, 66, 66, 270, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 270, 66, 4320, 4320, 270, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 270, 270, 270, 270, 270, 270, 66, 4320, 270, 4320, 66, 4320, 270, 66, 270, 66, 66, 270, 270, 270, 4320, 270, 66, 66]
Prompts retrieved: 297984 . Total input tokens: 66511279 . Total output tokens: 59553787
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 54.19201268395409,
    "estimated_duration": 3599.999430126142,
    "input_throughput": 6402.9985135837405,
    "output_throughput": 5605.442553998659,
    "total_throughput": 12008.441067582398,
    "itl": 89.29277542047213,
    "ttft": 483897.14842032996,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 886,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.897557206749893,
    "arrivals": 99385,
    "finished_requests": 92062,
    "scheduler_time": 125.20038757536535
}
#Debug simulation 
Total elapsed time: 54.192179499194026. Arrivals time: 0.3295011571608484 Scheduler time: 53.60859217401594 Scheduler overhead time: 0.10473093809559941 Adapter cache time: 0.02226946037262678 Engine time: 0.09045637398958206 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_192_slots_32_rate_0.4-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_192_slots_32_rate_0.4-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 270, 270, 270, 270, 4320, 270, 66, 4320, 66, 270, 270, 66, 4320, 4320, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 4320, 270, 66, 270, 4320, 4320, 270, 4320, 66, 270, 270, 4320, 270, 66, 66, 270, 4320, 66, 270, 66, 4320, 4320, 270, 4320, 4320, 4320, 66, 270, 4320, 66, 270, 66, 270, 66, 66, 270, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 270, 66, 66, 66, 66, 66, 4320, 66, 270, 66, 4320, 4320, 66, 4320, 66, 270, 270, 4320, 66, 66, 66, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 66, 4320, 270, 270, 270, 4320, 270, 66, 270, 4320, 4320, 270, 4320, 270, 66, 4320, 270, 66, 270, 270, 66, 270, 4320, 66, 270, 4320, 66, 270, 4320, 4320, 270, 66, 4320, 270, 66, 66, 270, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 270, 66, 4320, 4320, 270, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 270, 270, 270, 270, 270, 270, 66, 4320, 270, 4320, 66, 4320, 270, 66, 270, 66, 66, 270, 270, 270, 4320, 270, 66, 66]
Prompts retrieved: 297984 . Total input tokens: 66511279 . Total output tokens: 59553787
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 58.686103304848075,
    "estimated_duration": 3600.0881507024706,
    "input_throughput": 6319.493870048916,
    "output_throughput": 5516.369091163758,
    "total_throughput": 11835.862961212673,
    "itl": 86.0798254325131,
    "ttft": 509357.23056230304,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 825,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.580789587139128,
    "arrivals": 99385,
    "finished_requests": 90995,
    "scheduler_time": 124.97571177022634
}
#Debug simulation 
Total elapsed time: 58.68626946024597. Arrivals time: 0.3302789954468608 Scheduler time: 58.104932342190295 Scheduler overhead time: 0.09575659083202481 Adapter cache time: 0.022693792823702097 Engine time: 0.09501940244808793 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-32/adapters_192_slots_32_rate_0.4-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-32/adapters_192_slots_32_rate_0.4-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 270, 270, 270, 270, 4320, 270, 66, 4320, 66, 270, 270, 66, 4320, 4320, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 4320, 270, 66, 270, 4320, 4320, 270, 4320, 66, 270, 270, 4320, 270, 66, 66, 270, 4320, 66, 270, 66, 4320, 4320, 270, 4320, 4320, 4320, 66, 270, 4320, 66, 270, 66, 270, 66, 66, 270, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 270, 66, 66, 66, 66, 66, 4320, 66, 270, 66, 4320, 4320, 66, 4320, 66, 270, 270, 4320, 66, 66, 66, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 66, 4320, 270, 270, 270, 4320, 270, 66, 270, 4320, 4320, 270, 4320, 270, 66, 4320, 270, 66, 270, 270, 66, 270, 4320, 66, 270, 4320, 66, 270, 4320, 4320, 270, 66, 4320, 270, 66, 66, 270, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 270, 66, 4320, 4320, 270, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 270, 270, 270, 270, 270, 270, 66, 4320, 270, 4320, 66, 4320, 270, 66, 270, 66, 66, 270, 270, 270, 4320, 270, 66, 66]
Prompts retrieved: 297984 . Total input tokens: 66511279 . Total output tokens: 59553787
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 58.03470425819978,
    "estimated_duration": 3600.054493456867,
    "input_throughput": 6274.51863327486,
    "output_throughput": 5496.522076530918,
    "total_throughput": 11771.040709805779,
    "itl": 85.12002399514476,
    "ttft": 534093.2207781164,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 870,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.880653764363378,
    "arrivals": 99385,
    "finished_requests": 90302,
    "scheduler_time": 125.21045677045412
}
#Debug simulation 
Total elapsed time: 58.03486599121243. Arrivals time: 0.32940907776355743 Scheduler time: 57.45388478413224 Scheduler overhead time: 0.09812133200466633 Adapter cache time: 0.022840159479528666 Engine time: 0.09321916475892067 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_192_slots_32_rate_0.4-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_192_slots_32_rate_0.4-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 270, 270, 270, 270, 4320, 270, 66, 4320, 66, 270, 270, 66, 4320, 4320, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 4320, 270, 66, 270, 4320, 4320, 270, 4320, 66, 270, 270, 4320, 270, 66, 66, 270, 4320, 66, 270, 66, 4320, 4320, 270, 4320, 4320, 4320, 66, 270, 4320, 66, 270, 66, 270, 66, 66, 270, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 270, 66, 66, 66, 66, 66, 4320, 66, 270, 66, 4320, 4320, 66, 4320, 66, 270, 270, 4320, 66, 66, 66, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 66, 4320, 270, 270, 270, 4320, 270, 66, 270, 4320, 4320, 270, 4320, 270, 66, 4320, 270, 66, 270, 270, 66, 270, 4320, 66, 270, 4320, 66, 270, 4320, 4320, 270, 66, 4320, 270, 66, 66, 270, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 270, 66, 4320, 4320, 270, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 270, 270, 270, 270, 270, 270, 66, 4320, 270, 4320, 66, 4320, 270, 66, 270, 66, 66, 270, 270, 270, 4320, 270, 66, 66]
Prompts retrieved: 297984 . Total input tokens: 66511279 . Total output tokens: 59553787
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 58.19591323193163,
    "estimated_duration": 3600.00552934655,
    "input_throughput": 6274.603973761157,
    "output_throughput": 5496.596835392014,
    "total_throughput": 11771.200809153172,
    "itl": 85.11338535147857,
    "ttft": 534046.8886253776,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 870,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6013437565648374,
    "arrivals": 99385,
    "finished_requests": 90302,
    "scheduler_time": 125.21561044547725
}
#Debug simulation 
Total elapsed time: 58.19607923505828. Arrivals time: 0.34094986878335476 Scheduler time: 57.60243282932788 Scheduler overhead time: 0.0969627583399415 Adapter cache time: 0.023391165304929018 Engine time: 0.0943495873361826 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-32/adapters_192_slots_32_rate_0.4-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-32/adapters_192_slots_32_rate_0.4-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 270, 270, 270, 270, 4320, 270, 66, 4320, 66, 270, 270, 66, 4320, 4320, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 4320, 270, 66, 270, 4320, 4320, 270, 4320, 66, 270, 270, 4320, 270, 66, 66, 270, 4320, 66, 270, 66, 4320, 4320, 270, 4320, 4320, 4320, 66, 270, 4320, 66, 270, 66, 270, 66, 66, 270, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 270, 66, 66, 66, 66, 66, 4320, 66, 270, 66, 4320, 4320, 66, 4320, 66, 270, 270, 4320, 66, 66, 66, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 66, 4320, 270, 270, 270, 4320, 270, 66, 270, 4320, 4320, 270, 4320, 270, 66, 4320, 270, 66, 270, 270, 66, 270, 4320, 66, 270, 4320, 66, 270, 4320, 4320, 270, 66, 4320, 270, 66, 66, 270, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 270, 66, 4320, 4320, 270, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 270, 270, 270, 270, 270, 270, 66, 4320, 270, 4320, 66, 4320, 270, 66, 270, 66, 66, 270, 270, 270, 4320, 270, 66, 66]
Prompts retrieved: 297984 . Total input tokens: 66511279 . Total output tokens: 59553787
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 61.192195096984506,
    "estimated_duration": 3600.056979127989,
    "input_throughput": 6310.185680867348,
    "output_throughput": 5531.421895667735,
    "total_throughput": 11841.607576535083,
    "itl": 85.47364858413891,
    "ttft": 521458.78915875335,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 795,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6668401687964973,
    "arrivals": 99385,
    "finished_requests": 90836,
    "scheduler_time": 126.28425495602745
}
#Debug simulation 
Total elapsed time: 61.19246177887544. Arrivals time: 0.3393943449482322 Scheduler time: 60.59870747290552 Scheduler overhead time: 0.09955599950626493 Adapter cache time: 0.022377440705895424 Engine time: 0.09407223155722022 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_192_slots_32_rate_0.4-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_192_slots_32_rate_0.4-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 270, 270, 270, 270, 4320, 270, 33, 4320, 33, 270, 270, 33, 4320, 4320, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 4320, 270, 33, 270, 4320, 4320, 270, 4320, 33, 270, 270, 4320, 270, 33, 33, 270, 4320, 33, 270, 33, 4320, 4320, 270, 4320, 4320, 4320, 33, 270, 4320, 33, 270, 33, 270, 33, 33, 270, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 270, 33, 33, 33, 33, 33, 4320, 33, 270, 33, 4320, 4320, 33, 4320, 33, 270, 270, 4320, 33, 33, 33, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 33, 4320, 270, 270, 270, 4320, 270, 33, 270, 4320, 4320, 270, 4320, 270, 33, 4320, 270, 33, 270, 270, 33, 270, 4320, 33, 270, 4320, 33, 270, 4320, 4320, 270, 33, 4320, 270, 33, 33, 270, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 270, 33, 4320, 4320, 270, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 270, 270, 270, 270, 270, 270, 33, 4320, 270, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 270, 270, 4320, 270, 33, 33]
Prompts retrieved: 295872 . Total input tokens: 66041597 . Total output tokens: 59123757
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 55.107472924049944,
    "estimated_duration": 3600.0640556733615,
    "input_throughput": 6336.999466453357,
    "output_throughput": 5521.285369541065,
    "total_throughput": 11858.284835994422,
    "itl": 86.97831192191431,
    "ttft": 475789.97680976184,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 804,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4606321461219833,
    "arrivals": 98651,
    "finished_requests": 91266,
    "scheduler_time": 122.48698414035741
}
#Debug simulation 
Total elapsed time: 55.107645319309086. Arrivals time: 0.3299870556220412 Scheduler time: 54.53172631934285 Scheduler overhead time: 0.09567432571202517 Adapter cache time: 0.021385878790169954 Engine time: 0.09122431045398116 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_192_slots_32_rate_0.4-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_192_slots_32_rate_0.4-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 270, 270, 270, 270, 4320, 270, 33, 4320, 33, 270, 270, 33, 4320, 4320, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 4320, 270, 33, 270, 4320, 4320, 270, 4320, 33, 270, 270, 4320, 270, 33, 33, 270, 4320, 33, 270, 33, 4320, 4320, 270, 4320, 4320, 4320, 33, 270, 4320, 33, 270, 33, 270, 33, 33, 270, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 270, 33, 33, 33, 33, 33, 4320, 33, 270, 33, 4320, 4320, 33, 4320, 33, 270, 270, 4320, 33, 33, 33, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 33, 4320, 270, 270, 270, 4320, 270, 33, 270, 4320, 4320, 270, 4320, 270, 33, 4320, 270, 33, 270, 270, 33, 270, 4320, 33, 270, 4320, 33, 270, 4320, 4320, 270, 33, 4320, 270, 33, 33, 270, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 270, 33, 4320, 4320, 270, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 270, 270, 270, 270, 270, 270, 33, 4320, 270, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 270, 270, 4320, 270, 33, 33]
Prompts retrieved: 295872 . Total input tokens: 66041597 . Total output tokens: 59123757
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 58.01052333088592,
    "estimated_duration": 3600.0570837445634,
    "input_throughput": 6295.627117230492,
    "output_throughput": 5506.815180658019,
    "total_throughput": 11802.442297888512,
    "itl": 85.07229734174328,
    "ttft": 490215.4823846895,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 761,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4785001476854136,
    "arrivals": 98651,
    "finished_requests": 90626,
    "scheduler_time": 122.78825097282285
}
#Debug simulation 
Total elapsed time: 58.010691482108086. Arrivals time: 0.3370021488517523 Scheduler time: 57.42032992094755 Scheduler overhead time: 0.099886329844594 Adapter cache time: 0.021294670645147562 Engine time: 0.09425160009413958 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-32/adapters_192_slots_32_rate_0.4-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-32/adapters_192_slots_32_rate_0.4-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 270, 270, 270, 270, 4320, 270, 33, 4320, 33, 270, 270, 33, 4320, 4320, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 4320, 270, 33, 270, 4320, 4320, 270, 4320, 33, 270, 270, 4320, 270, 33, 33, 270, 4320, 33, 270, 33, 4320, 4320, 270, 4320, 4320, 4320, 33, 270, 4320, 33, 270, 33, 270, 33, 33, 270, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 270, 33, 33, 33, 33, 33, 4320, 33, 270, 33, 4320, 4320, 33, 4320, 33, 270, 270, 4320, 33, 33, 33, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 33, 4320, 270, 270, 270, 4320, 270, 33, 270, 4320, 4320, 270, 4320, 270, 33, 4320, 270, 33, 270, 270, 33, 270, 4320, 33, 270, 4320, 33, 270, 4320, 4320, 270, 33, 4320, 270, 33, 33, 270, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 270, 33, 4320, 4320, 270, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 270, 270, 270, 270, 270, 270, 33, 4320, 270, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 270, 270, 4320, 270, 33, 33]
Prompts retrieved: 295872 . Total input tokens: 66041597 . Total output tokens: 59123757
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 55.94643439818174,
    "estimated_duration": 3600.102265144948,
    "input_throughput": 6271.314628639025,
    "output_throughput": 5475.468625113165,
    "total_throughput": 11746.78325375219,
    "itl": 84.45822013825504,
    "ttft": 499413.0687274788,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 806,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6311428692191727,
    "arrivals": 98651,
    "finished_requests": 90358,
    "scheduler_time": 122.39231447123784
}
#Debug simulation 
Total elapsed time: 55.94659438729286. Arrivals time: 0.3282751189544797 Scheduler time: 55.368444920517504 Scheduler overhead time: 0.09654165944084525 Adapter cache time: 0.022853375878185034 Engine time: 0.09237534459680319 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_192_slots_32_rate_0.4-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_192_slots_32_rate_0.4-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 270, 270, 270, 270, 4320, 270, 33, 4320, 33, 270, 270, 33, 4320, 4320, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 4320, 270, 33, 270, 4320, 4320, 270, 4320, 33, 270, 270, 4320, 270, 33, 33, 270, 4320, 33, 270, 33, 4320, 4320, 270, 4320, 4320, 4320, 33, 270, 4320, 33, 270, 33, 270, 33, 33, 270, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 270, 33, 33, 33, 33, 33, 4320, 33, 270, 33, 4320, 4320, 33, 4320, 33, 270, 270, 4320, 33, 33, 33, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 33, 4320, 270, 270, 270, 4320, 270, 33, 270, 4320, 4320, 270, 4320, 270, 33, 4320, 270, 33, 270, 270, 33, 270, 4320, 33, 270, 4320, 33, 270, 4320, 4320, 270, 33, 4320, 270, 33, 33, 270, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 270, 33, 4320, 4320, 270, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 270, 270, 270, 270, 270, 270, 33, 4320, 270, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 270, 270, 4320, 270, 33, 33]
Prompts retrieved: 295872 . Total input tokens: 66041597 . Total output tokens: 59123757
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 54.90303197223693,
    "estimated_duration": 3600.135568030581,
    "input_throughput": 6262.084461539504,
    "output_throughput": 5449.985043405825,
    "total_throughput": 11712.06950494533,
    "itl": 83.30866553261306,
    "ttft": 501363.86080601095,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 826,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5764249217021034,
    "arrivals": 98651,
    "finished_requests": 90123,
    "scheduler_time": 119.71311171410477
}
#Debug simulation 
Total elapsed time: 54.90319863520563. Arrivals time: 0.3214653106406331 Scheduler time: 54.33329677209258 Scheduler overhead time: 0.09688187763094902 Adapter cache time: 0.02167807100340724 Engine time: 0.09229082614183426 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-32/adapters_192_slots_32_rate_0.4-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-32/adapters_192_slots_32_rate_0.4-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 270, 270, 270, 270, 4320, 270, 33, 4320, 33, 270, 270, 33, 4320, 4320, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 4320, 270, 33, 270, 4320, 4320, 270, 4320, 33, 270, 270, 4320, 270, 33, 33, 270, 4320, 33, 270, 33, 4320, 4320, 270, 4320, 4320, 4320, 33, 270, 4320, 33, 270, 33, 270, 33, 33, 270, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 270, 33, 33, 33, 33, 33, 4320, 33, 270, 33, 4320, 4320, 33, 4320, 33, 270, 270, 4320, 33, 33, 33, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 33, 4320, 270, 270, 270, 4320, 270, 33, 270, 4320, 4320, 270, 4320, 270, 33, 4320, 270, 33, 270, 270, 33, 270, 4320, 33, 270, 4320, 33, 270, 4320, 4320, 270, 33, 4320, 270, 33, 33, 270, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 270, 33, 4320, 4320, 270, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 270, 270, 270, 270, 270, 270, 33, 4320, 270, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 270, 270, 4320, 270, 33, 33]
Prompts retrieved: 295872 . Total input tokens: 66041597 . Total output tokens: 59123757
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 54.90083547588438,
    "estimated_duration": 3600.0245015394676,
    "input_throughput": 6278.966987678482,
    "output_throughput": 5500.511730276319,
    "total_throughput": 11779.478717954802,
    "itl": 84.24168423197446,
    "ttft": 489901.84529829735,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 833,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.755485381931068,
    "arrivals": 98651,
    "finished_requests": 90387,
    "scheduler_time": 119.94092500870973
}
#Debug simulation 
Total elapsed time: 54.900994373019785. Arrivals time: 0.3199700047262013 Scheduler time: 54.32833610428497 Scheduler overhead time: 0.09700987441465259 Adapter cache time: 0.022490701638162136 Engine time: 0.0941231595352292 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_192_slots_32_rate_0.4-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_192_slots_32_rate_0.4-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 270, 270, 270, 270, 4320, 270, 33, 4320, 33, 270, 270, 33, 4320, 4320, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 4320, 270, 33, 270, 4320, 4320, 270, 4320, 33, 270, 270, 4320, 270, 33, 33, 270, 4320, 33, 270, 33, 4320, 4320, 270, 4320, 4320, 4320, 33, 270, 4320, 33, 270, 33, 270, 33, 33, 270, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 270, 33, 33, 33, 33, 33, 4320, 33, 270, 33, 4320, 4320, 33, 4320, 33, 270, 270, 4320, 33, 33, 33, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 33, 4320, 270, 270, 270, 4320, 270, 33, 270, 4320, 4320, 270, 4320, 270, 33, 4320, 270, 33, 270, 270, 33, 270, 4320, 33, 270, 4320, 33, 270, 4320, 4320, 270, 33, 4320, 270, 33, 33, 270, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 270, 33, 4320, 4320, 270, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 270, 270, 270, 270, 270, 270, 33, 4320, 270, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 270, 270, 4320, 270, 33, 33]
Prompts retrieved: 295872 . Total input tokens: 66041597 . Total output tokens: 59123757
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 52.774024926126,
    "estimated_duration": 3600.0194967475236,
    "input_throughput": 6283.171805162686,
    "output_throughput": 5471.695366593586,
    "total_throughput": 11754.867171756272,
    "itl": 84.43284131321278,
    "ttft": 488194.2739134439,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 849,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.538552700371894,
    "arrivals": 98651,
    "finished_requests": 90413,
    "scheduler_time": 119.20749877477445
}
#Debug simulation 
Total elapsed time: 52.7741816341877. Arrivals time: 0.3230288033373654 Scheduler time: 52.204820338170975 Scheduler overhead time: 0.09437474189326167 Adapter cache time: 0.02235699025914073 Engine time: 0.09201978240162134 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-32/adapters_192_slots_32_rate_0.4-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-32/adapters_192_slots_32_rate_0.4-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 270, 270, 270, 270, 4320, 270, 33, 4320, 33, 270, 270, 33, 4320, 4320, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 4320, 270, 33, 270, 4320, 4320, 270, 4320, 33, 270, 270, 4320, 270, 33, 33, 270, 4320, 33, 270, 33, 4320, 4320, 270, 4320, 4320, 4320, 33, 270, 4320, 33, 270, 33, 270, 33, 33, 270, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 270, 33, 33, 33, 33, 33, 4320, 33, 270, 33, 4320, 4320, 33, 4320, 33, 270, 270, 4320, 33, 33, 33, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 33, 4320, 270, 270, 270, 4320, 270, 33, 270, 4320, 4320, 270, 4320, 270, 33, 4320, 270, 33, 270, 270, 33, 270, 4320, 33, 270, 4320, 33, 270, 4320, 4320, 270, 33, 4320, 270, 33, 33, 270, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 270, 33, 4320, 4320, 270, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 270, 270, 270, 270, 270, 270, 33, 4320, 270, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 270, 270, 4320, 270, 33, 33]
Prompts retrieved: 295872 . Total input tokens: 66041597 . Total output tokens: 59123757
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 57.00269884057343,
    "estimated_duration": 3600.083373337069,
    "input_throughput": 6316.6159340696095,
    "output_throughput": 5502.934222780604,
    "total_throughput": 11819.550156850213,
    "itl": 85.59671443240435,
    "ttft": 483055.1204014252,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 789,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.640708033926802,
    "arrivals": 98651,
    "finished_requests": 90944,
    "scheduler_time": 122.68456011065732
}
#Debug simulation 
Total elapsed time: 57.00285691674799. Arrivals time: 0.32946509635075927 Scheduler time: 56.42368384124711 Scheduler overhead time: 0.09648261358961463 Adapter cache time: 0.02139639062806964 Engine time: 0.0940937539562583 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_192_slots_32_rate_0.4-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_192_slots_32_rate_0.4-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 135, 135, 135, 135, 4320, 135, 66, 4320, 66, 135, 135, 66, 4320, 4320, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 4320, 135, 66, 135, 4320, 4320, 135, 4320, 66, 135, 135, 4320, 135, 66, 66, 135, 4320, 66, 135, 66, 4320, 4320, 135, 4320, 4320, 4320, 66, 135, 4320, 66, 135, 66, 135, 66, 66, 135, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 135, 66, 66, 66, 66, 66, 4320, 66, 135, 66, 4320, 4320, 66, 4320, 66, 135, 135, 4320, 66, 66, 66, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 66, 4320, 135, 135, 135, 4320, 135, 66, 135, 4320, 4320, 135, 4320, 135, 66, 4320, 135, 66, 135, 135, 66, 135, 4320, 66, 135, 4320, 66, 135, 4320, 4320, 135, 66, 4320, 135, 66, 66, 135, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 135, 66, 4320, 4320, 135, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 135, 135, 135, 135, 135, 135, 66, 4320, 135, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 135, 135, 4320, 135, 66, 66]
Prompts retrieved: 289344 . Total input tokens: 64591017 . Total output tokens: 57818491
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 49.69265922671184,
    "estimated_duration": 3599.976879039603,
    "input_throughput": 6151.8114543858355,
    "output_throughput": 5508.125931433757,
    "total_throughput": 11659.937385819592,
    "itl": 86.43300134116133,
    "ttft": 434309.5030994229,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 861,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6350799475261564,
    "arrivals": 96558,
    "finished_requests": 89623,
    "scheduler_time": 116.45281661202118
}
#Debug simulation 
Total elapsed time: 49.69291709270328. Arrivals time: 0.3168998402543366 Scheduler time: 49.132935321424156 Scheduler overhead time: 0.09337999951094389 Adapter cache time: 0.02160655939951539 Engine time: 0.0907827247865498 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_192_slots_32_rate_0.4-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_192_slots_32_rate_0.4-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 135, 135, 135, 135, 4320, 135, 66, 4320, 66, 135, 135, 66, 4320, 4320, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 4320, 135, 66, 135, 4320, 4320, 135, 4320, 66, 135, 135, 4320, 135, 66, 66, 135, 4320, 66, 135, 66, 4320, 4320, 135, 4320, 4320, 4320, 66, 135, 4320, 66, 135, 66, 135, 66, 66, 135, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 135, 66, 66, 66, 66, 66, 4320, 66, 135, 66, 4320, 4320, 66, 4320, 66, 135, 135, 4320, 66, 66, 66, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 66, 4320, 135, 135, 135, 4320, 135, 66, 135, 4320, 4320, 135, 4320, 135, 66, 4320, 135, 66, 135, 135, 66, 135, 4320, 66, 135, 4320, 66, 135, 4320, 4320, 135, 66, 4320, 135, 66, 66, 135, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 135, 66, 4320, 4320, 135, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 135, 135, 135, 135, 135, 135, 66, 4320, 135, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 135, 135, 4320, 135, 66, 66]
Prompts retrieved: 289344 . Total input tokens: 64591017 . Total output tokens: 57818491
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 55.03221265692264,
    "estimated_duration": 3599.9554007805036,
    "input_throughput": 6142.299706048001,
    "output_throughput": 5499.205350074018,
    "total_throughput": 11641.505056122018,
    "itl": 85.73237275108852,
    "ttft": 464063.34207031404,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 784,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.55421742488165,
    "arrivals": 96558,
    "finished_requests": 89525,
    "scheduler_time": 120.65276887131321
}
#Debug simulation 
Total elapsed time: 55.03237508563325. Arrivals time: 0.331506937276572 Scheduler time: 54.44726920686662 Scheduler overhead time: 0.0968273370526731 Adapter cache time: 0.022900367621332407 Engine time: 0.09442896116524935 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-32/adapters_192_slots_32_rate_0.4-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-32/adapters_192_slots_32_rate_0.4-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 135, 135, 135, 135, 4320, 135, 66, 4320, 66, 135, 135, 66, 4320, 4320, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 4320, 135, 66, 135, 4320, 4320, 135, 4320, 66, 135, 135, 4320, 135, 66, 66, 135, 4320, 66, 135, 66, 4320, 4320, 135, 4320, 4320, 4320, 66, 135, 4320, 66, 135, 66, 135, 66, 66, 135, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 135, 66, 66, 66, 66, 66, 4320, 66, 135, 66, 4320, 4320, 66, 4320, 66, 135, 135, 4320, 66, 66, 66, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 66, 4320, 135, 135, 135, 4320, 135, 66, 135, 4320, 4320, 135, 4320, 135, 66, 4320, 135, 66, 135, 135, 66, 135, 4320, 66, 135, 4320, 66, 135, 4320, 4320, 135, 66, 4320, 135, 66, 66, 135, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 135, 66, 4320, 4320, 135, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 135, 135, 135, 135, 135, 135, 66, 4320, 135, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 135, 135, 4320, 135, 66, 66]
Prompts retrieved: 289344 . Total input tokens: 64591017 . Total output tokens: 57818491
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 55.2117718430236,
    "estimated_duration": 3599.9832881536445,
    "input_throughput": 6141.532398984956,
    "output_throughput": 5499.880809211961,
    "total_throughput": 11641.413208196916,
    "itl": 85.70137164102204,
    "ttft": 464590.89911639655,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 784,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5594639896228815,
    "arrivals": 96558,
    "finished_requests": 89508,
    "scheduler_time": 120.6605382279396
}
#Debug simulation 
Total elapsed time: 55.21194471558556. Arrivals time: 0.3325836891308427 Scheduler time: 54.626609763130546 Scheduler overhead time: 0.09789946116507053 Adapter cache time: 0.02257526433095336 Engine time: 0.09351139375939965 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_192_slots_32_rate_0.4-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_192_slots_32_rate_0.4-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 135, 135, 135, 135, 4320, 135, 66, 4320, 66, 135, 135, 66, 4320, 4320, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 4320, 135, 66, 135, 4320, 4320, 135, 4320, 66, 135, 135, 4320, 135, 66, 66, 135, 4320, 66, 135, 66, 4320, 4320, 135, 4320, 4320, 4320, 66, 135, 4320, 66, 135, 66, 135, 66, 66, 135, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 135, 66, 66, 66, 66, 66, 4320, 66, 135, 66, 4320, 4320, 66, 4320, 66, 135, 135, 4320, 66, 66, 66, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 66, 4320, 135, 135, 135, 4320, 135, 66, 135, 4320, 4320, 135, 4320, 135, 66, 4320, 135, 66, 135, 135, 66, 135, 4320, 66, 135, 4320, 66, 135, 4320, 4320, 135, 66, 4320, 135, 66, 66, 135, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 135, 66, 4320, 4320, 135, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 135, 135, 135, 135, 135, 135, 66, 4320, 135, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 135, 135, 4320, 135, 66, 66]
Prompts retrieved: 289344 . Total input tokens: 64591017 . Total output tokens: 57818491
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 56.774856326170266,
    "estimated_duration": 3600.0860777057196,
    "input_throughput": 6119.76256246641,
    "output_throughput": 5444.518152324638,
    "total_throughput": 11564.280714791048,
    "itl": 83.11941558418398,
    "ttft": 489622.9930340725,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 809,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5272284479625298,
    "arrivals": 96558,
    "finished_requests": 89128,
    "scheduler_time": 122.10448051739064
}
#Debug simulation 
Total elapsed time: 56.77502365317196. Arrivals time: 0.3248565080575645 Scheduler time: 56.19858912937343 Scheduler overhead time: 0.09614052576944232 Adapter cache time: 0.022997314110398293 Engine time: 0.09447190724313259 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-32/adapters_192_slots_32_rate_0.4-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-32/adapters_192_slots_32_rate_0.4-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 135, 135, 135, 135, 4320, 135, 66, 4320, 66, 135, 135, 66, 4320, 4320, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 4320, 135, 66, 135, 4320, 4320, 135, 4320, 66, 135, 135, 4320, 135, 66, 66, 135, 4320, 66, 135, 66, 4320, 4320, 135, 4320, 4320, 4320, 66, 135, 4320, 66, 135, 66, 135, 66, 66, 135, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 135, 66, 66, 66, 66, 66, 4320, 66, 135, 66, 4320, 4320, 66, 4320, 66, 135, 135, 4320, 66, 66, 66, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 66, 4320, 135, 135, 135, 4320, 135, 66, 135, 4320, 4320, 135, 4320, 135, 66, 4320, 135, 66, 135, 135, 66, 135, 4320, 66, 135, 4320, 66, 135, 4320, 4320, 135, 66, 4320, 135, 66, 66, 135, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 135, 66, 4320, 4320, 135, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 135, 135, 135, 135, 135, 135, 66, 4320, 135, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 135, 135, 4320, 135, 66, 66]
Prompts retrieved: 289344 . Total input tokens: 64591017 . Total output tokens: 57818491
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 62.418756457977,
    "estimated_duration": 3600.036726166171,
    "input_throughput": 6045.781378230131,
    "output_throughput": 5379.978448338197,
    "total_throughput": 11425.759826568328,
    "itl": 80.59020528616479,
    "ttft": 527680.1762423149,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 776,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5676003295928265,
    "arrivals": 96558,
    "finished_requests": 88026,
    "scheduler_time": 123.83783430887823
}
#Debug simulation 
Total elapsed time: 62.41892938502133. Arrivals time: 0.32685546251013875 Scheduler time: 61.831520883366466 Scheduler overhead time: 0.10123982233926654 Adapter cache time: 0.022395398002117872 Engine time: 0.09767785342410207 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_192_slots_32_rate_0.4-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_192_slots_32_rate_0.4-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 135, 135, 135, 135, 4320, 135, 66, 4320, 66, 135, 135, 66, 4320, 4320, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 4320, 135, 66, 135, 4320, 4320, 135, 4320, 66, 135, 135, 4320, 135, 66, 66, 135, 4320, 66, 135, 66, 4320, 4320, 135, 4320, 4320, 4320, 66, 135, 4320, 66, 135, 66, 135, 66, 66, 135, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 135, 66, 66, 66, 66, 66, 4320, 66, 135, 66, 4320, 4320, 66, 4320, 66, 135, 135, 4320, 66, 66, 66, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 66, 4320, 135, 135, 135, 4320, 135, 66, 135, 4320, 4320, 135, 4320, 135, 66, 4320, 135, 66, 135, 135, 66, 135, 4320, 66, 135, 4320, 66, 135, 4320, 4320, 135, 66, 4320, 135, 66, 66, 135, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 135, 66, 4320, 4320, 135, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 135, 135, 135, 135, 135, 135, 66, 4320, 135, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 135, 135, 4320, 135, 66, 66]
Prompts retrieved: 289344 . Total input tokens: 64591017 . Total output tokens: 57818491
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 52.34608624689281,
    "estimated_duration": 3600.020236618962,
    "input_throughput": 6140.6729815390845,
    "output_throughput": 5466.838158244241,
    "total_throughput": 11607.511139783324,
    "itl": 84.71465319026734,
    "ttft": 454216.5921915453,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 850,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.541542750666796,
    "arrivals": 96558,
    "finished_requests": 89440,
    "scheduler_time": 117.86489682218681
}
#Debug simulation 
Total elapsed time: 52.346235781908035. Arrivals time: 0.30850430531427264 Scheduler time: 51.79319372866303 Scheduler overhead time: 0.09435231145471334 Adapter cache time: 0.021638864651322365 Engine time: 0.09093640744686127 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-32/adapters_192_slots_32_rate_0.4-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-32/adapters_192_slots_32_rate_0.4-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [64 64 64]
Adapter prompts. [4320, 66, 4320, 66, 4320, 66, 4320, 66, 66, 66, 135, 135, 135, 135, 4320, 135, 66, 4320, 66, 135, 135, 66, 4320, 4320, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 4320, 135, 66, 135, 4320, 4320, 135, 4320, 66, 135, 135, 4320, 135, 66, 66, 135, 4320, 66, 135, 66, 4320, 4320, 135, 4320, 4320, 4320, 66, 135, 4320, 66, 135, 66, 135, 66, 66, 135, 4320, 4320, 66, 66, 66, 4320, 4320, 4320, 135, 66, 66, 66, 66, 66, 4320, 66, 135, 66, 4320, 4320, 66, 4320, 66, 135, 135, 4320, 66, 66, 66, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 66, 4320, 135, 135, 135, 4320, 135, 66, 135, 4320, 4320, 135, 4320, 135, 66, 4320, 135, 66, 135, 135, 66, 135, 4320, 66, 135, 4320, 66, 135, 4320, 4320, 135, 66, 4320, 135, 66, 66, 135, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 135, 66, 4320, 4320, 135, 4320, 66, 4320, 4320, 4320, 66, 4320, 4320, 4320, 135, 135, 135, 135, 135, 135, 66, 4320, 135, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 135, 135, 4320, 135, 66, 66]
Prompts retrieved: 289344 . Total input tokens: 64591017 . Total output tokens: 57818491
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 63.05022957501933,
    "estimated_duration": 3600.0813683200417,
    "input_throughput": 6032.583371895977,
    "output_throughput": 5366.2967648465,
    "total_throughput": 11398.880136742477,
    "itl": 80.24027303427725,
    "ttft": 539491.9717305531,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 775,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.592542754672482,
    "arrivals": 96558,
    "finished_requests": 87834,
    "scheduler_time": 124.21587481465524
}
#Debug simulation 
Total elapsed time: 63.05038689589128. Arrivals time: 0.32808675384148955 Scheduler time: 62.46272355830297 Scheduler overhead time: 0.10026245005428791 Adapter cache time: 0.0230565182864666 Engine time: 0.0975253120996058 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_192_slots_32_rate_0.4-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_192_slots_32_rate_0.4-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 135, 135, 135, 135, 4320, 135, 33, 4320, 33, 135, 135, 33, 4320, 4320, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 4320, 135, 33, 135, 4320, 4320, 135, 4320, 33, 135, 135, 4320, 135, 33, 33, 135, 4320, 33, 135, 33, 4320, 4320, 135, 4320, 4320, 4320, 33, 135, 4320, 33, 135, 33, 135, 33, 33, 135, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 135, 33, 33, 33, 33, 33, 4320, 33, 135, 33, 4320, 4320, 33, 4320, 33, 135, 135, 4320, 33, 33, 33, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 33, 4320, 135, 135, 135, 4320, 135, 33, 135, 4320, 4320, 135, 4320, 135, 33, 4320, 135, 33, 135, 135, 33, 135, 4320, 33, 135, 4320, 33, 135, 4320, 4320, 135, 33, 4320, 135, 33, 33, 135, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 135, 33, 4320, 4320, 135, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 135, 135, 135, 135, 135, 135, 33, 4320, 135, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 135, 135, 4320, 135, 33, 33]
Prompts retrieved: 287232 . Total input tokens: 64128402 . Total output tokens: 57391951
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 51.300128269940615,
    "estimated_duration": 3600.102627953187,
    "input_throughput": 6202.114858235185,
    "output_throughput": 5406.189214962868,
    "total_throughput": 11608.304073198055,
    "itl": 83.42270831613845,
    "ttft": 425494.84301010973,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 779,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.384119952523662,
    "arrivals": 95849,
    "finished_requests": 89611,
    "scheduler_time": 116.75292746323319
}
#Debug simulation 
Total elapsed time: 51.30028235493228. Arrivals time: 0.30969472974538803 Scheduler time: 50.74639496020973 Scheduler overhead time: 0.09330987883731723 Adapter cache time: 0.021790081169456244 Engine time: 0.09172346908599138 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_192_slots_32_rate_0.4-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_192_slots_32_rate_0.4-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 135, 135, 135, 135, 4320, 135, 33, 4320, 33, 135, 135, 33, 4320, 4320, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 4320, 135, 33, 135, 4320, 4320, 135, 4320, 33, 135, 135, 4320, 135, 33, 33, 135, 4320, 33, 135, 33, 4320, 4320, 135, 4320, 4320, 4320, 33, 135, 4320, 33, 135, 33, 135, 33, 33, 135, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 135, 33, 33, 33, 33, 33, 4320, 33, 135, 33, 4320, 4320, 33, 4320, 33, 135, 135, 4320, 33, 33, 33, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 33, 4320, 135, 135, 135, 4320, 135, 33, 135, 4320, 4320, 135, 4320, 135, 33, 4320, 135, 33, 135, 135, 33, 135, 4320, 33, 135, 4320, 33, 135, 4320, 4320, 135, 33, 4320, 135, 33, 33, 135, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 135, 33, 4320, 4320, 135, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 135, 135, 135, 135, 135, 135, 33, 4320, 135, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 135, 135, 4320, 135, 33, 33]
Prompts retrieved: 287232 . Total input tokens: 64128402 . Total output tokens: 57391951
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 48.033390308730304,
    "estimated_duration": 3600.0393209523836,
    "input_throughput": 6218.453467913136,
    "output_throughput": 5447.168836703763,
    "total_throughput": 11665.622304616898,
    "itl": 81.1980860315805,
    "ttft": 392585.9279053973,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 854,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.787219473994343,
    "arrivals": 95849,
    "finished_requests": 89805,
    "scheduler_time": 112.87988288174655
}
#Debug simulation 
Total elapsed time: 48.03361774003133. Arrivals time: 0.305081351660192 Scheduler time: 47.485565478913486 Scheduler overhead time: 0.09394648252055049 Adapter cache time: 0.021270259749144316 Engine time: 0.0902859247289598 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-32/adapters_192_slots_32_rate_0.4-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-32/adapters_192_slots_32_rate_0.4-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 135, 135, 135, 135, 4320, 135, 33, 4320, 33, 135, 135, 33, 4320, 4320, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 4320, 135, 33, 135, 4320, 4320, 135, 4320, 33, 135, 135, 4320, 135, 33, 33, 135, 4320, 33, 135, 33, 4320, 4320, 135, 4320, 4320, 4320, 33, 135, 4320, 33, 135, 33, 135, 33, 33, 135, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 135, 33, 33, 33, 33, 33, 4320, 33, 135, 33, 4320, 4320, 33, 4320, 33, 135, 135, 4320, 33, 33, 33, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 33, 4320, 135, 135, 135, 4320, 135, 33, 135, 4320, 4320, 135, 4320, 135, 33, 4320, 135, 33, 135, 135, 33, 135, 4320, 33, 135, 4320, 33, 135, 4320, 4320, 135, 33, 4320, 135, 33, 33, 135, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 135, 33, 4320, 4320, 135, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 135, 135, 135, 135, 135, 135, 33, 4320, 135, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 135, 135, 4320, 135, 33, 33]
Prompts retrieved: 287232 . Total input tokens: 64128402 . Total output tokens: 57391951
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 49.96129709016532,
    "estimated_duration": 3600.0620445490617,
    "input_throughput": 6177.831027572143,
    "output_throughput": 5388.853236397496,
    "total_throughput": 11566.684263969639,
    "itl": 80.13703349020612,
    "ttft": 422033.1597656967,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 851,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7822656121849825,
    "arrivals": 95849,
    "finished_requests": 89246,
    "scheduler_time": 114.08166002787132
}
#Debug simulation 
Total elapsed time: 49.96145733818412. Arrivals time: 0.2993072126992047 Scheduler time: 49.41422787774354 Scheduler overhead time: 0.09487404627725482 Adapter cache time: 0.022479578852653503 Engine time: 0.09283477859571576 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_192_slots_32_rate_0.4-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_192_slots_32_rate_0.4-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 135, 135, 135, 135, 4320, 135, 33, 4320, 33, 135, 135, 33, 4320, 4320, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 4320, 135, 33, 135, 4320, 4320, 135, 4320, 33, 135, 135, 4320, 135, 33, 33, 135, 4320, 33, 135, 33, 4320, 4320, 135, 4320, 4320, 4320, 33, 135, 4320, 33, 135, 33, 135, 33, 33, 135, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 135, 33, 33, 33, 33, 33, 4320, 33, 135, 33, 4320, 4320, 33, 4320, 33, 135, 135, 4320, 33, 33, 33, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 33, 4320, 135, 135, 135, 4320, 135, 33, 135, 4320, 4320, 135, 4320, 135, 33, 4320, 135, 33, 135, 135, 33, 135, 4320, 33, 135, 4320, 33, 135, 4320, 4320, 135, 33, 4320, 135, 33, 33, 135, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 135, 33, 4320, 4320, 135, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 135, 135, 135, 135, 135, 135, 33, 4320, 135, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 135, 135, 4320, 135, 33, 33]
Prompts retrieved: 287232 . Total input tokens: 64128402 . Total output tokens: 57391951
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 49.22196078393608,
    "estimated_duration": 3600.013386145848,
    "input_throughput": 6191.725032407129,
    "output_throughput": 5426.769265687535,
    "total_throughput": 11618.494298094663,
    "itl": 80.1917176824046,
    "ttft": 414432.99656791956,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 846,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6427634526951924,
    "arrivals": 95849,
    "finished_requests": 89425,
    "scheduler_time": 113.51477666408128
}
#Debug simulation 
Total elapsed time: 49.22211409918964. Arrivals time: 0.2927307430654764 Scheduler time: 48.68921328522265 Scheduler overhead time: 0.0922850058414042 Adapter cache time: 0.02130615571513772 Engine time: 0.0892898179590702 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-32/adapters_192_slots_32_rate_0.4-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-32/adapters_192_slots_32_rate_0.4-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 135, 135, 135, 135, 4320, 135, 33, 4320, 33, 135, 135, 33, 4320, 4320, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 4320, 135, 33, 135, 4320, 4320, 135, 4320, 33, 135, 135, 4320, 135, 33, 33, 135, 4320, 33, 135, 33, 4320, 4320, 135, 4320, 4320, 4320, 33, 135, 4320, 33, 135, 33, 135, 33, 33, 135, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 135, 33, 33, 33, 33, 33, 4320, 33, 135, 33, 4320, 4320, 33, 4320, 33, 135, 135, 4320, 33, 33, 33, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 33, 4320, 135, 135, 135, 4320, 135, 33, 135, 4320, 4320, 135, 4320, 135, 33, 4320, 135, 33, 135, 135, 33, 135, 4320, 33, 135, 4320, 33, 135, 4320, 4320, 135, 33, 4320, 135, 33, 33, 135, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 135, 33, 4320, 4320, 135, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 135, 135, 135, 135, 135, 135, 33, 4320, 135, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 135, 135, 4320, 135, 33, 33]
Prompts retrieved: 287232 . Total input tokens: 64128402 . Total output tokens: 57391951
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 47.420290330424905,
    "estimated_duration": 3600.0441043928863,
    "input_throughput": 6174.9549048230065,
    "output_throughput": 5406.480708458528,
    "total_throughput": 11581.435613281534,
    "itl": 79.73800513425039,
    "ttft": 407136.56564854743,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 863,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.856816920116546,
    "arrivals": 95849,
    "finished_requests": 89152,
    "scheduler_time": 111.72614754886607
}
#Debug simulation 
Total elapsed time: 47.42045257333666. Arrivals time: 0.2899780897423625 Scheduler time: 46.887213920708746 Scheduler overhead time: 0.09390741819515824 Adapter cache time: 0.02162545220926404 Engine time: 0.090102375485003 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_192_slots_32_rate_0.4-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_192_slots_32_rate_0.4-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 135, 135, 135, 135, 4320, 135, 33, 4320, 33, 135, 135, 33, 4320, 4320, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 4320, 135, 33, 135, 4320, 4320, 135, 4320, 33, 135, 135, 4320, 135, 33, 33, 135, 4320, 33, 135, 33, 4320, 4320, 135, 4320, 4320, 4320, 33, 135, 4320, 33, 135, 33, 135, 33, 33, 135, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 135, 33, 33, 33, 33, 33, 4320, 33, 135, 33, 4320, 4320, 33, 4320, 33, 135, 135, 4320, 33, 33, 33, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 33, 4320, 135, 135, 135, 4320, 135, 33, 135, 4320, 4320, 135, 4320, 135, 33, 4320, 135, 33, 135, 135, 33, 135, 4320, 33, 135, 4320, 33, 135, 4320, 4320, 135, 33, 4320, 135, 33, 33, 135, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 135, 33, 4320, 4320, 135, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 135, 135, 135, 135, 135, 135, 33, 4320, 135, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 135, 135, 4320, 135, 33, 33]
Prompts retrieved: 287232 . Total input tokens: 64128402 . Total output tokens: 57391951
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 49.232702428940684,
    "estimated_duration": 3600.050443180578,
    "input_throughput": 6191.784351862178,
    "output_throughput": 5426.784515480203,
    "total_throughput": 11618.56886734238,
    "itl": 80.17839239532195,
    "ttft": 414399.08652832994,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 846,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5295825494871877,
    "arrivals": 95849,
    "finished_requests": 89427,
    "scheduler_time": 113.51897622899442
}
#Debug simulation 
Total elapsed time: 49.23284163000062. Arrivals time: 0.2936311117373407 Scheduler time: 48.696094756480306 Scheduler overhead time: 0.09362440789118409 Adapter cache time: 0.021060129161924124 Engine time: 0.09074128651991487 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-32/adapters_192_slots_32_rate_0.4-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-32/adapters_192_slots_32_rate_0.4-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 135, 135, 135, 135, 4320, 135, 33, 4320, 33, 135, 135, 33, 4320, 4320, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 4320, 135, 33, 135, 4320, 4320, 135, 4320, 33, 135, 135, 4320, 135, 33, 33, 135, 4320, 33, 135, 33, 4320, 4320, 135, 4320, 4320, 4320, 33, 135, 4320, 33, 135, 33, 135, 33, 33, 135, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 135, 33, 33, 33, 33, 33, 4320, 33, 135, 33, 4320, 4320, 33, 4320, 33, 135, 135, 4320, 33, 33, 33, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 33, 4320, 135, 135, 135, 4320, 135, 33, 135, 4320, 4320, 135, 4320, 135, 33, 4320, 135, 33, 135, 135, 33, 135, 4320, 33, 135, 4320, 33, 135, 4320, 4320, 135, 33, 4320, 135, 33, 33, 135, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 135, 33, 4320, 4320, 135, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 135, 135, 135, 135, 135, 135, 33, 4320, 135, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 135, 135, 4320, 135, 33, 33]
Prompts retrieved: 287232 . Total input tokens: 64128402 . Total output tokens: 57391951
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 48.054292873013765,
    "estimated_duration": 3600.04057407735,
    "input_throughput": 6218.451303354394,
    "output_throughput": 5447.16694061867,
    "total_throughput": 11665.618243973066,
    "itl": 81.14911095492954,
    "ttft": 392599.3878526853,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 854,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8640018295496947,
    "arrivals": 95849,
    "finished_requests": 89805,
    "scheduler_time": 112.87993606704225
}
#Debug simulation 
Total elapsed time: 48.05443497467786. Arrivals time: 0.3004076797515154 Scheduler time: 47.51049426570535 Scheduler overhead time: 0.09436671109870076 Adapter cache time: 0.021751062478870153 Engine time: 0.0898165157996118 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_192_slots_32_rate_0.4-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_192_slots_32_rate_0.4-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 66, 66, 66, 66, 4320, 66, 33, 4320, 33, 66, 66, 33, 4320, 4320, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 4320, 66, 33, 66, 4320, 4320, 66, 4320, 33, 66, 66, 4320, 66, 33, 33, 66, 4320, 33, 66, 33, 4320, 4320, 66, 4320, 4320, 4320, 33, 66, 4320, 33, 66, 33, 66, 33, 33, 66, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 66, 33, 33, 33, 33, 33, 4320, 33, 66, 33, 4320, 4320, 33, 4320, 33, 66, 66, 4320, 33, 33, 33, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 33, 4320, 66, 66, 66, 4320, 66, 33, 66, 4320, 4320, 66, 4320, 66, 33, 4320, 66, 33, 66, 66, 33, 66, 4320, 33, 66, 4320, 33, 66, 4320, 4320, 66, 33, 4320, 66, 33, 33, 66, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 66, 33, 4320, 4320, 66, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 66, 66, 66, 66, 66, 66, 33, 4320, 66, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 66, 66, 4320, 66, 33, 33]
Prompts retrieved: 282816 . Total input tokens: 63124961 . Total output tokens: 56509939
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 48.04830757481977,
    "estimated_duration": 3600.0202170665025,
    "input_throughput": 6169.667296507213,
    "output_throughput": 5425.59258623163,
    "total_throughput": 11595.259882738843,
    "itl": 81.91573488716195,
    "ttft": 380302.99141505884,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 822,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.515720925512775,
    "arrivals": 94443,
    "finished_requests": 88880,
    "scheduler_time": 112.23103759601034
}
#Debug simulation 
Total elapsed time: 48.048450524918735. Arrivals time: 0.295377132948488 Scheduler time: 47.50851230928674 Scheduler overhead time: 0.09370081638917327 Adapter cache time: 0.02193128503859043 Engine time: 0.0914591564796865 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_192_slots_32_rate_0.4-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_192_slots_32_rate_0.4-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 66, 66, 66, 66, 4320, 66, 33, 4320, 33, 66, 66, 33, 4320, 4320, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 4320, 66, 33, 66, 4320, 4320, 66, 4320, 33, 66, 66, 4320, 66, 33, 33, 66, 4320, 33, 66, 33, 4320, 4320, 66, 4320, 4320, 4320, 33, 66, 4320, 33, 66, 33, 66, 33, 33, 66, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 66, 33, 33, 33, 33, 33, 4320, 33, 66, 33, 4320, 4320, 33, 4320, 33, 66, 66, 4320, 33, 33, 33, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 33, 4320, 66, 66, 66, 4320, 66, 33, 66, 4320, 4320, 66, 4320, 66, 33, 4320, 66, 33, 66, 66, 33, 66, 4320, 33, 66, 4320, 33, 66, 4320, 4320, 66, 33, 4320, 66, 33, 33, 66, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 66, 33, 4320, 4320, 66, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 66, 66, 66, 66, 66, 66, 33, 4320, 66, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 66, 66, 4320, 66, 33, 33]
Prompts retrieved: 282816 . Total input tokens: 63124961 . Total output tokens: 56509939
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 48.042726567946374,
    "estimated_duration": 3600.067917015484,
    "input_throughput": 6169.585550045185,
    "output_throughput": 5425.520698562974,
    "total_throughput": 11595.10624860816,
    "itl": 81.92128465646432,
    "ttft": 380345.0874857239,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 822,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6837745535071074,
    "arrivals": 94443,
    "finished_requests": 88880,
    "scheduler_time": 112.22987318593198
}
#Debug simulation 
Total elapsed time: 48.04288174910471. Arrivals time: 0.3002612735144794 Scheduler time: 47.50052573205903 Scheduler overhead time: 0.09388294816017151 Adapter cache time: 0.021141075063496828 Engine time: 0.08953180490061641 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-32/adapters_192_slots_32_rate_0.4-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-32/adapters_192_slots_32_rate_0.4-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 66, 66, 66, 66, 4320, 66, 33, 4320, 33, 66, 66, 33, 4320, 4320, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 4320, 66, 33, 66, 4320, 4320, 66, 4320, 33, 66, 66, 4320, 66, 33, 33, 66, 4320, 33, 66, 33, 4320, 4320, 66, 4320, 4320, 4320, 33, 66, 4320, 33, 66, 33, 66, 33, 33, 66, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 66, 33, 33, 33, 33, 33, 4320, 33, 66, 33, 4320, 4320, 33, 4320, 33, 66, 66, 4320, 33, 33, 33, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 33, 4320, 66, 66, 66, 4320, 66, 33, 66, 4320, 4320, 66, 4320, 66, 33, 4320, 66, 33, 66, 66, 33, 66, 4320, 33, 66, 4320, 33, 66, 4320, 4320, 66, 33, 4320, 66, 33, 33, 66, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 66, 33, 4320, 4320, 66, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 66, 66, 66, 66, 66, 66, 33, 4320, 66, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 66, 66, 4320, 66, 33, 33]
Prompts retrieved: 282816 . Total input tokens: 63124961 . Total output tokens: 56509939
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 48.08630218124017,
    "estimated_duration": 3600.0257458426154,
    "input_throughput": 6159.135118854607,
    "output_throughput": 5429.869223178211,
    "total_throughput": 11589.004342032817,
    "itl": 81.65523588622477,
    "ttft": 383376.93444585206,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 824,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.694020148366675,
    "arrivals": 94443,
    "finished_requests": 88795,
    "scheduler_time": 112.26419428961675
}
#Debug simulation 
Total elapsed time: 48.08645096095279. Arrivals time: 0.2940227435901761 Scheduler time: 47.545633423142135 Scheduler overhead time: 0.09525126917287707 Adapter cache time: 0.02210171427577734 Engine time: 0.09111825283616781 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_192_slots_32_rate_0.4-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_192_slots_32_rate_0.4-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 66, 66, 66, 66, 4320, 66, 33, 4320, 33, 66, 66, 33, 4320, 4320, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 4320, 66, 33, 66, 4320, 4320, 66, 4320, 33, 66, 66, 4320, 66, 33, 33, 66, 4320, 33, 66, 33, 4320, 4320, 66, 4320, 4320, 4320, 33, 66, 4320, 33, 66, 33, 66, 33, 33, 66, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 66, 33, 33, 33, 33, 33, 4320, 33, 66, 33, 4320, 4320, 33, 4320, 33, 66, 66, 4320, 33, 33, 33, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 33, 4320, 66, 66, 66, 4320, 66, 33, 66, 4320, 4320, 66, 4320, 66, 33, 4320, 66, 33, 66, 66, 33, 66, 4320, 33, 66, 4320, 33, 66, 4320, 4320, 66, 33, 4320, 66, 33, 33, 66, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 66, 33, 4320, 4320, 66, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 66, 66, 66, 66, 66, 66, 33, 4320, 66, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 66, 66, 4320, 66, 33, 33]
Prompts retrieved: 282816 . Total input tokens: 63124961 . Total output tokens: 56509939
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 44.49804128520191,
    "estimated_duration": 3600.051377324646,
    "input_throughput": 6271.956878787575,
    "output_throughput": 5512.943544363824,
    "total_throughput": 11784.900423151399,
    "itl": 86.18302868900689,
    "ttft": 326620.78620669304,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 823,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.571949319320242,
    "arrivals": 94443,
    "finished_requests": 90305,
    "scheduler_time": 111.31815602058471
}
#Debug simulation 
Total elapsed time: 44.4981742631644. Arrivals time: 0.2759915958158672 Scheduler time: 43.98813084047288 Scheduler overhead time: 0.09043741505593061 Adapter cache time: 0.020728664472699165 Engine time: 0.08669566735625267 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-32/adapters_192_slots_32_rate_0.4-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-32/adapters_192_slots_32_rate_0.4-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 66, 66, 66, 66, 4320, 66, 33, 4320, 33, 66, 66, 33, 4320, 4320, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 4320, 66, 33, 66, 4320, 4320, 66, 4320, 33, 66, 66, 4320, 66, 33, 33, 66, 4320, 33, 66, 33, 4320, 4320, 66, 4320, 4320, 4320, 33, 66, 4320, 33, 66, 33, 66, 33, 33, 66, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 66, 33, 33, 33, 33, 33, 4320, 33, 66, 33, 4320, 4320, 33, 4320, 33, 66, 66, 4320, 33, 33, 33, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 33, 4320, 66, 66, 66, 4320, 66, 33, 66, 4320, 4320, 66, 4320, 66, 33, 4320, 66, 33, 66, 66, 33, 66, 4320, 33, 66, 4320, 33, 66, 4320, 4320, 66, 33, 4320, 66, 33, 33, 66, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 66, 33, 4320, 4320, 66, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 66, 66, 66, 66, 66, 66, 33, 4320, 66, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 66, 66, 4320, 66, 33, 33]
Prompts retrieved: 282816 . Total input tokens: 63124961 . Total output tokens: 56509939
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 48.33743642270565,
    "estimated_duration": 3600.0189930674596,
    "input_throughput": 6160.108055736705,
    "output_throughput": 5426.5185927128605,
    "total_throughput": 11586.626648449566,
    "itl": 81.53328678708179,
    "ttft": 384688.45799801336,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 816,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7033683001436306,
    "arrivals": 94443,
    "finished_requests": 88765,
    "scheduler_time": 112.32570270126544
}
#Debug simulation 
Total elapsed time: 48.33757534204051. Arrivals time: 0.29962663585320115 Scheduler time: 47.79369565844536 Scheduler overhead time: 0.09366564732044935 Adapter cache time: 0.021448560059070587 Engine time: 0.09173111943528056 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_192_slots_32_rate_0.4-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_192_slots_32_rate_0.4-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 66, 66, 66, 66, 4320, 66, 33, 4320, 33, 66, 66, 33, 4320, 4320, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 4320, 66, 33, 66, 4320, 4320, 66, 4320, 33, 66, 66, 4320, 66, 33, 33, 66, 4320, 33, 66, 33, 4320, 4320, 66, 4320, 4320, 4320, 33, 66, 4320, 33, 66, 33, 66, 33, 33, 66, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 66, 33, 33, 33, 33, 33, 4320, 33, 66, 33, 4320, 4320, 33, 4320, 33, 66, 66, 4320, 33, 33, 33, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 33, 4320, 66, 66, 66, 4320, 66, 33, 66, 4320, 4320, 66, 4320, 66, 33, 4320, 66, 33, 66, 66, 33, 66, 4320, 33, 66, 4320, 33, 66, 4320, 4320, 66, 33, 4320, 66, 33, 33, 66, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 66, 33, 4320, 4320, 66, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 66, 66, 66, 66, 66, 66, 33, 4320, 66, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 66, 66, 4320, 66, 33, 33]
Prompts retrieved: 282816 . Total input tokens: 63124961 . Total output tokens: 56509939
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 47.98697456298396,
    "estimated_duration": 3600.0482508751643,
    "input_throughput": 6170.435630855741,
    "output_throughput": 5427.338368381643,
    "total_throughput": 11597.773999237383,
    "itl": 81.89950403639718,
    "ttft": 379632.064298242,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 820,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.451841241819734,
    "arrivals": 94443,
    "finished_requests": 88898,
    "scheduler_time": 112.22548650939964
}
#Debug simulation 
Total elapsed time: 47.987122253049165. Arrivals time: 0.299482945818454 Scheduler time: 47.44208865473047 Scheduler overhead time: 0.09346431167796254 Adapter cache time: 0.021900789346545935 Engine time: 0.09282975504174829 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-32/adapters_192_slots_32_rate_0.4-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-32/adapters_192_slots_32_rate_0.4-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [64 64 64]
Adapter prompts. [4320, 33, 4320, 33, 4320, 33, 4320, 33, 33, 33, 66, 66, 66, 66, 4320, 66, 33, 4320, 33, 66, 66, 33, 4320, 4320, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 4320, 66, 33, 66, 4320, 4320, 66, 4320, 33, 66, 66, 4320, 66, 33, 33, 66, 4320, 33, 66, 33, 4320, 4320, 66, 4320, 4320, 4320, 33, 66, 4320, 33, 66, 33, 66, 33, 33, 66, 4320, 4320, 33, 33, 33, 4320, 4320, 4320, 66, 33, 33, 33, 33, 33, 4320, 33, 66, 33, 4320, 4320, 33, 4320, 33, 66, 66, 4320, 33, 33, 33, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 33, 4320, 66, 66, 66, 4320, 66, 33, 66, 4320, 4320, 66, 4320, 66, 33, 4320, 66, 33, 66, 66, 33, 66, 4320, 33, 66, 4320, 33, 66, 4320, 4320, 66, 33, 4320, 66, 33, 33, 66, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 66, 33, 4320, 4320, 66, 4320, 33, 4320, 4320, 4320, 33, 4320, 4320, 4320, 66, 66, 66, 66, 66, 66, 33, 4320, 66, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 66, 66, 4320, 66, 33, 33]
Prompts retrieved: 282816 . Total input tokens: 63124961 . Total output tokens: 56509939
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 47.96385512966663,
    "estimated_duration": 3600.070414746394,
    "input_throughput": 6169.581269583207,
    "output_throughput": 5425.516934333615,
    "total_throughput": 11595.098203916821,
    "itl": 81.91949644555261,
    "ttft": 380350.1342257098,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 822,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7578122020513027,
    "arrivals": 94443,
    "finished_requests": 88880,
    "scheduler_time": 112.22890925065748
}
#Debug simulation 
Total elapsed time: 47.96399600664154. Arrivals time: 0.3033230542205274 Scheduler time: 47.4203045652248 Scheduler overhead time: 0.09314281912520528 Adapter cache time: 0.0214167688973248 Engine time: 0.08844916056841612 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_192_slots_32_rate_0.1-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_192_slots_32_rate_0.1-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [64 64 64]
Adapter prompts. [1080, 270, 1080, 270, 1080, 270, 1080, 270, 270, 270, 540, 540, 540, 540, 1080, 540, 270, 1080, 270, 540, 540, 270, 1080, 1080, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 1080, 540, 270, 540, 1080, 1080, 540, 1080, 270, 540, 540, 1080, 540, 270, 270, 540, 1080, 270, 540, 270, 1080, 1080, 540, 1080, 1080, 1080, 270, 540, 1080, 270, 540, 270, 540, 270, 270, 540, 1080, 1080, 270, 270, 270, 1080, 1080, 1080, 540, 270, 270, 270, 270, 270, 1080, 270, 540, 270, 1080, 1080, 270, 1080, 270, 540, 540, 1080, 270, 270, 270, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 270, 1080, 540, 540, 540, 1080, 540, 270, 540, 1080, 1080, 540, 1080, 540, 270, 1080, 540, 270, 540, 540, 270, 540, 1080, 270, 540, 1080, 270, 540, 1080, 1080, 540, 270, 1080, 540, 270, 270, 540, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 540, 270, 1080, 1080, 540, 1080, 270, 1080, 1080, 1080, 270, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 270, 1080, 540, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 540, 540, 1080, 540, 270, 270]
Prompts retrieved: 120960 . Total input tokens: 26955942 . Total output tokens: 24190742
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 4.820611695758998,
    "estimated_duration": 3599.7404301459173,
    "input_throughput": 2781.117470626677,
    "output_throughput": 2429.3504405942726,
    "total_throughput": 5210.46791122095,
    "itl": 31.35969159793292,
    "ttft": 69533.82520469675,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6720,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.566477639227788,
    "arrivals": 40505,
    "finished_requests": 40070,
    "scheduler_time": 21.484609263743966
}
#Debug simulation 
Total elapsed time: 4.820677143055946. Arrivals time: 0.11086285300552845 Scheduler time: 4.3545252601616085 Scheduler overhead time: 0.12407970009371638 Adapter cache time: 0.06389658665284514 Engine time: 0.11348777543753386 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_192_slots_32_rate_0.1-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_192_slots_32_rate_0.1-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [64 64 64]
Adapter prompts. [1080, 270, 1080, 270, 1080, 270, 1080, 270, 270, 270, 540, 540, 540, 540, 1080, 540, 270, 1080, 270, 540, 540, 270, 1080, 1080, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 1080, 540, 270, 540, 1080, 1080, 540, 1080, 270, 540, 540, 1080, 540, 270, 270, 540, 1080, 270, 540, 270, 1080, 1080, 540, 1080, 1080, 1080, 270, 540, 1080, 270, 540, 270, 540, 270, 270, 540, 1080, 1080, 270, 270, 270, 1080, 1080, 1080, 540, 270, 270, 270, 270, 270, 1080, 270, 540, 270, 1080, 1080, 270, 1080, 270, 540, 540, 1080, 270, 270, 270, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 270, 1080, 540, 540, 540, 1080, 540, 270, 540, 1080, 1080, 540, 1080, 540, 270, 1080, 540, 270, 540, 540, 270, 540, 1080, 270, 540, 1080, 270, 540, 1080, 1080, 540, 270, 1080, 540, 270, 270, 540, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 540, 270, 1080, 1080, 540, 1080, 270, 1080, 1080, 1080, 270, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 270, 1080, 540, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 540, 540, 1080, 540, 270, 270]
Prompts retrieved: 120960 . Total input tokens: 26955942 . Total output tokens: 24190742
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.9030893365852535,
    "estimated_duration": 3599.7503190142834,
    "input_throughput": 2781.391516826551,
    "output_throughput": 2429.795187127059,
    "total_throughput": 5211.18670395361,
    "itl": 31.379690278875966,
    "ttft": 69761.37927057335,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6710,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.884755408399634,
    "arrivals": 40505,
    "finished_requests": 40069,
    "scheduler_time": 21.53091656755314
}
#Debug simulation 
Total elapsed time: 4.903171175625175. Arrivals time: 0.11066514858976007 Scheduler time: 4.437970300205052 Scheduler overhead time: 0.12491835653781891 Adapter cache time: 0.061050246469676495 Engine time: 0.11522594233974814 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-32/adapters_192_slots_32_rate_0.1-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-32/adapters_192_slots_32_rate_0.1-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [64 64 64]
Adapter prompts. [1080, 270, 1080, 270, 1080, 270, 1080, 270, 270, 270, 540, 540, 540, 540, 1080, 540, 270, 1080, 270, 540, 540, 270, 1080, 1080, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 1080, 540, 270, 540, 1080, 1080, 540, 1080, 270, 540, 540, 1080, 540, 270, 270, 540, 1080, 270, 540, 270, 1080, 1080, 540, 1080, 1080, 1080, 270, 540, 1080, 270, 540, 270, 540, 270, 270, 540, 1080, 1080, 270, 270, 270, 1080, 1080, 1080, 540, 270, 270, 270, 270, 270, 1080, 270, 540, 270, 1080, 1080, 270, 1080, 270, 540, 540, 1080, 270, 270, 270, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 270, 1080, 540, 540, 540, 1080, 540, 270, 540, 1080, 1080, 540, 1080, 540, 270, 1080, 540, 270, 540, 540, 270, 540, 1080, 270, 540, 1080, 270, 540, 1080, 1080, 540, 270, 1080, 540, 270, 270, 540, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 540, 270, 1080, 1080, 540, 1080, 270, 1080, 1080, 1080, 270, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 270, 1080, 540, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 540, 540, 1080, 540, 270, 270]
Prompts retrieved: 120960 . Total input tokens: 26955942 . Total output tokens: 24190742
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.866868192795664,
    "estimated_duration": 3599.730640716919,
    "input_throughput": 2781.86425582266,
    "output_throughput": 2429.4417757486117,
    "total_throughput": 5211.306031571272,
    "itl": 31.377167572711812,
    "ttft": 69019.7916014419,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6723,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.96637554086713,
    "arrivals": 40505,
    "finished_requests": 40077,
    "scheduler_time": 21.534308596966127
}
#Debug simulation 
Total elapsed time: 4.866978046949953. Arrivals time: 0.11524697206914425 Scheduler time: 4.397571442183107 Scheduler overhead time: 0.12537043681368232 Adapter cache time: 0.06125597609207034 Engine time: 0.11387398652732372 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_192_slots_32_rate_0.1-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_192_slots_32_rate_0.1-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [64 64 64]
Adapter prompts. [1080, 270, 1080, 270, 1080, 270, 1080, 270, 270, 270, 540, 540, 540, 540, 1080, 540, 270, 1080, 270, 540, 540, 270, 1080, 1080, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 1080, 540, 270, 540, 1080, 1080, 540, 1080, 270, 540, 540, 1080, 540, 270, 270, 540, 1080, 270, 540, 270, 1080, 1080, 540, 1080, 1080, 1080, 270, 540, 1080, 270, 540, 270, 540, 270, 270, 540, 1080, 1080, 270, 270, 270, 1080, 1080, 1080, 540, 270, 270, 270, 270, 270, 1080, 270, 540, 270, 1080, 1080, 270, 1080, 270, 540, 540, 1080, 270, 270, 270, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 270, 1080, 540, 540, 540, 1080, 540, 270, 540, 1080, 1080, 540, 1080, 540, 270, 1080, 540, 270, 540, 540, 270, 540, 1080, 270, 540, 1080, 270, 540, 1080, 1080, 540, 270, 1080, 540, 270, 270, 540, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 540, 270, 1080, 1080, 540, 1080, 270, 1080, 1080, 1080, 270, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 270, 1080, 540, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 540, 540, 1080, 540, 270, 270]
Prompts retrieved: 120960 . Total input tokens: 26955942 . Total output tokens: 24190742
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 4.820602773223072,
    "estimated_duration": 3599.7361982868556,
    "input_throughput": 2782.1483154143966,
    "output_throughput": 2429.7527702620314,
    "total_throughput": 5211.901085676428,
    "itl": 31.364640067779995,
    "ttft": 68913.56297340644,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6703,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.957969235353826,
    "arrivals": 40505,
    "finished_requests": 40079,
    "scheduler_time": 21.540942706206103
}
#Debug simulation 
Total elapsed time: 4.820728683378547. Arrivals time: 0.11093683587387204 Scheduler time: 4.358597679063678 Scheduler overhead time: 0.12381426198408008 Adapter cache time: 0.060583649668842554 Engine time: 0.11346648773178458 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-32/adapters_192_slots_32_rate_0.1-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-32/adapters_192_slots_32_rate_0.1-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [64 64 64]
Adapter prompts. [1080, 270, 1080, 270, 1080, 270, 1080, 270, 270, 270, 540, 540, 540, 540, 1080, 540, 270, 1080, 270, 540, 540, 270, 1080, 1080, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 1080, 540, 270, 540, 1080, 1080, 540, 1080, 270, 540, 540, 1080, 540, 270, 270, 540, 1080, 270, 540, 270, 1080, 1080, 540, 1080, 1080, 1080, 270, 540, 1080, 270, 540, 270, 540, 270, 270, 540, 1080, 1080, 270, 270, 270, 1080, 1080, 1080, 540, 270, 270, 270, 270, 270, 1080, 270, 540, 270, 1080, 1080, 270, 1080, 270, 540, 540, 1080, 270, 270, 270, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 270, 1080, 540, 540, 540, 1080, 540, 270, 540, 1080, 1080, 540, 1080, 540, 270, 1080, 540, 270, 540, 540, 270, 540, 1080, 270, 540, 1080, 270, 540, 1080, 1080, 540, 270, 1080, 540, 270, 270, 540, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 540, 270, 1080, 1080, 540, 1080, 270, 1080, 1080, 1080, 270, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 270, 1080, 540, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 540, 540, 1080, 540, 270, 270]
Prompts retrieved: 120960 . Total input tokens: 26955942 . Total output tokens: 24190742
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 4.879231168888509,
    "estimated_duration": 3599.7278248110547,
    "input_throughput": 2781.6861405419136,
    "output_throughput": 2429.1528208688883,
    "total_throughput": 5210.838961410802,
    "itl": 31.38620367486103,
    "ttft": 69504.85828281724,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6722,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.241619439161294,
    "arrivals": 40505,
    "finished_requests": 40071,
    "scheduler_time": 21.518516223132533
}
#Debug simulation 
Total elapsed time: 4.879333628341556. Arrivals time: 0.11093124561011791 Scheduler time: 4.41662319470197 Scheduler overhead time: 0.12385583436116576 Adapter cache time: 0.060987409204244614 Engine time: 0.11331318691372871 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_192_slots_32_rate_0.1-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_192_slots_32_rate_0.1-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [64 64 64]
Adapter prompts. [1080, 270, 1080, 270, 1080, 270, 1080, 270, 270, 270, 540, 540, 540, 540, 1080, 540, 270, 1080, 270, 540, 540, 270, 1080, 1080, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 1080, 540, 270, 540, 1080, 1080, 540, 1080, 270, 540, 540, 1080, 540, 270, 270, 540, 1080, 270, 540, 270, 1080, 1080, 540, 1080, 1080, 1080, 270, 540, 1080, 270, 540, 270, 540, 270, 270, 540, 1080, 1080, 270, 270, 270, 1080, 1080, 1080, 540, 270, 270, 270, 270, 270, 1080, 270, 540, 270, 1080, 1080, 270, 1080, 270, 540, 540, 1080, 270, 270, 270, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 270, 1080, 540, 540, 540, 1080, 540, 270, 540, 1080, 1080, 540, 1080, 540, 270, 1080, 540, 270, 540, 540, 270, 540, 1080, 270, 540, 1080, 270, 540, 1080, 1080, 540, 270, 1080, 540, 270, 270, 540, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 540, 270, 1080, 1080, 540, 1080, 270, 1080, 1080, 1080, 270, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 270, 1080, 540, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 540, 540, 1080, 540, 270, 270]
Prompts retrieved: 120960 . Total input tokens: 26955942 . Total output tokens: 24190742
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 4.876109241973609,
    "estimated_duration": 3599.736438950022,
    "input_throughput": 2783.200984270476,
    "output_throughput": 2431.0146446589606,
    "total_throughput": 5214.215628929436,
    "itl": 31.37019880725403,
    "ttft": 67072.37165387308,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6716,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.081177780563497,
    "arrivals": 40505,
    "finished_requests": 40098,
    "scheduler_time": 21.50826076965288
}
#Debug simulation 
Total elapsed time: 4.876189052127302. Arrivals time: 0.11087811505421996 Scheduler time: 4.411217194516212 Scheduler overhead time: 0.12519207084551454 Adapter cache time: 0.06113930931314826 Engine time: 0.11399730201810598 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-32/adapters_192_slots_32_rate_0.1-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-32/adapters_192_slots_32_rate_0.1-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [64 64 64]
Adapter prompts. [1080, 270, 1080, 270, 1080, 270, 1080, 270, 270, 270, 540, 540, 540, 540, 1080, 540, 270, 1080, 270, 540, 540, 270, 1080, 1080, 270, 540, 270, 540, 270, 270, 540, 270, 270, 540, 540, 1080, 540, 270, 540, 1080, 1080, 540, 1080, 270, 540, 540, 1080, 540, 270, 270, 540, 1080, 270, 540, 270, 1080, 1080, 540, 1080, 1080, 1080, 270, 540, 1080, 270, 540, 270, 540, 270, 270, 540, 1080, 1080, 270, 270, 270, 1080, 1080, 1080, 540, 270, 270, 270, 270, 270, 1080, 270, 540, 270, 1080, 1080, 270, 1080, 270, 540, 540, 1080, 270, 270, 270, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 270, 1080, 540, 540, 540, 1080, 540, 270, 540, 1080, 1080, 540, 1080, 540, 270, 1080, 540, 270, 540, 540, 270, 540, 1080, 270, 540, 1080, 270, 540, 1080, 1080, 540, 270, 1080, 540, 270, 270, 540, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 540, 270, 1080, 1080, 540, 1080, 270, 1080, 1080, 1080, 270, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 270, 1080, 540, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 540, 540, 1080, 540, 270, 270]
Prompts retrieved: 120960 . Total input tokens: 26955942 . Total output tokens: 24190742
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 5.015699598938227,
    "estimated_duration": 3599.7384685203033,
    "input_throughput": 2781.6345791687404,
    "output_throughput": 2429.5067756949948,
    "total_throughput": 5211.141354863735,
    "itl": 31.404013253380423,
    "ttft": 69488.67010069323,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6726,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.538008496238007,
    "arrivals": 40505,
    "finished_requests": 40071,
    "scheduler_time": 21.520121674350133
}
#Debug simulation 
Total elapsed time: 5.015784432180226. Arrivals time: 0.11066135810688138 Scheduler time: 4.551125469151884 Scheduler overhead time: 0.12421208247542381 Adapter cache time: 0.060931164771318436 Engine time: 0.11493927845731378 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_192_slots_32_rate_0.1-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_192_slots_32_rate_0.1-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [64 64 64]
Adapter prompts. [1080, 135, 1080, 135, 1080, 135, 1080, 135, 135, 135, 540, 540, 540, 540, 1080, 540, 135, 1080, 135, 540, 540, 135, 1080, 1080, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 1080, 540, 135, 540, 1080, 1080, 540, 1080, 135, 540, 540, 1080, 540, 135, 135, 540, 1080, 135, 540, 135, 1080, 1080, 540, 1080, 1080, 1080, 135, 540, 1080, 135, 540, 135, 540, 135, 135, 540, 1080, 1080, 135, 135, 135, 1080, 1080, 1080, 540, 135, 135, 135, 135, 135, 1080, 135, 540, 135, 1080, 1080, 135, 1080, 135, 540, 540, 1080, 135, 135, 135, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 135, 1080, 540, 540, 540, 1080, 540, 135, 540, 1080, 1080, 540, 1080, 540, 135, 1080, 540, 135, 540, 540, 135, 540, 1080, 135, 540, 1080, 135, 540, 1080, 1080, 540, 135, 1080, 540, 135, 135, 540, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 540, 135, 1080, 1080, 540, 1080, 135, 1080, 1080, 1080, 135, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 135, 1080, 540, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 540, 540, 1080, 540, 135, 135]
Prompts retrieved: 112320 . Total input tokens: 25029474 . Total output tokens: 22460635
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 4.369383303914219,
    "estimated_duration": 3600.016425946006,
    "input_throughput": 2568.621891098752,
    "output_throughput": 2325.8838319882666,
    "total_throughput": 4894.505723087018,
    "itl": 30.85648215728797,
    "ttft": 54391.28830904576,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7018,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.478502986920045,
    "arrivals": 37714,
    "finished_requests": 37407,
    "scheduler_time": 18.062883610556156
}
#Debug simulation 
Total elapsed time: 4.369450413621962. Arrivals time: 0.10219743475317955 Scheduler time: 3.91871554357931 Scheduler overhead time: 0.1203045635484159 Adapter cache time: 0.06152148963883519 Engine time: 0.1128377765417099 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_192_slots_32_rate_0.1-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_192_slots_32_rate_0.1-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [64 64 64]
Adapter prompts. [1080, 135, 1080, 135, 1080, 135, 1080, 135, 135, 135, 540, 540, 540, 540, 1080, 540, 135, 1080, 135, 540, 540, 135, 1080, 1080, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 1080, 540, 135, 540, 1080, 1080, 540, 1080, 135, 540, 540, 1080, 540, 135, 135, 540, 1080, 135, 540, 135, 1080, 1080, 540, 1080, 1080, 1080, 135, 540, 1080, 135, 540, 135, 540, 135, 135, 540, 1080, 1080, 135, 135, 135, 1080, 1080, 1080, 540, 135, 135, 135, 135, 135, 1080, 135, 540, 135, 1080, 1080, 135, 1080, 135, 540, 540, 1080, 135, 135, 135, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 135, 1080, 540, 540, 540, 1080, 540, 135, 540, 1080, 1080, 540, 1080, 540, 135, 1080, 540, 135, 540, 540, 135, 540, 1080, 135, 540, 1080, 135, 540, 1080, 1080, 540, 135, 1080, 540, 135, 135, 540, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 540, 135, 1080, 1080, 540, 1080, 135, 1080, 1080, 1080, 135, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 135, 1080, 540, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 540, 540, 1080, 540, 135, 135]
Prompts retrieved: 112320 . Total input tokens: 25029474 . Total output tokens: 22460635
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.317072527017444,
    "estimated_duration": 3600.0142069145636,
    "input_throughput": 2568.671529750843,
    "output_throughput": 2325.552489187354,
    "total_throughput": 4894.224018938196,
    "itl": 30.86638492218115,
    "ttft": 54327.34611944507,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7003,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.82825837234829,
    "arrivals": 37714,
    "finished_requests": 37408,
    "scheduler_time": 18.07129400421005
}
#Debug simulation 
Total elapsed time: 4.317167521920055. Arrivals time: 0.10188362468034029 Scheduler time: 3.8664898797869682 Scheduler overhead time: 0.12006666930392385 Adapter cache time: 0.061253136955201626 Engine time: 0.11350925313308835 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-32/adapters_192_slots_32_rate_0.1-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-32/adapters_192_slots_32_rate_0.1-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [64 64 64]
Adapter prompts. [1080, 135, 1080, 135, 1080, 135, 1080, 135, 135, 135, 540, 540, 540, 540, 1080, 540, 135, 1080, 135, 540, 540, 135, 1080, 1080, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 1080, 540, 135, 540, 1080, 1080, 540, 1080, 135, 540, 540, 1080, 540, 135, 135, 540, 1080, 135, 540, 135, 1080, 1080, 540, 1080, 1080, 1080, 135, 540, 1080, 135, 540, 135, 540, 135, 135, 540, 1080, 1080, 135, 135, 135, 1080, 1080, 1080, 540, 135, 135, 135, 135, 135, 1080, 135, 540, 135, 1080, 1080, 135, 1080, 135, 540, 540, 1080, 135, 135, 135, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 135, 1080, 540, 540, 540, 1080, 540, 135, 540, 1080, 1080, 540, 1080, 540, 135, 1080, 540, 135, 540, 540, 135, 540, 1080, 135, 540, 1080, 135, 540, 1080, 1080, 540, 135, 1080, 540, 135, 135, 540, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 540, 135, 1080, 1080, 540, 1080, 135, 1080, 1080, 1080, 135, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 135, 1080, 540, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 540, 540, 1080, 540, 135, 135]
Prompts retrieved: 112320 . Total input tokens: 25029474 . Total output tokens: 22460635
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.372737482190132,
    "estimated_duration": 3600.0168153500917,
    "input_throughput": 2568.988833764827,
    "output_throughput": 2326.0096909257586,
    "total_throughput": 4894.998524690585,
    "itl": 30.87210433651226,
    "ttft": 53919.58975938283,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6980,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.797123524211166,
    "arrivals": 37714,
    "finished_requests": 37413,
    "scheduler_time": 18.092979435606882
}
#Debug simulation 
Total elapsed time: 4.372814904898405. Arrivals time: 0.10337928310036659 Scheduler time: 3.9196487944573164 Scheduler overhead time: 0.12113965721800923 Adapter cache time: 0.061685876455157995 Engine time: 0.11305719474330544 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_192_slots_32_rate_0.1-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_192_slots_32_rate_0.1-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [64 64 64]
Adapter prompts. [1080, 135, 1080, 135, 1080, 135, 1080, 135, 135, 135, 540, 540, 540, 540, 1080, 540, 135, 1080, 135, 540, 540, 135, 1080, 1080, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 1080, 540, 135, 540, 1080, 1080, 540, 1080, 135, 540, 540, 1080, 540, 135, 135, 540, 1080, 135, 540, 135, 1080, 1080, 540, 1080, 1080, 1080, 135, 540, 1080, 135, 540, 135, 540, 135, 135, 540, 1080, 1080, 135, 135, 135, 1080, 1080, 1080, 540, 135, 135, 135, 135, 135, 1080, 135, 540, 135, 1080, 1080, 135, 1080, 135, 540, 540, 1080, 135, 135, 135, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 135, 1080, 540, 540, 540, 1080, 540, 135, 540, 1080, 1080, 540, 1080, 540, 135, 1080, 540, 135, 540, 540, 135, 540, 1080, 135, 540, 1080, 135, 540, 1080, 1080, 540, 135, 1080, 540, 135, 135, 540, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 540, 135, 1080, 1080, 540, 1080, 135, 1080, 1080, 1080, 135, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 135, 1080, 540, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 540, 540, 1080, 540, 135, 135]
Prompts retrieved: 112320 . Total input tokens: 25029474 . Total output tokens: 22460635
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 4.3727559060789645,
    "estimated_duration": 3600.031895080559,
    "input_throughput": 2568.883073685394,
    "output_throughput": 2325.6707840397194,
    "total_throughput": 4894.553857725113,
    "itl": 30.85578751898724,
    "ttft": 54449.207811430315,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7002,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.876101397317246,
    "arrivals": 37714,
    "finished_requests": 37407,
    "scheduler_time": 18.069800304526005
}
#Debug simulation 
Total elapsed time: 4.372836458031088. Arrivals time: 0.10343533055856824 Scheduler time: 3.919218576513231 Scheduler overhead time: 0.12146135373041034 Adapter cache time: 0.0617881678044796 Engine time: 0.11274626338854432 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-32/adapters_192_slots_32_rate_0.1-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-32/adapters_192_slots_32_rate_0.1-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [64 64 64]
Adapter prompts. [1080, 135, 1080, 135, 1080, 135, 1080, 135, 135, 135, 540, 540, 540, 540, 1080, 540, 135, 1080, 135, 540, 540, 135, 1080, 1080, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 1080, 540, 135, 540, 1080, 1080, 540, 1080, 135, 540, 540, 1080, 540, 135, 135, 540, 1080, 135, 540, 135, 1080, 1080, 540, 1080, 1080, 1080, 135, 540, 1080, 135, 540, 135, 540, 135, 135, 540, 1080, 1080, 135, 135, 135, 1080, 1080, 1080, 540, 135, 135, 135, 135, 135, 1080, 135, 540, 135, 1080, 1080, 135, 1080, 135, 540, 540, 1080, 135, 135, 135, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 135, 1080, 540, 540, 540, 1080, 540, 135, 540, 1080, 1080, 540, 1080, 540, 135, 1080, 540, 135, 540, 540, 135, 540, 1080, 135, 540, 1080, 135, 540, 1080, 1080, 540, 135, 1080, 540, 135, 135, 540, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 540, 135, 1080, 1080, 540, 1080, 135, 1080, 1080, 1080, 135, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 135, 1080, 540, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 540, 540, 1080, 540, 135, 135]
Prompts retrieved: 112320 . Total input tokens: 25029474 . Total output tokens: 22460635
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 4.384865772910416,
    "estimated_duration": 3600.0207761694533,
    "input_throughput": 2568.6565647655398,
    "output_throughput": 2325.8107440449626,
    "total_throughput": 4894.467308810503,
    "itl": 30.877378696093974,
    "ttft": 54416.38567935455,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7009,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.18333056399499,
    "arrivals": 37714,
    "finished_requests": 37407,
    "scheduler_time": 18.075879775157656
}
#Debug simulation 
Total elapsed time: 4.384976475965232. Arrivals time: 0.10427822405472398 Scheduler time: 3.9305021800100803 Scheduler overhead time: 0.12039555981755257 Adapter cache time: 0.06181618198752403 Engine time: 0.11387344542890787 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_192_slots_32_rate_0.1-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_192_slots_32_rate_0.1-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [64 64 64]
Adapter prompts. [1080, 135, 1080, 135, 1080, 135, 1080, 135, 135, 135, 540, 540, 540, 540, 1080, 540, 135, 1080, 135, 540, 540, 135, 1080, 1080, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 1080, 540, 135, 540, 1080, 1080, 540, 1080, 135, 540, 540, 1080, 540, 135, 135, 540, 1080, 135, 540, 135, 1080, 1080, 540, 1080, 1080, 1080, 135, 540, 1080, 135, 540, 135, 540, 135, 135, 540, 1080, 1080, 135, 135, 135, 1080, 1080, 1080, 540, 135, 135, 135, 135, 135, 1080, 135, 540, 135, 1080, 1080, 135, 1080, 135, 540, 540, 1080, 135, 135, 135, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 135, 1080, 540, 540, 540, 1080, 540, 135, 540, 1080, 1080, 540, 1080, 540, 135, 1080, 540, 135, 540, 540, 135, 540, 1080, 135, 540, 1080, 135, 540, 1080, 1080, 540, 135, 1080, 540, 135, 135, 540, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 540, 135, 1080, 1080, 540, 1080, 135, 1080, 1080, 1080, 135, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 135, 1080, 540, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 540, 540, 1080, 540, 135, 135]
Prompts retrieved: 112320 . Total input tokens: 25029474 . Total output tokens: 22460635
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 4.316281055100262,
    "estimated_duration": 3600.02905520172,
    "input_throughput": 2568.456492494028,
    "output_throughput": 2325.471231378966,
    "total_throughput": 4893.927723872995,
    "itl": 30.84872383275989,
    "ttft": 54343.70081853796,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6987,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.891481410481717,
    "arrivals": 37714,
    "finished_requests": 37409,
    "scheduler_time": 18.084770841202538
}
#Debug simulation 
Total elapsed time: 4.316345556173474. Arrivals time: 0.10167641984298825 Scheduler time: 3.867299026809633 Scheduler overhead time: 0.11906168702989817 Adapter cache time: 0.06158630084246397 Engine time: 0.11301839025691152 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-32/adapters_192_slots_32_rate_0.1-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-32/adapters_192_slots_32_rate_0.1-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [64 64 64]
Adapter prompts. [1080, 135, 1080, 135, 1080, 135, 1080, 135, 135, 135, 540, 540, 540, 540, 1080, 540, 135, 1080, 135, 540, 540, 135, 1080, 1080, 135, 540, 135, 540, 135, 135, 540, 135, 135, 540, 540, 1080, 540, 135, 540, 1080, 1080, 540, 1080, 135, 540, 540, 1080, 540, 135, 135, 540, 1080, 135, 540, 135, 1080, 1080, 540, 1080, 1080, 1080, 135, 540, 1080, 135, 540, 135, 540, 135, 135, 540, 1080, 1080, 135, 135, 135, 1080, 1080, 1080, 540, 135, 135, 135, 135, 135, 1080, 135, 540, 135, 1080, 1080, 135, 1080, 135, 540, 540, 1080, 135, 135, 135, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 135, 1080, 540, 540, 540, 1080, 540, 135, 540, 1080, 1080, 540, 1080, 540, 135, 1080, 540, 135, 540, 540, 135, 540, 1080, 135, 540, 1080, 135, 540, 1080, 1080, 540, 135, 1080, 540, 135, 135, 540, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 540, 135, 1080, 1080, 540, 1080, 135, 1080, 1080, 1080, 135, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 135, 1080, 540, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 540, 540, 1080, 540, 135, 135]
Prompts retrieved: 112320 . Total input tokens: 25029474 . Total output tokens: 22460635
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 4.345685902051628,
    "estimated_duration": 3600.0311612101054,
    "input_throughput": 2568.16499246419,
    "output_throughput": 2325.640702839286,
    "total_throughput": 4893.805695303476,
    "itl": 30.87612892957124,
    "ttft": 54356.32243130459,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6995,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.427091261258344,
    "arrivals": 37714,
    "finished_requests": 37408,
    "scheduler_time": 18.09037656473415
}
#Debug simulation 
Total elapsed time: 4.345771845895797. Arrivals time: 0.10311478888615966 Scheduler time: 3.896050510928035 Scheduler overhead time: 0.11955428775399923 Adapter cache time: 0.0612708549015224 Engine time: 0.11186854960396886 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_192_slots_32_rate_0.1-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_192_slots_32_rate_0.1-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 540, 540, 540, 540, 1080, 540, 66, 1080, 66, 540, 540, 66, 1080, 1080, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 1080, 540, 66, 540, 1080, 1080, 540, 1080, 66, 540, 540, 1080, 540, 66, 66, 540, 1080, 66, 540, 66, 1080, 1080, 540, 1080, 1080, 1080, 66, 540, 1080, 66, 540, 66, 540, 66, 66, 540, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 540, 66, 66, 66, 66, 66, 1080, 66, 540, 66, 1080, 1080, 66, 1080, 66, 540, 540, 1080, 66, 66, 66, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 66, 1080, 540, 540, 540, 1080, 540, 66, 540, 1080, 1080, 540, 1080, 540, 66, 1080, 540, 66, 540, 540, 66, 540, 1080, 66, 540, 1080, 66, 540, 1080, 1080, 540, 66, 1080, 540, 66, 66, 540, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 540, 66, 1080, 1080, 540, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 66, 1080, 540, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 540, 540, 1080, 540, 66, 66]
Prompts retrieved: 107904 . Total input tokens: 24015577 . Total output tokens: 21599596
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 3.898142132908106,
    "estimated_duration": 3599.981984797525,
    "input_throughput": 2481.592696220801,
    "output_throughput": 2184.9003781729725,
    "total_throughput": 4666.493074393773,
    "itl": 30.062745598328284,
    "ttft": 46059.05778256289,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7435,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.754726376140418,
    "arrivals": 36267,
    "finished_requests": 36005,
    "scheduler_time": 14.430884184685048
}
#Debug simulation 
Total elapsed time: 3.898206979036331. Arrivals time: 0.09638166101649404 Scheduler time: 3.4549949509091675 Scheduler overhead time: 0.11634173896163702 Adapter cache time: 0.06326636532321572 Engine time: 0.11280811997130513 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_192_slots_32_rate_0.1-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_192_slots_32_rate_0.1-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 540, 540, 540, 540, 1080, 540, 66, 1080, 66, 540, 540, 66, 1080, 1080, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 1080, 540, 66, 540, 1080, 1080, 540, 1080, 66, 540, 540, 1080, 540, 66, 66, 540, 1080, 66, 540, 66, 1080, 1080, 540, 1080, 1080, 1080, 66, 540, 1080, 66, 540, 66, 540, 66, 66, 540, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 540, 66, 66, 66, 66, 66, 1080, 66, 540, 66, 1080, 1080, 66, 1080, 66, 540, 540, 1080, 66, 66, 66, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 66, 1080, 540, 540, 540, 1080, 540, 66, 540, 1080, 1080, 540, 1080, 540, 66, 1080, 540, 66, 540, 540, 66, 540, 1080, 66, 540, 1080, 66, 540, 1080, 1080, 540, 66, 1080, 540, 66, 66, 540, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 540, 66, 1080, 1080, 540, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 66, 1080, 540, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 540, 540, 1080, 540, 66, 66]
Prompts retrieved: 107904 . Total input tokens: 24015577 . Total output tokens: 21599596
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 3.9289597938768566,
    "estimated_duration": 3599.98620390907,
    "input_throughput": 2480.601172944262,
    "output_throughput": 2184.806706053328,
    "total_throughput": 4665.40787899759,
    "itl": 30.082328680178186,
    "ttft": 47358.176490598395,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7490,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.384518718982985,
    "arrivals": 36267,
    "finished_requests": 35991,
    "scheduler_time": 14.425789895241907
}
#Debug simulation 
Total elapsed time: 3.929037634283304. Arrivals time: 0.09711073338985443 Scheduler time: 3.485200170893222 Scheduler overhead time: 0.11590554751455784 Adapter cache time: 0.0638488344848156 Engine time: 0.11269364459440112 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-32/adapters_192_slots_32_rate_0.1-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-32/adapters_192_slots_32_rate_0.1-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 540, 540, 540, 540, 1080, 540, 66, 1080, 66, 540, 540, 66, 1080, 1080, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 1080, 540, 66, 540, 1080, 1080, 540, 1080, 66, 540, 540, 1080, 540, 66, 66, 540, 1080, 66, 540, 66, 1080, 1080, 540, 1080, 1080, 1080, 66, 540, 1080, 66, 540, 66, 540, 66, 66, 540, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 540, 66, 66, 66, 66, 66, 1080, 66, 540, 66, 1080, 1080, 66, 1080, 66, 540, 540, 1080, 66, 66, 66, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 66, 1080, 540, 540, 540, 1080, 540, 66, 540, 1080, 1080, 540, 1080, 540, 66, 1080, 540, 66, 540, 540, 66, 540, 1080, 66, 540, 1080, 66, 540, 1080, 1080, 540, 66, 1080, 540, 66, 66, 540, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 540, 66, 1080, 1080, 540, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 66, 1080, 540, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 540, 540, 1080, 540, 66, 66]
Prompts retrieved: 107904 . Total input tokens: 24015577 . Total output tokens: 21599596
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 3.957515051122755,
    "estimated_duration": 3599.9847709768214,
    "input_throughput": 2481.0713289702157,
    "output_throughput": 2184.363684923663,
    "total_throughput": 4665.435013893879,
    "itl": 30.08315359050378,
    "ttft": 47667.17838820504,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7478,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.39778227951386,
    "arrivals": 36267,
    "finished_requests": 35989,
    "scheduler_time": 14.441417563882395
}
#Debug simulation 
Total elapsed time: 3.957580493763089. Arrivals time: 0.09734377637505531 Scheduler time: 3.510988130234182 Scheduler overhead time: 0.11785919452086091 Adapter cache time: 0.0637523247860372 Engine time: 0.11277161771431565 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_192_slots_32_rate_0.1-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_192_slots_32_rate_0.1-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 540, 540, 540, 540, 1080, 540, 66, 1080, 66, 540, 540, 66, 1080, 1080, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 1080, 540, 66, 540, 1080, 1080, 540, 1080, 66, 540, 540, 1080, 540, 66, 66, 540, 1080, 66, 540, 66, 1080, 1080, 540, 1080, 1080, 1080, 66, 540, 1080, 66, 540, 66, 540, 66, 66, 540, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 540, 66, 66, 66, 66, 66, 1080, 66, 540, 66, 1080, 1080, 66, 1080, 66, 540, 540, 1080, 66, 66, 66, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 66, 1080, 540, 540, 540, 1080, 540, 66, 540, 1080, 1080, 540, 1080, 540, 66, 1080, 540, 66, 540, 540, 66, 540, 1080, 66, 540, 1080, 66, 540, 1080, 1080, 540, 66, 1080, 540, 66, 66, 540, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 540, 66, 1080, 1080, 540, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 66, 1080, 540, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 540, 540, 1080, 540, 66, 66]
Prompts retrieved: 107904 . Total input tokens: 24015577 . Total output tokens: 21599596
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 3.9726971769705415,
    "estimated_duration": 3600.0149465545674,
    "input_throughput": 2480.883588705018,
    "output_throughput": 2184.7870402670237,
    "total_throughput": 4665.670628972042,
    "itl": 30.075750315651547,
    "ttft": 47492.66049452614,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7442,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.24892687165537,
    "arrivals": 36267,
    "finished_requests": 35991,
    "scheduler_time": 14.444841633976932
}
#Debug simulation 
Total elapsed time: 3.972777994349599. Arrivals time: 0.09789676172658801 Scheduler time: 3.525085257831961 Scheduler overhead time: 0.11694352701306343 Adapter cache time: 0.06410659570246935 Engine time: 0.1140545611269772 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-32/adapters_192_slots_32_rate_0.1-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-32/adapters_192_slots_32_rate_0.1-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 540, 540, 540, 540, 1080, 540, 66, 1080, 66, 540, 540, 66, 1080, 1080, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 1080, 540, 66, 540, 1080, 1080, 540, 1080, 66, 540, 540, 1080, 540, 66, 66, 540, 1080, 66, 540, 66, 1080, 1080, 540, 1080, 1080, 1080, 66, 540, 1080, 66, 540, 66, 540, 66, 66, 540, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 540, 66, 66, 66, 66, 66, 1080, 66, 540, 66, 1080, 1080, 66, 1080, 66, 540, 540, 1080, 66, 66, 66, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 66, 1080, 540, 540, 540, 1080, 540, 66, 540, 1080, 1080, 540, 1080, 540, 66, 1080, 540, 66, 540, 540, 66, 540, 1080, 66, 540, 1080, 66, 540, 1080, 1080, 540, 66, 1080, 540, 66, 66, 540, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 540, 66, 1080, 1080, 540, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 66, 1080, 540, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 540, 540, 1080, 540, 66, 66]
Prompts retrieved: 107904 . Total input tokens: 24015577 . Total output tokens: 21599596
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 3.897624116856605,
    "estimated_duration": 3600.0062005193054,
    "input_throughput": 2482.69600166542,
    "output_throughput": 2184.8226258236473,
    "total_throughput": 4667.5186274890675,
    "itl": 30.086101286904835,
    "ttft": 44958.66784774263,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7491,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.744667401256955,
    "arrivals": 36267,
    "finished_requests": 36015,
    "scheduler_time": 14.422126922993211
}
#Debug simulation 
Total elapsed time: 3.8977004531770945. Arrivals time: 0.09688077541068196 Scheduler time: 3.4548953836783767 Scheduler overhead time: 0.11588548729196191 Adapter cache time: 0.0637080492451787 Engine time: 0.1119226492010057 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_192_slots_32_rate_0.1-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_192_slots_32_rate_0.1-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 540, 540, 540, 540, 1080, 540, 66, 1080, 66, 540, 540, 66, 1080, 1080, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 1080, 540, 66, 540, 1080, 1080, 540, 1080, 66, 540, 540, 1080, 540, 66, 66, 540, 1080, 66, 540, 66, 1080, 1080, 540, 1080, 1080, 1080, 66, 540, 1080, 66, 540, 66, 540, 66, 66, 540, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 540, 66, 66, 66, 66, 66, 1080, 66, 540, 66, 1080, 1080, 66, 1080, 66, 540, 540, 1080, 66, 66, 66, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 66, 1080, 540, 540, 540, 1080, 540, 66, 540, 1080, 1080, 540, 1080, 540, 66, 1080, 540, 66, 540, 540, 66, 540, 1080, 66, 540, 1080, 66, 540, 1080, 1080, 540, 66, 1080, 540, 66, 66, 540, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 540, 66, 1080, 1080, 540, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 66, 1080, 540, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 540, 540, 1080, 540, 66, 66]
Prompts retrieved: 107904 . Total input tokens: 24015577 . Total output tokens: 21599596
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 3.9596803546883166,
    "estimated_duration": 3600.002882683891,
    "input_throughput": 2482.2002346114914,
    "output_throughput": 2184.8154727410088,
    "total_throughput": 4667.015707352501,
    "itl": 30.05833659465944,
    "ttft": 46515.59191622291,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7436,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.234013992892347,
    "arrivals": 36267,
    "finished_requests": 36001,
    "scheduler_time": 14.442887191485159
}
#Debug simulation 
Total elapsed time: 3.9597705006599426. Arrivals time: 0.09735648287460208 Scheduler time: 3.5155794648453593 Scheduler overhead time: 0.11586007988080382 Adapter cache time: 0.0635908986441791 Engine time: 0.1130189592950046 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-32/adapters_192_slots_32_rate_0.1-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-32/adapters_192_slots_32_rate_0.1-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 540, 540, 540, 540, 1080, 540, 66, 1080, 66, 540, 540, 66, 1080, 1080, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 1080, 540, 66, 540, 1080, 1080, 540, 1080, 66, 540, 540, 1080, 540, 66, 66, 540, 1080, 66, 540, 66, 1080, 1080, 540, 1080, 1080, 1080, 66, 540, 1080, 66, 540, 66, 540, 66, 66, 540, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 540, 66, 66, 66, 66, 66, 1080, 66, 540, 66, 1080, 1080, 66, 1080, 66, 540, 540, 1080, 66, 66, 66, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 66, 1080, 540, 540, 540, 1080, 540, 66, 540, 1080, 1080, 540, 1080, 540, 66, 1080, 540, 66, 540, 540, 66, 540, 1080, 66, 540, 1080, 66, 540, 1080, 1080, 540, 66, 1080, 540, 66, 66, 540, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 540, 66, 1080, 1080, 540, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 66, 1080, 540, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 540, 540, 1080, 540, 66, 66]
Prompts retrieved: 107904 . Total input tokens: 24015577 . Total output tokens: 21599596
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 3.899468152783811,
    "estimated_duration": 3600.009235165476,
    "input_throughput": 2481.6303004815345,
    "output_throughput": 2185.054116851016,
    "total_throughput": 4666.68441733255,
    "itl": 30.092557908965958,
    "ttft": 46407.09795316555,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7486,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.036746334953058,
    "arrivals": 36267,
    "finished_requests": 36001,
    "scheduler_time": 14.439191720197245
}
#Debug simulation 
Total elapsed time: 3.8995517627336085. Arrivals time: 0.0978884189389646 Scheduler time: 3.453267429023981 Scheduler overhead time: 0.11862953566014767 Adapter cache time: 0.06313154520466924 Engine time: 0.11207996541634202 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_192_slots_32_rate_0.1-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_192_slots_32_rate_0.1-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 540, 540, 540, 540, 1080, 540, 33, 1080, 33, 540, 540, 33, 1080, 1080, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 1080, 540, 33, 540, 1080, 1080, 540, 1080, 33, 540, 540, 1080, 540, 33, 33, 540, 1080, 33, 540, 33, 1080, 1080, 540, 1080, 1080, 1080, 33, 540, 1080, 33, 540, 33, 540, 33, 33, 540, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 540, 33, 33, 33, 33, 33, 1080, 33, 540, 33, 1080, 1080, 33, 1080, 33, 540, 540, 1080, 33, 33, 33, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 33, 1080, 540, 540, 540, 1080, 540, 33, 540, 1080, 1080, 540, 1080, 540, 33, 1080, 540, 33, 540, 540, 33, 540, 1080, 33, 540, 1080, 33, 540, 1080, 1080, 540, 33, 1080, 540, 33, 33, 540, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 540, 33, 1080, 1080, 540, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 33, 1080, 540, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 540, 540, 1080, 540, 33, 33]
Prompts retrieved: 105792 . Total input tokens: 23538003 . Total output tokens: 21187347
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 3.7830142402090132,
    "estimated_duration": 3600.020882870076,
    "input_throughput": 2434.9269865933593,
    "output_throughput": 2135.995109525457,
    "total_throughput": 4570.922096118817,
    "itl": 29.832550175491548,
    "ttft": 44281.80313436067,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7518,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.00874685888692,
    "arrivals": 35501,
    "finished_requests": 35238,
    "scheduler_time": 13.03618008474099
}
#Debug simulation 
Total elapsed time: 3.78307799436152. Arrivals time: 0.09519896283745766 Scheduler time: 3.338259876240045 Scheduler overhead time: 0.1169811999425292 Adapter cache time: 0.06417074892669916 Engine time: 0.11364213936030865 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_192_slots_32_rate_0.1-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_192_slots_32_rate_0.1-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 540, 540, 540, 540, 1080, 540, 33, 1080, 33, 540, 540, 33, 1080, 1080, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 1080, 540, 33, 540, 1080, 1080, 540, 1080, 33, 540, 540, 1080, 540, 33, 33, 540, 1080, 33, 540, 33, 1080, 1080, 540, 1080, 1080, 1080, 33, 540, 1080, 33, 540, 33, 540, 33, 33, 540, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 540, 33, 33, 33, 33, 33, 1080, 33, 540, 33, 1080, 1080, 33, 1080, 33, 540, 540, 1080, 33, 33, 33, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 33, 1080, 540, 540, 540, 1080, 540, 33, 540, 1080, 1080, 540, 1080, 540, 33, 1080, 540, 33, 540, 540, 33, 540, 1080, 33, 540, 1080, 33, 540, 1080, 1080, 540, 33, 1080, 540, 33, 33, 540, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 540, 33, 1080, 1080, 540, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 33, 1080, 540, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 540, 540, 1080, 540, 33, 33]
Prompts retrieved: 105792 . Total input tokens: 23538003 . Total output tokens: 21187347
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 3.7721453648991883,
    "estimated_duration": 3600.0141113723494,
    "input_throughput": 2435.372120432555,
    "output_throughput": 2136.6021804475195,
    "total_throughput": 4571.974300880074,
    "itl": 29.84889497550401,
    "ttft": 43791.104002787375,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7524,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.490266382194026,
    "arrivals": 35501,
    "finished_requests": 35243,
    "scheduler_time": 13.05001978886806
}
#Debug simulation 
Total elapsed time: 3.7722349911928177. Arrivals time: 0.09750087559223175 Scheduler time: 3.3244155612774193 Scheduler overhead time: 0.11700754147022963 Adapter cache time: 0.06420277571305633 Engine time: 0.11442634556442499 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-32/adapters_192_slots_32_rate_0.1-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-32/adapters_192_slots_32_rate_0.1-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 540, 540, 540, 540, 1080, 540, 33, 1080, 33, 540, 540, 33, 1080, 1080, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 1080, 540, 33, 540, 1080, 1080, 540, 1080, 33, 540, 540, 1080, 540, 33, 33, 540, 1080, 33, 540, 33, 1080, 1080, 540, 1080, 1080, 1080, 33, 540, 1080, 33, 540, 33, 540, 33, 33, 540, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 540, 33, 33, 33, 33, 33, 1080, 33, 540, 33, 1080, 1080, 33, 1080, 33, 540, 540, 1080, 33, 33, 33, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 33, 1080, 540, 540, 540, 1080, 540, 33, 540, 1080, 1080, 540, 1080, 540, 33, 1080, 540, 33, 540, 540, 33, 540, 1080, 33, 540, 1080, 33, 540, 1080, 1080, 540, 33, 1080, 540, 33, 33, 540, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 540, 33, 1080, 1080, 540, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 33, 1080, 540, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 540, 540, 1080, 540, 33, 33]
Prompts retrieved: 105792 . Total input tokens: 23538003 . Total output tokens: 21187347
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 3.7245369269512594,
    "estimated_duration": 3599.989058563406,
    "input_throughput": 2435.218234662752,
    "output_throughput": 2136.372048605364,
    "total_throughput": 4571.590283268116,
    "itl": 29.845214102821707,
    "ttft": 44010.74064581453,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7491,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.436673529557968,
    "arrivals": 35501,
    "finished_requests": 35241,
    "scheduler_time": 13.053460332023457
}
#Debug simulation 
Total elapsed time: 3.724604398943484. Arrivals time: 0.09422084549441934 Scheduler time: 3.2818995909765363 Scheduler overhead time: 0.11782954400405288 Adapter cache time: 0.06340570282191038 Engine time: 0.1123830871656537 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_192_slots_32_rate_0.1-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_192_slots_32_rate_0.1-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 540, 540, 540, 540, 1080, 540, 33, 1080, 33, 540, 540, 33, 1080, 1080, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 1080, 540, 33, 540, 1080, 1080, 540, 1080, 33, 540, 540, 1080, 540, 33, 33, 540, 1080, 33, 540, 33, 1080, 1080, 540, 1080, 1080, 1080, 33, 540, 1080, 33, 540, 33, 540, 33, 33, 540, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 540, 33, 33, 33, 33, 33, 1080, 33, 540, 33, 1080, 1080, 33, 1080, 33, 540, 540, 1080, 33, 33, 33, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 33, 1080, 540, 540, 540, 1080, 540, 33, 540, 1080, 1080, 540, 1080, 540, 33, 1080, 540, 33, 540, 540, 33, 540, 1080, 33, 540, 1080, 33, 540, 1080, 1080, 540, 33, 1080, 540, 33, 33, 540, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 540, 33, 1080, 1080, 540, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 33, 1080, 540, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 540, 540, 1080, 540, 33, 33]
Prompts retrieved: 105792 . Total input tokens: 23538003 . Total output tokens: 21187347
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 3.7865760112181306,
    "estimated_duration": 3599.9905323799085,
    "input_throughput": 2435.1405708293873,
    "output_throughput": 2136.4653409006073,
    "total_throughput": 4571.605911729995,
    "itl": 29.84021074798657,
    "ttft": 44356.673633426515,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7526,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.496005143242684,
    "arrivals": 35501,
    "finished_requests": 35237,
    "scheduler_time": 13.035433652055204
}
#Debug simulation 
Total elapsed time: 3.7866560900583863. Arrivals time: 0.096000746358186 Scheduler time: 3.3352267001755536 Scheduler overhead time: 0.1209335308521986 Adapter cache time: 0.0645504854619503 Engine time: 0.11432967241853476 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-32/adapters_192_slots_32_rate_0.1-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-32/adapters_192_slots_32_rate_0.1-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 540, 540, 540, 540, 1080, 540, 33, 1080, 33, 540, 540, 33, 1080, 1080, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 1080, 540, 33, 540, 1080, 1080, 540, 1080, 33, 540, 540, 1080, 540, 33, 33, 540, 1080, 33, 540, 33, 1080, 1080, 540, 1080, 1080, 1080, 33, 540, 1080, 33, 540, 33, 540, 33, 33, 540, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 540, 33, 33, 33, 33, 33, 1080, 33, 540, 33, 1080, 1080, 33, 1080, 33, 540, 540, 1080, 33, 33, 33, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 33, 1080, 540, 540, 540, 1080, 540, 33, 540, 1080, 1080, 540, 1080, 540, 33, 1080, 540, 33, 540, 540, 33, 540, 1080, 33, 540, 1080, 33, 540, 1080, 1080, 540, 33, 1080, 540, 33, 33, 540, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 540, 33, 1080, 1080, 540, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 33, 1080, 540, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 540, 540, 1080, 540, 33, 33]
Prompts retrieved: 105792 . Total input tokens: 23538003 . Total output tokens: 21187347
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 3.7830916312523186,
    "estimated_duration": 3600.0003186284384,
    "input_throughput": 2435.743395528579,
    "output_throughput": 2136.481755348932,
    "total_throughput": 4572.225150877511,
    "itl": 29.84437168283183,
    "ttft": 43814.942645489646,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7460,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.637457186094455,
    "arrivals": 35501,
    "finished_requests": 35244,
    "scheduler_time": 13.071715582991468
}
#Debug simulation 
Total elapsed time: 3.7831672211177647. Arrivals time: 0.09643604326993227 Scheduler time: 3.335515676997602 Scheduler overhead time: 0.11788232857361436 Adapter cache time: 0.06397879589349031 Engine time: 0.11427579261362553 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_192_slots_32_rate_0.1-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_192_slots_32_rate_0.1-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 540, 540, 540, 540, 1080, 540, 33, 1080, 33, 540, 540, 33, 1080, 1080, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 1080, 540, 33, 540, 1080, 1080, 540, 1080, 33, 540, 540, 1080, 540, 33, 33, 540, 1080, 33, 540, 33, 1080, 1080, 540, 1080, 1080, 1080, 33, 540, 1080, 33, 540, 33, 540, 33, 33, 540, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 540, 33, 33, 33, 33, 33, 1080, 33, 540, 33, 1080, 1080, 33, 1080, 33, 540, 540, 1080, 33, 33, 33, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 33, 1080, 540, 540, 540, 1080, 540, 33, 540, 1080, 1080, 540, 1080, 540, 33, 1080, 540, 33, 540, 540, 33, 540, 1080, 33, 540, 1080, 33, 540, 1080, 1080, 540, 33, 1080, 540, 33, 33, 540, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 540, 33, 1080, 1080, 540, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 33, 1080, 540, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 540, 540, 1080, 540, 33, 33]
Prompts retrieved: 105792 . Total input tokens: 23538003 . Total output tokens: 21187347
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 3.7718789731152356,
    "estimated_duration": 3600.0166521292826,
    "input_throughput": 2436.5281740605124,
    "output_throughput": 2136.567894887554,
    "total_throughput": 4573.096068948066,
    "itl": 29.833692053076934,
    "ttft": 43120.834095831786,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7540,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.54497922356207,
    "arrivals": 35501,
    "finished_requests": 35249,
    "scheduler_time": 13.025270367183255
}
#Debug simulation 
Total elapsed time: 3.771946032065898. Arrivals time: 0.09537930507212877 Scheduler time: 3.323742319829762 Scheduler overhead time: 0.11912709614261985 Adapter cache time: 0.06413367856293917 Engine time: 0.11433203145861626 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-32/adapters_192_slots_32_rate_0.1-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-32/adapters_192_slots_32_rate_0.1-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 540, 540, 540, 540, 1080, 540, 33, 1080, 33, 540, 540, 33, 1080, 1080, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 1080, 540, 33, 540, 1080, 1080, 540, 1080, 33, 540, 540, 1080, 540, 33, 33, 540, 1080, 33, 540, 33, 1080, 1080, 540, 1080, 1080, 1080, 33, 540, 1080, 33, 540, 33, 540, 33, 33, 540, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 540, 33, 33, 33, 33, 33, 1080, 33, 540, 33, 1080, 1080, 33, 1080, 33, 540, 540, 1080, 33, 33, 33, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 33, 1080, 540, 540, 540, 1080, 540, 33, 540, 1080, 1080, 540, 1080, 540, 33, 1080, 540, 33, 540, 540, 33, 540, 1080, 33, 540, 1080, 33, 540, 1080, 1080, 540, 33, 1080, 540, 33, 33, 540, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 540, 33, 1080, 1080, 540, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 33, 1080, 540, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 540, 540, 1080, 540, 33, 33]
Prompts retrieved: 105792 . Total input tokens: 23538003 . Total output tokens: 21187347
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 3.7798181301914155,
    "estimated_duration": 3600.019710757965,
    "input_throughput": 2435.6244422211457,
    "output_throughput": 2136.4377469979613,
    "total_throughput": 4572.0621892191075,
    "itl": 29.849822606340304,
    "ttft": 43641.55544164327,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7466,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.961985919548027,
    "arrivals": 35501,
    "finished_requests": 35245,
    "scheduler_time": 13.060351380949083
}
#Debug simulation 
Total elapsed time: 3.7799160038121045. Arrivals time: 0.09576992224901915 Scheduler time: 3.3359925993718207 Scheduler overhead time: 0.11571388132870197 Adapter cache time: 0.0637439931742847 Engine time: 0.11404371215030551 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_192_slots_32_rate_0.1-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_192_slots_32_rate_0.1-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [64 64 64]
Adapter prompts. [1080, 135, 1080, 135, 1080, 135, 1080, 135, 135, 135, 270, 270, 270, 270, 1080, 270, 135, 1080, 135, 270, 270, 135, 1080, 1080, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 1080, 270, 135, 270, 1080, 1080, 270, 1080, 135, 270, 270, 1080, 270, 135, 135, 270, 1080, 135, 270, 135, 1080, 1080, 270, 1080, 1080, 1080, 135, 270, 1080, 135, 270, 135, 270, 135, 135, 270, 1080, 1080, 135, 135, 135, 1080, 1080, 1080, 270, 135, 135, 135, 135, 135, 1080, 135, 270, 135, 1080, 1080, 135, 1080, 135, 270, 270, 1080, 135, 135, 135, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 135, 1080, 270, 270, 270, 1080, 270, 135, 270, 1080, 1080, 270, 1080, 270, 135, 1080, 270, 135, 270, 270, 135, 270, 1080, 135, 270, 1080, 135, 270, 1080, 1080, 270, 135, 1080, 270, 135, 135, 270, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 270, 135, 1080, 1080, 270, 1080, 135, 1080, 1080, 1080, 135, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 135, 1080, 270, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 270, 270, 1080, 270, 135, 135]
Prompts retrieved: 95040 . Total input tokens: 21168775 . Total output tokens: 19051203
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 3.392827769741416,
    "estimated_duration": 3599.972644348119,
    "input_throughput": 2173.185680253039,
    "output_throughput": 1930.6291148938828,
    "total_throughput": 4103.814795146922,
    "itl": 28.922567078409372,
    "ttft": 40803.94320593381,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8990,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.513784817957397,
    "arrivals": 31858,
    "finished_requests": 31629,
    "scheduler_time": 8.626704847736358
}
#Debug simulation 
Total elapsed time: 3.3928912128321826. Arrivals time: 0.08734194515272975 Scheduler time: 2.9419590826146305 Scheduler overhead time: 0.11804071813821793 Adapter cache time: 0.07490926841273904 Engine time: 0.11444571567699313 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_192_slots_32_rate_0.1-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_192_slots_32_rate_0.1-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [64 64 64]
Adapter prompts. [1080, 135, 1080, 135, 1080, 135, 1080, 135, 135, 135, 270, 270, 270, 270, 1080, 270, 135, 1080, 135, 270, 270, 135, 1080, 1080, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 1080, 270, 135, 270, 1080, 1080, 270, 1080, 135, 270, 270, 1080, 270, 135, 135, 270, 1080, 135, 270, 135, 1080, 1080, 270, 1080, 1080, 1080, 135, 270, 1080, 135, 270, 135, 270, 135, 135, 270, 1080, 1080, 135, 135, 135, 1080, 1080, 1080, 270, 135, 135, 135, 135, 135, 1080, 135, 270, 135, 1080, 1080, 135, 1080, 135, 270, 270, 1080, 135, 135, 135, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 135, 1080, 270, 270, 270, 1080, 270, 135, 270, 1080, 1080, 270, 1080, 270, 135, 1080, 270, 135, 270, 270, 135, 270, 1080, 135, 270, 1080, 135, 270, 1080, 1080, 270, 135, 1080, 270, 135, 135, 270, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 270, 135, 1080, 1080, 270, 1080, 135, 1080, 1080, 1080, 135, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 135, 1080, 270, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 270, 270, 1080, 270, 135, 135]
Prompts retrieved: 95040 . Total input tokens: 21168775 . Total output tokens: 19051203
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 3.381453488022089,
    "estimated_duration": 3599.973676695264,
    "input_throughput": 2172.8192210506922,
    "output_throughput": 1930.491893590668,
    "total_throughput": 4103.31111464136,
    "itl": 28.941593594036654,
    "ttft": 41060.587928405825,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8946,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.152756196575766,
    "arrivals": 31858,
    "finished_requests": 31628,
    "scheduler_time": 8.664085964412344
}
#Debug simulation 
Total elapsed time: 3.381536338943988. Arrivals time: 0.08823903417214751 Scheduler time: 2.928797683212906 Scheduler overhead time: 0.11864332994446158 Adapter cache time: 0.07289754366502166 Engine time: 0.11687608622014523 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-32/adapters_192_slots_32_rate_0.1-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-32/adapters_192_slots_32_rate_0.1-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [64 64 64]
Adapter prompts. [1080, 135, 1080, 135, 1080, 135, 1080, 135, 135, 135, 270, 270, 270, 270, 1080, 270, 135, 1080, 135, 270, 270, 135, 1080, 1080, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 1080, 270, 135, 270, 1080, 1080, 270, 1080, 135, 270, 270, 1080, 270, 135, 135, 270, 1080, 135, 270, 135, 1080, 1080, 270, 1080, 1080, 1080, 135, 270, 1080, 135, 270, 135, 270, 135, 135, 270, 1080, 1080, 135, 135, 135, 1080, 1080, 1080, 270, 135, 135, 135, 135, 135, 1080, 135, 270, 135, 1080, 1080, 135, 1080, 135, 270, 270, 1080, 135, 135, 135, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 135, 1080, 270, 270, 270, 1080, 270, 135, 270, 1080, 1080, 270, 1080, 270, 135, 1080, 270, 135, 270, 270, 135, 270, 1080, 135, 270, 1080, 135, 270, 1080, 1080, 270, 135, 1080, 270, 135, 135, 270, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 270, 135, 1080, 1080, 270, 1080, 135, 1080, 1080, 1080, 135, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 135, 1080, 270, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 270, 270, 1080, 270, 135, 135]
Prompts retrieved: 95040 . Total input tokens: 21168775 . Total output tokens: 19051203
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 3.3782422221265733,
    "estimated_duration": 3599.9810366778397,
    "input_throughput": 2172.815612167347,
    "output_throughput": 1930.4826689902159,
    "total_throughput": 4103.298281157563,
    "itl": 28.941079655575844,
    "ttft": 41116.78551030801,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8966,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.276601225809287,
    "arrivals": 31858,
    "finished_requests": 31627,
    "scheduler_time": 8.65545403259418
}
#Debug simulation 
Total elapsed time: 3.378307942301035. Arrivals time: 0.08679655706509948 Scheduler time: 2.9285063119605184 Scheduler overhead time: 0.11842443933710456 Adapter cache time: 0.07256362913176417 Engine time: 0.11601263238117099 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_192_slots_32_rate_0.1-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_192_slots_32_rate_0.1-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [64 64 64]
Adapter prompts. [1080, 135, 1080, 135, 1080, 135, 1080, 135, 135, 135, 270, 270, 270, 270, 1080, 270, 135, 1080, 135, 270, 270, 135, 1080, 1080, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 1080, 270, 135, 270, 1080, 1080, 270, 1080, 135, 270, 270, 1080, 270, 135, 135, 270, 1080, 135, 270, 135, 1080, 1080, 270, 1080, 1080, 1080, 135, 270, 1080, 135, 270, 135, 270, 135, 135, 270, 1080, 1080, 135, 135, 135, 1080, 1080, 1080, 270, 135, 135, 135, 135, 135, 1080, 135, 270, 135, 1080, 1080, 135, 1080, 135, 270, 270, 1080, 135, 135, 135, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 135, 1080, 270, 270, 270, 1080, 270, 135, 270, 1080, 1080, 270, 1080, 270, 135, 1080, 270, 135, 270, 270, 135, 270, 1080, 135, 270, 1080, 135, 270, 1080, 1080, 270, 135, 1080, 270, 135, 135, 270, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 270, 135, 1080, 1080, 270, 1080, 135, 1080, 1080, 1080, 135, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 135, 1080, 270, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 270, 270, 1080, 270, 135, 135]
Prompts retrieved: 95040 . Total input tokens: 21168775 . Total output tokens: 19051203
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 3.3606464969925582,
    "estimated_duration": 3599.9728993880376,
    "input_throughput": 2172.443020704254,
    "output_throughput": 1930.4936993224003,
    "total_throughput": 4102.936720026654,
    "itl": 28.92601759298124,
    "ttft": 41420.46375144181,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8970,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.028150311261008,
    "arrivals": 31858,
    "finished_requests": 31624,
    "scheduler_time": 8.636804530920553
}
#Debug simulation 
Total elapsed time: 3.360726068727672. Arrivals time: 0.08738075895234942 Scheduler time: 2.9072112473659217 Scheduler overhead time: 0.12097714468836784 Adapter cache time: 0.07229944784194231 Engine time: 0.1167482347227633 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-32/adapters_192_slots_32_rate_0.1-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-32/adapters_192_slots_32_rate_0.1-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [64 64 64]
Adapter prompts. [1080, 135, 1080, 135, 1080, 135, 1080, 135, 135, 135, 270, 270, 270, 270, 1080, 270, 135, 1080, 135, 270, 270, 135, 1080, 1080, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 1080, 270, 135, 270, 1080, 1080, 270, 1080, 135, 270, 270, 1080, 270, 135, 135, 270, 1080, 135, 270, 135, 1080, 1080, 270, 1080, 1080, 1080, 135, 270, 1080, 135, 270, 135, 270, 135, 135, 270, 1080, 1080, 135, 135, 135, 1080, 1080, 1080, 270, 135, 135, 135, 135, 135, 1080, 135, 270, 135, 1080, 1080, 135, 1080, 135, 270, 270, 1080, 135, 135, 135, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 135, 1080, 270, 270, 270, 1080, 270, 135, 270, 1080, 1080, 270, 1080, 270, 135, 1080, 270, 135, 270, 270, 135, 270, 1080, 135, 270, 1080, 135, 270, 1080, 1080, 270, 135, 1080, 270, 135, 135, 270, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 270, 135, 1080, 1080, 270, 1080, 135, 1080, 1080, 1080, 135, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 135, 1080, 270, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 270, 270, 1080, 270, 135, 135]
Prompts retrieved: 95040 . Total input tokens: 21168775 . Total output tokens: 19051203
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 3.4409315320663154,
    "estimated_duration": 3599.983612399582,
    "input_throughput": 2171.993220488058,
    "output_throughput": 1929.6648951603452,
    "total_throughput": 4101.658115648403,
    "itl": 28.933152310969383,
    "ttft": 44310.685514067154,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8587,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.39569066652948,
    "arrivals": 31858,
    "finished_requests": 31611,
    "scheduler_time": 8.894162636486717
}
#Debug simulation 
Total elapsed time: 3.4410073249600828. Arrivals time: 0.0870762630365789 Scheduler time: 2.9926796494983137 Scheduler overhead time: 0.11848100321367383 Adapter cache time: 0.07076604198664427 Engine time: 0.1159071079455316 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_192_slots_32_rate_0.1-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_192_slots_32_rate_0.1-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [64 64 64]
Adapter prompts. [1080, 135, 1080, 135, 1080, 135, 1080, 135, 135, 135, 270, 270, 270, 270, 1080, 270, 135, 1080, 135, 270, 270, 135, 1080, 1080, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 1080, 270, 135, 270, 1080, 1080, 270, 1080, 135, 270, 270, 1080, 270, 135, 135, 270, 1080, 135, 270, 135, 1080, 1080, 270, 1080, 1080, 1080, 135, 270, 1080, 135, 270, 135, 270, 135, 135, 270, 1080, 1080, 135, 135, 135, 1080, 1080, 1080, 270, 135, 135, 135, 135, 135, 1080, 135, 270, 135, 1080, 1080, 135, 1080, 135, 270, 270, 1080, 135, 135, 135, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 135, 1080, 270, 270, 270, 1080, 270, 135, 270, 1080, 1080, 270, 1080, 270, 135, 1080, 270, 135, 270, 270, 135, 270, 1080, 135, 270, 1080, 135, 270, 1080, 1080, 270, 135, 1080, 270, 135, 135, 270, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 270, 135, 1080, 1080, 270, 1080, 135, 1080, 1080, 1080, 135, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 135, 1080, 270, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 270, 270, 1080, 270, 135, 135]
Prompts retrieved: 95040 . Total input tokens: 21168775 . Total output tokens: 19051203
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 3.3390632839873433,
    "estimated_duration": 3599.9573480898234,
    "input_throughput": 2173.194914142854,
    "output_throughput": 1930.6373181581882,
    "total_throughput": 4103.8322323010425,
    "itl": 28.914269602075546,
    "ttft": 40772.970836966764,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9005,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.9254029055923,
    "arrivals": 31858,
    "finished_requests": 31629,
    "scheduler_time": 8.61683063522666
}
#Debug simulation 
Total elapsed time: 3.3391328351572156. Arrivals time: 0.08636894961819053 Scheduler time: 2.8906244337558746 Scheduler overhead time: 0.11879452271386981 Adapter cache time: 0.07254422502592206 Engine time: 0.11495823133736849 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-32/adapters_192_slots_32_rate_0.1-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-32/adapters_192_slots_32_rate_0.1-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [64 64 64]
Adapter prompts. [1080, 135, 1080, 135, 1080, 135, 1080, 135, 135, 135, 270, 270, 270, 270, 1080, 270, 135, 1080, 135, 270, 270, 135, 1080, 1080, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 1080, 270, 135, 270, 1080, 1080, 270, 1080, 135, 270, 270, 1080, 270, 135, 135, 270, 1080, 135, 270, 135, 1080, 1080, 270, 1080, 1080, 1080, 135, 270, 1080, 135, 270, 135, 270, 135, 135, 270, 1080, 1080, 135, 135, 135, 1080, 1080, 1080, 270, 135, 135, 135, 135, 135, 1080, 135, 270, 135, 1080, 1080, 135, 1080, 135, 270, 270, 1080, 135, 135, 135, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 135, 1080, 270, 270, 270, 1080, 270, 135, 270, 1080, 1080, 270, 1080, 270, 135, 1080, 270, 135, 270, 270, 135, 270, 1080, 135, 270, 1080, 135, 270, 1080, 1080, 270, 135, 1080, 270, 135, 135, 270, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 270, 135, 1080, 1080, 270, 1080, 135, 1080, 1080, 1080, 135, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 135, 1080, 270, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 270, 270, 1080, 270, 135, 135]
Prompts retrieved: 95040 . Total input tokens: 21168775 . Total output tokens: 19051203
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 3.4217207529582083,
    "estimated_duration": 3599.970053066451,
    "input_throughput": 2171.8213998308725,
    "output_throughput": 1929.7024412974386,
    "total_throughput": 4101.523841128311,
    "itl": 28.935226841358084,
    "ttft": 44332.532375995994,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8583,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.73523850735037,
    "arrivals": 31858,
    "finished_requests": 31611,
    "scheduler_time": 8.905410523157009
}
#Debug simulation 
Total elapsed time: 3.421797575894743. Arrivals time: 0.08757394133135676 Scheduler time: 2.9706696928478777 Scheduler overhead time: 0.1204346870072186 Adapter cache time: 0.07049173302948475 Engine time: 0.1165936766192317 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_192_slots_32_rate_0.1-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_192_slots_32_rate_0.1-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 270, 270, 270, 270, 1080, 270, 66, 1080, 66, 270, 270, 66, 1080, 1080, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 1080, 270, 66, 270, 1080, 1080, 270, 1080, 66, 270, 270, 1080, 270, 66, 66, 270, 1080, 66, 270, 66, 1080, 1080, 270, 1080, 1080, 1080, 66, 270, 1080, 66, 270, 66, 270, 66, 66, 270, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 270, 66, 66, 66, 66, 66, 1080, 66, 270, 66, 1080, 1080, 66, 1080, 66, 270, 270, 1080, 66, 66, 66, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 66, 1080, 270, 270, 270, 1080, 270, 66, 270, 1080, 1080, 270, 1080, 270, 66, 1080, 270, 66, 270, 270, 66, 270, 1080, 66, 270, 1080, 66, 270, 1080, 1080, 270, 66, 1080, 270, 66, 66, 270, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 270, 66, 1080, 1080, 270, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 66, 1080, 270, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 270, 270, 1080, 270, 66, 66]
Prompts retrieved: 90624 . Total input tokens: 20161865 . Total output tokens: 18163334
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 3.059406332205981,
    "estimated_duration": 3600.00408459933,
    "input_throughput": 2061.3909944565903,
    "output_throughput": 1840.455967354108,
    "total_throughput": 3901.8469618106983,
    "itl": 28.52140652198537,
    "ttft": 28411.26621702743,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9317,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.514564310223733,
    "arrivals": 30402,
    "finished_requests": 30257,
    "scheduler_time": 6.250333048710019
}
#Debug simulation 
Total elapsed time: 3.059489624109119. Arrivals time: 0.08287636889144778 Scheduler time: 2.609484517481178 Scheduler overhead time: 0.12012732867151499 Adapter cache time: 0.07410389091819525 Engine time: 0.1167396530508995 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_192_slots_32_rate_0.1-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_192_slots_32_rate_0.1-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 270, 270, 270, 270, 1080, 270, 66, 1080, 66, 270, 270, 66, 1080, 1080, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 1080, 270, 66, 270, 1080, 1080, 270, 1080, 66, 270, 270, 1080, 270, 66, 66, 270, 1080, 66, 270, 66, 1080, 1080, 270, 1080, 1080, 1080, 66, 270, 1080, 66, 270, 66, 270, 66, 66, 270, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 270, 66, 66, 66, 66, 66, 1080, 66, 270, 66, 1080, 1080, 66, 1080, 66, 270, 270, 1080, 66, 66, 66, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 66, 1080, 270, 270, 270, 1080, 270, 66, 270, 1080, 1080, 270, 1080, 270, 66, 1080, 270, 66, 270, 270, 66, 270, 1080, 66, 270, 1080, 66, 270, 1080, 1080, 270, 66, 1080, 270, 66, 66, 270, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 270, 66, 1080, 1080, 270, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 66, 1080, 270, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 270, 270, 1080, 270, 66, 66]
Prompts retrieved: 90624 . Total input tokens: 20161865 . Total output tokens: 18163334
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 3.1032927818596363,
    "estimated_duration": 3599.9830129305337,
    "input_throughput": 2061.3133376869055,
    "output_throughput": 1840.4336843263454,
    "total_throughput": 3901.747022013251,
    "itl": 28.536207952696103,
    "ttft": 28672.638180288304,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9317,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 30.33479482266644,
    "arrivals": 30402,
    "finished_requests": 30255,
    "scheduler_time": 6.2657964975676155
}
#Debug simulation 
Total elapsed time: 3.10337450588122. Arrivals time: 0.08462708722800016 Scheduler time: 2.6511021396145225 Scheduler overhead time: 0.11961105978116393 Adapter cache time: 0.07438866281881928 Engine time: 0.11695172684267163 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_192_slots_32_rate_0.1-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_192_slots_32_rate_0.1-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 270, 270, 270, 270, 1080, 270, 66, 1080, 66, 270, 270, 66, 1080, 1080, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 1080, 270, 66, 270, 1080, 1080, 270, 1080, 66, 270, 270, 1080, 270, 66, 66, 270, 1080, 66, 270, 66, 1080, 1080, 270, 1080, 1080, 1080, 66, 270, 1080, 66, 270, 66, 270, 66, 66, 270, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 270, 66, 66, 66, 66, 66, 1080, 66, 270, 66, 1080, 1080, 66, 1080, 66, 270, 270, 1080, 66, 66, 66, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 66, 1080, 270, 270, 270, 1080, 270, 66, 270, 1080, 1080, 270, 1080, 270, 66, 1080, 270, 66, 270, 270, 66, 270, 1080, 66, 270, 1080, 66, 270, 1080, 1080, 270, 66, 1080, 270, 66, 66, 270, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 270, 66, 1080, 1080, 270, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 66, 1080, 270, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 270, 270, 1080, 270, 66, 66]
Prompts retrieved: 90624 . Total input tokens: 20161865 . Total output tokens: 18163334
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 3.0842040982097387,
    "estimated_duration": 3600.004213864171,
    "input_throughput": 2061.3009205438625,
    "output_throughput": 1840.4222901973476,
    "total_throughput": 3901.72321074121,
    "itl": 28.53693295644958,
    "ttft": 28806.46145374709,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9286,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 30.29841640163328,
    "arrivals": 30402,
    "finished_requests": 30254,
    "scheduler_time": 6.2703492262003
}
#Debug simulation 
Total elapsed time: 3.0842709988355637. Arrivals time: 0.08297888655215502 Scheduler time: 2.632566044572741 Scheduler overhead time: 0.12034427747130394 Adapter cache time: 0.07442911434918642 Engine time: 0.11739087337628007 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_192_slots_32_rate_0.1-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_192_slots_32_rate_0.1-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 270, 270, 270, 270, 1080, 270, 66, 1080, 66, 270, 270, 66, 1080, 1080, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 1080, 270, 66, 270, 1080, 1080, 270, 1080, 66, 270, 270, 1080, 270, 66, 66, 270, 1080, 66, 270, 66, 1080, 1080, 270, 1080, 1080, 1080, 66, 270, 1080, 66, 270, 66, 270, 66, 66, 270, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 270, 66, 66, 66, 66, 66, 1080, 66, 270, 66, 1080, 1080, 66, 1080, 66, 270, 270, 1080, 66, 66, 66, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 66, 1080, 270, 270, 270, 1080, 270, 66, 270, 1080, 1080, 270, 1080, 270, 66, 1080, 270, 66, 270, 270, 66, 270, 1080, 66, 270, 1080, 66, 270, 1080, 1080, 270, 66, 1080, 270, 66, 66, 270, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 270, 66, 1080, 1080, 270, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 66, 1080, 270, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 270, 270, 1080, 270, 66, 66]
Prompts retrieved: 90624 . Total input tokens: 20161865 . Total output tokens: 18163334
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 3.082968020811677,
    "estimated_duration": 3599.9862273329218,
    "input_throughput": 2060.9701069597613,
    "output_throughput": 1840.0862063596433,
    "total_throughput": 3901.0563133194046,
    "itl": 28.523719922455285,
    "ttft": 29130.33306119509,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9319,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.12438666026029,
    "arrivals": 30402,
    "finished_requests": 30251,
    "scheduler_time": 6.255421209875561
}
#Debug simulation 
Total elapsed time: 3.083056481089443. Arrivals time: 0.08329852484166622 Scheduler time: 2.6325831883586943 Scheduler overhead time: 0.12056592060253024 Adapter cache time: 0.07446485152468085 Engine time: 0.11521030962467194 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_192_slots_32_rate_0.1-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_192_slots_32_rate_0.1-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 270, 270, 270, 270, 1080, 270, 66, 1080, 66, 270, 270, 66, 1080, 1080, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 1080, 270, 66, 270, 1080, 1080, 270, 1080, 66, 270, 270, 1080, 270, 66, 66, 270, 1080, 66, 270, 66, 1080, 1080, 270, 1080, 1080, 1080, 66, 270, 1080, 66, 270, 66, 270, 66, 66, 270, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 270, 66, 66, 66, 66, 66, 1080, 66, 270, 66, 1080, 1080, 66, 1080, 66, 270, 270, 1080, 66, 66, 66, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 66, 1080, 270, 270, 270, 1080, 270, 66, 270, 1080, 1080, 270, 1080, 270, 66, 1080, 270, 66, 270, 270, 66, 270, 1080, 66, 270, 1080, 66, 270, 1080, 1080, 270, 66, 1080, 270, 66, 66, 270, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 270, 66, 1080, 1080, 270, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 66, 1080, 270, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 270, 270, 1080, 270, 66, 66]
Prompts retrieved: 90624 . Total input tokens: 20161865 . Total output tokens: 18163334
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 3.048066419083625,
    "estimated_duration": 3599.9755303469556,
    "input_throughput": 2061.317344366731,
    "output_throughput": 1840.4369541260326,
    "total_throughput": 3901.7542984927636,
    "itl": 28.540284720962497,
    "ttft": 28839.583416417925,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9275,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 30.63568844612623,
    "arrivals": 30402,
    "finished_requests": 30254,
    "scheduler_time": 6.276856917743718
}
#Debug simulation 
Total elapsed time: 3.04814446112141. Arrivals time: 0.08293252531439066 Scheduler time: 2.5987460198812187 Scheduler overhead time: 0.11944088200107217 Adapter cache time: 0.07391176884993911 Engine time: 0.11662607220932841 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_192_slots_32_rate_0.1-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_192_slots_32_rate_0.1-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 270, 270, 270, 270, 1080, 270, 66, 1080, 66, 270, 270, 66, 1080, 1080, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 1080, 270, 66, 270, 1080, 1080, 270, 1080, 66, 270, 270, 1080, 270, 66, 66, 270, 1080, 66, 270, 66, 1080, 1080, 270, 1080, 1080, 1080, 66, 270, 1080, 66, 270, 66, 270, 66, 66, 270, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 270, 66, 66, 66, 66, 66, 1080, 66, 270, 66, 1080, 1080, 66, 1080, 66, 270, 270, 1080, 66, 66, 66, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 66, 1080, 270, 270, 270, 1080, 270, 66, 270, 1080, 1080, 270, 1080, 270, 66, 1080, 270, 66, 270, 270, 66, 270, 1080, 66, 270, 1080, 66, 270, 1080, 1080, 270, 66, 1080, 270, 66, 66, 270, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 270, 66, 1080, 1080, 270, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 66, 1080, 270, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 270, 270, 1080, 270, 66, 66]
Prompts retrieved: 90624 . Total input tokens: 20161865 . Total output tokens: 18163334
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 3.0944109680131078,
    "estimated_duration": 3599.9882776318177,
    "input_throughput": 2061.110322526129,
    "output_throughput": 1840.1684919812724,
    "total_throughput": 3901.2788145074014,
    "itl": 28.512931177126475,
    "ttft": 29013.487244861444,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9308,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.831388144947358,
    "arrivals": 30402,
    "finished_requests": 30252,
    "scheduler_time": 6.246994723202273
}
#Debug simulation 
Total elapsed time: 3.0944764059968293. Arrivals time: 0.08382454747334123 Scheduler time: 2.6429229001514614 Scheduler overhead time: 0.12049976410344243 Adapter cache time: 0.07421675464138389 Engine time: 0.11633397499099374 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_192_slots_32_rate_0.1-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_192_slots_32_rate_0.1-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 270, 270, 270, 270, 1080, 270, 66, 1080, 66, 270, 270, 66, 1080, 1080, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 1080, 270, 66, 270, 1080, 1080, 270, 1080, 66, 270, 270, 1080, 270, 66, 66, 270, 1080, 66, 270, 66, 1080, 1080, 270, 1080, 1080, 1080, 66, 270, 1080, 66, 270, 66, 270, 66, 66, 270, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 270, 66, 66, 66, 66, 66, 1080, 66, 270, 66, 1080, 1080, 66, 1080, 66, 270, 270, 1080, 66, 66, 66, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 66, 1080, 270, 270, 270, 1080, 270, 66, 270, 1080, 1080, 270, 1080, 270, 66, 1080, 270, 66, 270, 270, 66, 270, 1080, 66, 270, 1080, 66, 270, 1080, 1080, 270, 66, 1080, 270, 66, 66, 270, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 270, 66, 1080, 1080, 270, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 66, 1080, 270, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 270, 270, 1080, 270, 66, 66]
Prompts retrieved: 90624 . Total input tokens: 20161865 . Total output tokens: 18163334
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 3.096568745095283,
    "estimated_duration": 3599.9747058760063,
    "input_throughput": 2060.97670294452,
    "output_throughput": 1840.0920954215615,
    "total_throughput": 3901.0687983660814,
    "itl": 28.53993679484663,
    "ttft": 29192.767296052712,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9271,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 31.007897969742466,
    "arrivals": 30402,
    "finished_requests": 30251,
    "scheduler_time": 6.281910310200683
}
#Debug simulation 
Total elapsed time: 3.0966438399627805. Arrivals time: 0.08310630079358816 Scheduler time: 2.6462031272239983 Scheduler overhead time: 0.11951938411220908 Adapter cache time: 0.07425846625119448 Engine time: 0.11699671437963843 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_192_slots_32_rate_0.1-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_192_slots_32_rate_0.1-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 270, 270, 270, 270, 1080, 270, 33, 1080, 33, 270, 270, 33, 1080, 1080, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 1080, 270, 33, 270, 1080, 1080, 270, 1080, 33, 270, 270, 1080, 270, 33, 33, 270, 1080, 33, 270, 33, 1080, 1080, 270, 1080, 1080, 1080, 33, 270, 1080, 33, 270, 33, 270, 33, 33, 270, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 270, 33, 33, 33, 33, 33, 1080, 33, 270, 33, 1080, 1080, 33, 1080, 33, 270, 270, 1080, 33, 33, 33, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 33, 1080, 270, 270, 270, 1080, 270, 33, 270, 1080, 1080, 270, 1080, 270, 33, 1080, 270, 33, 270, 270, 33, 270, 1080, 33, 270, 1080, 33, 270, 1080, 1080, 270, 33, 1080, 270, 33, 33, 270, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 270, 33, 1080, 1080, 270, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 33, 1080, 270, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 270, 270, 1080, 270, 33, 33]
Prompts retrieved: 88512 . Total input tokens: 19700412 . Total output tokens: 17743755
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 2.9809974916279316,
    "estimated_duration": 3600.0100914243453,
    "input_throughput": 2021.2773895644839,
    "output_throughput": 1814.1951922740193,
    "total_throughput": 3835.472581838503,
    "itl": 28.380915695379674,
    "ttft": 32465.606842872396,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9350,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.615560405773547,
    "arrivals": 29640,
    "finished_requests": 29451,
    "scheduler_time": 5.4907426699366955
}
#Debug simulation 
Total elapsed time: 2.981076827738434. Arrivals time: 0.0818172381259501 Scheduler time: 2.5321301235817373 Scheduler overhead time: 0.12003500107675791 Adapter cache time: 0.07429854152724147 Engine time: 0.11557517014443874 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_192_slots_32_rate_0.1-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_192_slots_32_rate_0.1-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 270, 270, 270, 270, 1080, 270, 33, 1080, 33, 270, 270, 33, 1080, 1080, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 1080, 270, 33, 270, 1080, 1080, 270, 1080, 33, 270, 270, 1080, 270, 33, 33, 270, 1080, 33, 270, 33, 1080, 1080, 270, 1080, 1080, 1080, 33, 270, 1080, 33, 270, 33, 270, 33, 33, 270, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 270, 33, 33, 33, 33, 33, 1080, 33, 270, 33, 1080, 1080, 33, 1080, 33, 270, 270, 1080, 33, 33, 33, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 33, 1080, 270, 270, 270, 1080, 270, 33, 270, 1080, 1080, 270, 1080, 270, 33, 1080, 270, 33, 270, 270, 33, 270, 1080, 33, 270, 1080, 33, 270, 1080, 1080, 270, 33, 1080, 270, 33, 33, 270, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 270, 33, 1080, 1080, 270, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 33, 1080, 270, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 270, 270, 1080, 270, 33, 33]
Prompts retrieved: 88512 . Total input tokens: 19700412 . Total output tokens: 17743755
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.9892084901221097,
    "estimated_duration": 3600.0259441578773,
    "input_throughput": 2021.2684888586703,
    "output_throughput": 1814.1872034557707,
    "total_throughput": 3835.455692314441,
    "itl": 28.3990051305291,
    "ttft": 32525.688519790732,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9336,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 30.39732611272772,
    "arrivals": 29640,
    "finished_requests": 29451,
    "scheduler_time": 5.512958213291237
}
#Debug simulation 
Total elapsed time: 2.989315001759678. Arrivals time: 0.08419215772300959 Scheduler time: 2.5344218560494483 Scheduler overhead time: 0.12050522165372968 Adapter cache time: 0.07489216886460781 Engine time: 0.11850764323025942 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_192_slots_32_rate_0.1-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_192_slots_32_rate_0.1-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 270, 270, 270, 270, 1080, 270, 33, 1080, 33, 270, 270, 33, 1080, 1080, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 1080, 270, 33, 270, 1080, 1080, 270, 1080, 33, 270, 270, 1080, 270, 33, 33, 270, 1080, 33, 270, 33, 1080, 1080, 270, 1080, 1080, 1080, 33, 270, 1080, 33, 270, 33, 270, 33, 33, 270, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 270, 33, 33, 33, 33, 33, 1080, 33, 270, 33, 1080, 1080, 33, 1080, 33, 270, 270, 1080, 33, 33, 33, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 33, 1080, 270, 270, 270, 1080, 270, 33, 270, 1080, 1080, 270, 1080, 270, 33, 1080, 270, 33, 270, 270, 33, 270, 1080, 33, 270, 1080, 33, 270, 1080, 1080, 270, 33, 1080, 270, 33, 33, 270, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 270, 33, 1080, 1080, 270, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 33, 1080, 270, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 270, 270, 1080, 270, 33, 33]
Prompts retrieved: 88512 . Total input tokens: 19700412 . Total output tokens: 17743755
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.9846008298918605,
    "estimated_duration": 3600.025131712803,
    "input_throughput": 2021.2689450137154,
    "output_throughput": 1814.1876128772062,
    "total_throughput": 3835.456557890922,
    "itl": 28.395697274600874,
    "ttft": 32518.806032567823,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9346,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 30.492156699878393,
    "arrivals": 29640,
    "finished_requests": 29451,
    "scheduler_time": 5.514547872969847
}
#Debug simulation 
Total elapsed time: 2.98466938175261. Arrivals time: 0.08160165790468454 Scheduler time: 2.535328291822225 Scheduler overhead time: 0.11979714408516884 Adapter cache time: 0.07458338746801019 Engine time: 0.11673377733677626 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_192_slots_32_rate_0.1-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_192_slots_32_rate_0.1-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 270, 270, 270, 270, 1080, 270, 33, 1080, 33, 270, 270, 33, 1080, 1080, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 1080, 270, 33, 270, 1080, 1080, 270, 1080, 33, 270, 270, 1080, 270, 33, 33, 270, 1080, 33, 270, 33, 1080, 1080, 270, 1080, 1080, 1080, 33, 270, 1080, 33, 270, 33, 270, 33, 33, 270, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 270, 33, 33, 33, 33, 33, 1080, 33, 270, 33, 1080, 1080, 33, 1080, 33, 270, 270, 1080, 33, 33, 33, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 33, 1080, 270, 270, 270, 1080, 270, 33, 270, 1080, 1080, 270, 1080, 270, 33, 1080, 270, 33, 270, 270, 33, 270, 1080, 33, 270, 1080, 33, 270, 1080, 1080, 270, 33, 1080, 270, 33, 33, 270, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 270, 33, 1080, 1080, 270, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 33, 1080, 270, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 270, 270, 1080, 270, 33, 33]
Prompts retrieved: 88512 . Total input tokens: 19700412 . Total output tokens: 17743755
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 2.9667277988046408,
    "estimated_duration": 3600.0051672941895,
    "input_throughput": 2021.1376544964282,
    "output_throughput": 1814.1948959781264,
    "total_throughput": 3835.332550474555,
    "itl": 28.38619649694478,
    "ttft": 33084.07338567507,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9374,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.297011332848665,
    "arrivals": 29640,
    "finished_requests": 29446,
    "scheduler_time": 5.499424666415329
}
#Debug simulation 
Total elapsed time: 2.966806328855455. Arrivals time: 0.08200662769377232 Scheduler time: 2.5165478154085577 Scheduler overhead time: 0.12010634923353791 Adapter cache time: 0.07482668478041887 Engine time: 0.11653189174830914 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_192_slots_32_rate_0.1-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_192_slots_32_rate_0.1-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 270, 270, 270, 270, 1080, 270, 33, 1080, 33, 270, 270, 33, 1080, 1080, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 1080, 270, 33, 270, 1080, 1080, 270, 1080, 33, 270, 270, 1080, 270, 33, 33, 270, 1080, 33, 270, 33, 1080, 1080, 270, 1080, 1080, 1080, 33, 270, 1080, 33, 270, 33, 270, 33, 33, 270, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 270, 33, 33, 33, 33, 33, 1080, 33, 270, 33, 1080, 1080, 33, 1080, 33, 270, 270, 1080, 33, 33, 33, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 33, 1080, 270, 270, 270, 1080, 270, 33, 270, 1080, 1080, 270, 1080, 270, 33, 1080, 270, 33, 270, 270, 33, 270, 1080, 33, 270, 1080, 33, 270, 1080, 1080, 270, 33, 1080, 270, 33, 33, 270, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 270, 33, 1080, 1080, 270, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 33, 1080, 270, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 270, 270, 1080, 270, 33, 33]
Prompts retrieved: 88512 . Total input tokens: 19700412 . Total output tokens: 17743755
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 2.982558696065098,
    "estimated_duration": 3600.0236415034215,
    "input_throughput": 2021.016450036856,
    "output_throughput": 1814.142530817542,
    "total_throughput": 3835.1589808543977,
    "itl": 28.40333981689658,
    "ttft": 32910.91355331327,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9335,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 30.832749781067736,
    "arrivals": 29640,
    "finished_requests": 29448,
    "scheduler_time": 5.520379161293776
}
#Debug simulation 
Total elapsed time: 2.9826348391361535. Arrivals time: 0.08226817473769188 Scheduler time: 2.5322898169979453 Scheduler overhead time: 0.12006017519161105 Adapter cache time: 0.07435242552310228 Engine time: 0.11708344658836722 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_192_slots_32_rate_0.1-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_192_slots_32_rate_0.1-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 270, 270, 270, 270, 1080, 270, 33, 1080, 33, 270, 270, 33, 1080, 1080, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 1080, 270, 33, 270, 1080, 1080, 270, 1080, 33, 270, 270, 1080, 270, 33, 33, 270, 1080, 33, 270, 33, 1080, 1080, 270, 1080, 1080, 1080, 33, 270, 1080, 33, 270, 33, 270, 33, 33, 270, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 270, 33, 33, 33, 33, 33, 1080, 33, 270, 33, 1080, 1080, 33, 1080, 33, 270, 270, 1080, 33, 33, 33, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 33, 1080, 270, 270, 270, 1080, 270, 33, 270, 1080, 1080, 270, 1080, 270, 33, 1080, 270, 33, 270, 270, 33, 270, 1080, 33, 270, 1080, 33, 270, 1080, 1080, 270, 33, 1080, 270, 33, 33, 270, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 270, 33, 1080, 1080, 270, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 33, 1080, 270, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 270, 270, 1080, 270, 33, 33]
Prompts retrieved: 88512 . Total input tokens: 19700412 . Total output tokens: 17743755
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 2.981968983076513,
    "estimated_duration": 3600.033537789929,
    "input_throughput": 2021.264225351394,
    "output_throughput": 1814.1833767497271,
    "total_throughput": 3835.4476021011214,
    "itl": 28.375555279773394,
    "ttft": 32610.57345347531,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9347,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.948000106448504,
    "arrivals": 29640,
    "finished_requests": 29451,
    "scheduler_time": 5.491397738702607
}
#Debug simulation 
Total elapsed time: 2.9820480132475495. Arrivals time: 0.08209674619138241 Scheduler time: 2.5321651459671557 Scheduler overhead time: 0.12036299286410213 Adapter cache time: 0.07442534854635596 Engine time: 0.11639798851683736 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_192_slots_32_rate_0.1-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_192_slots_32_rate_0.1-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 270, 270, 270, 270, 1080, 270, 33, 1080, 33, 270, 270, 33, 1080, 1080, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 1080, 270, 33, 270, 1080, 1080, 270, 1080, 33, 270, 270, 1080, 270, 33, 33, 270, 1080, 33, 270, 33, 1080, 1080, 270, 1080, 1080, 1080, 33, 270, 1080, 33, 270, 33, 270, 33, 33, 270, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 270, 33, 33, 33, 33, 33, 1080, 33, 270, 33, 1080, 1080, 33, 1080, 33, 270, 270, 1080, 33, 33, 33, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 33, 1080, 270, 270, 270, 1080, 270, 33, 270, 1080, 1080, 270, 1080, 270, 33, 1080, 270, 33, 270, 270, 33, 270, 1080, 33, 270, 1080, 33, 270, 1080, 1080, 270, 33, 1080, 270, 33, 33, 270, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 270, 33, 1080, 1080, 270, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 33, 1080, 270, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 270, 270, 1080, 270, 33, 33]
Prompts retrieved: 88512 . Total input tokens: 19700412 . Total output tokens: 17743755
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.9816840551793575,
    "estimated_duration": 3600.0206321715373,
    "input_throughput": 2021.2714713278556,
    "output_throughput": 1814.189880367552,
    "total_throughput": 3835.4613516954078,
    "itl": 28.405838823850544,
    "ttft": 32536.696606707956,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9319,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 31.168802915473613,
    "arrivals": 29640,
    "finished_requests": 29451,
    "scheduler_time": 5.521259819450962
}
#Debug simulation 
Total elapsed time: 2.9817765671759844. Arrivals time: 0.08186775539070368 Scheduler time: 2.532374654430896 Scheduler overhead time: 0.11999188363552094 Adapter cache time: 0.07403257815167308 Engine time: 0.11658285837620497 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_192_slots_32_rate_0.1-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_192_slots_32_rate_0.1-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 135, 135, 135, 135, 1080, 135, 66, 1080, 66, 135, 135, 66, 1080, 1080, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 1080, 135, 66, 135, 1080, 1080, 135, 1080, 66, 135, 135, 1080, 135, 66, 66, 135, 1080, 66, 135, 66, 1080, 1080, 135, 1080, 1080, 1080, 66, 135, 1080, 66, 135, 66, 135, 66, 66, 135, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 135, 66, 66, 66, 66, 66, 1080, 66, 135, 66, 1080, 1080, 66, 1080, 66, 135, 135, 1080, 66, 66, 66, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 66, 1080, 135, 135, 135, 1080, 135, 66, 135, 1080, 1080, 135, 1080, 135, 66, 1080, 135, 66, 135, 135, 66, 135, 1080, 66, 135, 1080, 66, 135, 1080, 1080, 135, 66, 1080, 135, 66, 66, 135, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 135, 66, 1080, 1080, 135, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 135, 135, 135, 135, 135, 135, 66, 1080, 135, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 135, 135, 1080, 135, 66, 66]
Prompts retrieved: 81984 . Total input tokens: 18269562 . Total output tokens: 16390057
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 2.6556934523396194,
    "estimated_duration": 3600.019901013218,
    "input_throughput": 1883.6379204713464,
    "output_throughput": 1662.608031226554,
    "total_throughput": 3546.2459516979006,
    "itl": 27.725135777753216,
    "ttft": 21917.51216129686,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10634,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 32.545226668983844,
    "arrivals": 27529,
    "finished_requests": 27403,
    "scheduler_time": 2.344813425814279
}
#Debug simulation 
Total elapsed time: 2.6557795694097877. Arrivals time: 0.07759714126586914 Scheduler time: 2.197914815042168 Scheduler overhead time: 0.12280718004330993 Adapter cache time: 0.08228694461286068 Engine time: 0.11741882096976042 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_192_slots_32_rate_0.1-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_192_slots_32_rate_0.1-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 135, 135, 135, 135, 1080, 135, 66, 1080, 66, 135, 135, 66, 1080, 1080, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 1080, 135, 66, 135, 1080, 1080, 135, 1080, 66, 135, 135, 1080, 135, 66, 66, 135, 1080, 66, 135, 66, 1080, 1080, 135, 1080, 1080, 1080, 66, 135, 1080, 66, 135, 66, 135, 66, 66, 135, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 135, 66, 66, 66, 66, 66, 1080, 66, 135, 66, 1080, 1080, 66, 1080, 66, 135, 135, 1080, 66, 66, 66, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 66, 1080, 135, 135, 135, 1080, 135, 66, 135, 1080, 1080, 135, 1080, 135, 66, 1080, 135, 66, 135, 135, 66, 135, 1080, 66, 135, 1080, 66, 135, 1080, 1080, 135, 66, 1080, 135, 66, 66, 135, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 135, 66, 1080, 1080, 135, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 135, 135, 135, 135, 135, 135, 66, 1080, 135, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 135, 135, 1080, 135, 66, 66]
Prompts retrieved: 81984 . Total input tokens: 18269562 . Total output tokens: 16390057
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.6429213220253587,
    "estimated_duration": 3600.0124301872324,
    "input_throughput": 1883.6626627001167,
    "output_throughput": 1662.6514813696624,
    "total_throughput": 3546.314144069779,
    "itl": 27.745556555493867,
    "ttft": 21939.004696415355,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10617,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 34.563854487575114,
    "arrivals": 27529,
    "finished_requests": 27403,
    "scheduler_time": 2.3559965653637116
}
#Debug simulation 
Total elapsed time: 2.6429893570020795. Arrivals time: 0.07668215362355113 Scheduler time: 2.184756799135357 Scheduler overhead time: 0.1241819248534739 Adapter cache time: 0.081324209459126 Engine time: 0.11735755251720548 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_192_slots_32_rate_0.1-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_192_slots_32_rate_0.1-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 135, 135, 135, 135, 1080, 135, 66, 1080, 66, 135, 135, 66, 1080, 1080, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 1080, 135, 66, 135, 1080, 1080, 135, 1080, 66, 135, 135, 1080, 135, 66, 66, 135, 1080, 66, 135, 66, 1080, 1080, 135, 1080, 1080, 1080, 66, 135, 1080, 66, 135, 66, 135, 66, 66, 135, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 135, 66, 66, 66, 66, 66, 1080, 66, 135, 66, 1080, 1080, 66, 1080, 66, 135, 135, 1080, 66, 66, 66, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 66, 1080, 135, 135, 135, 1080, 135, 66, 135, 1080, 1080, 135, 1080, 135, 66, 1080, 135, 66, 135, 135, 66, 135, 1080, 66, 135, 1080, 66, 135, 1080, 1080, 135, 66, 1080, 135, 66, 66, 135, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 135, 66, 1080, 1080, 135, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 135, 135, 135, 135, 135, 135, 66, 1080, 135, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 135, 135, 1080, 135, 66, 66]
Prompts retrieved: 81984 . Total input tokens: 18269562 . Total output tokens: 16390057
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.6390864797867835,
    "estimated_duration": 3600.0175618583066,
    "input_throughput": 1883.8252545910568,
    "output_throughput": 1662.723277635943,
    "total_throughput": 3546.5485322269997,
    "itl": 27.74832302234116,
    "ttft": 21671.994145242745,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10617,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 34.64072182461919,
    "arrivals": 27529,
    "finished_requests": 27405,
    "scheduler_time": 2.3595938344867298
}
#Debug simulation 
Total elapsed time: 2.6391847557388246. Arrivals time: 0.07702477462589741 Scheduler time: 2.181653053034097 Scheduler overhead time: 0.1220513773150742 Adapter cache time: 0.08111986517906189 Engine time: 0.11925562750548124 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_192_slots_32_rate_0.1-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_192_slots_32_rate_0.1-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 135, 135, 135, 135, 1080, 135, 66, 1080, 66, 135, 135, 66, 1080, 1080, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 1080, 135, 66, 135, 1080, 1080, 135, 1080, 66, 135, 135, 1080, 135, 66, 66, 135, 1080, 66, 135, 66, 1080, 1080, 135, 1080, 1080, 1080, 66, 135, 1080, 66, 135, 66, 135, 66, 66, 135, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 135, 66, 66, 66, 66, 66, 1080, 66, 135, 66, 1080, 1080, 66, 1080, 66, 135, 135, 1080, 66, 66, 66, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 66, 1080, 135, 135, 135, 1080, 135, 66, 135, 1080, 1080, 135, 1080, 135, 66, 1080, 135, 66, 135, 135, 66, 135, 1080, 66, 135, 1080, 66, 135, 1080, 1080, 135, 66, 1080, 135, 66, 66, 135, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 135, 66, 1080, 1080, 135, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 135, 135, 135, 135, 135, 135, 66, 1080, 135, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 135, 135, 1080, 135, 66, 66]
Prompts retrieved: 81984 . Total input tokens: 18269562 . Total output tokens: 16390057
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 2.644651251845062,
    "estimated_duration": 3600.021494694915,
    "input_throughput": 1883.8231966097542,
    "output_throughput": 1662.721461197073,
    "total_throughput": 3546.544657806827,
    "itl": 27.73319115425895,
    "ttft": 21667.64799494909,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10618,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 33.2123510572399,
    "arrivals": 27529,
    "finished_requests": 27405,
    "scheduler_time": 2.3502632033218855
}
#Debug simulation 
Total elapsed time: 2.644739478826523. Arrivals time: 0.07789230719208717 Scheduler time: 2.1878189062699676 Scheduler overhead time: 0.12218140624463558 Adapter cache time: 0.08134371787309647 Engine time: 0.1174804512411356 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_192_slots_32_rate_0.1-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_192_slots_32_rate_0.1-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 135, 135, 135, 135, 1080, 135, 66, 1080, 66, 135, 135, 66, 1080, 1080, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 1080, 135, 66, 135, 1080, 1080, 135, 1080, 66, 135, 135, 1080, 135, 66, 66, 135, 1080, 66, 135, 66, 1080, 1080, 135, 1080, 1080, 1080, 66, 135, 1080, 66, 135, 66, 135, 66, 66, 135, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 135, 66, 66, 66, 66, 66, 1080, 66, 135, 66, 1080, 1080, 66, 1080, 66, 135, 135, 1080, 66, 66, 66, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 66, 1080, 135, 135, 135, 1080, 135, 66, 135, 1080, 1080, 135, 1080, 135, 66, 1080, 135, 66, 135, 135, 66, 135, 1080, 66, 135, 1080, 66, 135, 1080, 1080, 135, 66, 1080, 135, 66, 66, 135, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 135, 66, 1080, 1080, 135, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 135, 135, 135, 135, 135, 135, 66, 1080, 135, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 135, 135, 1080, 135, 66, 66]
Prompts retrieved: 81984 . Total input tokens: 18269562 . Total output tokens: 16390057
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 2.6459329472854733,
    "estimated_duration": 3600.0191619351344,
    "input_throughput": 1883.824417299642,
    "output_throughput": 1662.722538616269,
    "total_throughput": 3546.546955915911,
    "itl": 27.749900205625092,
    "ttft": 21682.24891114818,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10617,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 35.05649814417656,
    "arrivals": 27529,
    "finished_requests": 27405,
    "scheduler_time": 2.3621763337929886
}
#Debug simulation 
Total elapsed time: 2.646038413979113. Arrivals time: 0.07820626953616738 Scheduler time: 2.1885508191771805 Scheduler overhead time: 0.1231847652234137 Adapter cache time: 0.08112073130905628 Engine time: 0.11704876739531755 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_192_slots_32_rate_0.1-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_192_slots_32_rate_0.1-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 135, 135, 135, 135, 1080, 135, 66, 1080, 66, 135, 135, 66, 1080, 1080, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 1080, 135, 66, 135, 1080, 1080, 135, 1080, 66, 135, 135, 1080, 135, 66, 66, 135, 1080, 66, 135, 66, 1080, 1080, 135, 1080, 1080, 1080, 66, 135, 1080, 66, 135, 66, 135, 66, 66, 135, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 135, 66, 66, 66, 66, 66, 1080, 66, 135, 66, 1080, 1080, 66, 1080, 66, 135, 135, 1080, 66, 66, 66, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 66, 1080, 135, 135, 135, 1080, 135, 66, 135, 1080, 1080, 135, 1080, 135, 66, 1080, 135, 66, 135, 135, 66, 135, 1080, 66, 135, 1080, 66, 135, 1080, 1080, 135, 66, 1080, 135, 66, 66, 135, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 135, 66, 1080, 1080, 135, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 135, 135, 135, 135, 135, 135, 66, 1080, 135, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 135, 135, 1080, 135, 66, 66]
Prompts retrieved: 81984 . Total input tokens: 18269562 . Total output tokens: 16390057
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 2.6337074819020927,
    "estimated_duration": 3600.006514702501,
    "input_throughput": 1883.6449246149161,
    "output_throughput": 1662.614213489729,
    "total_throughput": 3546.2591381046454,
    "itl": 27.717848575954854,
    "ttft": 21902.404002662428,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10644,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 31.826095338935335,
    "arrivals": 27529,
    "finished_requests": 27403,
    "scheduler_time": 2.341125802374412
}
#Debug simulation 
Total elapsed time: 2.633796284906566. Arrivals time: 0.07737791119143367 Scheduler time: 2.170975469984114 Scheduler overhead time: 0.127692561596632 Adapter cache time: 0.08161273458972573 Engine time: 0.11734020384028554 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_192_slots_32_rate_0.1-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_192_slots_32_rate_0.1-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 135, 135, 135, 135, 1080, 135, 66, 1080, 66, 135, 135, 66, 1080, 1080, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 1080, 135, 66, 135, 1080, 1080, 135, 1080, 66, 135, 135, 1080, 135, 66, 66, 135, 1080, 66, 135, 66, 1080, 1080, 135, 1080, 1080, 1080, 66, 135, 1080, 66, 135, 66, 135, 66, 66, 135, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 135, 66, 66, 66, 66, 66, 1080, 66, 135, 66, 1080, 1080, 66, 1080, 66, 135, 135, 1080, 66, 66, 66, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 66, 1080, 135, 135, 135, 1080, 135, 66, 135, 1080, 1080, 135, 1080, 135, 66, 1080, 135, 66, 135, 135, 66, 135, 1080, 66, 135, 1080, 66, 135, 1080, 1080, 135, 66, 1080, 135, 66, 66, 135, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 135, 66, 1080, 1080, 135, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 135, 135, 135, 135, 135, 135, 66, 1080, 135, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 135, 135, 1080, 135, 66, 66]
Prompts retrieved: 81984 . Total input tokens: 18269562 . Total output tokens: 16390057
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.6670593516901135,
    "estimated_duration": 3600.0273578553924,
    "input_throughput": 1883.820128533705,
    "output_throughput": 1662.7187532168864,
    "total_throughput": 3546.5388817505914,
    "itl": 27.755119476636196,
    "ttft": 21681.62654762108,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10623,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 35.52739857282314,
    "arrivals": 27529,
    "finished_requests": 27405,
    "scheduler_time": 2.365059172622278
}
#Debug simulation 
Total elapsed time: 2.667140144854784. Arrivals time: 0.07715988159179688 Scheduler time: 2.209420802537352 Scheduler overhead time: 0.12176597537472844 Adapter cache time: 0.08149692695587873 Engine time: 0.11939135380089283 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_192_slots_32_rate_0.1-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_192_slots_32_rate_0.1-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 135, 135, 135, 135, 1080, 135, 33, 1080, 33, 135, 135, 33, 1080, 1080, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 1080, 135, 33, 135, 1080, 1080, 135, 1080, 33, 135, 135, 1080, 135, 33, 33, 135, 1080, 33, 135, 33, 1080, 1080, 135, 1080, 1080, 1080, 33, 135, 1080, 33, 135, 33, 135, 33, 33, 135, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 135, 33, 33, 33, 33, 33, 1080, 33, 135, 33, 1080, 1080, 33, 1080, 33, 135, 135, 1080, 33, 33, 33, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 33, 1080, 135, 135, 135, 1080, 135, 33, 135, 1080, 1080, 135, 1080, 135, 33, 1080, 135, 33, 135, 135, 33, 135, 1080, 33, 135, 1080, 33, 135, 1080, 1080, 135, 33, 1080, 135, 33, 33, 135, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 135, 33, 1080, 1080, 135, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 135, 135, 135, 135, 135, 135, 33, 1080, 135, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 79872 . Total input tokens: 17789080 . Total output tokens: 15964667
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 2.5101217119954526,
    "estimated_duration": 3599.980508324483,
    "input_throughput": 1816.1798334411096,
    "output_throughput": 1624.5985183742127,
    "total_throughput": 3440.7783518153224,
    "itl": 27.609136930495936,
    "ttft": 15199.60122568668,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10826,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 33.13284031581844,
    "arrivals": 26760,
    "finished_requests": 26679,
    "scheduler_time": 1.7290424692804334
}
#Debug simulation 
Total elapsed time: 2.510189120657742. Arrivals time: 0.07502736058086157 Scheduler time: 2.055816006846726 Scheduler overhead time: 0.12168675940483809 Adapter cache time: 0.08151593618094921 Engine time: 0.11825893819332123 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_192_slots_32_rate_0.1-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_192_slots_32_rate_0.1-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 135, 135, 135, 135, 1080, 135, 33, 1080, 33, 135, 135, 33, 1080, 1080, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 1080, 135, 33, 135, 1080, 1080, 135, 1080, 33, 135, 135, 1080, 135, 33, 33, 135, 1080, 33, 135, 33, 1080, 1080, 135, 1080, 1080, 1080, 33, 135, 1080, 33, 135, 33, 135, 33, 33, 135, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 135, 33, 33, 33, 33, 33, 1080, 33, 135, 33, 1080, 1080, 33, 1080, 33, 135, 135, 1080, 33, 33, 33, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 33, 1080, 135, 135, 135, 1080, 135, 33, 135, 1080, 1080, 135, 1080, 135, 33, 1080, 135, 33, 135, 135, 33, 135, 1080, 33, 135, 1080, 33, 135, 1080, 1080, 135, 33, 1080, 135, 33, 33, 135, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 135, 33, 1080, 1080, 135, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 135, 135, 135, 135, 135, 135, 33, 1080, 135, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 79872 . Total input tokens: 17789080 . Total output tokens: 15964667
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.518973080907017,
    "estimated_duration": 3599.9779293990755,
    "input_throughput": 1816.3897468925632,
    "output_throughput": 1624.6002377509749,
    "total_throughput": 3440.989984643538,
    "itl": 27.624762234785717,
    "ttft": 15067.516018906106,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10824,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 35.238363861928235,
    "arrivals": 26760,
    "finished_requests": 26680,
    "scheduler_time": 1.7370927386944206
}
#Debug simulation 
Total elapsed time: 2.51904833316803. Arrivals time: 0.07466964051127434 Scheduler time: 2.0673250295221806 Scheduler overhead time: 0.1220158888027072 Adapter cache time: 0.08134910138323903 Engine time: 0.11581917945295572 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_192_slots_32_rate_0.1-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_192_slots_32_rate_0.1-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 135, 135, 135, 135, 1080, 135, 33, 1080, 33, 135, 135, 33, 1080, 1080, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 1080, 135, 33, 135, 1080, 1080, 135, 1080, 33, 135, 135, 1080, 135, 33, 33, 135, 1080, 33, 135, 33, 1080, 1080, 135, 1080, 1080, 1080, 33, 135, 1080, 33, 135, 33, 135, 33, 33, 135, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 135, 33, 33, 33, 33, 33, 1080, 33, 135, 33, 1080, 1080, 33, 1080, 33, 135, 135, 1080, 33, 33, 33, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 33, 1080, 135, 135, 135, 1080, 135, 33, 135, 1080, 1080, 135, 1080, 135, 33, 1080, 135, 33, 135, 135, 33, 135, 1080, 33, 135, 1080, 33, 135, 1080, 1080, 135, 33, 1080, 135, 33, 33, 135, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 135, 33, 1080, 1080, 135, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 135, 135, 135, 135, 135, 135, 33, 1080, 135, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 79872 . Total input tokens: 17789080 . Total output tokens: 15964667
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.53147582616657,
    "estimated_duration": 3599.9863580409706,
    "input_throughput": 1816.3854941823593,
    "output_throughput": 1624.5964340772202,
    "total_throughput": 3440.9819282595795,
    "itl": 27.624362189682824,
    "ttft": 15068.643760294563,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10818,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 35.29462505003767,
    "arrivals": 26760,
    "finished_requests": 26680,
    "scheduler_time": 1.7351957734418084
}
#Debug simulation 
Total elapsed time: 2.531551503110677. Arrivals time: 0.0750207151286304 Scheduler time: 2.0745125389657915 Scheduler overhead time: 0.12498818058520555 Adapter cache time: 0.08134313859045506 Engine time: 0.116974379401654 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_192_slots_32_rate_0.1-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_192_slots_32_rate_0.1-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 135, 135, 135, 135, 1080, 135, 33, 1080, 33, 135, 135, 33, 1080, 1080, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 1080, 135, 33, 135, 1080, 1080, 135, 1080, 33, 135, 135, 1080, 135, 33, 33, 135, 1080, 33, 135, 33, 1080, 1080, 135, 1080, 1080, 1080, 33, 135, 1080, 33, 135, 33, 135, 33, 33, 135, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 135, 33, 33, 33, 33, 33, 1080, 33, 135, 33, 1080, 1080, 33, 1080, 33, 135, 135, 1080, 33, 33, 33, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 33, 1080, 135, 135, 135, 1080, 135, 33, 135, 1080, 1080, 135, 1080, 135, 33, 1080, 135, 33, 135, 135, 33, 135, 1080, 33, 135, 1080, 33, 135, 1080, 1080, 135, 33, 1080, 135, 33, 33, 135, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 135, 33, 1080, 1080, 135, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 135, 135, 135, 135, 135, 135, 33, 1080, 135, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 79872 . Total input tokens: 17789080 . Total output tokens: 15964667
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 2.538992331828922,
    "estimated_duration": 3599.977140322639,
    "input_throughput": 1816.3901450257435,
    "output_throughput": 1624.6005938459489,
    "total_throughput": 3440.9907388716924,
    "itl": 27.614313530737036,
    "ttft": 15072.486504120208,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10823,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 33.85105287275707,
    "arrivals": 26760,
    "finished_requests": 26680,
    "scheduler_time": 1.732464436285785
}
#Debug simulation 
Total elapsed time: 2.539102939888835. Arrivals time: 0.07588225463405252 Scheduler time: 2.0815238715149462 Scheduler overhead time: 0.1215626010671258 Adapter cache time: 0.08188957814127207 Engine time: 0.11991084553301334 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_192_slots_32_rate_0.1-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_192_slots_32_rate_0.1-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 135, 135, 135, 135, 1080, 135, 33, 1080, 33, 135, 135, 33, 1080, 1080, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 1080, 135, 33, 135, 1080, 1080, 135, 1080, 33, 135, 135, 1080, 135, 33, 33, 135, 1080, 33, 135, 33, 1080, 1080, 135, 1080, 1080, 1080, 33, 135, 1080, 33, 135, 33, 135, 33, 33, 135, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 135, 33, 33, 33, 33, 33, 1080, 33, 135, 33, 1080, 1080, 33, 1080, 33, 135, 135, 1080, 33, 33, 33, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 33, 1080, 135, 135, 135, 1080, 135, 33, 135, 1080, 1080, 135, 1080, 135, 33, 1080, 135, 33, 135, 135, 33, 135, 1080, 33, 135, 1080, 33, 135, 1080, 1080, 135, 33, 1080, 135, 33, 33, 135, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 135, 33, 1080, 1080, 135, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 135, 135, 135, 135, 135, 135, 33, 1080, 135, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 79872 . Total input tokens: 17789080 . Total output tokens: 15964667
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 2.5192598858848214,
    "estimated_duration": 3599.9773380900574,
    "input_throughput": 1816.390045241007,
    "output_throughput": 1624.6005045973134,
    "total_throughput": 3440.9905498383205,
    "itl": 27.630013094596524,
    "ttft": 15072.490757964872,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10812,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 35.701914750170964,
    "arrivals": 26760,
    "finished_requests": 26680,
    "scheduler_time": 1.7397541425633738
}
#Debug simulation 
Total elapsed time: 2.5193382636643946. Arrivals time: 0.07465375401079655 Scheduler time: 2.0663451394066215 Scheduler overhead time: 0.12178268888965249 Adapter cache time: 0.0814234409481287 Engine time: 0.11711291410028934 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_192_slots_32_rate_0.1-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_192_slots_32_rate_0.1-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 135, 135, 135, 135, 1080, 135, 33, 1080, 33, 135, 135, 33, 1080, 1080, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 1080, 135, 33, 135, 1080, 1080, 135, 1080, 33, 135, 135, 1080, 135, 33, 33, 135, 1080, 33, 135, 33, 1080, 1080, 135, 1080, 1080, 1080, 33, 135, 1080, 33, 135, 33, 135, 33, 33, 135, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 135, 33, 33, 33, 33, 33, 1080, 33, 135, 33, 1080, 1080, 33, 1080, 33, 135, 135, 1080, 33, 33, 33, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 33, 1080, 135, 135, 135, 1080, 135, 33, 135, 1080, 1080, 135, 1080, 135, 33, 1080, 135, 33, 135, 135, 33, 135, 1080, 33, 135, 1080, 33, 135, 1080, 1080, 135, 33, 1080, 135, 33, 33, 135, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 135, 33, 1080, 1080, 135, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 135, 135, 135, 135, 135, 135, 33, 1080, 135, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 79872 . Total input tokens: 17789080 . Total output tokens: 15964667
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 2.5285926931537688,
    "estimated_duration": 3599.9751838088487,
    "input_throughput": 1816.182519647937,
    "output_throughput": 1624.6009212241684,
    "total_throughput": 3440.783440872105,
    "itl": 27.600446595802975,
    "ttft": 15194.44020902971,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10835,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 32.39719494526193,
    "arrivals": 26760,
    "finished_requests": 26679,
    "scheduler_time": 1.723591517859922
}
#Debug simulation 
Total elapsed time: 2.528677531052381. Arrivals time: 0.07701029628515244 Scheduler time: 2.071533937007189 Scheduler overhead time: 0.12281779386103153 Adapter cache time: 0.08183137839660048 Engine time: 0.11751315370202065 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_192_slots_32_rate_0.1-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_192_slots_32_rate_0.1-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 135, 135, 135, 135, 1080, 135, 33, 1080, 33, 135, 135, 33, 1080, 1080, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 1080, 135, 33, 135, 1080, 1080, 135, 1080, 33, 135, 135, 1080, 135, 33, 33, 135, 1080, 33, 135, 33, 1080, 1080, 135, 1080, 1080, 1080, 33, 135, 1080, 33, 135, 33, 135, 33, 33, 135, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 135, 33, 33, 33, 33, 33, 1080, 33, 135, 33, 1080, 1080, 33, 1080, 33, 135, 135, 1080, 33, 33, 33, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 33, 1080, 135, 135, 135, 1080, 135, 33, 135, 1080, 1080, 135, 1080, 135, 33, 1080, 135, 33, 135, 135, 33, 135, 1080, 33, 135, 1080, 33, 135, 1080, 1080, 135, 33, 1080, 135, 33, 33, 135, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 135, 33, 1080, 1080, 135, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 135, 135, 135, 135, 135, 135, 33, 1080, 135, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 79872 . Total input tokens: 17789080 . Total output tokens: 15964667
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.5231670080684125,
    "estimated_duration": 3599.9722895561276,
    "input_throughput": 1816.3925925124959,
    "output_throughput": 1624.6027829067307,
    "total_throughput": 3440.9953754192265,
    "itl": 27.633357355389663,
    "ttft": 15081.608749187615,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10804,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 36.13244663432084,
    "arrivals": 26760,
    "finished_requests": 26680,
    "scheduler_time": 1.7464958879292178
}
#Debug simulation 
Total elapsed time: 2.5232341708615422. Arrivals time: 0.07502712588757277 Scheduler time: 2.068985005374998 Scheduler overhead time: 0.12242712965235114 Adapter cache time: 0.08103767316788435 Engine time: 0.11784041998907924 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_192_slots_32_rate_0.1-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_192_slots_32_rate_0.1-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 66, 66, 66, 66, 1080, 66, 33, 1080, 33, 66, 66, 33, 1080, 1080, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 1080, 66, 33, 66, 1080, 1080, 66, 1080, 33, 66, 66, 1080, 66, 33, 33, 66, 1080, 33, 66, 33, 1080, 1080, 66, 1080, 1080, 1080, 33, 66, 1080, 33, 66, 33, 66, 33, 33, 66, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 66, 33, 33, 33, 33, 33, 1080, 33, 66, 33, 1080, 1080, 33, 1080, 33, 66, 66, 1080, 33, 33, 33, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 33, 1080, 66, 66, 66, 1080, 66, 33, 66, 1080, 1080, 66, 1080, 66, 33, 1080, 66, 33, 66, 66, 33, 66, 1080, 33, 66, 1080, 33, 66, 1080, 1080, 66, 33, 1080, 66, 33, 33, 66, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 66, 33, 1080, 1080, 66, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 66, 66, 66, 66, 66, 66, 33, 1080, 66, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 75456 . Total input tokens: 16792402 . Total output tokens: 15073813
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 2.3668857449665666,
    "estimated_duration": 3599.8666965954167,
    "input_throughput": 1728.362054596175,
    "output_throughput": 1542.4115579755407,
    "total_throughput": 3270.773612571716,
    "itl": 27.25315897790284,
    "ttft": 10463.336566833854,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11454,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 35.054826619006604,
    "arrivals": 25342,
    "finished_requests": 25284,
    "scheduler_time": 0.6637929749621594
}
#Debug simulation 
Total elapsed time: 2.36696569994092. Arrivals time: 0.071973723359406 Scheduler time: 1.9102334836497903 Scheduler overhead time: 0.12300822418183088 Adapter cache time: 0.08470907295122743 Engine time: 0.11852110316976905 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_192_slots_32_rate_0.1-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_192_slots_32_rate_0.1-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 66, 66, 66, 66, 1080, 66, 33, 1080, 33, 66, 66, 33, 1080, 1080, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 1080, 66, 33, 66, 1080, 1080, 66, 1080, 33, 66, 66, 1080, 66, 33, 33, 66, 1080, 33, 66, 33, 1080, 1080, 66, 1080, 1080, 1080, 33, 66, 1080, 33, 66, 33, 66, 33, 33, 66, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 66, 33, 33, 33, 33, 33, 1080, 33, 66, 33, 1080, 1080, 33, 1080, 33, 66, 66, 1080, 33, 33, 33, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 33, 1080, 66, 66, 66, 1080, 66, 33, 66, 1080, 1080, 66, 1080, 66, 33, 1080, 66, 33, 66, 66, 33, 66, 1080, 33, 66, 1080, 33, 66, 1080, 1080, 66, 33, 1080, 66, 33, 33, 66, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 66, 33, 1080, 1080, 66, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 66, 66, 66, 66, 66, 66, 33, 1080, 66, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 75456 . Total input tokens: 16792402 . Total output tokens: 15073813
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.3189626252278686,
    "estimated_duration": 3599.8838332450277,
    "input_throughput": 1728.3538270154245,
    "output_throughput": 1542.4042155812722,
    "total_throughput": 3270.7580425966967,
    "itl": 27.270137684609725,
    "ttft": 10476.056775278874,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11447,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 37.25071108220294,
    "arrivals": 25342,
    "finished_requests": 25284,
    "scheduler_time": 0.670326901051326
}
#Debug simulation 
Total elapsed time: 2.3190398779697716. Arrivals time: 0.07126235077157617 Scheduler time: 1.8666592696681619 Scheduler overhead time: 0.12236167909577489 Adapter cache time: 0.08324208855628967 Engine time: 0.11740890936926007 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_192_slots_32_rate_0.1-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_192_slots_32_rate_0.1-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 66, 66, 66, 66, 1080, 66, 33, 1080, 33, 66, 66, 33, 1080, 1080, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 1080, 66, 33, 66, 1080, 1080, 66, 1080, 33, 66, 66, 1080, 66, 33, 33, 66, 1080, 33, 66, 33, 1080, 1080, 66, 1080, 1080, 1080, 33, 66, 1080, 33, 66, 33, 66, 33, 33, 66, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 66, 33, 33, 33, 33, 33, 1080, 33, 66, 33, 1080, 1080, 33, 1080, 33, 66, 66, 1080, 33, 33, 33, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 33, 1080, 66, 66, 66, 1080, 66, 33, 66, 1080, 1080, 66, 1080, 66, 33, 1080, 66, 33, 66, 66, 33, 66, 1080, 33, 66, 1080, 33, 66, 1080, 1080, 66, 33, 1080, 66, 33, 33, 66, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 66, 33, 1080, 1080, 66, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 66, 66, 66, 66, 66, 66, 33, 1080, 66, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 75456 . Total input tokens: 16792402 . Total output tokens: 15073813
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.3313310630619526,
    "estimated_duration": 3599.8868165696385,
    "input_throughput": 1728.352394681362,
    "output_throughput": 1542.4029373487358,
    "total_throughput": 3270.7553320300976,
    "itl": 27.271883552580604,
    "ttft": 10475.913529354844,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11442,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 37.31889963213804,
    "arrivals": 25342,
    "finished_requests": 25284,
    "scheduler_time": 0.6706177467587329
}
#Debug simulation 
Total elapsed time: 2.3314128569327295. Arrivals time: 0.07257389090955257 Scheduler time: 1.874340868089348 Scheduler overhead time: 0.12247775308787823 Adapter cache time: 0.08439467707648873 Engine time: 0.11953266384080052 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_192_slots_32_rate_0.1-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_192_slots_32_rate_0.1-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 66, 66, 66, 66, 1080, 66, 33, 1080, 33, 66, 66, 33, 1080, 1080, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 1080, 66, 33, 66, 1080, 1080, 66, 1080, 33, 66, 66, 1080, 66, 33, 33, 66, 1080, 33, 66, 33, 1080, 1080, 66, 1080, 1080, 1080, 33, 66, 1080, 33, 66, 33, 66, 33, 33, 66, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 66, 33, 33, 33, 33, 33, 1080, 33, 66, 33, 1080, 1080, 33, 1080, 33, 66, 66, 1080, 33, 33, 33, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 33, 1080, 66, 66, 66, 1080, 66, 33, 66, 1080, 1080, 66, 1080, 66, 33, 1080, 66, 33, 66, 66, 33, 66, 1080, 33, 66, 1080, 33, 66, 1080, 1080, 66, 33, 1080, 66, 33, 33, 66, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 66, 33, 1080, 1080, 66, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 66, 66, 66, 66, 66, 66, 33, 1080, 66, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 75456 . Total input tokens: 16792402 . Total output tokens: 15073813
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 2.3149604499340057,
    "estimated_duration": 3599.884675750427,
    "input_throughput": 1728.353422517069,
    "output_throughput": 1542.403854601964,
    "total_throughput": 3270.757277119033,
    "itl": 27.25874100985247,
    "ttft": 10467.419014001056,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11458,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 35.832271064346486,
    "arrivals": 25342,
    "finished_requests": 25284,
    "scheduler_time": 0.6661262885183018
}
#Debug simulation 
Total elapsed time: 2.3150336258113384. Arrivals time: 0.07211519731208682 Scheduler time: 1.8625924373045564 Scheduler overhead time: 0.12272898154333234 Adapter cache time: 0.08348609926179051 Engine time: 0.11593361664563417 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_192_slots_32_rate_0.1-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_192_slots_32_rate_0.1-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 66, 66, 66, 66, 1080, 66, 33, 1080, 33, 66, 66, 33, 1080, 1080, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 1080, 66, 33, 66, 1080, 1080, 66, 1080, 33, 66, 66, 1080, 66, 33, 33, 66, 1080, 33, 66, 33, 1080, 1080, 66, 1080, 1080, 1080, 33, 66, 1080, 33, 66, 33, 66, 33, 33, 66, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 66, 33, 33, 33, 33, 33, 1080, 33, 66, 33, 1080, 1080, 33, 1080, 33, 66, 66, 1080, 33, 33, 33, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 33, 1080, 66, 66, 66, 1080, 66, 33, 66, 1080, 1080, 66, 1080, 66, 33, 1080, 66, 33, 66, 66, 33, 66, 1080, 33, 66, 1080, 33, 66, 1080, 1080, 66, 33, 1080, 66, 33, 33, 66, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 66, 33, 1080, 1080, 66, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 66, 66, 66, 66, 66, 66, 33, 1080, 66, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 75456 . Total input tokens: 16792402 . Total output tokens: 15073813
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 2.370093525853008,
    "estimated_duration": 3599.877226121881,
    "input_throughput": 1728.3569991921013,
    "output_throughput": 1542.4070464707593,
    "total_throughput": 3270.7640456628606,
    "itl": 27.275283492616218,
    "ttft": 10479.315516163138,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11443,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 37.769460862969964,
    "arrivals": 25342,
    "finished_requests": 25284,
    "scheduler_time": 0.6716417166136128
}
#Debug simulation 
Total elapsed time: 2.37015981413424. Arrivals time: 0.07245492748916149 Scheduler time: 1.91176926670596 Scheduler overhead time: 0.12240811809897423 Adapter cache time: 0.08521394990384579 Engine time: 0.11987882759422064 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_192_slots_32_rate_0.1-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_192_slots_32_rate_0.1-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 66, 66, 66, 66, 1080, 66, 33, 1080, 33, 66, 66, 33, 1080, 1080, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 1080, 66, 33, 66, 1080, 1080, 66, 1080, 33, 66, 66, 1080, 66, 33, 33, 66, 1080, 33, 66, 33, 1080, 1080, 66, 1080, 1080, 1080, 33, 66, 1080, 33, 66, 33, 66, 33, 33, 66, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 66, 33, 33, 33, 33, 33, 1080, 33, 66, 33, 1080, 1080, 33, 1080, 33, 66, 66, 1080, 33, 33, 33, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 33, 1080, 66, 66, 66, 1080, 66, 33, 66, 1080, 1080, 66, 1080, 66, 33, 1080, 66, 33, 66, 66, 33, 66, 1080, 33, 66, 1080, 33, 66, 1080, 1080, 66, 33, 1080, 66, 33, 33, 66, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 66, 33, 1080, 1080, 66, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 66, 66, 66, 66, 66, 66, 33, 1080, 66, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 75456 . Total input tokens: 16792402 . Total output tokens: 15073813
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 2.3364394600503147,
    "estimated_duration": 3599.882484578766,
    "input_throughput": 1728.3544745289212,
    "output_throughput": 1542.4047934302816,
    "total_throughput": 3270.7592679592026,
    "itl": 27.24450409438689,
    "ttft": 10462.025614891223,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11460,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 34.26597637957739,
    "arrivals": 25342,
    "finished_requests": 25284,
    "scheduler_time": 0.660937091384863
}
#Debug simulation 
Total elapsed time: 2.3365132049657404. Arrivals time: 0.07157555362209678 Scheduler time: 1.8811716460622847 Scheduler overhead time: 0.12198932655155659 Adapter cache time: 0.0841903118416667 Engine time: 0.11916199745610356 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_192_slots_32_rate_0.1-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_192_slots_32_rate_0.1-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 66, 66, 66, 66, 1080, 66, 33, 1080, 33, 66, 66, 33, 1080, 1080, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 1080, 66, 33, 66, 1080, 1080, 66, 1080, 33, 66, 66, 1080, 66, 33, 33, 66, 1080, 33, 66, 33, 1080, 1080, 66, 1080, 1080, 1080, 33, 66, 1080, 33, 66, 33, 66, 33, 33, 66, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 66, 33, 33, 33, 33, 33, 1080, 33, 66, 33, 1080, 1080, 33, 1080, 33, 66, 66, 1080, 33, 33, 33, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 33, 1080, 66, 66, 66, 1080, 66, 33, 66, 1080, 1080, 66, 1080, 66, 33, 1080, 66, 33, 66, 66, 33, 66, 1080, 33, 66, 1080, 33, 66, 1080, 1080, 66, 33, 1080, 66, 33, 33, 66, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 66, 33, 1080, 1080, 66, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 66, 66, 66, 66, 66, 66, 33, 1080, 66, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 75456 . Total input tokens: 16792402 . Total output tokens: 15073813
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.3640852537937462,
    "estimated_duration": 3599.8787605010275,
    "input_throughput": 1728.3562625131426,
    "output_throughput": 1542.4063890493946,
    "total_throughput": 3270.762651562537,
    "itl": 27.281029823366325,
    "ttft": 10481.210824368038,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11440,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 38.243139106332286,
    "arrivals": 25342,
    "finished_requests": 25284,
    "scheduler_time": 0.6736410295453872
}
#Debug simulation 
Total elapsed time: 2.364152228925377. Arrivals time: 0.07206094870343804 Scheduler time: 1.9066339344717562 Scheduler overhead time: 0.12234288640320301 Adapter cache time: 0.08447054121643305 Engine time: 0.1203805124387145 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_192_slots_32_rate_0.05-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_192_slots_32_rate_0.05-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [64 64 64]
Adapter prompts. [540, 135, 540, 135, 540, 135, 540, 135, 135, 135, 270, 270, 270, 270, 540, 270, 135, 540, 135, 270, 270, 135, 540, 540, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 540, 270, 135, 270, 540, 540, 270, 540, 135, 270, 270, 540, 270, 135, 135, 270, 540, 135, 270, 135, 540, 540, 270, 540, 540, 540, 135, 270, 540, 135, 270, 135, 270, 135, 135, 270, 540, 540, 135, 135, 135, 540, 540, 540, 270, 135, 135, 135, 135, 135, 540, 135, 270, 135, 540, 540, 135, 540, 135, 270, 270, 540, 135, 135, 135, 540, 540, 270, 540, 270, 540, 540, 270, 270, 135, 540, 270, 270, 270, 540, 270, 135, 270, 540, 540, 270, 540, 270, 135, 540, 270, 135, 270, 270, 135, 270, 540, 135, 270, 540, 135, 270, 540, 540, 270, 135, 540, 270, 135, 135, 270, 540, 540, 540, 135, 540, 135, 540, 135, 270, 135, 540, 540, 270, 540, 135, 540, 540, 540, 135, 540, 540, 540, 270, 270, 270, 270, 270, 270, 135, 540, 270, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 60480 . Total input tokens: 13415393 . Total output tokens: 12119019
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 1.988100925926119,
    "estimated_duration": 3599.5096982064388,
    "input_throughput": 1402.6699254389491,
    "output_throughput": 1231.7727612205795,
    "total_throughput": 2634.4426866595286,
    "itl": 26.013009674532587,
    "ttft": 11394.681734061754,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 14942,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 45.72980786983513,
    "arrivals": 20309,
    "finished_requests": 20253,
    "scheduler_time": 0.0009318446573863519
}
#Debug simulation 
Total elapsed time: 1.9881758457049727. Arrivals time: 0.0607054247520864 Scheduler time: 1.5198106984607875 Scheduler overhead time: 0.12413018383085728 Adapter cache time: 0.10334979370236397 Engine time: 0.12034088699147105 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_192_slots_32_rate_0.05-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_192_slots_32_rate_0.05-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [64 64 64]
Adapter prompts. [540, 135, 540, 135, 540, 135, 540, 135, 135, 135, 270, 270, 270, 270, 540, 270, 135, 540, 135, 270, 270, 135, 540, 540, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 540, 270, 135, 270, 540, 540, 270, 540, 135, 270, 270, 540, 270, 135, 135, 270, 540, 135, 270, 135, 540, 540, 270, 540, 540, 540, 135, 270, 540, 135, 270, 135, 270, 135, 135, 270, 540, 540, 135, 135, 135, 540, 540, 540, 270, 135, 135, 135, 135, 135, 540, 135, 270, 135, 540, 540, 135, 540, 135, 270, 270, 540, 135, 135, 135, 540, 540, 270, 540, 270, 540, 540, 270, 270, 135, 540, 270, 270, 270, 540, 270, 135, 270, 540, 540, 270, 540, 270, 135, 540, 270, 135, 270, 270, 135, 270, 540, 135, 270, 540, 135, 270, 540, 540, 270, 135, 540, 270, 135, 135, 270, 540, 540, 540, 135, 540, 135, 540, 135, 270, 135, 540, 540, 270, 540, 135, 540, 540, 540, 135, 540, 540, 540, 270, 270, 270, 270, 270, 270, 135, 540, 270, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 60480 . Total input tokens: 13415393 . Total output tokens: 12119019
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.9574011201038957,
    "estimated_duration": 3599.5226579890104,
    "input_throughput": 1402.664597427689,
    "output_throughput": 1231.6799812775441,
    "total_throughput": 2634.344578705233,
    "itl": 26.04280529302986,
    "ttft": 11588.03193615101,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 14932,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 48.62551502382194,
    "arrivals": 20309,
    "finished_requests": 20252,
    "scheduler_time": 0.0009648874562637435
}
#Debug simulation 
Total elapsed time: 1.9574861521832645. Arrivals time: 0.06021036859601736 Scheduler time: 1.4912344459444284 Scheduler overhead time: 0.1244772607460618 Adapter cache time: 0.10282849241048098 Engine time: 0.11911853402853012 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_192_slots_32_rate_0.05-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_192_slots_32_rate_0.05-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [64 64 64]
Adapter prompts. [540, 135, 540, 135, 540, 135, 540, 135, 135, 135, 270, 270, 270, 270, 540, 270, 135, 540, 135, 270, 270, 135, 540, 540, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 540, 270, 135, 270, 540, 540, 270, 540, 135, 270, 270, 540, 270, 135, 135, 270, 540, 135, 270, 135, 540, 540, 270, 540, 540, 540, 135, 270, 540, 135, 270, 135, 270, 135, 135, 270, 540, 540, 135, 135, 135, 540, 540, 540, 270, 135, 135, 135, 135, 135, 540, 135, 270, 135, 540, 540, 135, 540, 135, 270, 270, 540, 135, 135, 135, 540, 540, 270, 540, 270, 540, 540, 270, 270, 135, 540, 270, 270, 270, 540, 270, 135, 270, 540, 540, 270, 540, 270, 135, 540, 270, 135, 270, 270, 135, 270, 540, 135, 270, 540, 135, 270, 540, 540, 270, 135, 540, 270, 135, 135, 270, 540, 540, 540, 135, 540, 135, 540, 135, 270, 135, 540, 540, 270, 540, 135, 540, 540, 540, 135, 540, 540, 540, 270, 270, 270, 270, 270, 270, 135, 540, 270, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 60480 . Total input tokens: 13415393 . Total output tokens: 12119019
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.0134852482005954,
    "estimated_duration": 3599.5156814284924,
    "input_throughput": 1402.6673160641158,
    "output_throughput": 1231.6823685125748,
    "total_throughput": 2634.3496845766904,
    "itl": 26.04214132092651,
    "ttft": 11588.717466243856,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 14936,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 48.74177637945077,
    "arrivals": 20309,
    "finished_requests": 20252,
    "scheduler_time": 0.0009691934942169787
}
#Debug simulation 
Total elapsed time: 2.0135617121122777. Arrivals time: 0.06132595706731081 Scheduler time: 1.5431283698417246 Scheduler overhead time: 0.12311911070719361 Adapter cache time: 0.10385202942416072 Engine time: 0.12198044313117862 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_192_slots_32_rate_0.05-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_192_slots_32_rate_0.05-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [64 64 64]
Adapter prompts. [540, 135, 540, 135, 540, 135, 540, 135, 135, 135, 270, 270, 270, 270, 540, 270, 135, 540, 135, 270, 270, 135, 540, 540, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 540, 270, 135, 270, 540, 540, 270, 540, 135, 270, 270, 540, 270, 135, 135, 270, 540, 135, 270, 135, 540, 540, 270, 540, 540, 540, 135, 270, 540, 135, 270, 135, 270, 135, 135, 270, 540, 540, 135, 135, 135, 540, 540, 540, 270, 135, 135, 135, 135, 135, 540, 135, 270, 135, 540, 540, 135, 540, 135, 270, 270, 540, 135, 135, 135, 540, 540, 270, 540, 270, 540, 540, 270, 270, 135, 540, 270, 270, 270, 540, 270, 135, 270, 540, 540, 270, 540, 270, 135, 540, 270, 135, 270, 270, 135, 270, 540, 135, 270, 540, 135, 270, 540, 540, 270, 135, 540, 270, 135, 135, 270, 540, 540, 540, 135, 540, 135, 540, 135, 270, 135, 540, 540, 270, 540, 135, 540, 540, 540, 135, 540, 540, 540, 270, 270, 270, 270, 270, 270, 135, 540, 270, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 60480 . Total input tokens: 13415393 . Total output tokens: 12119019
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 1.948496744967997,
    "estimated_duration": 3599.5009549900706,
    "input_throughput": 1402.6730547190334,
    "output_throughput": 1231.687407626269,
    "total_throughput": 2634.3604623453025,
    "itl": 26.023144056715427,
    "ttft": 11576.820584737341,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 14936,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 46.68602398413047,
    "arrivals": 20309,
    "finished_requests": 20252,
    "scheduler_time": 0.0009448498202386683
}
#Debug simulation 
Total elapsed time: 1.9485652446746826. Arrivals time: 0.06002483889460564 Scheduler time: 1.481178495567292 Scheduler overhead time: 0.12489632936194539 Adapter cache time: 0.10311989393085241 Engine time: 0.11922764545306563 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_192_slots_32_rate_0.05-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_192_slots_32_rate_0.05-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [64 64 64]
Adapter prompts. [540, 135, 540, 135, 540, 135, 540, 135, 135, 135, 270, 270, 270, 270, 540, 270, 135, 540, 135, 270, 270, 135, 540, 540, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 540, 270, 135, 270, 540, 540, 270, 540, 135, 270, 270, 540, 270, 135, 135, 270, 540, 135, 270, 135, 540, 540, 270, 540, 540, 540, 135, 270, 540, 135, 270, 135, 270, 135, 135, 270, 540, 540, 135, 135, 135, 540, 540, 540, 270, 135, 135, 135, 135, 135, 540, 135, 270, 135, 540, 540, 135, 540, 135, 270, 270, 540, 135, 135, 135, 540, 540, 270, 540, 270, 540, 540, 270, 270, 135, 540, 270, 270, 270, 540, 270, 135, 270, 540, 540, 270, 540, 270, 135, 540, 270, 135, 270, 270, 135, 270, 540, 135, 270, 540, 135, 270, 540, 540, 270, 135, 540, 270, 135, 135, 270, 540, 540, 540, 135, 540, 135, 540, 135, 270, 135, 540, 540, 270, 540, 135, 540, 540, 540, 135, 540, 540, 540, 270, 270, 270, 270, 270, 270, 135, 540, 270, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 60480 . Total input tokens: 13415393 . Total output tokens: 12119019
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 1.9389910218305886,
    "estimated_duration": 3599.507377083393,
    "input_throughput": 1402.6705521273411,
    "output_throughput": 1231.6852101001505,
    "total_throughput": 2634.3557622274916,
    "itl": 26.04656194642329,
    "ttft": 11591.859634954526,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 14932,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 49.32973938668803,
    "arrivals": 20309,
    "finished_requests": 20252,
    "scheduler_time": 0.0009862067123910028
}
#Debug simulation 
Total elapsed time: 1.9390677860938013. Arrivals time: 0.06059511564671993 Scheduler time: 1.4738405845128 Scheduler overhead time: 0.12326483009383082 Adapter cache time: 0.10190675361081958 Engine time: 0.12002736050635576 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_192_slots_32_rate_0.05-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_192_slots_32_rate_0.05-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [64 64 64]
Adapter prompts. [540, 135, 540, 135, 540, 135, 540, 135, 135, 135, 270, 270, 270, 270, 540, 270, 135, 540, 135, 270, 270, 135, 540, 540, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 540, 270, 135, 270, 540, 540, 270, 540, 135, 270, 270, 540, 270, 135, 135, 270, 540, 135, 270, 135, 540, 540, 270, 540, 540, 540, 135, 270, 540, 135, 270, 135, 270, 135, 135, 270, 540, 540, 135, 135, 135, 540, 540, 540, 270, 135, 135, 135, 135, 135, 540, 135, 270, 135, 540, 540, 135, 540, 135, 270, 270, 540, 135, 135, 135, 540, 540, 270, 540, 270, 540, 540, 270, 270, 135, 540, 270, 270, 270, 540, 270, 135, 270, 540, 540, 270, 540, 270, 135, 540, 270, 135, 270, 270, 135, 270, 540, 135, 270, 540, 135, 270, 540, 540, 270, 135, 540, 270, 135, 135, 270, 540, 540, 540, 135, 540, 135, 540, 135, 270, 135, 540, 540, 270, 540, 135, 540, 540, 540, 135, 540, 540, 540, 270, 270, 270, 270, 270, 270, 135, 540, 270, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 60480 . Total input tokens: 13415393 . Total output tokens: 12119019
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 2.0011708182282746,
    "estimated_duration": 3599.513291915647,
    "input_throughput": 1402.407100798198,
    "output_throughput": 1231.2403485087225,
    "total_throughput": 2633.6474493069204,
    "itl": 26.088098795458407,
    "ttft": 13166.57226381888,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 14593,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 43.63380395351392,
    "arrivals": 20309,
    "finished_requests": 20246,
    "scheduler_time": 0.0016534040336913245
}
#Debug simulation 
Total elapsed time: 2.001280850265175. Arrivals time: 0.06187859084457159 Scheduler time: 1.5318189994432032 Scheduler overhead time: 0.12220842903479934 Adapter cache time: 0.10257439268752933 Engine time: 0.12290112441405654 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_192_slots_32_rate_0.05-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_192_slots_32_rate_0.05-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [64 64 64]
Adapter prompts. [540, 135, 540, 135, 540, 135, 540, 135, 135, 135, 270, 270, 270, 270, 540, 270, 135, 540, 135, 270, 270, 135, 540, 540, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 540, 270, 135, 270, 540, 540, 270, 540, 135, 270, 270, 540, 270, 135, 135, 270, 540, 135, 270, 135, 540, 540, 270, 540, 540, 540, 135, 270, 540, 135, 270, 135, 270, 135, 135, 270, 540, 540, 135, 135, 135, 540, 540, 540, 270, 135, 135, 135, 135, 135, 540, 135, 270, 135, 540, 540, 135, 540, 135, 270, 270, 540, 135, 135, 135, 540, 540, 270, 540, 270, 540, 540, 270, 270, 135, 540, 270, 270, 270, 540, 270, 135, 270, 540, 540, 270, 540, 270, 135, 540, 270, 135, 270, 270, 135, 270, 540, 135, 270, 540, 135, 270, 540, 540, 270, 135, 540, 270, 135, 135, 270, 540, 540, 540, 135, 540, 135, 540, 135, 270, 135, 540, 540, 270, 540, 135, 540, 540, 540, 135, 540, 540, 540, 270, 270, 270, 270, 270, 270, 135, 540, 270, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 60480 . Total input tokens: 13415393 . Total output tokens: 12119019
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.9825819968245924,
    "estimated_duration": 3599.5179231905186,
    "input_throughput": 1402.6664424898229,
    "output_throughput": 1231.6816014268647,
    "total_throughput": 2634.3480439166874,
    "itl": 26.050633460268642,
    "ttft": 11596.632365408692,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 14929,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 49.94354736197948,
    "arrivals": 20309,
    "finished_requests": 20252,
    "scheduler_time": 0.0010110761883896872
}
#Debug simulation 
Total elapsed time: 1.982659187167883. Arrivals time: 0.06088573485612869 Scheduler time: 1.5131346643902361 Scheduler overhead time: 0.1230893679894507 Adapter cache time: 0.103526143822819 Engine time: 0.12206131312996149 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_192_slots_32_rate_0.05-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_192_slots_32_rate_0.05-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [64 64 64]
Adapter prompts. [540, 66, 540, 66, 540, 66, 540, 66, 66, 66, 270, 270, 270, 270, 540, 270, 66, 540, 66, 270, 270, 66, 540, 540, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 540, 270, 66, 270, 540, 540, 270, 540, 66, 270, 270, 540, 270, 66, 66, 270, 540, 66, 270, 66, 540, 540, 270, 540, 540, 540, 66, 270, 540, 66, 270, 66, 270, 66, 66, 270, 540, 540, 66, 66, 66, 540, 540, 540, 270, 66, 66, 66, 66, 66, 540, 66, 270, 66, 540, 540, 66, 540, 66, 270, 270, 540, 66, 66, 66, 540, 540, 270, 540, 270, 540, 540, 270, 270, 66, 540, 270, 270, 270, 540, 270, 66, 270, 540, 540, 270, 540, 270, 66, 540, 270, 66, 270, 270, 66, 270, 540, 66, 270, 540, 66, 270, 540, 540, 270, 66, 540, 270, 66, 66, 270, 540, 540, 540, 66, 540, 66, 540, 66, 270, 66, 540, 540, 270, 540, 66, 540, 540, 540, 66, 540, 540, 540, 270, 270, 270, 270, 270, 270, 66, 540, 270, 540, 66, 540, 270, 66, 270, 66, 66, 270, 270, 270, 540, 270, 66, 66]
Prompts retrieved: 56064 . Total input tokens: 12438405 . Total output tokens: 11244593
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 1.8433753922581673,
    "estimated_duration": 3600.0039523749356,
    "input_throughput": 1291.6324708289435,
    "output_throughput": 1165.2684428950593,
    "total_throughput": 2456.9009137240027,
    "itl": 25.425626165568907,
    "ttft": 6818.388564004727,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13909,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 42.568324030355235,
    "arrivals": 18908,
    "finished_requests": 18876,
    "scheduler_time": 9.536715128806835e-05
}
#Debug simulation 
Total elapsed time: 1.8434540079906583. Arrivals time: 0.057205233722925186 Scheduler time: 1.3803671170026064 Scheduler overhead time: 0.1259497469291091 Adapter cache time: 0.09708565007895231 Engine time: 0.12223673006519675 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_192_slots_32_rate_0.05-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_192_slots_32_rate_0.05-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [64 64 64]
Adapter prompts. [540, 66, 540, 66, 540, 66, 540, 66, 66, 66, 270, 270, 270, 270, 540, 270, 66, 540, 66, 270, 270, 66, 540, 540, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 540, 270, 66, 270, 540, 540, 270, 540, 66, 270, 270, 540, 270, 66, 66, 270, 540, 66, 270, 66, 540, 540, 270, 540, 540, 540, 66, 270, 540, 66, 270, 66, 270, 66, 66, 270, 540, 540, 66, 66, 66, 540, 540, 540, 270, 66, 66, 66, 66, 66, 540, 66, 270, 66, 540, 540, 66, 540, 66, 270, 270, 540, 66, 66, 66, 540, 540, 270, 540, 270, 540, 540, 270, 270, 66, 540, 270, 270, 270, 540, 270, 66, 270, 540, 540, 270, 540, 270, 66, 540, 270, 66, 270, 270, 66, 270, 540, 66, 270, 540, 66, 270, 540, 540, 270, 66, 540, 270, 66, 66, 270, 540, 540, 540, 66, 540, 66, 540, 66, 270, 66, 540, 540, 270, 540, 66, 540, 540, 540, 66, 540, 540, 540, 270, 270, 270, 270, 270, 270, 66, 540, 270, 540, 66, 540, 270, 66, 270, 66, 66, 270, 270, 270, 540, 270, 66, 66]
Prompts retrieved: 56064 . Total input tokens: 12438405 . Total output tokens: 11244593
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.8617715979926288,
    "estimated_duration": 3600.001279542237,
    "input_throughput": 1291.6334298056865,
    "output_throughput": 1165.2693080524175,
    "total_throughput": 2456.902737858104,
    "itl": 25.452334146552854,
    "ttft": 6825.486715022199,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13905,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 45.2503298587169,
    "arrivals": 18908,
    "finished_requests": 18876,
    "scheduler_time": 9.712674210600995e-05
}
#Debug simulation 
Total elapsed time: 1.8618682539090514. Arrivals time: 0.05781666189432144 Scheduler time: 1.3929060623049736 Scheduler overhead time: 0.1275726961903274 Adapter cache time: 0.0973583604209125 Engine time: 0.12485722359269857 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_192_slots_32_rate_0.05-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_192_slots_32_rate_0.05-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [64 64 64]
Adapter prompts. [540, 66, 540, 66, 540, 66, 540, 66, 66, 66, 270, 270, 270, 270, 540, 270, 66, 540, 66, 270, 270, 66, 540, 540, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 540, 270, 66, 270, 540, 540, 270, 540, 66, 270, 270, 540, 270, 66, 66, 270, 540, 66, 270, 66, 540, 540, 270, 540, 540, 540, 66, 270, 540, 66, 270, 66, 270, 66, 66, 270, 540, 540, 66, 66, 66, 540, 540, 540, 270, 66, 66, 66, 66, 66, 540, 66, 270, 66, 540, 540, 66, 540, 66, 270, 270, 540, 66, 66, 66, 540, 540, 270, 540, 270, 540, 540, 270, 270, 66, 540, 270, 270, 270, 540, 270, 66, 270, 540, 540, 270, 540, 270, 66, 540, 270, 66, 270, 270, 66, 270, 540, 66, 270, 540, 66, 270, 540, 540, 270, 66, 540, 270, 66, 66, 270, 540, 540, 540, 66, 540, 66, 540, 66, 270, 66, 540, 540, 270, 540, 66, 540, 540, 540, 66, 540, 540, 540, 270, 270, 270, 270, 270, 270, 66, 540, 270, 540, 66, 540, 270, 66, 270, 66, 66, 270, 270, 270, 540, 270, 66, 66]
Prompts retrieved: 56064 . Total input tokens: 12438405 . Total output tokens: 11244593
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.8341723987832665,
    "estimated_duration": 3600.0064529878164,
    "input_throughput": 1291.6315736436645,
    "output_throughput": 1165.267633483933,
    "total_throughput": 2456.8992071275975,
    "itl": 25.45270713288702,
    "ttft": 6825.691716260325,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13907,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 45.35908334813049,
    "arrivals": 18908,
    "finished_requests": 18876,
    "scheduler_time": 9.741698834886623e-05
}
#Debug simulation 
Total elapsed time: 1.8342531896196306. Arrivals time: 0.05715681239962578 Scheduler time: 1.374211615882814 Scheduler overhead time: 0.12425774754956365 Adapter cache time: 0.09670768957585096 Engine time: 0.12159511307254434 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_192_slots_32_rate_0.05-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_192_slots_32_rate_0.05-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [64 64 64]
Adapter prompts. [540, 66, 540, 66, 540, 66, 540, 66, 66, 66, 270, 270, 270, 270, 540, 270, 66, 540, 66, 270, 270, 66, 540, 540, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 540, 270, 66, 270, 540, 540, 270, 540, 66, 270, 270, 540, 270, 66, 66, 270, 540, 66, 270, 66, 540, 540, 270, 540, 540, 540, 66, 270, 540, 66, 270, 66, 270, 66, 66, 270, 540, 540, 66, 66, 66, 540, 540, 540, 270, 66, 66, 66, 66, 66, 540, 66, 270, 66, 540, 540, 66, 540, 66, 270, 270, 540, 66, 66, 66, 540, 540, 270, 540, 270, 540, 540, 270, 270, 66, 540, 270, 270, 270, 540, 270, 66, 270, 540, 540, 270, 540, 270, 66, 540, 270, 66, 270, 270, 66, 270, 540, 66, 270, 540, 66, 270, 540, 540, 270, 66, 540, 270, 66, 66, 270, 540, 540, 540, 66, 540, 66, 540, 66, 270, 66, 540, 540, 270, 540, 66, 540, 540, 540, 66, 540, 540, 540, 270, 270, 270, 270, 270, 270, 66, 540, 270, 540, 66, 540, 270, 66, 270, 66, 66, 270, 270, 270, 540, 270, 66, 66]
Prompts retrieved: 56064 . Total input tokens: 12438405 . Total output tokens: 11244593
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 1.8060111072845757,
    "estimated_duration": 3600.0014908101657,
    "input_throughput": 1291.6333540055182,
    "output_throughput": 1165.2692396679922,
    "total_throughput": 2456.90259367351,
    "itl": 25.434136396547157,
    "ttft": 6821.069607326525,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13908,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 43.42715860171503,
    "arrivals": 18908,
    "finished_requests": 18876,
    "scheduler_time": 9.650430841468913e-05
}
#Debug simulation 
Total elapsed time: 1.8060838971287012. Arrivals time: 0.05614260816946626 Scheduler time: 1.3489499599672854 Scheduler overhead time: 0.1233704099431634 Adapter cache time: 0.09641764871776104 Engine time: 0.12057527899742126 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_192_slots_32_rate_0.05-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_192_slots_32_rate_0.05-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [64 64 64]
Adapter prompts. [540, 66, 540, 66, 540, 66, 540, 66, 66, 66, 270, 270, 270, 270, 540, 270, 66, 540, 66, 270, 270, 66, 540, 540, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 540, 270, 66, 270, 540, 540, 270, 540, 66, 270, 270, 540, 270, 66, 66, 270, 540, 66, 270, 66, 540, 540, 270, 540, 540, 540, 66, 270, 540, 66, 270, 66, 270, 66, 66, 270, 540, 540, 66, 66, 66, 540, 540, 540, 270, 66, 66, 66, 66, 66, 540, 66, 270, 66, 540, 540, 66, 540, 66, 270, 270, 540, 66, 66, 66, 540, 540, 270, 540, 270, 540, 540, 270, 270, 66, 540, 270, 270, 270, 540, 270, 66, 270, 540, 540, 270, 540, 270, 66, 540, 270, 66, 270, 270, 66, 270, 540, 66, 270, 540, 66, 270, 540, 540, 270, 66, 540, 270, 66, 66, 270, 540, 540, 540, 66, 540, 66, 540, 66, 270, 66, 540, 540, 270, 540, 66, 540, 540, 540, 66, 540, 540, 540, 270, 270, 270, 270, 270, 270, 66, 540, 270, 540, 66, 540, 270, 66, 270, 66, 66, 270, 270, 270, 540, 270, 66, 66]
Prompts retrieved: 56064 . Total input tokens: 12438405 . Total output tokens: 11244593
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 1.8330588266253471,
    "estimated_duration": 3600.012191898024,
    "input_throughput": 1291.6295146068537,
    "output_throughput": 1165.2657758884693,
    "total_throughput": 2456.895290495323,
    "itl": 25.458781645606063,
    "ttft": 6827.455245004811,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13906,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 45.919622573932266,
    "arrivals": 18908,
    "finished_requests": 18876,
    "scheduler_time": 9.759952433570165e-05
}
#Debug simulation 
Total elapsed time: 1.8331397590227425. Arrivals time: 0.05666022514924407 Scheduler time: 1.3741087042726576 Scheduler overhead time: 0.1254243804141879 Adapter cache time: 0.09667138801887631 Engine time: 0.11991169769316912 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_192_slots_32_rate_0.05-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_192_slots_32_rate_0.05-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [64 64 64]
Adapter prompts. [540, 66, 540, 66, 540, 66, 540, 66, 66, 66, 270, 270, 270, 270, 540, 270, 66, 540, 66, 270, 270, 66, 540, 540, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 540, 270, 66, 270, 540, 540, 270, 540, 66, 270, 270, 540, 270, 66, 66, 270, 540, 66, 270, 66, 540, 540, 270, 540, 540, 540, 66, 270, 540, 66, 270, 66, 270, 66, 66, 270, 540, 540, 66, 66, 66, 540, 540, 540, 270, 66, 66, 66, 66, 66, 540, 66, 270, 66, 540, 540, 66, 540, 66, 270, 270, 540, 66, 66, 66, 540, 540, 270, 540, 270, 540, 540, 270, 270, 66, 540, 270, 270, 270, 540, 270, 66, 270, 540, 540, 270, 540, 270, 66, 540, 270, 66, 270, 270, 66, 270, 540, 66, 270, 540, 66, 270, 540, 540, 270, 66, 540, 270, 66, 66, 270, 540, 540, 540, 66, 540, 66, 540, 66, 270, 66, 540, 540, 270, 540, 66, 540, 540, 540, 66, 540, 540, 540, 270, 270, 270, 270, 270, 270, 66, 540, 270, 540, 66, 540, 270, 66, 270, 66, 66, 270, 270, 270, 540, 270, 66, 66]
Prompts retrieved: 56064 . Total input tokens: 12438405 . Total output tokens: 11244593
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 1.8313105120323598,
    "estimated_duration": 3600.0117504975074,
    "input_throughput": 1291.629672974652,
    "output_throughput": 1165.2659187627016,
    "total_throughput": 2456.8955917373537,
    "itl": 25.41552474413949,
    "ttft": 6815.881431150602,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13911,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 41.59458965238889,
    "arrivals": 18908,
    "finished_requests": 18876,
    "scheduler_time": 9.121463299079815e-05
}
#Debug simulation 
Total elapsed time: 1.831389364786446. Arrivals time: 0.05678356532007456 Scheduler time: 1.3714798078872263 Scheduler overhead time: 0.1250526956282556 Adapter cache time: 0.09635430574417114 Engine time: 0.12090250570327044 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_192_slots_32_rate_0.05-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_192_slots_32_rate_0.05-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [64 64 64]
Adapter prompts. [540, 66, 540, 66, 540, 66, 540, 66, 66, 66, 270, 270, 270, 270, 540, 270, 66, 540, 66, 270, 270, 66, 540, 540, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 540, 270, 66, 270, 540, 540, 270, 540, 66, 270, 270, 540, 270, 66, 66, 270, 540, 66, 270, 66, 540, 540, 270, 540, 540, 540, 66, 270, 540, 66, 270, 66, 270, 66, 66, 270, 540, 540, 66, 66, 66, 540, 540, 540, 270, 66, 66, 66, 66, 66, 540, 66, 270, 66, 540, 540, 66, 540, 66, 270, 270, 540, 66, 66, 66, 540, 540, 270, 540, 270, 540, 540, 270, 270, 66, 540, 270, 270, 270, 540, 270, 66, 270, 540, 540, 270, 540, 270, 66, 540, 270, 66, 270, 270, 66, 270, 540, 66, 270, 540, 66, 270, 540, 540, 270, 66, 540, 270, 66, 66, 270, 540, 540, 540, 66, 540, 66, 540, 66, 270, 66, 540, 540, 270, 540, 66, 540, 540, 540, 66, 540, 540, 540, 270, 270, 270, 270, 270, 270, 66, 540, 270, 540, 66, 540, 270, 66, 270, 66, 66, 270, 270, 270, 540, 270, 66, 66]
Prompts retrieved: 56064 . Total input tokens: 12438405 . Total output tokens: 11244593
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.8568061608821154,
    "estimated_duration": 3600.022657147924,
    "input_throughput": 1291.6257598455825,
    "output_throughput": 1165.2623884660263,
    "total_throughput": 2456.888148311609,
    "itl": 25.463360023556273,
    "ttft": 6828.884639137308,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13904,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 46.47946758896241,
    "arrivals": 18908,
    "finished_requests": 18876,
    "scheduler_time": 9.723445236203081e-05
}
#Debug simulation 
Total elapsed time: 1.8568880800157785. Arrivals time: 0.05732095055282116 Scheduler time: 1.3904033666476607 Scheduler overhead time: 0.1266095107421279 Adapter cache time: 0.0968655007891357 Engine time: 0.12494636606425047 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_192_slots_32_rate_0.05-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_192_slots_32_rate_0.05-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 270, 270, 270, 270, 540, 270, 33, 540, 33, 270, 270, 33, 540, 540, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 540, 270, 33, 270, 540, 540, 270, 540, 33, 270, 270, 540, 270, 33, 33, 270, 540, 33, 270, 33, 540, 540, 270, 540, 540, 540, 33, 270, 540, 33, 270, 33, 270, 33, 33, 270, 540, 540, 33, 33, 33, 540, 540, 540, 270, 33, 33, 33, 33, 33, 540, 33, 270, 33, 540, 540, 33, 540, 33, 270, 270, 540, 33, 33, 33, 540, 540, 270, 540, 270, 540, 540, 270, 270, 33, 540, 270, 270, 270, 540, 270, 33, 270, 540, 540, 270, 540, 270, 33, 540, 270, 33, 270, 270, 33, 270, 540, 33, 270, 540, 33, 270, 540, 540, 270, 33, 540, 270, 33, 33, 270, 540, 540, 540, 33, 540, 33, 540, 33, 270, 33, 540, 540, 270, 540, 33, 540, 540, 540, 33, 540, 540, 540, 270, 270, 270, 270, 270, 270, 33, 540, 270, 540, 33, 540, 270, 33, 270, 33, 33, 270, 270, 270, 540, 270, 33, 33]
Prompts retrieved: 53952 . Total input tokens: 11959790 . Total output tokens: 10819341
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 1.754409221932292,
    "estimated_duration": 3599.640594836808,
    "input_throughput": 1260.8778238889056,
    "output_throughput": 1105.4606411839297,
    "total_throughput": 2366.3384650728353,
    "itl": 24.833188064612823,
    "ttft": 7144.6380754664315,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13377,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 40.94014455058437,
    "arrivals": 18247,
    "finished_requests": 18212,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.754474830813706. Arrivals time: 0.05509750917553902 Scheduler time: 1.2940889550372958 Scheduler overhead time: 0.12992373388260603 Adapter cache time: 0.09299793653190136 Engine time: 0.12021609209477901 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_192_slots_32_rate_0.05-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_192_slots_32_rate_0.05-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 270, 270, 270, 270, 540, 270, 33, 540, 33, 270, 270, 33, 540, 540, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 540, 270, 33, 270, 540, 540, 270, 540, 33, 270, 270, 540, 270, 33, 33, 270, 540, 33, 270, 33, 540, 540, 270, 540, 540, 540, 33, 270, 540, 33, 270, 33, 270, 33, 33, 270, 540, 540, 33, 33, 33, 540, 540, 540, 270, 33, 33, 33, 33, 33, 540, 33, 270, 33, 540, 540, 33, 540, 33, 270, 270, 540, 33, 33, 33, 540, 540, 270, 540, 270, 540, 540, 270, 270, 33, 540, 270, 270, 270, 540, 270, 33, 270, 540, 540, 270, 540, 270, 33, 540, 270, 33, 270, 270, 33, 270, 540, 33, 270, 540, 33, 270, 540, 540, 270, 33, 540, 270, 33, 33, 270, 540, 540, 540, 33, 540, 33, 540, 33, 270, 33, 540, 540, 270, 540, 33, 540, 540, 540, 33, 540, 540, 540, 270, 270, 270, 270, 270, 270, 33, 540, 270, 540, 33, 540, 270, 33, 270, 33, 33, 270, 270, 270, 540, 270, 33, 33]
Prompts retrieved: 53952 . Total input tokens: 11959790 . Total output tokens: 10819341
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.7449474427849054,
    "estimated_duration": 3599.6341380454196,
    "input_throughput": 1260.880085570166,
    "output_throughput": 1105.462624087879,
    "total_throughput": 2366.3427096580454,
    "itl": 24.859157919319287,
    "ttft": 7147.0991608297445,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13371,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 43.456700057749636,
    "arrivals": 18247,
    "finished_requests": 18212,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.7450207700021565. Arrivals time: 0.05570512684062123 Scheduler time: 1.286088832654059 Scheduler overhead time: 0.12497321516275406 Adapter cache time: 0.09367746021598577 Engine time: 0.12319461675360799 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-32/adapters_192_slots_32_rate_0.05-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-32/adapters_192_slots_32_rate_0.05-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 270, 270, 270, 270, 540, 270, 33, 540, 33, 270, 270, 33, 540, 540, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 540, 270, 33, 270, 540, 540, 270, 540, 33, 270, 270, 540, 270, 33, 33, 270, 540, 33, 270, 33, 540, 540, 270, 540, 540, 540, 33, 270, 540, 33, 270, 33, 270, 33, 33, 270, 540, 540, 33, 33, 33, 540, 540, 540, 270, 33, 33, 33, 33, 33, 540, 33, 270, 33, 540, 540, 33, 540, 33, 270, 270, 540, 33, 33, 33, 540, 540, 270, 540, 270, 540, 540, 270, 270, 33, 540, 270, 270, 270, 540, 270, 33, 270, 540, 540, 270, 540, 270, 33, 540, 270, 33, 270, 270, 33, 270, 540, 33, 270, 540, 33, 270, 540, 540, 270, 33, 540, 270, 33, 33, 270, 540, 540, 540, 33, 540, 33, 540, 33, 270, 33, 540, 540, 270, 540, 33, 540, 540, 540, 33, 540, 540, 540, 270, 270, 270, 270, 270, 270, 33, 540, 270, 540, 33, 540, 270, 33, 270, 33, 33, 270, 270, 270, 540, 270, 33, 33]
Prompts retrieved: 53952 . Total input tokens: 11959790 . Total output tokens: 10819341
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.7383998176082969,
    "estimated_duration": 3599.632819940512,
    "input_throughput": 1260.88054727621,
    "output_throughput": 1105.46302888353,
    "total_throughput": 2366.3435761597398,
    "itl": 24.86117902048101,
    "ttft": 7147.26957961876,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13377,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 43.58380231340281,
    "arrivals": 18247,
    "finished_requests": 18212,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.7384881866164505. Arrivals time: 0.055854564532637596 Scheduler time: 1.280916175339371 Scheduler overhead time: 0.12474242737516761 Adapter cache time: 0.09355121059343219 Engine time: 0.12251055333763361 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_192_slots_32_rate_0.05-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_192_slots_32_rate_0.05-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 270, 270, 270, 270, 540, 270, 33, 540, 33, 270, 270, 33, 540, 540, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 540, 270, 33, 270, 540, 540, 270, 540, 33, 270, 270, 540, 270, 33, 33, 270, 540, 33, 270, 33, 540, 540, 270, 540, 540, 540, 33, 270, 540, 33, 270, 33, 270, 33, 33, 270, 540, 540, 33, 33, 33, 540, 540, 540, 270, 33, 33, 33, 33, 33, 540, 33, 270, 33, 540, 540, 33, 540, 33, 270, 270, 540, 33, 33, 33, 540, 540, 270, 540, 270, 540, 540, 270, 270, 33, 540, 270, 270, 270, 540, 270, 33, 270, 540, 540, 270, 540, 270, 33, 540, 270, 33, 270, 270, 33, 270, 540, 33, 270, 540, 33, 270, 540, 540, 270, 33, 540, 270, 33, 33, 270, 540, 540, 540, 33, 540, 33, 540, 33, 270, 33, 540, 540, 270, 540, 33, 540, 540, 540, 33, 540, 540, 540, 270, 270, 270, 270, 270, 270, 33, 540, 270, 540, 33, 540, 270, 33, 270, 33, 33, 270, 270, 270, 540, 270, 33, 33]
Prompts retrieved: 53952 . Total input tokens: 11959790 . Total output tokens: 10819341
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 1.7679104120470583,
    "estimated_duration": 3599.6360640249254,
    "input_throughput": 1260.8794109382975,
    "output_throughput": 1105.462032611874,
    "total_throughput": 2366.341443550172,
    "itl": 24.841791493960525,
    "ttft": 7145.680783799907,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13364,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 41.74091632479462,
    "arrivals": 18247,
    "finished_requests": 18212,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.7679961542598903. Arrivals time: 0.05577146401628852 Scheduler time: 1.2997766183689237 Scheduler overhead time: 0.1304406081326306 Adapter cache time: 0.09367687162011862 Engine time: 0.12612188886851072 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-32/adapters_192_slots_32_rate_0.05-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-32/adapters_192_slots_32_rate_0.05-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 270, 270, 270, 270, 540, 270, 33, 540, 33, 270, 270, 33, 540, 540, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 540, 270, 33, 270, 540, 540, 270, 540, 33, 270, 270, 540, 270, 33, 33, 270, 540, 33, 270, 33, 540, 540, 270, 540, 540, 540, 33, 270, 540, 33, 270, 33, 270, 33, 33, 270, 540, 540, 33, 33, 33, 540, 540, 540, 270, 33, 33, 33, 33, 33, 540, 33, 270, 33, 540, 540, 33, 540, 33, 270, 270, 540, 33, 33, 33, 540, 540, 270, 540, 270, 540, 540, 270, 270, 33, 540, 270, 270, 270, 540, 270, 33, 270, 540, 540, 270, 540, 270, 33, 540, 270, 33, 270, 270, 33, 270, 540, 33, 270, 540, 33, 270, 540, 540, 270, 33, 540, 270, 33, 33, 270, 540, 540, 540, 33, 540, 33, 540, 33, 270, 33, 540, 540, 270, 540, 33, 540, 540, 540, 33, 540, 540, 540, 270, 270, 270, 270, 270, 270, 33, 540, 270, 540, 33, 540, 270, 33, 270, 33, 33, 270, 270, 270, 540, 270, 33, 33]
Prompts retrieved: 53952 . Total input tokens: 11959790 . Total output tokens: 10819341
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 1.7412134683690965,
    "estimated_duration": 3599.6496003646994,
    "input_throughput": 1260.8746694512042,
    "output_throughput": 1105.4578755656773,
    "total_throughput": 2366.332545016882,
    "itl": 24.86452684025581,
    "ttft": 7147.7462668418,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13371,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 44.08590465629929,
    "arrivals": 18247,
    "finished_requests": 18212,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.741284571122378. Arrivals time: 0.05497584631666541 Scheduler time: 1.2828822969458997 Scheduler overhead time: 0.12672583246603608 Adapter cache time: 0.09292745729908347 Engine time: 0.12221350986510515 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_192_slots_32_rate_0.05-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_192_slots_32_rate_0.05-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 270, 270, 270, 270, 540, 270, 33, 540, 33, 270, 270, 33, 540, 540, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 540, 270, 33, 270, 540, 540, 270, 540, 33, 270, 270, 540, 270, 33, 33, 270, 540, 33, 270, 33, 540, 540, 270, 540, 540, 540, 33, 270, 540, 33, 270, 33, 270, 33, 33, 270, 540, 540, 33, 33, 33, 540, 540, 540, 270, 33, 33, 33, 33, 33, 540, 33, 270, 33, 540, 540, 33, 540, 33, 270, 270, 540, 33, 33, 33, 540, 540, 270, 540, 270, 540, 540, 270, 270, 33, 540, 270, 270, 270, 540, 270, 33, 270, 540, 540, 270, 540, 270, 33, 540, 270, 33, 270, 270, 33, 270, 540, 33, 270, 540, 33, 270, 540, 540, 270, 33, 540, 270, 33, 33, 270, 540, 540, 540, 33, 540, 33, 540, 33, 270, 33, 540, 540, 270, 540, 33, 540, 540, 540, 33, 540, 540, 540, 270, 270, 270, 270, 270, 270, 33, 540, 270, 540, 33, 540, 270, 33, 270, 33, 33, 270, 270, 270, 540, 270, 33, 33]
Prompts retrieved: 53952 . Total input tokens: 11959790 . Total output tokens: 10819341
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 1.758225327823311,
    "estimated_duration": 3599.6497911594943,
    "input_throughput": 1260.8746026201686,
    "output_throughput": 1105.4578169723084,
    "total_throughput": 2366.332419592477,
    "itl": 24.824443802441863,
    "ttft": 7143.804744545376,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13376,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 39.99491274461486,
    "arrivals": 18247,
    "finished_requests": 18212,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.7582998918369412. Arrivals time: 0.055369664914906025 Scheduler time: 1.2993515483103693 Scheduler overhead time: 0.12629487877711654 Adapter cache time: 0.09380171447992325 Engine time: 0.12193458527326584 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-32/adapters_192_slots_32_rate_0.05-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-32/adapters_192_slots_32_rate_0.05-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 270, 270, 270, 270, 540, 270, 33, 540, 33, 270, 270, 33, 540, 540, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 540, 270, 33, 270, 540, 540, 270, 540, 33, 270, 270, 540, 270, 33, 33, 270, 540, 33, 270, 33, 540, 540, 270, 540, 540, 540, 33, 270, 540, 33, 270, 33, 270, 33, 33, 270, 540, 540, 33, 33, 33, 540, 540, 540, 270, 33, 33, 33, 33, 33, 540, 33, 270, 33, 540, 540, 33, 540, 33, 270, 270, 540, 33, 33, 33, 540, 540, 270, 540, 270, 540, 540, 270, 270, 33, 540, 270, 270, 270, 540, 270, 33, 270, 540, 540, 270, 540, 270, 33, 540, 270, 33, 270, 270, 33, 270, 540, 33, 270, 540, 33, 270, 540, 540, 270, 33, 540, 270, 33, 33, 270, 540, 540, 540, 33, 540, 33, 540, 33, 270, 33, 540, 540, 270, 540, 33, 540, 540, 540, 33, 540, 540, 540, 270, 270, 270, 270, 270, 270, 33, 540, 270, 540, 33, 540, 270, 33, 270, 33, 33, 270, 270, 270, 540, 270, 33, 33]
Prompts retrieved: 53952 . Total input tokens: 11959790 . Total output tokens: 10819341
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.7797529818490148,
    "estimated_duration": 3599.6443269038014,
    "input_throughput": 1260.8765166262758,
    "output_throughput": 1105.4594950559247,
    "total_throughput": 2366.3360116822005,
    "itl": 24.87120503914929,
    "ttft": 7148.271235720274,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13377,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 44.65468154464005,
    "arrivals": 18247,
    "finished_requests": 18212,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.7798282289877534. Arrivals time: 0.055547886062413454 Scheduler time: 1.318387868348509 Scheduler overhead time: 0.12599776685237885 Adapter cache time: 0.09388357633724809 Engine time: 0.12457241071388125 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_192_slots_32_rate_0.05-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_192_slots_32_rate_0.05-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [64 64 64]
Adapter prompts. [540, 66, 540, 66, 540, 66, 540, 66, 66, 66, 135, 135, 135, 135, 540, 135, 66, 540, 66, 135, 135, 66, 540, 540, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 540, 135, 66, 135, 540, 540, 135, 540, 66, 135, 135, 540, 135, 66, 66, 135, 540, 66, 135, 66, 540, 540, 135, 540, 540, 540, 66, 135, 540, 66, 135, 66, 135, 66, 66, 135, 540, 540, 66, 66, 66, 540, 540, 540, 135, 66, 66, 66, 66, 66, 540, 66, 135, 66, 540, 540, 66, 540, 66, 135, 135, 540, 66, 66, 66, 540, 540, 135, 540, 135, 540, 540, 135, 135, 66, 540, 135, 135, 135, 540, 135, 66, 135, 540, 540, 135, 540, 135, 66, 540, 135, 66, 135, 135, 66, 135, 540, 66, 135, 540, 66, 135, 540, 540, 135, 66, 540, 135, 66, 66, 135, 540, 540, 540, 66, 540, 66, 540, 66, 135, 66, 540, 540, 135, 540, 66, 540, 540, 540, 66, 540, 540, 540, 135, 135, 135, 135, 135, 135, 66, 540, 135, 540, 66, 540, 135, 66, 135, 66, 66, 135, 135, 135, 540, 135, 66, 66]
Prompts retrieved: 47424 . Total input tokens: 10486917 . Total output tokens: 9511922
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 1.6283412710763514,
    "estimated_duration": 3600.016670979409,
    "input_throughput": 1105.3871033651003,
    "output_throughput": 992.6867919274812,
    "total_throughput": 2098.0738952925813,
    "itl": 23.80929866823692,
    "ttft": 4997.243237532272,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11540,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 35.3180285649846,
    "arrivals": 16073,
    "finished_requests": 16051,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6284075253643095. Arrivals time: 0.05034226505085826 Scheduler time: 1.171136952470988 Scheduler overhead time: 0.1307153357192874 Adapter cache time: 0.08539451565593481 Engine time: 0.12764882994815707 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_192_slots_32_rate_0.05-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_192_slots_32_rate_0.05-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [64 64 64]
Adapter prompts. [540, 66, 540, 66, 540, 66, 540, 66, 66, 66, 135, 135, 135, 135, 540, 135, 66, 540, 66, 135, 135, 66, 540, 540, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 540, 135, 66, 135, 540, 540, 135, 540, 66, 135, 135, 540, 135, 66, 66, 135, 540, 66, 135, 66, 540, 540, 135, 540, 540, 540, 66, 135, 540, 66, 135, 66, 135, 66, 66, 135, 540, 540, 66, 66, 66, 540, 540, 540, 135, 66, 66, 66, 66, 66, 540, 66, 135, 66, 540, 540, 66, 540, 66, 135, 135, 540, 66, 66, 66, 540, 540, 135, 540, 135, 540, 540, 135, 135, 66, 540, 135, 135, 135, 540, 135, 66, 135, 540, 540, 135, 540, 135, 66, 540, 135, 66, 135, 135, 66, 135, 540, 66, 135, 540, 66, 135, 540, 540, 135, 66, 540, 135, 66, 66, 135, 540, 540, 540, 66, 540, 66, 540, 66, 135, 66, 540, 540, 135, 540, 66, 540, 540, 540, 66, 540, 540, 540, 135, 135, 135, 135, 135, 135, 66, 540, 135, 540, 66, 540, 135, 66, 135, 66, 66, 135, 135, 135, 540, 135, 66, 66]
Prompts retrieved: 47424 . Total input tokens: 10486917 . Total output tokens: 9511922
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.6195300817489624,
    "estimated_duration": 3600.0175117999834,
    "input_throughput": 1105.3868451907397,
    "output_throughput": 992.6865600754205,
    "total_throughput": 2098.07340526616,
    "itl": 23.828442351168775,
    "ttft": 4997.859689767491,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11539,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 37.55684895353561,
    "arrivals": 16073,
    "finished_requests": 16051,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6196045456454158. Arrivals time: 0.05010568676516414 Scheduler time: 1.162850228138268 Scheduler overhead time: 0.1303478004410863 Adapter cache time: 0.08542571775615215 Engine time: 0.12765818228945136 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-32/adapters_192_slots_32_rate_0.05-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-32/adapters_192_slots_32_rate_0.05-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [64 64 64]
Adapter prompts. [540, 66, 540, 66, 540, 66, 540, 66, 66, 66, 135, 135, 135, 135, 540, 135, 66, 540, 66, 135, 135, 66, 540, 540, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 540, 135, 66, 135, 540, 540, 135, 540, 66, 135, 135, 540, 135, 66, 66, 135, 540, 66, 135, 66, 540, 540, 135, 540, 540, 540, 66, 135, 540, 66, 135, 66, 135, 66, 66, 135, 540, 540, 66, 66, 66, 540, 540, 540, 135, 66, 66, 66, 66, 66, 540, 66, 135, 66, 540, 540, 66, 540, 66, 135, 135, 540, 66, 66, 66, 540, 540, 135, 540, 135, 540, 540, 135, 135, 66, 540, 135, 135, 135, 540, 135, 66, 135, 540, 540, 135, 540, 135, 66, 540, 135, 66, 135, 135, 66, 135, 540, 66, 135, 540, 66, 135, 540, 540, 135, 66, 540, 135, 66, 66, 135, 540, 540, 540, 66, 540, 66, 540, 66, 135, 66, 540, 540, 135, 540, 66, 540, 540, 540, 66, 540, 540, 540, 135, 135, 135, 135, 135, 135, 66, 540, 135, 540, 66, 540, 135, 66, 135, 66, 66, 135, 135, 135, 540, 135, 66, 66]
Prompts retrieved: 47424 . Total input tokens: 10486917 . Total output tokens: 9511922
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.6150192678906024,
    "estimated_duration": 3600.0098369788907,
    "input_throughput": 1105.38920175271,
    "output_throughput": 992.6886763729016,
    "total_throughput": 2098.0778781256117,
    "itl": 23.82968092888811,
    "ttft": 4997.784759408497,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11539,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 37.64042626504312,
    "arrivals": 16073,
    "finished_requests": 16051,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6150888316333294. Arrivals time: 0.05045081069692969 Scheduler time: 1.1564140608534217 Scheduler overhead time: 0.13084595510736108 Adapter cache time: 0.08536897972226143 Engine time: 0.12863425072282553 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_192_slots_32_rate_0.05-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_192_slots_32_rate_0.05-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [64 64 64]
Adapter prompts. [540, 66, 540, 66, 540, 66, 540, 66, 66, 66, 135, 135, 135, 135, 540, 135, 66, 540, 66, 135, 135, 66, 540, 540, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 540, 135, 66, 135, 540, 540, 135, 540, 66, 135, 135, 540, 135, 66, 66, 135, 540, 66, 135, 66, 540, 540, 135, 540, 540, 540, 66, 135, 540, 66, 135, 66, 135, 66, 66, 135, 540, 540, 66, 66, 66, 540, 540, 540, 135, 66, 66, 66, 66, 66, 540, 66, 135, 66, 540, 540, 66, 540, 66, 135, 135, 540, 66, 66, 66, 540, 540, 135, 540, 135, 540, 540, 135, 135, 66, 540, 135, 135, 135, 540, 135, 66, 135, 540, 540, 135, 540, 135, 66, 540, 135, 66, 135, 135, 66, 135, 540, 66, 135, 540, 66, 135, 540, 540, 135, 66, 540, 135, 66, 66, 135, 540, 540, 540, 66, 540, 66, 540, 66, 135, 66, 540, 540, 135, 540, 66, 540, 540, 540, 66, 540, 540, 540, 135, 135, 135, 135, 135, 135, 66, 540, 135, 540, 66, 540, 135, 66, 135, 66, 66, 135, 135, 135, 540, 135, 66, 66]
Prompts retrieved: 47424 . Total input tokens: 10486917 . Total output tokens: 9511922
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 1.6086114849895239,
    "estimated_duration": 3600.025811502606,
    "input_throughput": 1105.3842967695398,
    "output_throughput": 992.6842714798166,
    "total_throughput": 2098.0685682493563,
    "itl": 23.816261037418286,
    "ttft": 4997.38378272633,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11537,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 36.05050684363255,
    "arrivals": 16073,
    "finished_requests": 16051,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6086921207606792. Arrivals time: 0.050057880114763975 Scheduler time: 1.1542925899848342 Scheduler overhead time: 0.13060053065419197 Adapter cache time: 0.08522428944706917 Engine time: 0.1251768679358065 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-32/adapters_192_slots_32_rate_0.05-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-32/adapters_192_slots_32_rate_0.05-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [64 64 64]
Adapter prompts. [540, 66, 540, 66, 540, 66, 540, 66, 66, 66, 135, 135, 135, 135, 540, 135, 66, 540, 66, 135, 135, 66, 540, 540, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 540, 135, 66, 135, 540, 540, 135, 540, 66, 135, 135, 540, 135, 66, 66, 135, 540, 66, 135, 66, 540, 540, 135, 540, 540, 540, 66, 135, 540, 66, 135, 66, 135, 66, 66, 135, 540, 540, 66, 66, 66, 540, 540, 540, 135, 66, 66, 66, 66, 66, 540, 66, 135, 66, 540, 540, 66, 540, 66, 135, 135, 540, 66, 66, 66, 540, 540, 135, 540, 135, 540, 540, 135, 135, 66, 540, 135, 135, 135, 540, 135, 66, 135, 540, 540, 135, 540, 135, 66, 540, 135, 66, 135, 135, 66, 135, 540, 66, 135, 540, 66, 135, 540, 540, 135, 66, 540, 135, 66, 66, 135, 540, 540, 540, 66, 540, 66, 540, 66, 135, 66, 540, 540, 135, 540, 66, 540, 540, 540, 66, 540, 540, 540, 135, 135, 135, 135, 135, 135, 66, 540, 135, 540, 66, 540, 135, 66, 135, 66, 66, 135, 135, 135, 540, 135, 66, 66]
Prompts retrieved: 47424 . Total input tokens: 10486917 . Total output tokens: 9511922
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 1.5969393481500447,
    "estimated_duration": 3600.020138149853,
    "input_throughput": 1105.3860387695293,
    "output_throughput": 992.6858358733,
    "total_throughput": 2098.0718746428292,
    "itl": 23.83584442925759,
    "ttft": 4997.966552534791,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11535,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 38.089094090798824,
    "arrivals": 16073,
    "finished_requests": 16051,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5970130520872772. Arrivals time: 0.04992228839546442 Scheduler time: 1.1443353006616235 Scheduler overhead time: 0.12881794525310397 Adapter cache time: 0.08470842894166708 Engine time: 0.12613171990960836 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_192_slots_32_rate_0.05-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_192_slots_32_rate_0.05-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [64 64 64]
Adapter prompts. [540, 66, 540, 66, 540, 66, 540, 66, 66, 66, 135, 135, 135, 135, 540, 135, 66, 540, 66, 135, 135, 66, 540, 540, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 540, 135, 66, 135, 540, 540, 135, 540, 66, 135, 135, 540, 135, 66, 66, 135, 540, 66, 135, 66, 540, 540, 135, 540, 540, 540, 66, 135, 540, 66, 135, 66, 135, 66, 66, 135, 540, 540, 66, 66, 66, 540, 540, 540, 135, 66, 66, 66, 66, 66, 540, 66, 135, 66, 540, 540, 66, 540, 66, 135, 135, 540, 66, 66, 66, 540, 540, 135, 540, 135, 540, 540, 135, 135, 66, 540, 135, 135, 135, 540, 135, 66, 135, 540, 540, 135, 540, 135, 66, 540, 135, 66, 135, 135, 66, 135, 540, 66, 135, 540, 66, 135, 540, 540, 135, 66, 540, 135, 66, 66, 135, 540, 540, 540, 66, 540, 66, 540, 66, 135, 66, 540, 540, 135, 540, 66, 540, 540, 540, 66, 540, 540, 540, 135, 135, 135, 135, 135, 135, 66, 540, 135, 540, 66, 540, 135, 66, 135, 66, 66, 135, 135, 135, 540, 135, 66, 66]
Prompts retrieved: 47424 . Total input tokens: 10486917 . Total output tokens: 9511922
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 1.607145280111581,
    "estimated_duration": 3600.020485954407,
    "input_throughput": 1105.3859319761655,
    "output_throughput": 992.6857399681085,
    "total_throughput": 2098.071671944274,
    "itl": 23.802766973024408,
    "ttft": 4997.085101744441,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11540,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 34.50518040316977,
    "arrivals": 16073,
    "finished_requests": 16051,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6072114370763302. Arrivals time: 0.049744267016649246 Scheduler time: 1.1509307906962931 Scheduler overhead time: 0.13020620262250304 Adapter cache time: 0.08437471371144056 Engine time: 0.12872469704598188 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-32/adapters_192_slots_32_rate_0.05-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-32/adapters_192_slots_32_rate_0.05-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [64 64 64]
Adapter prompts. [540, 66, 540, 66, 540, 66, 540, 66, 66, 66, 135, 135, 135, 135, 540, 135, 66, 540, 66, 135, 135, 66, 540, 540, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 540, 135, 66, 135, 540, 540, 135, 540, 66, 135, 135, 540, 135, 66, 66, 135, 540, 66, 135, 66, 540, 540, 135, 540, 540, 540, 66, 135, 540, 66, 135, 66, 135, 66, 66, 135, 540, 540, 66, 66, 66, 540, 540, 540, 135, 66, 66, 66, 66, 66, 540, 66, 135, 66, 540, 540, 66, 540, 66, 135, 135, 540, 66, 66, 66, 540, 540, 135, 540, 135, 540, 540, 135, 135, 66, 540, 135, 135, 135, 540, 135, 66, 135, 540, 540, 135, 540, 135, 66, 540, 135, 66, 135, 135, 66, 135, 540, 66, 135, 540, 66, 135, 540, 540, 135, 66, 540, 135, 66, 66, 135, 540, 540, 540, 66, 540, 66, 540, 66, 135, 66, 540, 540, 135, 540, 66, 540, 540, 540, 66, 540, 540, 540, 135, 135, 135, 135, 135, 135, 66, 540, 135, 540, 66, 540, 135, 66, 135, 66, 66, 135, 135, 135, 540, 135, 66, 66]
Prompts retrieved: 47424 . Total input tokens: 10486917 . Total output tokens: 9511922
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.5961304069496691,
    "estimated_duration": 3600.0076016110556,
    "input_throughput": 1105.3898881266682,
    "output_throughput": 992.6892927672493,
    "total_throughput": 2098.0791808939175,
    "itl": 23.837537496939085,
    "ttft": 4997.996484305557,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11536,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 38.570042011885846,
    "arrivals": 16073,
    "finished_requests": 16051,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.596206121146679. Arrivals time: 0.04972731787711382 Scheduler time: 1.145238154567778 Scheduler overhead time: 0.12990077817812562 Adapter cache time: 0.084024369250983 Engine time: 0.1243769726715982 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_192_slots_32_rate_0.05-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_192_slots_32_rate_0.05-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 135, 135, 135, 135, 540, 135, 33, 540, 33, 135, 135, 33, 540, 540, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 540, 135, 33, 135, 540, 540, 135, 540, 33, 135, 135, 540, 135, 33, 33, 135, 540, 33, 135, 33, 540, 540, 135, 540, 540, 540, 33, 135, 540, 33, 135, 33, 135, 33, 33, 135, 540, 540, 33, 33, 33, 540, 540, 540, 135, 33, 33, 33, 33, 33, 540, 33, 135, 33, 540, 540, 33, 540, 33, 135, 135, 540, 33, 33, 33, 540, 540, 135, 540, 135, 540, 540, 135, 135, 33, 540, 135, 135, 135, 540, 135, 33, 135, 540, 540, 135, 540, 135, 33, 540, 135, 33, 135, 135, 33, 135, 540, 33, 135, 540, 33, 135, 540, 540, 135, 33, 540, 135, 33, 33, 135, 540, 540, 540, 33, 540, 33, 540, 33, 135, 33, 540, 540, 135, 540, 33, 540, 540, 540, 33, 540, 540, 540, 135, 135, 135, 135, 135, 135, 33, 540, 135, 540, 33, 540, 135, 33, 135, 33, 33, 135, 135, 135, 540, 135, 33, 33]
Prompts retrieved: 45312 . Total input tokens: 10004990 . Total output tokens: 9089958
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 1.5774611830711365,
    "estimated_duration": 3599.9917604477364,
    "input_throughput": 1038.592932650208,
    "output_throughput": 944.1791054480793,
    "total_throughput": 1982.7720380982873,
    "itl": 23.412604896123064,
    "ttft": 4264.731708426311,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10716,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 32.79618666398612,
    "arrivals": 15374,
    "finished_requests": 15356,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5775486072525382. Arrivals time: 0.049581950064748526 Scheduler time: 1.1202308805659413 Scheduler overhead time: 0.1323643666692078 Adapter cache time: 0.08143699541687965 Engine time: 0.12963418988510966 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_192_slots_32_rate_0.05-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_192_slots_32_rate_0.05-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 135, 135, 135, 135, 540, 135, 33, 540, 33, 135, 135, 33, 540, 540, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 540, 135, 33, 135, 540, 540, 135, 540, 33, 135, 135, 540, 135, 33, 33, 135, 540, 33, 135, 33, 540, 540, 135, 540, 540, 540, 33, 135, 540, 33, 135, 33, 135, 33, 33, 135, 540, 540, 33, 33, 33, 540, 540, 540, 135, 33, 33, 33, 33, 33, 540, 33, 135, 33, 540, 540, 33, 540, 33, 135, 135, 540, 33, 33, 33, 540, 540, 135, 540, 135, 540, 540, 135, 135, 33, 540, 135, 135, 135, 540, 135, 33, 135, 540, 540, 135, 540, 135, 33, 540, 135, 33, 135, 135, 33, 135, 540, 33, 135, 540, 33, 135, 540, 540, 135, 33, 540, 135, 33, 33, 135, 540, 540, 540, 33, 540, 33, 540, 33, 135, 33, 540, 540, 135, 540, 33, 540, 540, 540, 33, 540, 540, 540, 135, 135, 135, 135, 135, 135, 33, 540, 135, 540, 33, 540, 135, 33, 135, 33, 33, 135, 135, 135, 540, 135, 33, 33]
Prompts retrieved: 45312 . Total input tokens: 10004990 . Total output tokens: 9089958
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.5725612067617476,
    "estimated_duration": 3599.9989456805542,
    "input_throughput": 1038.5908597240389,
    "output_throughput": 944.1772209623346,
    "total_throughput": 1982.7680806863732,
    "itl": 23.432683955762144,
    "ttft": 4264.993743882379,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10712,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 34.850360837501675,
    "arrivals": 15374,
    "finished_requests": 15356,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5726375500671566. Arrivals time: 0.04853903967887163 Scheduler time: 1.1091223191469908 Scheduler overhead time: 0.1349620595574379 Adapter cache time: 0.08181190956383944 Engine time: 0.13330948585644364 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-32/adapters_192_slots_32_rate_0.05-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-32/adapters_192_slots_32_rate_0.05-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 135, 135, 135, 135, 540, 135, 33, 540, 33, 135, 135, 33, 540, 540, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 540, 135, 33, 135, 540, 540, 135, 540, 33, 135, 135, 540, 135, 33, 33, 135, 540, 33, 135, 33, 540, 540, 135, 540, 540, 540, 33, 135, 540, 33, 135, 33, 135, 33, 33, 135, 540, 540, 33, 33, 33, 540, 540, 540, 135, 33, 33, 33, 33, 33, 540, 33, 135, 33, 540, 540, 33, 540, 33, 135, 135, 540, 33, 33, 33, 540, 540, 135, 540, 135, 540, 540, 135, 135, 33, 540, 135, 135, 135, 540, 135, 33, 135, 540, 540, 135, 540, 135, 33, 540, 135, 33, 135, 135, 33, 135, 540, 33, 135, 540, 33, 135, 540, 540, 135, 33, 540, 135, 33, 33, 135, 540, 540, 540, 33, 540, 33, 540, 33, 135, 33, 540, 540, 135, 540, 33, 540, 540, 540, 33, 540, 540, 540, 135, 135, 135, 135, 135, 135, 33, 540, 135, 540, 33, 540, 135, 33, 135, 33, 33, 135, 135, 135, 540, 135, 33, 33]
Prompts retrieved: 45312 . Total input tokens: 10004990 . Total output tokens: 9089958
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.564517896156758,
    "estimated_duration": 3599.9982832634314,
    "input_throughput": 1038.591050829788,
    "output_throughput": 944.1773946955169,
    "total_throughput": 1982.768445525305,
    "itl": 23.43204264878625,
    "ttft": 4265.087142649247,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10716,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 34.9433791806207,
    "arrivals": 15374,
    "finished_requests": 15356,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5645900638774037. Arrivals time: 0.04817444086074829 Scheduler time: 1.109115714672953 Scheduler overhead time: 0.13260603183880448 Adapter cache time: 0.08147807838395238 Engine time: 0.12857998022809625 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-16/adapters_192_slots_32_rate_0.05-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-16/adapters_192_slots_32_rate_0.05-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 135, 135, 135, 135, 540, 135, 33, 540, 33, 135, 135, 33, 540, 540, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 540, 135, 33, 135, 540, 540, 135, 540, 33, 135, 135, 540, 135, 33, 33, 135, 540, 33, 135, 33, 540, 540, 135, 540, 540, 540, 33, 135, 540, 33, 135, 33, 135, 33, 33, 135, 540, 540, 33, 33, 33, 540, 540, 540, 135, 33, 33, 33, 33, 33, 540, 33, 135, 33, 540, 540, 33, 540, 33, 135, 135, 540, 33, 33, 33, 540, 540, 135, 540, 135, 540, 540, 135, 135, 33, 540, 135, 135, 135, 540, 135, 33, 135, 540, 540, 135, 540, 135, 33, 540, 135, 33, 135, 135, 33, 135, 540, 33, 135, 540, 33, 135, 540, 540, 135, 33, 540, 135, 33, 33, 135, 540, 540, 540, 33, 540, 33, 540, 33, 135, 33, 540, 540, 135, 540, 33, 540, 540, 540, 33, 540, 540, 540, 135, 135, 135, 135, 135, 135, 33, 540, 135, 540, 33, 540, 135, 33, 135, 33, 33, 135, 135, 135, 540, 135, 33, 33]
Prompts retrieved: 45312 . Total input tokens: 10004990 . Total output tokens: 9089958
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 1.583660030271858,
    "estimated_duration": 3599.992322898246,
    "input_throughput": 1038.592770383994,
    "output_throughput": 944.1789579327594,
    "total_throughput": 1982.7717283167535,
    "itl": 23.418970706817742,
    "ttft": 4264.75894579502,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10719,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 33.504539849382674,
    "arrivals": 15374,
    "finished_requests": 15356,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5837262612767518. Arrivals time: 0.049129067454487085 Scheduler time: 1.1235219524241984 Scheduler overhead time: 0.13324794452637434 Adapter cache time: 0.08177511161193252 Engine time: 0.13110500946640968 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-32/adapters_192_slots_32_rate_0.05-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-32/adapters_192_slots_32_rate_0.05-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 135, 135, 135, 135, 540, 135, 33, 540, 33, 135, 135, 33, 540, 540, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 540, 135, 33, 135, 540, 540, 135, 540, 33, 135, 135, 540, 135, 33, 33, 135, 540, 33, 135, 33, 540, 540, 135, 540, 540, 540, 33, 135, 540, 33, 135, 33, 135, 33, 33, 135, 540, 540, 33, 33, 33, 540, 540, 540, 135, 33, 33, 33, 33, 33, 540, 33, 135, 33, 540, 540, 33, 540, 33, 135, 135, 540, 33, 33, 33, 540, 540, 135, 540, 135, 540, 540, 135, 135, 33, 540, 135, 135, 135, 540, 135, 33, 135, 540, 540, 135, 540, 135, 33, 540, 135, 33, 135, 135, 33, 135, 540, 33, 135, 540, 33, 135, 540, 540, 135, 33, 540, 135, 33, 33, 135, 540, 540, 540, 33, 540, 33, 540, 33, 135, 33, 540, 540, 135, 540, 33, 540, 540, 540, 33, 540, 540, 540, 135, 135, 135, 135, 135, 135, 33, 540, 135, 540, 33, 540, 135, 33, 135, 33, 33, 135, 135, 135, 540, 135, 33, 33]
Prompts retrieved: 45312 . Total input tokens: 10004990 . Total output tokens: 9089958
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 1.5332543957047164,
    "estimated_duration": 3599.9849920230113,
    "input_throughput": 1038.5948853355944,
    "output_throughput": 944.1808806235915,
    "total_throughput": 1982.775765959186,
    "itl": 23.437279194727466,
    "ttft": 4265.072513192622,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10718,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 35.37070138894102,
    "arrivals": 15374,
    "finished_requests": 15356,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5333336368203163. Arrivals time: 0.047995999455451965 Scheduler time: 1.0835374789312482 Scheduler overhead time: 0.13174379151314497 Adapter cache time: 0.0802720244973898 Engine time: 0.12574074836447835 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-16/adapters_192_slots_32_rate_0.05-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-16/adapters_192_slots_32_rate_0.05-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 135, 135, 135, 135, 540, 135, 33, 540, 33, 135, 135, 33, 540, 540, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 540, 135, 33, 135, 540, 540, 135, 540, 33, 135, 135, 540, 135, 33, 33, 135, 540, 33, 135, 33, 540, 540, 135, 540, 540, 540, 33, 135, 540, 33, 135, 33, 135, 33, 33, 135, 540, 540, 33, 33, 33, 540, 540, 540, 135, 33, 33, 33, 33, 33, 540, 33, 135, 33, 540, 540, 33, 540, 33, 135, 135, 540, 33, 33, 33, 540, 540, 135, 540, 135, 540, 540, 135, 135, 33, 540, 135, 135, 135, 540, 135, 33, 135, 540, 540, 135, 540, 135, 33, 540, 135, 33, 135, 135, 33, 135, 540, 33, 135, 540, 33, 135, 540, 540, 135, 33, 540, 135, 33, 33, 135, 540, 540, 540, 33, 540, 33, 540, 33, 135, 33, 540, 540, 135, 540, 33, 540, 540, 540, 33, 540, 540, 540, 135, 135, 135, 135, 135, 135, 33, 540, 135, 540, 33, 540, 135, 33, 135, 33, 33, 135, 135, 135, 540, 135, 33, 33]
Prompts retrieved: 45312 . Total input tokens: 10004990 . Total output tokens: 9089958
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 1.5856089000590146,
    "estimated_duration": 3599.993923673103,
    "input_throughput": 1038.5923085628833,
    "output_throughput": 944.1785380937351,
    "total_throughput": 1982.7708466566185,
    "itl": 23.40670328874932,
    "ttft": 4264.7001413770395,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10717,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 32.04436901046317,
    "arrivals": 15374,
    "finished_requests": 15356,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5856819283217192. Arrivals time: 0.0492976987734437 Scheduler time: 1.1265517678111792 Scheduler overhead time: 0.1309501864016056 Adapter cache time: 0.08384471060708165 Engine time: 0.1308513255789876 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-32/adapters_192_slots_32_rate_0.05-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-32/adapters_192_slots_32_rate_0.05-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 135, 135, 135, 135, 540, 135, 33, 540, 33, 135, 135, 33, 540, 540, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 540, 135, 33, 135, 540, 540, 135, 540, 33, 135, 135, 540, 135, 33, 33, 135, 540, 33, 135, 33, 540, 540, 135, 540, 540, 540, 33, 135, 540, 33, 135, 33, 135, 33, 33, 135, 540, 540, 33, 33, 33, 540, 540, 540, 135, 33, 33, 33, 33, 33, 540, 33, 135, 33, 540, 540, 33, 540, 33, 135, 135, 540, 33, 33, 33, 540, 540, 135, 540, 135, 540, 540, 135, 135, 33, 540, 135, 135, 135, 540, 135, 33, 135, 540, 540, 135, 540, 135, 33, 540, 135, 33, 135, 135, 33, 135, 540, 33, 135, 540, 33, 135, 540, 540, 135, 33, 540, 135, 33, 33, 135, 540, 540, 540, 33, 540, 33, 540, 33, 135, 33, 540, 540, 135, 540, 33, 540, 540, 540, 33, 540, 540, 540, 135, 135, 135, 135, 135, 135, 33, 540, 135, 540, 33, 540, 135, 33, 135, 33, 33, 135, 135, 135, 540, 135, 33, 33]
Prompts retrieved: 45312 . Total input tokens: 10004990 . Total output tokens: 9089958
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.5744097088463604,
    "estimated_duration": 3599.9859329167143,
    "input_throughput": 1038.5946138880372,
    "output_throughput": 944.1806338521147,
    "total_throughput": 1982.7752477401518,
    "itl": 23.4400529775592,
    "ttft": 4265.200697017325,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10720,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 35.82447190627286,
    "arrivals": 15374,
    "finished_requests": 15356,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5744747249409556. Arrivals time: 0.04966235579922795 Scheduler time: 1.1176620493642986 Scheduler overhead time: 0.13237770833075047 Adapter cache time: 0.08142167888581753 Engine time: 0.12911493191495538 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-8/adapters_192_slots_32_rate_0.05-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-8/adapters_192_slots_32_rate_0.05-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 66, 66, 66, 66, 540, 66, 33, 540, 33, 66, 66, 33, 540, 540, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 540, 66, 33, 66, 540, 540, 66, 540, 33, 66, 66, 540, 66, 33, 33, 66, 540, 33, 66, 33, 540, 540, 66, 540, 540, 540, 33, 66, 540, 33, 66, 33, 66, 33, 33, 66, 540, 540, 33, 33, 33, 540, 540, 540, 66, 33, 33, 33, 33, 33, 540, 33, 66, 33, 540, 540, 33, 540, 33, 66, 66, 540, 33, 33, 33, 540, 540, 66, 540, 66, 540, 540, 66, 66, 33, 540, 66, 66, 66, 540, 66, 33, 66, 540, 540, 66, 540, 66, 33, 540, 66, 33, 66, 66, 33, 66, 540, 33, 66, 540, 33, 66, 540, 540, 66, 33, 540, 66, 33, 33, 66, 540, 540, 540, 33, 540, 33, 540, 33, 66, 33, 540, 540, 66, 540, 33, 540, 540, 540, 33, 540, 540, 540, 66, 66, 66, 66, 66, 66, 33, 540, 66, 540, 33, 540, 66, 33, 66, 33, 33, 66, 66, 66, 540, 66, 33, 33]
Prompts retrieved: 40896 . Total input tokens: 9009721 . Total output tokens: 8220936
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 1.4759830576367676,
    "estimated_duration": 3599.9186307691675,
    "input_throughput": 935.0572458024653,
    "output_throughput": 853.1528945541146,
    "total_throughput": 1788.2101403565798,
    "itl": 22.526910753222435,
    "ttft": 6528.254849216038,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8995,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.529087256677066,
    "arrivals": 13872,
    "finished_requests": 13847,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4760549790225923. Arrivals time: 0.045610465575009584 Scheduler time: 1.020355821121484 Scheduler overhead time: 0.1362221329472959 Adapter cache time: 0.07384117133915424 Engine time: 0.13394217425957322 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-16/adapters_192_slots_32_rate_0.05-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-16/adapters_192_slots_32_rate_0.05-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 66, 66, 66, 66, 540, 66, 33, 540, 33, 66, 66, 33, 540, 540, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 540, 66, 33, 66, 540, 540, 66, 540, 33, 66, 66, 540, 66, 33, 33, 66, 540, 33, 66, 33, 540, 540, 66, 540, 540, 540, 33, 66, 540, 33, 66, 33, 66, 33, 33, 66, 540, 540, 33, 33, 33, 540, 540, 540, 66, 33, 33, 33, 33, 33, 540, 33, 66, 33, 540, 540, 33, 540, 33, 66, 66, 540, 33, 33, 33, 540, 540, 66, 540, 66, 540, 540, 66, 66, 33, 540, 66, 66, 66, 540, 66, 33, 66, 540, 540, 66, 540, 66, 33, 540, 66, 33, 66, 66, 33, 66, 540, 33, 66, 540, 33, 66, 540, 540, 66, 33, 540, 66, 33, 33, 66, 540, 540, 540, 33, 540, 33, 540, 33, 66, 33, 540, 540, 66, 540, 33, 540, 540, 540, 33, 540, 540, 540, 66, 66, 66, 66, 66, 66, 33, 540, 66, 540, 33, 540, 66, 33, 66, 33, 33, 66, 66, 66, 540, 66, 33, 33]
Prompts retrieved: 40896 . Total input tokens: 9009721 . Total output tokens: 8220936
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.4637934430502355,
    "estimated_duration": 3599.9171602235942,
    "input_throughput": 935.057627768003,
    "output_throughput": 853.153243062193,
    "total_throughput": 1788.2108708301962,
    "itl": 22.54373846824266,
    "ttft": 6528.368707379269,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8994,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.259505032071417,
    "arrivals": 13872,
    "finished_requests": 13847,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4638597327284515. Arrivals time: 0.045026097912341356 Scheduler time: 1.01154709700495 Scheduler overhead time: 0.13500260282307863 Adapter cache time: 0.07385274767875671 Engine time: 0.13244845531880856 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-32/adapters_192_slots_32_rate_0.05-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-32/adapters_192_slots_32_rate_0.05-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 66, 66, 66, 66, 540, 66, 33, 540, 33, 66, 66, 33, 540, 540, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 540, 66, 33, 66, 540, 540, 66, 540, 33, 66, 66, 540, 66, 33, 33, 66, 540, 33, 66, 33, 540, 540, 66, 540, 540, 540, 33, 66, 540, 33, 66, 33, 66, 33, 33, 66, 540, 540, 33, 33, 33, 540, 540, 540, 66, 33, 33, 33, 33, 33, 540, 33, 66, 33, 540, 540, 33, 540, 33, 66, 66, 540, 33, 33, 33, 540, 540, 66, 540, 66, 540, 540, 66, 66, 33, 540, 66, 66, 66, 540, 66, 33, 66, 540, 540, 66, 540, 66, 33, 540, 66, 33, 66, 66, 33, 66, 540, 33, 66, 540, 33, 66, 540, 540, 66, 33, 540, 66, 33, 33, 66, 540, 540, 540, 33, 540, 33, 540, 33, 66, 33, 540, 540, 66, 540, 33, 540, 540, 540, 33, 540, 540, 540, 66, 66, 66, 66, 66, 66, 33, 540, 66, 540, 33, 540, 66, 33, 66, 33, 33, 66, 66, 66, 540, 66, 33, 33]
Prompts retrieved: 40896 . Total input tokens: 9009721 . Total output tokens: 8220936
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.46648937324062,
    "estimated_duration": 3599.914210801426,
    "input_throughput": 935.0583938639526,
    "output_throughput": 853.1539420535969,
    "total_throughput": 1788.2123359175496,
    "itl": 22.543061899174155,
    "ttft": 6528.3490857484985,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8993,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.32370249528531,
    "arrivals": 13872,
    "finished_requests": 13847,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4665802861563861. Arrivals time: 0.04637964768335223 Scheduler time: 1.014009041711688 Scheduler overhead time: 0.1351462621241808 Adapter cache time: 0.07414028560742736 Engine time: 0.1311569521203637 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-16/adapters_192_slots_32_rate_0.05-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-16/adapters_192_slots_32_rate_0.05-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 66, 66, 66, 66, 540, 66, 33, 540, 33, 66, 66, 33, 540, 540, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 540, 66, 33, 66, 540, 540, 66, 540, 33, 66, 66, 540, 66, 33, 33, 66, 540, 33, 66, 33, 540, 540, 66, 540, 540, 540, 33, 66, 540, 33, 66, 33, 66, 33, 33, 66, 540, 540, 33, 33, 33, 540, 540, 540, 66, 33, 33, 33, 33, 33, 540, 33, 66, 33, 540, 540, 33, 540, 33, 66, 66, 540, 33, 33, 33, 540, 540, 66, 540, 66, 540, 540, 66, 66, 33, 540, 66, 66, 66, 540, 66, 33, 66, 540, 540, 66, 540, 66, 33, 540, 66, 33, 66, 66, 33, 66, 540, 33, 66, 540, 33, 66, 540, 540, 66, 33, 540, 66, 33, 33, 66, 540, 540, 540, 33, 540, 33, 540, 33, 66, 33, 540, 540, 66, 540, 33, 540, 540, 540, 33, 540, 540, 540, 66, 66, 66, 66, 66, 66, 33, 540, 66, 540, 33, 540, 66, 33, 66, 33, 33, 66, 66, 66, 540, 66, 33, 33]
Prompts retrieved: 40896 . Total input tokens: 9009721 . Total output tokens: 8220936
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 1.4761841068975627,
    "estimated_duration": 3599.905475596073,
    "input_throughput": 934.9076032177559,
    "output_throughput": 853.155456669722,
    "total_throughput": 1788.0630598874777,
    "itl": 22.533259373246256,
    "ttft": 6787.876762439465,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9001,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.159249830336304,
    "arrivals": 13872,
    "finished_requests": 13846,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.476253384258598. Arrivals time: 0.04565972089767456 Scheduler time: 1.0171297597698867 Scheduler overhead time: 0.1371745108626783 Adapter cache time: 0.07409383915364742 Engine time: 0.13604889390990138 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-32/adapters_192_slots_32_rate_0.05-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-32/adapters_192_slots_32_rate_0.05-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 66, 66, 66, 66, 540, 66, 33, 540, 33, 66, 66, 33, 540, 540, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 540, 66, 33, 66, 540, 540, 66, 540, 33, 66, 66, 540, 66, 33, 33, 66, 540, 33, 66, 33, 540, 540, 66, 540, 540, 540, 33, 66, 540, 33, 66, 33, 66, 33, 33, 66, 540, 540, 33, 33, 33, 540, 540, 540, 66, 33, 33, 33, 33, 33, 540, 33, 66, 33, 540, 540, 33, 540, 33, 66, 66, 540, 33, 33, 33, 540, 540, 66, 540, 66, 540, 540, 66, 66, 33, 540, 66, 66, 66, 540, 66, 33, 66, 540, 540, 66, 540, 66, 33, 540, 66, 33, 66, 66, 33, 66, 540, 33, 66, 540, 33, 66, 540, 540, 66, 33, 540, 66, 33, 33, 66, 540, 540, 540, 33, 540, 33, 540, 33, 66, 33, 540, 540, 66, 540, 33, 540, 540, 540, 33, 540, 540, 540, 66, 66, 66, 66, 66, 66, 33, 540, 66, 540, 33, 540, 66, 33, 66, 33, 33, 66, 66, 66, 540, 66, 33, 33]
Prompts retrieved: 40896 . Total input tokens: 9009721 . Total output tokens: 8220936
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 1.4603609507903457,
    "estimated_duration": 3599.9154432209257,
    "input_throughput": 935.0580737497121,
    "output_throughput": 853.1536499790827,
    "total_throughput": 1788.2117237287948,
    "itl": 22.54686631598475,
    "ttft": 6528.48338868294,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9000,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.692727771046805,
    "arrivals": 13872,
    "finished_requests": 13847,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4604335739277303. Arrivals time: 0.04562656953930855 Scheduler time: 1.0093003129586577 Scheduler overhead time: 0.13547009881585836 Adapter cache time: 0.07316551869735122 Engine time: 0.1308869170024991 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-16/adapters_192_slots_32_rate_0.05-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-16/adapters_192_slots_32_rate_0.05-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 66, 66, 66, 66, 540, 66, 33, 540, 33, 66, 66, 33, 540, 540, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 540, 66, 33, 66, 540, 540, 66, 540, 33, 66, 66, 540, 66, 33, 33, 66, 540, 33, 66, 33, 540, 540, 66, 540, 540, 540, 33, 66, 540, 33, 66, 33, 66, 33, 33, 66, 540, 540, 33, 33, 33, 540, 540, 540, 66, 33, 33, 33, 33, 33, 540, 33, 66, 33, 540, 540, 33, 540, 33, 66, 66, 540, 33, 33, 33, 540, 540, 66, 540, 66, 540, 540, 66, 66, 33, 540, 66, 66, 66, 540, 66, 33, 66, 540, 540, 66, 540, 66, 33, 540, 66, 33, 66, 66, 33, 66, 540, 33, 66, 540, 33, 66, 540, 540, 66, 33, 540, 66, 33, 33, 66, 540, 540, 540, 33, 540, 33, 540, 33, 66, 33, 540, 540, 66, 540, 33, 540, 540, 540, 33, 540, 540, 540, 66, 66, 66, 66, 66, 66, 33, 540, 66, 540, 33, 540, 66, 33, 66, 33, 33, 66, 66, 66, 540, 66, 33, 33]
Prompts retrieved: 40896 . Total input tokens: 9009721 . Total output tokens: 8220936
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 1.4436270869337022,
    "estimated_duration": 3599.902227543276,
    "input_throughput": 934.9084467487919,
    "output_throughput": 853.1562264389523,
    "total_throughput": 1788.0646731877443,
    "itl": 22.52464843716079,
    "ttft": 6787.701354511481,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8992,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.886532251758585,
    "arrivals": 13872,
    "finished_requests": 13846,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4436955777928233. Arrivals time: 0.04488170752301812 Scheduler time: 0.9934438923373818 Scheduler overhead time: 0.13635819125920534 Adapter cache time: 0.0724772741086781 Engine time: 0.13047821167856455 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-32/adapters_192_slots_32_rate_0.05-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-32/adapters_192_slots_32_rate_0.05-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 66, 66, 66, 66, 540, 66, 33, 540, 33, 66, 66, 33, 540, 540, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 540, 66, 33, 66, 540, 540, 66, 540, 33, 66, 66, 540, 66, 33, 33, 66, 540, 33, 66, 33, 540, 540, 66, 540, 540, 540, 33, 66, 540, 33, 66, 33, 66, 33, 33, 66, 540, 540, 33, 33, 33, 540, 540, 540, 66, 33, 33, 33, 33, 33, 540, 33, 66, 33, 540, 540, 33, 540, 33, 66, 66, 540, 33, 33, 33, 540, 540, 66, 540, 66, 540, 540, 66, 66, 33, 540, 66, 66, 66, 540, 66, 33, 66, 540, 540, 66, 540, 66, 33, 540, 66, 33, 66, 66, 33, 66, 540, 33, 66, 540, 33, 66, 540, 540, 66, 33, 540, 66, 33, 33, 66, 540, 540, 540, 33, 540, 33, 540, 33, 66, 33, 540, 540, 66, 540, 33, 540, 540, 540, 33, 540, 540, 540, 66, 66, 66, 66, 66, 66, 33, 540, 66, 540, 33, 540, 66, 33, 66, 33, 33, 66, 66, 66, 540, 66, 33, 33]
Prompts retrieved: 40896 . Total input tokens: 9009721 . Total output tokens: 8220936
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.4648021589964628,
    "estimated_duration": 3599.9206342216585,
    "input_throughput": 935.0567254180017,
    "output_throughput": 853.1524197516216,
    "total_throughput": 1788.2091451696233,
    "itl": 22.54962164214166,
    "ttft": 6528.432922844927,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8999,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 30.073107546975148,
    "arrivals": 13872,
    "finished_requests": 13847,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4648632109165192. Arrivals time: 0.04556191340088844 Scheduler time: 1.0111799305304885 Scheduler overhead time: 0.13831863179802895 Adapter cache time: 0.07309535378590226 Engine time: 0.13002832047641277 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-8/adapters_192_slots_32_rate_0.025-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-8/adapters_192_slots_32_rate_0.025-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [64 64 64]
Adapter prompts. [270, 66, 270, 66, 270, 66, 270, 66, 66, 66, 135, 135, 135, 135, 270, 135, 66, 270, 66, 135, 135, 66, 270, 270, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 270, 135, 66, 135, 270, 270, 135, 270, 66, 135, 135, 270, 135, 66, 66, 135, 270, 66, 135, 66, 270, 270, 135, 270, 270, 270, 66, 135, 270, 66, 135, 66, 135, 66, 66, 135, 270, 270, 66, 66, 66, 270, 270, 270, 135, 66, 66, 66, 66, 66, 270, 66, 135, 66, 270, 270, 66, 270, 66, 135, 135, 270, 66, 66, 66, 270, 270, 135, 270, 135, 270, 270, 135, 135, 66, 270, 135, 135, 135, 270, 135, 66, 135, 270, 270, 135, 270, 135, 66, 270, 135, 66, 135, 135, 66, 135, 270, 66, 135, 270, 66, 135, 270, 270, 135, 66, 270, 135, 66, 66, 135, 270, 270, 270, 66, 270, 66, 270, 66, 135, 66, 270, 270, 135, 270, 66, 270, 270, 270, 66, 270, 270, 270, 135, 135, 135, 135, 135, 135, 66, 270, 135, 270, 66, 270, 135, 66, 135, 66, 66, 135, 135, 135, 270, 135, 66, 66]
Prompts retrieved: 30144 . Total input tokens: 6607829 . Total output tokens: 6040768
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 1.2250262540765107,
    "estimated_duration": 3599.238888188252,
    "input_throughput": 696.3588908269511,
    "output_throughput": 615.3745468989705,
    "total_throughput": 1311.7334377259217,
    "itl": 20.95432406043165,
    "ttft": 4638.5772161187515,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7959,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.358421953961702,
    "arrivals": 10170,
    "finished_requests": 10157,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2250847104005516. Arrivals time: 0.03716880176216364 Scheduler time: 0.769162863958627 Scheduler overhead time: 0.14544808445498347 Adapter cache time: 0.06456967769190669 Engine time: 0.13828893145546317 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-16/adapters_192_slots_32_rate_0.025-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-16/adapters_192_slots_32_rate_0.025-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [64 64 64]
Adapter prompts. [270, 66, 270, 66, 270, 66, 270, 66, 66, 66, 135, 135, 135, 135, 270, 135, 66, 270, 66, 135, 135, 66, 270, 270, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 270, 135, 66, 135, 270, 270, 135, 270, 66, 135, 135, 270, 135, 66, 66, 135, 270, 66, 135, 66, 270, 270, 135, 270, 270, 270, 66, 135, 270, 66, 135, 66, 135, 66, 66, 135, 270, 270, 66, 66, 66, 270, 270, 270, 135, 66, 66, 66, 66, 66, 270, 66, 135, 66, 270, 270, 66, 270, 66, 135, 135, 270, 66, 66, 66, 270, 270, 135, 270, 135, 270, 270, 135, 135, 66, 270, 135, 135, 135, 270, 135, 66, 135, 270, 270, 135, 270, 135, 66, 270, 135, 66, 135, 135, 66, 135, 270, 66, 135, 270, 66, 135, 270, 270, 135, 66, 270, 135, 66, 66, 135, 270, 270, 270, 66, 270, 66, 270, 66, 135, 66, 270, 270, 135, 270, 66, 270, 270, 270, 66, 270, 270, 270, 135, 135, 135, 135, 135, 135, 66, 270, 135, 270, 66, 270, 135, 66, 135, 66, 66, 135, 135, 135, 270, 135, 66, 66]
Prompts retrieved: 30144 . Total input tokens: 6607829 . Total output tokens: 6040768
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.2084893779829144,
    "estimated_duration": 3599.2389045911136,
    "input_throughput": 696.3588876534251,
    "output_throughput": 615.3745440945155,
    "total_throughput": 1311.7334317479406,
    "itl": 20.965494994691426,
    "ttft": 4638.742062238137,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7955,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.906459798649728,
    "arrivals": 10170,
    "finished_requests": 10157,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.208546953741461. Arrivals time: 0.03704248974099755 Scheduler time: 0.7566962568089366 Scheduler overhead time: 0.1432466935366392 Adapter cache time: 0.06466700276359916 Engine time: 0.13693017791956663 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-32/adapters_192_slots_32_rate_0.025-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-32/adapters_192_slots_32_rate_0.025-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [64 64 64]
Adapter prompts. [270, 66, 270, 66, 270, 66, 270, 66, 66, 66, 135, 135, 135, 135, 270, 135, 66, 270, 66, 135, 135, 66, 270, 270, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 270, 135, 66, 135, 270, 270, 135, 270, 66, 135, 135, 270, 135, 66, 66, 135, 270, 66, 135, 66, 270, 270, 135, 270, 270, 270, 66, 135, 270, 66, 135, 66, 135, 66, 66, 135, 270, 270, 66, 66, 66, 270, 270, 270, 135, 66, 66, 66, 66, 66, 270, 66, 135, 66, 270, 270, 66, 270, 66, 135, 135, 270, 66, 66, 66, 270, 270, 135, 270, 135, 270, 270, 135, 135, 66, 270, 135, 135, 135, 270, 135, 66, 135, 270, 270, 135, 270, 135, 66, 270, 135, 66, 135, 135, 66, 135, 270, 66, 135, 270, 66, 135, 270, 270, 135, 66, 270, 135, 66, 66, 135, 270, 270, 270, 66, 270, 66, 270, 66, 135, 66, 270, 270, 135, 270, 66, 270, 270, 270, 66, 270, 270, 270, 135, 135, 135, 135, 135, 135, 66, 270, 135, 270, 66, 270, 135, 66, 135, 66, 66, 135, 135, 135, 270, 135, 66, 66]
Prompts retrieved: 30144 . Total input tokens: 6607829 . Total output tokens: 6040768
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.2260653609409928,
    "estimated_duration": 3599.244506054313,
    "input_throughput": 696.3578039180255,
    "output_throughput": 615.3735863941267,
    "total_throughput": 1311.7313903121524,
    "itl": 20.96720612462211,
    "ttft": 4638.641249055394,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7957,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.967931223754267,
    "arrivals": 10170,
    "finished_requests": 10157,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.22615678422153. Arrivals time: 0.03775605885311961 Scheduler time: 0.768882586620748 Scheduler overhead time: 0.14374547637999058 Adapter cache time: 0.06438909936696291 Engine time: 0.14112657262012362 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-16/adapters_192_slots_32_rate_0.025-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-16/adapters_192_slots_32_rate_0.025-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [64 64 64]
Adapter prompts. [270, 66, 270, 66, 270, 66, 270, 66, 66, 66, 135, 135, 135, 135, 270, 135, 66, 270, 66, 135, 135, 66, 270, 270, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 270, 135, 66, 135, 270, 270, 135, 270, 66, 135, 135, 270, 135, 66, 66, 135, 270, 66, 135, 66, 270, 270, 135, 270, 270, 270, 66, 135, 270, 66, 135, 66, 135, 66, 66, 135, 270, 270, 66, 66, 66, 270, 270, 270, 135, 66, 66, 66, 66, 66, 270, 66, 135, 66, 270, 270, 66, 270, 66, 135, 135, 270, 66, 66, 66, 270, 270, 135, 270, 135, 270, 270, 135, 135, 66, 270, 135, 135, 135, 270, 135, 66, 135, 270, 270, 135, 270, 135, 66, 270, 135, 66, 135, 135, 66, 135, 270, 66, 135, 270, 66, 135, 270, 270, 135, 66, 270, 135, 66, 66, 135, 270, 270, 270, 66, 270, 66, 270, 66, 135, 66, 270, 270, 135, 270, 66, 270, 270, 270, 66, 270, 270, 270, 135, 135, 135, 135, 135, 135, 66, 270, 135, 270, 66, 270, 135, 66, 135, 66, 66, 135, 135, 135, 270, 135, 66, 66]
Prompts retrieved: 30144 . Total input tokens: 6607829 . Total output tokens: 6040768
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 1.2194719999097288,
    "estimated_duration": 3599.2301388940364,
    "input_throughput": 696.3605835913982,
    "output_throughput": 615.3760428002482,
    "total_throughput": 1311.7366263916463,
    "itl": 20.958949635019945,
    "ttft": 4638.692423144234,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7956,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.861811452464423,
    "arrivals": 10170,
    "finished_requests": 10157,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2195413168519735. Arrivals time: 0.03699875622987747 Scheduler time: 0.7668112176470459 Scheduler overhead time: 0.14187518181279302 Adapter cache time: 0.06455806270241737 Engine time: 0.1392971957102418 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-32/adapters_192_slots_32_rate_0.025-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-32/adapters_192_slots_32_rate_0.025-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [64 64 64]
Adapter prompts. [270, 66, 270, 66, 270, 66, 270, 66, 66, 66, 135, 135, 135, 135, 270, 135, 66, 270, 66, 135, 135, 66, 270, 270, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 270, 135, 66, 135, 270, 270, 135, 270, 66, 135, 135, 270, 135, 66, 66, 135, 270, 66, 135, 66, 270, 270, 135, 270, 270, 270, 66, 135, 270, 66, 135, 66, 135, 66, 66, 135, 270, 270, 66, 66, 66, 270, 270, 270, 135, 66, 66, 66, 66, 66, 270, 66, 135, 66, 270, 270, 66, 270, 66, 135, 135, 270, 66, 66, 66, 270, 270, 135, 270, 135, 270, 270, 135, 135, 66, 270, 135, 135, 135, 270, 135, 66, 135, 270, 270, 135, 270, 135, 66, 270, 135, 66, 135, 135, 66, 135, 270, 66, 135, 270, 66, 135, 270, 270, 135, 66, 270, 135, 66, 66, 135, 270, 270, 270, 66, 270, 66, 270, 66, 135, 66, 270, 270, 135, 270, 66, 270, 270, 270, 66, 270, 270, 270, 135, 135, 135, 135, 135, 135, 66, 270, 135, 270, 66, 270, 135, 66, 135, 66, 66, 135, 135, 135, 270, 135, 66, 66]
Prompts retrieved: 30144 . Total input tokens: 6607829 . Total output tokens: 6040768
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 1.2081446154043078,
    "estimated_duration": 3599.2326868998334,
    "input_throughput": 696.3600906166565,
    "output_throughput": 615.3756071569152,
    "total_throughput": 1311.7356977735717,
    "itl": 20.968634734776373,
    "ttft": 4638.833776378619,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7958,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.293533204755853,
    "arrivals": 10170,
    "finished_requests": 10157,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2082171184010804. Arrivals time: 0.0373880323022604 Scheduler time: 0.7558553479611874 Scheduler overhead time: 0.14168225973844528 Adapter cache time: 0.06410380639135838 Engine time: 0.13957992708310485 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-16/adapters_192_slots_32_rate_0.025-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-16/adapters_192_slots_32_rate_0.025-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [64 64 64]
Adapter prompts. [270, 66, 270, 66, 270, 66, 270, 66, 66, 66, 135, 135, 135, 135, 270, 135, 66, 270, 66, 135, 135, 66, 270, 270, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 270, 135, 66, 135, 270, 270, 135, 270, 66, 135, 135, 270, 135, 66, 66, 135, 270, 66, 135, 66, 270, 270, 135, 270, 270, 270, 66, 135, 270, 66, 135, 66, 135, 66, 66, 135, 270, 270, 66, 66, 66, 270, 270, 270, 135, 66, 66, 66, 66, 66, 270, 66, 135, 66, 270, 270, 66, 270, 66, 135, 135, 270, 66, 66, 66, 270, 270, 135, 270, 135, 270, 270, 135, 135, 66, 270, 135, 135, 135, 270, 135, 66, 135, 270, 270, 135, 270, 135, 66, 270, 135, 66, 135, 135, 66, 135, 270, 66, 135, 270, 66, 135, 270, 270, 135, 66, 270, 135, 66, 66, 135, 270, 270, 270, 66, 270, 66, 270, 66, 135, 66, 270, 270, 135, 270, 66, 270, 270, 270, 66, 270, 270, 270, 135, 135, 135, 135, 135, 135, 66, 270, 135, 270, 66, 270, 135, 66, 135, 66, 66, 135, 135, 135, 270, 135, 66, 66]
Prompts retrieved: 30144 . Total input tokens: 6607829 . Total output tokens: 6040768
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 1.2135814647190273,
    "estimated_duration": 3599.2387052162135,
    "input_throughput": 696.3589262272723,
    "output_throughput": 615.3745781823459,
    "total_throughput": 1311.733504409618,
    "itl": 20.94926437739776,
    "ttft": 4638.509597284781,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7958,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.794820246830763,
    "arrivals": 10170,
    "finished_requests": 10157,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2136463187634945. Arrivals time: 0.037537554278969765 Scheduler time: 0.7624671924859285 Scheduler overhead time: 0.14246837561950088 Adapter cache time: 0.0639228280633688 Engine time: 0.13703194400295615 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-32/adapters_192_slots_32_rate_0.025-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-32/adapters_192_slots_32_rate_0.025-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [64 64 64]
Adapter prompts. [270, 66, 270, 66, 270, 66, 270, 66, 66, 66, 135, 135, 135, 135, 270, 135, 66, 270, 66, 135, 135, 66, 270, 270, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 270, 135, 66, 135, 270, 270, 135, 270, 66, 135, 135, 270, 135, 66, 66, 135, 270, 66, 135, 66, 270, 270, 135, 270, 270, 270, 66, 135, 270, 66, 135, 66, 135, 66, 66, 135, 270, 270, 66, 66, 66, 270, 270, 270, 135, 66, 66, 66, 66, 66, 270, 66, 135, 66, 270, 270, 66, 270, 66, 135, 135, 270, 66, 66, 66, 270, 270, 135, 270, 135, 270, 270, 135, 135, 66, 270, 135, 135, 135, 270, 135, 66, 135, 270, 270, 135, 270, 135, 66, 270, 135, 66, 135, 135, 66, 135, 270, 66, 135, 270, 66, 135, 270, 270, 135, 66, 270, 135, 66, 66, 135, 270, 270, 270, 66, 270, 66, 270, 66, 135, 66, 270, 270, 135, 270, 66, 270, 270, 270, 66, 270, 270, 270, 135, 135, 135, 135, 135, 135, 66, 270, 135, 270, 66, 270, 135, 66, 135, 66, 66, 135, 135, 135, 270, 135, 66, 66]
Prompts retrieved: 30144 . Total input tokens: 6607829 . Total output tokens: 6040768
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.2069045277312398,
    "estimated_duration": 3599.2399223845523,
    "input_throughput": 696.3586907369865,
    "output_throughput": 615.3743700788381,
    "total_throughput": 1311.7330608158247,
    "itl": 20.970307498827665,
    "ttft": 4638.827755250276,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7958,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.623299646598895,
    "arrivals": 10170,
    "finished_requests": 10157,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2069769380614161. Arrivals time: 0.03700227057561278 Scheduler time: 0.7566240075975657 Scheduler overhead time: 0.14427080936729908 Adapter cache time: 0.0636751395650208 Engine time: 0.13492964580655098 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-8/adapters_192_slots_32_rate_0.025-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-8/adapters_192_slots_32_rate_0.025-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [64 64 64]
Adapter prompts. [270, 33, 270, 33, 270, 33, 270, 33, 33, 33, 135, 135, 135, 135, 270, 135, 33, 270, 33, 135, 135, 33, 270, 270, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 270, 135, 33, 135, 270, 270, 135, 270, 33, 135, 135, 270, 135, 33, 33, 135, 270, 33, 135, 33, 270, 270, 135, 270, 270, 270, 33, 135, 270, 33, 135, 33, 135, 33, 33, 135, 270, 270, 33, 33, 33, 270, 270, 270, 135, 33, 33, 33, 33, 33, 270, 33, 135, 33, 270, 270, 33, 270, 33, 135, 135, 270, 33, 33, 33, 270, 270, 135, 270, 135, 270, 270, 135, 135, 33, 270, 135, 135, 135, 270, 135, 33, 135, 270, 270, 135, 270, 135, 33, 270, 135, 33, 135, 135, 33, 135, 270, 33, 135, 270, 33, 135, 270, 270, 135, 33, 270, 135, 33, 33, 135, 270, 270, 270, 33, 270, 33, 270, 33, 135, 33, 270, 270, 135, 270, 33, 270, 270, 270, 33, 270, 270, 270, 135, 135, 135, 135, 135, 135, 33, 270, 135, 270, 33, 270, 135, 33, 135, 33, 33, 135, 135, 135, 270, 135, 33, 33]
Prompts retrieved: 28032 . Total input tokens: 6152033 . Total output tokens: 5608060
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 1.1677518873475492,
    "estimated_duration": 3599.7706970219438,
    "input_throughput": 641.2269542361712,
    "output_throughput": 572.6461970773229,
    "total_throughput": 1213.8731513134942,
    "itl": 20.673281030370813,
    "ttft": 4987.662344729916,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7185,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.98960444015698,
    "arrivals": 9452,
    "finished_requests": 9439,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1678263382054865. Arrivals time: 0.03579478431493044 Scheduler time: 0.7155694500543177 Scheduler overhead time: 0.14306153543293476 Adapter cache time: 0.060690485406666994 Engine time: 0.1423732927069068 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-16/adapters_192_slots_32_rate_0.025-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-16/adapters_192_slots_32_rate_0.025-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [64 64 64]
Adapter prompts. [270, 33, 270, 33, 270, 33, 270, 33, 33, 33, 135, 135, 135, 135, 270, 135, 33, 270, 33, 135, 135, 33, 270, 270, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 270, 135, 33, 135, 270, 270, 135, 270, 33, 135, 135, 270, 135, 33, 33, 135, 270, 33, 135, 33, 270, 270, 135, 270, 270, 270, 33, 135, 270, 33, 135, 33, 135, 33, 33, 135, 270, 270, 33, 33, 33, 270, 270, 270, 135, 33, 33, 33, 33, 33, 270, 33, 135, 33, 270, 270, 33, 270, 33, 135, 135, 270, 33, 33, 33, 270, 270, 135, 270, 135, 270, 270, 135, 135, 33, 270, 135, 135, 135, 270, 135, 33, 135, 270, 270, 135, 270, 135, 33, 270, 135, 33, 135, 135, 33, 135, 270, 33, 135, 270, 33, 135, 270, 270, 135, 33, 270, 135, 33, 33, 135, 270, 270, 270, 33, 270, 33, 270, 33, 135, 33, 270, 270, 135, 270, 33, 270, 270, 270, 33, 270, 270, 270, 135, 135, 135, 135, 135, 135, 33, 270, 135, 270, 33, 270, 135, 33, 135, 33, 33, 135, 135, 135, 270, 135, 33, 33]
Prompts retrieved: 28032 . Total input tokens: 6152033 . Total output tokens: 5608060
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.165246597956866,
    "estimated_duration": 3599.7697443290676,
    "input_throughput": 641.2271239393452,
    "output_throughput": 572.6463486303363,
    "total_throughput": 1213.8734725696816,
    "itl": 20.68421717950919,
    "ttft": 4987.694359177881,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7184,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.364145736585694,
    "arrivals": 9452,
    "finished_requests": 9439,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1653203507885337. Arrivals time: 0.036270261742174625 Scheduler time: 0.7156911711208522 Scheduler overhead time: 0.14228603336960077 Adapter cache time: 0.06046187551692128 Engine time: 0.14046346908435225 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-32/adapters_192_slots_32_rate_0.025-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-32/adapters_192_slots_32_rate_0.025-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [64 64 64]
Adapter prompts. [270, 33, 270, 33, 270, 33, 270, 33, 33, 33, 135, 135, 135, 135, 270, 135, 33, 270, 33, 135, 135, 33, 270, 270, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 270, 135, 33, 135, 270, 270, 135, 270, 33, 135, 135, 270, 135, 33, 33, 135, 270, 33, 135, 33, 270, 270, 135, 270, 270, 270, 33, 135, 270, 33, 135, 33, 135, 33, 33, 135, 270, 270, 33, 33, 33, 270, 270, 270, 135, 33, 33, 33, 33, 33, 270, 33, 135, 33, 270, 270, 33, 270, 33, 135, 135, 270, 33, 33, 33, 270, 270, 135, 270, 135, 270, 270, 135, 135, 33, 270, 135, 135, 135, 270, 135, 33, 135, 270, 270, 135, 270, 135, 33, 270, 135, 33, 135, 135, 33, 135, 270, 33, 135, 270, 33, 135, 270, 270, 135, 33, 270, 135, 33, 33, 135, 270, 270, 270, 33, 270, 33, 270, 33, 135, 33, 270, 270, 135, 270, 33, 270, 270, 270, 33, 270, 270, 270, 135, 135, 135, 135, 135, 135, 33, 270, 135, 270, 33, 270, 135, 33, 135, 33, 33, 135, 135, 135, 270, 135, 33, 33]
Prompts retrieved: 28032 . Total input tokens: 6152033 . Total output tokens: 5608060
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.1673148348927498,
    "estimated_duration": 3599.7684686823736,
    "input_throughput": 641.2273511704207,
    "output_throughput": 572.6465515585046,
    "total_throughput": 1213.8739027289253,
    "itl": 20.684648178907953,
    "ttft": 4987.737900584119,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7185,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.422393878176607,
    "arrivals": 9452,
    "finished_requests": 9439,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1673735999502242. Arrivals time: 0.03554926672950387 Scheduler time: 0.7180541027337313 Scheduler overhead time: 0.14322883123531938 Adapter cache time: 0.061172365210950375 Engine time: 0.13914732355624437 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-16/adapters_192_slots_32_rate_0.025-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-16/adapters_192_slots_32_rate_0.025-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [64 64 64]
Adapter prompts. [270, 33, 270, 33, 270, 33, 270, 33, 33, 33, 135, 135, 135, 135, 270, 135, 33, 270, 33, 135, 135, 33, 270, 270, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 270, 135, 33, 135, 270, 270, 135, 270, 33, 135, 135, 270, 135, 33, 33, 135, 270, 33, 135, 33, 270, 270, 135, 270, 270, 270, 33, 135, 270, 33, 135, 33, 135, 33, 33, 135, 270, 270, 33, 33, 33, 270, 270, 270, 135, 33, 33, 33, 33, 33, 270, 33, 135, 33, 270, 270, 33, 270, 33, 135, 135, 270, 33, 33, 33, 270, 270, 135, 270, 135, 270, 270, 135, 135, 33, 270, 135, 135, 135, 270, 135, 33, 135, 270, 270, 135, 270, 135, 33, 270, 135, 33, 135, 135, 33, 135, 270, 33, 135, 270, 33, 135, 270, 270, 135, 33, 270, 135, 33, 33, 135, 270, 270, 270, 33, 270, 33, 270, 33, 135, 33, 270, 270, 135, 270, 33, 270, 270, 270, 33, 270, 270, 270, 135, 135, 135, 135, 135, 135, 33, 270, 135, 270, 33, 270, 135, 33, 135, 33, 33, 135, 135, 135, 270, 135, 33, 33]
Prompts retrieved: 28032 . Total input tokens: 6152033 . Total output tokens: 5608060
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 1.1558256731368601,
    "estimated_duration": 3599.77870990067,
    "input_throughput": 641.225526905706,
    "output_throughput": 572.6449224032665,
    "total_throughput": 1213.8704493089726,
    "itl": 20.677193032603977,
    "ttft": 4987.512182577873,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7184,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.431322624587146,
    "arrivals": 9452,
    "finished_requests": 9439,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1558987810276449. Arrivals time: 0.03488941444084048 Scheduler time: 0.7077370597980917 Scheduler overhead time: 0.14599608583375812 Adapter cache time: 0.060153815895318985 Engine time: 0.13633341947570443 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-32/adapters_192_slots_32_rate_0.025-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-32/adapters_192_slots_32_rate_0.025-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [64 64 64]
Adapter prompts. [270, 33, 270, 33, 270, 33, 270, 33, 33, 33, 135, 135, 135, 135, 270, 135, 33, 270, 33, 135, 135, 33, 270, 270, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 270, 135, 33, 135, 270, 270, 135, 270, 33, 135, 135, 270, 135, 33, 33, 135, 270, 33, 135, 33, 270, 270, 135, 270, 270, 270, 33, 135, 270, 33, 135, 33, 135, 33, 33, 135, 270, 270, 33, 33, 33, 270, 270, 270, 135, 33, 33, 33, 33, 33, 270, 33, 135, 33, 270, 270, 33, 270, 33, 135, 135, 270, 33, 33, 33, 270, 270, 135, 270, 135, 270, 270, 135, 135, 33, 270, 135, 135, 135, 270, 135, 33, 135, 270, 270, 135, 270, 135, 33, 270, 135, 33, 135, 135, 33, 135, 270, 33, 135, 270, 33, 135, 270, 270, 135, 33, 270, 135, 33, 33, 135, 270, 270, 270, 33, 270, 33, 270, 33, 135, 33, 270, 270, 135, 270, 33, 270, 270, 270, 33, 270, 270, 270, 135, 135, 135, 135, 135, 135, 33, 270, 135, 270, 33, 270, 135, 33, 135, 33, 33, 135, 135, 135, 270, 135, 33, 33]
Prompts retrieved: 28032 . Total input tokens: 6152033 . Total output tokens: 5608060
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 1.170170514844358,
    "estimated_duration": 3599.774099992618,
    "input_throughput": 641.2263480657671,
    "output_throughput": 572.6456557382941,
    "total_throughput": 1213.872003804061,
    "itl": 20.685482601697526,
    "ttft": 4987.671466601476,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7185,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.70948977256093,
    "arrivals": 9452,
    "finished_requests": 9439,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1702539939433336. Arrivals time: 0.03590826177969575 Scheduler time: 0.7169248252175748 Scheduler overhead time: 0.14387729112058878 Adapter cache time: 0.06079837027937174 Engine time: 0.14230819093063474 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-16/adapters_192_slots_32_rate_0.025-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-16/adapters_192_slots_32_rate_0.025-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [64 64 64]
Adapter prompts. [270, 33, 270, 33, 270, 33, 270, 33, 33, 33, 135, 135, 135, 135, 270, 135, 33, 270, 33, 135, 135, 33, 270, 270, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 270, 135, 33, 135, 270, 270, 135, 270, 33, 135, 135, 270, 135, 33, 33, 135, 270, 33, 135, 33, 270, 270, 135, 270, 270, 270, 33, 135, 270, 33, 135, 33, 135, 33, 33, 135, 270, 270, 33, 33, 33, 270, 270, 270, 135, 33, 33, 33, 33, 33, 270, 33, 135, 33, 270, 270, 33, 270, 33, 135, 135, 270, 33, 33, 33, 270, 270, 135, 270, 135, 270, 270, 135, 135, 33, 270, 135, 135, 135, 270, 135, 33, 135, 270, 270, 135, 270, 135, 33, 270, 135, 33, 135, 135, 33, 135, 270, 33, 135, 270, 33, 135, 270, 270, 135, 33, 270, 135, 33, 33, 135, 270, 270, 270, 33, 270, 33, 270, 33, 135, 33, 270, 270, 135, 270, 33, 270, 270, 270, 33, 270, 270, 270, 135, 135, 135, 135, 135, 135, 33, 270, 135, 270, 33, 270, 135, 33, 135, 33, 33, 135, 135, 135, 270, 135, 33, 33]
Prompts retrieved: 28032 . Total input tokens: 6152033 . Total output tokens: 5608060
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 1.1621981263160706,
    "estimated_duration": 3599.769543336527,
    "input_throughput": 641.2271597421562,
    "output_throughput": 572.6463806039511,
    "total_throughput": 1213.8735403461073,
    "itl": 20.670277854846162,
    "ttft": 4987.631729881701,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7184,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.48052131857725,
    "arrivals": 9452,
    "finished_requests": 9439,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1622599973343313. Arrivals time: 0.03543479507789016 Scheduler time: 0.7134969998151064 Scheduler overhead time: 0.1423971806652844 Adapter cache time: 0.06106370594352484 Engine time: 0.13938873540610075 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-32/adapters_192_slots_32_rate_0.025-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-32/adapters_192_slots_32_rate_0.025-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [64 64 64]
Adapter prompts. [270, 33, 270, 33, 270, 33, 270, 33, 33, 33, 135, 135, 135, 135, 270, 135, 33, 270, 33, 135, 135, 33, 270, 270, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 270, 135, 33, 135, 270, 270, 135, 270, 33, 135, 135, 270, 135, 33, 33, 135, 270, 33, 135, 33, 270, 270, 135, 270, 270, 270, 33, 135, 270, 33, 135, 33, 135, 33, 33, 135, 270, 270, 33, 33, 33, 270, 270, 270, 135, 33, 33, 33, 33, 33, 270, 33, 135, 33, 270, 270, 33, 270, 33, 135, 135, 270, 33, 33, 33, 270, 270, 135, 270, 135, 270, 270, 135, 135, 33, 270, 135, 135, 135, 270, 135, 33, 135, 270, 270, 135, 270, 135, 33, 270, 135, 33, 135, 135, 33, 135, 270, 33, 135, 270, 33, 135, 270, 270, 135, 33, 270, 135, 33, 33, 135, 270, 270, 270, 33, 270, 33, 270, 33, 135, 33, 270, 270, 135, 270, 33, 270, 270, 270, 33, 270, 270, 270, 135, 135, 135, 135, 135, 135, 33, 270, 135, 270, 33, 270, 135, 33, 135, 33, 33, 135, 135, 135, 270, 135, 33, 33]
Prompts retrieved: 28032 . Total input tokens: 6152033 . Total output tokens: 5608060
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.1650079488754272,
    "estimated_duration": 3599.775539463131,
    "input_throughput": 641.226091653552,
    "output_throughput": 572.6454267499789,
    "total_throughput": 1213.871518403531,
    "itl": 20.689113355552887,
    "ttft": 4987.724207666961,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7182,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.99298827700122,
    "arrivals": 9452,
    "finished_requests": 9439,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1650747172534466. Arrivals time: 0.03543324116617441 Scheduler time: 0.7146221296861768 Scheduler overhead time: 0.14402223750948906 Adapter cache time: 0.060870468616485596 Engine time: 0.13961879489943385 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-8/adapters_192_slots_32_rate_0.025-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-8/adapters_192_slots_32_rate_0.025-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [64 64 64]
Adapter prompts. [270, 33, 270, 33, 270, 33, 270, 33, 33, 33, 66, 66, 66, 66, 270, 66, 33, 270, 33, 66, 66, 33, 270, 270, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 270, 66, 33, 66, 270, 270, 66, 270, 33, 66, 66, 270, 66, 33, 33, 66, 270, 33, 66, 33, 270, 270, 66, 270, 270, 270, 33, 66, 270, 33, 66, 33, 66, 33, 33, 66, 270, 270, 33, 33, 33, 270, 270, 270, 66, 33, 33, 33, 33, 33, 270, 33, 66, 33, 270, 270, 33, 270, 33, 66, 66, 270, 33, 33, 33, 270, 270, 66, 270, 66, 270, 270, 66, 66, 33, 270, 66, 66, 66, 270, 66, 33, 66, 270, 270, 66, 270, 66, 33, 270, 66, 33, 66, 66, 33, 66, 270, 33, 66, 270, 33, 66, 270, 270, 66, 33, 270, 66, 33, 33, 66, 270, 270, 270, 33, 270, 33, 270, 33, 66, 33, 270, 270, 66, 270, 33, 270, 270, 270, 33, 270, 270, 270, 66, 66, 66, 66, 66, 66, 33, 270, 66, 270, 33, 270, 66, 33, 66, 33, 33, 66, 66, 66, 270, 66, 33, 33]
Prompts retrieved: 23616 . Total input tokens: 5190960 . Total output tokens: 4735188
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 1.0868803220801055,
    "estimated_duration": 3598.801050418165,
    "input_throughput": 543.8152797506257,
    "output_throughput": 487.28256311813504,
    "total_throughput": 1031.0978428687608,
    "itl": 19.926394465202627,
    "ttft": 5403.569777249965,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5801,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.753889402552673,
    "arrivals": 8047,
    "finished_requests": 8035,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0869492958299816. Arrivals time: 0.03273102222010493 Scheduler time: 0.6387625313363969 Scheduler overhead time: 0.14556883415207267 Adapter cache time: 0.05421460326761007 Engine time: 0.14381786808371544 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-16/adapters_192_slots_32_rate_0.025-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-16/adapters_192_slots_32_rate_0.025-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [64 64 64]
Adapter prompts. [270, 33, 270, 33, 270, 33, 270, 33, 33, 33, 66, 66, 66, 66, 270, 66, 33, 270, 33, 66, 66, 33, 270, 270, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 270, 66, 33, 66, 270, 270, 66, 270, 33, 66, 66, 270, 66, 33, 33, 66, 270, 33, 66, 33, 270, 270, 66, 270, 270, 270, 33, 66, 270, 33, 66, 33, 66, 33, 33, 66, 270, 270, 33, 33, 33, 270, 270, 270, 66, 33, 33, 33, 33, 33, 270, 33, 66, 33, 270, 270, 33, 270, 33, 66, 66, 270, 33, 33, 33, 270, 270, 66, 270, 66, 270, 270, 66, 66, 33, 270, 66, 66, 66, 270, 66, 33, 66, 270, 270, 66, 270, 66, 33, 270, 66, 33, 66, 66, 33, 66, 270, 33, 66, 270, 33, 66, 270, 270, 66, 33, 270, 66, 33, 33, 66, 270, 270, 270, 33, 270, 33, 270, 33, 66, 33, 270, 270, 66, 270, 33, 270, 270, 270, 33, 270, 270, 270, 66, 66, 66, 66, 66, 66, 33, 270, 66, 270, 33, 270, 66, 33, 66, 33, 33, 66, 66, 66, 270, 66, 33, 33]
Prompts retrieved: 23616 . Total input tokens: 5190960 . Total output tokens: 4735188
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.077384137082845,
    "estimated_duration": 3598.8044119070423,
    "input_throughput": 543.8147717960927,
    "output_throughput": 487.2821079683884,
    "total_throughput": 1031.0968797644812,
    "itl": 19.93388559952604,
    "ttft": 5403.832168400472,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5804,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.90732271700404,
    "arrivals": 8047,
    "finished_requests": 8035,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0774383977986872. Arrivals time: 0.03243786981329322 Scheduler time: 0.6313373567536473 Scheduler overhead time: 0.14420659374445677 Adapter cache time: 0.05427869549021125 Engine time: 0.1429471354931593 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-32/adapters_192_slots_32_rate_0.025-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-32/adapters_192_slots_32_rate_0.025-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [64 64 64]
Adapter prompts. [270, 33, 270, 33, 270, 33, 270, 33, 33, 33, 66, 66, 66, 66, 270, 66, 33, 270, 33, 66, 66, 33, 270, 270, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 270, 66, 33, 66, 270, 270, 66, 270, 33, 66, 66, 270, 66, 33, 33, 66, 270, 33, 66, 33, 270, 270, 66, 270, 270, 270, 33, 66, 270, 33, 66, 33, 66, 33, 33, 66, 270, 270, 33, 33, 33, 270, 270, 270, 66, 33, 33, 33, 33, 33, 270, 33, 66, 33, 270, 270, 33, 270, 33, 66, 66, 270, 33, 33, 33, 270, 270, 66, 270, 66, 270, 270, 66, 66, 33, 270, 66, 66, 66, 270, 66, 33, 66, 270, 270, 66, 270, 66, 33, 270, 66, 33, 66, 66, 33, 66, 270, 33, 66, 270, 33, 66, 270, 270, 66, 33, 270, 66, 33, 33, 66, 270, 270, 270, 33, 270, 33, 270, 33, 66, 33, 270, 270, 66, 270, 33, 270, 270, 270, 33, 270, 270, 270, 66, 66, 66, 66, 66, 66, 33, 270, 66, 270, 33, 270, 66, 33, 66, 33, 33, 66, 66, 66, 270, 66, 33, 33]
Prompts retrieved: 23616 . Total input tokens: 5190960 . Total output tokens: 4735188
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.0781924529001117,
    "estimated_duration": 3598.80150287603,
    "input_throughput": 543.8152113796693,
    "output_throughput": 487.2825018547316,
    "total_throughput": 1031.097713234401,
    "itl": 19.93369424155972,
    "ttft": 5403.82359312996,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5803,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.943080358616115,
    "arrivals": 8047,
    "finished_requests": 8035,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0782794249244034. Arrivals time: 0.03300303686410189 Scheduler time: 0.6301481435075402 Scheduler overhead time: 0.14413827750831842 Adapter cache time: 0.05428803898394108 Engine time: 0.14498694753274322 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-16/adapters_192_slots_32_rate_0.025-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-16/adapters_192_slots_32_rate_0.025-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [64 64 64]
Adapter prompts. [270, 33, 270, 33, 270, 33, 270, 33, 33, 33, 66, 66, 66, 66, 270, 66, 33, 270, 33, 66, 66, 33, 270, 270, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 270, 66, 33, 66, 270, 270, 66, 270, 33, 66, 66, 270, 66, 33, 33, 66, 270, 33, 66, 33, 270, 270, 66, 270, 270, 270, 33, 66, 270, 33, 66, 33, 66, 33, 33, 66, 270, 270, 33, 33, 33, 270, 270, 270, 66, 33, 33, 33, 33, 33, 270, 33, 66, 33, 270, 270, 33, 270, 33, 66, 66, 270, 33, 33, 33, 270, 270, 66, 270, 66, 270, 270, 66, 66, 33, 270, 66, 66, 66, 270, 66, 33, 66, 270, 270, 66, 270, 66, 33, 270, 66, 33, 66, 66, 33, 66, 270, 33, 66, 270, 33, 66, 270, 270, 66, 33, 270, 66, 33, 33, 66, 270, 270, 270, 33, 270, 33, 270, 33, 66, 33, 270, 270, 66, 270, 33, 270, 270, 270, 33, 270, 270, 270, 66, 66, 66, 66, 66, 66, 33, 270, 66, 270, 33, 270, 66, 33, 66, 33, 33, 66, 66, 66, 270, 66, 33, 33]
Prompts retrieved: 23616 . Total input tokens: 5190960 . Total output tokens: 4735188
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 1.0730960848741233,
    "estimated_duration": 3598.8090880576633,
    "input_throughput": 543.814065184622,
    "output_throughput": 487.2814748132318,
    "total_throughput": 1031.0955399978538,
    "itl": 19.929003171555163,
    "ttft": 5403.614854157649,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5803,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.157420424600826,
    "arrivals": 8047,
    "finished_requests": 8035,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0731583926826715. Arrivals time: 0.03222193196415901 Scheduler time: 0.6271467451006174 Scheduler overhead time: 0.14576205145567656 Adapter cache time: 0.05444697057828307 Engine time: 0.14142267685383558 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-32/adapters_192_slots_32_rate_0.025-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-32/adapters_192_slots_32_rate_0.025-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [64 64 64]
Adapter prompts. [270, 33, 270, 33, 270, 33, 270, 33, 33, 33, 66, 66, 66, 66, 270, 66, 33, 270, 33, 66, 66, 33, 270, 270, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 270, 66, 33, 66, 270, 270, 66, 270, 33, 66, 66, 270, 66, 33, 33, 66, 270, 33, 66, 33, 270, 270, 66, 270, 270, 270, 33, 66, 270, 33, 66, 33, 66, 33, 33, 66, 270, 270, 33, 33, 33, 270, 270, 270, 66, 33, 33, 33, 33, 33, 270, 33, 66, 33, 270, 270, 33, 270, 33, 66, 66, 270, 33, 33, 33, 270, 270, 66, 270, 66, 270, 270, 66, 66, 33, 270, 66, 66, 66, 270, 66, 33, 66, 270, 270, 66, 270, 66, 33, 270, 66, 33, 66, 66, 33, 66, 270, 33, 66, 270, 33, 66, 270, 270, 66, 33, 270, 66, 33, 33, 66, 270, 270, 270, 33, 270, 33, 270, 33, 66, 33, 270, 270, 66, 270, 33, 270, 270, 270, 33, 270, 270, 270, 66, 66, 66, 66, 66, 66, 33, 270, 66, 270, 33, 270, 66, 33, 66, 33, 33, 66, 66, 66, 270, 66, 33, 33]
Prompts retrieved: 23616 . Total input tokens: 5190960 . Total output tokens: 4735188
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 1.0810963599942625,
    "estimated_duration": 3598.8074521031763,
    "input_throughput": 543.8143123929185,
    "output_throughput": 487.28169632280844,
    "total_throughput": 1031.096008715727,
    "itl": 19.935502640084035,
    "ttft": 5403.862934516607,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5803,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.1728325263958,
    "arrivals": 8047,
    "finished_requests": 8035,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0811695461161435. Arrivals time: 0.03308475064113736 Scheduler time: 0.6327039157040417 Scheduler overhead time: 0.1463686777278781 Adapter cache time: 0.053972999565303326 Engine time: 0.14303792174905539 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-16/adapters_192_slots_32_rate_0.025-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-16/adapters_192_slots_32_rate_0.025-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [64 64 64]
Adapter prompts. [270, 33, 270, 33, 270, 33, 270, 33, 33, 33, 66, 66, 66, 66, 270, 66, 33, 270, 33, 66, 66, 33, 270, 270, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 270, 66, 33, 66, 270, 270, 66, 270, 33, 66, 66, 270, 66, 33, 33, 66, 270, 33, 66, 33, 270, 270, 66, 270, 270, 270, 33, 66, 270, 33, 66, 33, 66, 33, 33, 66, 270, 270, 33, 33, 33, 270, 270, 270, 66, 33, 33, 33, 33, 33, 270, 33, 66, 33, 270, 270, 33, 270, 33, 66, 66, 270, 33, 33, 33, 270, 270, 66, 270, 66, 270, 270, 66, 66, 33, 270, 66, 66, 66, 270, 66, 33, 66, 270, 270, 66, 270, 66, 33, 270, 66, 33, 66, 66, 33, 66, 270, 33, 66, 270, 33, 66, 270, 270, 66, 33, 270, 66, 33, 33, 66, 270, 270, 270, 33, 270, 33, 270, 33, 66, 33, 270, 270, 66, 270, 33, 270, 270, 270, 33, 270, 270, 270, 66, 66, 66, 66, 66, 66, 33, 270, 66, 270, 33, 270, 66, 33, 66, 33, 33, 66, 66, 66, 270, 66, 33, 33]
Prompts retrieved: 23616 . Total input tokens: 5190960 . Total output tokens: 4735188
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 1.0715125533752143,
    "estimated_duration": 3598.799164530324,
    "input_throughput": 543.815564727524,
    "output_throughput": 487.2828184700507,
    "total_throughput": 1031.0983831975748,
    "itl": 19.92326272457524,
    "ttft": 5403.593303702586,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5804,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.35425191161362,
    "arrivals": 8047,
    "finished_requests": 8035,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0715921223163605. Arrivals time: 0.032468182034790516 Scheduler time: 0.6259831008501351 Scheduler overhead time: 0.14480842230841517 Adapter cache time: 0.053744157776236534 Engine time: 0.1429073540493846 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-32/adapters_192_slots_32_rate_0.025-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-32/adapters_192_slots_32_rate_0.025-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [64 64 64]
Adapter prompts. [270, 33, 270, 33, 270, 33, 270, 33, 33, 33, 66, 66, 66, 66, 270, 66, 33, 270, 33, 66, 66, 33, 270, 270, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 270, 66, 33, 66, 270, 270, 66, 270, 33, 66, 66, 270, 66, 33, 33, 66, 270, 33, 66, 33, 270, 270, 66, 270, 270, 270, 33, 66, 270, 33, 66, 33, 66, 33, 33, 66, 270, 270, 33, 33, 33, 270, 270, 270, 66, 33, 33, 33, 33, 33, 270, 33, 66, 33, 270, 270, 33, 270, 33, 66, 66, 270, 33, 33, 33, 270, 270, 66, 270, 66, 270, 270, 66, 66, 33, 270, 66, 66, 66, 270, 66, 33, 66, 270, 270, 66, 270, 66, 33, 270, 66, 33, 66, 66, 33, 66, 270, 33, 66, 270, 33, 66, 270, 270, 66, 33, 270, 66, 33, 33, 66, 270, 270, 270, 33, 270, 33, 270, 33, 66, 33, 270, 270, 66, 270, 33, 270, 270, 270, 33, 270, 270, 270, 66, 66, 66, 66, 66, 66, 33, 270, 66, 270, 33, 270, 66, 33, 66, 33, 33, 66, 66, 66, 270, 66, 33, 33]
Prompts retrieved: 23616 . Total input tokens: 5190960 . Total output tokens: 4735188
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.078148253262043,
    "estimated_duration": 3598.8111301968365,
    "input_throughput": 543.8137565982679,
    "output_throughput": 487.28119830619875,
    "total_throughput": 1031.0949549044667,
    "itl": 19.93770132140356,
    "ttft": 5403.966330840277,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5803,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.42094474699201,
    "arrivals": 8047,
    "finished_requests": 8035,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0781995942816138. Arrivals time: 0.03266301192343235 Scheduler time: 0.6302703050896525 Scheduler overhead time: 0.14605531189590693 Adapter cache time: 0.05380530096590519 Engine time: 0.1439480809494853 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-8/adapters_192_slots_32_rate_0.0125-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-8/adapters_192_slots_32_rate_0.0125-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [64 64 64]
Adapter prompts. [135, 33, 135, 33, 135, 33, 135, 33, 33, 33, 66, 66, 66, 66, 135, 66, 33, 135, 33, 66, 66, 33, 135, 135, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 135, 66, 33, 66, 135, 135, 66, 135, 33, 66, 66, 135, 66, 33, 33, 66, 135, 33, 66, 33, 135, 135, 66, 135, 135, 135, 33, 66, 135, 33, 66, 33, 66, 33, 33, 66, 135, 135, 33, 33, 33, 135, 135, 135, 66, 33, 33, 33, 33, 33, 135, 33, 66, 33, 135, 135, 33, 135, 33, 66, 66, 135, 33, 33, 33, 135, 135, 66, 135, 66, 135, 135, 66, 66, 33, 135, 66, 66, 66, 135, 66, 33, 66, 135, 135, 66, 135, 66, 33, 135, 66, 33, 66, 66, 33, 66, 135, 33, 66, 135, 33, 66, 135, 135, 66, 33, 135, 66, 33, 33, 66, 135, 135, 135, 33, 135, 33, 135, 33, 66, 33, 135, 135, 66, 135, 33, 135, 135, 135, 33, 135, 135, 135, 66, 66, 66, 66, 66, 66, 33, 135, 66, 135, 33, 135, 66, 33, 66, 33, 33, 66, 66, 66, 135, 66, 33, 33]
Prompts retrieved: 14976 . Total input tokens: 3282180 . Total output tokens: 3038664
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 0.8844628869555891,
    "estimated_duration": 3599.941385827334,
    "input_throughput": 340.32359660723716,
    "output_throughput": 312.1603602836825,
    "total_throughput": 652.4839568909197,
    "itl": 19.007627634763246,
    "ttft": 7822.835463468427,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3987,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.202164635059058,
    "arrivals": 5084,
    "finished_requests": 5073,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8845300506800413. Arrivals time: 0.02596809808164835 Scheduler time: 0.4451561514288187 Scheduler overhead time: 0.1495960927568376 Adapter cache time: 0.04327769624069333 Engine time: 0.14604305056855083 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-16/adapters_192_slots_32_rate_0.0125-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-16/adapters_192_slots_32_rate_0.0125-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [64 64 64]
Adapter prompts. [135, 33, 135, 33, 135, 33, 135, 33, 33, 33, 66, 66, 66, 66, 135, 66, 33, 135, 33, 66, 66, 33, 135, 135, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 135, 66, 33, 66, 135, 135, 66, 135, 33, 66, 66, 135, 66, 33, 33, 66, 135, 33, 66, 33, 135, 135, 66, 135, 135, 135, 33, 66, 135, 33, 66, 33, 66, 33, 33, 66, 135, 135, 33, 33, 33, 135, 135, 135, 66, 33, 33, 33, 33, 33, 135, 33, 66, 33, 135, 135, 33, 135, 33, 66, 66, 135, 33, 33, 33, 135, 135, 66, 135, 66, 135, 135, 66, 66, 33, 135, 66, 66, 66, 135, 66, 33, 66, 135, 135, 66, 135, 66, 33, 135, 66, 33, 66, 66, 33, 66, 135, 33, 66, 135, 33, 66, 135, 135, 66, 33, 135, 66, 33, 33, 66, 135, 135, 135, 33, 135, 33, 135, 33, 66, 33, 135, 135, 66, 135, 33, 135, 135, 135, 33, 135, 135, 135, 66, 66, 66, 66, 66, 66, 33, 135, 66, 135, 33, 135, 66, 33, 66, 33, 33, 66, 66, 66, 135, 66, 33, 33]
Prompts retrieved: 14976 . Total input tokens: 3282180 . Total output tokens: 3038664
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 0.8920125309377909,
    "estimated_duration": 3599.933124514318,
    "input_throughput": 340.32437759945594,
    "output_throughput": 312.1610766454477,
    "total_throughput": 652.4854542449036,
    "itl": 19.01102326715387,
    "ttft": 7823.008593525543,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3986,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.975785159604252,
    "arrivals": 5084,
    "finished_requests": 5073,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8920596963725984. Arrivals time: 0.02606264967471361 Scheduler time: 0.4515037131495774 Scheduler overhead time: 0.14833192946389318 Adapter cache time: 0.043562307953834534 Engine time: 0.1479393159970641 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-32/adapters_192_slots_32_rate_0.0125-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-32/adapters_192_slots_32_rate_0.0125-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [64 64 64]
Adapter prompts. [135, 33, 135, 33, 135, 33, 135, 33, 33, 33, 66, 66, 66, 66, 135, 66, 33, 135, 33, 66, 66, 33, 135, 135, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 135, 66, 33, 66, 135, 135, 66, 135, 33, 66, 66, 135, 66, 33, 33, 66, 135, 33, 66, 33, 135, 135, 66, 135, 135, 135, 33, 66, 135, 33, 66, 33, 66, 33, 33, 66, 135, 135, 33, 33, 33, 135, 135, 135, 66, 33, 33, 33, 33, 33, 135, 33, 66, 33, 135, 135, 33, 135, 33, 66, 66, 135, 33, 33, 33, 135, 135, 66, 135, 66, 135, 135, 66, 66, 33, 135, 66, 66, 66, 135, 66, 33, 66, 135, 135, 66, 135, 66, 33, 135, 66, 33, 66, 66, 33, 66, 135, 33, 66, 135, 33, 66, 135, 135, 66, 33, 135, 66, 33, 33, 66, 135, 135, 135, 33, 135, 33, 135, 33, 66, 33, 135, 135, 66, 135, 33, 135, 135, 135, 33, 135, 135, 135, 66, 66, 66, 66, 66, 66, 33, 135, 66, 135, 33, 135, 66, 33, 66, 33, 33, 66, 66, 66, 135, 66, 33, 33]
Prompts retrieved: 14976 . Total input tokens: 3282180 . Total output tokens: 3038664
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 0.8846780681051314,
    "estimated_duration": 3599.93456714124,
    "input_throughput": 340.3242412188912,
    "output_throughput": 312.1609515509592,
    "total_throughput": 652.4851927698504,
    "itl": 19.011415166054057,
    "ttft": 7822.916407967793,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3987,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.007643413375149,
    "arrivals": 5084,
    "finished_requests": 5073,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8847245741635561. Arrivals time: 0.025704536586999893 Scheduler time: 0.4467586618848145 Scheduler overhead time: 0.14807096496224403 Adapter cache time: 0.043205857276916504 Engine time: 0.14728216594085097 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-16/adapters_192_slots_32_rate_0.0125-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-16/adapters_192_slots_32_rate_0.0125-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [64 64 64]
Adapter prompts. [135, 33, 135, 33, 135, 33, 135, 33, 33, 33, 66, 66, 66, 66, 135, 66, 33, 135, 33, 66, 66, 33, 135, 135, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 135, 66, 33, 66, 135, 135, 66, 135, 33, 66, 66, 135, 66, 33, 33, 66, 135, 33, 66, 33, 135, 135, 66, 135, 135, 135, 33, 66, 135, 33, 66, 33, 66, 33, 33, 66, 135, 135, 33, 33, 33, 135, 135, 135, 66, 33, 33, 33, 33, 33, 135, 33, 66, 33, 135, 135, 33, 135, 33, 66, 66, 135, 33, 33, 33, 135, 135, 66, 135, 66, 135, 135, 66, 66, 33, 135, 66, 66, 66, 135, 66, 33, 66, 135, 135, 66, 135, 66, 33, 135, 66, 33, 66, 66, 33, 66, 135, 33, 66, 135, 33, 66, 135, 135, 66, 33, 135, 66, 33, 33, 66, 135, 135, 135, 33, 135, 33, 135, 33, 66, 33, 135, 135, 66, 135, 33, 135, 135, 135, 33, 135, 135, 135, 66, 66, 66, 66, 66, 66, 33, 135, 66, 135, 33, 135, 66, 33, 66, 33, 33, 66, 66, 66, 135, 66, 33, 33]
Prompts retrieved: 14976 . Total input tokens: 3282180 . Total output tokens: 3038664
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 0.893478665035218,
    "estimated_duration": 3599.9482431190477,
    "input_throughput": 340.32294834842304,
    "output_throughput": 312.1597656710639,
    "total_throughput": 652.4827140194869,
    "itl": 19.008854433766512,
    "ttft": 7822.873249867552,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3987,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.458224774206275,
    "arrivals": 5084,
    "finished_requests": 5073,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8935517352074385. Arrivals time: 0.026141296606510878 Scheduler time: 0.44868171121925116 Scheduler overhead time: 0.14790547545999289 Adapter cache time: 0.04337150789797306 Engine time: 0.1502412473782897 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-32/adapters_192_slots_32_rate_0.0125-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-32/adapters_192_slots_32_rate_0.0125-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [64 64 64]
Adapter prompts. [135, 33, 135, 33, 135, 33, 135, 33, 33, 33, 66, 66, 66, 66, 135, 66, 33, 135, 33, 66, 66, 33, 135, 135, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 135, 66, 33, 66, 135, 135, 66, 135, 33, 66, 66, 135, 66, 33, 33, 66, 135, 33, 66, 33, 135, 135, 66, 135, 135, 135, 33, 66, 135, 33, 66, 33, 66, 33, 33, 66, 135, 135, 33, 33, 33, 135, 135, 135, 66, 33, 33, 33, 33, 33, 135, 33, 66, 33, 135, 135, 33, 135, 33, 66, 66, 135, 33, 33, 33, 135, 135, 66, 135, 66, 135, 135, 66, 66, 33, 135, 66, 66, 66, 135, 66, 33, 66, 135, 135, 66, 135, 66, 33, 135, 66, 33, 66, 66, 33, 66, 135, 33, 66, 135, 33, 66, 135, 135, 66, 33, 135, 66, 33, 33, 66, 135, 135, 135, 33, 135, 33, 135, 33, 66, 33, 135, 135, 66, 135, 33, 135, 135, 135, 33, 135, 135, 135, 66, 66, 66, 66, 66, 66, 33, 135, 66, 135, 33, 135, 66, 33, 66, 33, 33, 66, 66, 66, 135, 66, 33, 33]
Prompts retrieved: 14976 . Total input tokens: 3282180 . Total output tokens: 3038664
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 0.8803208987228572,
    "estimated_duration": 3599.9440734537625,
    "input_throughput": 340.3233425303199,
    "output_throughput": 312.1601272327192,
    "total_throughput": 652.4834697630391,
    "itl": 19.012756614737693,
    "ttft": 7822.8011082012945,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3986,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.164598724710778,
    "arrivals": 5084,
    "finished_requests": 5073,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8803688106127083. Arrivals time: 0.02594413235783577 Scheduler time: 0.4428889942355454 Scheduler overhead time: 0.1476812157779932 Adapter cache time: 0.04316906398162246 Engine time: 0.1467187162488699 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-16/adapters_192_slots_32_rate_0.0125-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-16/adapters_192_slots_32_rate_0.0125-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [64 64 64]
Adapter prompts. [135, 33, 135, 33, 135, 33, 135, 33, 33, 33, 66, 66, 66, 66, 135, 66, 33, 135, 33, 66, 66, 33, 135, 135, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 135, 66, 33, 66, 135, 135, 66, 135, 33, 66, 66, 135, 66, 33, 33, 66, 135, 33, 66, 33, 135, 135, 66, 135, 135, 135, 33, 66, 135, 33, 66, 33, 66, 33, 33, 66, 135, 135, 33, 33, 33, 135, 135, 135, 66, 33, 33, 33, 33, 33, 135, 33, 66, 33, 135, 135, 33, 135, 33, 66, 66, 135, 33, 33, 33, 135, 135, 66, 135, 66, 135, 135, 66, 66, 33, 135, 66, 66, 66, 135, 66, 33, 66, 135, 135, 66, 135, 66, 33, 135, 66, 33, 66, 66, 33, 66, 135, 33, 66, 135, 33, 66, 135, 135, 66, 33, 135, 66, 33, 33, 66, 135, 135, 135, 33, 135, 33, 135, 33, 66, 33, 135, 135, 66, 135, 33, 135, 135, 135, 33, 135, 135, 135, 66, 66, 66, 66, 66, 66, 33, 135, 66, 135, 33, 135, 66, 33, 66, 33, 33, 66, 66, 66, 135, 66, 33, 33]
Prompts retrieved: 14976 . Total input tokens: 3282180 . Total output tokens: 3038664
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 0.8827597065828741,
    "estimated_duration": 3599.9493487108257,
    "input_throughput": 340.322843830771,
    "output_throughput": 312.1596698026955,
    "total_throughput": 652.4825136334664,
    "itl": 19.002469712534243,
    "ttft": 7822.617074121195,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3987,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.921330525775751,
    "arrivals": 5084,
    "finished_requests": 5073,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8828743286430836. Arrivals time: 0.025575515814125538 Scheduler time: 0.44413779210299253 Scheduler overhead time: 0.14834203897044063 Adapter cache time: 0.043023505713790655 Engine time: 0.1472950465977192 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-32/adapters_192_slots_32_rate_0.0125-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-32/adapters_192_slots_32_rate_0.0125-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [64 64 64]
Adapter prompts. [135, 33, 135, 33, 135, 33, 135, 33, 33, 33, 66, 66, 66, 66, 135, 66, 33, 135, 33, 66, 66, 33, 135, 135, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 135, 66, 33, 66, 135, 135, 66, 135, 33, 66, 66, 135, 66, 33, 33, 66, 135, 33, 66, 33, 135, 135, 66, 135, 135, 135, 33, 66, 135, 33, 66, 33, 66, 33, 33, 66, 135, 135, 33, 33, 33, 135, 135, 135, 66, 33, 33, 33, 33, 33, 135, 33, 66, 33, 135, 135, 33, 135, 33, 66, 66, 135, 33, 33, 33, 135, 135, 66, 135, 66, 135, 135, 66, 66, 33, 135, 66, 66, 66, 135, 66, 33, 66, 135, 135, 66, 135, 66, 33, 135, 66, 33, 66, 66, 33, 66, 135, 33, 66, 135, 33, 66, 135, 135, 66, 33, 135, 66, 33, 33, 66, 135, 135, 135, 33, 135, 33, 135, 33, 66, 33, 135, 135, 66, 135, 33, 135, 135, 135, 33, 135, 135, 135, 66, 66, 66, 66, 66, 66, 33, 135, 66, 135, 33, 135, 66, 33, 66, 33, 33, 66, 66, 66, 135, 66, 33, 33]
Prompts retrieved: 14976 . Total input tokens: 3282180 . Total output tokens: 3038664
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 0.8848349670879543,
    "estimated_duration": 3599.9292532310033,
    "input_throughput": 340.3247435766716,
    "output_throughput": 312.16141233648005,
    "total_throughput": 652.4861559131516,
    "itl": 19.01124922225537,
    "ttft": 7822.993740675933,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3986,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.329713446273528,
    "arrivals": 5084,
    "finished_requests": 5073,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8849492338486016. Arrivals time: 0.02564012771472335 Scheduler time: 0.4463899964466691 Scheduler overhead time: 0.15041661402210593 Adapter cache time: 0.04309389600530267 Engine time: 0.1449591564014554 
