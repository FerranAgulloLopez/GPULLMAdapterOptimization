INFO 06-01 00:47:19 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:47:20 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-8/adapters_384_slots_64_rate_3.2-0.8-0.4_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-8/adapters_384_slots_64_rate_3.2-0.8-0.4_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [128 128 128]
Adapter prompts. [4320, 4320, 34560, 8640, 4320, 34560, 34560, 4320, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 4320, 34560, 4320, 34560, 8640, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 4320, 34560, 8640, 34560, 8640, 4320, 8640, 34560, 8640, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 8640, 8640, 8640, 34560, 8640, 4320, 8640, 4320, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 4320, 4320, 34560, 8640, 8640, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 4320, 34560, 34560, 34560, 34560, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 4320, 34560, 8640, 8640, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 8640, 8640, 34560, 4320, 4320, 34560, 4320, 34560, 8640, 4320, 34560, 8640, 8640, 4320, 34560, 34560, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 8640, 34560, 34560, 4320, 8640, 34560, 4320, 8640, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 34560, 4320, 34560, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 34560, 4320, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 4320, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 4320, 34560, 4320, 4320, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 34560, 4320, 34560, 34560, 4320, 8640, 34560, 4320, 4320, 8640, 8640, 4320, 4320, 34560, 34560, 34560, 34560, 8640, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 34560, 8640, 8640, 8640, 34560, 4320, 8640, 8640, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 4320, 4320, 8640, 4320, 34560, 34560, 34560, 8640, 4320, 34560, 34560, 8640, 8640, 34560, 34560, 4320, 34560, 34560, 8640, 4320, 34560, 8640, 8640, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 34560, 4320, 8640, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 4320, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 8640, 34560, 8640, 8640, 8640, 4320, 8640, 4320, 4320, 34560, 4320, 8640, 4320, 4320, 8640, 34560, 8640, 34560, 4320, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 6082560 . Total input tokens: 1354711576 . Total output tokens: 1216423649
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 83.25599990505725,
    "estimated_duration": 3600.10668648729,
    "input_throughput": 6147.287546523694,
    "output_throughput": 5465.322478873006,
    "total_throughput": 11612.6100253967,
    "itl": 152.71921953706692,
    "ttft": 2117837.5816670116,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 614,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.87913947477474,
    "arrivals": 2026382,
    "finished_requests": 89802,
    "scheduler_time": 176.1047162608793
}
#Debug simulation 
Total elapsed time: 83.25622937409207. Arrivals time: 0.5046873702667654 Scheduler time: 82.59220153559 Scheduler overhead time: 0.06012033484876156 Adapter cache time: 0.018852298613637686 Engine time: 0.057338365353643894 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-16/adapters_384_slots_64_rate_3.2-0.8-0.4_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-16/adapters_384_slots_64_rate_3.2-0.8-0.4_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [128 128 128]
Adapter prompts. [4320, 4320, 34560, 8640, 4320, 34560, 34560, 4320, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 4320, 34560, 4320, 34560, 8640, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 4320, 34560, 8640, 34560, 8640, 4320, 8640, 34560, 8640, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 8640, 8640, 8640, 34560, 8640, 4320, 8640, 4320, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 4320, 4320, 34560, 8640, 8640, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 4320, 34560, 34560, 34560, 34560, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 4320, 34560, 8640, 8640, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 8640, 8640, 34560, 4320, 4320, 34560, 4320, 34560, 8640, 4320, 34560, 8640, 8640, 4320, 34560, 34560, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 8640, 34560, 34560, 4320, 8640, 34560, 4320, 8640, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 34560, 4320, 34560, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 34560, 4320, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 4320, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 4320, 34560, 4320, 4320, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 34560, 4320, 34560, 34560, 4320, 8640, 34560, 4320, 4320, 8640, 8640, 4320, 4320, 34560, 34560, 34560, 34560, 8640, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 34560, 8640, 8640, 8640, 34560, 4320, 8640, 8640, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 4320, 4320, 8640, 4320, 34560, 34560, 34560, 8640, 4320, 34560, 34560, 8640, 8640, 34560, 34560, 4320, 34560, 34560, 8640, 4320, 34560, 8640, 8640, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 34560, 4320, 8640, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 4320, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 8640, 34560, 8640, 8640, 8640, 4320, 8640, 4320, 4320, 34560, 4320, 8640, 4320, 4320, 8640, 34560, 8640, 34560, 4320, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 6082560 . Total input tokens: 1354711576 . Total output tokens: 1216423649
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 83.08679470000789,
    "estimated_duration": 3600.1373508023535,
    "input_throughput": 6146.044954387282,
    "output_throughput": 5467.388347173261,
    "total_throughput": 11613.433301560543,
    "itl": 153.1808414579936,
    "ttft": 2117868.7024061666,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 640,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.090145366303628,
    "arrivals": 2026382,
    "finished_requests": 89815,
    "scheduler_time": 175.73846009998934
}
#Debug simulation 
Total elapsed time: 83.08699901308864. Arrivals time: 0.4980645077303052 Scheduler time: 82.42885925108567 Scheduler overhead time: 0.06085621193051338 Adapter cache time: 0.01946279965341091 Engine time: 0.05772113939747214 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-32/adapters_384_slots_64_rate_3.2-0.8-0.4_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-32/adapters_384_slots_64_rate_3.2-0.8-0.4_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [128 128 128]
Adapter prompts. [4320, 4320, 34560, 8640, 4320, 34560, 34560, 4320, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 4320, 34560, 4320, 34560, 8640, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 4320, 34560, 8640, 34560, 8640, 4320, 8640, 34560, 8640, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 8640, 8640, 8640, 34560, 8640, 4320, 8640, 4320, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 4320, 4320, 34560, 8640, 8640, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 4320, 34560, 34560, 34560, 34560, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 4320, 34560, 8640, 8640, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 8640, 8640, 34560, 4320, 4320, 34560, 4320, 34560, 8640, 4320, 34560, 8640, 8640, 4320, 34560, 34560, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 8640, 34560, 34560, 4320, 8640, 34560, 4320, 8640, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 34560, 4320, 34560, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 34560, 4320, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 4320, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 4320, 34560, 4320, 4320, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 34560, 4320, 34560, 34560, 4320, 8640, 34560, 4320, 4320, 8640, 8640, 4320, 4320, 34560, 34560, 34560, 34560, 8640, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 34560, 8640, 8640, 8640, 34560, 4320, 8640, 8640, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 4320, 4320, 8640, 4320, 34560, 34560, 34560, 8640, 4320, 34560, 34560, 8640, 8640, 34560, 34560, 4320, 34560, 34560, 8640, 4320, 34560, 8640, 8640, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 34560, 4320, 8640, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 4320, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 8640, 34560, 8640, 8640, 8640, 4320, 8640, 4320, 4320, 34560, 4320, 8640, 4320, 4320, 8640, 34560, 8640, 34560, 4320, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 6082560 . Total input tokens: 1354711576 . Total output tokens: 1216423649
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 82.85010391101241,
    "estimated_duration": 3600.1407562659697,
    "input_throughput": 6146.039140688904,
    "output_throughput": 5467.383175433222,
    "total_throughput": 11613.422316122125,
    "itl": 153.18097181502563,
    "ttft": 2117870.04736103,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 640,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.093542980849752,
    "arrivals": 2026382,
    "finished_requests": 89815,
    "scheduler_time": 175.73846794903676
}
#Debug simulation 
Total elapsed time: 82.85027538239956. Arrivals time: 0.5095084486529231 Scheduler time: 82.18027144437656 Scheduler overhead time: 0.061568901408463717 Adapter cache time: 0.019304831512272358 Engine time: 0.05742703564465046 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-16-16/adapters_384_slots_64_rate_3.2-0.8-0.4_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-16-16/adapters_384_slots_64_rate_3.2-0.8-0.4_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [128 128 128]
Adapter prompts. [4320, 4320, 34560, 8640, 4320, 34560, 34560, 4320, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 4320, 34560, 4320, 34560, 8640, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 4320, 34560, 8640, 34560, 8640, 4320, 8640, 34560, 8640, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 8640, 8640, 8640, 34560, 8640, 4320, 8640, 4320, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 4320, 4320, 34560, 8640, 8640, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 4320, 34560, 34560, 34560, 34560, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 4320, 34560, 8640, 8640, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 8640, 8640, 34560, 4320, 4320, 34560, 4320, 34560, 8640, 4320, 34560, 8640, 8640, 4320, 34560, 34560, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 8640, 34560, 34560, 4320, 8640, 34560, 4320, 8640, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 34560, 4320, 34560, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 34560, 4320, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 4320, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 4320, 34560, 4320, 4320, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 34560, 4320, 34560, 34560, 4320, 8640, 34560, 4320, 4320, 8640, 8640, 4320, 4320, 34560, 34560, 34560, 34560, 8640, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 34560, 8640, 8640, 8640, 34560, 4320, 8640, 8640, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 4320, 4320, 8640, 4320, 34560, 34560, 34560, 8640, 4320, 34560, 34560, 8640, 8640, 34560, 34560, 4320, 34560, 34560, 8640, 4320, 34560, 8640, 8640, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 34560, 4320, 8640, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 4320, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 8640, 34560, 8640, 8640, 8640, 4320, 8640, 4320, 4320, 34560, 4320, 8640, 4320, 4320, 8640, 34560, 8640, 34560, 4320, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 6082560 . Total input tokens: 1354711576 . Total output tokens: 1216423649
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 83.4281871560961,
    "estimated_duration": 3600.04743581735,
    "input_throughput": 6146.198458347925,
    "output_throughput": 5467.524900968733,
    "total_throughput": 11613.723359316658,
    "itl": 153.1774442033526,
    "ttft": 2117830.3168631727,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 640,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.000662991565172,
    "arrivals": 2026382,
    "finished_requests": 89815,
    "scheduler_time": 175.73802748970053
}
#Debug simulation 
Total elapsed time: 83.42836026614532. Arrivals time: 0.5264163394458592 Scheduler time: 82.74052865803242 Scheduler overhead time: 0.06188608193770051 Adapter cache time: 0.019892108626663685 Engine time: 0.0576349962502718 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-16-32/adapters_384_slots_64_rate_3.2-0.8-0.4_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-16-32/adapters_384_slots_64_rate_3.2-0.8-0.4_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [128 128 128]
Adapter prompts. [4320, 4320, 34560, 8640, 4320, 34560, 34560, 4320, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 4320, 34560, 4320, 34560, 8640, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 4320, 34560, 8640, 34560, 8640, 4320, 8640, 34560, 8640, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 8640, 8640, 8640, 34560, 8640, 4320, 8640, 4320, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 4320, 4320, 34560, 8640, 8640, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 4320, 34560, 34560, 34560, 34560, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 4320, 34560, 8640, 8640, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 8640, 8640, 34560, 4320, 4320, 34560, 4320, 34560, 8640, 4320, 34560, 8640, 8640, 4320, 34560, 34560, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 8640, 34560, 34560, 4320, 8640, 34560, 4320, 8640, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 34560, 4320, 34560, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 34560, 4320, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 4320, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 4320, 34560, 4320, 4320, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 34560, 4320, 34560, 34560, 4320, 8640, 34560, 4320, 4320, 8640, 8640, 4320, 4320, 34560, 34560, 34560, 34560, 8640, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 34560, 8640, 8640, 8640, 34560, 4320, 8640, 8640, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 4320, 4320, 8640, 4320, 34560, 34560, 34560, 8640, 4320, 34560, 34560, 8640, 8640, 34560, 34560, 4320, 34560, 34560, 8640, 4320, 34560, 8640, 8640, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 34560, 4320, 8640, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 4320, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 8640, 34560, 8640, 8640, 8640, 4320, 8640, 4320, 4320, 34560, 4320, 8640, 4320, 4320, 8640, 34560, 8640, 34560, 4320, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 6082560 . Total input tokens: 1354711576 . Total output tokens: 1216423649
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 83.0302667520009,
    "estimated_duration": 3600.1684272234756,
    "input_throughput": 6145.991902124561,
    "output_throughput": 5467.3411530305,
    "total_throughput": 11613.333055155063,
    "itl": 153.18201734427817,
    "ttft": 2117881.859579062,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 640,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1210830600746,
    "arrivals": 2026382,
    "finished_requests": 89815,
    "scheduler_time": 175.73859882733933
}
#Debug simulation 
Total elapsed time: 83.03044107928872. Arrivals time: 0.5193537985906005 Scheduler time: 82.35026744194329 Scheduler overhead time: 0.06140336440876126 Adapter cache time: 0.019351848866790533 Engine time: 0.057691365480422974 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_16-16-16/adapters_384_slots_64_rate_3.2-0.8-0.4_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_16-16-16/adapters_384_slots_64_rate_3.2-0.8-0.4_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [128 128 128]
Adapter prompts. [4320, 4320, 34560, 8640, 4320, 34560, 34560, 4320, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 4320, 34560, 4320, 34560, 8640, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 4320, 34560, 8640, 34560, 8640, 4320, 8640, 34560, 8640, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 8640, 8640, 8640, 34560, 8640, 4320, 8640, 4320, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 4320, 4320, 34560, 8640, 8640, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 4320, 34560, 34560, 34560, 34560, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 4320, 34560, 8640, 8640, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 8640, 8640, 34560, 4320, 4320, 34560, 4320, 34560, 8640, 4320, 34560, 8640, 8640, 4320, 34560, 34560, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 8640, 34560, 34560, 4320, 8640, 34560, 4320, 8640, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 34560, 4320, 34560, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 34560, 4320, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 4320, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 4320, 34560, 4320, 4320, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 34560, 4320, 34560, 34560, 4320, 8640, 34560, 4320, 4320, 8640, 8640, 4320, 4320, 34560, 34560, 34560, 34560, 8640, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 34560, 8640, 8640, 8640, 34560, 4320, 8640, 8640, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 4320, 4320, 8640, 4320, 34560, 34560, 34560, 8640, 4320, 34560, 34560, 8640, 8640, 34560, 34560, 4320, 34560, 34560, 8640, 4320, 34560, 8640, 8640, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 34560, 4320, 8640, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 4320, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 8640, 34560, 8640, 8640, 8640, 4320, 8640, 4320, 4320, 34560, 4320, 8640, 4320, 4320, 8640, 34560, 8640, 34560, 4320, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 6082560 . Total input tokens: 1354711576 . Total output tokens: 1216423649
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 84.02913343766704,
    "estimated_duration": 3600.063232175616,
    "input_throughput": 6147.361746928456,
    "output_throughput": 5465.388447666074,
    "total_throughput": 11612.75019459453,
    "itl": 152.71760089250284,
    "ttft": 2117818.8017295087,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 614,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8358908810699075,
    "arrivals": 2026382,
    "finished_requests": 89802,
    "scheduler_time": 176.1045105428221
}
#Debug simulation 
Total elapsed time: 84.02930900175124. Arrivals time: 0.9759359695017338 Scheduler time: 82.89355968730524 Scheduler overhead time: 0.06083714170381427 Adapter cache time: 0.019463186617940664 Engine time: 0.057521110866218805 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_16-16-32/adapters_384_slots_64_rate_3.2-0.8-0.4_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_16-16-32/adapters_384_slots_64_rate_3.2-0.8-0.4_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [128 128 128]
Adapter prompts. [4320, 4320, 34560, 8640, 4320, 34560, 34560, 4320, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 4320, 34560, 4320, 34560, 8640, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 4320, 34560, 8640, 34560, 8640, 4320, 8640, 34560, 8640, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 8640, 8640, 8640, 34560, 8640, 4320, 8640, 4320, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 4320, 4320, 34560, 8640, 8640, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 4320, 34560, 34560, 34560, 34560, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 4320, 34560, 8640, 8640, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 8640, 8640, 34560, 4320, 4320, 34560, 4320, 34560, 8640, 4320, 34560, 8640, 8640, 4320, 34560, 34560, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 8640, 34560, 34560, 4320, 8640, 34560, 4320, 8640, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 34560, 4320, 34560, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 34560, 4320, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 4320, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 4320, 34560, 4320, 4320, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 34560, 4320, 34560, 34560, 4320, 8640, 34560, 4320, 4320, 8640, 8640, 4320, 4320, 34560, 34560, 34560, 34560, 8640, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 34560, 8640, 8640, 8640, 34560, 4320, 8640, 8640, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 4320, 4320, 8640, 4320, 34560, 34560, 34560, 8640, 4320, 34560, 34560, 8640, 8640, 34560, 34560, 4320, 34560, 34560, 8640, 4320, 34560, 8640, 8640, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 34560, 4320, 8640, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 4320, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 8640, 34560, 8640, 8640, 8640, 4320, 8640, 4320, 4320, 34560, 4320, 8640, 4320, 4320, 8640, 34560, 8640, 34560, 4320, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 6082560 . Total input tokens: 1354711576 . Total output tokens: 1216423649
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 83.44924482423812,
    "estimated_duration": 3600.0199779638156,
    "input_throughput": 6145.725339144876,
    "output_throughput": 5467.209660078677,
    "total_throughput": 11612.934999223553,
    "itl": 153.1825701141972,
    "ttft": 2117879.2865500785,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 640,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.147868616580963,
    "arrivals": 2026382,
    "finished_requests": 89809,
    "scheduler_time": 175.73029820765723
}
#Debug simulation 
Total elapsed time: 83.44942643633112. Arrivals time: 0.5325650740414858 Scheduler time: 82.75556669337675 Scheduler overhead time: 0.06198966596275568 Adapter cache time: 0.01951731415465474 Engine time: 0.05789094092324376 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-8/adapters_384_slots_64_rate_3.2-0.8-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-8/adapters_384_slots_64_rate_3.2-0.8-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 34560, 8640, 1080, 34560, 34560, 1080, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 1080, 34560, 1080, 34560, 8640, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 1080, 34560, 8640, 34560, 8640, 1080, 8640, 34560, 8640, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 8640, 8640, 8640, 34560, 8640, 1080, 8640, 1080, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 1080, 1080, 34560, 8640, 8640, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 1080, 34560, 34560, 34560, 34560, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 1080, 34560, 8640, 8640, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 8640, 8640, 34560, 1080, 1080, 34560, 1080, 34560, 8640, 1080, 34560, 8640, 8640, 1080, 34560, 34560, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 8640, 34560, 34560, 1080, 8640, 34560, 1080, 8640, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 34560, 1080, 34560, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 34560, 1080, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 1080, 34560, 1080, 1080, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 34560, 1080, 34560, 34560, 1080, 8640, 34560, 1080, 1080, 8640, 8640, 1080, 1080, 34560, 34560, 34560, 34560, 8640, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 34560, 8640, 8640, 8640, 34560, 1080, 8640, 8640, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 1080, 1080, 8640, 1080, 34560, 34560, 34560, 8640, 1080, 34560, 34560, 8640, 8640, 34560, 34560, 1080, 34560, 34560, 8640, 1080, 34560, 8640, 8640, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 34560, 1080, 8640, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 1080, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 8640, 34560, 8640, 8640, 8640, 1080, 8640, 1080, 1080, 34560, 1080, 8640, 1080, 1080, 8640, 34560, 8640, 34560, 1080, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5667840 . Total input tokens: 1262484234 . Total output tokens: 1133400767
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 81.15167723130435,
    "estimated_duration": 3600.0082546919516,
    "input_throughput": 6195.475793959952,
    "output_throughput": 5487.247140129221,
    "total_throughput": 11682.722934089174,
    "itl": 153.81674560796924,
    "ttft": 2114048.79585334,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 631,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9311677664215987,
    "arrivals": 1888011,
    "finished_requests": 90197,
    "scheduler_time": 174.9096978261801
}
#Debug simulation 
Total elapsed time: 81.15184601023793. Arrivals time: 0.5253364951349795 Scheduler time: 80.46790159121156 Scheduler overhead time: 0.060611043125391006 Adapter cache time: 0.018983935937285423 Engine time: 0.057025998365134 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-16/adapters_384_slots_64_rate_3.2-0.8-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-16/adapters_384_slots_64_rate_3.2-0.8-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 34560, 8640, 1080, 34560, 34560, 1080, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 1080, 34560, 1080, 34560, 8640, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 1080, 34560, 8640, 34560, 8640, 1080, 8640, 34560, 8640, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 8640, 8640, 8640, 34560, 8640, 1080, 8640, 1080, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 1080, 1080, 34560, 8640, 8640, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 1080, 34560, 34560, 34560, 34560, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 1080, 34560, 8640, 8640, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 8640, 8640, 34560, 1080, 1080, 34560, 1080, 34560, 8640, 1080, 34560, 8640, 8640, 1080, 34560, 34560, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 8640, 34560, 34560, 1080, 8640, 34560, 1080, 8640, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 34560, 1080, 34560, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 34560, 1080, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 1080, 34560, 1080, 1080, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 34560, 1080, 34560, 34560, 1080, 8640, 34560, 1080, 1080, 8640, 8640, 1080, 1080, 34560, 34560, 34560, 34560, 8640, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 34560, 8640, 8640, 8640, 34560, 1080, 8640, 8640, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 1080, 1080, 8640, 1080, 34560, 34560, 34560, 8640, 1080, 34560, 34560, 8640, 8640, 34560, 34560, 1080, 34560, 34560, 8640, 1080, 34560, 8640, 8640, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 34560, 1080, 8640, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 1080, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 8640, 34560, 8640, 8640, 8640, 1080, 8640, 1080, 1080, 34560, 1080, 8640, 1080, 1080, 8640, 34560, 8640, 34560, 1080, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5667840 . Total input tokens: 1262484234 . Total output tokens: 1133400767
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 80.9394876868464,
    "estimated_duration": 3600.056330067319,
    "input_throughput": 6179.983022538975,
    "output_throughput": 5474.060457168317,
    "total_throughput": 11654.043479707292,
    "itl": 153.22513661185744,
    "ttft": 2114442.1480658646,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 642,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.094491085619671,
    "arrivals": 1888011,
    "finished_requests": 89982,
    "scheduler_time": 175.58894316689015
}
#Debug simulation 
Total elapsed time: 80.93965716287494. Arrivals time: 0.6493366230279207 Scheduler time: 80.13238472072408 Scheduler overhead time: 0.05952402902767062 Adapter cache time: 0.019279371481388807 Engine time: 0.05748498998582363 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-32/adapters_384_slots_64_rate_3.2-0.8-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-32/adapters_384_slots_64_rate_3.2-0.8-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 34560, 8640, 1080, 34560, 34560, 1080, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 1080, 34560, 1080, 34560, 8640, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 1080, 34560, 8640, 34560, 8640, 1080, 8640, 34560, 8640, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 8640, 8640, 8640, 34560, 8640, 1080, 8640, 1080, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 1080, 1080, 34560, 8640, 8640, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 1080, 34560, 34560, 34560, 34560, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 1080, 34560, 8640, 8640, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 8640, 8640, 34560, 1080, 1080, 34560, 1080, 34560, 8640, 1080, 34560, 8640, 8640, 1080, 34560, 34560, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 8640, 34560, 34560, 1080, 8640, 34560, 1080, 8640, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 34560, 1080, 34560, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 34560, 1080, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 1080, 34560, 1080, 1080, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 34560, 1080, 34560, 34560, 1080, 8640, 34560, 1080, 1080, 8640, 8640, 1080, 1080, 34560, 34560, 34560, 34560, 8640, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 34560, 8640, 8640, 8640, 34560, 1080, 8640, 8640, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 1080, 1080, 8640, 1080, 34560, 34560, 34560, 8640, 1080, 34560, 34560, 8640, 8640, 34560, 34560, 1080, 34560, 34560, 8640, 1080, 34560, 8640, 8640, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 34560, 1080, 8640, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 1080, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 8640, 34560, 8640, 8640, 8640, 1080, 8640, 1080, 1080, 34560, 1080, 8640, 1080, 1080, 8640, 34560, 8640, 34560, 1080, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5667840 . Total input tokens: 1262484234 . Total output tokens: 1133400767
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 81.98601859761402,
    "estimated_duration": 3600.0601289545643,
    "input_throughput": 6179.976501242708,
    "output_throughput": 5474.054680781894,
    "total_throughput": 11654.0311820246,
    "itl": 153.2252844208373,
    "ttft": 2114443.5078842645,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 642,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.098281028568754,
    "arrivals": 1888011,
    "finished_requests": 89982,
    "scheduler_time": 175.5889521111535
}
#Debug simulation 
Total elapsed time: 81.98618838889524. Arrivals time: 0.516433831769973 Scheduler time: 81.31077163340524 Scheduler overhead time: 0.06035738764330745 Adapter cache time: 0.019225445576012135 Engine time: 0.05759784206748009 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-16-16/adapters_384_slots_64_rate_3.2-0.8-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-16-16/adapters_384_slots_64_rate_3.2-0.8-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 34560, 8640, 1080, 34560, 34560, 1080, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 1080, 34560, 1080, 34560, 8640, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 1080, 34560, 8640, 34560, 8640, 1080, 8640, 34560, 8640, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 8640, 8640, 8640, 34560, 8640, 1080, 8640, 1080, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 1080, 1080, 34560, 8640, 8640, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 1080, 34560, 34560, 34560, 34560, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 1080, 34560, 8640, 8640, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 8640, 8640, 34560, 1080, 1080, 34560, 1080, 34560, 8640, 1080, 34560, 8640, 8640, 1080, 34560, 34560, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 8640, 34560, 34560, 1080, 8640, 34560, 1080, 8640, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 34560, 1080, 34560, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 34560, 1080, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 1080, 34560, 1080, 1080, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 34560, 1080, 34560, 34560, 1080, 8640, 34560, 1080, 1080, 8640, 8640, 1080, 1080, 34560, 34560, 34560, 34560, 8640, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 34560, 8640, 8640, 8640, 34560, 1080, 8640, 8640, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 1080, 1080, 8640, 1080, 34560, 34560, 34560, 8640, 1080, 34560, 34560, 8640, 8640, 34560, 34560, 1080, 34560, 34560, 8640, 1080, 34560, 8640, 8640, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 34560, 1080, 8640, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 1080, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 8640, 34560, 8640, 8640, 8640, 1080, 8640, 1080, 1080, 34560, 1080, 8640, 1080, 1080, 8640, 34560, 8640, 34560, 1080, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5667840 . Total input tokens: 1262484234 . Total output tokens: 1133400767
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 81.6047662626952,
    "estimated_duration": 3600.049753318587,
    "input_throughput": 6195.40437724229,
    "output_throughput": 5487.183887331085,
    "total_throughput": 11682.588264573375,
    "itl": 153.81836938286418,
    "ttft": 2114064.96348031,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 631,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9725267529557324,
    "arrivals": 1888011,
    "finished_requests": 90197,
    "scheduler_time": 174.90983746621004
}
#Debug simulation 
Total elapsed time: 81.6049483595416. Arrivals time: 0.987778456415981 Scheduler time: 80.4597974899225 Scheduler overhead time: 0.060204587411135435 Adapter cache time: 0.019044727087020874 Engine time: 0.05637090699747205 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-16-32/adapters_384_slots_64_rate_3.2-0.8-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-16-32/adapters_384_slots_64_rate_3.2-0.8-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 34560, 8640, 1080, 34560, 34560, 1080, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 1080, 34560, 1080, 34560, 8640, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 1080, 34560, 8640, 34560, 8640, 1080, 8640, 34560, 8640, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 8640, 8640, 8640, 34560, 8640, 1080, 8640, 1080, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 1080, 1080, 34560, 8640, 8640, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 1080, 34560, 34560, 34560, 34560, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 1080, 34560, 8640, 8640, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 8640, 8640, 34560, 1080, 1080, 34560, 1080, 34560, 8640, 1080, 34560, 8640, 8640, 1080, 34560, 34560, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 8640, 34560, 34560, 1080, 8640, 34560, 1080, 8640, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 34560, 1080, 34560, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 34560, 1080, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 1080, 34560, 1080, 1080, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 34560, 1080, 34560, 34560, 1080, 8640, 34560, 1080, 1080, 8640, 8640, 1080, 1080, 34560, 34560, 34560, 34560, 8640, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 34560, 8640, 8640, 8640, 34560, 1080, 8640, 8640, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 1080, 1080, 8640, 1080, 34560, 34560, 34560, 8640, 1080, 34560, 34560, 8640, 8640, 34560, 34560, 1080, 34560, 34560, 8640, 1080, 34560, 8640, 8640, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 34560, 1080, 8640, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 1080, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 8640, 34560, 8640, 8640, 8640, 1080, 8640, 1080, 1080, 34560, 1080, 8640, 1080, 1080, 8640, 34560, 8640, 34560, 1080, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5667840 . Total input tokens: 1262484234 . Total output tokens: 1133400767
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 81.64655363606289,
    "estimated_duration": 3600.0871696828403,
    "input_throughput": 6179.930082626312,
    "output_throughput": 5474.013564437146,
    "total_throughput": 11653.943647063457,
    "itl": 153.22626382861262,
    "ttft": 2114454.227446245,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 642,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1251923388615275,
    "arrivals": 1888011,
    "finished_requests": 89982,
    "scheduler_time": 175.58908152916817
}
#Debug simulation 
Total elapsed time: 81.64672767417505. Arrivals time: 0.512392635922879 Scheduler time: 80.97651378577575 Scheduler overhead time: 0.059571823570877314 Adapter cache time: 0.018816986586898565 Engine time: 0.05760338017717004 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_16-16-16/adapters_384_slots_64_rate_3.2-0.8-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_16-16-16/adapters_384_slots_64_rate_3.2-0.8-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 34560, 8640, 1080, 34560, 34560, 1080, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 1080, 34560, 1080, 34560, 8640, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 1080, 34560, 8640, 34560, 8640, 1080, 8640, 34560, 8640, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 8640, 8640, 8640, 34560, 8640, 1080, 8640, 1080, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 1080, 1080, 34560, 8640, 8640, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 1080, 34560, 34560, 34560, 34560, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 1080, 34560, 8640, 8640, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 8640, 8640, 34560, 1080, 1080, 34560, 1080, 34560, 8640, 1080, 34560, 8640, 8640, 1080, 34560, 34560, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 8640, 34560, 34560, 1080, 8640, 34560, 1080, 8640, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 34560, 1080, 34560, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 34560, 1080, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 1080, 34560, 1080, 1080, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 34560, 1080, 34560, 34560, 1080, 8640, 34560, 1080, 1080, 8640, 8640, 1080, 1080, 34560, 34560, 34560, 34560, 8640, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 34560, 8640, 8640, 8640, 34560, 1080, 8640, 8640, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 1080, 1080, 8640, 1080, 34560, 34560, 34560, 8640, 1080, 34560, 34560, 8640, 8640, 34560, 34560, 1080, 34560, 34560, 8640, 1080, 34560, 8640, 8640, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 34560, 1080, 8640, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 1080, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 8640, 34560, 8640, 8640, 8640, 1080, 8640, 1080, 1080, 34560, 1080, 8640, 1080, 1080, 8640, 34560, 8640, 34560, 1080, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5667840 . Total input tokens: 1262484234 . Total output tokens: 1133400767
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 81.02918791398406,
    "estimated_duration": 3600.138689374059,
    "input_throughput": 6195.706311491613,
    "output_throughput": 5487.427208931999,
    "total_throughput": 11683.133520423611,
    "itl": 153.8155323986773,
    "ttft": 2114044.1864089672,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 631,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8867217360832427,
    "arrivals": 1888011,
    "finished_requests": 90204,
    "scheduler_time": 174.91792281793096
}
#Debug simulation 
Total elapsed time: 81.02936017233878. Arrivals time: 0.6442801812663674 Scheduler time: 80.22745888540521 Scheduler overhead time: 0.06000906741246581 Adapter cache time: 0.018820570781826973 Engine time: 0.05730146635323763 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_16-16-32/adapters_384_slots_64_rate_3.2-0.8-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_16-16-32/adapters_384_slots_64_rate_3.2-0.8-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 34560, 8640, 1080, 34560, 34560, 1080, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 1080, 34560, 1080, 34560, 8640, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 1080, 34560, 8640, 34560, 8640, 1080, 8640, 34560, 8640, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 8640, 8640, 8640, 34560, 8640, 1080, 8640, 1080, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 1080, 1080, 34560, 8640, 8640, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 1080, 34560, 34560, 34560, 34560, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 1080, 34560, 8640, 8640, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 8640, 8640, 34560, 1080, 1080, 34560, 1080, 34560, 8640, 1080, 34560, 8640, 8640, 1080, 34560, 34560, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 8640, 34560, 34560, 1080, 8640, 34560, 1080, 8640, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 34560, 1080, 34560, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 34560, 1080, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 1080, 34560, 1080, 1080, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 34560, 1080, 34560, 34560, 1080, 8640, 34560, 1080, 1080, 8640, 8640, 1080, 1080, 34560, 34560, 34560, 34560, 8640, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 34560, 8640, 8640, 8640, 34560, 1080, 8640, 8640, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 1080, 1080, 8640, 1080, 34560, 34560, 34560, 8640, 1080, 34560, 34560, 8640, 8640, 34560, 34560, 1080, 34560, 34560, 8640, 1080, 34560, 8640, 8640, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 34560, 1080, 8640, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 1080, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 8640, 34560, 8640, 8640, 8640, 1080, 8640, 1080, 1080, 34560, 1080, 8640, 1080, 1080, 8640, 34560, 8640, 34560, 1080, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5667840 . Total input tokens: 1262484234 . Total output tokens: 1133400767
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 81.42853343905881,
    "estimated_duration": 3600.114186133833,
    "input_throughput": 6179.88370638112,
    "output_throughput": 5473.972485623655,
    "total_throughput": 11653.856192004776,
    "itl": 153.227302009395,
    "ttft": 2114464.6403632895,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 642,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.152103649154305,
    "arrivals": 1888011,
    "finished_requests": 89982,
    "scheduler_time": 175.58918666989658
}
#Debug simulation 
Total elapsed time: 81.4287019893527. Arrivals time: 0.5081783500500023 Scheduler time: 80.76117074908689 Scheduler overhead time: 0.06019389536231756 Adapter cache time: 0.01922107581049204 Engine time: 0.057514399755746126 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-8/adapters_384_slots_64_rate_3.2-0.8-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-8/adapters_384_slots_64_rate_3.2-0.8-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 8640, 540, 34560, 34560, 540, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 540, 34560, 540, 34560, 8640, 8640, 8640, 540, 540, 8640, 540, 34560, 540, 34560, 8640, 34560, 8640, 540, 8640, 34560, 8640, 34560, 540, 34560, 34560, 34560, 34560, 540, 8640, 8640, 8640, 34560, 8640, 540, 8640, 540, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 540, 540, 34560, 8640, 8640, 540, 540, 540, 8640, 540, 8640, 540, 34560, 540, 8640, 34560, 540, 34560, 8640, 540, 34560, 34560, 34560, 34560, 8640, 540, 8640, 34560, 34560, 8640, 540, 540, 34560, 8640, 8640, 540, 540, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 540, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 34560, 540, 540, 540, 8640, 8640, 34560, 540, 540, 34560, 540, 34560, 8640, 540, 34560, 8640, 8640, 540, 34560, 34560, 34560, 540, 8640, 34560, 540, 34560, 8640, 8640, 34560, 34560, 540, 8640, 34560, 540, 8640, 8640, 540, 8640, 540, 8640, 34560, 34560, 8640, 540, 34560, 540, 34560, 8640, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 34560, 540, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 540, 540, 540, 540, 540, 8640, 540, 540, 8640, 34560, 34560, 540, 540, 34560, 540, 540, 540, 8640, 540, 8640, 34560, 34560, 8640, 8640, 540, 34560, 8640, 34560, 540, 8640, 8640, 540, 540, 8640, 540, 34560, 34560, 540, 34560, 34560, 540, 8640, 34560, 540, 540, 8640, 8640, 540, 540, 34560, 34560, 34560, 34560, 8640, 540, 8640, 8640, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 34560, 8640, 8640, 8640, 34560, 540, 8640, 8640, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 8640, 540, 34560, 34560, 34560, 8640, 540, 34560, 34560, 8640, 8640, 34560, 34560, 540, 34560, 34560, 8640, 540, 34560, 8640, 8640, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 8640, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 34560, 540, 540, 540, 8640, 540, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 34560, 34560, 540, 34560, 34560, 540, 34560, 8640, 34560, 8640, 8640, 8640, 540, 8640, 540, 540, 34560, 540, 8640, 540, 540, 8640, 34560, 8640, 34560, 540, 34560, 34560, 8640, 34560, 8640, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5598720 . Total input tokens: 1247095620 . Total output tokens: 1119518383
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 77.98181173205376,
    "estimated_duration": 3600.0694324133674,
    "input_throughput": 6194.423307288987,
    "output_throughput": 5472.995832414168,
    "total_throughput": 11667.419139703155,
    "itl": 153.14231767031035,
    "ttft": 2113086.3818219206,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 610,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8668975237990086,
    "arrivals": 1864865,
    "finished_requests": 90282,
    "scheduler_time": 175.47417039637037
}
#Debug simulation 
Total elapsed time: 77.98198492079973. Arrivals time: 0.4995248718187213 Scheduler time: 77.32420265907422 Scheduler overhead time: 0.060168322175741196 Adapter cache time: 0.018700866494327784 Engine time: 0.05750312656164169 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-16/adapters_384_slots_64_rate_3.2-0.8-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-16/adapters_384_slots_64_rate_3.2-0.8-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 8640, 540, 34560, 34560, 540, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 540, 34560, 540, 34560, 8640, 8640, 8640, 540, 540, 8640, 540, 34560, 540, 34560, 8640, 34560, 8640, 540, 8640, 34560, 8640, 34560, 540, 34560, 34560, 34560, 34560, 540, 8640, 8640, 8640, 34560, 8640, 540, 8640, 540, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 540, 540, 34560, 8640, 8640, 540, 540, 540, 8640, 540, 8640, 540, 34560, 540, 8640, 34560, 540, 34560, 8640, 540, 34560, 34560, 34560, 34560, 8640, 540, 8640, 34560, 34560, 8640, 540, 540, 34560, 8640, 8640, 540, 540, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 540, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 34560, 540, 540, 540, 8640, 8640, 34560, 540, 540, 34560, 540, 34560, 8640, 540, 34560, 8640, 8640, 540, 34560, 34560, 34560, 540, 8640, 34560, 540, 34560, 8640, 8640, 34560, 34560, 540, 8640, 34560, 540, 8640, 8640, 540, 8640, 540, 8640, 34560, 34560, 8640, 540, 34560, 540, 34560, 8640, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 34560, 540, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 540, 540, 540, 540, 540, 8640, 540, 540, 8640, 34560, 34560, 540, 540, 34560, 540, 540, 540, 8640, 540, 8640, 34560, 34560, 8640, 8640, 540, 34560, 8640, 34560, 540, 8640, 8640, 540, 540, 8640, 540, 34560, 34560, 540, 34560, 34560, 540, 8640, 34560, 540, 540, 8640, 8640, 540, 540, 34560, 34560, 34560, 34560, 8640, 540, 8640, 8640, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 34560, 8640, 8640, 8640, 34560, 540, 8640, 8640, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 8640, 540, 34560, 34560, 34560, 8640, 540, 34560, 34560, 8640, 8640, 34560, 34560, 540, 34560, 34560, 8640, 540, 34560, 8640, 8640, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 8640, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 34560, 540, 540, 540, 8640, 540, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 34560, 34560, 540, 34560, 34560, 540, 34560, 8640, 34560, 8640, 8640, 8640, 540, 8640, 540, 540, 34560, 540, 8640, 540, 540, 8640, 34560, 8640, 34560, 540, 34560, 34560, 8640, 34560, 8640, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5598720 . Total input tokens: 1247095620 . Total output tokens: 1119518383
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 84.5065426141955,
    "estimated_duration": 3600.109155075877,
    "input_throughput": 6199.589800918021,
    "output_throughput": 5460.33721568803,
    "total_throughput": 11659.92701660605,
    "itl": 152.45917510484657,
    "ttft": 2112344.9742602534,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 590,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9251162294577864,
    "arrivals": 1864865,
    "finished_requests": 90214,
    "scheduler_time": 176.19052436644463
}
#Debug simulation 
Total elapsed time: 84.50670202309266. Arrivals time: 0.5039407517760992 Scheduler time: 83.84381996886805 Scheduler overhead time: 0.0608011013828218 Adapter cache time: 0.018539998680353165 Engine time: 0.05746333859860897 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-32/adapters_384_slots_64_rate_3.2-0.8-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-32/adapters_384_slots_64_rate_3.2-0.8-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 8640, 540, 34560, 34560, 540, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 540, 34560, 540, 34560, 8640, 8640, 8640, 540, 540, 8640, 540, 34560, 540, 34560, 8640, 34560, 8640, 540, 8640, 34560, 8640, 34560, 540, 34560, 34560, 34560, 34560, 540, 8640, 8640, 8640, 34560, 8640, 540, 8640, 540, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 540, 540, 34560, 8640, 8640, 540, 540, 540, 8640, 540, 8640, 540, 34560, 540, 8640, 34560, 540, 34560, 8640, 540, 34560, 34560, 34560, 34560, 8640, 540, 8640, 34560, 34560, 8640, 540, 540, 34560, 8640, 8640, 540, 540, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 540, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 34560, 540, 540, 540, 8640, 8640, 34560, 540, 540, 34560, 540, 34560, 8640, 540, 34560, 8640, 8640, 540, 34560, 34560, 34560, 540, 8640, 34560, 540, 34560, 8640, 8640, 34560, 34560, 540, 8640, 34560, 540, 8640, 8640, 540, 8640, 540, 8640, 34560, 34560, 8640, 540, 34560, 540, 34560, 8640, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 34560, 540, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 540, 540, 540, 540, 540, 8640, 540, 540, 8640, 34560, 34560, 540, 540, 34560, 540, 540, 540, 8640, 540, 8640, 34560, 34560, 8640, 8640, 540, 34560, 8640, 34560, 540, 8640, 8640, 540, 540, 8640, 540, 34560, 34560, 540, 34560, 34560, 540, 8640, 34560, 540, 540, 8640, 8640, 540, 540, 34560, 34560, 34560, 34560, 8640, 540, 8640, 8640, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 34560, 8640, 8640, 8640, 34560, 540, 8640, 8640, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 8640, 540, 34560, 34560, 34560, 8640, 540, 34560, 34560, 8640, 8640, 34560, 34560, 540, 34560, 34560, 8640, 540, 34560, 8640, 8640, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 8640, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 34560, 540, 540, 540, 8640, 540, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 34560, 34560, 540, 34560, 34560, 540, 34560, 8640, 34560, 8640, 8640, 8640, 540, 8640, 540, 540, 34560, 540, 8640, 540, 540, 8640, 34560, 8640, 34560, 540, 34560, 34560, 8640, 34560, 8640, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5598720 . Total input tokens: 1247095620 . Total output tokens: 1119518383
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 83.74105887580663,
    "estimated_duration": 3600.1125908451418,
    "input_throughput": 6199.583884336371,
    "output_throughput": 5460.332004612457,
    "total_throughput": 11659.915888948828,
    "itl": 152.45930922373455,
    "ttft": 2112346.243347471,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 590,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.928551633618784,
    "arrivals": 1864865,
    "finished_requests": 90214,
    "scheduler_time": 176.1905247315166
}
#Debug simulation 
Total elapsed time: 83.74121929192916. Arrivals time: 0.5009503997862339 Scheduler time: 83.08128412440419 Scheduler overhead time: 0.06102173775434494 Adapter cache time: 0.018311983440071344 Engine time: 0.05755171738564968 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-16-16/adapters_384_slots_64_rate_3.2-0.8-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-16-16/adapters_384_slots_64_rate_3.2-0.8-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 8640, 540, 34560, 34560, 540, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 540, 34560, 540, 34560, 8640, 8640, 8640, 540, 540, 8640, 540, 34560, 540, 34560, 8640, 34560, 8640, 540, 8640, 34560, 8640, 34560, 540, 34560, 34560, 34560, 34560, 540, 8640, 8640, 8640, 34560, 8640, 540, 8640, 540, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 540, 540, 34560, 8640, 8640, 540, 540, 540, 8640, 540, 8640, 540, 34560, 540, 8640, 34560, 540, 34560, 8640, 540, 34560, 34560, 34560, 34560, 8640, 540, 8640, 34560, 34560, 8640, 540, 540, 34560, 8640, 8640, 540, 540, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 540, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 34560, 540, 540, 540, 8640, 8640, 34560, 540, 540, 34560, 540, 34560, 8640, 540, 34560, 8640, 8640, 540, 34560, 34560, 34560, 540, 8640, 34560, 540, 34560, 8640, 8640, 34560, 34560, 540, 8640, 34560, 540, 8640, 8640, 540, 8640, 540, 8640, 34560, 34560, 8640, 540, 34560, 540, 34560, 8640, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 34560, 540, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 540, 540, 540, 540, 540, 8640, 540, 540, 8640, 34560, 34560, 540, 540, 34560, 540, 540, 540, 8640, 540, 8640, 34560, 34560, 8640, 8640, 540, 34560, 8640, 34560, 540, 8640, 8640, 540, 540, 8640, 540, 34560, 34560, 540, 34560, 34560, 540, 8640, 34560, 540, 540, 8640, 8640, 540, 540, 34560, 34560, 34560, 34560, 8640, 540, 8640, 8640, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 34560, 8640, 8640, 8640, 34560, 540, 8640, 8640, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 8640, 540, 34560, 34560, 34560, 8640, 540, 34560, 34560, 8640, 8640, 34560, 34560, 540, 34560, 34560, 8640, 540, 34560, 8640, 8640, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 8640, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 34560, 540, 540, 540, 8640, 540, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 34560, 34560, 540, 34560, 34560, 540, 34560, 8640, 34560, 8640, 8640, 8640, 540, 8640, 540, 540, 34560, 540, 8640, 540, 540, 8640, 34560, 8640, 34560, 540, 34560, 34560, 8640, 34560, 8640, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5598720 . Total input tokens: 1247095620 . Total output tokens: 1119518383
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 77.90387038467452,
    "estimated_duration": 3600.162030711265,
    "input_throughput": 6203.493845411083,
    "output_throughput": 5475.325508087089,
    "total_throughput": 11678.819353498173,
    "itl": 153.28923553228947,
    "ttft": 2112987.021292083,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 600,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8741148593556012,
    "arrivals": 1864865,
    "finished_requests": 90327,
    "scheduler_time": 175.39707758343525
}
#Debug simulation 
Total elapsed time: 77.90404032263905. Arrivals time: 0.5010032965801656 Scheduler time: 77.24461655085906 Scheduler overhead time: 0.0597893544472754 Adapter cache time: 0.018414991907775402 Engine time: 0.0579708693549037 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-16-32/adapters_384_slots_64_rate_3.2-0.8-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-16-32/adapters_384_slots_64_rate_3.2-0.8-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 8640, 540, 34560, 34560, 540, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 540, 34560, 540, 34560, 8640, 8640, 8640, 540, 540, 8640, 540, 34560, 540, 34560, 8640, 34560, 8640, 540, 8640, 34560, 8640, 34560, 540, 34560, 34560, 34560, 34560, 540, 8640, 8640, 8640, 34560, 8640, 540, 8640, 540, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 540, 540, 34560, 8640, 8640, 540, 540, 540, 8640, 540, 8640, 540, 34560, 540, 8640, 34560, 540, 34560, 8640, 540, 34560, 34560, 34560, 34560, 8640, 540, 8640, 34560, 34560, 8640, 540, 540, 34560, 8640, 8640, 540, 540, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 540, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 34560, 540, 540, 540, 8640, 8640, 34560, 540, 540, 34560, 540, 34560, 8640, 540, 34560, 8640, 8640, 540, 34560, 34560, 34560, 540, 8640, 34560, 540, 34560, 8640, 8640, 34560, 34560, 540, 8640, 34560, 540, 8640, 8640, 540, 8640, 540, 8640, 34560, 34560, 8640, 540, 34560, 540, 34560, 8640, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 34560, 540, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 540, 540, 540, 540, 540, 8640, 540, 540, 8640, 34560, 34560, 540, 540, 34560, 540, 540, 540, 8640, 540, 8640, 34560, 34560, 8640, 8640, 540, 34560, 8640, 34560, 540, 8640, 8640, 540, 540, 8640, 540, 34560, 34560, 540, 34560, 34560, 540, 8640, 34560, 540, 540, 8640, 8640, 540, 540, 34560, 34560, 34560, 34560, 8640, 540, 8640, 8640, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 34560, 8640, 8640, 8640, 34560, 540, 8640, 8640, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 8640, 540, 34560, 34560, 34560, 8640, 540, 34560, 34560, 8640, 8640, 34560, 34560, 540, 34560, 34560, 8640, 540, 34560, 8640, 8640, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 8640, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 34560, 540, 540, 540, 8640, 540, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 34560, 34560, 540, 34560, 34560, 540, 34560, 8640, 34560, 8640, 8640, 8640, 540, 8640, 540, 540, 34560, 540, 8640, 540, 540, 8640, 34560, 8640, 34560, 540, 34560, 34560, 8640, 34560, 8640, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5598720 . Total input tokens: 1247095620 . Total output tokens: 1119518383
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 84.56955287186429,
    "estimated_duration": 3600.1380128373594,
    "input_throughput": 6199.5401066332115,
    "output_throughput": 5460.293447057932,
    "total_throughput": 11659.833553691144,
    "itl": 152.46019566015792,
    "ttft": 2112356.3611625023,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 590,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9538281446881622,
    "arrivals": 1864865,
    "finished_requests": 90214,
    "scheduler_time": 176.19067021269814
}
#Debug simulation 
Total elapsed time: 84.56971563072875. Arrivals time: 0.6341892145574093 Scheduler time: 83.77552392752841 Scheduler overhead time: 0.06102635757997632 Adapter cache time: 0.018387798685580492 Engine time: 0.05833844328299165 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_16-16-16/adapters_384_slots_64_rate_3.2-0.8-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_16-16-16/adapters_384_slots_64_rate_3.2-0.8-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 8640, 540, 34560, 34560, 540, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 540, 34560, 540, 34560, 8640, 8640, 8640, 540, 540, 8640, 540, 34560, 540, 34560, 8640, 34560, 8640, 540, 8640, 34560, 8640, 34560, 540, 34560, 34560, 34560, 34560, 540, 8640, 8640, 8640, 34560, 8640, 540, 8640, 540, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 540, 540, 34560, 8640, 8640, 540, 540, 540, 8640, 540, 8640, 540, 34560, 540, 8640, 34560, 540, 34560, 8640, 540, 34560, 34560, 34560, 34560, 8640, 540, 8640, 34560, 34560, 8640, 540, 540, 34560, 8640, 8640, 540, 540, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 540, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 34560, 540, 540, 540, 8640, 8640, 34560, 540, 540, 34560, 540, 34560, 8640, 540, 34560, 8640, 8640, 540, 34560, 34560, 34560, 540, 8640, 34560, 540, 34560, 8640, 8640, 34560, 34560, 540, 8640, 34560, 540, 8640, 8640, 540, 8640, 540, 8640, 34560, 34560, 8640, 540, 34560, 540, 34560, 8640, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 34560, 540, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 540, 540, 540, 540, 540, 8640, 540, 540, 8640, 34560, 34560, 540, 540, 34560, 540, 540, 540, 8640, 540, 8640, 34560, 34560, 8640, 8640, 540, 34560, 8640, 34560, 540, 8640, 8640, 540, 540, 8640, 540, 34560, 34560, 540, 34560, 34560, 540, 8640, 34560, 540, 540, 8640, 8640, 540, 540, 34560, 34560, 34560, 34560, 8640, 540, 8640, 8640, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 34560, 8640, 8640, 8640, 34560, 540, 8640, 8640, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 8640, 540, 34560, 34560, 34560, 8640, 540, 34560, 34560, 8640, 8640, 34560, 34560, 540, 34560, 34560, 8640, 540, 34560, 8640, 8640, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 8640, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 34560, 540, 540, 540, 8640, 540, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 34560, 34560, 540, 34560, 34560, 540, 34560, 8640, 34560, 8640, 8640, 8640, 540, 8640, 540, 540, 34560, 540, 8640, 540, 540, 8640, 34560, 8640, 34560, 540, 34560, 34560, 8640, 34560, 8640, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5598720 . Total input tokens: 1247095620 . Total output tokens: 1119518383
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 78.17938082711771,
    "estimated_duration": 3600.0262554706287,
    "input_throughput": 6194.497600152833,
    "output_throughput": 5473.061472832014,
    "total_throughput": 11667.559072984848,
    "itl": 153.1407612955674,
    "ttft": 2113068.158653972,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 610,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8239306798902992,
    "arrivals": 1864865,
    "finished_requests": 90282,
    "scheduler_time": 175.47396029744954
}
#Debug simulation 
Total elapsed time: 78.1795525541529. Arrivals time: 0.4963378282263875 Scheduler time: 77.52343141101301 Scheduler overhead time: 0.06133928336203098 Adapter cache time: 0.018528256565332413 Engine time: 0.057874804362654686 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_16-16-32/adapters_384_slots_64_rate_3.2-0.8-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_16-16-32/adapters_384_slots_64_rate_3.2-0.8-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 8640, 540, 34560, 34560, 540, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 540, 34560, 540, 34560, 8640, 8640, 8640, 540, 540, 8640, 540, 34560, 540, 34560, 8640, 34560, 8640, 540, 8640, 34560, 8640, 34560, 540, 34560, 34560, 34560, 34560, 540, 8640, 8640, 8640, 34560, 8640, 540, 8640, 540, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 540, 540, 34560, 8640, 8640, 540, 540, 540, 8640, 540, 8640, 540, 34560, 540, 8640, 34560, 540, 34560, 8640, 540, 34560, 34560, 34560, 34560, 8640, 540, 8640, 34560, 34560, 8640, 540, 540, 34560, 8640, 8640, 540, 540, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 540, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 34560, 540, 540, 540, 8640, 8640, 34560, 540, 540, 34560, 540, 34560, 8640, 540, 34560, 8640, 8640, 540, 34560, 34560, 34560, 540, 8640, 34560, 540, 34560, 8640, 8640, 34560, 34560, 540, 8640, 34560, 540, 8640, 8640, 540, 8640, 540, 8640, 34560, 34560, 8640, 540, 34560, 540, 34560, 8640, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 34560, 540, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 540, 540, 540, 540, 540, 8640, 540, 540, 8640, 34560, 34560, 540, 540, 34560, 540, 540, 540, 8640, 540, 8640, 34560, 34560, 8640, 8640, 540, 34560, 8640, 34560, 540, 8640, 8640, 540, 540, 8640, 540, 34560, 34560, 540, 34560, 34560, 540, 8640, 34560, 540, 540, 8640, 8640, 540, 540, 34560, 34560, 34560, 34560, 8640, 540, 8640, 8640, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 34560, 8640, 8640, 8640, 34560, 540, 8640, 8640, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 8640, 540, 34560, 34560, 34560, 8640, 540, 34560, 34560, 8640, 8640, 34560, 34560, 540, 34560, 34560, 8640, 540, 34560, 8640, 8640, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 8640, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 34560, 540, 540, 540, 8640, 540, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 34560, 34560, 540, 34560, 34560, 540, 34560, 8640, 34560, 8640, 8640, 8640, 540, 8640, 540, 540, 34560, 540, 8640, 540, 540, 8640, 34560, 8640, 34560, 540, 34560, 34560, 8640, 34560, 8640, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5598720 . Total input tokens: 1247095620 . Total output tokens: 1119518383
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 84.26308370800689,
    "estimated_duration": 3600.1624176645973,
    "input_throughput": 6199.498081111108,
    "output_throughput": 5460.256432750581,
    "total_throughput": 11659.75451386169,
    "itl": 152.46106425591213,
    "ttft": 2112366.253751954,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 590,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.978098625466223,
    "arrivals": 1864865,
    "finished_requests": 90214,
    "scheduler_time": 176.19080455918444
}
#Debug simulation 
Total elapsed time: 84.26324703590944. Arrivals time: 0.4992180191911757 Scheduler time: 83.60515803005546 Scheduler overhead time: 0.060164022259414196 Adapter cache time: 0.0186611688695848 Engine time: 0.058292537927627563 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-8/adapters_384_slots_64_rate_3.2-0.8-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-8/adapters_384_slots_64_rate_3.2-0.8-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 8640, 270, 34560, 34560, 270, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 270, 34560, 270, 34560, 8640, 8640, 8640, 270, 270, 8640, 270, 34560, 270, 34560, 8640, 34560, 8640, 270, 8640, 34560, 8640, 34560, 270, 34560, 34560, 34560, 34560, 270, 8640, 8640, 8640, 34560, 8640, 270, 8640, 270, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 270, 270, 34560, 8640, 8640, 270, 270, 270, 8640, 270, 8640, 270, 34560, 270, 8640, 34560, 270, 34560, 8640, 270, 34560, 34560, 34560, 34560, 8640, 270, 8640, 34560, 34560, 8640, 270, 270, 34560, 8640, 8640, 270, 270, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 270, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 34560, 270, 270, 270, 8640, 8640, 34560, 270, 270, 34560, 270, 34560, 8640, 270, 34560, 8640, 8640, 270, 34560, 34560, 34560, 270, 8640, 34560, 270, 34560, 8640, 8640, 34560, 34560, 270, 8640, 34560, 270, 8640, 8640, 270, 8640, 270, 8640, 34560, 34560, 8640, 270, 34560, 270, 34560, 8640, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 34560, 270, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 270, 270, 270, 270, 270, 8640, 270, 270, 8640, 34560, 34560, 270, 270, 34560, 270, 270, 270, 8640, 270, 8640, 34560, 34560, 8640, 8640, 270, 34560, 8640, 34560, 270, 8640, 8640, 270, 270, 8640, 270, 34560, 34560, 270, 34560, 34560, 270, 8640, 34560, 270, 270, 8640, 8640, 270, 270, 34560, 34560, 34560, 34560, 8640, 270, 8640, 8640, 270, 270, 270, 270, 270, 270, 270, 270, 8640, 34560, 8640, 8640, 8640, 34560, 270, 8640, 8640, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 8640, 270, 34560, 34560, 34560, 8640, 270, 34560, 34560, 8640, 8640, 34560, 34560, 270, 34560, 34560, 8640, 270, 34560, 8640, 8640, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 8640, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 34560, 270, 270, 270, 8640, 270, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 34560, 34560, 270, 34560, 34560, 270, 34560, 8640, 34560, 8640, 8640, 8640, 270, 8640, 270, 270, 34560, 270, 8640, 270, 270, 8640, 34560, 8640, 34560, 270, 34560, 34560, 8640, 34560, 8640, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5564160 . Total input tokens: 1239343507 . Total output tokens: 1112626833
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 83.60954434191808,
    "estimated_duration": 3600.097214279244,
    "input_throughput": 6208.372627091606,
    "output_throughput": 5478.674554056115,
    "total_throughput": 11687.047181147722,
    "itl": 153.2925965003118,
    "ttft": 2108753.34495233,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 584,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7873248424567543,
    "arrivals": 1853406,
    "finished_requests": 90481,
    "scheduler_time": 175.35899772323577
}
#Debug simulation 
Total elapsed time: 83.60970708914101. Arrivals time: 0.4986015260219574 Scheduler time: 82.95363590400666 Scheduler overhead time: 0.060555858071893454 Adapter cache time: 0.018164435867220163 Engine time: 0.056614074390381575 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-16/adapters_384_slots_64_rate_3.2-0.8-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-16/adapters_384_slots_64_rate_3.2-0.8-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 8640, 270, 34560, 34560, 270, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 270, 34560, 270, 34560, 8640, 8640, 8640, 270, 270, 8640, 270, 34560, 270, 34560, 8640, 34560, 8640, 270, 8640, 34560, 8640, 34560, 270, 34560, 34560, 34560, 34560, 270, 8640, 8640, 8640, 34560, 8640, 270, 8640, 270, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 270, 270, 34560, 8640, 8640, 270, 270, 270, 8640, 270, 8640, 270, 34560, 270, 8640, 34560, 270, 34560, 8640, 270, 34560, 34560, 34560, 34560, 8640, 270, 8640, 34560, 34560, 8640, 270, 270, 34560, 8640, 8640, 270, 270, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 270, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 34560, 270, 270, 270, 8640, 8640, 34560, 270, 270, 34560, 270, 34560, 8640, 270, 34560, 8640, 8640, 270, 34560, 34560, 34560, 270, 8640, 34560, 270, 34560, 8640, 8640, 34560, 34560, 270, 8640, 34560, 270, 8640, 8640, 270, 8640, 270, 8640, 34560, 34560, 8640, 270, 34560, 270, 34560, 8640, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 34560, 270, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 270, 270, 270, 270, 270, 8640, 270, 270, 8640, 34560, 34560, 270, 270, 34560, 270, 270, 270, 8640, 270, 8640, 34560, 34560, 8640, 8640, 270, 34560, 8640, 34560, 270, 8640, 8640, 270, 270, 8640, 270, 34560, 34560, 270, 34560, 34560, 270, 8640, 34560, 270, 270, 8640, 8640, 270, 270, 34560, 34560, 34560, 34560, 8640, 270, 8640, 8640, 270, 270, 270, 270, 270, 270, 270, 270, 8640, 34560, 8640, 8640, 8640, 34560, 270, 8640, 8640, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 8640, 270, 34560, 34560, 34560, 8640, 270, 34560, 34560, 8640, 8640, 34560, 34560, 270, 34560, 34560, 8640, 270, 34560, 8640, 8640, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 8640, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 34560, 270, 270, 270, 8640, 270, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 34560, 34560, 270, 34560, 34560, 270, 34560, 8640, 34560, 8640, 8640, 8640, 270, 8640, 270, 270, 34560, 270, 8640, 270, 270, 8640, 34560, 8640, 34560, 270, 34560, 34560, 8640, 34560, 8640, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5564160 . Total input tokens: 1239343507 . Total output tokens: 1112626833
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 82.76043972279876,
    "estimated_duration": 3600.0419605665966,
    "input_throughput": 6207.939864257194,
    "output_throughput": 5478.467811218489,
    "total_throughput": 11686.407675475682,
    "itl": 153.29680217244828,
    "ttft": 2108720.476134349,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 584,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9051329510961719,
    "arrivals": 1853406,
    "finished_requests": 90475,
    "scheduler_time": 175.35119924317746
}
#Debug simulation 
Total elapsed time: 82.7606030809693. Arrivals time: 0.49876710772514343 Scheduler time: 82.10326697770506 Scheduler overhead time: 0.060988785699009895 Adapter cache time: 0.018334303982555866 Engine time: 0.0573707427829504 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-32/adapters_384_slots_64_rate_3.2-0.8-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-32/adapters_384_slots_64_rate_3.2-0.8-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 8640, 270, 34560, 34560, 270, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 270, 34560, 270, 34560, 8640, 8640, 8640, 270, 270, 8640, 270, 34560, 270, 34560, 8640, 34560, 8640, 270, 8640, 34560, 8640, 34560, 270, 34560, 34560, 34560, 34560, 270, 8640, 8640, 8640, 34560, 8640, 270, 8640, 270, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 270, 270, 34560, 8640, 8640, 270, 270, 270, 8640, 270, 8640, 270, 34560, 270, 8640, 34560, 270, 34560, 8640, 270, 34560, 34560, 34560, 34560, 8640, 270, 8640, 34560, 34560, 8640, 270, 270, 34560, 8640, 8640, 270, 270, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 270, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 34560, 270, 270, 270, 8640, 8640, 34560, 270, 270, 34560, 270, 34560, 8640, 270, 34560, 8640, 8640, 270, 34560, 34560, 34560, 270, 8640, 34560, 270, 34560, 8640, 8640, 34560, 34560, 270, 8640, 34560, 270, 8640, 8640, 270, 8640, 270, 8640, 34560, 34560, 8640, 270, 34560, 270, 34560, 8640, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 34560, 270, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 270, 270, 270, 270, 270, 8640, 270, 270, 8640, 34560, 34560, 270, 270, 34560, 270, 270, 270, 8640, 270, 8640, 34560, 34560, 8640, 8640, 270, 34560, 8640, 34560, 270, 8640, 8640, 270, 270, 8640, 270, 34560, 34560, 270, 34560, 34560, 270, 8640, 34560, 270, 270, 8640, 8640, 270, 270, 34560, 34560, 34560, 34560, 8640, 270, 8640, 8640, 270, 270, 270, 270, 270, 270, 270, 270, 8640, 34560, 8640, 8640, 8640, 34560, 270, 8640, 8640, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 8640, 270, 34560, 34560, 34560, 8640, 270, 34560, 34560, 8640, 8640, 34560, 34560, 270, 34560, 34560, 8640, 270, 34560, 8640, 8640, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 8640, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 34560, 270, 270, 270, 8640, 270, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 34560, 34560, 270, 34560, 34560, 270, 34560, 8640, 34560, 8640, 8640, 8640, 270, 8640, 270, 270, 34560, 270, 8640, 270, 270, 8640, 34560, 8640, 34560, 270, 34560, 34560, 8640, 34560, 8640, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5564160 . Total input tokens: 1239343507 . Total output tokens: 1112626833
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 83.22343055717647,
    "estimated_duration": 3600.045451247401,
    "input_throughput": 6207.933844906379,
    "output_throughput": 5478.462499179325,
    "total_throughput": 11686.396344085704,
    "itl": 153.29694000192995,
    "ttft": 2108721.87635647,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 584,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9086042830534398,
    "arrivals": 1853406,
    "finished_requests": 90475,
    "scheduler_time": 175.35121859199208
}
#Debug simulation 
Total elapsed time: 83.22359912516549. Arrivals time: 0.4956820821389556 Scheduler time: 82.5691638593562 Scheduler overhead time: 0.0606623706407845 Adapter cache time: 0.018129487056285143 Engine time: 0.05786169087514281 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-16-16/adapters_384_slots_64_rate_3.2-0.8-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-16-16/adapters_384_slots_64_rate_3.2-0.8-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 8640, 270, 34560, 34560, 270, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 270, 34560, 270, 34560, 8640, 8640, 8640, 270, 270, 8640, 270, 34560, 270, 34560, 8640, 34560, 8640, 270, 8640, 34560, 8640, 34560, 270, 34560, 34560, 34560, 34560, 270, 8640, 8640, 8640, 34560, 8640, 270, 8640, 270, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 270, 270, 34560, 8640, 8640, 270, 270, 270, 8640, 270, 8640, 270, 34560, 270, 8640, 34560, 270, 34560, 8640, 270, 34560, 34560, 34560, 34560, 8640, 270, 8640, 34560, 34560, 8640, 270, 270, 34560, 8640, 8640, 270, 270, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 270, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 34560, 270, 270, 270, 8640, 8640, 34560, 270, 270, 34560, 270, 34560, 8640, 270, 34560, 8640, 8640, 270, 34560, 34560, 34560, 270, 8640, 34560, 270, 34560, 8640, 8640, 34560, 34560, 270, 8640, 34560, 270, 8640, 8640, 270, 8640, 270, 8640, 34560, 34560, 8640, 270, 34560, 270, 34560, 8640, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 34560, 270, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 270, 270, 270, 270, 270, 8640, 270, 270, 8640, 34560, 34560, 270, 270, 34560, 270, 270, 270, 8640, 270, 8640, 34560, 34560, 8640, 8640, 270, 34560, 8640, 34560, 270, 8640, 8640, 270, 270, 8640, 270, 34560, 34560, 270, 34560, 34560, 270, 8640, 34560, 270, 270, 8640, 8640, 270, 270, 34560, 34560, 34560, 34560, 8640, 270, 8640, 8640, 270, 270, 270, 270, 270, 270, 270, 270, 8640, 34560, 8640, 8640, 8640, 34560, 270, 8640, 8640, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 8640, 270, 34560, 34560, 34560, 8640, 270, 34560, 34560, 8640, 8640, 34560, 34560, 270, 34560, 34560, 8640, 270, 34560, 8640, 8640, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 8640, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 34560, 270, 270, 270, 8640, 270, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 34560, 34560, 270, 34560, 34560, 270, 34560, 8640, 34560, 8640, 8640, 8640, 270, 8640, 270, 270, 34560, 270, 8640, 270, 270, 8640, 34560, 8640, 34560, 270, 34560, 34560, 8640, 34560, 8640, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5564160 . Total input tokens: 1239343507 . Total output tokens: 1112626833
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 83.03040962805972,
    "estimated_duration": 3600.138390099282,
    "input_throughput": 6208.3016201451155,
    "output_throughput": 5478.611892876727,
    "total_throughput": 11686.913513021842,
    "itl": 153.2941802673781,
    "ttft": 2108769.457589945,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 584,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8283170312293706,
    "arrivals": 1853406,
    "finished_requests": 90481,
    "scheduler_time": 175.35918135443853
}
#Debug simulation 
Total elapsed time: 83.03057824028656. Arrivals time: 0.49696137523278594 Scheduler time: 82.37458279076964 Scheduler overhead time: 0.061001093592494726 Adapter cache time: 0.01820877380669117 Engine time: 0.05795551557093859 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-16-32/adapters_384_slots_64_rate_3.2-0.8-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-16-32/adapters_384_slots_64_rate_3.2-0.8-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 8640, 270, 34560, 34560, 270, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 270, 34560, 270, 34560, 8640, 8640, 8640, 270, 270, 8640, 270, 34560, 270, 34560, 8640, 34560, 8640, 270, 8640, 34560, 8640, 34560, 270, 34560, 34560, 34560, 34560, 270, 8640, 8640, 8640, 34560, 8640, 270, 8640, 270, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 270, 270, 34560, 8640, 8640, 270, 270, 270, 8640, 270, 8640, 270, 34560, 270, 8640, 34560, 270, 34560, 8640, 270, 34560, 34560, 34560, 34560, 8640, 270, 8640, 34560, 34560, 8640, 270, 270, 34560, 8640, 8640, 270, 270, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 270, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 34560, 270, 270, 270, 8640, 8640, 34560, 270, 270, 34560, 270, 34560, 8640, 270, 34560, 8640, 8640, 270, 34560, 34560, 34560, 270, 8640, 34560, 270, 34560, 8640, 8640, 34560, 34560, 270, 8640, 34560, 270, 8640, 8640, 270, 8640, 270, 8640, 34560, 34560, 8640, 270, 34560, 270, 34560, 8640, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 34560, 270, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 270, 270, 270, 270, 270, 8640, 270, 270, 8640, 34560, 34560, 270, 270, 34560, 270, 270, 270, 8640, 270, 8640, 34560, 34560, 8640, 8640, 270, 34560, 8640, 34560, 270, 8640, 8640, 270, 270, 8640, 270, 34560, 34560, 270, 34560, 34560, 270, 8640, 34560, 270, 270, 8640, 8640, 270, 270, 34560, 34560, 34560, 34560, 8640, 270, 8640, 8640, 270, 270, 270, 270, 270, 270, 270, 270, 8640, 34560, 8640, 8640, 8640, 34560, 270, 8640, 8640, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 8640, 270, 34560, 34560, 34560, 8640, 270, 34560, 34560, 8640, 8640, 34560, 34560, 270, 34560, 34560, 8640, 270, 34560, 8640, 8640, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 8640, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 34560, 270, 270, 270, 8640, 270, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 34560, 34560, 270, 34560, 34560, 270, 34560, 8640, 34560, 8640, 8640, 8640, 270, 8640, 270, 270, 34560, 270, 8640, 270, 270, 8640, 34560, 8640, 34560, 270, 34560, 34560, 8640, 34560, 8640, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5564160 . Total input tokens: 1239343507 . Total output tokens: 1112626833
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 82.95882122404873,
    "estimated_duration": 3600.0692121552165,
    "input_throughput": 6207.892871765275,
    "output_throughput": 5478.426340640492,
    "total_throughput": 11686.319212405768,
    "itl": 153.29781950556173,
    "ttft": 2108731.2087322227,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 584,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9322459948994257,
    "arrivals": 1853406,
    "finished_requests": 90475,
    "scheduler_time": 175.35133778799147
}
#Debug simulation 
Total elapsed time: 82.95898740412667. Arrivals time: 0.5032986290752888 Scheduler time: 82.29640011070296 Scheduler overhead time: 0.06069816602393985 Adapter cache time: 0.0184575910679996 Engine time: 0.058000621385872364 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_16-16-16/adapters_384_slots_64_rate_3.2-0.8-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_16-16-16/adapters_384_slots_64_rate_3.2-0.8-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 8640, 270, 34560, 34560, 270, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 270, 34560, 270, 34560, 8640, 8640, 8640, 270, 270, 8640, 270, 34560, 270, 34560, 8640, 34560, 8640, 270, 8640, 34560, 8640, 34560, 270, 34560, 34560, 34560, 34560, 270, 8640, 8640, 8640, 34560, 8640, 270, 8640, 270, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 270, 270, 34560, 8640, 8640, 270, 270, 270, 8640, 270, 8640, 270, 34560, 270, 8640, 34560, 270, 34560, 8640, 270, 34560, 34560, 34560, 34560, 8640, 270, 8640, 34560, 34560, 8640, 270, 270, 34560, 8640, 8640, 270, 270, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 270, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 34560, 270, 270, 270, 8640, 8640, 34560, 270, 270, 34560, 270, 34560, 8640, 270, 34560, 8640, 8640, 270, 34560, 34560, 34560, 270, 8640, 34560, 270, 34560, 8640, 8640, 34560, 34560, 270, 8640, 34560, 270, 8640, 8640, 270, 8640, 270, 8640, 34560, 34560, 8640, 270, 34560, 270, 34560, 8640, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 34560, 270, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 270, 270, 270, 270, 270, 8640, 270, 270, 8640, 34560, 34560, 270, 270, 34560, 270, 270, 270, 8640, 270, 8640, 34560, 34560, 8640, 8640, 270, 34560, 8640, 34560, 270, 8640, 8640, 270, 270, 8640, 270, 34560, 34560, 270, 34560, 34560, 270, 8640, 34560, 270, 270, 8640, 8640, 270, 270, 34560, 34560, 34560, 34560, 8640, 270, 8640, 8640, 270, 270, 270, 270, 270, 270, 270, 270, 8640, 34560, 8640, 8640, 8640, 34560, 270, 8640, 8640, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 8640, 270, 34560, 34560, 34560, 8640, 270, 34560, 34560, 8640, 8640, 34560, 34560, 270, 34560, 34560, 8640, 270, 34560, 8640, 8640, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 8640, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 34560, 270, 270, 270, 8640, 270, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 34560, 34560, 270, 34560, 34560, 270, 34560, 8640, 34560, 8640, 8640, 8640, 270, 8640, 270, 270, 34560, 270, 8640, 270, 270, 8640, 34560, 8640, 34560, 270, 34560, 34560, 8640, 34560, 8640, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5564160 . Total input tokens: 1239343507 . Total output tokens: 1112626833
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 83.14488328294829,
    "estimated_duration": 3600.0558750989344,
    "input_throughput": 6208.443917383857,
    "output_throughput": 5478.737465278359,
    "total_throughput": 11687.181382662216,
    "itl": 153.29103375793758,
    "ttft": 2108737.075522501,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 584,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7461893722228454,
    "arrivals": 1853406,
    "finished_requests": 90481,
    "scheduler_time": 175.35879401307446
}
#Debug simulation 
Total elapsed time: 83.14505452523008. Arrivals time: 0.500726253259927 Scheduler time: 82.48612302355468 Scheduler overhead time: 0.06076420471072197 Adapter cache time: 0.018250526394695044 Engine time: 0.057384606916457415 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_16-16-32/adapters_384_slots_64_rate_3.2-0.8-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_16-16-32/adapters_384_slots_64_rate_3.2-0.8-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 8640, 270, 34560, 34560, 270, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 270, 34560, 270, 34560, 8640, 8640, 8640, 270, 270, 8640, 270, 34560, 270, 34560, 8640, 34560, 8640, 270, 8640, 34560, 8640, 34560, 270, 34560, 34560, 34560, 34560, 270, 8640, 8640, 8640, 34560, 8640, 270, 8640, 270, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 270, 270, 34560, 8640, 8640, 270, 270, 270, 8640, 270, 8640, 270, 34560, 270, 8640, 34560, 270, 34560, 8640, 270, 34560, 34560, 34560, 34560, 8640, 270, 8640, 34560, 34560, 8640, 270, 270, 34560, 8640, 8640, 270, 270, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 270, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 34560, 270, 270, 270, 8640, 8640, 34560, 270, 270, 34560, 270, 34560, 8640, 270, 34560, 8640, 8640, 270, 34560, 34560, 34560, 270, 8640, 34560, 270, 34560, 8640, 8640, 34560, 34560, 270, 8640, 34560, 270, 8640, 8640, 270, 8640, 270, 8640, 34560, 34560, 8640, 270, 34560, 270, 34560, 8640, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 34560, 270, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 270, 270, 270, 270, 270, 8640, 270, 270, 8640, 34560, 34560, 270, 270, 34560, 270, 270, 270, 8640, 270, 8640, 34560, 34560, 8640, 8640, 270, 34560, 8640, 34560, 270, 8640, 8640, 270, 270, 8640, 270, 34560, 34560, 270, 34560, 34560, 270, 8640, 34560, 270, 270, 8640, 8640, 270, 270, 34560, 34560, 34560, 34560, 8640, 270, 8640, 8640, 270, 270, 270, 270, 270, 270, 270, 270, 8640, 34560, 8640, 8640, 8640, 34560, 270, 8640, 8640, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 8640, 270, 34560, 34560, 34560, 8640, 270, 34560, 34560, 8640, 8640, 34560, 34560, 270, 34560, 34560, 8640, 270, 34560, 8640, 8640, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 8640, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 34560, 270, 270, 270, 8640, 270, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 34560, 34560, 270, 34560, 34560, 270, 34560, 8640, 34560, 8640, 8640, 8640, 270, 8640, 270, 270, 34560, 270, 8640, 270, 270, 8640, 34560, 8640, 34560, 270, 34560, 34560, 8640, 34560, 8640, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5564160 . Total input tokens: 1239343507 . Total output tokens: 1112626833
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 83.31180047383532,
    "estimated_duration": 3600.0945976402395,
    "input_throughput": 6207.849097812329,
    "output_throughput": 5478.387710402855,
    "total_throughput": 11686.236808215184,
    "itl": 153.29878747661957,
    "ttft": 2108741.1665172013,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 584,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9575225059688044,
    "arrivals": 1853406,
    "finished_requests": 90475,
    "scheduler_time": 175.3514467619756
}
#Debug simulation 
Total elapsed time: 83.31196997920051. Arrivals time: 0.5038517792709172 Scheduler time: 82.64879772579297 Scheduler overhead time: 0.0610261713154614 Adapter cache time: 0.018447681330144405 Engine time: 0.05796450516209006 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-8/adapters_384_slots_64_rate_3.2-0.8-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-8/adapters_384_slots_64_rate_3.2-0.8-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 8640, 135, 34560, 34560, 135, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 135, 34560, 135, 34560, 8640, 8640, 8640, 135, 135, 8640, 135, 34560, 135, 34560, 8640, 34560, 8640, 135, 8640, 34560, 8640, 34560, 135, 34560, 34560, 34560, 34560, 135, 8640, 8640, 8640, 34560, 8640, 135, 8640, 135, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 135, 135, 34560, 8640, 8640, 135, 135, 135, 8640, 135, 8640, 135, 34560, 135, 8640, 34560, 135, 34560, 8640, 135, 34560, 34560, 34560, 34560, 8640, 135, 8640, 34560, 34560, 8640, 135, 135, 34560, 8640, 8640, 135, 135, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 135, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 34560, 135, 135, 135, 8640, 8640, 34560, 135, 135, 34560, 135, 34560, 8640, 135, 34560, 8640, 8640, 135, 34560, 34560, 34560, 135, 8640, 34560, 135, 34560, 8640, 8640, 34560, 34560, 135, 8640, 34560, 135, 8640, 8640, 135, 8640, 135, 8640, 34560, 34560, 8640, 135, 34560, 135, 34560, 8640, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 34560, 135, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 135, 135, 135, 135, 135, 8640, 135, 135, 8640, 34560, 34560, 135, 135, 34560, 135, 135, 135, 8640, 135, 8640, 34560, 34560, 8640, 8640, 135, 34560, 8640, 34560, 135, 8640, 8640, 135, 135, 8640, 135, 34560, 34560, 135, 34560, 34560, 135, 8640, 34560, 135, 135, 8640, 8640, 135, 135, 34560, 34560, 34560, 34560, 8640, 135, 8640, 8640, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 34560, 8640, 8640, 8640, 34560, 135, 8640, 8640, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 8640, 135, 34560, 34560, 34560, 8640, 135, 34560, 34560, 8640, 8640, 34560, 34560, 135, 34560, 34560, 8640, 135, 34560, 8640, 8640, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 8640, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 34560, 135, 135, 135, 8640, 135, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 34560, 34560, 135, 34560, 34560, 135, 34560, 8640, 34560, 8640, 8640, 8640, 135, 8640, 135, 135, 34560, 135, 8640, 135, 135, 8640, 34560, 8640, 34560, 135, 34560, 34560, 8640, 34560, 8640, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 5546880 . Total input tokens: 1235512233 . Total output tokens: 1109175816
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 82.00530010135844,
    "estimated_duration": 3600.1569783144655,
    "input_throughput": 6249.664705046841,
    "output_throughput": 5491.291940624145,
    "total_throughput": 11740.956645670985,
    "itl": 153.48842630336418,
    "ttft": 2103871.042895425,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 541,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6557238694676413,
    "arrivals": 1847695,
    "finished_requests": 90719,
    "scheduler_time": 174.7009713931829
}
#Debug simulation 
Total elapsed time: 82.00547080533579. Arrivals time: 0.5061757708899677 Scheduler time: 81.34239381877705 Scheduler overhead time: 0.05980987520888448 Adapter cache time: 0.01766526699066162 Engine time: 0.05738634569570422 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-16/adapters_384_slots_64_rate_3.2-0.8-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-16/adapters_384_slots_64_rate_3.2-0.8-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 8640, 135, 34560, 34560, 135, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 135, 34560, 135, 34560, 8640, 8640, 8640, 135, 135, 8640, 135, 34560, 135, 34560, 8640, 34560, 8640, 135, 8640, 34560, 8640, 34560, 135, 34560, 34560, 34560, 34560, 135, 8640, 8640, 8640, 34560, 8640, 135, 8640, 135, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 135, 135, 34560, 8640, 8640, 135, 135, 135, 8640, 135, 8640, 135, 34560, 135, 8640, 34560, 135, 34560, 8640, 135, 34560, 34560, 34560, 34560, 8640, 135, 8640, 34560, 34560, 8640, 135, 135, 34560, 8640, 8640, 135, 135, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 135, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 34560, 135, 135, 135, 8640, 8640, 34560, 135, 135, 34560, 135, 34560, 8640, 135, 34560, 8640, 8640, 135, 34560, 34560, 34560, 135, 8640, 34560, 135, 34560, 8640, 8640, 34560, 34560, 135, 8640, 34560, 135, 8640, 8640, 135, 8640, 135, 8640, 34560, 34560, 8640, 135, 34560, 135, 34560, 8640, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 34560, 135, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 135, 135, 135, 135, 135, 8640, 135, 135, 8640, 34560, 34560, 135, 135, 34560, 135, 135, 135, 8640, 135, 8640, 34560, 34560, 8640, 8640, 135, 34560, 8640, 34560, 135, 8640, 8640, 135, 135, 8640, 135, 34560, 34560, 135, 34560, 34560, 135, 8640, 34560, 135, 135, 8640, 8640, 135, 135, 34560, 34560, 34560, 34560, 8640, 135, 8640, 8640, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 34560, 8640, 8640, 8640, 34560, 135, 8640, 8640, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 8640, 135, 34560, 34560, 34560, 8640, 135, 34560, 34560, 8640, 8640, 34560, 34560, 135, 34560, 34560, 8640, 135, 34560, 8640, 8640, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 8640, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 34560, 135, 135, 135, 8640, 135, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 34560, 34560, 135, 34560, 34560, 135, 34560, 8640, 34560, 8640, 8640, 8640, 135, 8640, 135, 135, 34560, 135, 8640, 135, 135, 8640, 34560, 8640, 34560, 135, 34560, 34560, 8640, 34560, 8640, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 5546880 . Total input tokens: 1235512233 . Total output tokens: 1109175816
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 84.22025356302038,
    "estimated_duration": 3600.0242918922795,
    "input_throughput": 6246.50868346776,
    "output_throughput": 5491.628777207029,
    "total_throughput": 11738.13746067479,
    "itl": 153.89464777936286,
    "ttft": 2100084.4523710706,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 547,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7891893510450676,
    "arrivals": 1847695,
    "finished_requests": 90652,
    "scheduler_time": 174.7498445174813
}
#Debug simulation 
Total elapsed time: 84.2204125658609. Arrivals time: 0.5136087336577475 Scheduler time: 83.5462102922611 Scheduler overhead time: 0.06164310034364462 Adapter cache time: 0.01830355217680335 Engine time: 0.05872013419866562 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-32/adapters_384_slots_64_rate_3.2-0.8-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-32/adapters_384_slots_64_rate_3.2-0.8-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 8640, 135, 34560, 34560, 135, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 135, 34560, 135, 34560, 8640, 8640, 8640, 135, 135, 8640, 135, 34560, 135, 34560, 8640, 34560, 8640, 135, 8640, 34560, 8640, 34560, 135, 34560, 34560, 34560, 34560, 135, 8640, 8640, 8640, 34560, 8640, 135, 8640, 135, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 135, 135, 34560, 8640, 8640, 135, 135, 135, 8640, 135, 8640, 135, 34560, 135, 8640, 34560, 135, 34560, 8640, 135, 34560, 34560, 34560, 34560, 8640, 135, 8640, 34560, 34560, 8640, 135, 135, 34560, 8640, 8640, 135, 135, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 135, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 34560, 135, 135, 135, 8640, 8640, 34560, 135, 135, 34560, 135, 34560, 8640, 135, 34560, 8640, 8640, 135, 34560, 34560, 34560, 135, 8640, 34560, 135, 34560, 8640, 8640, 34560, 34560, 135, 8640, 34560, 135, 8640, 8640, 135, 8640, 135, 8640, 34560, 34560, 8640, 135, 34560, 135, 34560, 8640, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 34560, 135, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 135, 135, 135, 135, 135, 8640, 135, 135, 8640, 34560, 34560, 135, 135, 34560, 135, 135, 135, 8640, 135, 8640, 34560, 34560, 8640, 8640, 135, 34560, 8640, 34560, 135, 8640, 8640, 135, 135, 8640, 135, 34560, 34560, 135, 34560, 34560, 135, 8640, 34560, 135, 135, 8640, 8640, 135, 135, 34560, 34560, 34560, 34560, 8640, 135, 8640, 8640, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 34560, 8640, 8640, 8640, 34560, 135, 8640, 8640, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 8640, 135, 34560, 34560, 34560, 8640, 135, 34560, 34560, 8640, 8640, 34560, 34560, 135, 34560, 34560, 8640, 135, 34560, 8640, 8640, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 8640, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 34560, 135, 135, 135, 8640, 135, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 34560, 34560, 135, 34560, 34560, 135, 34560, 8640, 34560, 8640, 8640, 8640, 135, 8640, 135, 135, 34560, 135, 8640, 135, 135, 8640, 34560, 8640, 34560, 135, 34560, 34560, 8640, 34560, 8640, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 5546880 . Total input tokens: 1235512233 . Total output tokens: 1109175816
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 84.20097985910252,
    "estimated_duration": 3600.026721536266,
    "input_throughput": 6246.504467723425,
    "output_throughput": 5491.625070928197,
    "total_throughput": 11738.129538651621,
    "itl": 153.89474655355252,
    "ttft": 2100085.676775387,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 547,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.791609868220996,
    "arrivals": 1847695,
    "finished_requests": 90652,
    "scheduler_time": 174.74985364428065
}
#Debug simulation 
Total elapsed time: 84.20114359818399. Arrivals time: 0.6462728003971279 Scheduler time: 83.39561940915883 Scheduler overhead time: 0.060846110340207815 Adapter cache time: 0.018209805246442556 Engine time: 0.05819328082725406 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-16/adapters_384_slots_64_rate_3.2-0.8-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-16/adapters_384_slots_64_rate_3.2-0.8-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 8640, 135, 34560, 34560, 135, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 135, 34560, 135, 34560, 8640, 8640, 8640, 135, 135, 8640, 135, 34560, 135, 34560, 8640, 34560, 8640, 135, 8640, 34560, 8640, 34560, 135, 34560, 34560, 34560, 34560, 135, 8640, 8640, 8640, 34560, 8640, 135, 8640, 135, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 135, 135, 34560, 8640, 8640, 135, 135, 135, 8640, 135, 8640, 135, 34560, 135, 8640, 34560, 135, 34560, 8640, 135, 34560, 34560, 34560, 34560, 8640, 135, 8640, 34560, 34560, 8640, 135, 135, 34560, 8640, 8640, 135, 135, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 135, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 34560, 135, 135, 135, 8640, 8640, 34560, 135, 135, 34560, 135, 34560, 8640, 135, 34560, 8640, 8640, 135, 34560, 34560, 34560, 135, 8640, 34560, 135, 34560, 8640, 8640, 34560, 34560, 135, 8640, 34560, 135, 8640, 8640, 135, 8640, 135, 8640, 34560, 34560, 8640, 135, 34560, 135, 34560, 8640, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 34560, 135, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 135, 135, 135, 135, 135, 8640, 135, 135, 8640, 34560, 34560, 135, 135, 34560, 135, 135, 135, 8640, 135, 8640, 34560, 34560, 8640, 8640, 135, 34560, 8640, 34560, 135, 8640, 8640, 135, 135, 8640, 135, 34560, 34560, 135, 34560, 34560, 135, 8640, 34560, 135, 135, 8640, 8640, 135, 135, 34560, 34560, 34560, 34560, 8640, 135, 8640, 8640, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 34560, 8640, 8640, 8640, 34560, 135, 8640, 8640, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 8640, 135, 34560, 34560, 34560, 8640, 135, 34560, 34560, 8640, 8640, 34560, 34560, 135, 34560, 34560, 8640, 135, 34560, 8640, 8640, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 8640, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 34560, 135, 135, 135, 8640, 135, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 34560, 34560, 135, 34560, 34560, 135, 34560, 8640, 34560, 8640, 8640, 8640, 135, 8640, 135, 135, 34560, 135, 8640, 135, 135, 8640, 34560, 8640, 34560, 135, 34560, 34560, 8640, 34560, 8640, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 5546880 . Total input tokens: 1235512233 . Total output tokens: 1109175816
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 81.97824125830084,
    "estimated_duration": 3600.0232534999905,
    "input_throughput": 6249.22241214075,
    "output_throughput": 5491.123142268906,
    "total_throughput": 11740.345554409656,
    "itl": 153.48934662910824,
    "ttft": 2103851.1395910988,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 541,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6932073434535337,
    "arrivals": 1847695,
    "finished_requests": 90712,
    "scheduler_time": 174.69293787694656
}
#Debug simulation 
Total elapsed time: 81.97841349430382. Arrivals time: 0.509565579239279 Scheduler time: 81.3107473636046 Scheduler overhead time: 0.060513217467814684 Adapter cache time: 0.01812071166932583 Engine time: 0.0576578127220273 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-32/adapters_384_slots_64_rate_3.2-0.8-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-32/adapters_384_slots_64_rate_3.2-0.8-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 8640, 135, 34560, 34560, 135, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 135, 34560, 135, 34560, 8640, 8640, 8640, 135, 135, 8640, 135, 34560, 135, 34560, 8640, 34560, 8640, 135, 8640, 34560, 8640, 34560, 135, 34560, 34560, 34560, 34560, 135, 8640, 8640, 8640, 34560, 8640, 135, 8640, 135, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 135, 135, 34560, 8640, 8640, 135, 135, 135, 8640, 135, 8640, 135, 34560, 135, 8640, 34560, 135, 34560, 8640, 135, 34560, 34560, 34560, 34560, 8640, 135, 8640, 34560, 34560, 8640, 135, 135, 34560, 8640, 8640, 135, 135, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 135, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 34560, 135, 135, 135, 8640, 8640, 34560, 135, 135, 34560, 135, 34560, 8640, 135, 34560, 8640, 8640, 135, 34560, 34560, 34560, 135, 8640, 34560, 135, 34560, 8640, 8640, 34560, 34560, 135, 8640, 34560, 135, 8640, 8640, 135, 8640, 135, 8640, 34560, 34560, 8640, 135, 34560, 135, 34560, 8640, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 34560, 135, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 135, 135, 135, 135, 135, 8640, 135, 135, 8640, 34560, 34560, 135, 135, 34560, 135, 135, 135, 8640, 135, 8640, 34560, 34560, 8640, 8640, 135, 34560, 8640, 34560, 135, 8640, 8640, 135, 135, 8640, 135, 34560, 34560, 135, 34560, 34560, 135, 8640, 34560, 135, 135, 8640, 8640, 135, 135, 34560, 34560, 34560, 34560, 8640, 135, 8640, 8640, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 34560, 8640, 8640, 8640, 34560, 135, 8640, 8640, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 8640, 135, 34560, 34560, 34560, 8640, 135, 34560, 34560, 8640, 8640, 34560, 34560, 135, 34560, 34560, 8640, 135, 34560, 8640, 8640, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 8640, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 34560, 135, 135, 135, 8640, 135, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 34560, 34560, 135, 34560, 34560, 135, 34560, 8640, 34560, 8640, 8640, 8640, 135, 8640, 135, 135, 34560, 135, 8640, 135, 135, 8640, 34560, 8640, 34560, 135, 34560, 34560, 8640, 34560, 8640, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 5546880 . Total input tokens: 1235512233 . Total output tokens: 1109175816
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 83.32757923426107,
    "estimated_duration": 3600.057260392885,
    "input_throughput": 6250.2780851725565,
    "output_throughput": 5513.657579389103,
    "total_throughput": 11763.935664561659,
    "itl": 153.95273922375262,
    "ttft": 2096691.863377584,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 546,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8113677985779981,
    "arrivals": 1847695,
    "finished_requests": 90726,
    "scheduler_time": 174.95982661726077
}
#Debug simulation 
Total elapsed time: 83.32774652028456. Arrivals time: 0.5125877568498254 Scheduler time: 82.65539669152349 Scheduler overhead time: 0.061389156617224216 Adapter cache time: 0.01815830310806632 Engine time: 0.05801716027781367 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-16/adapters_384_slots_64_rate_3.2-0.8-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-16/adapters_384_slots_64_rate_3.2-0.8-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 8640, 135, 34560, 34560, 135, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 135, 34560, 135, 34560, 8640, 8640, 8640, 135, 135, 8640, 135, 34560, 135, 34560, 8640, 34560, 8640, 135, 8640, 34560, 8640, 34560, 135, 34560, 34560, 34560, 34560, 135, 8640, 8640, 8640, 34560, 8640, 135, 8640, 135, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 135, 135, 34560, 8640, 8640, 135, 135, 135, 8640, 135, 8640, 135, 34560, 135, 8640, 34560, 135, 34560, 8640, 135, 34560, 34560, 34560, 34560, 8640, 135, 8640, 34560, 34560, 8640, 135, 135, 34560, 8640, 8640, 135, 135, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 135, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 34560, 135, 135, 135, 8640, 8640, 34560, 135, 135, 34560, 135, 34560, 8640, 135, 34560, 8640, 8640, 135, 34560, 34560, 34560, 135, 8640, 34560, 135, 34560, 8640, 8640, 34560, 34560, 135, 8640, 34560, 135, 8640, 8640, 135, 8640, 135, 8640, 34560, 34560, 8640, 135, 34560, 135, 34560, 8640, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 34560, 135, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 135, 135, 135, 135, 135, 8640, 135, 135, 8640, 34560, 34560, 135, 135, 34560, 135, 135, 135, 8640, 135, 8640, 34560, 34560, 8640, 8640, 135, 34560, 8640, 34560, 135, 8640, 8640, 135, 135, 8640, 135, 34560, 34560, 135, 34560, 34560, 135, 8640, 34560, 135, 135, 8640, 8640, 135, 135, 34560, 34560, 34560, 34560, 8640, 135, 8640, 8640, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 34560, 8640, 8640, 8640, 34560, 135, 8640, 8640, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 8640, 135, 34560, 34560, 34560, 8640, 135, 34560, 34560, 8640, 8640, 34560, 34560, 135, 34560, 34560, 8640, 135, 34560, 8640, 8640, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 8640, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 34560, 135, 135, 135, 8640, 135, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 34560, 34560, 135, 34560, 34560, 135, 34560, 8640, 34560, 8640, 8640, 8640, 135, 8640, 135, 135, 34560, 135, 8640, 135, 135, 8640, 34560, 8640, 34560, 135, 34560, 34560, 8640, 34560, 8640, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 5546880 . Total input tokens: 1235512233 . Total output tokens: 1109175816
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 82.54451973782852,
    "estimated_duration": 3600.1186553494654,
    "input_throughput": 6249.731232210161,
    "output_throughput": 5491.35039497218,
    "total_throughput": 11741.08162718234,
    "itl": 153.48701817629853,
    "ttft": 2103853.2020751545,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 541,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6176172095420565,
    "arrivals": 1847695,
    "finished_requests": 90719,
    "scheduler_time": 174.7007550880385
}
#Debug simulation 
Total elapsed time: 82.54469341598451. Arrivals time: 0.5075778043828905 Scheduler time: 81.87972969654948 Scheduler overhead time: 0.059764433186501265 Adapter cache time: 0.01790791656821966 Engine time: 0.057771457359194756 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-32/adapters_384_slots_64_rate_3.2-0.8-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-32/adapters_384_slots_64_rate_3.2-0.8-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 8640, 135, 34560, 34560, 135, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 135, 34560, 135, 34560, 8640, 8640, 8640, 135, 135, 8640, 135, 34560, 135, 34560, 8640, 34560, 8640, 135, 8640, 34560, 8640, 34560, 135, 34560, 34560, 34560, 34560, 135, 8640, 8640, 8640, 34560, 8640, 135, 8640, 135, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 135, 135, 34560, 8640, 8640, 135, 135, 135, 8640, 135, 8640, 135, 34560, 135, 8640, 34560, 135, 34560, 8640, 135, 34560, 34560, 34560, 34560, 8640, 135, 8640, 34560, 34560, 8640, 135, 135, 34560, 8640, 8640, 135, 135, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 135, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 34560, 135, 135, 135, 8640, 8640, 34560, 135, 135, 34560, 135, 34560, 8640, 135, 34560, 8640, 8640, 135, 34560, 34560, 34560, 135, 8640, 34560, 135, 34560, 8640, 8640, 34560, 34560, 135, 8640, 34560, 135, 8640, 8640, 135, 8640, 135, 8640, 34560, 34560, 8640, 135, 34560, 135, 34560, 8640, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 34560, 135, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 135, 135, 135, 135, 135, 8640, 135, 135, 8640, 34560, 34560, 135, 135, 34560, 135, 135, 135, 8640, 135, 8640, 34560, 34560, 8640, 8640, 135, 34560, 8640, 34560, 135, 8640, 8640, 135, 135, 8640, 135, 34560, 34560, 135, 34560, 34560, 135, 8640, 34560, 135, 135, 8640, 8640, 135, 135, 34560, 34560, 34560, 34560, 8640, 135, 8640, 8640, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 34560, 8640, 8640, 8640, 34560, 135, 8640, 8640, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 8640, 135, 34560, 34560, 34560, 8640, 135, 34560, 34560, 8640, 8640, 34560, 34560, 135, 34560, 34560, 8640, 135, 34560, 8640, 8640, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 8640, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 34560, 135, 135, 135, 8640, 135, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 34560, 34560, 135, 34560, 34560, 135, 34560, 8640, 34560, 8640, 8640, 8640, 135, 8640, 135, 135, 34560, 135, 8640, 135, 135, 8640, 34560, 8640, 34560, 135, 34560, 34560, 8640, 34560, 8640, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 5546880 . Total input tokens: 1235512233 . Total output tokens: 1109175816
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 83.45592503296211,
    "estimated_duration": 3600.081427220233,
    "input_throughput": 6250.236127957306,
    "output_throughput": 5513.620567001059,
    "total_throughput": 11763.856694958364,
    "itl": 153.95359380828683,
    "ttft": 2096703.0180679604,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 546,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8353867717832284,
    "arrivals": 1847695,
    "finished_requests": 90726,
    "scheduler_time": 174.9599744714101
}
#Debug simulation 
Total elapsed time: 83.4560954561457. Arrivals time: 0.5106337135657668 Scheduler time: 82.7863200288266 Scheduler overhead time: 0.06065035564824939 Adapter cache time: 0.01817000610753894 Engine time: 0.05855804029852152 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-8/adapters_384_slots_64_rate_3.2-0.8-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-8/adapters_384_slots_64_rate_3.2-0.8-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 8640, 66, 34560, 34560, 66, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 66, 34560, 66, 34560, 8640, 8640, 8640, 66, 66, 8640, 66, 34560, 66, 34560, 8640, 34560, 8640, 66, 8640, 34560, 8640, 34560, 66, 34560, 34560, 34560, 34560, 66, 8640, 8640, 8640, 34560, 8640, 66, 8640, 66, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 66, 66, 34560, 8640, 8640, 66, 66, 66, 8640, 66, 8640, 66, 34560, 66, 8640, 34560, 66, 34560, 8640, 66, 34560, 34560, 34560, 34560, 8640, 66, 8640, 34560, 34560, 8640, 66, 66, 34560, 8640, 8640, 66, 66, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 66, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 34560, 66, 66, 66, 8640, 8640, 34560, 66, 66, 34560, 66, 34560, 8640, 66, 34560, 8640, 8640, 66, 34560, 34560, 34560, 66, 8640, 34560, 66, 34560, 8640, 8640, 34560, 34560, 66, 8640, 34560, 66, 8640, 8640, 66, 8640, 66, 8640, 34560, 34560, 8640, 66, 34560, 66, 34560, 8640, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 34560, 66, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 66, 66, 66, 66, 66, 8640, 66, 66, 8640, 34560, 34560, 66, 66, 34560, 66, 66, 66, 8640, 66, 8640, 34560, 34560, 8640, 8640, 66, 34560, 8640, 34560, 66, 8640, 8640, 66, 66, 8640, 66, 34560, 34560, 66, 34560, 34560, 66, 8640, 34560, 66, 66, 8640, 8640, 66, 66, 34560, 34560, 34560, 34560, 8640, 66, 8640, 8640, 66, 66, 66, 66, 66, 66, 66, 66, 8640, 34560, 8640, 8640, 8640, 34560, 66, 8640, 8640, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 8640, 66, 34560, 34560, 34560, 8640, 66, 34560, 34560, 8640, 8640, 34560, 34560, 66, 34560, 34560, 8640, 66, 34560, 8640, 8640, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 8640, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 34560, 66, 66, 66, 8640, 66, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 34560, 34560, 66, 34560, 34560, 66, 34560, 8640, 34560, 8640, 8640, 8640, 66, 8640, 66, 66, 34560, 66, 8640, 66, 66, 8640, 34560, 8640, 34560, 66, 34560, 34560, 8640, 34560, 8640, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 5538048 . Total input tokens: 1233587320 . Total output tokens: 1107392299
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 86.01841077394783,
    "estimated_duration": 3600.1054825561605,
    "input_throughput": 6230.453832167706,
    "output_throughput": 5483.840986231999,
    "total_throughput": 11714.294818399705,
    "itl": 153.43015565256496,
    "ttft": 2113306.874046968,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 522,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.597574602332917,
    "arrivals": 1844823,
    "finished_requests": 90448,
    "scheduler_time": 174.96342479848968
}
#Debug simulation 
Total elapsed time: 86.01857477473095. Arrivals time: 0.9915826190263033 Scheduler time: 84.86991673102602 Scheduler overhead time: 0.0602139956317842 Adapter cache time: 0.01739999372512102 Engine time: 0.057251294143497944 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-16/adapters_384_slots_64_rate_3.2-0.8-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-16/adapters_384_slots_64_rate_3.2-0.8-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 8640, 66, 34560, 34560, 66, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 66, 34560, 66, 34560, 8640, 8640, 8640, 66, 66, 8640, 66, 34560, 66, 34560, 8640, 34560, 8640, 66, 8640, 34560, 8640, 34560, 66, 34560, 34560, 34560, 34560, 66, 8640, 8640, 8640, 34560, 8640, 66, 8640, 66, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 66, 66, 34560, 8640, 8640, 66, 66, 66, 8640, 66, 8640, 66, 34560, 66, 8640, 34560, 66, 34560, 8640, 66, 34560, 34560, 34560, 34560, 8640, 66, 8640, 34560, 34560, 8640, 66, 66, 34560, 8640, 8640, 66, 66, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 66, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 34560, 66, 66, 66, 8640, 8640, 34560, 66, 66, 34560, 66, 34560, 8640, 66, 34560, 8640, 8640, 66, 34560, 34560, 34560, 66, 8640, 34560, 66, 34560, 8640, 8640, 34560, 34560, 66, 8640, 34560, 66, 8640, 8640, 66, 8640, 66, 8640, 34560, 34560, 8640, 66, 34560, 66, 34560, 8640, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 34560, 66, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 66, 66, 66, 66, 66, 8640, 66, 66, 8640, 34560, 34560, 66, 66, 34560, 66, 66, 66, 8640, 66, 8640, 34560, 34560, 8640, 8640, 66, 34560, 8640, 34560, 66, 8640, 8640, 66, 66, 8640, 66, 34560, 34560, 66, 34560, 34560, 66, 8640, 34560, 66, 66, 8640, 8640, 66, 66, 34560, 34560, 34560, 34560, 8640, 66, 8640, 8640, 66, 66, 66, 66, 66, 66, 66, 66, 8640, 34560, 8640, 8640, 8640, 34560, 66, 8640, 8640, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 8640, 66, 34560, 34560, 34560, 8640, 66, 34560, 34560, 8640, 8640, 34560, 34560, 66, 34560, 34560, 8640, 66, 34560, 8640, 8640, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 8640, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 34560, 66, 66, 66, 8640, 66, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 34560, 34560, 66, 34560, 34560, 66, 34560, 8640, 34560, 8640, 8640, 8640, 66, 8640, 66, 66, 34560, 66, 8640, 66, 66, 8640, 34560, 8640, 34560, 66, 34560, 34560, 8640, 34560, 8640, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 5538048 . Total input tokens: 1233587320 . Total output tokens: 1107392299
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 85.31305631389841,
    "estimated_duration": 3600.04193769952,
    "input_throughput": 6229.969924831465,
    "output_throughput": 5483.46528780012,
    "total_throughput": 11713.435212631584,
    "itl": 153.43466705957184,
    "ttft": 2113233.4764812193,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 522,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7062661873037053,
    "arrivals": 1844823,
    "finished_requests": 90441,
    "scheduler_time": 174.95561627051413
}
#Debug simulation 
Total elapsed time: 85.31322495918721. Arrivals time: 0.520135076250881 Scheduler time: 84.63450555037707 Scheduler overhead time: 0.061489753890782595 Adapter cache time: 0.01753301965072751 Engine time: 0.05733954021707177 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-32/adapters_384_slots_64_rate_3.2-0.8-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-32/adapters_384_slots_64_rate_3.2-0.8-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 8640, 66, 34560, 34560, 66, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 66, 34560, 66, 34560, 8640, 8640, 8640, 66, 66, 8640, 66, 34560, 66, 34560, 8640, 34560, 8640, 66, 8640, 34560, 8640, 34560, 66, 34560, 34560, 34560, 34560, 66, 8640, 8640, 8640, 34560, 8640, 66, 8640, 66, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 66, 66, 34560, 8640, 8640, 66, 66, 66, 8640, 66, 8640, 66, 34560, 66, 8640, 34560, 66, 34560, 8640, 66, 34560, 34560, 34560, 34560, 8640, 66, 8640, 34560, 34560, 8640, 66, 66, 34560, 8640, 8640, 66, 66, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 66, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 34560, 66, 66, 66, 8640, 8640, 34560, 66, 66, 34560, 66, 34560, 8640, 66, 34560, 8640, 8640, 66, 34560, 34560, 34560, 66, 8640, 34560, 66, 34560, 8640, 8640, 34560, 34560, 66, 8640, 34560, 66, 8640, 8640, 66, 8640, 66, 8640, 34560, 34560, 8640, 66, 34560, 66, 34560, 8640, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 34560, 66, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 66, 66, 66, 66, 66, 8640, 66, 66, 8640, 34560, 34560, 66, 66, 34560, 66, 66, 66, 8640, 66, 8640, 34560, 34560, 8640, 8640, 66, 34560, 8640, 34560, 66, 8640, 8640, 66, 66, 8640, 66, 34560, 34560, 66, 34560, 34560, 66, 8640, 34560, 66, 66, 8640, 8640, 66, 66, 34560, 34560, 34560, 34560, 8640, 66, 8640, 8640, 66, 66, 66, 66, 66, 66, 66, 66, 8640, 34560, 8640, 8640, 8640, 34560, 66, 8640, 8640, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 8640, 66, 34560, 34560, 34560, 8640, 66, 34560, 34560, 8640, 8640, 34560, 34560, 66, 34560, 34560, 8640, 66, 34560, 8640, 8640, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 8640, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 34560, 66, 66, 66, 8640, 66, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 34560, 34560, 66, 34560, 34560, 66, 34560, 8640, 34560, 8640, 8640, 8640, 66, 8640, 66, 66, 34560, 66, 8640, 66, 66, 8640, 34560, 8640, 34560, 66, 34560, 34560, 8640, 34560, 8640, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 5538048 . Total input tokens: 1233587320 . Total output tokens: 1107392299
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 86.32346552284434,
    "estimated_duration": 3600.0444619670147,
    "input_throughput": 6229.965556521368,
    "output_throughput": 5483.461442921722,
    "total_throughput": 11713.426999443089,
    "itl": 153.4347584261981,
    "ttft": 2113234.494545708,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 522,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7087769471109018,
    "arrivals": 1844823,
    "finished_requests": 90441,
    "scheduler_time": 174.95562977817715
}
#Debug simulation 
Total elapsed time: 86.32363507105038. Arrivals time: 0.5297616198658943 Scheduler time: 85.6379193821922 Scheduler overhead time: 0.05955709610134363 Adapter cache time: 0.01759838778525591 Engine time: 0.05726577714085579 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-16/adapters_384_slots_64_rate_3.2-0.8-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-16/adapters_384_slots_64_rate_3.2-0.8-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 8640, 66, 34560, 34560, 66, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 66, 34560, 66, 34560, 8640, 8640, 8640, 66, 66, 8640, 66, 34560, 66, 34560, 8640, 34560, 8640, 66, 8640, 34560, 8640, 34560, 66, 34560, 34560, 34560, 34560, 66, 8640, 8640, 8640, 34560, 8640, 66, 8640, 66, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 66, 66, 34560, 8640, 8640, 66, 66, 66, 8640, 66, 8640, 66, 34560, 66, 8640, 34560, 66, 34560, 8640, 66, 34560, 34560, 34560, 34560, 8640, 66, 8640, 34560, 34560, 8640, 66, 66, 34560, 8640, 8640, 66, 66, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 66, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 34560, 66, 66, 66, 8640, 8640, 34560, 66, 66, 34560, 66, 34560, 8640, 66, 34560, 8640, 8640, 66, 34560, 34560, 34560, 66, 8640, 34560, 66, 34560, 8640, 8640, 34560, 34560, 66, 8640, 34560, 66, 8640, 8640, 66, 8640, 66, 8640, 34560, 34560, 8640, 66, 34560, 66, 34560, 8640, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 34560, 66, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 66, 66, 66, 66, 66, 8640, 66, 66, 8640, 34560, 34560, 66, 66, 34560, 66, 66, 66, 8640, 66, 8640, 34560, 34560, 8640, 8640, 66, 34560, 8640, 34560, 66, 8640, 8640, 66, 66, 8640, 66, 34560, 34560, 66, 34560, 34560, 66, 8640, 34560, 66, 66, 8640, 8640, 66, 66, 34560, 34560, 34560, 34560, 8640, 66, 8640, 8640, 66, 66, 66, 66, 66, 66, 66, 66, 8640, 34560, 8640, 8640, 8640, 34560, 66, 8640, 8640, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 8640, 66, 34560, 34560, 34560, 8640, 66, 34560, 34560, 8640, 8640, 34560, 34560, 66, 34560, 34560, 8640, 66, 34560, 8640, 8640, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 8640, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 34560, 66, 66, 66, 8640, 66, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 34560, 34560, 66, 34560, 34560, 66, 34560, 8640, 34560, 8640, 8640, 8640, 66, 8640, 66, 66, 34560, 66, 8640, 66, 66, 8640, 34560, 8640, 34560, 66, 34560, 34560, 8640, 34560, 8640, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 5538048 . Total input tokens: 1233587320 . Total output tokens: 1107392299
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 85.58333889907226,
    "estimated_duration": 3600.143371160966,
    "input_throughput": 6230.388261667126,
    "output_throughput": 5483.783273229342,
    "total_throughput": 11714.171534896468,
    "itl": 153.43152749449,
    "ttft": 2113322.8927212646,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 522,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6351706018950725,
    "arrivals": 1844823,
    "finished_requests": 90448,
    "scheduler_time": 174.96371740367658
}
#Debug simulation 
Total elapsed time: 85.583506597206. Arrivals time: 0.5287531218491495 Scheduler time: 84.89730338705704 Scheduler overhead time: 0.06090656295418739 Adapter cache time: 0.017498509027063847 Engine time: 0.057193152606487274 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-32/adapters_384_slots_64_rate_3.2-0.8-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-32/adapters_384_slots_64_rate_3.2-0.8-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 8640, 66, 34560, 34560, 66, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 66, 34560, 66, 34560, 8640, 8640, 8640, 66, 66, 8640, 66, 34560, 66, 34560, 8640, 34560, 8640, 66, 8640, 34560, 8640, 34560, 66, 34560, 34560, 34560, 34560, 66, 8640, 8640, 8640, 34560, 8640, 66, 8640, 66, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 66, 66, 34560, 8640, 8640, 66, 66, 66, 8640, 66, 8640, 66, 34560, 66, 8640, 34560, 66, 34560, 8640, 66, 34560, 34560, 34560, 34560, 8640, 66, 8640, 34560, 34560, 8640, 66, 66, 34560, 8640, 8640, 66, 66, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 66, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 34560, 66, 66, 66, 8640, 8640, 34560, 66, 66, 34560, 66, 34560, 8640, 66, 34560, 8640, 8640, 66, 34560, 34560, 34560, 66, 8640, 34560, 66, 34560, 8640, 8640, 34560, 34560, 66, 8640, 34560, 66, 8640, 8640, 66, 8640, 66, 8640, 34560, 34560, 8640, 66, 34560, 66, 34560, 8640, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 34560, 66, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 66, 66, 66, 66, 66, 8640, 66, 66, 8640, 34560, 34560, 66, 66, 34560, 66, 66, 66, 8640, 66, 8640, 34560, 34560, 8640, 8640, 66, 34560, 8640, 34560, 66, 8640, 8640, 66, 66, 8640, 66, 34560, 34560, 66, 34560, 34560, 66, 8640, 34560, 66, 66, 8640, 8640, 66, 66, 34560, 34560, 34560, 34560, 8640, 66, 8640, 8640, 66, 66, 66, 66, 66, 66, 66, 66, 8640, 34560, 8640, 8640, 8640, 34560, 66, 8640, 8640, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 8640, 66, 34560, 34560, 34560, 8640, 66, 34560, 34560, 8640, 8640, 34560, 34560, 66, 34560, 34560, 8640, 66, 34560, 8640, 8640, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 8640, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 34560, 66, 66, 66, 8640, 66, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 34560, 34560, 66, 34560, 34560, 66, 34560, 8640, 34560, 8640, 8640, 8640, 66, 8640, 66, 66, 34560, 66, 8640, 66, 66, 8640, 34560, 8640, 34560, 66, 34560, 34560, 8640, 34560, 8640, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 5538048 . Total input tokens: 1233587320 . Total output tokens: 1107392299
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 85.99948864988983,
    "estimated_duration": 3600.066421981376,
    "input_throughput": 6229.927554407779,
    "output_throughput": 5483.427994402188,
    "total_throughput": 11713.355548809968,
    "itl": 153.43561123433133,
    "ttft": 2113242.7370615504,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 522,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7306581059470811,
    "arrivals": 1844823,
    "finished_requests": 90441,
    "scheduler_time": 174.95570863372345
}
#Debug simulation 
Total elapsed time: 85.99965082295239. Arrivals time: 1.0009329565800726 Scheduler time: 84.84153688931838 Scheduler overhead time: 0.06017347890883684 Adapter cache time: 0.017432686872780323 Engine time: 0.05754694156348705 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-16/adapters_384_slots_64_rate_3.2-0.8-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-16/adapters_384_slots_64_rate_3.2-0.8-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 8640, 66, 34560, 34560, 66, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 66, 34560, 66, 34560, 8640, 8640, 8640, 66, 66, 8640, 66, 34560, 66, 34560, 8640, 34560, 8640, 66, 8640, 34560, 8640, 34560, 66, 34560, 34560, 34560, 34560, 66, 8640, 8640, 8640, 34560, 8640, 66, 8640, 66, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 66, 66, 34560, 8640, 8640, 66, 66, 66, 8640, 66, 8640, 66, 34560, 66, 8640, 34560, 66, 34560, 8640, 66, 34560, 34560, 34560, 34560, 8640, 66, 8640, 34560, 34560, 8640, 66, 66, 34560, 8640, 8640, 66, 66, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 66, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 34560, 66, 66, 66, 8640, 8640, 34560, 66, 66, 34560, 66, 34560, 8640, 66, 34560, 8640, 8640, 66, 34560, 34560, 34560, 66, 8640, 34560, 66, 34560, 8640, 8640, 34560, 34560, 66, 8640, 34560, 66, 8640, 8640, 66, 8640, 66, 8640, 34560, 34560, 8640, 66, 34560, 66, 34560, 8640, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 34560, 66, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 66, 66, 66, 66, 66, 8640, 66, 66, 8640, 34560, 34560, 66, 66, 34560, 66, 66, 66, 8640, 66, 8640, 34560, 34560, 8640, 8640, 66, 34560, 8640, 34560, 66, 8640, 8640, 66, 66, 8640, 66, 34560, 34560, 66, 34560, 34560, 66, 8640, 34560, 66, 66, 8640, 8640, 66, 66, 34560, 34560, 34560, 34560, 8640, 66, 8640, 8640, 66, 66, 66, 66, 66, 66, 66, 66, 8640, 34560, 8640, 8640, 8640, 34560, 66, 8640, 8640, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 8640, 66, 34560, 34560, 34560, 8640, 66, 34560, 34560, 8640, 8640, 34560, 34560, 66, 34560, 34560, 8640, 66, 34560, 8640, 8640, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 8640, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 34560, 66, 66, 66, 8640, 66, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 34560, 34560, 66, 34560, 34560, 66, 34560, 8640, 34560, 8640, 8640, 8640, 66, 8640, 66, 66, 34560, 66, 8640, 66, 66, 8640, 34560, 8640, 34560, 66, 34560, 34560, 8640, 34560, 8640, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 5538048 . Total input tokens: 1233587320 . Total output tokens: 1107392299
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 86.06098406901583,
    "estimated_duration": 3600.0685318543924,
    "input_throughput": 6230.517780850737,
    "output_throughput": 5483.8972717640745,
    "total_throughput": 11714.415052614811,
    "itl": 153.4287619032476,
    "ttft": 2113292.348263943,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 522,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5608062539389171,
    "arrivals": 1844823,
    "finished_requests": 90448,
    "scheduler_time": 174.96324244503884
}
#Debug simulation 
Total elapsed time: 86.06114924699068. Arrivals time: 0.5253432556055486 Scheduler time: 85.37822429882362 Scheduler overhead time: 0.06066943611949682 Adapter cache time: 0.01729755150154233 Engine time: 0.057205074932426214 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-32/adapters_384_slots_64_rate_3.2-0.8-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-32/adapters_384_slots_64_rate_3.2-0.8-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 8640, 66, 34560, 34560, 66, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 66, 34560, 66, 34560, 8640, 8640, 8640, 66, 66, 8640, 66, 34560, 66, 34560, 8640, 34560, 8640, 66, 8640, 34560, 8640, 34560, 66, 34560, 34560, 34560, 34560, 66, 8640, 8640, 8640, 34560, 8640, 66, 8640, 66, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 66, 66, 34560, 8640, 8640, 66, 66, 66, 8640, 66, 8640, 66, 34560, 66, 8640, 34560, 66, 34560, 8640, 66, 34560, 34560, 34560, 34560, 8640, 66, 8640, 34560, 34560, 8640, 66, 66, 34560, 8640, 8640, 66, 66, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 66, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 34560, 66, 66, 66, 8640, 8640, 34560, 66, 66, 34560, 66, 34560, 8640, 66, 34560, 8640, 8640, 66, 34560, 34560, 34560, 66, 8640, 34560, 66, 34560, 8640, 8640, 34560, 34560, 66, 8640, 34560, 66, 8640, 8640, 66, 8640, 66, 8640, 34560, 34560, 8640, 66, 34560, 66, 34560, 8640, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 34560, 66, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 66, 66, 66, 66, 66, 8640, 66, 66, 8640, 34560, 34560, 66, 66, 34560, 66, 66, 66, 8640, 66, 8640, 34560, 34560, 8640, 8640, 66, 34560, 8640, 34560, 66, 8640, 8640, 66, 66, 8640, 66, 34560, 34560, 66, 34560, 34560, 66, 8640, 34560, 66, 66, 8640, 8640, 66, 66, 34560, 34560, 34560, 34560, 8640, 66, 8640, 8640, 66, 66, 66, 66, 66, 66, 66, 66, 8640, 34560, 8640, 8640, 8640, 34560, 66, 8640, 8640, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 8640, 66, 34560, 34560, 34560, 8640, 66, 34560, 34560, 8640, 8640, 34560, 34560, 66, 34560, 34560, 8640, 66, 34560, 8640, 8640, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 8640, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 34560, 66, 66, 66, 8640, 66, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 34560, 34560, 66, 34560, 34560, 66, 34560, 8640, 34560, 8640, 8640, 8640, 66, 8640, 66, 66, 34560, 66, 8640, 66, 66, 8640, 34560, 8640, 34560, 66, 34560, 34560, 8640, 34560, 8640, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 5538048 . Total input tokens: 1233587320 . Total output tokens: 1107392299
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 85.97350873611867,
    "estimated_duration": 3600.0894489930465,
    "input_throughput": 6229.887706338299,
    "output_throughput": 5483.39292111798,
    "total_throughput": 11713.280627456279,
    "itl": 153.43646214577512,
    "ttft": 2113252.1323604686,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 522,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7535452950745791,
    "arrivals": 1844823,
    "finished_requests": 90441,
    "scheduler_time": 174.95584845628937
}
#Debug simulation 
Total elapsed time: 85.97367399092764. Arrivals time: 0.5312039605341852 Scheduler time: 85.28595815040171 Scheduler overhead time: 0.05957381380721927 Adapter cache time: 0.01761899795383215 Engine time: 0.05743497610092163 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-8/adapters_384_slots_64_rate_3.2-0.8-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-8/adapters_384_slots_64_rate_3.2-0.8-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 8640, 33, 34560, 34560, 33, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 33, 34560, 33, 34560, 8640, 8640, 8640, 33, 33, 8640, 33, 34560, 33, 34560, 8640, 34560, 8640, 33, 8640, 34560, 8640, 34560, 33, 34560, 34560, 34560, 34560, 33, 8640, 8640, 8640, 34560, 8640, 33, 8640, 33, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 33, 33, 34560, 8640, 8640, 33, 33, 33, 8640, 33, 8640, 33, 34560, 33, 8640, 34560, 33, 34560, 8640, 33, 34560, 34560, 34560, 34560, 8640, 33, 8640, 34560, 34560, 8640, 33, 33, 34560, 8640, 8640, 33, 33, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 33, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 34560, 33, 33, 33, 8640, 8640, 34560, 33, 33, 34560, 33, 34560, 8640, 33, 34560, 8640, 8640, 33, 34560, 34560, 34560, 33, 8640, 34560, 33, 34560, 8640, 8640, 34560, 34560, 33, 8640, 34560, 33, 8640, 8640, 33, 8640, 33, 8640, 34560, 34560, 8640, 33, 34560, 33, 34560, 8640, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 34560, 33, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 33, 33, 33, 33, 33, 8640, 33, 33, 8640, 34560, 34560, 33, 33, 34560, 33, 33, 33, 8640, 33, 8640, 34560, 34560, 8640, 8640, 33, 34560, 8640, 34560, 33, 8640, 8640, 33, 33, 8640, 33, 34560, 34560, 33, 34560, 34560, 33, 8640, 34560, 33, 33, 8640, 8640, 33, 33, 34560, 34560, 34560, 34560, 8640, 33, 8640, 8640, 33, 33, 33, 33, 33, 33, 33, 33, 8640, 34560, 8640, 8640, 8640, 34560, 33, 8640, 8640, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 8640, 33, 34560, 34560, 34560, 8640, 33, 34560, 34560, 8640, 8640, 34560, 34560, 33, 34560, 34560, 8640, 33, 34560, 8640, 8640, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 8640, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 34560, 33, 33, 33, 8640, 33, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 34560, 34560, 33, 34560, 34560, 33, 34560, 8640, 34560, 8640, 8640, 8640, 33, 8640, 33, 33, 34560, 33, 8640, 33, 33, 8640, 34560, 8640, 34560, 33, 34560, 34560, 8640, 34560, 8640, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 5533824 . Total input tokens: 1232656559 . Total output tokens: 1106535012
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 86.0437682447955,
    "estimated_duration": 3600.133259035597,
    "input_throughput": 6208.343245046253,
    "output_throughput": 5497.280399365437,
    "total_throughput": 11705.623644411691,
    "itl": 153.79753808052516,
    "ttft": 2110762.7124623614,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 498,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5241228964785283,
    "arrivals": 1843393,
    "finished_requests": 90652,
    "scheduler_time": 175.07958994729276
}
#Debug simulation 
Total elapsed time: 86.04393532080576. Arrivals time: 0.6520192422904074 Scheduler time: 85.23343014763668 Scheduler overhead time: 0.06154155032709241 Adapter cache time: 0.017016249243170023 Engine time: 0.05796984862536192 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-16/adapters_384_slots_64_rate_3.2-0.8-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-16/adapters_384_slots_64_rate_3.2-0.8-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 8640, 33, 34560, 34560, 33, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 33, 34560, 33, 34560, 8640, 8640, 8640, 33, 33, 8640, 33, 34560, 33, 34560, 8640, 34560, 8640, 33, 8640, 34560, 8640, 34560, 33, 34560, 34560, 34560, 34560, 33, 8640, 8640, 8640, 34560, 8640, 33, 8640, 33, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 33, 33, 34560, 8640, 8640, 33, 33, 33, 8640, 33, 8640, 33, 34560, 33, 8640, 34560, 33, 34560, 8640, 33, 34560, 34560, 34560, 34560, 8640, 33, 8640, 34560, 34560, 8640, 33, 33, 34560, 8640, 8640, 33, 33, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 33, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 34560, 33, 33, 33, 8640, 8640, 34560, 33, 33, 34560, 33, 34560, 8640, 33, 34560, 8640, 8640, 33, 34560, 34560, 34560, 33, 8640, 34560, 33, 34560, 8640, 8640, 34560, 34560, 33, 8640, 34560, 33, 8640, 8640, 33, 8640, 33, 8640, 34560, 34560, 8640, 33, 34560, 33, 34560, 8640, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 34560, 33, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 33, 33, 33, 33, 33, 8640, 33, 33, 8640, 34560, 34560, 33, 33, 34560, 33, 33, 33, 8640, 33, 8640, 34560, 34560, 8640, 8640, 33, 34560, 8640, 34560, 33, 8640, 8640, 33, 33, 8640, 33, 34560, 34560, 33, 34560, 34560, 33, 8640, 34560, 33, 33, 8640, 8640, 33, 33, 34560, 34560, 34560, 34560, 8640, 33, 8640, 8640, 33, 33, 33, 33, 33, 33, 33, 33, 8640, 34560, 8640, 8640, 8640, 34560, 33, 8640, 8640, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 8640, 33, 34560, 34560, 34560, 8640, 33, 34560, 34560, 8640, 8640, 34560, 34560, 33, 34560, 34560, 8640, 33, 34560, 8640, 8640, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 8640, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 34560, 33, 33, 33, 8640, 33, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 34560, 34560, 33, 34560, 34560, 33, 34560, 8640, 34560, 8640, 8640, 8640, 33, 8640, 33, 33, 34560, 33, 8640, 33, 33, 8640, 34560, 8640, 34560, 33, 34560, 34560, 8640, 34560, 8640, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 5533824 . Total input tokens: 1232656559 . Total output tokens: 1106535012
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 91.24971022084355,
    "estimated_duration": 3600.065895193597,
    "input_throughput": 6192.801367820822,
    "output_throughput": 5499.646833252002,
    "total_throughput": 11692.448201072824,
    "itl": 154.21505713123014,
    "ttft": 2106323.5665241564,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 436,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4246061428356969,
    "arrivals": 1843393,
    "finished_requests": 90487,
    "scheduler_time": 174.7478671729367
}
#Debug simulation 
Total elapsed time: 91.24987713107839. Arrivals time: 0.5286429841071367 Scheduler time: 90.56174672860652 Scheduler overhead time: 0.061599139124155045 Adapter cache time: 0.016533067915588617 Engine time: 0.05903683044016361 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-32/adapters_384_slots_64_rate_3.2-0.8-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-32/adapters_384_slots_64_rate_3.2-0.8-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 8640, 33, 34560, 34560, 33, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 33, 34560, 33, 34560, 8640, 8640, 8640, 33, 33, 8640, 33, 34560, 33, 34560, 8640, 34560, 8640, 33, 8640, 34560, 8640, 34560, 33, 34560, 34560, 34560, 34560, 33, 8640, 8640, 8640, 34560, 8640, 33, 8640, 33, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 33, 33, 34560, 8640, 8640, 33, 33, 33, 8640, 33, 8640, 33, 34560, 33, 8640, 34560, 33, 34560, 8640, 33, 34560, 34560, 34560, 34560, 8640, 33, 8640, 34560, 34560, 8640, 33, 33, 34560, 8640, 8640, 33, 33, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 33, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 34560, 33, 33, 33, 8640, 8640, 34560, 33, 33, 34560, 33, 34560, 8640, 33, 34560, 8640, 8640, 33, 34560, 34560, 34560, 33, 8640, 34560, 33, 34560, 8640, 8640, 34560, 34560, 33, 8640, 34560, 33, 8640, 8640, 33, 8640, 33, 8640, 34560, 34560, 8640, 33, 34560, 33, 34560, 8640, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 34560, 33, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 33, 33, 33, 33, 33, 8640, 33, 33, 8640, 34560, 34560, 33, 33, 34560, 33, 33, 33, 8640, 33, 8640, 34560, 34560, 8640, 8640, 33, 34560, 8640, 34560, 33, 8640, 8640, 33, 33, 8640, 33, 34560, 34560, 33, 34560, 34560, 33, 8640, 34560, 33, 33, 8640, 8640, 33, 33, 34560, 34560, 34560, 34560, 8640, 33, 8640, 8640, 33, 33, 33, 33, 33, 33, 33, 33, 8640, 34560, 8640, 8640, 8640, 34560, 33, 8640, 8640, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 8640, 33, 34560, 34560, 34560, 8640, 33, 34560, 34560, 8640, 8640, 34560, 34560, 33, 34560, 34560, 8640, 33, 34560, 8640, 8640, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 8640, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 34560, 33, 33, 33, 8640, 33, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 34560, 34560, 33, 34560, 34560, 33, 34560, 8640, 34560, 8640, 8640, 8640, 33, 8640, 33, 33, 34560, 33, 8640, 33, 33, 8640, 34560, 8640, 34560, 33, 34560, 34560, 8640, 34560, 8640, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 5533824 . Total input tokens: 1232656559 . Total output tokens: 1106535012
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 90.03421960910782,
    "estimated_duration": 3600.0681014872803,
    "input_throughput": 6192.797572576356,
    "output_throughput": 5499.643462805742,
    "total_throughput": 11692.441035382099,
    "itl": 154.21514285772972,
    "ttft": 2106324.3977538794,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 436,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4267994764447296,
    "arrivals": 1843393,
    "finished_requests": 90487,
    "scheduler_time": 174.74788013299178
}
#Debug simulation 
Total elapsed time: 90.03438087319955. Arrivals time: 0.5049780607223511 Scheduler time: 89.37198623549193 Scheduler overhead time: 0.061421065125614405 Adapter cache time: 0.016136170364916325 Engine time: 0.05784589145332575 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-16/adapters_384_slots_64_rate_3.2-0.8-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-16/adapters_384_slots_64_rate_3.2-0.8-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 8640, 33, 34560, 34560, 33, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 33, 34560, 33, 34560, 8640, 8640, 8640, 33, 33, 8640, 33, 34560, 33, 34560, 8640, 34560, 8640, 33, 8640, 34560, 8640, 34560, 33, 34560, 34560, 34560, 34560, 33, 8640, 8640, 8640, 34560, 8640, 33, 8640, 33, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 33, 33, 34560, 8640, 8640, 33, 33, 33, 8640, 33, 8640, 33, 34560, 33, 8640, 34560, 33, 34560, 8640, 33, 34560, 34560, 34560, 34560, 8640, 33, 8640, 34560, 34560, 8640, 33, 33, 34560, 8640, 8640, 33, 33, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 33, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 34560, 33, 33, 33, 8640, 8640, 34560, 33, 33, 34560, 33, 34560, 8640, 33, 34560, 8640, 8640, 33, 34560, 34560, 34560, 33, 8640, 34560, 33, 34560, 8640, 8640, 34560, 34560, 33, 8640, 34560, 33, 8640, 8640, 33, 8640, 33, 8640, 34560, 34560, 8640, 33, 34560, 33, 34560, 8640, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 34560, 33, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 33, 33, 33, 33, 33, 8640, 33, 33, 8640, 34560, 34560, 33, 33, 34560, 33, 33, 33, 8640, 33, 8640, 34560, 34560, 8640, 8640, 33, 34560, 8640, 34560, 33, 8640, 8640, 33, 33, 8640, 33, 34560, 34560, 33, 34560, 34560, 33, 8640, 34560, 33, 33, 8640, 8640, 33, 33, 34560, 34560, 34560, 34560, 8640, 33, 8640, 8640, 33, 33, 33, 33, 33, 33, 33, 33, 8640, 34560, 8640, 8640, 8640, 34560, 33, 8640, 8640, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 8640, 33, 34560, 34560, 34560, 8640, 33, 34560, 34560, 8640, 8640, 34560, 34560, 33, 34560, 34560, 8640, 33, 34560, 8640, 8640, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 8640, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 34560, 33, 33, 33, 8640, 33, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 34560, 34560, 33, 34560, 34560, 33, 34560, 8640, 34560, 8640, 8640, 8640, 33, 8640, 33, 33, 34560, 33, 8640, 33, 33, 8640, 34560, 8640, 34560, 33, 34560, 34560, 8640, 34560, 8640, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 5533824 . Total input tokens: 1232656559 . Total output tokens: 1106535012
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 90.36846500914544,
    "estimated_duration": 3600.009566800819,
    "input_throughput": 6192.898264937724,
    "output_throughput": 5499.732884764148,
    "total_throughput": 11692.631149701872,
    "itl": 154.21298671420743,
    "ttft": 2106297.1612268067,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 436,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3686285842093615,
    "arrivals": 1843393,
    "finished_requests": 90487,
    "scheduler_time": 174.74751633877003
}
#Debug simulation 
Total elapsed time: 90.36862309882417. Arrivals time: 0.5066330465488136 Scheduler time: 89.70400797203183 Scheduler overhead time: 0.06174724083393812 Adapter cache time: 0.015722984913736582 Engine time: 0.058185182977467775 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-32/adapters_384_slots_64_rate_3.2-0.8-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-32/adapters_384_slots_64_rate_3.2-0.8-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 8640, 33, 34560, 34560, 33, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 33, 34560, 33, 34560, 8640, 8640, 8640, 33, 33, 8640, 33, 34560, 33, 34560, 8640, 34560, 8640, 33, 8640, 34560, 8640, 34560, 33, 34560, 34560, 34560, 34560, 33, 8640, 8640, 8640, 34560, 8640, 33, 8640, 33, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 33, 33, 34560, 8640, 8640, 33, 33, 33, 8640, 33, 8640, 33, 34560, 33, 8640, 34560, 33, 34560, 8640, 33, 34560, 34560, 34560, 34560, 8640, 33, 8640, 34560, 34560, 8640, 33, 33, 34560, 8640, 8640, 33, 33, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 33, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 34560, 33, 33, 33, 8640, 8640, 34560, 33, 33, 34560, 33, 34560, 8640, 33, 34560, 8640, 8640, 33, 34560, 34560, 34560, 33, 8640, 34560, 33, 34560, 8640, 8640, 34560, 34560, 33, 8640, 34560, 33, 8640, 8640, 33, 8640, 33, 8640, 34560, 34560, 8640, 33, 34560, 33, 34560, 8640, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 34560, 33, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 33, 33, 33, 33, 33, 8640, 33, 33, 8640, 34560, 34560, 33, 33, 34560, 33, 33, 33, 8640, 33, 8640, 34560, 34560, 8640, 8640, 33, 34560, 8640, 34560, 33, 8640, 8640, 33, 33, 8640, 33, 34560, 34560, 33, 34560, 34560, 33, 8640, 34560, 33, 33, 8640, 8640, 33, 33, 34560, 34560, 34560, 34560, 8640, 33, 8640, 8640, 33, 33, 33, 33, 33, 33, 33, 33, 8640, 34560, 8640, 8640, 8640, 34560, 33, 8640, 8640, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 8640, 33, 34560, 34560, 34560, 8640, 33, 34560, 34560, 8640, 8640, 34560, 34560, 33, 34560, 34560, 8640, 33, 34560, 8640, 8640, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 8640, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 34560, 33, 33, 33, 8640, 33, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 34560, 34560, 33, 34560, 34560, 33, 34560, 8640, 34560, 8640, 8640, 8640, 33, 8640, 33, 33, 34560, 33, 8640, 33, 33, 8640, 34560, 8640, 34560, 33, 34560, 34560, 8640, 34560, 8640, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 5533824 . Total input tokens: 1232656559 . Total output tokens: 1106535012
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 89.62785835564137,
    "estimated_duration": 3600.085445848891,
    "input_throughput": 6192.76773713992,
    "output_throughput": 5499.616966822137,
    "total_throughput": 11692.384703962058,
    "itl": 154.21578036925817,
    "ttft": 2106332.530784287,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 436,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4440277451835621,
    "arrivals": 1843393,
    "finished_requests": 90487,
    "scheduler_time": 174.7479962258794
}
#Debug simulation 
Total elapsed time: 89.62801706790924. Arrivals time: 0.6383051094599068 Scheduler time: 88.83230137266219 Scheduler overhead time: 0.06158648570999503 Adapter cache time: 0.015672903507947922 Engine time: 0.05842101247981191 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-16/adapters_384_slots_64_rate_3.2-0.8-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-16/adapters_384_slots_64_rate_3.2-0.8-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 8640, 33, 34560, 34560, 33, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 33, 34560, 33, 34560, 8640, 8640, 8640, 33, 33, 8640, 33, 34560, 33, 34560, 8640, 34560, 8640, 33, 8640, 34560, 8640, 34560, 33, 34560, 34560, 34560, 34560, 33, 8640, 8640, 8640, 34560, 8640, 33, 8640, 33, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 33, 33, 34560, 8640, 8640, 33, 33, 33, 8640, 33, 8640, 33, 34560, 33, 8640, 34560, 33, 34560, 8640, 33, 34560, 34560, 34560, 34560, 8640, 33, 8640, 34560, 34560, 8640, 33, 33, 34560, 8640, 8640, 33, 33, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 33, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 34560, 33, 33, 33, 8640, 8640, 34560, 33, 33, 34560, 33, 34560, 8640, 33, 34560, 8640, 8640, 33, 34560, 34560, 34560, 33, 8640, 34560, 33, 34560, 8640, 8640, 34560, 34560, 33, 8640, 34560, 33, 8640, 8640, 33, 8640, 33, 8640, 34560, 34560, 8640, 33, 34560, 33, 34560, 8640, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 34560, 33, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 33, 33, 33, 33, 33, 8640, 33, 33, 8640, 34560, 34560, 33, 33, 34560, 33, 33, 33, 8640, 33, 8640, 34560, 34560, 8640, 8640, 33, 34560, 8640, 34560, 33, 8640, 8640, 33, 33, 8640, 33, 34560, 34560, 33, 34560, 34560, 33, 8640, 34560, 33, 33, 8640, 8640, 33, 33, 34560, 34560, 34560, 34560, 8640, 33, 8640, 8640, 33, 33, 33, 33, 33, 33, 33, 33, 8640, 34560, 8640, 8640, 8640, 34560, 33, 8640, 8640, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 8640, 33, 34560, 34560, 34560, 8640, 33, 34560, 34560, 8640, 8640, 34560, 34560, 33, 34560, 34560, 8640, 33, 34560, 8640, 8640, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 8640, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 34560, 33, 33, 33, 8640, 33, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 34560, 34560, 33, 34560, 34560, 33, 34560, 8640, 34560, 8640, 8640, 8640, 33, 8640, 33, 33, 34560, 33, 8640, 33, 33, 8640, 34560, 8640, 34560, 33, 34560, 34560, 8640, 34560, 8640, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 5533824 . Total input tokens: 1232656559 . Total output tokens: 1106535012
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 84.73702195379883,
    "estimated_duration": 3600.0979756505258,
    "input_throughput": 6208.404090991794,
    "output_throughput": 5497.334276416142,
    "total_throughput": 11705.738367407936,
    "itl": 153.79624392305095,
    "ttft": 2110748.0984426155,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 498,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4890450468612675,
    "arrivals": 1843393,
    "finished_requests": 90652,
    "scheduler_time": 175.07938441177157
}
#Debug simulation 
Total elapsed time: 84.73717588419095. Arrivals time: 0.46824152721092105 Scheduler time: 84.11614873027429 Scheduler overhead time: 0.05949334427714348 Adapter cache time: 0.016048879362642765 Engine time: 0.05621326342225075 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-32/adapters_384_slots_64_rate_3.2-0.8-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-32/adapters_384_slots_64_rate_3.2-0.8-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 8640, 33, 34560, 34560, 33, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 33, 34560, 33, 34560, 8640, 8640, 8640, 33, 33, 8640, 33, 34560, 33, 34560, 8640, 34560, 8640, 33, 8640, 34560, 8640, 34560, 33, 34560, 34560, 34560, 34560, 33, 8640, 8640, 8640, 34560, 8640, 33, 8640, 33, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 33, 33, 34560, 8640, 8640, 33, 33, 33, 8640, 33, 8640, 33, 34560, 33, 8640, 34560, 33, 34560, 8640, 33, 34560, 34560, 34560, 34560, 8640, 33, 8640, 34560, 34560, 8640, 33, 33, 34560, 8640, 8640, 33, 33, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 33, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 34560, 33, 33, 33, 8640, 8640, 34560, 33, 33, 34560, 33, 34560, 8640, 33, 34560, 8640, 8640, 33, 34560, 34560, 34560, 33, 8640, 34560, 33, 34560, 8640, 8640, 34560, 34560, 33, 8640, 34560, 33, 8640, 8640, 33, 8640, 33, 8640, 34560, 34560, 8640, 33, 34560, 33, 34560, 8640, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 34560, 33, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 33, 33, 33, 33, 33, 8640, 33, 33, 8640, 34560, 34560, 33, 33, 34560, 33, 33, 33, 8640, 33, 8640, 34560, 34560, 8640, 8640, 33, 34560, 8640, 34560, 33, 8640, 8640, 33, 33, 8640, 33, 34560, 34560, 33, 34560, 34560, 33, 8640, 34560, 33, 33, 8640, 8640, 33, 33, 34560, 34560, 34560, 34560, 8640, 33, 8640, 8640, 33, 33, 33, 33, 33, 33, 33, 33, 8640, 34560, 8640, 8640, 8640, 34560, 33, 8640, 8640, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 8640, 33, 34560, 34560, 34560, 8640, 33, 34560, 34560, 8640, 8640, 34560, 34560, 33, 34560, 34560, 8640, 33, 34560, 8640, 8640, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 8640, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 34560, 33, 33, 33, 8640, 33, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 34560, 34560, 33, 34560, 34560, 33, 34560, 8640, 34560, 8640, 8640, 8640, 33, 8640, 33, 33, 34560, 33, 8640, 33, 33, 8640, 34560, 8640, 34560, 33, 34560, 34560, 8640, 34560, 8640, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 5533824 . Total input tokens: 1232656559 . Total output tokens: 1106535012
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 88.38496417924762,
    "estimated_duration": 3600.0070214970956,
    "input_throughput": 6192.780143725613,
    "output_throughput": 5499.677606674905,
    "total_throughput": 11692.457750400517,
    "itl": 154.21665542219603,
    "ttft": 2106343.9707083525,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 436,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.464022597223521,
    "arrivals": 1843393,
    "finished_requests": 90486,
    "scheduler_time": 174.74187968647428
}
#Debug simulation 
Total elapsed time: 88.38511660508811. Arrivals time: 0.5608535832725465 Scheduler time: 87.67666228627786 Scheduler overhead time: 0.05744916433468461 Adapter cache time: 0.014829293824732304 Engine time: 0.05459981178864837 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-8/adapters_384_slots_64_rate_3.2-0.4-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-8/adapters_384_slots_64_rate_3.2-0.4-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 34560, 4320, 1080, 34560, 34560, 1080, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 1080, 34560, 1080, 34560, 4320, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 1080, 34560, 4320, 34560, 4320, 1080, 4320, 34560, 4320, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 4320, 4320, 4320, 34560, 4320, 1080, 4320, 1080, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 1080, 1080, 34560, 4320, 4320, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 34560, 1080, 4320, 34560, 1080, 34560, 4320, 1080, 34560, 34560, 34560, 34560, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 1080, 34560, 4320, 4320, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 4320, 4320, 34560, 1080, 1080, 34560, 1080, 34560, 4320, 1080, 34560, 4320, 4320, 1080, 34560, 34560, 34560, 1080, 4320, 34560, 1080, 34560, 4320, 4320, 34560, 34560, 1080, 4320, 34560, 1080, 4320, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 34560, 1080, 34560, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 34560, 1080, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 1080, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 1080, 34560, 1080, 1080, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 34560, 1080, 34560, 34560, 1080, 4320, 34560, 1080, 1080, 4320, 4320, 1080, 1080, 34560, 34560, 34560, 34560, 4320, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 34560, 4320, 4320, 4320, 34560, 1080, 4320, 4320, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 1080, 1080, 4320, 1080, 34560, 34560, 34560, 4320, 1080, 34560, 34560, 4320, 4320, 34560, 34560, 1080, 34560, 34560, 4320, 1080, 34560, 4320, 4320, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 34560, 1080, 4320, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 1080, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 4320, 34560, 4320, 4320, 4320, 1080, 4320, 1080, 1080, 34560, 1080, 4320, 1080, 1080, 4320, 34560, 4320, 34560, 1080, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5114880 . Total input tokens: 1139568477 . Total output tokens: 1022716391
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 78.00367650995031,
    "estimated_duration": 3600.1202751966853,
    "input_throughput": 6132.955377107154,
    "output_throughput": 5406.173269846293,
    "total_throughput": 11539.128646953448,
    "itl": 148.70943468504373,
    "ttft": 2108939.2122439845,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 506,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5486067984299912,
    "arrivals": 1703822,
    "finished_requests": 88985,
    "scheduler_time": 179.0403550408624
}
#Debug simulation 
Total elapsed time: 78.00382887385786. Arrivals time: 0.41483293008059263 Scheduler time: 77.4392110183835 Scheduler overhead time: 0.057880965527147055 Adapter cache time: 0.015842854510992765 Engine time: 0.05496963998302817 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-16/adapters_384_slots_64_rate_3.2-0.4-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-16/adapters_384_slots_64_rate_3.2-0.4-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 34560, 4320, 1080, 34560, 34560, 1080, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 1080, 34560, 1080, 34560, 4320, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 1080, 34560, 4320, 34560, 4320, 1080, 4320, 34560, 4320, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 4320, 4320, 4320, 34560, 4320, 1080, 4320, 1080, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 1080, 1080, 34560, 4320, 4320, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 34560, 1080, 4320, 34560, 1080, 34560, 4320, 1080, 34560, 34560, 34560, 34560, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 1080, 34560, 4320, 4320, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 4320, 4320, 34560, 1080, 1080, 34560, 1080, 34560, 4320, 1080, 34560, 4320, 4320, 1080, 34560, 34560, 34560, 1080, 4320, 34560, 1080, 34560, 4320, 4320, 34560, 34560, 1080, 4320, 34560, 1080, 4320, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 34560, 1080, 34560, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 34560, 1080, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 1080, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 1080, 34560, 1080, 1080, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 34560, 1080, 34560, 34560, 1080, 4320, 34560, 1080, 1080, 4320, 4320, 1080, 1080, 34560, 34560, 34560, 34560, 4320, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 34560, 4320, 4320, 4320, 34560, 1080, 4320, 4320, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 1080, 1080, 4320, 1080, 34560, 34560, 34560, 4320, 1080, 34560, 34560, 4320, 4320, 34560, 34560, 1080, 34560, 34560, 4320, 1080, 34560, 4320, 4320, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 34560, 1080, 4320, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 1080, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 4320, 34560, 4320, 4320, 4320, 1080, 4320, 1080, 1080, 34560, 1080, 4320, 1080, 1080, 4320, 34560, 4320, 34560, 1080, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5114880 . Total input tokens: 1139568477 . Total output tokens: 1022716391
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 77.52621724503115,
    "estimated_duration": 3600.04813469521,
    "input_throughput": 6132.936331383041,
    "output_throughput": 5406.070216793842,
    "total_throughput": 11539.006548176882,
    "itl": 148.71280754361044,
    "ttft": 2108947.609218668,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 506,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6502534762164631,
    "arrivals": 1703822,
    "finished_requests": 88982,
    "scheduler_time": 179.03252739250053
}
#Debug simulation 
Total elapsed time: 77.52637310372666. Arrivals time: 0.4241309673525393 Scheduler time: 76.94980041030794 Scheduler overhead time: 0.05944636557251215 Adapter cache time: 0.01623245095834136 Engine time: 0.05555929662659764 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-32/adapters_384_slots_64_rate_3.2-0.4-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-32/adapters_384_slots_64_rate_3.2-0.4-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 34560, 4320, 1080, 34560, 34560, 1080, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 1080, 34560, 1080, 34560, 4320, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 1080, 34560, 4320, 34560, 4320, 1080, 4320, 34560, 4320, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 4320, 4320, 4320, 34560, 4320, 1080, 4320, 1080, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 1080, 1080, 34560, 4320, 4320, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 34560, 1080, 4320, 34560, 1080, 34560, 4320, 1080, 34560, 34560, 34560, 34560, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 1080, 34560, 4320, 4320, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 4320, 4320, 34560, 1080, 1080, 34560, 1080, 34560, 4320, 1080, 34560, 4320, 4320, 1080, 34560, 34560, 34560, 1080, 4320, 34560, 1080, 34560, 4320, 4320, 34560, 34560, 1080, 4320, 34560, 1080, 4320, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 34560, 1080, 34560, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 34560, 1080, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 1080, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 1080, 34560, 1080, 1080, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 34560, 1080, 34560, 34560, 1080, 4320, 34560, 1080, 1080, 4320, 4320, 1080, 1080, 34560, 34560, 34560, 34560, 4320, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 34560, 4320, 4320, 4320, 34560, 1080, 4320, 4320, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 1080, 1080, 4320, 1080, 34560, 34560, 34560, 4320, 1080, 34560, 34560, 4320, 4320, 34560, 34560, 1080, 34560, 34560, 4320, 1080, 34560, 4320, 4320, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 34560, 1080, 4320, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 1080, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 4320, 34560, 4320, 4320, 4320, 1080, 4320, 1080, 1080, 34560, 1080, 4320, 1080, 1080, 4320, 34560, 4320, 34560, 1080, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5114880 . Total input tokens: 1139568477 . Total output tokens: 1022716391
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 77.63932074606419,
    "estimated_duration": 3600.0512353508025,
    "input_throughput": 6132.931049201735,
    "output_throughput": 5406.065560648483,
    "total_throughput": 11538.99660985022,
    "itl": 148.7128980952622,
    "ttft": 2108948.779634404,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 506,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6533356956392626,
    "arrivals": 1703822,
    "finished_requests": 88982,
    "scheduler_time": 179.0325458286352
}
#Debug simulation 
Total elapsed time: 77.63947581592947. Arrivals time: 0.42461452446877956 Scheduler time: 77.06294149998575 Scheduler overhead time: 0.05888692708685994 Adapter cache time: 0.016221131198108196 Engine time: 0.055268827360123396 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-16-16/adapters_384_slots_64_rate_3.2-0.4-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-16-16/adapters_384_slots_64_rate_3.2-0.4-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 34560, 4320, 1080, 34560, 34560, 1080, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 1080, 34560, 1080, 34560, 4320, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 1080, 34560, 4320, 34560, 4320, 1080, 4320, 34560, 4320, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 4320, 4320, 4320, 34560, 4320, 1080, 4320, 1080, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 1080, 1080, 34560, 4320, 4320, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 34560, 1080, 4320, 34560, 1080, 34560, 4320, 1080, 34560, 34560, 34560, 34560, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 1080, 34560, 4320, 4320, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 4320, 4320, 34560, 1080, 1080, 34560, 1080, 34560, 4320, 1080, 34560, 4320, 4320, 1080, 34560, 34560, 34560, 1080, 4320, 34560, 1080, 34560, 4320, 4320, 34560, 34560, 1080, 4320, 34560, 1080, 4320, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 34560, 1080, 34560, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 34560, 1080, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 1080, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 1080, 34560, 1080, 1080, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 34560, 1080, 34560, 34560, 1080, 4320, 34560, 1080, 1080, 4320, 4320, 1080, 1080, 34560, 34560, 34560, 34560, 4320, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 34560, 4320, 4320, 4320, 34560, 1080, 4320, 4320, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 1080, 1080, 4320, 1080, 34560, 34560, 34560, 4320, 1080, 34560, 34560, 4320, 4320, 34560, 34560, 1080, 34560, 34560, 4320, 1080, 34560, 4320, 4320, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 34560, 1080, 4320, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 1080, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 4320, 34560, 4320, 4320, 4320, 1080, 4320, 1080, 1080, 34560, 1080, 4320, 1080, 1080, 4320, 34560, 4320, 34560, 1080, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5114880 . Total input tokens: 1139568477 . Total output tokens: 1022716391
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 77.76028329925612,
    "estimated_duration": 3600.154264079987,
    "input_throughput": 6132.897476170328,
    "output_throughput": 5406.122230424396,
    "total_throughput": 11539.019706594725,
    "itl": 148.71058135207974,
    "ttft": 2108953.2114950437,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 506,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5824266533553537,
    "arrivals": 1703822,
    "finished_requests": 88985,
    "scheduler_time": 179.0405240691862
}
#Debug simulation 
Total elapsed time: 77.76043976424262. Arrivals time: 0.43176778173074126 Scheduler time: 77.17814218904823 Scheduler overhead time: 0.059032962657511234 Adapter cache time: 0.016386730130761862 Engine time: 0.05383670702576637 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-16-32/adapters_384_slots_64_rate_3.2-0.4-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-16-32/adapters_384_slots_64_rate_3.2-0.4-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 34560, 4320, 1080, 34560, 34560, 1080, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 1080, 34560, 1080, 34560, 4320, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 1080, 34560, 4320, 34560, 4320, 1080, 4320, 34560, 4320, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 4320, 4320, 4320, 34560, 4320, 1080, 4320, 1080, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 1080, 1080, 34560, 4320, 4320, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 34560, 1080, 4320, 34560, 1080, 34560, 4320, 1080, 34560, 34560, 34560, 34560, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 1080, 34560, 4320, 4320, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 4320, 4320, 34560, 1080, 1080, 34560, 1080, 34560, 4320, 1080, 34560, 4320, 4320, 1080, 34560, 34560, 34560, 1080, 4320, 34560, 1080, 34560, 4320, 4320, 34560, 34560, 1080, 4320, 34560, 1080, 4320, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 34560, 1080, 34560, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 34560, 1080, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 1080, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 1080, 34560, 1080, 1080, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 34560, 1080, 34560, 34560, 1080, 4320, 34560, 1080, 1080, 4320, 4320, 1080, 1080, 34560, 34560, 34560, 34560, 4320, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 34560, 4320, 4320, 4320, 34560, 1080, 4320, 4320, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 1080, 1080, 4320, 1080, 34560, 34560, 34560, 4320, 1080, 34560, 34560, 4320, 4320, 34560, 34560, 1080, 34560, 34560, 4320, 1080, 34560, 4320, 4320, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 34560, 1080, 4320, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 1080, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 4320, 34560, 4320, 4320, 4320, 1080, 4320, 1080, 1080, 34560, 1080, 4320, 1080, 1080, 4320, 34560, 4320, 34560, 1080, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5114880 . Total input tokens: 1139568477 . Total output tokens: 1022716391
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 78.0947924903594,
    "estimated_duration": 3600.0722325958895,
    "input_throughput": 6132.895279181574,
    "output_throughput": 5406.034030035707,
    "total_throughput": 11538.929309217281,
    "itl": 148.7135377447588,
    "ttft": 2108956.9913085527,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 506,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6742108241841236,
    "arrivals": 1703822,
    "finished_requests": 88982,
    "scheduler_time": 179.0326679452104
}
#Debug simulation 
Total elapsed time: 78.09494545822963. Arrivals time: 0.43565648375079036 Scheduler time: 77.50825804192573 Scheduler overhead time: 0.059264179319143295 Adapter cache time: 0.015988668892532587 Engine time: 0.05411547748371959 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_16-16-16/adapters_384_slots_64_rate_3.2-0.4-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_16-16-16/adapters_384_slots_64_rate_3.2-0.4-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 34560, 4320, 1080, 34560, 34560, 1080, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 1080, 34560, 1080, 34560, 4320, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 1080, 34560, 4320, 34560, 4320, 1080, 4320, 34560, 4320, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 4320, 4320, 4320, 34560, 4320, 1080, 4320, 1080, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 1080, 1080, 34560, 4320, 4320, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 34560, 1080, 4320, 34560, 1080, 34560, 4320, 1080, 34560, 34560, 34560, 34560, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 1080, 34560, 4320, 4320, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 4320, 4320, 34560, 1080, 1080, 34560, 1080, 34560, 4320, 1080, 34560, 4320, 4320, 1080, 34560, 34560, 34560, 1080, 4320, 34560, 1080, 34560, 4320, 4320, 34560, 34560, 1080, 4320, 34560, 1080, 4320, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 34560, 1080, 34560, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 34560, 1080, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 1080, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 1080, 34560, 1080, 1080, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 34560, 1080, 34560, 34560, 1080, 4320, 34560, 1080, 1080, 4320, 4320, 1080, 1080, 34560, 34560, 34560, 34560, 4320, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 34560, 4320, 4320, 4320, 34560, 1080, 4320, 4320, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 1080, 1080, 4320, 1080, 34560, 34560, 34560, 4320, 1080, 34560, 34560, 4320, 4320, 34560, 34560, 1080, 34560, 34560, 4320, 1080, 34560, 4320, 4320, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 34560, 1080, 4320, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 1080, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 4320, 34560, 4320, 4320, 4320, 1080, 4320, 1080, 1080, 34560, 1080, 4320, 1080, 1080, 4320, 34560, 4320, 34560, 1080, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5114880 . Total input tokens: 1139568477 . Total output tokens: 1022716391
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 77.86554653616622,
    "estimated_duration": 3600.084428494563,
    "input_throughput": 6133.016444070694,
    "output_throughput": 5406.227100106854,
    "total_throughput": 11539.243544177547,
    "itl": 148.70831616094142,
    "ttft": 2108925.0520756105,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 506,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.512965449220484,
    "arrivals": 1703822,
    "finished_requests": 88985,
    "scheduler_time": 179.0401496878772
}
#Debug simulation 
Total elapsed time: 77.8656987552531. Arrivals time: 0.430737373419106 Scheduler time: 77.28511022822931 Scheduler overhead time: 0.05869873287156224 Adapter cache time: 0.01615687320008874 Engine time: 0.05375187983736396 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_16-16-32/adapters_384_slots_64_rate_3.2-0.4-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_16-16-32/adapters_384_slots_64_rate_3.2-0.4-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 34560, 4320, 1080, 34560, 34560, 1080, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 1080, 34560, 1080, 34560, 4320, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 1080, 34560, 4320, 34560, 4320, 1080, 4320, 34560, 4320, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 4320, 4320, 4320, 34560, 4320, 1080, 4320, 1080, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 1080, 1080, 34560, 4320, 4320, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 34560, 1080, 4320, 34560, 1080, 34560, 4320, 1080, 34560, 34560, 34560, 34560, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 1080, 34560, 4320, 4320, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 4320, 4320, 34560, 1080, 1080, 34560, 1080, 34560, 4320, 1080, 34560, 4320, 4320, 1080, 34560, 34560, 34560, 1080, 4320, 34560, 1080, 34560, 4320, 4320, 34560, 34560, 1080, 4320, 34560, 1080, 4320, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 34560, 1080, 34560, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 34560, 1080, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 1080, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 1080, 34560, 1080, 1080, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 34560, 1080, 34560, 34560, 1080, 4320, 34560, 1080, 1080, 4320, 4320, 1080, 1080, 34560, 34560, 34560, 34560, 4320, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 34560, 4320, 4320, 4320, 34560, 1080, 4320, 4320, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 1080, 1080, 4320, 1080, 34560, 34560, 34560, 4320, 1080, 34560, 34560, 4320, 4320, 34560, 34560, 1080, 34560, 34560, 4320, 1080, 34560, 4320, 4320, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 34560, 1080, 4320, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 1080, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 4320, 34560, 4320, 4320, 4320, 1080, 4320, 1080, 1080, 34560, 1080, 4320, 1080, 1080, 4320, 34560, 4320, 34560, 1080, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5114880 . Total input tokens: 1139568477 . Total output tokens: 1022716391
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 77.92066317005083,
    "estimated_duration": 3600.0937246420035,
    "input_throughput": 6132.858666671391,
    "output_throughput": 5406.001756783521,
    "total_throughput": 11538.860423454911,
    "itl": 148.71423472385666,
    "ttft": 2108965.656678306,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 506,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6955889678746445,
    "arrivals": 1703822,
    "finished_requests": 88982,
    "scheduler_time": 179.03278184766617
}
#Debug simulation 
Total elapsed time: 77.92081770813093. Arrivals time: 0.431610781699419 Scheduler time: 77.34017192339525 Scheduler overhead time: 0.05779202561825514 Adapter cache time: 0.01618227455765009 Engine time: 0.05368036637082696 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-8/adapters_384_slots_64_rate_3.2-0.4-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-8/adapters_384_slots_64_rate_3.2-0.4-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 4320, 540, 34560, 34560, 540, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 540, 34560, 540, 34560, 4320, 4320, 4320, 540, 540, 4320, 540, 34560, 540, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 34560, 540, 34560, 34560, 34560, 34560, 540, 4320, 4320, 4320, 34560, 4320, 540, 4320, 540, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 540, 540, 34560, 4320, 4320, 540, 540, 540, 4320, 540, 4320, 540, 34560, 540, 4320, 34560, 540, 34560, 4320, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 34560, 34560, 4320, 540, 540, 34560, 4320, 4320, 540, 540, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 540, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 34560, 540, 540, 540, 4320, 4320, 34560, 540, 540, 34560, 540, 34560, 4320, 540, 34560, 4320, 4320, 540, 34560, 34560, 34560, 540, 4320, 34560, 540, 34560, 4320, 4320, 34560, 34560, 540, 4320, 34560, 540, 4320, 4320, 540, 4320, 540, 4320, 34560, 34560, 4320, 540, 34560, 540, 34560, 4320, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 34560, 540, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 540, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 540, 540, 540, 540, 540, 4320, 540, 540, 4320, 34560, 34560, 540, 540, 34560, 540, 540, 540, 4320, 540, 4320, 34560, 34560, 4320, 4320, 540, 34560, 4320, 34560, 540, 4320, 4320, 540, 540, 4320, 540, 34560, 34560, 540, 34560, 34560, 540, 4320, 34560, 540, 540, 4320, 4320, 540, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 4320, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 34560, 4320, 4320, 4320, 34560, 540, 4320, 4320, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 4320, 540, 34560, 34560, 34560, 4320, 540, 34560, 34560, 4320, 4320, 34560, 34560, 540, 34560, 34560, 4320, 540, 34560, 4320, 4320, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 4320, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 34560, 540, 540, 540, 4320, 540, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 34560, 34560, 540, 34560, 34560, 540, 34560, 4320, 34560, 4320, 4320, 4320, 540, 4320, 540, 540, 34560, 540, 4320, 540, 540, 4320, 34560, 4320, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5045760 . Total input tokens: 1124027934 . Total output tokens: 1008922740
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 74.10085960989818,
    "estimated_duration": 3600.053770237559,
    "input_throughput": 6170.812553873068,
    "output_throughput": 5456.795440781344,
    "total_throughput": 11627.607994654412,
    "itl": 152.3442162555882,
    "ttft": 2106261.473902422,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 510,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5608487494057226,
    "arrivals": 1680953,
    "finished_requests": 89674,
    "scheduler_time": 176.3882405346809
}
#Debug simulation 
Total elapsed time: 74.10098728863522. Arrivals time: 0.4368687281385064 Scheduler time: 73.51660952623934 Scheduler overhead time: 0.05757518205791712 Adapter cache time: 0.015957048628479242 Engine time: 0.052862797398120165 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-16/adapters_384_slots_64_rate_3.2-0.4-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-16/adapters_384_slots_64_rate_3.2-0.4-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 4320, 540, 34560, 34560, 540, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 540, 34560, 540, 34560, 4320, 4320, 4320, 540, 540, 4320, 540, 34560, 540, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 34560, 540, 34560, 34560, 34560, 34560, 540, 4320, 4320, 4320, 34560, 4320, 540, 4320, 540, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 540, 540, 34560, 4320, 4320, 540, 540, 540, 4320, 540, 4320, 540, 34560, 540, 4320, 34560, 540, 34560, 4320, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 34560, 34560, 4320, 540, 540, 34560, 4320, 4320, 540, 540, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 540, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 34560, 540, 540, 540, 4320, 4320, 34560, 540, 540, 34560, 540, 34560, 4320, 540, 34560, 4320, 4320, 540, 34560, 34560, 34560, 540, 4320, 34560, 540, 34560, 4320, 4320, 34560, 34560, 540, 4320, 34560, 540, 4320, 4320, 540, 4320, 540, 4320, 34560, 34560, 4320, 540, 34560, 540, 34560, 4320, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 34560, 540, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 540, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 540, 540, 540, 540, 540, 4320, 540, 540, 4320, 34560, 34560, 540, 540, 34560, 540, 540, 540, 4320, 540, 4320, 34560, 34560, 4320, 4320, 540, 34560, 4320, 34560, 540, 4320, 4320, 540, 540, 4320, 540, 34560, 34560, 540, 34560, 34560, 540, 4320, 34560, 540, 540, 4320, 4320, 540, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 4320, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 34560, 4320, 4320, 4320, 34560, 540, 4320, 4320, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 4320, 540, 34560, 34560, 34560, 4320, 540, 34560, 34560, 4320, 4320, 34560, 34560, 540, 34560, 34560, 4320, 540, 34560, 4320, 4320, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 4320, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 34560, 540, 540, 540, 4320, 540, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 34560, 34560, 540, 34560, 34560, 540, 34560, 4320, 34560, 4320, 4320, 4320, 540, 4320, 540, 540, 34560, 540, 4320, 540, 540, 4320, 34560, 4320, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5045760 . Total input tokens: 1124027934 . Total output tokens: 1008922740
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 78.77640453306958,
    "estimated_duration": 3600.0532066044875,
    "input_throughput": 6178.261465468274,
    "output_throughput": 5462.573987496212,
    "total_throughput": 11640.835452964486,
    "itl": 152.68839045572398,
    "ttft": 2106665.6183858793,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 506,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6527050481271053,
    "arrivals": 1680953,
    "finished_requests": 89774,
    "scheduler_time": 176.1424195396266
}
#Debug simulation 
Total elapsed time: 78.77652898617089. Arrivals time: 0.4365694997832179 Scheduler time: 78.18945435946807 Scheduler overhead time: 0.058368530590087175 Adapter cache time: 0.016199149657040834 Engine time: 0.05489590251818299 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-32/adapters_384_slots_64_rate_3.2-0.4-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-32/adapters_384_slots_64_rate_3.2-0.4-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 4320, 540, 34560, 34560, 540, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 540, 34560, 540, 34560, 4320, 4320, 4320, 540, 540, 4320, 540, 34560, 540, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 34560, 540, 34560, 34560, 34560, 34560, 540, 4320, 4320, 4320, 34560, 4320, 540, 4320, 540, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 540, 540, 34560, 4320, 4320, 540, 540, 540, 4320, 540, 4320, 540, 34560, 540, 4320, 34560, 540, 34560, 4320, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 34560, 34560, 4320, 540, 540, 34560, 4320, 4320, 540, 540, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 540, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 34560, 540, 540, 540, 4320, 4320, 34560, 540, 540, 34560, 540, 34560, 4320, 540, 34560, 4320, 4320, 540, 34560, 34560, 34560, 540, 4320, 34560, 540, 34560, 4320, 4320, 34560, 34560, 540, 4320, 34560, 540, 4320, 4320, 540, 4320, 540, 4320, 34560, 34560, 4320, 540, 34560, 540, 34560, 4320, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 34560, 540, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 540, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 540, 540, 540, 540, 540, 4320, 540, 540, 4320, 34560, 34560, 540, 540, 34560, 540, 540, 540, 4320, 540, 4320, 34560, 34560, 4320, 4320, 540, 34560, 4320, 34560, 540, 4320, 4320, 540, 540, 4320, 540, 34560, 34560, 540, 34560, 34560, 540, 4320, 34560, 540, 540, 4320, 4320, 540, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 4320, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 34560, 4320, 4320, 4320, 34560, 540, 4320, 4320, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 4320, 540, 34560, 34560, 34560, 4320, 540, 34560, 34560, 4320, 4320, 34560, 34560, 540, 34560, 34560, 4320, 540, 34560, 4320, 4320, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 4320, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 34560, 540, 540, 540, 4320, 540, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 34560, 34560, 540, 34560, 34560, 540, 34560, 4320, 34560, 4320, 4320, 4320, 540, 4320, 540, 540, 34560, 540, 4320, 540, 540, 4320, 34560, 4320, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5045760 . Total input tokens: 1124027934 . Total output tokens: 1008922740
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 78.01700360001996,
    "estimated_duration": 3600.0558629274365,
    "input_throughput": 6178.256906800759,
    "output_throughput": 5462.569956903022,
    "total_throughput": 11640.826863703782,
    "itl": 152.68848795232236,
    "ttft": 2106666.478501922,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 506,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6553591806069117,
    "arrivals": 1680953,
    "finished_requests": 89774,
    "scheduler_time": 176.14242173005843
}
#Debug simulation 
Total elapsed time: 78.01713212020695. Arrivals time: 0.42573637375608087 Scheduler time: 77.44231000868604 Scheduler overhead time: 0.05853787297382951 Adapter cache time: 0.015808185562491417 Engine time: 0.05366075783967972 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-16-16/adapters_384_slots_64_rate_3.2-0.4-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-16-16/adapters_384_slots_64_rate_3.2-0.4-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 4320, 540, 34560, 34560, 540, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 540, 34560, 540, 34560, 4320, 4320, 4320, 540, 540, 4320, 540, 34560, 540, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 34560, 540, 34560, 34560, 34560, 34560, 540, 4320, 4320, 4320, 34560, 4320, 540, 4320, 540, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 540, 540, 34560, 4320, 4320, 540, 540, 540, 4320, 540, 4320, 540, 34560, 540, 4320, 34560, 540, 34560, 4320, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 34560, 34560, 4320, 540, 540, 34560, 4320, 4320, 540, 540, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 540, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 34560, 540, 540, 540, 4320, 4320, 34560, 540, 540, 34560, 540, 34560, 4320, 540, 34560, 4320, 4320, 540, 34560, 34560, 34560, 540, 4320, 34560, 540, 34560, 4320, 4320, 34560, 34560, 540, 4320, 34560, 540, 4320, 4320, 540, 4320, 540, 4320, 34560, 34560, 4320, 540, 34560, 540, 34560, 4320, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 34560, 540, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 540, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 540, 540, 540, 540, 540, 4320, 540, 540, 4320, 34560, 34560, 540, 540, 34560, 540, 540, 540, 4320, 540, 4320, 34560, 34560, 4320, 4320, 540, 34560, 4320, 34560, 540, 4320, 4320, 540, 540, 4320, 540, 34560, 34560, 540, 34560, 34560, 540, 4320, 34560, 540, 540, 4320, 4320, 540, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 4320, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 34560, 4320, 4320, 4320, 34560, 540, 4320, 4320, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 4320, 540, 34560, 34560, 34560, 4320, 540, 34560, 34560, 4320, 4320, 34560, 34560, 540, 34560, 34560, 4320, 540, 34560, 4320, 4320, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 4320, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 34560, 540, 540, 540, 4320, 540, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 34560, 34560, 540, 34560, 34560, 540, 34560, 4320, 34560, 4320, 4320, 4320, 540, 4320, 540, 540, 34560, 540, 4320, 540, 540, 4320, 34560, 4320, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5045760 . Total input tokens: 1124027934 . Total output tokens: 1008922740
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 74.64668612508103,
    "estimated_duration": 3600.0883506002506,
    "input_throughput": 6170.753280623238,
    "output_throughput": 5456.743025966179,
    "total_throughput": 11627.496306589417,
    "itl": 152.34532550654097,
    "ttft": 2106275.923105099,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 510,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.595204045171842,
    "arrivals": 1680953,
    "finished_requests": 89674,
    "scheduler_time": 176.38846560155267
}
#Debug simulation 
Total elapsed time: 74.64681327296421. Arrivals time: 0.42642394872382283 Scheduler time: 74.07151188887656 Scheduler overhead time: 0.057795058470219374 Adapter cache time: 0.016172476578503847 Engine time: 0.054026548750698566 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-16-32/adapters_384_slots_64_rate_3.2-0.4-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-16-32/adapters_384_slots_64_rate_3.2-0.4-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 4320, 540, 34560, 34560, 540, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 540, 34560, 540, 34560, 4320, 4320, 4320, 540, 540, 4320, 540, 34560, 540, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 34560, 540, 34560, 34560, 34560, 34560, 540, 4320, 4320, 4320, 34560, 4320, 540, 4320, 540, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 540, 540, 34560, 4320, 4320, 540, 540, 540, 4320, 540, 4320, 540, 34560, 540, 4320, 34560, 540, 34560, 4320, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 34560, 34560, 4320, 540, 540, 34560, 4320, 4320, 540, 540, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 540, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 34560, 540, 540, 540, 4320, 4320, 34560, 540, 540, 34560, 540, 34560, 4320, 540, 34560, 4320, 4320, 540, 34560, 34560, 34560, 540, 4320, 34560, 540, 34560, 4320, 4320, 34560, 34560, 540, 4320, 34560, 540, 4320, 4320, 540, 4320, 540, 4320, 34560, 34560, 4320, 540, 34560, 540, 34560, 4320, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 34560, 540, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 540, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 540, 540, 540, 540, 540, 4320, 540, 540, 4320, 34560, 34560, 540, 540, 34560, 540, 540, 540, 4320, 540, 4320, 34560, 34560, 4320, 4320, 540, 34560, 4320, 34560, 540, 4320, 4320, 540, 540, 4320, 540, 34560, 34560, 540, 34560, 34560, 540, 4320, 34560, 540, 540, 4320, 4320, 540, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 4320, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 34560, 4320, 4320, 4320, 34560, 540, 4320, 4320, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 4320, 540, 34560, 34560, 34560, 4320, 540, 34560, 34560, 4320, 4320, 34560, 34560, 540, 34560, 34560, 4320, 540, 34560, 4320, 4320, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 4320, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 34560, 540, 540, 540, 4320, 540, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 34560, 34560, 540, 34560, 34560, 540, 34560, 4320, 34560, 4320, 4320, 4320, 540, 4320, 540, 540, 34560, 540, 4320, 540, 540, 4320, 34560, 4320, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5045760 . Total input tokens: 1124027934 . Total output tokens: 1008922740
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 78.25109771173447,
    "estimated_duration": 3600.077741726776,
    "input_throughput": 6178.219359599607,
    "output_throughput": 5462.5367591554905,
    "total_throughput": 11640.756118755098,
    "itl": 152.68922842300242,
    "ttft": 2106674.9009322645,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 506,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6771145856566767,
    "arrivals": 1680953,
    "finished_requests": 89774,
    "scheduler_time": 176.14254512438555
}
#Debug simulation 
Total elapsed time: 78.25122400186956. Arrivals time: 0.4404553039930761 Scheduler time: 77.65986843314022 Scheduler overhead time: 0.059036686550825834 Adapter cache time: 0.016446516383439302 Engine time: 0.05409058975055814 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_16-16-16/adapters_384_slots_64_rate_3.2-0.4-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_16-16-16/adapters_384_slots_64_rate_3.2-0.4-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 4320, 540, 34560, 34560, 540, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 540, 34560, 540, 34560, 4320, 4320, 4320, 540, 540, 4320, 540, 34560, 540, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 34560, 540, 34560, 34560, 34560, 34560, 540, 4320, 4320, 4320, 34560, 4320, 540, 4320, 540, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 540, 540, 34560, 4320, 4320, 540, 540, 540, 4320, 540, 4320, 540, 34560, 540, 4320, 34560, 540, 34560, 4320, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 34560, 34560, 4320, 540, 540, 34560, 4320, 4320, 540, 540, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 540, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 34560, 540, 540, 540, 4320, 4320, 34560, 540, 540, 34560, 540, 34560, 4320, 540, 34560, 4320, 4320, 540, 34560, 34560, 34560, 540, 4320, 34560, 540, 34560, 4320, 4320, 34560, 34560, 540, 4320, 34560, 540, 4320, 4320, 540, 4320, 540, 4320, 34560, 34560, 4320, 540, 34560, 540, 34560, 4320, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 34560, 540, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 540, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 540, 540, 540, 540, 540, 4320, 540, 540, 4320, 34560, 34560, 540, 540, 34560, 540, 540, 540, 4320, 540, 4320, 34560, 34560, 4320, 4320, 540, 34560, 4320, 34560, 540, 4320, 4320, 540, 540, 4320, 540, 34560, 34560, 540, 34560, 34560, 540, 4320, 34560, 540, 540, 4320, 4320, 540, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 4320, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 34560, 4320, 4320, 4320, 34560, 540, 4320, 4320, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 4320, 540, 34560, 34560, 34560, 4320, 540, 34560, 34560, 4320, 4320, 34560, 34560, 540, 34560, 34560, 4320, 540, 34560, 4320, 4320, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 4320, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 34560, 540, 540, 540, 4320, 540, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 34560, 34560, 540, 34560, 34560, 540, 34560, 4320, 34560, 4320, 4320, 4320, 540, 4320, 540, 540, 34560, 540, 4320, 540, 540, 4320, 34560, 4320, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5045760 . Total input tokens: 1124027934 . Total output tokens: 1008922740
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 74.37844065576792,
    "estimated_duration": 3600.017640142817,
    "input_throughput": 6170.87448469244,
    "output_throughput": 5456.850205661955,
    "total_throughput": 11627.724690354396,
    "itl": 152.34300690875293,
    "ttft": 2106247.1342948987,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 510,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5249256504000923,
    "arrivals": 1680953,
    "finished_requests": 89674,
    "scheduler_time": 176.38803353887184
}
#Debug simulation 
Total elapsed time: 74.37856095656753. Arrivals time: 0.43166113132610917 Scheduler time: 73.79889847477898 Scheduler overhead time: 0.05753852566704154 Adapter cache time: 0.015852622222155333 Engine time: 0.053493030834943056 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_16-16-32/adapters_384_slots_64_rate_3.2-0.4-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_16-16-32/adapters_384_slots_64_rate_3.2-0.4-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 4320, 540, 34560, 34560, 540, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 540, 34560, 540, 34560, 4320, 4320, 4320, 540, 540, 4320, 540, 34560, 540, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 34560, 540, 34560, 34560, 34560, 34560, 540, 4320, 4320, 4320, 34560, 4320, 540, 4320, 540, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 540, 540, 34560, 4320, 4320, 540, 540, 540, 4320, 540, 4320, 540, 34560, 540, 4320, 34560, 540, 34560, 4320, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 34560, 34560, 4320, 540, 540, 34560, 4320, 4320, 540, 540, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 540, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 34560, 540, 540, 540, 4320, 4320, 34560, 540, 540, 34560, 540, 34560, 4320, 540, 34560, 4320, 4320, 540, 34560, 34560, 34560, 540, 4320, 34560, 540, 34560, 4320, 4320, 34560, 34560, 540, 4320, 34560, 540, 4320, 4320, 540, 4320, 540, 4320, 34560, 34560, 4320, 540, 34560, 540, 34560, 4320, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 34560, 540, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 540, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 540, 540, 540, 540, 540, 4320, 540, 540, 4320, 34560, 34560, 540, 540, 34560, 540, 540, 540, 4320, 540, 4320, 34560, 34560, 4320, 4320, 540, 34560, 4320, 34560, 540, 4320, 4320, 540, 540, 4320, 540, 34560, 34560, 540, 34560, 34560, 540, 4320, 34560, 540, 540, 4320, 4320, 540, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 4320, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 34560, 4320, 4320, 4320, 34560, 540, 4320, 4320, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 4320, 540, 34560, 34560, 34560, 4320, 540, 34560, 34560, 4320, 4320, 34560, 34560, 540, 34560, 34560, 4320, 540, 34560, 4320, 4320, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 4320, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 34560, 540, 540, 540, 4320, 540, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 34560, 34560, 540, 34560, 34560, 540, 34560, 4320, 34560, 4320, 4320, 4320, 540, 4320, 540, 540, 34560, 540, 4320, 540, 540, 4320, 34560, 4320, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5045760 . Total input tokens: 1124027934 . Total output tokens: 1008922740
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 82.71110242279246,
    "estimated_duration": 3600.0991280980616,
    "input_throughput": 6178.182657917679,
    "output_throughput": 5462.504308982555,
    "total_throughput": 11640.686966900234,
    "itl": 152.68992659512548,
    "ttft": 2106683.460407561,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 506,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.698366975560782,
    "arrivals": 1680953,
    "finished_requests": 89774,
    "scheduler_time": 176.14267910579989
}
#Debug simulation 
Total elapsed time: 82.71123502589762. Arrivals time: 0.4333350551314652 Scheduler time: 82.12667488772422 Scheduler overhead time: 0.05921508278697729 Adapter cache time: 0.016250498592853546 Engine time: 0.054201805498450994 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-8/adapters_384_slots_64_rate_3.2-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-8/adapters_384_slots_64_rate_3.2-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 4320, 270, 34560, 34560, 270, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 270, 34560, 270, 34560, 4320, 4320, 4320, 270, 270, 4320, 270, 34560, 270, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 34560, 270, 34560, 34560, 34560, 34560, 270, 4320, 4320, 4320, 34560, 4320, 270, 4320, 270, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 270, 270, 34560, 4320, 4320, 270, 270, 270, 4320, 270, 4320, 270, 34560, 270, 4320, 34560, 270, 34560, 4320, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 34560, 34560, 4320, 270, 270, 34560, 4320, 4320, 270, 270, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 270, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 34560, 270, 270, 270, 4320, 4320, 34560, 270, 270, 34560, 270, 34560, 4320, 270, 34560, 4320, 4320, 270, 34560, 34560, 34560, 270, 4320, 34560, 270, 34560, 4320, 4320, 34560, 34560, 270, 4320, 34560, 270, 4320, 4320, 270, 4320, 270, 4320, 34560, 34560, 4320, 270, 34560, 270, 34560, 4320, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 34560, 270, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 270, 270, 270, 270, 270, 4320, 270, 270, 4320, 34560, 34560, 270, 270, 34560, 270, 270, 270, 4320, 270, 4320, 34560, 34560, 4320, 4320, 270, 34560, 4320, 34560, 270, 4320, 4320, 270, 270, 4320, 270, 34560, 34560, 270, 34560, 34560, 270, 4320, 34560, 270, 270, 4320, 4320, 270, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 4320, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 34560, 4320, 4320, 4320, 34560, 270, 4320, 4320, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 4320, 270, 34560, 34560, 34560, 4320, 270, 34560, 34560, 4320, 4320, 34560, 34560, 270, 34560, 34560, 4320, 270, 34560, 4320, 4320, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 4320, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 34560, 270, 270, 270, 4320, 270, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 34560, 34560, 270, 34560, 34560, 270, 34560, 4320, 34560, 4320, 4320, 4320, 270, 4320, 270, 270, 34560, 270, 4320, 270, 270, 4320, 34560, 4320, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5011200 . Total input tokens: 1116308708 . Total output tokens: 1002055410
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 74.37361405603588,
    "estimated_duration": 3600.0437608845477,
    "input_throughput": 6137.552615352387,
    "output_throughput": 5429.681497870789,
    "total_throughput": 11567.234113223176,
    "itl": 149.9618257069325,
    "ttft": 2105574.4378572083,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 495,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5149414332467297,
    "arrivals": 1669342,
    "finished_requests": 89244,
    "scheduler_time": 177.68988700685955
}
#Debug simulation 
Total elapsed time: 74.37374001927674. Arrivals time: 0.4206368033774197 Scheduler time: 73.80707495938987 Scheduler overhead time: 0.05683147767558694 Adapter cache time: 0.015841507352888584 Engine time: 0.05246036080643535 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-16/adapters_384_slots_64_rate_3.2-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-16/adapters_384_slots_64_rate_3.2-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 4320, 270, 34560, 34560, 270, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 270, 34560, 270, 34560, 4320, 4320, 4320, 270, 270, 4320, 270, 34560, 270, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 34560, 270, 34560, 34560, 34560, 34560, 270, 4320, 4320, 4320, 34560, 4320, 270, 4320, 270, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 270, 270, 34560, 4320, 4320, 270, 270, 270, 4320, 270, 4320, 270, 34560, 270, 4320, 34560, 270, 34560, 4320, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 34560, 34560, 4320, 270, 270, 34560, 4320, 4320, 270, 270, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 270, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 34560, 270, 270, 270, 4320, 4320, 34560, 270, 270, 34560, 270, 34560, 4320, 270, 34560, 4320, 4320, 270, 34560, 34560, 34560, 270, 4320, 34560, 270, 34560, 4320, 4320, 34560, 34560, 270, 4320, 34560, 270, 4320, 4320, 270, 4320, 270, 4320, 34560, 34560, 4320, 270, 34560, 270, 34560, 4320, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 34560, 270, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 270, 270, 270, 270, 270, 4320, 270, 270, 4320, 34560, 34560, 270, 270, 34560, 270, 270, 270, 4320, 270, 4320, 34560, 34560, 4320, 4320, 270, 34560, 4320, 34560, 270, 4320, 4320, 270, 270, 4320, 270, 34560, 34560, 270, 34560, 34560, 270, 4320, 34560, 270, 270, 4320, 4320, 270, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 4320, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 34560, 4320, 4320, 4320, 34560, 270, 4320, 4320, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 4320, 270, 34560, 34560, 34560, 4320, 270, 34560, 34560, 4320, 4320, 34560, 34560, 270, 34560, 34560, 4320, 270, 34560, 4320, 4320, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 4320, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 34560, 270, 270, 270, 4320, 270, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 34560, 34560, 270, 34560, 34560, 270, 34560, 4320, 34560, 4320, 4320, 4320, 270, 4320, 270, 270, 34560, 270, 4320, 270, 270, 4320, 34560, 4320, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5011200 . Total input tokens: 1116308708 . Total output tokens: 1002055410
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 76.34780522389337,
    "estimated_duration": 3600.033963513222,
    "input_throughput": 6135.46878275691,
    "output_throughput": 5425.516314001371,
    "total_throughput": 11560.98509675828,
    "itl": 149.69990296732388,
    "ttft": 2105523.294636224,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 508,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.657459362761589,
    "arrivals": 1669342,
    "finished_requests": 89204,
    "scheduler_time": 177.98962011539132
}
#Debug simulation 
Total elapsed time: 76.34792388090864. Arrivals time: 0.43035553209483624 Scheduler time: 75.77028295584023 Scheduler overhead time: 0.05768499011173844 Adapter cache time: 0.016242490615695715 Engine time: 0.05234035896137357 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-32/adapters_384_slots_64_rate_3.2-0.4-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-32/adapters_384_slots_64_rate_3.2-0.4-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 4320, 270, 34560, 34560, 270, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 270, 34560, 270, 34560, 4320, 4320, 4320, 270, 270, 4320, 270, 34560, 270, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 34560, 270, 34560, 34560, 34560, 34560, 270, 4320, 4320, 4320, 34560, 4320, 270, 4320, 270, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 270, 270, 34560, 4320, 4320, 270, 270, 270, 4320, 270, 4320, 270, 34560, 270, 4320, 34560, 270, 34560, 4320, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 34560, 34560, 4320, 270, 270, 34560, 4320, 4320, 270, 270, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 270, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 34560, 270, 270, 270, 4320, 4320, 34560, 270, 270, 34560, 270, 34560, 4320, 270, 34560, 4320, 4320, 270, 34560, 34560, 34560, 270, 4320, 34560, 270, 34560, 4320, 4320, 34560, 34560, 270, 4320, 34560, 270, 4320, 4320, 270, 4320, 270, 4320, 34560, 34560, 4320, 270, 34560, 270, 34560, 4320, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 34560, 270, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 270, 270, 270, 270, 270, 4320, 270, 270, 4320, 34560, 34560, 270, 270, 34560, 270, 270, 270, 4320, 270, 4320, 34560, 34560, 4320, 4320, 270, 34560, 4320, 34560, 270, 4320, 4320, 270, 270, 4320, 270, 34560, 34560, 270, 34560, 34560, 270, 4320, 34560, 270, 270, 4320, 4320, 270, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 4320, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 34560, 4320, 4320, 4320, 34560, 270, 4320, 4320, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 4320, 270, 34560, 34560, 34560, 4320, 270, 34560, 34560, 4320, 4320, 34560, 34560, 270, 34560, 34560, 4320, 270, 34560, 4320, 4320, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 4320, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 34560, 270, 270, 270, 4320, 270, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 34560, 34560, 270, 34560, 34560, 270, 34560, 4320, 34560, 4320, 4320, 4320, 270, 4320, 270, 270, 34560, 270, 4320, 270, 270, 4320, 34560, 4320, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5011200 . Total input tokens: 1116308708 . Total output tokens: 1002055410
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 76.40626261476427,
    "estimated_duration": 3600.036970752653,
    "input_throughput": 6135.463657580752,
    "output_throughput": 5425.51178187386,
    "total_throughput": 11560.97543945461,
    "itl": 149.69998217944413,
    "ttft": 2105524.4565085527,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 508,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6604344758205216,
    "arrivals": 1669342,
    "finished_requests": 89204,
    "scheduler_time": 177.98965224172503
}
#Debug simulation 
Total elapsed time: 76.40638653794304. Arrivals time: 0.42788348719477654 Scheduler time: 75.83076939499006 Scheduler overhead time: 0.05702412128448486 Adapter cache time: 0.016297404188662767 Engine time: 0.05285406718030572 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-16-16/adapters_384_slots_64_rate_3.2-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-16-16/adapters_384_slots_64_rate_3.2-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 4320, 270, 34560, 34560, 270, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 270, 34560, 270, 34560, 4320, 4320, 4320, 270, 270, 4320, 270, 34560, 270, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 34560, 270, 34560, 34560, 34560, 34560, 270, 4320, 4320, 4320, 34560, 4320, 270, 4320, 270, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 270, 270, 34560, 4320, 4320, 270, 270, 270, 4320, 270, 4320, 270, 34560, 270, 4320, 34560, 270, 34560, 4320, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 34560, 34560, 4320, 270, 270, 34560, 4320, 4320, 270, 270, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 270, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 34560, 270, 270, 270, 4320, 4320, 34560, 270, 270, 34560, 270, 34560, 4320, 270, 34560, 4320, 4320, 270, 34560, 34560, 34560, 270, 4320, 34560, 270, 34560, 4320, 4320, 34560, 34560, 270, 4320, 34560, 270, 4320, 4320, 270, 4320, 270, 4320, 34560, 34560, 4320, 270, 34560, 270, 34560, 4320, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 34560, 270, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 270, 270, 270, 270, 270, 4320, 270, 270, 4320, 34560, 34560, 270, 270, 34560, 270, 270, 270, 4320, 270, 4320, 34560, 34560, 4320, 4320, 270, 34560, 4320, 34560, 270, 4320, 4320, 270, 270, 4320, 270, 34560, 34560, 270, 34560, 34560, 270, 4320, 34560, 270, 270, 4320, 4320, 270, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 4320, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 34560, 4320, 4320, 4320, 34560, 270, 4320, 4320, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 4320, 270, 34560, 34560, 34560, 4320, 270, 34560, 34560, 4320, 4320, 34560, 34560, 270, 34560, 34560, 4320, 270, 34560, 4320, 4320, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 4320, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 34560, 270, 270, 270, 4320, 270, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 34560, 34560, 270, 34560, 34560, 270, 34560, 4320, 34560, 4320, 4320, 4320, 270, 4320, 270, 270, 34560, 270, 4320, 270, 270, 4320, 34560, 4320, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5011200 . Total input tokens: 1116308708 . Total output tokens: 1002055410
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 76.38929369207472,
    "estimated_duration": 3600.141643199855,
    "input_throughput": 6135.296104729908,
    "output_throughput": 5425.439312059783,
    "total_throughput": 11560.735416789692,
    "itl": 149.69747099638874,
    "ttft": 2105545.3534933836,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 508,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5900411352189199,
    "arrivals": 1669342,
    "finished_requests": 89207,
    "scheduler_time": 177.9977838330833
}
#Debug simulation 
Total elapsed time: 76.38941678218544. Arrivals time: 0.42602086532860994 Scheduler time: 75.81619508750737 Scheduler overhead time: 0.057509527541697025 Adapter cache time: 0.015882961452007294 Engine time: 0.05259401584044099 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-16-32/adapters_384_slots_64_rate_3.2-0.4-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-16-32/adapters_384_slots_64_rate_3.2-0.4-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 4320, 270, 34560, 34560, 270, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 270, 34560, 270, 34560, 4320, 4320, 4320, 270, 270, 4320, 270, 34560, 270, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 34560, 270, 34560, 34560, 34560, 34560, 270, 4320, 4320, 4320, 34560, 4320, 270, 4320, 270, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 270, 270, 34560, 4320, 4320, 270, 270, 270, 4320, 270, 4320, 270, 34560, 270, 4320, 34560, 270, 34560, 4320, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 34560, 34560, 4320, 270, 270, 34560, 4320, 4320, 270, 270, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 270, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 34560, 270, 270, 270, 4320, 4320, 34560, 270, 270, 34560, 270, 34560, 4320, 270, 34560, 4320, 4320, 270, 34560, 34560, 34560, 270, 4320, 34560, 270, 34560, 4320, 4320, 34560, 34560, 270, 4320, 34560, 270, 4320, 4320, 270, 4320, 270, 4320, 34560, 34560, 4320, 270, 34560, 270, 34560, 4320, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 34560, 270, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 270, 270, 270, 270, 270, 4320, 270, 270, 4320, 34560, 34560, 270, 270, 34560, 270, 270, 270, 4320, 270, 4320, 34560, 34560, 4320, 4320, 270, 34560, 4320, 34560, 270, 4320, 4320, 270, 270, 4320, 270, 34560, 34560, 270, 34560, 34560, 270, 4320, 34560, 270, 270, 4320, 4320, 270, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 4320, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 34560, 4320, 4320, 4320, 34560, 270, 4320, 4320, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 4320, 270, 34560, 34560, 34560, 4320, 270, 34560, 34560, 4320, 4320, 34560, 34560, 270, 34560, 34560, 4320, 270, 34560, 4320, 4320, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 4320, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 34560, 270, 270, 270, 4320, 270, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 34560, 34560, 270, 34560, 34560, 270, 34560, 4320, 34560, 4320, 4320, 4320, 270, 4320, 270, 270, 34560, 270, 4320, 270, 270, 4320, 34560, 4320, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5011200 . Total input tokens: 1116308708 . Total output tokens: 1002055410
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 76.41000623675063,
    "estimated_duration": 3600.057802998715,
    "input_throughput": 6135.428153848418,
    "output_throughput": 5425.480386378944,
    "total_throughput": 11560.908540227363,
    "itl": 149.7006790233372,
    "ttft": 2105531.866852875,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 508,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6811838505789682,
    "arrivals": 1669342,
    "finished_requests": 89204,
    "scheduler_time": 177.98973511306303
}
#Debug simulation 
Total elapsed time: 76.41012754384428. Arrivals time: 0.4134557479992509 Scheduler time: 75.84879146656021 Scheduler overhead time: 0.05755425617098808 Adapter cache time: 0.016091850586235523 Engine time: 0.05345126334577799 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_16-16-16/adapters_384_slots_64_rate_3.2-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_16-16-16/adapters_384_slots_64_rate_3.2-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 4320, 270, 34560, 34560, 270, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 270, 34560, 270, 34560, 4320, 4320, 4320, 270, 270, 4320, 270, 34560, 270, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 34560, 270, 34560, 34560, 34560, 34560, 270, 4320, 4320, 4320, 34560, 4320, 270, 4320, 270, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 270, 270, 34560, 4320, 4320, 270, 270, 270, 4320, 270, 4320, 270, 34560, 270, 4320, 34560, 270, 34560, 4320, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 34560, 34560, 4320, 270, 270, 34560, 4320, 4320, 270, 270, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 270, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 34560, 270, 270, 270, 4320, 4320, 34560, 270, 270, 34560, 270, 34560, 4320, 270, 34560, 4320, 4320, 270, 34560, 34560, 34560, 270, 4320, 34560, 270, 34560, 4320, 4320, 34560, 34560, 270, 4320, 34560, 270, 4320, 4320, 270, 4320, 270, 4320, 34560, 34560, 4320, 270, 34560, 270, 34560, 4320, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 34560, 270, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 270, 270, 270, 270, 270, 4320, 270, 270, 4320, 34560, 34560, 270, 270, 34560, 270, 270, 270, 4320, 270, 4320, 34560, 34560, 4320, 4320, 270, 34560, 4320, 34560, 270, 4320, 4320, 270, 270, 4320, 270, 34560, 34560, 270, 34560, 34560, 270, 4320, 34560, 270, 270, 4320, 4320, 270, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 4320, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 34560, 4320, 4320, 4320, 34560, 270, 4320, 4320, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 4320, 270, 34560, 34560, 34560, 4320, 270, 34560, 34560, 4320, 4320, 34560, 34560, 270, 34560, 34560, 4320, 270, 34560, 4320, 4320, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 4320, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 34560, 270, 270, 270, 4320, 270, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 34560, 34560, 270, 34560, 34560, 270, 34560, 4320, 34560, 4320, 4320, 4320, 270, 4320, 270, 270, 34560, 270, 4320, 270, 270, 4320, 34560, 4320, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5011200 . Total input tokens: 1116308708 . Total output tokens: 1002055410
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 74.44004552718252,
    "estimated_duration": 3600.0087006766666,
    "input_throughput": 6137.612388505307,
    "output_throughput": 5429.734377121333,
    "total_throughput": 11567.346765626638,
    "itl": 149.960681888177,
    "ttft": 2105561.320542425,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 495,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4800748959765613,
    "arrivals": 1669342,
    "finished_requests": 89244,
    "scheduler_time": 177.68969333617753
}
#Debug simulation 
Total elapsed time: 74.44016905594617. Arrivals time: 0.410563251003623 Scheduler time: 73.88292283983901 Scheduler overhead time: 0.05728671047836542 Adapter cache time: 0.01577804097905755 Engine time: 0.05279749073088169 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_16-16-32/adapters_384_slots_64_rate_3.2-0.4-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_16-16-32/adapters_384_slots_64_rate_3.2-0.4-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 4320, 270, 34560, 34560, 270, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 270, 34560, 270, 34560, 4320, 4320, 4320, 270, 270, 4320, 270, 34560, 270, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 34560, 270, 34560, 34560, 34560, 34560, 270, 4320, 4320, 4320, 34560, 4320, 270, 4320, 270, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 270, 270, 34560, 4320, 4320, 270, 270, 270, 4320, 270, 4320, 270, 34560, 270, 4320, 34560, 270, 34560, 4320, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 34560, 34560, 4320, 270, 270, 34560, 4320, 4320, 270, 270, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 270, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 34560, 270, 270, 270, 4320, 4320, 34560, 270, 270, 34560, 270, 34560, 4320, 270, 34560, 4320, 4320, 270, 34560, 34560, 34560, 270, 4320, 34560, 270, 34560, 4320, 4320, 34560, 34560, 270, 4320, 34560, 270, 4320, 4320, 270, 4320, 270, 4320, 34560, 34560, 4320, 270, 34560, 270, 34560, 4320, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 34560, 270, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 270, 270, 270, 270, 270, 4320, 270, 270, 4320, 34560, 34560, 270, 270, 34560, 270, 270, 270, 4320, 270, 4320, 34560, 34560, 4320, 4320, 270, 34560, 4320, 34560, 270, 4320, 4320, 270, 270, 4320, 270, 34560, 34560, 270, 34560, 34560, 270, 4320, 34560, 270, 270, 4320, 4320, 270, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 4320, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 34560, 4320, 4320, 4320, 34560, 270, 4320, 4320, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 4320, 270, 34560, 34560, 34560, 4320, 270, 34560, 34560, 4320, 4320, 34560, 34560, 270, 34560, 34560, 4320, 270, 34560, 4320, 4320, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 4320, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 34560, 270, 270, 270, 4320, 270, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 34560, 34560, 270, 34560, 34560, 270, 34560, 4320, 34560, 4320, 4320, 4320, 270, 4320, 270, 270, 34560, 270, 4320, 270, 270, 4320, 34560, 4320, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5011200 . Total input tokens: 1116308708 . Total output tokens: 1002055410
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 76.86510681873187,
    "estimated_duration": 3600.079800250402,
    "input_throughput": 6135.39066508017,
    "output_throughput": 5425.4472355422395,
    "total_throughput": 11560.83790062241,
    "itl": 149.7014127000758,
    "ttft": 2105539.8799785906,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 508,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7030650094151478,
    "arrivals": 1669342,
    "finished_requests": 89204,
    "scheduler_time": 177.98985120595066
}
#Debug simulation 
Total elapsed time: 76.8652253318578. Arrivals time: 0.4075357476249337 Scheduler time: 76.31102883117273 Scheduler overhead time: 0.05734180985018611 Adapter cache time: 0.01596888294443488 Engine time: 0.052460186183452606 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-8/adapters_384_slots_64_rate_3.2-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-8/adapters_384_slots_64_rate_3.2-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 4320, 135, 34560, 34560, 135, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 135, 34560, 135, 34560, 4320, 4320, 4320, 135, 135, 4320, 135, 34560, 135, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 34560, 135, 34560, 34560, 34560, 34560, 135, 4320, 4320, 4320, 34560, 4320, 135, 4320, 135, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 135, 135, 34560, 4320, 4320, 135, 135, 135, 4320, 135, 4320, 135, 34560, 135, 4320, 34560, 135, 34560, 4320, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 34560, 34560, 4320, 135, 135, 34560, 4320, 4320, 135, 135, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 135, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 34560, 135, 135, 135, 4320, 4320, 34560, 135, 135, 34560, 135, 34560, 4320, 135, 34560, 4320, 4320, 135, 34560, 34560, 34560, 135, 4320, 34560, 135, 34560, 4320, 4320, 34560, 34560, 135, 4320, 34560, 135, 4320, 4320, 135, 4320, 135, 4320, 34560, 34560, 4320, 135, 34560, 135, 34560, 4320, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 34560, 135, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 135, 135, 135, 135, 135, 4320, 135, 135, 4320, 34560, 34560, 135, 135, 34560, 135, 135, 135, 4320, 135, 4320, 34560, 34560, 4320, 4320, 135, 34560, 4320, 34560, 135, 4320, 4320, 135, 135, 4320, 135, 34560, 34560, 135, 34560, 34560, 135, 4320, 34560, 135, 135, 4320, 4320, 135, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 4320, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 34560, 4320, 4320, 4320, 34560, 135, 4320, 4320, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 4320, 135, 34560, 34560, 34560, 4320, 135, 34560, 34560, 4320, 4320, 34560, 34560, 135, 34560, 34560, 4320, 135, 34560, 4320, 4320, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 4320, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 34560, 135, 135, 135, 4320, 135, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 34560, 34560, 135, 34560, 34560, 135, 34560, 4320, 34560, 4320, 4320, 4320, 135, 4320, 135, 135, 34560, 135, 4320, 135, 135, 4320, 34560, 4320, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4993920 . Total input tokens: 1112390199 . Total output tokens: 998610757
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 74.27117548324168,
    "estimated_duration": 3600.139817229668,
    "input_throughput": 6167.904061317025,
    "output_throughput": 5457.020559584199,
    "total_throughput": 11624.924620901224,
    "itl": 151.97845309936207,
    "ttft": 2101278.6536089494,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 474,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4506711906241396,
    "arrivals": 1663594,
    "finished_requests": 90093,
    "scheduler_time": 176.5165448141987
}
#Debug simulation 
Total elapsed time: 74.27130855806172. Arrivals time: 0.41402211459353566 Scheduler time: 73.71070554479957 Scheduler overhead time: 0.05775679089128971 Adapter cache time: 0.015037577599287033 Engine time: 0.05248898081481457 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-16/adapters_384_slots_64_rate_3.2-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-16/adapters_384_slots_64_rate_3.2-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 4320, 135, 34560, 34560, 135, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 135, 34560, 135, 34560, 4320, 4320, 4320, 135, 135, 4320, 135, 34560, 135, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 34560, 135, 34560, 34560, 34560, 34560, 135, 4320, 4320, 4320, 34560, 4320, 135, 4320, 135, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 135, 135, 34560, 4320, 4320, 135, 135, 135, 4320, 135, 4320, 135, 34560, 135, 4320, 34560, 135, 34560, 4320, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 34560, 34560, 4320, 135, 135, 34560, 4320, 4320, 135, 135, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 135, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 34560, 135, 135, 135, 4320, 4320, 34560, 135, 135, 34560, 135, 34560, 4320, 135, 34560, 4320, 4320, 135, 34560, 34560, 34560, 135, 4320, 34560, 135, 34560, 4320, 4320, 34560, 34560, 135, 4320, 34560, 135, 4320, 4320, 135, 4320, 135, 4320, 34560, 34560, 4320, 135, 34560, 135, 34560, 4320, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 34560, 135, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 135, 135, 135, 135, 135, 4320, 135, 135, 4320, 34560, 34560, 135, 135, 34560, 135, 135, 135, 4320, 135, 4320, 34560, 34560, 4320, 4320, 135, 34560, 4320, 34560, 135, 4320, 4320, 135, 135, 4320, 135, 34560, 34560, 135, 34560, 34560, 135, 4320, 34560, 135, 135, 4320, 4320, 135, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 4320, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 34560, 4320, 4320, 4320, 34560, 135, 4320, 4320, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 4320, 135, 34560, 34560, 34560, 4320, 135, 34560, 34560, 4320, 4320, 34560, 34560, 135, 34560, 34560, 4320, 135, 34560, 4320, 4320, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 4320, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 34560, 135, 135, 135, 4320, 135, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 34560, 34560, 135, 34560, 34560, 135, 34560, 4320, 34560, 4320, 4320, 4320, 135, 4320, 135, 135, 34560, 135, 4320, 135, 135, 4320, 34560, 4320, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4993920 . Total input tokens: 1112390199 . Total output tokens: 998610757
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 76.03667453397065,
    "estimated_duration": 3600.0446836812766,
    "input_throughput": 6185.333504591415,
    "output_throughput": 5466.736590579046,
    "total_throughput": 11652.07009517046,
    "itl": 153.18445743031288,
    "ttft": 2101750.6169970264,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 465,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5231668656226318,
    "arrivals": 1663594,
    "finished_requests": 90370,
    "scheduler_time": 175.83401564670595
}
#Debug simulation 
Total elapsed time: 76.03680138010532. Arrivals time: 0.5443031694740057 Scheduler time: 75.34230309538543 Scheduler overhead time: 0.058951147831976414 Adapter cache time: 0.015137040056288242 Engine time: 0.05472043389454484 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-32/adapters_384_slots_64_rate_3.2-0.4-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-32/adapters_384_slots_64_rate_3.2-0.4-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 4320, 135, 34560, 34560, 135, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 135, 34560, 135, 34560, 4320, 4320, 4320, 135, 135, 4320, 135, 34560, 135, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 34560, 135, 34560, 34560, 34560, 34560, 135, 4320, 4320, 4320, 34560, 4320, 135, 4320, 135, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 135, 135, 34560, 4320, 4320, 135, 135, 135, 4320, 135, 4320, 135, 34560, 135, 4320, 34560, 135, 34560, 4320, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 34560, 34560, 4320, 135, 135, 34560, 4320, 4320, 135, 135, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 135, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 34560, 135, 135, 135, 4320, 4320, 34560, 135, 135, 34560, 135, 34560, 4320, 135, 34560, 4320, 4320, 135, 34560, 34560, 34560, 135, 4320, 34560, 135, 34560, 4320, 4320, 34560, 34560, 135, 4320, 34560, 135, 4320, 4320, 135, 4320, 135, 4320, 34560, 34560, 4320, 135, 34560, 135, 34560, 4320, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 34560, 135, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 135, 135, 135, 135, 135, 4320, 135, 135, 4320, 34560, 34560, 135, 135, 34560, 135, 135, 135, 4320, 135, 4320, 34560, 34560, 4320, 4320, 135, 34560, 4320, 34560, 135, 4320, 4320, 135, 135, 4320, 135, 34560, 34560, 135, 34560, 34560, 135, 4320, 34560, 135, 135, 4320, 4320, 135, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 4320, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 34560, 4320, 4320, 4320, 34560, 135, 4320, 4320, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 4320, 135, 34560, 34560, 34560, 4320, 135, 34560, 34560, 4320, 4320, 34560, 34560, 135, 34560, 34560, 4320, 135, 34560, 4320, 4320, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 4320, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 34560, 135, 135, 135, 4320, 135, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 34560, 34560, 135, 34560, 34560, 135, 34560, 4320, 34560, 4320, 4320, 4320, 135, 4320, 135, 135, 34560, 135, 4320, 135, 135, 4320, 34560, 4320, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4993920 . Total input tokens: 1112390199 . Total output tokens: 998610757
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 76.04437555000186,
    "estimated_duration": 3600.046350301972,
    "input_throughput": 6185.330641126941,
    "output_throughput": 5466.734059784869,
    "total_throughput": 11652.064700911811,
    "itl": 153.18451773914714,
    "ttft": 2101751.191598188,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 465,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5248417004011663,
    "arrivals": 1663594,
    "finished_requests": 90370,
    "scheduler_time": 175.83400743258656
}
#Debug simulation 
Total elapsed time: 76.04449725104496. Arrivals time: 0.43381375866010785 Scheduler time: 75.45955623034388 Scheduler overhead time: 0.05955958133563399 Adapter cache time: 0.015651282854378223 Engine time: 0.05423995712772012 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-16/adapters_384_slots_64_rate_3.2-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-16/adapters_384_slots_64_rate_3.2-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 4320, 135, 34560, 34560, 135, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 135, 34560, 135, 34560, 4320, 4320, 4320, 135, 135, 4320, 135, 34560, 135, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 34560, 135, 34560, 34560, 34560, 34560, 135, 4320, 4320, 4320, 34560, 4320, 135, 4320, 135, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 135, 135, 34560, 4320, 4320, 135, 135, 135, 4320, 135, 4320, 135, 34560, 135, 4320, 34560, 135, 34560, 4320, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 34560, 34560, 4320, 135, 135, 34560, 4320, 4320, 135, 135, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 135, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 34560, 135, 135, 135, 4320, 4320, 34560, 135, 135, 34560, 135, 34560, 4320, 135, 34560, 4320, 4320, 135, 34560, 34560, 34560, 135, 4320, 34560, 135, 34560, 4320, 4320, 34560, 34560, 135, 4320, 34560, 135, 4320, 4320, 135, 4320, 135, 4320, 34560, 34560, 4320, 135, 34560, 135, 34560, 4320, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 34560, 135, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 135, 135, 135, 135, 135, 4320, 135, 135, 4320, 34560, 34560, 135, 135, 34560, 135, 135, 135, 4320, 135, 4320, 34560, 34560, 4320, 4320, 135, 34560, 4320, 34560, 135, 4320, 4320, 135, 135, 4320, 135, 34560, 34560, 135, 34560, 34560, 135, 4320, 34560, 135, 135, 4320, 4320, 135, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 4320, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 34560, 4320, 4320, 4320, 34560, 135, 4320, 4320, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 4320, 135, 34560, 34560, 34560, 4320, 135, 34560, 34560, 4320, 4320, 34560, 34560, 135, 34560, 34560, 4320, 135, 34560, 4320, 4320, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 4320, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 34560, 135, 135, 135, 4320, 135, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 34560, 34560, 135, 34560, 34560, 135, 34560, 4320, 34560, 4320, 4320, 4320, 135, 4320, 135, 135, 34560, 135, 4320, 135, 135, 4320, 34560, 4320, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4993920 . Total input tokens: 1112390199 . Total output tokens: 998610757
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 73.96505351690575,
    "estimated_duration": 3600.1176256108547,
    "input_throughput": 6167.381543882924,
    "output_throughput": 5460.074654273189,
    "total_throughput": 11627.456198156113,
    "itl": 151.87201356015183,
    "ttft": 2101587.7008265434,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 473,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.482937802986703,
    "arrivals": 1663594,
    "finished_requests": 90101,
    "scheduler_time": 176.45269404123718
}
#Debug simulation 
Total elapsed time: 73.96517032012343. Arrivals time: 0.43456689873710275 Scheduler time: 73.38362581562251 Scheduler overhead time: 0.05754255596548319 Adapter cache time: 0.015464990865439177 Engine time: 0.053021563682705164 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-32/adapters_384_slots_64_rate_3.2-0.4-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-32/adapters_384_slots_64_rate_3.2-0.4-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 4320, 135, 34560, 34560, 135, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 135, 34560, 135, 34560, 4320, 4320, 4320, 135, 135, 4320, 135, 34560, 135, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 34560, 135, 34560, 34560, 34560, 34560, 135, 4320, 4320, 4320, 34560, 4320, 135, 4320, 135, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 135, 135, 34560, 4320, 4320, 135, 135, 135, 4320, 135, 4320, 135, 34560, 135, 4320, 34560, 135, 34560, 4320, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 34560, 34560, 4320, 135, 135, 34560, 4320, 4320, 135, 135, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 135, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 34560, 135, 135, 135, 4320, 4320, 34560, 135, 135, 34560, 135, 34560, 4320, 135, 34560, 4320, 4320, 135, 34560, 34560, 34560, 135, 4320, 34560, 135, 34560, 4320, 4320, 34560, 34560, 135, 4320, 34560, 135, 4320, 4320, 135, 4320, 135, 4320, 34560, 34560, 4320, 135, 34560, 135, 34560, 4320, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 34560, 135, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 135, 135, 135, 135, 135, 4320, 135, 135, 4320, 34560, 34560, 135, 135, 34560, 135, 135, 135, 4320, 135, 4320, 34560, 34560, 4320, 4320, 135, 34560, 4320, 34560, 135, 4320, 4320, 135, 135, 4320, 135, 34560, 34560, 135, 34560, 34560, 135, 4320, 34560, 135, 135, 4320, 4320, 135, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 4320, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 34560, 4320, 4320, 4320, 34560, 135, 4320, 4320, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 4320, 135, 34560, 34560, 34560, 4320, 135, 34560, 34560, 4320, 4320, 34560, 34560, 135, 34560, 34560, 4320, 135, 34560, 4320, 4320, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 4320, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 34560, 135, 135, 135, 4320, 135, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 34560, 34560, 135, 34560, 34560, 135, 34560, 4320, 34560, 4320, 4320, 4320, 135, 4320, 135, 135, 34560, 135, 4320, 135, 135, 4320, 34560, 4320, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4993920 . Total input tokens: 1112390199 . Total output tokens: 998610757
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 75.98449923377484,
    "estimated_duration": 3600.066335128008,
    "input_throughput": 6185.296304882735,
    "output_throughput": 5466.703712641511,
    "total_throughput": 11652.000017524246,
    "itl": 153.18520676857713,
    "ttft": 2101758.8942185934,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 465,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.544710798654709,
    "arrivals": 1663594,
    "finished_requests": 90370,
    "scheduler_time": 175.8341231604022
}
#Debug simulation 
Total elapsed time: 75.98461799975485. Arrivals time: 0.4479269701987505 Scheduler time: 75.38559046760201 Scheduler overhead time: 0.05959096224978566 Adapter cache time: 0.015235855244100094 Engine time: 0.054771565832197666 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-16/adapters_384_slots_64_rate_3.2-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-16/adapters_384_slots_64_rate_3.2-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 4320, 135, 34560, 34560, 135, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 135, 34560, 135, 34560, 4320, 4320, 4320, 135, 135, 4320, 135, 34560, 135, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 34560, 135, 34560, 34560, 34560, 34560, 135, 4320, 4320, 4320, 34560, 4320, 135, 4320, 135, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 135, 135, 34560, 4320, 4320, 135, 135, 135, 4320, 135, 4320, 135, 34560, 135, 4320, 34560, 135, 34560, 4320, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 34560, 34560, 4320, 135, 135, 34560, 4320, 4320, 135, 135, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 135, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 34560, 135, 135, 135, 4320, 4320, 34560, 135, 135, 34560, 135, 34560, 4320, 135, 34560, 4320, 4320, 135, 34560, 34560, 34560, 135, 4320, 34560, 135, 34560, 4320, 4320, 34560, 34560, 135, 4320, 34560, 135, 4320, 4320, 135, 4320, 135, 4320, 34560, 34560, 4320, 135, 34560, 135, 34560, 4320, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 34560, 135, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 135, 135, 135, 135, 135, 4320, 135, 135, 4320, 34560, 34560, 135, 135, 34560, 135, 135, 135, 4320, 135, 4320, 34560, 34560, 4320, 4320, 135, 34560, 4320, 34560, 135, 4320, 4320, 135, 135, 4320, 135, 34560, 34560, 135, 34560, 34560, 135, 4320, 34560, 135, 135, 4320, 4320, 135, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 4320, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 34560, 4320, 4320, 4320, 34560, 135, 4320, 4320, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 4320, 135, 34560, 34560, 34560, 4320, 135, 34560, 34560, 4320, 4320, 34560, 34560, 135, 34560, 34560, 4320, 135, 34560, 4320, 4320, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 4320, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 34560, 135, 135, 135, 4320, 135, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 34560, 34560, 135, 34560, 34560, 135, 34560, 4320, 34560, 4320, 4320, 4320, 135, 4320, 135, 135, 34560, 135, 4320, 135, 135, 4320, 34560, 4320, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4993920 . Total input tokens: 1112390199 . Total output tokens: 998610757
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 74.48737404029816,
    "estimated_duration": 3600.1062279940897,
    "input_throughput": 6167.961608280758,
    "output_throughput": 5457.071473956588,
    "total_throughput": 11625.033082237347,
    "itl": 151.97732874250607,
    "ttft": 2101265.605077591,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 474,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4172838397836178,
    "arrivals": 1663594,
    "finished_requests": 90093,
    "scheduler_time": 176.51634292939727
}
#Debug simulation 
Total elapsed time: 74.48749788710847. Arrivals time: 0.4404317205771804 Scheduler time: 73.90158271929249 Scheduler overhead time: 0.05722134932875633 Adapter cache time: 0.01542256260290742 Engine time: 0.05230122525244951 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-32/adapters_384_slots_64_rate_3.2-0.4-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-32/adapters_384_slots_64_rate_3.2-0.4-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 4320, 135, 34560, 34560, 135, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 135, 34560, 135, 34560, 4320, 4320, 4320, 135, 135, 4320, 135, 34560, 135, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 34560, 135, 34560, 34560, 34560, 34560, 135, 4320, 4320, 4320, 34560, 4320, 135, 4320, 135, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 135, 135, 34560, 4320, 4320, 135, 135, 135, 4320, 135, 4320, 135, 34560, 135, 4320, 34560, 135, 34560, 4320, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 34560, 34560, 4320, 135, 135, 34560, 4320, 4320, 135, 135, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 135, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 34560, 135, 135, 135, 4320, 4320, 34560, 135, 135, 34560, 135, 34560, 4320, 135, 34560, 4320, 4320, 135, 34560, 34560, 34560, 135, 4320, 34560, 135, 34560, 4320, 4320, 34560, 34560, 135, 4320, 34560, 135, 4320, 4320, 135, 4320, 135, 4320, 34560, 34560, 4320, 135, 34560, 135, 34560, 4320, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 34560, 135, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 135, 135, 135, 135, 135, 4320, 135, 135, 4320, 34560, 34560, 135, 135, 34560, 135, 135, 135, 4320, 135, 4320, 34560, 34560, 4320, 4320, 135, 34560, 4320, 34560, 135, 4320, 4320, 135, 135, 4320, 135, 34560, 34560, 135, 34560, 34560, 135, 4320, 34560, 135, 135, 4320, 4320, 135, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 4320, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 34560, 4320, 4320, 4320, 34560, 135, 4320, 4320, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 4320, 135, 34560, 34560, 34560, 4320, 135, 34560, 34560, 4320, 4320, 34560, 34560, 135, 34560, 34560, 4320, 135, 34560, 4320, 4320, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 4320, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 34560, 135, 135, 135, 4320, 135, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 34560, 34560, 135, 34560, 34560, 135, 34560, 4320, 34560, 4320, 4320, 4320, 135, 4320, 135, 135, 34560, 135, 4320, 135, 135, 4320, 34560, 4320, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4993920 . Total input tokens: 1112390199 . Total output tokens: 998610757
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 76.0803656661883,
    "estimated_duration": 3600.087497919727,
    "input_throughput": 6185.25994517273,
    "output_throughput": 5466.671577113659,
    "total_throughput": 11651.931522286388,
    "itl": 153.1859005312194,
    "ttft": 2101767.7494411618,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 465,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5657116809859857,
    "arrivals": 1663594,
    "finished_requests": 90370,
    "scheduler_time": 175.83428506982253
}
#Debug simulation 
Total elapsed time: 76.08048938820139. Arrivals time: 0.44839850440621376 Scheduler time: 75.48143304605037 Scheduler overhead time: 0.059592773206532 Adapter cache time: 0.015152593608945608 Engine time: 0.05467475950717926 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-8/adapters_384_slots_64_rate_3.2-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-8/adapters_384_slots_64_rate_3.2-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 4320, 66, 34560, 34560, 66, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 66, 34560, 66, 34560, 4320, 4320, 4320, 66, 66, 4320, 66, 34560, 66, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 34560, 66, 34560, 34560, 34560, 34560, 66, 4320, 4320, 4320, 34560, 4320, 66, 4320, 66, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 66, 66, 34560, 4320, 4320, 66, 66, 66, 4320, 66, 4320, 66, 34560, 66, 4320, 34560, 66, 34560, 4320, 66, 34560, 34560, 34560, 34560, 4320, 66, 4320, 34560, 34560, 4320, 66, 66, 34560, 4320, 4320, 66, 66, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 66, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 34560, 66, 66, 66, 4320, 4320, 34560, 66, 66, 34560, 66, 34560, 4320, 66, 34560, 4320, 4320, 66, 34560, 34560, 34560, 66, 4320, 34560, 66, 34560, 4320, 4320, 34560, 34560, 66, 4320, 34560, 66, 4320, 4320, 66, 4320, 66, 4320, 34560, 34560, 4320, 66, 34560, 66, 34560, 4320, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 34560, 66, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 66, 66, 66, 66, 66, 4320, 66, 66, 4320, 34560, 34560, 66, 66, 34560, 66, 66, 66, 4320, 66, 4320, 34560, 34560, 4320, 4320, 66, 34560, 4320, 34560, 66, 4320, 4320, 66, 66, 4320, 66, 34560, 34560, 66, 34560, 34560, 66, 4320, 34560, 66, 66, 4320, 4320, 66, 66, 34560, 34560, 34560, 34560, 4320, 66, 4320, 4320, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 34560, 4320, 4320, 4320, 34560, 66, 4320, 4320, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 4320, 66, 34560, 34560, 34560, 4320, 66, 34560, 34560, 4320, 4320, 34560, 34560, 66, 34560, 34560, 4320, 66, 34560, 4320, 4320, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 4320, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 34560, 66, 66, 66, 4320, 66, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 34560, 34560, 66, 34560, 34560, 66, 34560, 4320, 34560, 4320, 4320, 4320, 66, 4320, 66, 66, 34560, 66, 4320, 66, 66, 4320, 34560, 4320, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4985088 . Total input tokens: 1110432516 . Total output tokens: 996850533
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 77.63499228097498,
    "estimated_duration": 3600.10847782791,
    "input_throughput": 6199.545690763733,
    "output_throughput": 5471.934560117904,
    "total_throughput": 11671.480250881636,
    "itl": 152.85140535278413,
    "ttft": 2103384.768738257,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 503,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5394253351981926,
    "arrivals": 1660646,
    "finished_requests": 90208,
    "scheduler_time": 175.5087376462734
}
#Debug simulation 
Total elapsed time: 77.63511593965814. Arrivals time: 0.43795144092291594 Scheduler time: 77.04694407945499 Scheduler overhead time: 0.05912995291873813 Adapter cache time: 0.01610397221520543 Engine time: 0.0540494997985661 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-16/adapters_384_slots_64_rate_3.2-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-16/adapters_384_slots_64_rate_3.2-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 4320, 66, 34560, 34560, 66, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 66, 34560, 66, 34560, 4320, 4320, 4320, 66, 66, 4320, 66, 34560, 66, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 34560, 66, 34560, 34560, 34560, 34560, 66, 4320, 4320, 4320, 34560, 4320, 66, 4320, 66, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 66, 66, 34560, 4320, 4320, 66, 66, 66, 4320, 66, 4320, 66, 34560, 66, 4320, 34560, 66, 34560, 4320, 66, 34560, 34560, 34560, 34560, 4320, 66, 4320, 34560, 34560, 4320, 66, 66, 34560, 4320, 4320, 66, 66, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 66, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 34560, 66, 66, 66, 4320, 4320, 34560, 66, 66, 34560, 66, 34560, 4320, 66, 34560, 4320, 4320, 66, 34560, 34560, 34560, 66, 4320, 34560, 66, 34560, 4320, 4320, 34560, 34560, 66, 4320, 34560, 66, 4320, 4320, 66, 4320, 66, 4320, 34560, 34560, 4320, 66, 34560, 66, 34560, 4320, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 34560, 66, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 66, 66, 66, 66, 66, 4320, 66, 66, 4320, 34560, 34560, 66, 66, 34560, 66, 66, 66, 4320, 66, 4320, 34560, 34560, 4320, 4320, 66, 34560, 4320, 34560, 66, 4320, 4320, 66, 66, 4320, 66, 34560, 34560, 66, 34560, 34560, 66, 4320, 34560, 66, 66, 4320, 4320, 66, 66, 34560, 34560, 34560, 34560, 4320, 66, 4320, 4320, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 34560, 4320, 4320, 4320, 34560, 66, 4320, 4320, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 4320, 66, 34560, 34560, 34560, 4320, 66, 34560, 34560, 4320, 4320, 34560, 34560, 66, 34560, 34560, 4320, 66, 34560, 4320, 4320, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 4320, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 34560, 66, 66, 66, 4320, 66, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 34560, 34560, 66, 34560, 34560, 66, 34560, 4320, 34560, 4320, 4320, 4320, 66, 4320, 66, 66, 34560, 66, 4320, 66, 66, 4320, 34560, 4320, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4985088 . Total input tokens: 1110432516 . Total output tokens: 996850533
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 82.5633420846425,
    "estimated_duration": 3600.1609313972926,
    "input_throughput": 6222.220735922973,
    "output_throughput": 5493.596363294748,
    "total_throughput": 11715.817099217722,
    "itl": 154.18527562778743,
    "ttft": 2102269.139009713,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 414,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3510617252974826,
    "arrivals": 1660646,
    "finished_requests": 90525,
    "scheduler_time": 174.54717771960455
}
#Debug simulation 
Total elapsed time: 82.56346927862614. Arrivals time: 0.43881275365129113 Scheduler time: 81.97318524168804 Scheduler overhead time: 0.05930311232805252 Adapter cache time: 0.015064389444887638 Engine time: 0.05526819499209523 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-32/adapters_384_slots_64_rate_3.2-0.4-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-32/adapters_384_slots_64_rate_3.2-0.4-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 4320, 66, 34560, 34560, 66, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 66, 34560, 66, 34560, 4320, 4320, 4320, 66, 66, 4320, 66, 34560, 66, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 34560, 66, 34560, 34560, 34560, 34560, 66, 4320, 4320, 4320, 34560, 4320, 66, 4320, 66, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 66, 66, 34560, 4320, 4320, 66, 66, 66, 4320, 66, 4320, 66, 34560, 66, 4320, 34560, 66, 34560, 4320, 66, 34560, 34560, 34560, 34560, 4320, 66, 4320, 34560, 34560, 4320, 66, 66, 34560, 4320, 4320, 66, 66, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 66, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 34560, 66, 66, 66, 4320, 4320, 34560, 66, 66, 34560, 66, 34560, 4320, 66, 34560, 4320, 4320, 66, 34560, 34560, 34560, 66, 4320, 34560, 66, 34560, 4320, 4320, 34560, 34560, 66, 4320, 34560, 66, 4320, 4320, 66, 4320, 66, 4320, 34560, 34560, 4320, 66, 34560, 66, 34560, 4320, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 34560, 66, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 66, 66, 66, 66, 66, 4320, 66, 66, 4320, 34560, 34560, 66, 66, 34560, 66, 66, 66, 4320, 66, 4320, 34560, 34560, 4320, 4320, 66, 34560, 4320, 34560, 66, 4320, 4320, 66, 66, 4320, 66, 34560, 34560, 66, 34560, 34560, 66, 4320, 34560, 66, 66, 4320, 4320, 66, 66, 34560, 34560, 34560, 34560, 4320, 66, 4320, 4320, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 34560, 4320, 4320, 4320, 34560, 66, 4320, 4320, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 4320, 66, 34560, 34560, 34560, 4320, 66, 34560, 34560, 4320, 4320, 34560, 34560, 66, 34560, 34560, 4320, 66, 34560, 4320, 4320, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 4320, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 34560, 66, 66, 66, 4320, 66, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 34560, 34560, 66, 34560, 34560, 66, 34560, 4320, 34560, 4320, 4320, 4320, 66, 4320, 66, 66, 34560, 66, 4320, 66, 66, 4320, 34560, 4320, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4985088 . Total input tokens: 1110432516 . Total output tokens: 996850533
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 82.52392349438742,
    "estimated_duration": 3600.1633241103486,
    "input_throughput": 6222.216600558144,
    "output_throughput": 5493.592712182684,
    "total_throughput": 11715.809312740828,
    "itl": 154.18535401040072,
    "ttft": 2102270.090152015,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 414,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3534343593753952,
    "arrivals": 1660646,
    "finished_requests": 90525,
    "scheduler_time": 174.5471977985631
}
#Debug simulation 
Total elapsed time: 82.52405615197495. Arrivals time: 0.4387767189182341 Scheduler time: 81.93315065512434 Scheduler overhead time: 0.060591788962483406 Adapter cache time: 0.014948904048651457 Engine time: 0.055147647857666016 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-16-16/adapters_384_slots_64_rate_3.2-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-16-16/adapters_384_slots_64_rate_3.2-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 4320, 66, 34560, 34560, 66, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 66, 34560, 66, 34560, 4320, 4320, 4320, 66, 66, 4320, 66, 34560, 66, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 34560, 66, 34560, 34560, 34560, 34560, 66, 4320, 4320, 4320, 34560, 4320, 66, 4320, 66, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 66, 66, 34560, 4320, 4320, 66, 66, 66, 4320, 66, 4320, 66, 34560, 66, 4320, 34560, 66, 34560, 4320, 66, 34560, 34560, 34560, 34560, 4320, 66, 4320, 34560, 34560, 4320, 66, 66, 34560, 4320, 4320, 66, 66, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 66, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 34560, 66, 66, 66, 4320, 4320, 34560, 66, 66, 34560, 66, 34560, 4320, 66, 34560, 4320, 4320, 66, 34560, 34560, 34560, 66, 4320, 34560, 66, 34560, 4320, 4320, 34560, 34560, 66, 4320, 34560, 66, 4320, 4320, 66, 4320, 66, 4320, 34560, 34560, 4320, 66, 34560, 66, 34560, 4320, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 34560, 66, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 66, 66, 66, 66, 66, 4320, 66, 66, 4320, 34560, 34560, 66, 66, 34560, 66, 66, 66, 4320, 66, 4320, 34560, 34560, 4320, 4320, 66, 34560, 4320, 34560, 66, 4320, 4320, 66, 66, 4320, 66, 34560, 34560, 66, 34560, 34560, 66, 4320, 34560, 66, 66, 4320, 4320, 66, 66, 34560, 34560, 34560, 34560, 4320, 66, 4320, 4320, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 34560, 4320, 4320, 4320, 34560, 66, 4320, 4320, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 4320, 66, 34560, 34560, 34560, 4320, 66, 34560, 34560, 4320, 4320, 34560, 34560, 66, 34560, 34560, 4320, 66, 34560, 4320, 4320, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 4320, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 34560, 66, 66, 66, 4320, 66, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 34560, 34560, 66, 34560, 34560, 66, 34560, 4320, 34560, 4320, 4320, 4320, 66, 4320, 66, 66, 34560, 66, 4320, 66, 66, 4320, 34560, 4320, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4985088 . Total input tokens: 1110432516 . Total output tokens: 996850533
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 77.42461980786175,
    "estimated_duration": 3600.142710332427,
    "input_throughput": 6199.486741440625,
    "output_throughput": 5471.882529395896,
    "total_throughput": 11671.369270836522,
    "itl": 152.85269857941483,
    "ttft": 2103399.9797915523,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 503,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5734565024706464,
    "arrivals": 1660646,
    "finished_requests": 90208,
    "scheduler_time": 175.5089389834669
}
#Debug simulation 
Total elapsed time: 77.42474947264418. Arrivals time: 0.4343358129262924 Scheduler time: 76.83726553525776 Scheduler overhead time: 0.06003901129588485 Adapter cache time: 0.016192809212952852 Engine time: 0.05554538778960705 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-16-32/adapters_384_slots_64_rate_3.2-0.4-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-16-32/adapters_384_slots_64_rate_3.2-0.4-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 4320, 66, 34560, 34560, 66, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 66, 34560, 66, 34560, 4320, 4320, 4320, 66, 66, 4320, 66, 34560, 66, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 34560, 66, 34560, 34560, 34560, 34560, 66, 4320, 4320, 4320, 34560, 4320, 66, 4320, 66, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 66, 66, 34560, 4320, 4320, 66, 66, 66, 4320, 66, 4320, 66, 34560, 66, 4320, 34560, 66, 34560, 4320, 66, 34560, 34560, 34560, 34560, 4320, 66, 4320, 34560, 34560, 4320, 66, 66, 34560, 4320, 4320, 66, 66, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 66, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 34560, 66, 66, 66, 4320, 4320, 34560, 66, 66, 34560, 66, 34560, 4320, 66, 34560, 4320, 4320, 66, 34560, 34560, 34560, 66, 4320, 34560, 66, 34560, 4320, 4320, 34560, 34560, 66, 4320, 34560, 66, 4320, 4320, 66, 4320, 66, 4320, 34560, 34560, 4320, 66, 34560, 66, 34560, 4320, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 34560, 66, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 66, 66, 66, 66, 66, 4320, 66, 66, 4320, 34560, 34560, 66, 66, 34560, 66, 66, 66, 4320, 66, 4320, 34560, 34560, 4320, 4320, 66, 34560, 4320, 34560, 66, 4320, 4320, 66, 66, 4320, 66, 34560, 34560, 66, 34560, 34560, 66, 4320, 34560, 66, 66, 4320, 4320, 66, 66, 34560, 34560, 34560, 34560, 4320, 66, 4320, 4320, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 34560, 4320, 4320, 4320, 34560, 66, 4320, 4320, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 4320, 66, 34560, 34560, 34560, 4320, 66, 34560, 34560, 4320, 4320, 34560, 34560, 66, 34560, 34560, 4320, 66, 34560, 4320, 4320, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 4320, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 34560, 66, 66, 66, 4320, 66, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 34560, 34560, 66, 34560, 34560, 66, 34560, 4320, 34560, 4320, 4320, 4320, 66, 4320, 66, 66, 34560, 66, 4320, 66, 66, 4320, 34560, 4320, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4985088 . Total input tokens: 1110432516 . Total output tokens: 996850533
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 82.72149412892759,
    "estimated_duration": 3600.009153694525,
    "input_throughput": 6222.301400820482,
    "output_throughput": 5493.691586784833,
    "total_throughput": 11715.992987605314,
    "itl": 154.18552291490852,
    "ttft": 2102244.1942764455,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 414,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.370914135687058,
    "arrivals": 1660646,
    "finished_requests": 90523,
    "scheduler_time": 174.53900085458588
}
#Debug simulation 
Total elapsed time: 82.72163193672895. Arrivals time: 0.43141045048832893 Scheduler time: 82.13777730241418 Scheduler overhead time: 0.06111736781895161 Adapter cache time: 0.015026672277599573 Engine time: 0.054923757910728455 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_16-16-16/adapters_384_slots_64_rate_3.2-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_16-16-16/adapters_384_slots_64_rate_3.2-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 4320, 66, 34560, 34560, 66, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 66, 34560, 66, 34560, 4320, 4320, 4320, 66, 66, 4320, 66, 34560, 66, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 34560, 66, 34560, 34560, 34560, 34560, 66, 4320, 4320, 4320, 34560, 4320, 66, 4320, 66, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 66, 66, 34560, 4320, 4320, 66, 66, 66, 4320, 66, 4320, 66, 34560, 66, 4320, 34560, 66, 34560, 4320, 66, 34560, 34560, 34560, 34560, 4320, 66, 4320, 34560, 34560, 4320, 66, 66, 34560, 4320, 4320, 66, 66, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 66, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 34560, 66, 66, 66, 4320, 4320, 34560, 66, 66, 34560, 66, 34560, 4320, 66, 34560, 4320, 4320, 66, 34560, 34560, 34560, 66, 4320, 34560, 66, 34560, 4320, 4320, 34560, 34560, 66, 4320, 34560, 66, 4320, 4320, 66, 4320, 66, 4320, 34560, 34560, 4320, 66, 34560, 66, 34560, 4320, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 34560, 66, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 66, 66, 66, 66, 66, 4320, 66, 66, 4320, 34560, 34560, 66, 66, 34560, 66, 66, 66, 4320, 66, 4320, 34560, 34560, 4320, 4320, 66, 34560, 4320, 34560, 66, 4320, 4320, 66, 66, 4320, 66, 34560, 34560, 66, 34560, 34560, 66, 4320, 34560, 66, 66, 4320, 4320, 66, 66, 34560, 34560, 34560, 34560, 4320, 66, 4320, 4320, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 34560, 4320, 4320, 4320, 34560, 66, 4320, 4320, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 4320, 66, 34560, 34560, 34560, 4320, 66, 34560, 34560, 4320, 4320, 34560, 34560, 66, 34560, 34560, 4320, 66, 34560, 4320, 4320, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 4320, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 34560, 66, 66, 66, 4320, 66, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 34560, 34560, 66, 34560, 34560, 66, 34560, 4320, 34560, 4320, 4320, 4320, 66, 4320, 66, 66, 34560, 66, 4320, 66, 66, 4320, 34560, 4320, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4985088 . Total input tokens: 1110432516 . Total output tokens: 996850533
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 77.40355837577954,
    "estimated_duration": 3600.072831851044,
    "input_throughput": 6199.607075316932,
    "output_throughput": 5471.988740258654,
    "total_throughput": 11671.595815575587,
    "itl": 152.85010167610105,
    "ttft": 2103370.0531210015,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 503,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5039952983357778,
    "arrivals": 1660646,
    "finished_requests": 90208,
    "scheduler_time": 175.50852170620098
}
#Debug simulation 
Total elapsed time: 77.40368046006188. Arrivals time: 0.44368706084787846 Scheduler time: 76.80790709424764 Scheduler overhead time: 0.0600138702429831 Adapter cache time: 0.015752532053738832 Engine time: 0.05473946966230869 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_16-16-32/adapters_384_slots_64_rate_3.2-0.4-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_16-16-32/adapters_384_slots_64_rate_3.2-0.4-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 4320, 66, 34560, 34560, 66, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 66, 34560, 66, 34560, 4320, 4320, 4320, 66, 66, 4320, 66, 34560, 66, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 34560, 66, 34560, 34560, 34560, 34560, 66, 4320, 4320, 4320, 34560, 4320, 66, 4320, 66, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 66, 66, 34560, 4320, 4320, 66, 66, 66, 4320, 66, 4320, 66, 34560, 66, 4320, 34560, 66, 34560, 4320, 66, 34560, 34560, 34560, 34560, 4320, 66, 4320, 34560, 34560, 4320, 66, 66, 34560, 4320, 4320, 66, 66, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 66, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 34560, 66, 66, 66, 4320, 4320, 34560, 66, 66, 34560, 66, 34560, 4320, 66, 34560, 4320, 4320, 66, 34560, 34560, 34560, 66, 4320, 34560, 66, 34560, 4320, 4320, 34560, 34560, 66, 4320, 34560, 66, 4320, 4320, 66, 4320, 66, 4320, 34560, 34560, 4320, 66, 34560, 66, 34560, 4320, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 34560, 66, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 66, 66, 66, 66, 66, 4320, 66, 66, 4320, 34560, 34560, 66, 66, 34560, 66, 66, 66, 4320, 66, 4320, 34560, 34560, 4320, 4320, 66, 34560, 4320, 34560, 66, 4320, 4320, 66, 66, 4320, 66, 34560, 34560, 66, 34560, 34560, 66, 4320, 34560, 66, 66, 4320, 4320, 66, 66, 34560, 34560, 34560, 34560, 4320, 66, 4320, 4320, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 34560, 4320, 4320, 4320, 34560, 66, 4320, 4320, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 4320, 66, 34560, 34560, 34560, 4320, 66, 34560, 34560, 4320, 4320, 34560, 34560, 66, 34560, 34560, 4320, 66, 34560, 4320, 4320, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 4320, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 34560, 66, 66, 66, 4320, 66, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 34560, 34560, 66, 34560, 34560, 66, 34560, 4320, 34560, 4320, 4320, 4320, 66, 4320, 66, 66, 34560, 66, 4320, 66, 66, 4320, 34560, 4320, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4985088 . Total input tokens: 1110432516 . Total output tokens: 996850533
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 82.8139312537387,
    "estimated_duration": 3600.026642063518,
    "input_throughput": 6222.271173848933,
    "output_throughput": 5493.664899286335,
    "total_throughput": 11715.936073135268,
    "itl": 154.18612182621948,
    "ttft": 2102252.305857653,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 414,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3882681582123053,
    "arrivals": 1660646,
    "finished_requests": 90523,
    "scheduler_time": 174.53913520107218
}
#Debug simulation 
Total elapsed time: 82.81405862467363. Arrivals time: 0.44401526590809226 Scheduler time: 82.21840381482616 Scheduler overhead time: 0.05969189153984189 Adapter cache time: 0.014865450095385313 Engine time: 0.05547913396731019 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-8/adapters_384_slots_64_rate_3.2-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-8/adapters_384_slots_64_rate_3.2-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 4320, 33, 34560, 34560, 33, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 33, 34560, 33, 34560, 4320, 4320, 4320, 33, 33, 4320, 33, 34560, 33, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 34560, 33, 34560, 34560, 34560, 34560, 33, 4320, 4320, 4320, 34560, 4320, 33, 4320, 33, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 33, 33, 34560, 4320, 4320, 33, 33, 33, 4320, 33, 4320, 33, 34560, 33, 4320, 34560, 33, 34560, 4320, 33, 34560, 34560, 34560, 34560, 4320, 33, 4320, 34560, 34560, 4320, 33, 33, 34560, 4320, 4320, 33, 33, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 33, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 34560, 33, 33, 33, 4320, 4320, 34560, 33, 33, 34560, 33, 34560, 4320, 33, 34560, 4320, 4320, 33, 34560, 34560, 34560, 33, 4320, 34560, 33, 34560, 4320, 4320, 34560, 34560, 33, 4320, 34560, 33, 4320, 4320, 33, 4320, 33, 4320, 34560, 34560, 4320, 33, 34560, 33, 34560, 4320, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 34560, 33, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 33, 33, 33, 33, 33, 4320, 33, 33, 4320, 34560, 34560, 33, 33, 34560, 33, 33, 33, 4320, 33, 4320, 34560, 34560, 4320, 4320, 33, 34560, 4320, 34560, 33, 4320, 4320, 33, 33, 4320, 33, 34560, 34560, 33, 34560, 34560, 33, 4320, 34560, 33, 33, 4320, 4320, 33, 33, 34560, 34560, 34560, 34560, 4320, 33, 4320, 4320, 33, 33, 33, 33, 33, 33, 33, 33, 4320, 34560, 4320, 4320, 4320, 34560, 33, 4320, 4320, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 4320, 33, 34560, 34560, 34560, 4320, 33, 34560, 34560, 4320, 4320, 34560, 34560, 33, 34560, 34560, 4320, 33, 34560, 4320, 4320, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 4320, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 34560, 33, 33, 33, 4320, 33, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 34560, 34560, 33, 34560, 34560, 33, 34560, 4320, 34560, 4320, 4320, 4320, 33, 4320, 33, 33, 34560, 33, 4320, 33, 33, 4320, 34560, 4320, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4980864 . Total input tokens: 1109503977 . Total output tokens: 996018309
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 74.69951190100983,
    "estimated_duration": 3600.0895804777824,
    "input_throughput": 6220.214663944026,
    "output_throughput": 5472.535491015565,
    "total_throughput": 11692.75015495959,
    "itl": 152.8086940571664,
    "ttft": 2100748.9129219963,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 443,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.355796070562221,
    "arrivals": 1659330,
    "finished_requests": 90339,
    "scheduler_time": 175.51115733089168
}
#Debug simulation 
Total elapsed time: 74.69963522907346. Arrivals time: 0.44877201318740845 Scheduler time: 74.10209866100922 Scheduler overhead time: 0.05904635274782777 Adapter cache time: 0.014951084740459919 Engine time: 0.053794543258845806 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-16/adapters_384_slots_64_rate_3.2-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-16/adapters_384_slots_64_rate_3.2-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 4320, 33, 34560, 34560, 33, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 33, 34560, 33, 34560, 4320, 4320, 4320, 33, 33, 4320, 33, 34560, 33, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 34560, 33, 34560, 34560, 34560, 34560, 33, 4320, 4320, 4320, 34560, 4320, 33, 4320, 33, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 33, 33, 34560, 4320, 4320, 33, 33, 33, 4320, 33, 4320, 33, 34560, 33, 4320, 34560, 33, 34560, 4320, 33, 34560, 34560, 34560, 34560, 4320, 33, 4320, 34560, 34560, 4320, 33, 33, 34560, 4320, 4320, 33, 33, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 33, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 34560, 33, 33, 33, 4320, 4320, 34560, 33, 33, 34560, 33, 34560, 4320, 33, 34560, 4320, 4320, 33, 34560, 34560, 34560, 33, 4320, 34560, 33, 34560, 4320, 4320, 34560, 34560, 33, 4320, 34560, 33, 4320, 4320, 33, 4320, 33, 4320, 34560, 34560, 4320, 33, 34560, 33, 34560, 4320, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 34560, 33, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 33, 33, 33, 33, 33, 4320, 33, 33, 4320, 34560, 34560, 33, 33, 34560, 33, 33, 33, 4320, 33, 4320, 34560, 34560, 4320, 4320, 33, 34560, 4320, 34560, 33, 4320, 4320, 33, 33, 4320, 33, 34560, 34560, 33, 34560, 34560, 33, 4320, 34560, 33, 33, 4320, 4320, 33, 33, 34560, 34560, 34560, 34560, 4320, 33, 4320, 4320, 33, 33, 33, 33, 33, 33, 33, 33, 4320, 34560, 4320, 4320, 4320, 34560, 33, 4320, 4320, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 4320, 33, 34560, 34560, 34560, 4320, 33, 34560, 34560, 4320, 4320, 34560, 34560, 33, 34560, 34560, 4320, 33, 34560, 4320, 4320, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 4320, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 34560, 33, 33, 33, 4320, 33, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 34560, 34560, 33, 34560, 34560, 33, 34560, 4320, 34560, 4320, 4320, 4320, 33, 4320, 33, 33, 34560, 33, 4320, 33, 33, 4320, 34560, 4320, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4980864 . Total input tokens: 1109503977 . Total output tokens: 996018309
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 74.79970539594069,
    "estimated_duration": 3600.0100936056733,
    "input_throughput": 6219.935060674496,
    "output_throughput": 5472.254379228376,
    "total_throughput": 11692.189439902872,
    "itl": 152.81168566846085,
    "ttft": 2100747.176917988,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 443,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4463536855368928,
    "arrivals": 1659330,
    "finished_requests": 90334,
    "scheduler_time": 175.50345218845763
}
#Debug simulation 
Total elapsed time: 74.79982402408496. Arrivals time: 0.44891752349212766 Scheduler time: 74.20110316202044 Scheduler overhead time: 0.059172640554606915 Adapter cache time: 0.015222056768834591 Engine time: 0.054388963617384434 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-32/adapters_384_slots_64_rate_3.2-0.4-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-32/adapters_384_slots_64_rate_3.2-0.4-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 4320, 33, 34560, 34560, 33, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 33, 34560, 33, 34560, 4320, 4320, 4320, 33, 33, 4320, 33, 34560, 33, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 34560, 33, 34560, 34560, 34560, 34560, 33, 4320, 4320, 4320, 34560, 4320, 33, 4320, 33, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 33, 33, 34560, 4320, 4320, 33, 33, 33, 4320, 33, 4320, 33, 34560, 33, 4320, 34560, 33, 34560, 4320, 33, 34560, 34560, 34560, 34560, 4320, 33, 4320, 34560, 34560, 4320, 33, 33, 34560, 4320, 4320, 33, 33, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 33, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 34560, 33, 33, 33, 4320, 4320, 34560, 33, 33, 34560, 33, 34560, 4320, 33, 34560, 4320, 4320, 33, 34560, 34560, 34560, 33, 4320, 34560, 33, 34560, 4320, 4320, 34560, 34560, 33, 4320, 34560, 33, 4320, 4320, 33, 4320, 33, 4320, 34560, 34560, 4320, 33, 34560, 33, 34560, 4320, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 34560, 33, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 33, 33, 33, 33, 33, 4320, 33, 33, 4320, 34560, 34560, 33, 33, 34560, 33, 33, 33, 4320, 33, 4320, 34560, 34560, 4320, 4320, 33, 34560, 4320, 34560, 33, 4320, 4320, 33, 33, 4320, 33, 34560, 34560, 33, 34560, 34560, 33, 4320, 34560, 33, 33, 4320, 4320, 33, 33, 34560, 34560, 34560, 34560, 4320, 33, 4320, 4320, 33, 33, 33, 33, 33, 33, 33, 33, 4320, 34560, 4320, 4320, 4320, 34560, 33, 4320, 4320, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 4320, 33, 34560, 34560, 34560, 4320, 33, 34560, 34560, 4320, 4320, 34560, 34560, 33, 34560, 34560, 4320, 33, 34560, 4320, 4320, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 4320, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 34560, 33, 33, 33, 4320, 33, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 34560, 34560, 33, 34560, 34560, 33, 34560, 4320, 34560, 4320, 4320, 4320, 33, 4320, 33, 33, 34560, 33, 4320, 33, 33, 4320, 34560, 4320, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4980864 . Total input tokens: 1109503977 . Total output tokens: 996018309
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 74.74989124992862,
    "estimated_duration": 3600.0125353168496,
    "input_throughput": 6219.93084199892,
    "output_throughput": 5472.250667667778,
    "total_throughput": 11692.181509666698,
    "itl": 152.8117679915099,
    "ttft": 2100748.0964339534,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 443,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4487786033749666,
    "arrivals": 1659330,
    "finished_requests": 90334,
    "scheduler_time": 175.5034689817684
}
#Debug simulation 
Total elapsed time: 74.75001216307282. Arrivals time: 0.44706407748162746 Scheduler time: 74.1519980346784 Scheduler overhead time: 0.05961216054856777 Adapter cache time: 0.0151474354788661 Engine time: 0.05479833297431469 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-16/adapters_384_slots_64_rate_3.2-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-16/adapters_384_slots_64_rate_3.2-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 4320, 33, 34560, 34560, 33, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 33, 34560, 33, 34560, 4320, 4320, 4320, 33, 33, 4320, 33, 34560, 33, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 34560, 33, 34560, 34560, 34560, 34560, 33, 4320, 4320, 4320, 34560, 4320, 33, 4320, 33, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 33, 33, 34560, 4320, 4320, 33, 33, 33, 4320, 33, 4320, 33, 34560, 33, 4320, 34560, 33, 34560, 4320, 33, 34560, 34560, 34560, 34560, 4320, 33, 4320, 34560, 34560, 4320, 33, 33, 34560, 4320, 4320, 33, 33, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 33, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 34560, 33, 33, 33, 4320, 4320, 34560, 33, 33, 34560, 33, 34560, 4320, 33, 34560, 4320, 4320, 33, 34560, 34560, 34560, 33, 4320, 34560, 33, 34560, 4320, 4320, 34560, 34560, 33, 4320, 34560, 33, 4320, 4320, 33, 4320, 33, 4320, 34560, 34560, 4320, 33, 34560, 33, 34560, 4320, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 34560, 33, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 33, 33, 33, 33, 33, 4320, 33, 33, 4320, 34560, 34560, 33, 33, 34560, 33, 33, 33, 4320, 33, 4320, 34560, 34560, 4320, 4320, 33, 34560, 4320, 34560, 33, 4320, 4320, 33, 33, 4320, 33, 34560, 34560, 33, 34560, 34560, 33, 4320, 34560, 33, 33, 4320, 4320, 33, 33, 34560, 34560, 34560, 34560, 4320, 33, 4320, 4320, 33, 33, 33, 33, 33, 33, 33, 33, 4320, 34560, 4320, 4320, 4320, 34560, 33, 4320, 4320, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 4320, 33, 34560, 34560, 34560, 4320, 33, 34560, 34560, 4320, 4320, 34560, 34560, 33, 34560, 34560, 4320, 33, 34560, 4320, 4320, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 4320, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 34560, 33, 33, 33, 4320, 33, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 34560, 34560, 33, 34560, 34560, 33, 34560, 4320, 34560, 4320, 4320, 4320, 33, 4320, 33, 33, 34560, 33, 4320, 33, 33, 4320, 34560, 4320, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4980864 . Total input tokens: 1109503977 . Total output tokens: 996018309
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 75.27038001595065,
    "estimated_duration": 3600.1190731317624,
    "input_throughput": 6220.1637071187,
    "output_throughput": 5472.490659277405,
    "total_throughput": 11692.654366396106,
    "itl": 152.80975026613234,
    "ttft": 2100762.167032506,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 443,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3850643877708317,
    "arrivals": 1659330,
    "finished_requests": 90339,
    "scheduler_time": 175.5113816676195
}
#Debug simulation 
Total elapsed time: 75.27050650399178. Arrivals time: 0.8488740413449705 Scheduler time: 74.27218369347975 Scheduler overhead time: 0.058599506970494986 Adapter cache time: 0.01547197112813592 Engine time: 0.05406846525147557 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-32/adapters_384_slots_64_rate_3.2-0.4-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-32/adapters_384_slots_64_rate_3.2-0.4-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 4320, 33, 34560, 34560, 33, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 33, 34560, 33, 34560, 4320, 4320, 4320, 33, 33, 4320, 33, 34560, 33, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 34560, 33, 34560, 34560, 34560, 34560, 33, 4320, 4320, 4320, 34560, 4320, 33, 4320, 33, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 33, 33, 34560, 4320, 4320, 33, 33, 33, 4320, 33, 4320, 33, 34560, 33, 4320, 34560, 33, 34560, 4320, 33, 34560, 34560, 34560, 34560, 4320, 33, 4320, 34560, 34560, 4320, 33, 33, 34560, 4320, 4320, 33, 33, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 33, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 34560, 33, 33, 33, 4320, 4320, 34560, 33, 33, 34560, 33, 34560, 4320, 33, 34560, 4320, 4320, 33, 34560, 34560, 34560, 33, 4320, 34560, 33, 34560, 4320, 4320, 34560, 34560, 33, 4320, 34560, 33, 4320, 4320, 33, 4320, 33, 4320, 34560, 34560, 4320, 33, 34560, 33, 34560, 4320, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 34560, 33, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 33, 33, 33, 33, 33, 4320, 33, 33, 4320, 34560, 34560, 33, 33, 34560, 33, 33, 33, 4320, 33, 4320, 34560, 34560, 4320, 4320, 33, 34560, 4320, 34560, 33, 4320, 4320, 33, 33, 4320, 33, 34560, 34560, 33, 34560, 34560, 33, 4320, 34560, 33, 33, 4320, 4320, 33, 33, 34560, 34560, 34560, 34560, 4320, 33, 4320, 4320, 33, 33, 33, 33, 33, 33, 33, 33, 4320, 34560, 4320, 4320, 4320, 34560, 33, 4320, 4320, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 4320, 33, 34560, 34560, 34560, 4320, 33, 34560, 34560, 4320, 4320, 34560, 34560, 33, 34560, 34560, 4320, 33, 34560, 4320, 4320, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 4320, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 34560, 33, 33, 33, 4320, 33, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 34560, 34560, 33, 34560, 34560, 33, 34560, 4320, 34560, 4320, 4320, 4320, 33, 4320, 33, 33, 34560, 33, 4320, 33, 33, 4320, 34560, 4320, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4980864 . Total input tokens: 1109503977 . Total output tokens: 996018309
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 74.84818347822875,
    "estimated_duration": 3600.0315102793434,
    "input_throughput": 6219.898058131861,
    "output_throughput": 5472.221824656021,
    "total_throughput": 11692.119882787883,
    "itl": 152.81243118171358,
    "ttft": 2100755.7423754577,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 443,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4676416713371914,
    "arrivals": 1659330,
    "finished_requests": 90334,
    "scheduler_time": 175.50358087632833
}
#Debug simulation 
Total elapsed time: 74.84830777626485. Arrivals time: 0.45681719621643424 Scheduler time: 74.24045547982678 Scheduler overhead time: 0.059820969589054585 Adapter cache time: 0.015526867005974054 Engine time: 0.05391611624509096 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-16/adapters_384_slots_64_rate_3.2-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-16/adapters_384_slots_64_rate_3.2-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 4320, 33, 34560, 34560, 33, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 33, 34560, 33, 34560, 4320, 4320, 4320, 33, 33, 4320, 33, 34560, 33, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 34560, 33, 34560, 34560, 34560, 34560, 33, 4320, 4320, 4320, 34560, 4320, 33, 4320, 33, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 33, 33, 34560, 4320, 4320, 33, 33, 33, 4320, 33, 4320, 33, 34560, 33, 4320, 34560, 33, 34560, 4320, 33, 34560, 34560, 34560, 34560, 4320, 33, 4320, 34560, 34560, 4320, 33, 33, 34560, 4320, 4320, 33, 33, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 33, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 34560, 33, 33, 33, 4320, 4320, 34560, 33, 33, 34560, 33, 34560, 4320, 33, 34560, 4320, 4320, 33, 34560, 34560, 34560, 33, 4320, 34560, 33, 34560, 4320, 4320, 34560, 34560, 33, 4320, 34560, 33, 4320, 4320, 33, 4320, 33, 4320, 34560, 34560, 4320, 33, 34560, 33, 34560, 4320, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 34560, 33, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 33, 33, 33, 33, 33, 4320, 33, 33, 4320, 34560, 34560, 33, 33, 34560, 33, 33, 33, 4320, 33, 4320, 34560, 34560, 4320, 4320, 33, 34560, 4320, 34560, 33, 4320, 4320, 33, 33, 4320, 33, 34560, 34560, 33, 34560, 34560, 33, 4320, 34560, 33, 33, 4320, 4320, 33, 33, 34560, 34560, 34560, 34560, 4320, 33, 4320, 4320, 33, 33, 33, 33, 33, 33, 33, 33, 4320, 34560, 4320, 4320, 4320, 34560, 33, 4320, 4320, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 4320, 33, 34560, 34560, 34560, 4320, 33, 34560, 34560, 4320, 4320, 34560, 34560, 33, 34560, 34560, 4320, 33, 34560, 4320, 4320, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 4320, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 34560, 33, 33, 33, 4320, 33, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 34560, 34560, 33, 34560, 34560, 33, 34560, 4320, 34560, 4320, 4320, 4320, 33, 4320, 33, 33, 34560, 33, 4320, 33, 33, 4320, 34560, 4320, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4980864 . Total input tokens: 1109503977 . Total output tokens: 996018309
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 75.04335549334064,
    "estimated_duration": 3600.058166954072,
    "input_throughput": 6220.2689405283945,
    "output_throughput": 5472.583243472728,
    "total_throughput": 11692.852184001124,
    "itl": 152.80759361676837,
    "ttft": 2100735.9532027426,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 443,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3245922806416537,
    "arrivals": 1659330,
    "finished_requests": 90339,
    "scheduler_time": 175.5109475970428
}
#Debug simulation 
Total elapsed time: 75.0434778383933. Arrivals time: 0.44949032505974174 Scheduler time: 74.44241271959618 Scheduler overhead time: 0.05927797872573137 Adapter cache time: 0.015423970762640238 Engine time: 0.05544564872980118 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-32/adapters_384_slots_64_rate_3.2-0.4-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-32/adapters_384_slots_64_rate_3.2-0.4-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 4320, 33, 34560, 34560, 33, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 33, 34560, 33, 34560, 4320, 4320, 4320, 33, 33, 4320, 33, 34560, 33, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 34560, 33, 34560, 34560, 34560, 34560, 33, 4320, 4320, 4320, 34560, 4320, 33, 4320, 33, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 33, 33, 34560, 4320, 4320, 33, 33, 33, 4320, 33, 4320, 33, 34560, 33, 4320, 34560, 33, 34560, 4320, 33, 34560, 34560, 34560, 34560, 4320, 33, 4320, 34560, 34560, 4320, 33, 33, 34560, 4320, 4320, 33, 33, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 33, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 34560, 33, 33, 33, 4320, 4320, 34560, 33, 33, 34560, 33, 34560, 4320, 33, 34560, 4320, 4320, 33, 34560, 34560, 34560, 33, 4320, 34560, 33, 34560, 4320, 4320, 34560, 34560, 33, 4320, 34560, 33, 4320, 4320, 33, 4320, 33, 4320, 34560, 34560, 4320, 33, 34560, 33, 34560, 4320, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 34560, 33, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 33, 33, 33, 33, 33, 4320, 33, 33, 4320, 34560, 34560, 33, 33, 34560, 33, 33, 33, 4320, 33, 4320, 34560, 34560, 4320, 4320, 33, 34560, 4320, 34560, 33, 4320, 4320, 33, 33, 4320, 33, 34560, 34560, 33, 34560, 34560, 33, 4320, 34560, 33, 33, 4320, 4320, 33, 33, 34560, 34560, 34560, 34560, 4320, 33, 4320, 4320, 33, 33, 33, 33, 33, 33, 33, 33, 4320, 34560, 4320, 4320, 4320, 34560, 33, 4320, 4320, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 4320, 33, 34560, 34560, 34560, 4320, 33, 34560, 34560, 4320, 4320, 34560, 34560, 33, 34560, 34560, 4320, 33, 34560, 4320, 4320, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 4320, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 34560, 33, 33, 33, 4320, 33, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 34560, 34560, 33, 34560, 34560, 33, 34560, 4320, 34560, 4320, 4320, 4320, 33, 4320, 33, 33, 34560, 33, 4320, 33, 33, 4320, 34560, 4320, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4980864 . Total input tokens: 1109503977 . Total output tokens: 996018309
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 74.76195535296574,
    "estimated_duration": 3600.050255638588,
    "input_throughput": 6219.865671299654,
    "output_throughput": 5472.193330952688,
    "total_throughput": 11692.059002252343,
    "itl": 152.81309495757998,
    "ttft": 2100763.8099068725,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 443,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.486253231726587,
    "arrivals": 1659330,
    "finished_requests": 90334,
    "scheduler_time": 175.50371467520668
}
#Debug simulation 
Total elapsed time: 74.76208472205326. Arrivals time: 0.4556582528166473 Scheduler time: 74.1555808391422 Scheduler overhead time: 0.05960970092564821 Adapter cache time: 0.015258946921676397 Engine time: 0.054613867308944464 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-8/adapters_384_slots_64_rate_3.2-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-8/adapters_384_slots_64_rate_3.2-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 1080, 540, 34560, 34560, 540, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 540, 34560, 540, 34560, 1080, 1080, 1080, 540, 540, 1080, 540, 34560, 540, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 34560, 540, 34560, 34560, 34560, 34560, 540, 1080, 1080, 1080, 34560, 1080, 540, 1080, 540, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 540, 540, 34560, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 34560, 540, 1080, 34560, 540, 34560, 1080, 540, 34560, 34560, 34560, 34560, 1080, 540, 1080, 34560, 34560, 1080, 540, 540, 34560, 1080, 1080, 540, 540, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 540, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 34560, 540, 540, 540, 1080, 1080, 34560, 540, 540, 34560, 540, 34560, 1080, 540, 34560, 1080, 1080, 540, 34560, 34560, 34560, 540, 1080, 34560, 540, 34560, 1080, 1080, 34560, 34560, 540, 1080, 34560, 540, 1080, 1080, 540, 1080, 540, 1080, 34560, 34560, 1080, 540, 34560, 540, 34560, 1080, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 34560, 540, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 34560, 34560, 540, 540, 34560, 540, 540, 540, 1080, 540, 1080, 34560, 34560, 1080, 1080, 540, 34560, 1080, 34560, 540, 1080, 1080, 540, 540, 1080, 540, 34560, 34560, 540, 34560, 34560, 540, 1080, 34560, 540, 540, 1080, 1080, 540, 540, 34560, 34560, 34560, 34560, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 34560, 1080, 1080, 1080, 34560, 540, 1080, 1080, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 1080, 540, 34560, 34560, 34560, 1080, 540, 34560, 34560, 1080, 1080, 34560, 34560, 540, 34560, 34560, 1080, 540, 34560, 1080, 1080, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 1080, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 34560, 540, 540, 540, 1080, 540, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 34560, 34560, 540, 34560, 34560, 540, 34560, 1080, 34560, 1080, 1080, 1080, 540, 1080, 540, 540, 34560, 540, 1080, 540, 540, 1080, 34560, 1080, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4631040 . Total input tokens: 1031716165 . Total output tokens: 925998705
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 75.91220643604174,
    "estimated_duration": 3600.10809348798,
    "input_throughput": 6149.903676516907,
    "output_throughput": 5405.587691992164,
    "total_throughput": 11555.49136850907,
    "itl": 150.39325882748145,
    "ttft": 2090654.08997673,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 501,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5333043597103269,
    "arrivals": 1542191,
    "finished_requests": 89411,
    "scheduler_time": 178.99379346280998
}
#Debug simulation 
Total elapsed time: 75.91232507908717. Arrivals time: 0.44107989268377423 Scheduler time: 75.32261541113257 Scheduler overhead time: 0.05787107488140464 Adapter cache time: 0.016086469404399395 Engine time: 0.05291352700442076 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-16/adapters_384_slots_64_rate_3.2-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-16/adapters_384_slots_64_rate_3.2-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 1080, 540, 34560, 34560, 540, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 540, 34560, 540, 34560, 1080, 1080, 1080, 540, 540, 1080, 540, 34560, 540, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 34560, 540, 34560, 34560, 34560, 34560, 540, 1080, 1080, 1080, 34560, 1080, 540, 1080, 540, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 540, 540, 34560, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 34560, 540, 1080, 34560, 540, 34560, 1080, 540, 34560, 34560, 34560, 34560, 1080, 540, 1080, 34560, 34560, 1080, 540, 540, 34560, 1080, 1080, 540, 540, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 540, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 34560, 540, 540, 540, 1080, 1080, 34560, 540, 540, 34560, 540, 34560, 1080, 540, 34560, 1080, 1080, 540, 34560, 34560, 34560, 540, 1080, 34560, 540, 34560, 1080, 1080, 34560, 34560, 540, 1080, 34560, 540, 1080, 1080, 540, 1080, 540, 1080, 34560, 34560, 1080, 540, 34560, 540, 34560, 1080, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 34560, 540, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 34560, 34560, 540, 540, 34560, 540, 540, 540, 1080, 540, 1080, 34560, 34560, 1080, 1080, 540, 34560, 1080, 34560, 540, 1080, 1080, 540, 540, 1080, 540, 34560, 34560, 540, 34560, 34560, 540, 1080, 34560, 540, 540, 1080, 1080, 540, 540, 34560, 34560, 34560, 34560, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 34560, 1080, 1080, 1080, 34560, 540, 1080, 1080, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 1080, 540, 34560, 34560, 34560, 1080, 540, 34560, 34560, 1080, 1080, 34560, 34560, 540, 34560, 34560, 1080, 540, 34560, 1080, 1080, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 1080, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 34560, 540, 540, 540, 1080, 540, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 34560, 34560, 540, 34560, 34560, 540, 34560, 1080, 34560, 1080, 1080, 1080, 540, 1080, 540, 540, 34560, 540, 1080, 540, 540, 1080, 34560, 1080, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4631040 . Total input tokens: 1031716165 . Total output tokens: 925998705
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 73.87624289188534,
    "estimated_duration": 3600.1594508477006,
    "input_throughput": 6157.923920503,
    "output_throughput": 5414.003259053025,
    "total_throughput": 11571.927179556025,
    "itl": 150.80748048218481,
    "ttft": 2091481.4909712118,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 499,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.63095750542591,
    "arrivals": 1542191,
    "finished_requests": 89576,
    "scheduler_time": 178.48982030859872
}
#Debug simulation 
Total elapsed time: 73.87636151304469. Arrivals time: 0.43427540268749 Scheduler time: 73.29474721476436 Scheduler overhead time: 0.05754544911906123 Adapter cache time: 0.015997523441910744 Engine time: 0.05297166761010885 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-32/adapters_384_slots_64_rate_3.2-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-32/adapters_384_slots_64_rate_3.2-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 1080, 540, 34560, 34560, 540, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 540, 34560, 540, 34560, 1080, 1080, 1080, 540, 540, 1080, 540, 34560, 540, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 34560, 540, 34560, 34560, 34560, 34560, 540, 1080, 1080, 1080, 34560, 1080, 540, 1080, 540, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 540, 540, 34560, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 34560, 540, 1080, 34560, 540, 34560, 1080, 540, 34560, 34560, 34560, 34560, 1080, 540, 1080, 34560, 34560, 1080, 540, 540, 34560, 1080, 1080, 540, 540, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 540, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 34560, 540, 540, 540, 1080, 1080, 34560, 540, 540, 34560, 540, 34560, 1080, 540, 34560, 1080, 1080, 540, 34560, 34560, 34560, 540, 1080, 34560, 540, 34560, 1080, 1080, 34560, 34560, 540, 1080, 34560, 540, 1080, 1080, 540, 1080, 540, 1080, 34560, 34560, 1080, 540, 34560, 540, 34560, 1080, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 34560, 540, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 34560, 34560, 540, 540, 34560, 540, 540, 540, 1080, 540, 1080, 34560, 34560, 1080, 1080, 540, 34560, 1080, 34560, 540, 1080, 1080, 540, 540, 1080, 540, 34560, 34560, 540, 34560, 34560, 540, 1080, 34560, 540, 540, 1080, 1080, 540, 540, 34560, 34560, 34560, 34560, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 34560, 1080, 1080, 1080, 34560, 540, 1080, 1080, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 1080, 540, 34560, 34560, 34560, 1080, 540, 34560, 34560, 1080, 1080, 34560, 34560, 540, 34560, 34560, 1080, 540, 34560, 1080, 1080, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 1080, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 34560, 540, 540, 540, 1080, 540, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 34560, 34560, 540, 34560, 34560, 540, 34560, 1080, 34560, 1080, 1080, 1080, 540, 1080, 540, 540, 34560, 540, 1080, 540, 540, 1080, 34560, 1080, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4631040 . Total input tokens: 1031716165 . Total output tokens: 925998705
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 73.83935287315398,
    "estimated_duration": 3600.1618768641724,
    "input_throughput": 6157.919770904906,
    "output_throughput": 5413.999610755661,
    "total_throughput": 11571.919381660568,
    "itl": 150.80754136268817,
    "ttft": 2091482.0886918297,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 499,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6333800536766747,
    "arrivals": 1542191,
    "finished_requests": 89576,
    "scheduler_time": 178.4898237767825
}
#Debug simulation 
Total elapsed time: 73.83947469387203. Arrivals time: 0.4349842923693359 Scheduler time: 73.2549926941283 Scheduler overhead time: 0.05800211662426591 Adapter cache time: 0.016035154461860657 Engine time: 0.05398479988798499 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-16-16/adapters_384_slots_64_rate_3.2-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-16-16/adapters_384_slots_64_rate_3.2-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 1080, 540, 34560, 34560, 540, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 540, 34560, 540, 34560, 1080, 1080, 1080, 540, 540, 1080, 540, 34560, 540, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 34560, 540, 34560, 34560, 34560, 34560, 540, 1080, 1080, 1080, 34560, 1080, 540, 1080, 540, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 540, 540, 34560, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 34560, 540, 1080, 34560, 540, 34560, 1080, 540, 34560, 34560, 34560, 34560, 1080, 540, 1080, 34560, 34560, 1080, 540, 540, 34560, 1080, 1080, 540, 540, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 540, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 34560, 540, 540, 540, 1080, 1080, 34560, 540, 540, 34560, 540, 34560, 1080, 540, 34560, 1080, 1080, 540, 34560, 34560, 34560, 540, 1080, 34560, 540, 34560, 1080, 1080, 34560, 34560, 540, 1080, 34560, 540, 1080, 1080, 540, 1080, 540, 1080, 34560, 34560, 1080, 540, 34560, 540, 34560, 1080, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 34560, 540, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 34560, 34560, 540, 540, 34560, 540, 540, 540, 1080, 540, 1080, 34560, 34560, 1080, 1080, 540, 34560, 1080, 34560, 540, 1080, 1080, 540, 540, 1080, 540, 34560, 34560, 540, 34560, 34560, 540, 1080, 34560, 540, 540, 1080, 1080, 540, 540, 34560, 34560, 34560, 34560, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 34560, 1080, 1080, 1080, 34560, 540, 1080, 1080, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 1080, 540, 34560, 34560, 34560, 1080, 540, 34560, 34560, 1080, 1080, 34560, 34560, 540, 34560, 34560, 1080, 540, 34560, 1080, 1080, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 1080, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 34560, 540, 540, 540, 1080, 540, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 34560, 34560, 540, 34560, 34560, 540, 34560, 1080, 34560, 1080, 1080, 1080, 540, 1080, 540, 540, 34560, 540, 1080, 540, 540, 1080, 34560, 1080, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4631040 . Total input tokens: 1031716165 . Total output tokens: 925998705
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 72.42663952894509,
    "estimated_duration": 3600.0267436023687,
    "input_throughput": 6158.628693356413,
    "output_throughput": 5417.601976057489,
    "total_throughput": 11576.230669413902,
    "itl": 151.04461710183784,
    "ttft": 2091925.0875172948,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 511,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5981940954667446,
    "arrivals": 1542191,
    "finished_requests": 89569,
    "scheduler_time": 178.38755550824183
}
#Debug simulation 
Total elapsed time: 72.42676053009927. Arrivals time: 0.4145657285116613 Scheduler time: 71.86675297329202 Scheduler overhead time: 0.056805903557688 Adapter cache time: 0.015645118430256844 Engine time: 0.052235409151762724 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-16-32/adapters_384_slots_64_rate_3.2-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-16-32/adapters_384_slots_64_rate_3.2-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 1080, 540, 34560, 34560, 540, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 540, 34560, 540, 34560, 1080, 1080, 1080, 540, 540, 1080, 540, 34560, 540, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 34560, 540, 34560, 34560, 34560, 34560, 540, 1080, 1080, 1080, 34560, 1080, 540, 1080, 540, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 540, 540, 34560, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 34560, 540, 1080, 34560, 540, 34560, 1080, 540, 34560, 34560, 34560, 34560, 1080, 540, 1080, 34560, 34560, 1080, 540, 540, 34560, 1080, 1080, 540, 540, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 540, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 34560, 540, 540, 540, 1080, 1080, 34560, 540, 540, 34560, 540, 34560, 1080, 540, 34560, 1080, 1080, 540, 34560, 34560, 34560, 540, 1080, 34560, 540, 34560, 1080, 1080, 34560, 34560, 540, 1080, 34560, 540, 1080, 1080, 540, 1080, 540, 1080, 34560, 34560, 1080, 540, 34560, 540, 34560, 1080, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 34560, 540, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 34560, 34560, 540, 540, 34560, 540, 540, 540, 1080, 540, 1080, 34560, 34560, 1080, 1080, 540, 34560, 1080, 34560, 540, 1080, 1080, 540, 540, 1080, 540, 34560, 34560, 540, 34560, 34560, 540, 1080, 34560, 540, 540, 1080, 1080, 540, 540, 34560, 34560, 34560, 34560, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 34560, 1080, 1080, 1080, 34560, 540, 1080, 1080, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 1080, 540, 34560, 34560, 34560, 1080, 540, 34560, 34560, 1080, 1080, 34560, 34560, 540, 34560, 34560, 1080, 540, 34560, 1080, 1080, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 1080, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 34560, 540, 540, 540, 1080, 540, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 34560, 34560, 540, 34560, 34560, 540, 34560, 1080, 34560, 1080, 1080, 1080, 540, 1080, 540, 540, 34560, 540, 1080, 540, 540, 1080, 34560, 1080, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4631040 . Total input tokens: 1031716165 . Total output tokens: 925998705
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 73.64989809412509,
    "estimated_duration": 3600.0109613918926,
    "input_throughput": 6157.836250428792,
    "output_throughput": 5413.9154599863805,
    "total_throughput": 11571.751710415172,
    "itl": 150.80723164808427,
    "ttft": 2091460.911333988,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 499,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6551354587264397,
    "arrivals": 1542191,
    "finished_requests": 89571,
    "scheduler_time": 178.48158081315825
}
#Debug simulation 
Total elapsed time: 73.65002086712047. Arrivals time: 0.41367643931880593 Scheduler time: 73.08915578853339 Scheduler overhead time: 0.056849269196391106 Adapter cache time: 0.01594841154292226 Engine time: 0.0530759347602725 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_16-16-16/adapters_384_slots_64_rate_3.2-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_16-16-16/adapters_384_slots_64_rate_3.2-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 1080, 540, 34560, 34560, 540, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 540, 34560, 540, 34560, 1080, 1080, 1080, 540, 540, 1080, 540, 34560, 540, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 34560, 540, 34560, 34560, 34560, 34560, 540, 1080, 1080, 1080, 34560, 1080, 540, 1080, 540, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 540, 540, 34560, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 34560, 540, 1080, 34560, 540, 34560, 1080, 540, 34560, 34560, 34560, 34560, 1080, 540, 1080, 34560, 34560, 1080, 540, 540, 34560, 1080, 1080, 540, 540, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 540, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 34560, 540, 540, 540, 1080, 1080, 34560, 540, 540, 34560, 540, 34560, 1080, 540, 34560, 1080, 1080, 540, 34560, 34560, 34560, 540, 1080, 34560, 540, 34560, 1080, 1080, 34560, 34560, 540, 1080, 34560, 540, 1080, 1080, 540, 1080, 540, 1080, 34560, 34560, 1080, 540, 34560, 540, 34560, 1080, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 34560, 540, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 34560, 34560, 540, 540, 34560, 540, 540, 540, 1080, 540, 1080, 34560, 34560, 1080, 1080, 540, 34560, 1080, 34560, 540, 1080, 1080, 540, 540, 1080, 540, 34560, 34560, 540, 34560, 34560, 540, 1080, 34560, 540, 540, 1080, 1080, 540, 540, 34560, 34560, 34560, 34560, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 34560, 1080, 1080, 1080, 34560, 540, 1080, 1080, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 1080, 540, 34560, 34560, 34560, 1080, 540, 34560, 34560, 1080, 1080, 34560, 34560, 540, 34560, 34560, 1080, 540, 34560, 1080, 1080, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 1080, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 34560, 540, 540, 540, 1080, 540, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 34560, 34560, 540, 34560, 34560, 540, 34560, 1080, 34560, 1080, 1080, 1080, 540, 1080, 540, 540, 34560, 540, 1080, 540, 540, 1080, 34560, 1080, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4631040 . Total input tokens: 1031716165 . Total output tokens: 925998705
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 76.01304067997262,
    "estimated_duration": 3600.072611020483,
    "input_throughput": 6149.964290226932,
    "output_throughput": 5405.640969692452,
    "total_throughput": 11555.605259919384,
    "itl": 150.39232090524402,
    "ttft": 2090642.4186403141,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 501,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4980151977459737,
    "arrivals": 1542191,
    "finished_requests": 89411,
    "scheduler_time": 178.99360015719992
}
#Debug simulation 
Total elapsed time: 76.01315720193088. Arrivals time: 0.4247182630933821 Scheduler time: 75.4393581468612 Scheduler overhead time: 0.058115669060498476 Adapter cache time: 0.016034380067139864 Engine time: 0.053636709228158 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_16-16-32/adapters_384_slots_64_rate_3.2-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_16-16-32/adapters_384_slots_64_rate_3.2-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 1080, 540, 34560, 34560, 540, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 540, 34560, 540, 34560, 1080, 1080, 1080, 540, 540, 1080, 540, 34560, 540, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 34560, 540, 34560, 34560, 34560, 34560, 540, 1080, 1080, 1080, 34560, 1080, 540, 1080, 540, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 540, 540, 34560, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 34560, 540, 1080, 34560, 540, 34560, 1080, 540, 34560, 34560, 34560, 34560, 1080, 540, 1080, 34560, 34560, 1080, 540, 540, 34560, 1080, 1080, 540, 540, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 540, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 34560, 540, 540, 540, 1080, 1080, 34560, 540, 540, 34560, 540, 34560, 1080, 540, 34560, 1080, 1080, 540, 34560, 34560, 34560, 540, 1080, 34560, 540, 34560, 1080, 1080, 34560, 34560, 540, 1080, 34560, 540, 1080, 1080, 540, 1080, 540, 1080, 34560, 34560, 1080, 540, 34560, 540, 34560, 1080, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 34560, 540, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 34560, 34560, 540, 540, 34560, 540, 540, 540, 1080, 540, 1080, 34560, 34560, 1080, 1080, 540, 34560, 1080, 34560, 540, 1080, 1080, 540, 540, 1080, 540, 34560, 34560, 540, 34560, 34560, 540, 1080, 34560, 540, 540, 1080, 1080, 540, 540, 34560, 34560, 34560, 34560, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 34560, 1080, 1080, 1080, 34560, 540, 1080, 1080, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 1080, 540, 34560, 34560, 34560, 1080, 540, 34560, 34560, 1080, 1080, 34560, 34560, 540, 34560, 34560, 1080, 540, 34560, 1080, 1080, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 1080, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 34560, 540, 540, 540, 1080, 540, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 34560, 34560, 540, 34560, 34560, 540, 34560, 1080, 34560, 1080, 1080, 1080, 540, 1080, 540, 540, 34560, 540, 1080, 540, 540, 1080, 34560, 1080, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4631040 . Total input tokens: 1031716165 . Total output tokens: 925998705
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 73.74083242285997,
    "estimated_duration": 3600.0320988111075,
    "input_throughput": 6157.800094982754,
    "output_throughput": 5413.883672436289,
    "total_throughput": 11571.683767419043,
    "itl": 150.80778846458168,
    "ttft": 2091468.449085084,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 499,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.676136341057716,
    "arrivals": 1542191,
    "finished_requests": 89571,
    "scheduler_time": 178.4817173500764
}
#Debug simulation 
Total elapsed time: 73.7409543725662. Arrivals time: 0.42528733192011714 Scheduler time: 73.16837684018537 Scheduler overhead time: 0.05739161558449268 Adapter cache time: 0.015693677123636007 Engine time: 0.052964200265705585 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-8/adapters_384_slots_64_rate_3.2-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-8/adapters_384_slots_64_rate_3.2-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 1080, 270, 34560, 34560, 270, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 270, 34560, 270, 34560, 1080, 1080, 1080, 270, 270, 1080, 270, 34560, 270, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 34560, 270, 34560, 34560, 34560, 34560, 270, 1080, 1080, 1080, 34560, 1080, 270, 1080, 270, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 270, 270, 34560, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 34560, 270, 1080, 34560, 270, 34560, 1080, 270, 34560, 34560, 34560, 34560, 1080, 270, 1080, 34560, 34560, 1080, 270, 270, 34560, 1080, 1080, 270, 270, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 270, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 34560, 270, 270, 270, 1080, 1080, 34560, 270, 270, 34560, 270, 34560, 1080, 270, 34560, 1080, 1080, 270, 34560, 34560, 34560, 270, 1080, 34560, 270, 34560, 1080, 1080, 34560, 34560, 270, 1080, 34560, 270, 1080, 1080, 270, 1080, 270, 1080, 34560, 34560, 1080, 270, 34560, 270, 34560, 1080, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 34560, 270, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 34560, 34560, 270, 270, 34560, 270, 270, 270, 1080, 270, 1080, 34560, 34560, 1080, 1080, 270, 34560, 1080, 34560, 270, 1080, 1080, 270, 270, 1080, 270, 34560, 34560, 270, 34560, 34560, 270, 1080, 34560, 270, 270, 1080, 1080, 270, 270, 34560, 34560, 34560, 34560, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 34560, 1080, 1080, 1080, 34560, 270, 1080, 1080, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 1080, 270, 34560, 34560, 34560, 1080, 270, 34560, 34560, 1080, 1080, 34560, 34560, 270, 34560, 34560, 1080, 270, 34560, 1080, 1080, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 1080, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 34560, 270, 270, 270, 1080, 270, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 34560, 34560, 270, 34560, 34560, 270, 34560, 1080, 34560, 1080, 1080, 1080, 270, 1080, 270, 270, 34560, 270, 1080, 270, 270, 1080, 34560, 1080, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4596480 . Total input tokens: 1024130951 . Total output tokens: 919050936
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 68.90391187462956,
    "estimated_duration": 3600.032406690595,
    "input_throughput": 6240.0674389070045,
    "output_throughput": 5501.463254384026,
    "total_throughput": 11741.53069329103,
    "itl": 154.70018075021025,
    "ttft": 2099994.5505713806,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 620,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8975024012383372,
    "arrivals": 1530695,
    "finished_requests": 90837,
    "scheduler_time": 173.85639249410548
}
#Debug simulation 
Total elapsed time: 68.90403014980257. Arrivals time: 0.42370125045999885 Scheduler time: 68.33591288654134 Scheduler overhead time: 0.05581532698124647 Adapter cache time: 0.016693952027708292 Engine time: 0.05141099821776152 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-16/adapters_384_slots_64_rate_3.2-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-16/adapters_384_slots_64_rate_3.2-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 1080, 270, 34560, 34560, 270, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 270, 34560, 270, 34560, 1080, 1080, 1080, 270, 270, 1080, 270, 34560, 270, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 34560, 270, 34560, 34560, 34560, 34560, 270, 1080, 1080, 1080, 34560, 1080, 270, 1080, 270, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 270, 270, 34560, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 34560, 270, 1080, 34560, 270, 34560, 1080, 270, 34560, 34560, 34560, 34560, 1080, 270, 1080, 34560, 34560, 1080, 270, 270, 34560, 1080, 1080, 270, 270, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 270, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 34560, 270, 270, 270, 1080, 1080, 34560, 270, 270, 34560, 270, 34560, 1080, 270, 34560, 1080, 1080, 270, 34560, 34560, 34560, 270, 1080, 34560, 270, 34560, 1080, 1080, 34560, 34560, 270, 1080, 34560, 270, 1080, 1080, 270, 1080, 270, 1080, 34560, 34560, 1080, 270, 34560, 270, 34560, 1080, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 34560, 270, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 34560, 34560, 270, 270, 34560, 270, 270, 270, 1080, 270, 1080, 34560, 34560, 1080, 1080, 270, 34560, 1080, 34560, 270, 1080, 1080, 270, 270, 1080, 270, 34560, 34560, 270, 34560, 34560, 270, 1080, 34560, 270, 270, 1080, 1080, 270, 270, 34560, 34560, 34560, 34560, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 34560, 1080, 1080, 1080, 34560, 270, 1080, 1080, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 1080, 270, 34560, 34560, 34560, 1080, 270, 34560, 34560, 1080, 1080, 34560, 34560, 270, 34560, 34560, 1080, 270, 34560, 1080, 1080, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 1080, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 34560, 270, 270, 270, 1080, 270, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 34560, 34560, 270, 34560, 34560, 270, 34560, 1080, 34560, 1080, 1080, 1080, 270, 1080, 270, 270, 34560, 270, 1080, 270, 270, 1080, 34560, 1080, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4596480 . Total input tokens: 1024130951 . Total output tokens: 919050936
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 69.33770278701559,
    "estimated_duration": 3600.1568281524032,
    "input_throughput": 6239.851782103818,
    "output_throughput": 5501.273123750038,
    "total_throughput": 11741.124905853856,
    "itl": 154.70489702764897,
    "ttft": 2100043.1724664913,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 620,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0213552633998964,
    "arrivals": 1530695,
    "finished_requests": 90837,
    "scheduler_time": 173.85696109370446
}
#Debug simulation 
Total elapsed time: 69.33782244101167. Arrivals time: 0.4272189396433532 Scheduler time: 68.76507418975234 Scheduler overhead time: 0.05627606529742479 Adapter cache time: 0.017102719750255346 Engine time: 0.051922251004725695 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-32/adapters_384_slots_64_rate_3.2-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-32/adapters_384_slots_64_rate_3.2-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 1080, 270, 34560, 34560, 270, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 270, 34560, 270, 34560, 1080, 1080, 1080, 270, 270, 1080, 270, 34560, 270, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 34560, 270, 34560, 34560, 34560, 34560, 270, 1080, 1080, 1080, 34560, 1080, 270, 1080, 270, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 270, 270, 34560, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 34560, 270, 1080, 34560, 270, 34560, 1080, 270, 34560, 34560, 34560, 34560, 1080, 270, 1080, 34560, 34560, 1080, 270, 270, 34560, 1080, 1080, 270, 270, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 270, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 34560, 270, 270, 270, 1080, 1080, 34560, 270, 270, 34560, 270, 34560, 1080, 270, 34560, 1080, 1080, 270, 34560, 34560, 34560, 270, 1080, 34560, 270, 34560, 1080, 1080, 34560, 34560, 270, 1080, 34560, 270, 1080, 1080, 270, 1080, 270, 1080, 34560, 34560, 1080, 270, 34560, 270, 34560, 1080, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 34560, 270, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 34560, 34560, 270, 270, 34560, 270, 270, 270, 1080, 270, 1080, 34560, 34560, 1080, 1080, 270, 34560, 1080, 34560, 270, 1080, 1080, 270, 270, 1080, 270, 34560, 34560, 270, 34560, 34560, 270, 1080, 34560, 270, 270, 1080, 1080, 270, 270, 34560, 34560, 34560, 34560, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 34560, 1080, 1080, 1080, 34560, 270, 1080, 1080, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 1080, 270, 34560, 34560, 34560, 1080, 270, 34560, 34560, 1080, 1080, 34560, 34560, 270, 34560, 34560, 1080, 270, 34560, 1080, 1080, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 1080, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 34560, 270, 270, 270, 1080, 270, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 34560, 34560, 270, 34560, 34560, 270, 34560, 1080, 34560, 1080, 1080, 1080, 270, 1080, 270, 270, 34560, 270, 1080, 270, 270, 1080, 34560, 1080, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4596480 . Total input tokens: 1024130951 . Total output tokens: 919050936
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 68.92587741324678,
    "estimated_duration": 3600.160747222205,
    "input_throughput": 6239.844989514152,
    "output_throughput": 5501.267135163726,
    "total_throughput": 11741.112124677878,
    "itl": 154.70504148057987,
    "ttft": 2100044.5862355363,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 620,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.025253158994031,
    "arrivals": 1530695,
    "finished_requests": 90837,
    "scheduler_time": 173.85698226787892
}
#Debug simulation 
Total elapsed time: 68.92599570006132. Arrivals time: 0.5337398913688958 Scheduler time: 68.24577690474689 Scheduler overhead time: 0.05688200984150171 Adapter cache time: 0.01684613898396492 Engine time: 0.05173280742019415 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-16-16/adapters_384_slots_64_rate_3.2-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-16-16/adapters_384_slots_64_rate_3.2-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 1080, 270, 34560, 34560, 270, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 270, 34560, 270, 34560, 1080, 1080, 1080, 270, 270, 1080, 270, 34560, 270, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 34560, 270, 34560, 34560, 34560, 34560, 270, 1080, 1080, 1080, 34560, 1080, 270, 1080, 270, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 270, 270, 34560, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 34560, 270, 1080, 34560, 270, 34560, 1080, 270, 34560, 34560, 34560, 34560, 1080, 270, 1080, 34560, 34560, 1080, 270, 270, 34560, 1080, 1080, 270, 270, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 270, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 34560, 270, 270, 270, 1080, 1080, 34560, 270, 270, 34560, 270, 34560, 1080, 270, 34560, 1080, 1080, 270, 34560, 34560, 34560, 270, 1080, 34560, 270, 34560, 1080, 1080, 34560, 34560, 270, 1080, 34560, 270, 1080, 1080, 270, 1080, 270, 1080, 34560, 34560, 1080, 270, 34560, 270, 34560, 1080, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 34560, 270, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 34560, 34560, 270, 270, 34560, 270, 270, 270, 1080, 270, 1080, 34560, 34560, 1080, 1080, 270, 34560, 1080, 34560, 270, 1080, 1080, 270, 270, 1080, 270, 34560, 34560, 270, 34560, 34560, 270, 1080, 34560, 270, 270, 1080, 1080, 270, 270, 34560, 34560, 34560, 34560, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 34560, 1080, 1080, 1080, 34560, 270, 1080, 1080, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 1080, 270, 34560, 34560, 34560, 1080, 270, 34560, 34560, 1080, 1080, 34560, 34560, 270, 34560, 34560, 1080, 270, 34560, 1080, 1080, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 1080, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 34560, 270, 270, 270, 1080, 270, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 34560, 34560, 270, 34560, 34560, 270, 34560, 1080, 34560, 1080, 1080, 1080, 270, 1080, 270, 270, 34560, 270, 1080, 270, 270, 1080, 34560, 1080, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4596480 . Total input tokens: 1024130951 . Total output tokens: 919050936
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 69.42853855714202,
    "estimated_duration": 3600.073488294911,
    "input_throughput": 6239.996231476861,
    "output_throughput": 5501.4004754054,
    "total_throughput": 11741.39670688226,
    "itl": 154.70177966713646,
    "ttft": 2100011.3356901817,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 620,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9384104137564877,
    "arrivals": 1530695,
    "finished_requests": 90837,
    "scheduler_time": 173.85656608582894
}
#Debug simulation 
Total elapsed time: 69.42865759786218. Arrivals time: 0.42639966728165746 Scheduler time: 68.85586901381612 Scheduler overhead time: 0.056672846898436546 Adapter cache time: 0.0169938700273633 Engine time: 0.05182644911110401 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-16-32/adapters_384_slots_64_rate_3.2-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-16-32/adapters_384_slots_64_rate_3.2-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 1080, 270, 34560, 34560, 270, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 270, 34560, 270, 34560, 1080, 1080, 1080, 270, 270, 1080, 270, 34560, 270, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 34560, 270, 34560, 34560, 34560, 34560, 270, 1080, 1080, 1080, 34560, 1080, 270, 1080, 270, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 270, 270, 34560, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 34560, 270, 1080, 34560, 270, 34560, 1080, 270, 34560, 34560, 34560, 34560, 1080, 270, 1080, 34560, 34560, 1080, 270, 270, 34560, 1080, 1080, 270, 270, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 270, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 34560, 270, 270, 270, 1080, 1080, 34560, 270, 270, 34560, 270, 34560, 1080, 270, 34560, 1080, 1080, 270, 34560, 34560, 34560, 270, 1080, 34560, 270, 34560, 1080, 1080, 34560, 34560, 270, 1080, 34560, 270, 1080, 1080, 270, 1080, 270, 1080, 34560, 34560, 1080, 270, 34560, 270, 34560, 1080, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 34560, 270, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 34560, 34560, 270, 270, 34560, 270, 270, 270, 1080, 270, 1080, 34560, 34560, 1080, 1080, 270, 34560, 1080, 34560, 270, 1080, 1080, 270, 270, 1080, 270, 34560, 34560, 270, 34560, 34560, 270, 1080, 34560, 270, 270, 1080, 1080, 270, 270, 34560, 34560, 34560, 34560, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 34560, 1080, 1080, 1080, 34560, 270, 1080, 1080, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 1080, 270, 34560, 34560, 34560, 1080, 270, 34560, 34560, 1080, 1080, 34560, 34560, 270, 34560, 34560, 1080, 270, 34560, 1080, 1080, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 1080, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 34560, 270, 270, 270, 1080, 270, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 34560, 34560, 270, 34560, 34560, 270, 34560, 1080, 34560, 1080, 1080, 1080, 270, 1080, 270, 270, 34560, 270, 1080, 270, 270, 1080, 34560, 1080, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4596480 . Total input tokens: 1024130951 . Total output tokens: 919050936
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 69.34718818869442,
    "estimated_duration": 3600.0106071082623,
    "input_throughput": 6239.91133682914,
    "output_throughput": 5501.417401630562,
    "total_throughput": 11741.328738459702,
    "itl": 154.70725542256062,
    "ttft": 2100022.4112065723,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 620,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0507811776362392,
    "arrivals": 1530695,
    "finished_requests": 90834,
    "scheduler_time": 173.84866604558897
}
#Debug simulation 
Total elapsed time: 69.34731732401997. Arrivals time: 0.4454698693007231 Scheduler time: 68.7551593631506 Scheduler overhead time: 0.056523943319916725 Adapter cache time: 0.017041902523487806 Engine time: 0.05197789892554283 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_16-16-16/adapters_384_slots_64_rate_3.2-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_16-16-16/adapters_384_slots_64_rate_3.2-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 1080, 270, 34560, 34560, 270, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 270, 34560, 270, 34560, 1080, 1080, 1080, 270, 270, 1080, 270, 34560, 270, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 34560, 270, 34560, 34560, 34560, 34560, 270, 1080, 1080, 1080, 34560, 1080, 270, 1080, 270, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 270, 270, 34560, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 34560, 270, 1080, 34560, 270, 34560, 1080, 270, 34560, 34560, 34560, 34560, 1080, 270, 1080, 34560, 34560, 1080, 270, 270, 34560, 1080, 1080, 270, 270, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 270, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 34560, 270, 270, 270, 1080, 1080, 34560, 270, 270, 34560, 270, 34560, 1080, 270, 34560, 1080, 1080, 270, 34560, 34560, 34560, 270, 1080, 34560, 270, 34560, 1080, 1080, 34560, 34560, 270, 1080, 34560, 270, 1080, 1080, 270, 1080, 270, 1080, 34560, 34560, 1080, 270, 34560, 270, 34560, 1080, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 34560, 270, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 34560, 34560, 270, 270, 34560, 270, 270, 270, 1080, 270, 1080, 34560, 34560, 1080, 1080, 270, 34560, 1080, 34560, 270, 1080, 1080, 270, 270, 1080, 270, 34560, 34560, 270, 34560, 34560, 270, 1080, 34560, 270, 270, 1080, 1080, 270, 270, 34560, 34560, 34560, 34560, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 34560, 1080, 1080, 1080, 34560, 270, 1080, 1080, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 1080, 270, 34560, 34560, 34560, 1080, 270, 34560, 34560, 1080, 1080, 34560, 34560, 270, 34560, 34560, 1080, 270, 34560, 1080, 1080, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 1080, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 34560, 270, 270, 270, 1080, 270, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 34560, 34560, 270, 34560, 34560, 270, 34560, 1080, 34560, 1080, 1080, 1080, 270, 1080, 270, 270, 34560, 270, 1080, 270, 270, 1080, 34560, 1080, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4596480 . Total input tokens: 1024130951 . Total output tokens: 919050936
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 69.54541004588827,
    "estimated_duration": 3600.164891674041,
    "input_throughput": 6240.304451597903,
    "output_throughput": 5501.699670980884,
    "total_throughput": 11742.004122578786,
    "itl": 154.6999514967175,
    "ttft": 2099999.8803989487,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 620,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.85383118283932,
    "arrivals": 1530695,
    "finished_requests": 90844,
    "scheduler_time": 173.8646398338577
}
#Debug simulation 
Total elapsed time: 69.5455334330909. Arrivals time: 0.4380248486995697 Scheduler time: 68.96038340590894 Scheduler overhead time: 0.05652061803266406 Adapter cache time: 0.01753999525681138 Engine time: 0.052507491782307625 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_16-16-32/adapters_384_slots_64_rate_3.2-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_16-16-32/adapters_384_slots_64_rate_3.2-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 1080, 270, 34560, 34560, 270, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 270, 34560, 270, 34560, 1080, 1080, 1080, 270, 270, 1080, 270, 34560, 270, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 34560, 270, 34560, 34560, 34560, 34560, 270, 1080, 1080, 1080, 34560, 1080, 270, 1080, 270, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 270, 270, 34560, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 34560, 270, 1080, 34560, 270, 34560, 1080, 270, 34560, 34560, 34560, 34560, 1080, 270, 1080, 34560, 34560, 1080, 270, 270, 34560, 1080, 1080, 270, 270, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 270, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 34560, 270, 270, 270, 1080, 1080, 34560, 270, 270, 34560, 270, 34560, 1080, 270, 34560, 1080, 1080, 270, 34560, 34560, 34560, 270, 1080, 34560, 270, 34560, 1080, 1080, 34560, 34560, 270, 1080, 34560, 270, 1080, 1080, 270, 1080, 270, 1080, 34560, 34560, 1080, 270, 34560, 270, 34560, 1080, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 34560, 270, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 34560, 34560, 270, 270, 34560, 270, 270, 270, 1080, 270, 1080, 34560, 34560, 1080, 1080, 270, 34560, 1080, 34560, 270, 1080, 1080, 270, 270, 1080, 270, 34560, 34560, 270, 34560, 34560, 270, 1080, 34560, 270, 270, 1080, 1080, 270, 270, 34560, 34560, 34560, 34560, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 34560, 1080, 1080, 1080, 34560, 270, 1080, 1080, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 1080, 270, 34560, 34560, 34560, 1080, 270, 34560, 34560, 1080, 1080, 34560, 34560, 270, 34560, 34560, 1080, 270, 34560, 1080, 1080, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 1080, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 34560, 270, 270, 270, 1080, 270, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 34560, 34560, 270, 34560, 34560, 270, 34560, 1080, 34560, 1080, 1080, 1080, 270, 1080, 270, 270, 34560, 270, 1080, 270, 270, 1080, 34560, 1080, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4596480 . Total input tokens: 1024130951 . Total output tokens: 919050936
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 68.98612079862505,
    "estimated_duration": 3600.0367545999793,
    "input_throughput": 6239.8660156168535,
    "output_throughput": 5501.377444186862,
    "total_throughput": 11741.243459803716,
    "itl": 154.70825730919324,
    "ttft": 2100032.7916532937,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 620,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0768122114241083,
    "arrivals": 1530695,
    "finished_requests": 90834,
    "scheduler_time": 173.8487825035486
}
#Debug simulation 
Total elapsed time: 68.98624461796135. Arrivals time: 0.5302114672958851 Scheduler time: 68.31108382763341 Scheduler overhead time: 0.0556689384393394 Adapter cache time: 0.01711154729127884 Engine time: 0.051394650246948004 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-8/adapters_384_slots_64_rate_3.2-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-8/adapters_384_slots_64_rate_3.2-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 1080, 135, 34560, 34560, 135, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 135, 34560, 135, 34560, 1080, 1080, 1080, 135, 135, 1080, 135, 34560, 135, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 34560, 135, 34560, 34560, 34560, 34560, 135, 1080, 1080, 1080, 34560, 1080, 135, 1080, 135, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 135, 135, 34560, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 34560, 135, 1080, 34560, 135, 34560, 1080, 135, 34560, 34560, 34560, 34560, 1080, 135, 1080, 34560, 34560, 1080, 135, 135, 34560, 1080, 1080, 135, 135, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 135, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 34560, 135, 135, 135, 1080, 1080, 34560, 135, 135, 34560, 135, 34560, 1080, 135, 34560, 1080, 1080, 135, 34560, 34560, 34560, 135, 1080, 34560, 135, 34560, 1080, 1080, 34560, 34560, 135, 1080, 34560, 135, 1080, 1080, 135, 1080, 135, 1080, 34560, 34560, 1080, 135, 34560, 135, 34560, 1080, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 34560, 135, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 34560, 34560, 135, 135, 34560, 135, 135, 135, 1080, 135, 1080, 34560, 34560, 1080, 1080, 135, 34560, 1080, 34560, 135, 1080, 1080, 135, 135, 1080, 135, 34560, 34560, 135, 34560, 34560, 135, 1080, 34560, 135, 135, 1080, 1080, 135, 135, 34560, 34560, 34560, 34560, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 34560, 1080, 1080, 1080, 34560, 135, 1080, 1080, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 1080, 135, 34560, 34560, 34560, 1080, 135, 34560, 34560, 1080, 1080, 34560, 34560, 135, 34560, 34560, 1080, 135, 34560, 1080, 1080, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 1080, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 34560, 135, 135, 135, 1080, 135, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 34560, 34560, 135, 34560, 34560, 135, 34560, 1080, 34560, 1080, 1080, 1080, 135, 1080, 135, 135, 34560, 135, 1080, 135, 135, 1080, 34560, 1080, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4579200 . Total input tokens: 1020308388 . Total output tokens: 915535080
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 74.84928770409897,
    "estimated_duration": 3600.1465269071023,
    "input_throughput": 6157.211056363204,
    "output_throughput": 5411.853338296847,
    "total_throughput": 11569.06439466005,
    "itl": 151.03311327653017,
    "ttft": 2092418.4482164693,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 449,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3741589970258181,
    "arrivals": 1525074,
    "finished_requests": 88994,
    "scheduler_time": 178.74265455343078
}
#Debug simulation 
Total elapsed time: 74.84940376272425. Arrivals time: 0.5139280422590673 Scheduler time: 74.18992626108229 Scheduler overhead time: 0.057227637618780136 Adapter cache time: 0.014835529960691929 Engine time: 0.052458849269896746 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-16/adapters_384_slots_64_rate_3.2-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-16/adapters_384_slots_64_rate_3.2-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 1080, 135, 34560, 34560, 135, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 135, 34560, 135, 34560, 1080, 1080, 1080, 135, 135, 1080, 135, 34560, 135, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 34560, 135, 34560, 34560, 34560, 34560, 135, 1080, 1080, 1080, 34560, 1080, 135, 1080, 135, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 135, 135, 34560, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 34560, 135, 1080, 34560, 135, 34560, 1080, 135, 34560, 34560, 34560, 34560, 1080, 135, 1080, 34560, 34560, 1080, 135, 135, 34560, 1080, 1080, 135, 135, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 135, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 34560, 135, 135, 135, 1080, 1080, 34560, 135, 135, 34560, 135, 34560, 1080, 135, 34560, 1080, 1080, 135, 34560, 34560, 34560, 135, 1080, 34560, 135, 34560, 1080, 1080, 34560, 34560, 135, 1080, 34560, 135, 1080, 1080, 135, 1080, 135, 1080, 34560, 34560, 1080, 135, 34560, 135, 34560, 1080, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 34560, 135, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 34560, 34560, 135, 135, 34560, 135, 135, 135, 1080, 135, 1080, 34560, 34560, 1080, 1080, 135, 34560, 1080, 34560, 135, 1080, 1080, 135, 135, 1080, 135, 34560, 34560, 135, 34560, 34560, 135, 1080, 34560, 135, 135, 1080, 1080, 135, 135, 34560, 34560, 34560, 34560, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 34560, 1080, 1080, 1080, 34560, 135, 1080, 1080, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 1080, 135, 34560, 34560, 34560, 1080, 135, 34560, 34560, 1080, 1080, 34560, 34560, 135, 34560, 34560, 1080, 135, 34560, 1080, 1080, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 1080, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 34560, 135, 135, 135, 1080, 135, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 34560, 34560, 135, 34560, 34560, 135, 34560, 1080, 34560, 1080, 1080, 1080, 135, 1080, 135, 135, 34560, 135, 1080, 135, 135, 1080, 34560, 1080, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4579200 . Total input tokens: 1020308388 . Total output tokens: 915535080
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 74.10557649610564,
    "estimated_duration": 3600.089573012727,
    "input_throughput": 6169.405663263335,
    "output_throughput": 5423.527277311712,
    "total_throughput": 11592.932940575047,
    "itl": 151.47423523310772,
    "ttft": 2094506.9478418836,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 461,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5050777346664166,
    "arrivals": 1525074,
    "finished_requests": 89201,
    "scheduler_time": 178.02808573881669
}
#Debug simulation 
Total elapsed time: 74.10569043410942. Arrivals time: 0.4253055243752897 Scheduler time: 73.5339734442532 Scheduler overhead time: 0.05743671674281359 Adapter cache time: 0.015405150130391121 Engine time: 0.05219457298517227 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-32/adapters_384_slots_64_rate_3.2-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-32/adapters_384_slots_64_rate_3.2-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 1080, 135, 34560, 34560, 135, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 135, 34560, 135, 34560, 1080, 1080, 1080, 135, 135, 1080, 135, 34560, 135, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 34560, 135, 34560, 34560, 34560, 34560, 135, 1080, 1080, 1080, 34560, 1080, 135, 1080, 135, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 135, 135, 34560, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 34560, 135, 1080, 34560, 135, 34560, 1080, 135, 34560, 34560, 34560, 34560, 1080, 135, 1080, 34560, 34560, 1080, 135, 135, 34560, 1080, 1080, 135, 135, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 135, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 34560, 135, 135, 135, 1080, 1080, 34560, 135, 135, 34560, 135, 34560, 1080, 135, 34560, 1080, 1080, 135, 34560, 34560, 34560, 135, 1080, 34560, 135, 34560, 1080, 1080, 34560, 34560, 135, 1080, 34560, 135, 1080, 1080, 135, 1080, 135, 1080, 34560, 34560, 1080, 135, 34560, 135, 34560, 1080, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 34560, 135, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 34560, 34560, 135, 135, 34560, 135, 135, 135, 1080, 135, 1080, 34560, 34560, 1080, 1080, 135, 34560, 1080, 34560, 135, 1080, 1080, 135, 135, 1080, 135, 34560, 34560, 135, 34560, 34560, 135, 1080, 34560, 135, 135, 1080, 1080, 135, 135, 34560, 34560, 34560, 34560, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 34560, 1080, 1080, 1080, 34560, 135, 1080, 1080, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 1080, 135, 34560, 34560, 34560, 1080, 135, 34560, 34560, 1080, 1080, 34560, 34560, 135, 34560, 34560, 1080, 135, 34560, 1080, 1080, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 1080, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 34560, 135, 135, 135, 1080, 135, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 34560, 34560, 135, 34560, 34560, 135, 34560, 1080, 34560, 1080, 1080, 1080, 135, 1080, 135, 135, 34560, 135, 1080, 135, 135, 1080, 34560, 1080, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4579200 . Total input tokens: 1020308388 . Total output tokens: 915535080
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 73.74764549639076,
    "estimated_duration": 3600.0921180634155,
    "input_throughput": 6169.401301861011,
    "output_throughput": 5423.523443200979,
    "total_throughput": 11592.92474506199,
    "itl": 151.4743055662608,
    "ttft": 2094507.641566204,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 461,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5076089125871748,
    "arrivals": 1525074,
    "finished_requests": 89201,
    "scheduler_time": 178.0280996115517
}
#Debug simulation 
Total elapsed time: 73.74775853939354. Arrivals time: 0.424841586034745 Scheduler time: 73.17769530881196 Scheduler overhead time: 0.056211212649941444 Adapter cache time: 0.015189818572252989 Engine time: 0.0527261164970696 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-16/adapters_384_slots_64_rate_3.2-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-16/adapters_384_slots_64_rate_3.2-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 1080, 135, 34560, 34560, 135, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 135, 34560, 135, 34560, 1080, 1080, 1080, 135, 135, 1080, 135, 34560, 135, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 34560, 135, 34560, 34560, 34560, 34560, 135, 1080, 1080, 1080, 34560, 1080, 135, 1080, 135, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 135, 135, 34560, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 34560, 135, 1080, 34560, 135, 34560, 1080, 135, 34560, 34560, 34560, 34560, 1080, 135, 1080, 34560, 34560, 1080, 135, 135, 34560, 1080, 1080, 135, 135, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 135, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 34560, 135, 135, 135, 1080, 1080, 34560, 135, 135, 34560, 135, 34560, 1080, 135, 34560, 1080, 1080, 135, 34560, 34560, 34560, 135, 1080, 34560, 135, 34560, 1080, 1080, 34560, 34560, 135, 1080, 34560, 135, 1080, 1080, 135, 1080, 135, 1080, 34560, 34560, 1080, 135, 34560, 135, 34560, 1080, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 34560, 135, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 34560, 34560, 135, 135, 34560, 135, 135, 135, 1080, 135, 1080, 34560, 34560, 1080, 1080, 135, 34560, 1080, 34560, 135, 1080, 1080, 135, 135, 1080, 135, 34560, 34560, 135, 34560, 34560, 135, 1080, 34560, 135, 135, 1080, 1080, 135, 135, 34560, 34560, 34560, 34560, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 34560, 1080, 1080, 1080, 34560, 135, 1080, 1080, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 1080, 135, 34560, 34560, 34560, 1080, 135, 34560, 34560, 1080, 1080, 34560, 34560, 135, 34560, 34560, 1080, 135, 34560, 1080, 1080, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 1080, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 34560, 135, 135, 135, 1080, 135, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 34560, 34560, 135, 34560, 34560, 135, 34560, 1080, 34560, 1080, 1080, 1080, 135, 1080, 135, 135, 34560, 135, 1080, 135, 135, 1080, 34560, 1080, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4579200 . Total input tokens: 1020308388 . Total output tokens: 915535080
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 74.58003272302449,
    "estimated_duration": 3600.0532948297623,
    "input_throughput": 6204.457315139895,
    "output_throughput": 5453.130937865277,
    "total_throughput": 11657.588253005171,
    "itl": 152.35257678127047,
    "ttft": 2098778.721428823,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 497,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5563333913381148,
    "arrivals": 1525074,
    "finished_requests": 89681,
    "scheduler_time": 176.6265786342874
}
#Debug simulation 
Total elapsed time: 74.58015652094036. Arrivals time: 0.4245658810250461 Scheduler time: 74.00942643871531 Scheduler overhead time: 0.05696433596313 Adapter cache time: 0.01569074811413884 Engine time: 0.052520324010401964 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-32/adapters_384_slots_64_rate_3.2-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-32/adapters_384_slots_64_rate_3.2-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 1080, 135, 34560, 34560, 135, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 135, 34560, 135, 34560, 1080, 1080, 1080, 135, 135, 1080, 135, 34560, 135, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 34560, 135, 34560, 34560, 34560, 34560, 135, 1080, 1080, 1080, 34560, 1080, 135, 1080, 135, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 135, 135, 34560, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 34560, 135, 1080, 34560, 135, 34560, 1080, 135, 34560, 34560, 34560, 34560, 1080, 135, 1080, 34560, 34560, 1080, 135, 135, 34560, 1080, 1080, 135, 135, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 135, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 34560, 135, 135, 135, 1080, 1080, 34560, 135, 135, 34560, 135, 34560, 1080, 135, 34560, 1080, 1080, 135, 34560, 34560, 34560, 135, 1080, 34560, 135, 34560, 1080, 1080, 34560, 34560, 135, 1080, 34560, 135, 1080, 1080, 135, 1080, 135, 1080, 34560, 34560, 1080, 135, 34560, 135, 34560, 1080, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 34560, 135, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 34560, 34560, 135, 135, 34560, 135, 135, 135, 1080, 135, 1080, 34560, 34560, 1080, 1080, 135, 34560, 1080, 34560, 135, 1080, 1080, 135, 135, 1080, 135, 34560, 34560, 135, 34560, 34560, 135, 1080, 34560, 135, 135, 1080, 1080, 135, 135, 34560, 34560, 34560, 34560, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 34560, 1080, 1080, 1080, 34560, 135, 1080, 1080, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 1080, 135, 34560, 34560, 34560, 1080, 135, 34560, 34560, 1080, 1080, 34560, 34560, 135, 34560, 34560, 1080, 135, 34560, 1080, 1080, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 1080, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 34560, 135, 135, 135, 1080, 135, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 34560, 34560, 135, 34560, 34560, 135, 34560, 1080, 34560, 1080, 1080, 1080, 135, 1080, 135, 135, 34560, 135, 1080, 135, 135, 1080, 34560, 1080, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4579200 . Total input tokens: 1020308388 . Total output tokens: 915535080
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 73.70308327907696,
    "estimated_duration": 3600.1116042551716,
    "input_throughput": 6169.367908969344,
    "output_throughput": 5423.4940874949825,
    "total_throughput": 11592.861996464328,
    "itl": 151.47481792962486,
    "ttft": 2094514.0247500676,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 461,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.526974995695058,
    "arrivals": 1525074,
    "finished_requests": 89201,
    "scheduler_time": 178.02821972023105
}
#Debug simulation 
Total elapsed time: 73.70319970697165. Arrivals time: 0.41689568711444736 Scheduler time: 73.14189073164016 Scheduler overhead time: 0.05638299509882927 Adapter cache time: 0.015217365231364965 Engine time: 0.051894658245146275 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-16/adapters_384_slots_64_rate_3.2-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-16/adapters_384_slots_64_rate_3.2-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 1080, 135, 34560, 34560, 135, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 135, 34560, 135, 34560, 1080, 1080, 1080, 135, 135, 1080, 135, 34560, 135, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 34560, 135, 34560, 34560, 34560, 34560, 135, 1080, 1080, 1080, 34560, 1080, 135, 1080, 135, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 135, 135, 34560, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 34560, 135, 1080, 34560, 135, 34560, 1080, 135, 34560, 34560, 34560, 34560, 1080, 135, 1080, 34560, 34560, 1080, 135, 135, 34560, 1080, 1080, 135, 135, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 135, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 34560, 135, 135, 135, 1080, 1080, 34560, 135, 135, 34560, 135, 34560, 1080, 135, 34560, 1080, 1080, 135, 34560, 34560, 34560, 135, 1080, 34560, 135, 34560, 1080, 1080, 34560, 34560, 135, 1080, 34560, 135, 1080, 1080, 135, 1080, 135, 1080, 34560, 34560, 1080, 135, 34560, 135, 34560, 1080, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 34560, 135, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 34560, 34560, 135, 135, 34560, 135, 135, 135, 1080, 135, 1080, 34560, 34560, 1080, 1080, 135, 34560, 1080, 34560, 135, 1080, 1080, 135, 135, 1080, 135, 34560, 34560, 135, 34560, 34560, 135, 1080, 34560, 135, 135, 1080, 1080, 135, 135, 34560, 34560, 34560, 34560, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 34560, 1080, 1080, 1080, 34560, 135, 1080, 1080, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 1080, 135, 34560, 34560, 34560, 1080, 135, 34560, 34560, 1080, 1080, 34560, 34560, 135, 34560, 34560, 1080, 135, 34560, 1080, 1080, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 1080, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 34560, 135, 135, 135, 1080, 135, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 34560, 34560, 135, 34560, 34560, 135, 34560, 1080, 34560, 1080, 1080, 1080, 135, 1080, 135, 135, 34560, 135, 1080, 135, 135, 1080, 34560, 1080, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4579200 . Total input tokens: 1020308388 . Total output tokens: 915535080
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 74.39593705395237,
    "estimated_duration": 3600.1147294563348,
    "input_throughput": 6157.265438967688,
    "output_throughput": 5411.901137645761,
    "total_throughput": 11569.16657661345,
    "itl": 151.03235912286672,
    "ttft": 2092408.2573092424,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 449,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.342532582411066,
    "arrivals": 1525074,
    "finished_requests": 88994,
    "scheduler_time": 178.7424835172111
}
#Debug simulation 
Total elapsed time: 74.39605419803411. Arrivals time: 0.4379219710826874 Scheduler time: 73.81177900964394 Scheduler overhead time: 0.057572036515921354 Adapter cache time: 0.014736173208802938 Engine time: 0.05269417027011514 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-32/adapters_384_slots_64_rate_3.2-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-32/adapters_384_slots_64_rate_3.2-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 1080, 135, 34560, 34560, 135, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 135, 34560, 135, 34560, 1080, 1080, 1080, 135, 135, 1080, 135, 34560, 135, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 34560, 135, 34560, 34560, 34560, 34560, 135, 1080, 1080, 1080, 34560, 1080, 135, 1080, 135, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 135, 135, 34560, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 34560, 135, 1080, 34560, 135, 34560, 1080, 135, 34560, 34560, 34560, 34560, 1080, 135, 1080, 34560, 34560, 1080, 135, 135, 34560, 1080, 1080, 135, 135, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 135, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 34560, 135, 135, 135, 1080, 1080, 34560, 135, 135, 34560, 135, 34560, 1080, 135, 34560, 1080, 1080, 135, 34560, 34560, 34560, 135, 1080, 34560, 135, 34560, 1080, 1080, 34560, 34560, 135, 1080, 34560, 135, 1080, 1080, 135, 1080, 135, 1080, 34560, 34560, 1080, 135, 34560, 135, 34560, 1080, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 34560, 135, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 34560, 34560, 135, 135, 34560, 135, 135, 135, 1080, 135, 1080, 34560, 34560, 1080, 1080, 135, 34560, 1080, 34560, 135, 1080, 1080, 135, 135, 1080, 135, 34560, 34560, 135, 34560, 34560, 135, 1080, 34560, 135, 135, 1080, 1080, 135, 135, 34560, 34560, 34560, 34560, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 34560, 1080, 1080, 1080, 34560, 135, 1080, 1080, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 1080, 135, 34560, 34560, 34560, 1080, 135, 34560, 34560, 1080, 1080, 34560, 34560, 135, 34560, 34560, 1080, 135, 34560, 1080, 1080, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 1080, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 34560, 135, 135, 135, 1080, 135, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 34560, 34560, 135, 34560, 34560, 135, 34560, 1080, 34560, 1080, 1080, 1080, 135, 1080, 135, 135, 34560, 135, 1080, 135, 135, 1080, 34560, 1080, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4579200 . Total input tokens: 1020308388 . Total output tokens: 915535080
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 74.31090504024178,
    "estimated_duration": 3600.1313165819984,
    "input_throughput": 6169.334128924717,
    "output_throughput": 5423.464391442646,
    "total_throughput": 11592.798520367363,
    "itl": 151.4753660496976,
    "ttft": 2094520.8001764568,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 461,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5465925863757723,
    "arrivals": 1525074,
    "finished_requests": 89201,
    "scheduler_time": 178.0283144564082
}
#Debug simulation 
Total elapsed time: 74.31102534523234. Arrivals time: 0.44108256651088595 Scheduler time: 73.7245048172772 Scheduler overhead time: 0.05711806891486049 Adapter cache time: 0.015264561865478754 Engine time: 0.05205559777095914 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-8/adapters_384_slots_64_rate_3.2-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-8/adapters_384_slots_64_rate_3.2-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 1080, 66, 34560, 34560, 66, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 66, 34560, 66, 34560, 1080, 1080, 1080, 66, 66, 1080, 66, 34560, 66, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 34560, 66, 34560, 34560, 34560, 34560, 66, 1080, 1080, 1080, 34560, 1080, 66, 1080, 66, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 66, 66, 34560, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 34560, 66, 1080, 34560, 66, 34560, 1080, 66, 34560, 34560, 34560, 34560, 1080, 66, 1080, 34560, 34560, 1080, 66, 66, 34560, 1080, 1080, 66, 66, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 66, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 34560, 66, 66, 66, 1080, 1080, 34560, 66, 66, 34560, 66, 34560, 1080, 66, 34560, 1080, 1080, 66, 34560, 34560, 34560, 66, 1080, 34560, 66, 34560, 1080, 1080, 34560, 34560, 66, 1080, 34560, 66, 1080, 1080, 66, 1080, 66, 1080, 34560, 34560, 1080, 66, 34560, 66, 34560, 1080, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 34560, 66, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 34560, 34560, 66, 66, 34560, 66, 66, 66, 1080, 66, 1080, 34560, 34560, 1080, 1080, 66, 34560, 1080, 34560, 66, 1080, 1080, 66, 66, 1080, 66, 34560, 34560, 66, 34560, 34560, 66, 1080, 34560, 66, 66, 1080, 1080, 66, 66, 34560, 34560, 34560, 34560, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 34560, 1080, 1080, 1080, 34560, 66, 1080, 1080, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 1080, 66, 34560, 34560, 34560, 1080, 66, 34560, 34560, 1080, 1080, 34560, 34560, 66, 34560, 34560, 1080, 66, 34560, 1080, 1080, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 1080, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 34560, 66, 66, 66, 1080, 66, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 34560, 34560, 66, 34560, 34560, 66, 34560, 1080, 34560, 1080, 1080, 1080, 66, 1080, 66, 66, 34560, 66, 1080, 66, 66, 1080, 34560, 1080, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4570368 . Total input tokens: 1018326849 . Total output tokens: 913762655
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 72.80615003081039,
    "estimated_duration": 3600.1070067955525,
    "input_throughput": 6187.3758079838635,
    "output_throughput": 5443.45458704664,
    "total_throughput": 11630.830395030503,
    "itl": 151.74768031606325,
    "ttft": 2095349.9706420258,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 459,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4047638744651467,
    "arrivals": 1522091,
    "finished_requests": 89902,
    "scheduler_time": 177.0948069518588
}
#Debug simulation 
Total elapsed time: 72.80626804986969. Arrivals time: 0.4291155431419611 Scheduler time: 72.23419168032706 Scheduler overhead time: 0.055527165066450834 Adapter cache time: 0.01528749754652381 Engine time: 0.05140328640118241 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-16/adapters_384_slots_64_rate_3.2-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-16/adapters_384_slots_64_rate_3.2-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 1080, 66, 34560, 34560, 66, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 66, 34560, 66, 34560, 1080, 1080, 1080, 66, 66, 1080, 66, 34560, 66, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 34560, 66, 34560, 34560, 34560, 34560, 66, 1080, 1080, 1080, 34560, 1080, 66, 1080, 66, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 66, 66, 34560, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 34560, 66, 1080, 34560, 66, 34560, 1080, 66, 34560, 34560, 34560, 34560, 1080, 66, 1080, 34560, 34560, 1080, 66, 66, 34560, 1080, 1080, 66, 66, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 66, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 34560, 66, 66, 66, 1080, 1080, 34560, 66, 66, 34560, 66, 34560, 1080, 66, 34560, 1080, 1080, 66, 34560, 34560, 34560, 66, 1080, 34560, 66, 34560, 1080, 1080, 34560, 34560, 66, 1080, 34560, 66, 1080, 1080, 66, 1080, 66, 1080, 34560, 34560, 1080, 66, 34560, 66, 34560, 1080, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 34560, 66, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 34560, 34560, 66, 66, 34560, 66, 66, 66, 1080, 66, 1080, 34560, 34560, 1080, 1080, 66, 34560, 1080, 34560, 66, 1080, 1080, 66, 66, 1080, 66, 34560, 34560, 66, 34560, 34560, 66, 1080, 34560, 66, 66, 1080, 1080, 66, 66, 34560, 34560, 34560, 34560, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 34560, 1080, 1080, 1080, 34560, 66, 1080, 1080, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 1080, 66, 34560, 34560, 34560, 1080, 66, 34560, 34560, 1080, 1080, 34560, 34560, 66, 34560, 34560, 1080, 66, 34560, 1080, 1080, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 1080, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 34560, 66, 66, 66, 1080, 66, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 34560, 34560, 66, 34560, 34560, 66, 34560, 1080, 34560, 1080, 1080, 1080, 66, 1080, 66, 66, 34560, 66, 1080, 66, 66, 1080, 34560, 1080, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4570368 . Total input tokens: 1018326849 . Total output tokens: 913762655
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 73.11383705213666,
    "estimated_duration": 3600.027268124763,
    "input_throughput": 6187.19869074838,
    "output_throughput": 5443.304880912051,
    "total_throughput": 11630.50357166043,
    "itl": 151.75002314549582,
    "ttft": 2095350.1349848984,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 459,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4970546574844104,
    "arrivals": 1522091,
    "finished_requests": 89899,
    "scheduler_time": 177.08706617375069
}
#Debug simulation 
Total elapsed time: 73.11395293613896. Arrivals time: 0.5380725655704737 Scheduler time: 72.43095726380125 Scheduler overhead time: 0.056038998533040285 Adapter cache time: 0.015478373505175114 Engine time: 0.052476507145911455 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-32/adapters_384_slots_64_rate_3.2-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-32/adapters_384_slots_64_rate_3.2-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 1080, 66, 34560, 34560, 66, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 66, 34560, 66, 34560, 1080, 1080, 1080, 66, 66, 1080, 66, 34560, 66, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 34560, 66, 34560, 34560, 34560, 34560, 66, 1080, 1080, 1080, 34560, 1080, 66, 1080, 66, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 66, 66, 34560, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 34560, 66, 1080, 34560, 66, 34560, 1080, 66, 34560, 34560, 34560, 34560, 1080, 66, 1080, 34560, 34560, 1080, 66, 66, 34560, 1080, 1080, 66, 66, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 66, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 34560, 66, 66, 66, 1080, 1080, 34560, 66, 66, 34560, 66, 34560, 1080, 66, 34560, 1080, 1080, 66, 34560, 34560, 34560, 66, 1080, 34560, 66, 34560, 1080, 1080, 34560, 34560, 66, 1080, 34560, 66, 1080, 1080, 66, 1080, 66, 1080, 34560, 34560, 1080, 66, 34560, 66, 34560, 1080, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 34560, 66, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 34560, 34560, 66, 66, 34560, 66, 66, 66, 1080, 66, 1080, 34560, 34560, 1080, 1080, 66, 34560, 1080, 34560, 66, 1080, 1080, 66, 66, 1080, 66, 34560, 34560, 66, 34560, 34560, 66, 1080, 34560, 66, 66, 1080, 1080, 66, 66, 34560, 34560, 34560, 34560, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 34560, 1080, 1080, 1080, 34560, 66, 1080, 1080, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 1080, 66, 34560, 34560, 34560, 1080, 66, 34560, 34560, 1080, 1080, 34560, 34560, 66, 34560, 34560, 1080, 66, 34560, 1080, 1080, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 1080, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 34560, 66, 66, 66, 1080, 66, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 34560, 34560, 66, 34560, 34560, 66, 34560, 1080, 34560, 1080, 1080, 1080, 66, 1080, 66, 66, 34560, 66, 1080, 66, 66, 1080, 34560, 1080, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4570368 . Total input tokens: 1018326849 . Total output tokens: 913762655
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 73.33381658094004,
    "estimated_duration": 3600.030050565014,
    "input_throughput": 6187.193908701998,
    "output_throughput": 5443.300673816448,
    "total_throughput": 11630.494582518446,
    "itl": 151.75010322907235,
    "ttft": 2095350.9743086451,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 459,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4998356374166995,
    "arrivals": 1522091,
    "finished_requests": 89899,
    "scheduler_time": 177.08706763403856
}
#Debug simulation 
Total elapsed time: 73.33393659396097. Arrivals time: 0.4340256047435105 Scheduler time: 72.75547421630472 Scheduler overhead time: 0.056650733575224876 Adapter cache time: 0.014986657537519932 Engine time: 0.051716928370296955 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-16/adapters_384_slots_64_rate_3.2-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-16/adapters_384_slots_64_rate_3.2-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 1080, 66, 34560, 34560, 66, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 66, 34560, 66, 34560, 1080, 1080, 1080, 66, 66, 1080, 66, 34560, 66, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 34560, 66, 34560, 34560, 34560, 34560, 66, 1080, 1080, 1080, 34560, 1080, 66, 1080, 66, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 66, 66, 34560, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 34560, 66, 1080, 34560, 66, 34560, 1080, 66, 34560, 34560, 34560, 34560, 1080, 66, 1080, 34560, 34560, 1080, 66, 66, 34560, 1080, 1080, 66, 66, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 66, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 34560, 66, 66, 66, 1080, 1080, 34560, 66, 66, 34560, 66, 34560, 1080, 66, 34560, 1080, 1080, 66, 34560, 34560, 34560, 66, 1080, 34560, 66, 34560, 1080, 1080, 34560, 34560, 66, 1080, 34560, 66, 1080, 1080, 66, 1080, 66, 1080, 34560, 34560, 1080, 66, 34560, 66, 34560, 1080, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 34560, 66, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 34560, 34560, 66, 66, 34560, 66, 66, 66, 1080, 66, 1080, 34560, 34560, 1080, 1080, 66, 34560, 1080, 34560, 66, 1080, 1080, 66, 66, 1080, 66, 34560, 34560, 66, 34560, 34560, 66, 1080, 34560, 66, 66, 1080, 1080, 66, 66, 34560, 34560, 34560, 34560, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 34560, 1080, 1080, 1080, 34560, 66, 1080, 1080, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 1080, 66, 34560, 34560, 34560, 1080, 66, 34560, 34560, 1080, 1080, 34560, 34560, 66, 34560, 34560, 1080, 66, 34560, 1080, 1080, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 1080, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 34560, 66, 66, 66, 1080, 66, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 34560, 34560, 66, 34560, 34560, 66, 34560, 1080, 34560, 1080, 1080, 1080, 66, 1080, 66, 66, 34560, 66, 1080, 66, 66, 1080, 34560, 1080, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4570368 . Total input tokens: 1018326849 . Total output tokens: 913762655
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 72.84279457619414,
    "estimated_duration": 3600.1398845223175,
    "input_throughput": 6187.319302720809,
    "output_throughput": 5443.404875530335,
    "total_throughput": 11630.724178251145,
    "itl": 151.74873891684823,
    "ttft": 2095362.251809332,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 459,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4373997409921104,
    "arrivals": 1522091,
    "finished_requests": 89902,
    "scheduler_time": 177.09504881204137
}
#Debug simulation 
Total elapsed time: 72.84291068837047. Arrivals time: 0.43358819326385856 Scheduler time: 72.26571854343638 Scheduler overhead time: 0.056082630064338446 Adapter cache time: 0.015227965079247952 Engine time: 0.051643598824739456 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-32/adapters_384_slots_64_rate_3.2-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-32/adapters_384_slots_64_rate_3.2-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 1080, 66, 34560, 34560, 66, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 66, 34560, 66, 34560, 1080, 1080, 1080, 66, 66, 1080, 66, 34560, 66, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 34560, 66, 34560, 34560, 34560, 34560, 66, 1080, 1080, 1080, 34560, 1080, 66, 1080, 66, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 66, 66, 34560, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 34560, 66, 1080, 34560, 66, 34560, 1080, 66, 34560, 34560, 34560, 34560, 1080, 66, 1080, 34560, 34560, 1080, 66, 66, 34560, 1080, 1080, 66, 66, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 66, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 34560, 66, 66, 66, 1080, 1080, 34560, 66, 66, 34560, 66, 34560, 1080, 66, 34560, 1080, 1080, 66, 34560, 34560, 34560, 66, 1080, 34560, 66, 34560, 1080, 1080, 34560, 34560, 66, 1080, 34560, 66, 1080, 1080, 66, 1080, 66, 1080, 34560, 34560, 1080, 66, 34560, 66, 34560, 1080, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 34560, 66, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 34560, 34560, 66, 66, 34560, 66, 66, 66, 1080, 66, 1080, 34560, 34560, 1080, 1080, 66, 34560, 1080, 34560, 66, 1080, 1080, 66, 66, 1080, 66, 34560, 34560, 66, 34560, 34560, 66, 1080, 34560, 66, 66, 1080, 1080, 66, 66, 34560, 34560, 34560, 34560, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 34560, 1080, 1080, 1080, 34560, 66, 1080, 1080, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 1080, 66, 34560, 34560, 34560, 1080, 66, 34560, 34560, 1080, 1080, 34560, 34560, 66, 34560, 34560, 1080, 66, 34560, 1080, 1080, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 1080, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 34560, 66, 66, 66, 1080, 66, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 34560, 34560, 66, 34560, 34560, 66, 34560, 1080, 34560, 1080, 1080, 1080, 66, 1080, 66, 66, 34560, 66, 1080, 66, 66, 1080, 34560, 1080, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4570368 . Total input tokens: 1018326849 . Total output tokens: 913762655
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 72.63096222514287,
    "estimated_duration": 3600.048516671209,
    "input_throughput": 6187.162172079772,
    "output_throughput": 5443.272752923763,
    "total_throughput": 11630.434925003534,
    "itl": 151.75068102692003,
    "ttft": 2095357.175462393,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 459,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.518195690233265,
    "arrivals": 1522091,
    "finished_requests": 89899,
    "scheduler_time": 177.08717368744692
}
#Debug simulation 
Total elapsed time: 72.63108503306285. Arrivals time: 0.419704198371619 Scheduler time: 72.0675263912417 Scheduler overhead time: 0.05576322693377733 Adapter cache time: 0.015405618585646152 Engine time: 0.05182559788227081 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-16/adapters_384_slots_64_rate_3.2-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-16/adapters_384_slots_64_rate_3.2-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 1080, 66, 34560, 34560, 66, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 66, 34560, 66, 34560, 1080, 1080, 1080, 66, 66, 1080, 66, 34560, 66, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 34560, 66, 34560, 34560, 34560, 34560, 66, 1080, 1080, 1080, 34560, 1080, 66, 1080, 66, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 66, 66, 34560, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 34560, 66, 1080, 34560, 66, 34560, 1080, 66, 34560, 34560, 34560, 34560, 1080, 66, 1080, 34560, 34560, 1080, 66, 66, 34560, 1080, 1080, 66, 66, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 66, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 34560, 66, 66, 66, 1080, 1080, 34560, 66, 66, 34560, 66, 34560, 1080, 66, 34560, 1080, 1080, 66, 34560, 34560, 34560, 66, 1080, 34560, 66, 34560, 1080, 1080, 34560, 34560, 66, 1080, 34560, 66, 1080, 1080, 66, 1080, 66, 1080, 34560, 34560, 1080, 66, 34560, 66, 34560, 1080, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 34560, 66, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 34560, 34560, 66, 66, 34560, 66, 66, 66, 1080, 66, 1080, 34560, 34560, 1080, 1080, 66, 34560, 1080, 34560, 66, 1080, 1080, 66, 66, 1080, 66, 34560, 34560, 66, 34560, 34560, 66, 1080, 34560, 66, 66, 1080, 1080, 66, 66, 34560, 34560, 34560, 34560, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 34560, 1080, 1080, 1080, 34560, 66, 1080, 1080, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 1080, 66, 34560, 34560, 34560, 1080, 66, 34560, 34560, 1080, 1080, 34560, 34560, 66, 34560, 34560, 1080, 66, 34560, 1080, 1080, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 1080, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 34560, 66, 66, 66, 1080, 66, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 34560, 34560, 66, 34560, 34560, 66, 34560, 1080, 34560, 1080, 1080, 1080, 66, 1080, 66, 66, 34560, 66, 1080, 66, 66, 1080, 34560, 1080, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4570368 . Total input tokens: 1018326849 . Total output tokens: 913762655
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 73.16970958421007,
    "estimated_duration": 3600.074495843504,
    "input_throughput": 6187.431683904884,
    "output_throughput": 5443.50374488803,
    "total_throughput": 11630.935428792915,
    "itl": 151.74666603662047,
    "ttft": 2095338.8436978844,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 459,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3724330853600868,
    "arrivals": 1522091,
    "finished_requests": 89902,
    "scheduler_time": 177.0946267888398
}
#Debug simulation 
Total elapsed time: 73.16982587007806. Arrivals time: 0.5331327812746167 Scheduler time: 72.49269660236314 Scheduler overhead time: 0.05592807289212942 Adapter cache time: 0.01522849127650261 Engine time: 0.051677064038813114 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-32/adapters_384_slots_64_rate_3.2-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-32/adapters_384_slots_64_rate_3.2-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 1080, 66, 34560, 34560, 66, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 66, 34560, 66, 34560, 1080, 1080, 1080, 66, 66, 1080, 66, 34560, 66, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 34560, 66, 34560, 34560, 34560, 34560, 66, 1080, 1080, 1080, 34560, 1080, 66, 1080, 66, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 66, 66, 34560, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 34560, 66, 1080, 34560, 66, 34560, 1080, 66, 34560, 34560, 34560, 34560, 1080, 66, 1080, 34560, 34560, 1080, 66, 66, 34560, 1080, 1080, 66, 66, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 66, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 34560, 66, 66, 66, 1080, 1080, 34560, 66, 66, 34560, 66, 34560, 1080, 66, 34560, 1080, 1080, 66, 34560, 34560, 34560, 66, 1080, 34560, 66, 34560, 1080, 1080, 34560, 34560, 66, 1080, 34560, 66, 1080, 1080, 66, 1080, 66, 1080, 34560, 34560, 1080, 66, 34560, 66, 34560, 1080, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 34560, 66, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 34560, 34560, 66, 66, 34560, 66, 66, 66, 1080, 66, 1080, 34560, 34560, 1080, 1080, 66, 34560, 1080, 34560, 66, 1080, 1080, 66, 66, 1080, 66, 34560, 34560, 66, 34560, 34560, 66, 1080, 34560, 66, 66, 1080, 1080, 66, 66, 34560, 34560, 34560, 34560, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 34560, 1080, 1080, 1080, 34560, 66, 1080, 1080, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 1080, 66, 34560, 34560, 34560, 1080, 66, 34560, 34560, 1080, 1080, 34560, 34560, 66, 34560, 34560, 1080, 66, 34560, 1080, 1080, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 1080, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 34560, 66, 66, 66, 1080, 66, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 34560, 34560, 66, 34560, 34560, 66, 34560, 1080, 34560, 1080, 1080, 1080, 66, 1080, 66, 66, 34560, 66, 1080, 66, 66, 1080, 34560, 1080, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4570368 . Total input tokens: 1018326849 . Total output tokens: 913762655
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 72.69786237506196,
    "estimated_duration": 3600.0686338223313,
    "input_throughput": 6187.127598273244,
    "output_throughput": 5443.242335964613,
    "total_throughput": 11630.369934237857,
    "itl": 151.75131871669637,
    "ttft": 2095364.3737082803,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 459,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.538190542273223,
    "arrivals": 1522091,
    "finished_requests": 89899,
    "scheduler_time": 177.0872959865581
}
#Debug simulation 
Total elapsed time: 72.69797707395628. Arrivals time: 0.43896556459367275 Scheduler time: 72.11455798987299 Scheduler overhead time: 0.05647592106834054 Adapter cache time: 0.015219050459563732 Engine time: 0.05175826791673899 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-8/adapters_384_slots_64_rate_3.2-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-8/adapters_384_slots_64_rate_3.2-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 1080, 33, 34560, 34560, 33, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 33, 34560, 33, 34560, 1080, 1080, 1080, 33, 33, 1080, 33, 34560, 33, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 34560, 33, 34560, 34560, 34560, 34560, 33, 1080, 1080, 1080, 34560, 1080, 33, 1080, 33, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 33, 33, 34560, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 34560, 33, 1080, 34560, 33, 34560, 1080, 33, 34560, 34560, 34560, 34560, 1080, 33, 1080, 34560, 34560, 1080, 33, 33, 34560, 1080, 1080, 33, 33, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 33, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 34560, 33, 33, 33, 1080, 1080, 34560, 33, 33, 34560, 33, 34560, 1080, 33, 34560, 1080, 1080, 33, 34560, 34560, 34560, 33, 1080, 34560, 33, 34560, 1080, 1080, 34560, 34560, 33, 1080, 34560, 33, 1080, 1080, 33, 1080, 33, 1080, 34560, 34560, 1080, 33, 34560, 33, 34560, 1080, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 34560, 33, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 34560, 34560, 33, 33, 34560, 33, 33, 33, 1080, 33, 1080, 34560, 34560, 1080, 1080, 33, 34560, 1080, 34560, 33, 1080, 1080, 33, 33, 1080, 33, 34560, 34560, 33, 34560, 34560, 33, 1080, 34560, 33, 33, 1080, 1080, 33, 33, 34560, 34560, 34560, 34560, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 34560, 1080, 1080, 1080, 34560, 33, 1080, 1080, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 1080, 33, 34560, 34560, 34560, 1080, 33, 34560, 34560, 1080, 1080, 34560, 34560, 33, 34560, 34560, 1080, 33, 34560, 1080, 1080, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 1080, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 34560, 33, 33, 33, 1080, 33, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 34560, 34560, 33, 34560, 34560, 33, 34560, 1080, 34560, 1080, 1080, 1080, 33, 1080, 33, 33, 34560, 33, 1080, 33, 33, 1080, 34560, 1080, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4566144 . Total input tokens: 1017376545 . Total output tokens: 912918458
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 72.90401326306164,
    "estimated_duration": 3600.0342782403213,
    "input_throughput": 6172.090119892107,
    "output_throughput": 5446.7581374209985,
    "total_throughput": 11618.848257313106,
    "itl": 152.24803945295116,
    "ttft": 2094724.0354044603,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 407,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.245618511780638,
    "arrivals": 1520700,
    "finished_requests": 90085,
    "scheduler_time": 176.9168668181522
}
#Debug simulation 
Total elapsed time: 72.90413589728996. Arrivals time: 0.8252421198412776 Scheduler time: 71.93680894328281 Scheduler overhead time: 0.05594292189925909 Adapter cache time: 0.014184468425810337 Engine time: 0.05127181299030781 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-16/adapters_384_slots_64_rate_3.2-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-16/adapters_384_slots_64_rate_3.2-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 1080, 33, 34560, 34560, 33, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 33, 34560, 33, 34560, 1080, 1080, 1080, 33, 33, 1080, 33, 34560, 33, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 34560, 33, 34560, 34560, 34560, 34560, 33, 1080, 1080, 1080, 34560, 1080, 33, 1080, 33, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 33, 33, 34560, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 34560, 33, 1080, 34560, 33, 34560, 1080, 33, 34560, 34560, 34560, 34560, 1080, 33, 1080, 34560, 34560, 1080, 33, 33, 34560, 1080, 1080, 33, 33, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 33, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 34560, 33, 33, 33, 1080, 1080, 34560, 33, 33, 34560, 33, 34560, 1080, 33, 34560, 1080, 1080, 33, 34560, 34560, 34560, 33, 1080, 34560, 33, 34560, 1080, 1080, 34560, 34560, 33, 1080, 34560, 33, 1080, 1080, 33, 1080, 33, 1080, 34560, 34560, 1080, 33, 34560, 33, 34560, 1080, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 34560, 33, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 34560, 34560, 33, 33, 34560, 33, 33, 33, 1080, 33, 1080, 34560, 34560, 1080, 1080, 33, 34560, 1080, 34560, 33, 1080, 1080, 33, 33, 1080, 33, 34560, 34560, 33, 34560, 34560, 33, 1080, 34560, 33, 33, 1080, 1080, 33, 33, 34560, 34560, 34560, 34560, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 34560, 1080, 1080, 1080, 34560, 33, 1080, 1080, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 1080, 33, 34560, 34560, 34560, 1080, 33, 34560, 34560, 1080, 1080, 34560, 34560, 33, 34560, 34560, 1080, 33, 34560, 1080, 1080, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 1080, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 34560, 33, 33, 33, 1080, 33, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 34560, 34560, 33, 34560, 34560, 33, 34560, 1080, 34560, 1080, 1080, 1080, 33, 1080, 33, 33, 34560, 33, 1080, 33, 33, 1080, 34560, 1080, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4566144 . Total input tokens: 1017376545 . Total output tokens: 912918458
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 73.18996530026197,
    "estimated_duration": 3600.1164683205157,
    "input_throughput": 6171.949212066934,
    "output_throughput": 5446.633788808376,
    "total_throughput": 11618.583000875311,
    "itl": 152.25053773709084,
    "ttft": 2094755.492527809,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 407,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3272712060040848,
    "arrivals": 1520700,
    "finished_requests": 90085,
    "scheduler_time": 176.9174042040974
}
#Debug simulation 
Total elapsed time: 73.19008735194802. Arrivals time: 0.43347577657550573 Scheduler time: 72.61484788823873 Scheduler overhead time: 0.055413109716027975 Adapter cache time: 0.014460134319961071 Engine time: 0.05110588809475303 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-32/adapters_384_slots_64_rate_3.2-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-32/adapters_384_slots_64_rate_3.2-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 1080, 33, 34560, 34560, 33, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 33, 34560, 33, 34560, 1080, 1080, 1080, 33, 33, 1080, 33, 34560, 33, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 34560, 33, 34560, 34560, 34560, 34560, 33, 1080, 1080, 1080, 34560, 1080, 33, 1080, 33, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 33, 33, 34560, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 34560, 33, 1080, 34560, 33, 34560, 1080, 33, 34560, 34560, 34560, 34560, 1080, 33, 1080, 34560, 34560, 1080, 33, 33, 34560, 1080, 1080, 33, 33, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 33, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 34560, 33, 33, 33, 1080, 1080, 34560, 33, 33, 34560, 33, 34560, 1080, 33, 34560, 1080, 1080, 33, 34560, 34560, 34560, 33, 1080, 34560, 33, 34560, 1080, 1080, 34560, 34560, 33, 1080, 34560, 33, 1080, 1080, 33, 1080, 33, 1080, 34560, 34560, 1080, 33, 34560, 33, 34560, 1080, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 34560, 33, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 34560, 34560, 33, 33, 34560, 33, 33, 33, 1080, 33, 1080, 34560, 34560, 1080, 1080, 33, 34560, 1080, 34560, 33, 1080, 1080, 33, 33, 1080, 33, 34560, 34560, 33, 34560, 34560, 33, 1080, 34560, 33, 33, 1080, 1080, 33, 33, 34560, 34560, 34560, 34560, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 34560, 1080, 1080, 1080, 34560, 33, 1080, 1080, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 1080, 33, 34560, 34560, 34560, 1080, 33, 34560, 34560, 1080, 1080, 34560, 34560, 33, 34560, 34560, 1080, 33, 34560, 1080, 1080, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 1080, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 34560, 33, 33, 33, 1080, 33, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 34560, 34560, 33, 34560, 34560, 33, 34560, 1080, 34560, 1080, 1080, 1080, 33, 1080, 33, 33, 34560, 33, 1080, 33, 33, 1080, 34560, 1080, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4566144 . Total input tokens: 1017376545 . Total output tokens: 912918458
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 72.69314742507413,
    "estimated_duration": 3600.1189829028194,
    "input_throughput": 6171.944901133228,
    "output_throughput": 5446.629984487184,
    "total_throughput": 11618.574885620412,
    "itl": 152.25061135502844,
    "ttft": 2094756.3640139075,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 407,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3297689949721174,
    "arrivals": 1520700,
    "finished_requests": 90085,
    "scheduler_time": 176.91742099740821
}
#Debug simulation 
Total elapsed time: 72.69326570117846. Arrivals time: 0.4350800667889416 Scheduler time: 72.11450809473172 Scheduler overhead time: 0.05631377128884196 Adapter cache time: 0.014526639599353075 Engine time: 0.051902801264077425 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-16/adapters_384_slots_64_rate_3.2-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-16/adapters_384_slots_64_rate_3.2-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 1080, 33, 34560, 34560, 33, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 33, 34560, 33, 34560, 1080, 1080, 1080, 33, 33, 1080, 33, 34560, 33, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 34560, 33, 34560, 34560, 34560, 34560, 33, 1080, 1080, 1080, 34560, 1080, 33, 1080, 33, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 33, 33, 34560, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 34560, 33, 1080, 34560, 33, 34560, 1080, 33, 34560, 34560, 34560, 34560, 1080, 33, 1080, 34560, 34560, 1080, 33, 33, 34560, 1080, 1080, 33, 33, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 33, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 34560, 33, 33, 33, 1080, 1080, 34560, 33, 33, 34560, 33, 34560, 1080, 33, 34560, 1080, 1080, 33, 34560, 34560, 34560, 33, 1080, 34560, 33, 34560, 1080, 1080, 34560, 34560, 33, 1080, 34560, 33, 1080, 1080, 33, 1080, 33, 1080, 34560, 34560, 1080, 33, 34560, 33, 34560, 1080, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 34560, 33, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 34560, 34560, 33, 33, 34560, 33, 33, 33, 1080, 33, 1080, 34560, 34560, 1080, 1080, 33, 34560, 1080, 34560, 33, 1080, 1080, 33, 33, 1080, 33, 34560, 34560, 33, 34560, 34560, 33, 1080, 34560, 33, 33, 1080, 1080, 33, 33, 34560, 34560, 34560, 34560, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 34560, 1080, 1080, 1080, 34560, 33, 1080, 1080, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 1080, 33, 34560, 34560, 34560, 1080, 33, 34560, 34560, 1080, 1080, 34560, 34560, 33, 34560, 34560, 1080, 33, 34560, 1080, 1080, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 1080, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 34560, 33, 33, 33, 1080, 33, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 34560, 34560, 33, 34560, 34560, 33, 34560, 1080, 34560, 1080, 1080, 1080, 33, 1080, 33, 33, 34560, 33, 1080, 33, 33, 1080, 34560, 1080, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4566144 . Total input tokens: 1017376545 . Total output tokens: 912918458
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 72.52002028701827,
    "estimated_duration": 3600.061762261637,
    "input_throughput": 6172.04300018483,
    "output_throughput": 5446.7165551297385,
    "total_throughput": 11618.75955531457,
    "itl": 152.2489954504182,
    "ttft": 2094735.7030119074,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 407,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2729280286515108,
    "arrivals": 1520700,
    "finished_requests": 90085,
    "scheduler_time": 176.9170413225556
}
#Debug simulation 
Total elapsed time: 72.52014071587473. Arrivals time: 0.44452287536114454 Scheduler time: 71.93156964099035 Scheduler overhead time: 0.05646783299744129 Adapter cache time: 0.014586583711206913 Engine time: 0.051947521045804024 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-32/adapters_384_slots_64_rate_3.2-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-32/adapters_384_slots_64_rate_3.2-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 1080, 33, 34560, 34560, 33, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 33, 34560, 33, 34560, 1080, 1080, 1080, 33, 33, 1080, 33, 34560, 33, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 34560, 33, 34560, 34560, 34560, 34560, 33, 1080, 1080, 1080, 34560, 1080, 33, 1080, 33, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 33, 33, 34560, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 34560, 33, 1080, 34560, 33, 34560, 1080, 33, 34560, 34560, 34560, 34560, 1080, 33, 1080, 34560, 34560, 1080, 33, 33, 34560, 1080, 1080, 33, 33, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 33, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 34560, 33, 33, 33, 1080, 1080, 34560, 33, 33, 34560, 33, 34560, 1080, 33, 34560, 1080, 1080, 33, 34560, 34560, 34560, 33, 1080, 34560, 33, 34560, 1080, 1080, 34560, 34560, 33, 1080, 34560, 33, 1080, 1080, 33, 1080, 33, 1080, 34560, 34560, 1080, 33, 34560, 33, 34560, 1080, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 34560, 33, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 34560, 34560, 33, 33, 34560, 33, 33, 33, 1080, 33, 1080, 34560, 34560, 1080, 1080, 33, 34560, 1080, 34560, 33, 1080, 1080, 33, 33, 1080, 33, 34560, 34560, 33, 34560, 34560, 33, 1080, 34560, 33, 33, 1080, 1080, 33, 33, 34560, 34560, 34560, 34560, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 34560, 1080, 1080, 1080, 34560, 33, 1080, 1080, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 1080, 33, 34560, 34560, 34560, 1080, 33, 34560, 34560, 1080, 1080, 34560, 34560, 33, 34560, 34560, 1080, 33, 34560, 1080, 1080, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 1080, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 34560, 33, 33, 33, 1080, 33, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 34560, 34560, 33, 34560, 34560, 33, 34560, 1080, 34560, 1080, 1080, 1080, 33, 1080, 33, 33, 34560, 33, 1080, 33, 33, 1080, 34560, 1080, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4566144 . Total input tokens: 1017376545 . Total output tokens: 912918458
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 72.61771561717615,
    "estimated_duration": 3600.1358207810913,
    "input_throughput": 6171.916034873143,
    "output_throughput": 5446.604510533634,
    "total_throughput": 11618.520545406776,
    "itl": 152.2510860510393,
    "ttft": 2094762.4553479096,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 407,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3464942485652909,
    "arrivals": 1520700,
    "finished_requests": 90085,
    "scheduler_time": 176.91753362211207
}
#Debug simulation 
Total elapsed time: 72.61783652333543. Arrivals time: 0.4442560882307589 Scheduler time: 72.03046923968941 Scheduler overhead time: 0.05598285887390375 Adapter cache time: 0.0145509815774858 Engine time: 0.051530785858631134 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-16/adapters_384_slots_64_rate_3.2-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-16/adapters_384_slots_64_rate_3.2-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 1080, 33, 34560, 34560, 33, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 33, 34560, 33, 34560, 1080, 1080, 1080, 33, 33, 1080, 33, 34560, 33, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 34560, 33, 34560, 34560, 34560, 34560, 33, 1080, 1080, 1080, 34560, 1080, 33, 1080, 33, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 33, 33, 34560, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 34560, 33, 1080, 34560, 33, 34560, 1080, 33, 34560, 34560, 34560, 34560, 1080, 33, 1080, 34560, 34560, 1080, 33, 33, 34560, 1080, 1080, 33, 33, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 33, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 34560, 33, 33, 33, 1080, 1080, 34560, 33, 33, 34560, 33, 34560, 1080, 33, 34560, 1080, 1080, 33, 34560, 34560, 34560, 33, 1080, 34560, 33, 34560, 1080, 1080, 34560, 34560, 33, 1080, 34560, 33, 1080, 1080, 33, 1080, 33, 1080, 34560, 34560, 1080, 33, 34560, 33, 34560, 1080, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 34560, 33, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 34560, 34560, 33, 33, 34560, 33, 33, 33, 1080, 33, 1080, 34560, 34560, 1080, 1080, 33, 34560, 1080, 34560, 33, 1080, 1080, 33, 33, 1080, 33, 34560, 34560, 33, 34560, 34560, 33, 1080, 34560, 33, 33, 1080, 1080, 33, 33, 34560, 34560, 34560, 34560, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 34560, 1080, 1080, 1080, 34560, 33, 1080, 1080, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 1080, 33, 34560, 34560, 34560, 1080, 33, 34560, 34560, 1080, 1080, 34560, 34560, 33, 34560, 34560, 1080, 33, 34560, 1080, 1080, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 1080, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 34560, 33, 33, 33, 1080, 33, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 34560, 34560, 33, 34560, 34560, 33, 34560, 1080, 34560, 1080, 1080, 1080, 33, 1080, 33, 33, 34560, 33, 1080, 33, 33, 1080, 34560, 1080, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4566144 . Total input tokens: 1017376545 . Total output tokens: 912918458
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 72.59353021439165,
    "estimated_duration": 3600.0054159803317,
    "input_throughput": 6172.139603281474,
    "output_throughput": 5446.801805619041,
    "total_throughput": 11618.941408900515,
    "itl": 152.24716695207962,
    "ttft": 2094713.1424826111,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 407,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2169504700251792,
    "arrivals": 1520700,
    "finished_requests": 90085,
    "scheduler_time": 176.91667259986218
}
#Debug simulation 
Total elapsed time: 72.59364703530446. Arrivals time: 0.4200917547568679 Scheduler time: 72.03152123140171 Scheduler overhead time: 0.055757713969796896 Adapter cache time: 0.014288350008428097 Engine time: 0.05144917359575629 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-32/adapters_384_slots_64_rate_3.2-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-32/adapters_384_slots_64_rate_3.2-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 1080, 33, 34560, 34560, 33, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 33, 34560, 33, 34560, 1080, 1080, 1080, 33, 33, 1080, 33, 34560, 33, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 34560, 33, 34560, 34560, 34560, 34560, 33, 1080, 1080, 1080, 34560, 1080, 33, 1080, 33, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 33, 33, 34560, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 34560, 33, 1080, 34560, 33, 34560, 1080, 33, 34560, 34560, 34560, 34560, 1080, 33, 1080, 34560, 34560, 1080, 33, 33, 34560, 1080, 1080, 33, 33, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 33, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 34560, 33, 33, 33, 1080, 1080, 34560, 33, 33, 34560, 33, 34560, 1080, 33, 34560, 1080, 1080, 33, 34560, 34560, 34560, 33, 1080, 34560, 33, 34560, 1080, 1080, 34560, 34560, 33, 1080, 34560, 33, 1080, 1080, 33, 1080, 33, 1080, 34560, 34560, 1080, 33, 34560, 33, 34560, 1080, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 34560, 33, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 34560, 34560, 33, 33, 34560, 33, 33, 33, 1080, 33, 1080, 34560, 34560, 1080, 1080, 33, 34560, 1080, 34560, 33, 1080, 1080, 33, 33, 1080, 33, 34560, 34560, 33, 34560, 34560, 33, 1080, 34560, 33, 33, 1080, 1080, 33, 33, 34560, 34560, 34560, 34560, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 34560, 1080, 1080, 1080, 34560, 33, 1080, 1080, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 1080, 33, 34560, 34560, 34560, 1080, 33, 34560, 34560, 1080, 1080, 34560, 34560, 33, 34560, 34560, 1080, 33, 34560, 1080, 1080, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 1080, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 34560, 33, 33, 33, 1080, 33, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 34560, 34560, 33, 34560, 34560, 33, 34560, 1080, 34560, 1080, 1080, 1080, 33, 1080, 33, 33, 34560, 33, 1080, 33, 33, 1080, 34560, 1080, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4566144 . Total input tokens: 1017376545 . Total output tokens: 912918458
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 72.5413267458789,
    "estimated_duration": 3600.1531603967596,
    "input_throughput": 6171.8863087345,
    "output_throughput": 5446.578277752777,
    "total_throughput": 11618.464586487276,
    "itl": 152.25164880331923,
    "ttft": 2094769.3971628968,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 407,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.363722517304124,
    "arrivals": 1520700,
    "finished_requests": 90085,
    "scheduler_time": 176.91764496906407
}
#Debug simulation 
Total elapsed time: 72.54144164687023. Arrivals time: 0.41436244966462255 Scheduler time: 71.98368054488674 Scheduler overhead time: 0.056274246890097857 Adapter cache time: 0.014577711466699839 Engine time: 0.05168791068717837 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-8/adapters_384_slots_64_rate_3.2-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-8/adapters_384_slots_64_rate_3.2-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 540, 270, 34560, 34560, 270, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 270, 34560, 270, 34560, 540, 540, 540, 270, 270, 540, 270, 34560, 270, 34560, 540, 34560, 540, 270, 540, 34560, 540, 34560, 270, 34560, 34560, 34560, 34560, 270, 540, 540, 540, 34560, 540, 270, 540, 270, 34560, 540, 34560, 34560, 540, 34560, 34560, 270, 270, 34560, 540, 540, 270, 270, 270, 540, 270, 540, 270, 34560, 270, 540, 34560, 270, 34560, 540, 270, 34560, 34560, 34560, 34560, 540, 270, 540, 34560, 34560, 540, 270, 270, 34560, 540, 540, 270, 270, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 270, 540, 540, 540, 540, 270, 270, 34560, 270, 34560, 270, 270, 270, 540, 540, 34560, 270, 270, 34560, 270, 34560, 540, 270, 34560, 540, 540, 270, 34560, 34560, 34560, 270, 540, 34560, 270, 34560, 540, 540, 34560, 34560, 270, 540, 34560, 270, 540, 540, 270, 540, 270, 540, 34560, 34560, 540, 270, 34560, 270, 34560, 540, 540, 540, 540, 540, 270, 270, 34560, 270, 34560, 270, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 270, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 270, 270, 270, 270, 270, 540, 270, 270, 540, 34560, 34560, 270, 270, 34560, 270, 270, 270, 540, 270, 540, 34560, 34560, 540, 540, 270, 34560, 540, 34560, 270, 540, 540, 270, 270, 540, 270, 34560, 34560, 270, 34560, 34560, 270, 540, 34560, 270, 270, 540, 540, 270, 270, 34560, 34560, 34560, 34560, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 34560, 540, 540, 540, 34560, 270, 540, 540, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 540, 270, 34560, 34560, 34560, 540, 270, 34560, 34560, 540, 540, 34560, 34560, 270, 34560, 34560, 540, 270, 34560, 540, 540, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 540, 34560, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 34560, 270, 270, 270, 540, 270, 540, 540, 270, 34560, 540, 34560, 270, 34560, 270, 540, 540, 540, 540, 270, 540, 34560, 34560, 270, 34560, 34560, 270, 34560, 540, 34560, 540, 540, 540, 270, 540, 270, 270, 34560, 270, 540, 270, 270, 540, 34560, 540, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4527360 . Total input tokens: 1008743448 . Total output tokens: 905196474
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 74.58610861934721,
    "estimated_duration": 3600.128150547208,
    "input_throughput": 6081.905444580336,
    "output_throughput": 5415.743047101382,
    "total_throughput": 11497.648491681719,
    "itl": 152.75758497008894,
    "ttft": 2089676.5253588287,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 487,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4904575312952668,
    "arrivals": 1507762,
    "finished_requests": 88680,
    "scheduler_time": 178.47548948633326
}
#Debug simulation 
Total elapsed time: 74.58621541503817. Arrivals time: 0.4200570988468826 Scheduler time: 74.02139153145254 Scheduler overhead time: 0.05656031519174576 Adapter cache time: 0.015429229009896517 Engine time: 0.05184664065018296 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-16/adapters_384_slots_64_rate_3.2-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-16/adapters_384_slots_64_rate_3.2-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 540, 270, 34560, 34560, 270, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 270, 34560, 270, 34560, 540, 540, 540, 270, 270, 540, 270, 34560, 270, 34560, 540, 34560, 540, 270, 540, 34560, 540, 34560, 270, 34560, 34560, 34560, 34560, 270, 540, 540, 540, 34560, 540, 270, 540, 270, 34560, 540, 34560, 34560, 540, 34560, 34560, 270, 270, 34560, 540, 540, 270, 270, 270, 540, 270, 540, 270, 34560, 270, 540, 34560, 270, 34560, 540, 270, 34560, 34560, 34560, 34560, 540, 270, 540, 34560, 34560, 540, 270, 270, 34560, 540, 540, 270, 270, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 270, 540, 540, 540, 540, 270, 270, 34560, 270, 34560, 270, 270, 270, 540, 540, 34560, 270, 270, 34560, 270, 34560, 540, 270, 34560, 540, 540, 270, 34560, 34560, 34560, 270, 540, 34560, 270, 34560, 540, 540, 34560, 34560, 270, 540, 34560, 270, 540, 540, 270, 540, 270, 540, 34560, 34560, 540, 270, 34560, 270, 34560, 540, 540, 540, 540, 540, 270, 270, 34560, 270, 34560, 270, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 270, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 270, 270, 270, 270, 270, 540, 270, 270, 540, 34560, 34560, 270, 270, 34560, 270, 270, 270, 540, 270, 540, 34560, 34560, 540, 540, 270, 34560, 540, 34560, 270, 540, 540, 270, 270, 540, 270, 34560, 34560, 270, 34560, 34560, 270, 540, 34560, 270, 270, 540, 540, 270, 270, 34560, 34560, 34560, 34560, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 34560, 540, 540, 540, 34560, 270, 540, 540, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 540, 270, 34560, 34560, 34560, 540, 270, 34560, 34560, 540, 540, 34560, 34560, 270, 34560, 34560, 540, 270, 34560, 540, 540, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 540, 34560, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 34560, 270, 270, 270, 540, 270, 540, 540, 270, 34560, 540, 34560, 270, 34560, 270, 540, 540, 540, 540, 270, 540, 34560, 34560, 270, 34560, 34560, 270, 34560, 540, 34560, 540, 540, 540, 270, 540, 270, 270, 34560, 270, 540, 270, 270, 540, 34560, 540, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4527360 . Total input tokens: 1008743448 . Total output tokens: 905196474
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 75.19709584396333,
    "estimated_duration": 3600.1690794636293,
    "input_throughput": 6070.537387998471,
    "output_throughput": 5407.356313081926,
    "total_throughput": 11477.893701080397,
    "itl": 152.6630963811009,
    "ttft": 2088502.0081226958,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 480,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5663832387724013,
    "arrivals": 1507762,
    "finished_requests": 88530,
    "scheduler_time": 178.9143746724584
}
#Debug simulation 
Total elapsed time: 75.19720827275887. Arrivals time: 0.4234157642349601 Scheduler time: 74.6293065706268 Scheduler overhead time: 0.056729492731392384 Adapter cache time: 0.015465822070837021 Engine time: 0.05121633131057024 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-32/adapters_384_slots_64_rate_3.2-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-32/adapters_384_slots_64_rate_3.2-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 540, 270, 34560, 34560, 270, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 270, 34560, 270, 34560, 540, 540, 540, 270, 270, 540, 270, 34560, 270, 34560, 540, 34560, 540, 270, 540, 34560, 540, 34560, 270, 34560, 34560, 34560, 34560, 270, 540, 540, 540, 34560, 540, 270, 540, 270, 34560, 540, 34560, 34560, 540, 34560, 34560, 270, 270, 34560, 540, 540, 270, 270, 270, 540, 270, 540, 270, 34560, 270, 540, 34560, 270, 34560, 540, 270, 34560, 34560, 34560, 34560, 540, 270, 540, 34560, 34560, 540, 270, 270, 34560, 540, 540, 270, 270, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 270, 540, 540, 540, 540, 270, 270, 34560, 270, 34560, 270, 270, 270, 540, 540, 34560, 270, 270, 34560, 270, 34560, 540, 270, 34560, 540, 540, 270, 34560, 34560, 34560, 270, 540, 34560, 270, 34560, 540, 540, 34560, 34560, 270, 540, 34560, 270, 540, 540, 270, 540, 270, 540, 34560, 34560, 540, 270, 34560, 270, 34560, 540, 540, 540, 540, 540, 270, 270, 34560, 270, 34560, 270, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 270, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 270, 270, 270, 270, 270, 540, 270, 270, 540, 34560, 34560, 270, 270, 34560, 270, 270, 270, 540, 270, 540, 34560, 34560, 540, 540, 270, 34560, 540, 34560, 270, 540, 540, 270, 270, 540, 270, 34560, 34560, 270, 34560, 34560, 270, 540, 34560, 270, 270, 540, 540, 270, 270, 34560, 34560, 34560, 34560, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 34560, 540, 540, 540, 34560, 270, 540, 540, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 540, 270, 34560, 34560, 34560, 540, 270, 34560, 34560, 540, 540, 34560, 34560, 270, 34560, 34560, 540, 270, 34560, 540, 540, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 540, 34560, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 34560, 270, 270, 270, 540, 270, 540, 540, 270, 34560, 540, 34560, 270, 34560, 270, 540, 540, 540, 540, 270, 540, 34560, 34560, 270, 34560, 34560, 270, 34560, 540, 34560, 540, 540, 540, 270, 540, 270, 270, 34560, 270, 540, 270, 270, 540, 34560, 540, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4527360 . Total input tokens: 1008743448 . Total output tokens: 905196474
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 74.86637621792033,
    "estimated_duration": 3600.171856320925,
    "input_throughput": 6070.532705717539,
    "output_throughput": 5407.3521423207985,
    "total_throughput": 11477.884848038337,
    "itl": 152.66316197472642,
    "ttft": 2088502.6644863586,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 480,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.569145493153492,
    "arrivals": 1507762,
    "finished_requests": 88530,
    "scheduler_time": 178.91438927533736
}
#Debug simulation 
Total elapsed time: 74.86648644087836. Arrivals time: 0.41845004679635167 Scheduler time: 74.30264758551493 Scheduler overhead time: 0.05676330579444766 Adapter cache time: 0.015409055631607771 Engine time: 0.05227807490155101 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-16-16/adapters_384_slots_64_rate_3.2-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-16-16/adapters_384_slots_64_rate_3.2-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 540, 270, 34560, 34560, 270, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 270, 34560, 270, 34560, 540, 540, 540, 270, 270, 540, 270, 34560, 270, 34560, 540, 34560, 540, 270, 540, 34560, 540, 34560, 270, 34560, 34560, 34560, 34560, 270, 540, 540, 540, 34560, 540, 270, 540, 270, 34560, 540, 34560, 34560, 540, 34560, 34560, 270, 270, 34560, 540, 540, 270, 270, 270, 540, 270, 540, 270, 34560, 270, 540, 34560, 270, 34560, 540, 270, 34560, 34560, 34560, 34560, 540, 270, 540, 34560, 34560, 540, 270, 270, 34560, 540, 540, 270, 270, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 270, 540, 540, 540, 540, 270, 270, 34560, 270, 34560, 270, 270, 270, 540, 540, 34560, 270, 270, 34560, 270, 34560, 540, 270, 34560, 540, 540, 270, 34560, 34560, 34560, 270, 540, 34560, 270, 34560, 540, 540, 34560, 34560, 270, 540, 34560, 270, 540, 540, 270, 540, 270, 540, 34560, 34560, 540, 270, 34560, 270, 34560, 540, 540, 540, 540, 540, 270, 270, 34560, 270, 34560, 270, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 270, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 270, 270, 270, 270, 270, 540, 270, 270, 540, 34560, 34560, 270, 270, 34560, 270, 270, 270, 540, 270, 540, 34560, 34560, 540, 540, 270, 34560, 540, 34560, 270, 540, 540, 270, 270, 540, 270, 34560, 34560, 270, 34560, 34560, 270, 540, 34560, 270, 270, 540, 540, 270, 270, 34560, 34560, 34560, 34560, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 34560, 540, 540, 540, 34560, 270, 540, 540, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 540, 270, 34560, 34560, 34560, 540, 270, 34560, 34560, 540, 540, 34560, 34560, 270, 34560, 34560, 540, 270, 34560, 540, 540, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 540, 34560, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 34560, 270, 270, 270, 540, 270, 540, 540, 270, 34560, 540, 34560, 270, 34560, 270, 540, 540, 540, 540, 270, 540, 34560, 34560, 270, 34560, 34560, 270, 34560, 540, 34560, 540, 540, 540, 270, 540, 270, 270, 34560, 270, 540, 270, 270, 540, 34560, 540, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4527360 . Total input tokens: 1008743448 . Total output tokens: 905196474
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 74.68178974185139,
    "estimated_duration": 3600.1050423380657,
    "input_throughput": 6070.645368115824,
    "output_throughput": 5407.452496818543,
    "total_throughput": 11478.097864934367,
    "itl": 152.66164181573254,
    "ttft": 2088482.527614168,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 480,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5026423690956963,
    "arrivals": 1507762,
    "finished_requests": 88530,
    "scheduler_time": 178.91407841655177
}
#Debug simulation 
Total elapsed time: 74.6819024309516. Arrivals time: 0.41470480943098664 Scheduler time: 74.12212175130844 Scheduler overhead time: 0.05670087086036801 Adapter cache time: 0.015575016383081675 Engine time: 0.05156928626820445 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-16-32/adapters_384_slots_64_rate_3.2-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-16-32/adapters_384_slots_64_rate_3.2-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 540, 270, 34560, 34560, 270, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 270, 34560, 270, 34560, 540, 540, 540, 270, 270, 540, 270, 34560, 270, 34560, 540, 34560, 540, 270, 540, 34560, 540, 34560, 270, 34560, 34560, 34560, 34560, 270, 540, 540, 540, 34560, 540, 270, 540, 270, 34560, 540, 34560, 34560, 540, 34560, 34560, 270, 270, 34560, 540, 540, 270, 270, 270, 540, 270, 540, 270, 34560, 270, 540, 34560, 270, 34560, 540, 270, 34560, 34560, 34560, 34560, 540, 270, 540, 34560, 34560, 540, 270, 270, 34560, 540, 540, 270, 270, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 270, 540, 540, 540, 540, 270, 270, 34560, 270, 34560, 270, 270, 270, 540, 540, 34560, 270, 270, 34560, 270, 34560, 540, 270, 34560, 540, 540, 270, 34560, 34560, 34560, 270, 540, 34560, 270, 34560, 540, 540, 34560, 34560, 270, 540, 34560, 270, 540, 540, 270, 540, 270, 540, 34560, 34560, 540, 270, 34560, 270, 34560, 540, 540, 540, 540, 540, 270, 270, 34560, 270, 34560, 270, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 270, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 270, 270, 270, 270, 270, 540, 270, 270, 540, 34560, 34560, 270, 270, 34560, 270, 270, 270, 540, 270, 540, 34560, 34560, 540, 540, 270, 34560, 540, 34560, 270, 540, 540, 270, 270, 540, 270, 34560, 34560, 270, 34560, 34560, 270, 540, 34560, 270, 270, 540, 540, 270, 270, 34560, 34560, 34560, 34560, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 34560, 540, 540, 540, 34560, 270, 540, 540, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 540, 270, 34560, 34560, 34560, 540, 270, 34560, 34560, 540, 540, 34560, 34560, 270, 34560, 34560, 540, 270, 34560, 540, 540, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 540, 34560, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 34560, 270, 270, 270, 540, 270, 540, 540, 270, 34560, 540, 34560, 270, 34560, 270, 540, 540, 540, 540, 270, 540, 34560, 34560, 270, 34560, 34560, 270, 34560, 540, 34560, 540, 540, 540, 270, 540, 270, 270, 34560, 270, 540, 270, 270, 540, 34560, 540, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4527360 . Total input tokens: 1008743448 . Total output tokens: 905196474
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 75.28584064776078,
    "estimated_duration": 3600.0164964551495,
    "input_throughput": 6070.364127919562,
    "output_throughput": 5407.1110560652705,
    "total_throughput": 11477.475183984832,
    "itl": 152.66246594394548,
    "ttft": 2088486.9239495182,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 480,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5887630838342055,
    "arrivals": 1507762,
    "finished_requests": 88521,
    "scheduler_time": 178.90606753951346
}
#Debug simulation 
Total elapsed time: 75.2859555548057. Arrivals time: 0.7890112739987671 Scheduler time: 74.3510055099614 Scheduler overhead time: 0.057090913876891136 Adapter cache time: 0.015618362464010715 Engine time: 0.05206400342285633 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_16-16-16/adapters_384_slots_64_rate_3.2-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_16-16-16/adapters_384_slots_64_rate_3.2-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 540, 270, 34560, 34560, 270, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 270, 34560, 270, 34560, 540, 540, 540, 270, 270, 540, 270, 34560, 270, 34560, 540, 34560, 540, 270, 540, 34560, 540, 34560, 270, 34560, 34560, 34560, 34560, 270, 540, 540, 540, 34560, 540, 270, 540, 270, 34560, 540, 34560, 34560, 540, 34560, 34560, 270, 270, 34560, 540, 540, 270, 270, 270, 540, 270, 540, 270, 34560, 270, 540, 34560, 270, 34560, 540, 270, 34560, 34560, 34560, 34560, 540, 270, 540, 34560, 34560, 540, 270, 270, 34560, 540, 540, 270, 270, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 270, 540, 540, 540, 540, 270, 270, 34560, 270, 34560, 270, 270, 270, 540, 540, 34560, 270, 270, 34560, 270, 34560, 540, 270, 34560, 540, 540, 270, 34560, 34560, 34560, 270, 540, 34560, 270, 34560, 540, 540, 34560, 34560, 270, 540, 34560, 270, 540, 540, 270, 540, 270, 540, 34560, 34560, 540, 270, 34560, 270, 34560, 540, 540, 540, 540, 540, 270, 270, 34560, 270, 34560, 270, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 270, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 270, 270, 270, 270, 270, 540, 270, 270, 540, 34560, 34560, 270, 270, 34560, 270, 270, 270, 540, 270, 540, 34560, 34560, 540, 540, 270, 34560, 540, 34560, 270, 540, 540, 270, 270, 540, 270, 34560, 34560, 270, 34560, 34560, 270, 540, 34560, 270, 270, 540, 540, 270, 270, 34560, 34560, 34560, 34560, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 34560, 540, 540, 540, 34560, 270, 540, 540, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 540, 270, 34560, 34560, 34560, 540, 270, 34560, 34560, 540, 540, 34560, 34560, 270, 34560, 34560, 540, 270, 34560, 540, 540, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 540, 34560, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 34560, 270, 270, 270, 540, 270, 540, 540, 270, 34560, 540, 34560, 270, 34560, 270, 540, 540, 540, 540, 270, 540, 34560, 34560, 270, 34560, 34560, 270, 34560, 540, 34560, 540, 540, 540, 270, 540, 270, 270, 34560, 270, 540, 270, 270, 540, 34560, 540, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4527360 . Total input tokens: 1008743448 . Total output tokens: 905196474
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 74.58482380909845,
    "estimated_duration": 3600.093667164054,
    "input_throughput": 6081.963699918986,
    "output_throughput": 5415.79492162461,
    "total_throughput": 11497.758621543595,
    "itl": 152.7567750671567,
    "ttft": 2089665.9805305107,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 487,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4561544936173447,
    "arrivals": 1507762,
    "finished_requests": 88680,
    "scheduler_time": 178.47530914077825
}
#Debug simulation 
Total elapsed time: 74.58494672365487. Arrivals time: 0.40581755619496107 Scheduler time: 74.03531412221491 Scheduler overhead time: 0.05592075642198324 Adapter cache time: 0.015248185489326715 Engine time: 0.05156618030741811 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_16-16-32/adapters_384_slots_64_rate_3.2-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_16-16-32/adapters_384_slots_64_rate_3.2-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 540, 270, 34560, 34560, 270, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 270, 34560, 270, 34560, 540, 540, 540, 270, 270, 540, 270, 34560, 270, 34560, 540, 34560, 540, 270, 540, 34560, 540, 34560, 270, 34560, 34560, 34560, 34560, 270, 540, 540, 540, 34560, 540, 270, 540, 270, 34560, 540, 34560, 34560, 540, 34560, 34560, 270, 270, 34560, 540, 540, 270, 270, 270, 540, 270, 540, 270, 34560, 270, 540, 34560, 270, 34560, 540, 270, 34560, 34560, 34560, 34560, 540, 270, 540, 34560, 34560, 540, 270, 270, 34560, 540, 540, 270, 270, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 270, 540, 540, 540, 540, 270, 270, 34560, 270, 34560, 270, 270, 270, 540, 540, 34560, 270, 270, 34560, 270, 34560, 540, 270, 34560, 540, 540, 270, 34560, 34560, 34560, 270, 540, 34560, 270, 34560, 540, 540, 34560, 34560, 270, 540, 34560, 270, 540, 540, 270, 540, 270, 540, 34560, 34560, 540, 270, 34560, 270, 34560, 540, 540, 540, 540, 540, 270, 270, 34560, 270, 34560, 270, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 270, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 270, 270, 270, 270, 270, 540, 270, 270, 540, 34560, 34560, 270, 270, 34560, 270, 270, 270, 540, 270, 540, 34560, 34560, 540, 540, 270, 34560, 540, 34560, 270, 540, 540, 270, 270, 540, 270, 34560, 34560, 270, 34560, 34560, 270, 540, 34560, 270, 270, 540, 540, 270, 270, 34560, 34560, 34560, 34560, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 34560, 540, 540, 540, 34560, 270, 540, 540, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 540, 270, 34560, 34560, 34560, 540, 270, 34560, 34560, 540, 540, 34560, 34560, 270, 34560, 34560, 540, 270, 34560, 540, 540, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 540, 34560, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 34560, 270, 270, 270, 540, 270, 540, 540, 270, 34560, 540, 34560, 270, 34560, 270, 540, 540, 540, 540, 270, 540, 34560, 34560, 270, 34560, 34560, 270, 34560, 540, 34560, 540, 540, 540, 270, 540, 270, 270, 34560, 270, 540, 270, 270, 540, 34560, 540, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4527360 . Total input tokens: 1008743448 . Total output tokens: 905196474
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 74.70063243201002,
    "estimated_duration": 3600.037373422529,
    "input_throughput": 6070.328925286718,
    "output_throughput": 5407.079699701593,
    "total_throughput": 11477.408624988311,
    "itl": 152.6629300894964,
    "ttft": 2088493.7696966913,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 480,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6095124585926521,
    "arrivals": 1507762,
    "finished_requests": 88521,
    "scheduler_time": 178.90619513216828
}
#Debug simulation 
Total elapsed time: 74.7007547263056. Arrivals time: 0.4049418717622757 Scheduler time: 74.15065370174125 Scheduler overhead time: 0.05672771297395229 Adapter cache time: 0.015584376640617847 Engine time: 0.05198272597044706 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-8/adapters_384_slots_64_rate_3.2-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-8/adapters_384_slots_64_rate_3.2-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 540, 135, 34560, 34560, 135, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 135, 34560, 135, 34560, 540, 540, 540, 135, 135, 540, 135, 34560, 135, 34560, 540, 34560, 540, 135, 540, 34560, 540, 34560, 135, 34560, 34560, 34560, 34560, 135, 540, 540, 540, 34560, 540, 135, 540, 135, 34560, 540, 34560, 34560, 540, 34560, 34560, 135, 135, 34560, 540, 540, 135, 135, 135, 540, 135, 540, 135, 34560, 135, 540, 34560, 135, 34560, 540, 135, 34560, 34560, 34560, 34560, 540, 135, 540, 34560, 34560, 540, 135, 135, 34560, 540, 540, 135, 135, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 135, 540, 540, 540, 540, 135, 135, 34560, 135, 34560, 135, 135, 135, 540, 540, 34560, 135, 135, 34560, 135, 34560, 540, 135, 34560, 540, 540, 135, 34560, 34560, 34560, 135, 540, 34560, 135, 34560, 540, 540, 34560, 34560, 135, 540, 34560, 135, 540, 540, 135, 540, 135, 540, 34560, 34560, 540, 135, 34560, 135, 34560, 540, 540, 540, 540, 540, 135, 135, 34560, 135, 34560, 135, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 135, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 135, 135, 135, 135, 135, 540, 135, 135, 540, 34560, 34560, 135, 135, 34560, 135, 135, 135, 540, 135, 540, 34560, 34560, 540, 540, 135, 34560, 540, 34560, 135, 540, 540, 135, 135, 540, 135, 34560, 34560, 135, 34560, 34560, 135, 540, 34560, 135, 135, 540, 540, 135, 135, 34560, 34560, 34560, 34560, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 34560, 540, 540, 540, 34560, 135, 540, 540, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 540, 135, 34560, 34560, 34560, 540, 135, 34560, 34560, 540, 540, 34560, 34560, 135, 34560, 34560, 540, 135, 34560, 540, 540, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 540, 34560, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 34560, 135, 135, 135, 540, 135, 540, 540, 135, 34560, 540, 34560, 135, 34560, 135, 540, 540, 540, 540, 135, 540, 34560, 34560, 135, 34560, 34560, 135, 34560, 540, 34560, 540, 540, 540, 135, 540, 135, 135, 34560, 135, 540, 135, 135, 540, 34560, 540, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4510080 . Total input tokens: 1004889616 . Total output tokens: 901721610
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 71.80216751806438,
    "estimated_duration": 3600.080958192888,
    "input_throughput": 6144.540708080041,
    "output_throughput": 5466.6265088324035,
    "total_throughput": 11611.167216912445,
    "itl": 153.63070856887077,
    "ttft": 2094606.835640028,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 519,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5883931391011183,
    "arrivals": 1502157,
    "finished_requests": 89602,
    "scheduler_time": 175.69179771848
}
#Debug simulation 
Total elapsed time: 71.80228685913607. Arrivals time: 0.5143806166015565 Scheduler time: 71.14425888238475 Scheduler overhead time: 0.05607709055766463 Adapter cache time: 0.015782432164996862 Engine time: 0.051119282841682434 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-16/adapters_384_slots_64_rate_3.2-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-16/adapters_384_slots_64_rate_3.2-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 540, 135, 34560, 34560, 135, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 135, 34560, 135, 34560, 540, 540, 540, 135, 135, 540, 135, 34560, 135, 34560, 540, 34560, 540, 135, 540, 34560, 540, 34560, 135, 34560, 34560, 34560, 34560, 135, 540, 540, 540, 34560, 540, 135, 540, 135, 34560, 540, 34560, 34560, 540, 34560, 34560, 135, 135, 34560, 540, 540, 135, 135, 135, 540, 135, 540, 135, 34560, 135, 540, 34560, 135, 34560, 540, 135, 34560, 34560, 34560, 34560, 540, 135, 540, 34560, 34560, 540, 135, 135, 34560, 540, 540, 135, 135, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 135, 540, 540, 540, 540, 135, 135, 34560, 135, 34560, 135, 135, 135, 540, 540, 34560, 135, 135, 34560, 135, 34560, 540, 135, 34560, 540, 540, 135, 34560, 34560, 34560, 135, 540, 34560, 135, 34560, 540, 540, 34560, 34560, 135, 540, 34560, 135, 540, 540, 135, 540, 135, 540, 34560, 34560, 540, 135, 34560, 135, 34560, 540, 540, 540, 540, 540, 135, 135, 34560, 135, 34560, 135, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 135, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 135, 135, 135, 135, 135, 540, 135, 135, 540, 34560, 34560, 135, 135, 34560, 135, 135, 135, 540, 135, 540, 34560, 34560, 540, 540, 135, 34560, 540, 34560, 135, 540, 540, 135, 135, 540, 135, 34560, 34560, 135, 34560, 34560, 135, 540, 34560, 135, 135, 540, 540, 135, 135, 34560, 34560, 34560, 34560, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 34560, 540, 540, 540, 34560, 135, 540, 540, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 540, 135, 34560, 34560, 34560, 540, 135, 34560, 34560, 540, 540, 34560, 34560, 135, 34560, 34560, 540, 135, 34560, 540, 540, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 540, 34560, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 34560, 135, 135, 135, 540, 135, 540, 540, 135, 34560, 540, 34560, 135, 34560, 135, 540, 540, 540, 540, 135, 540, 34560, 34560, 135, 34560, 34560, 135, 34560, 540, 34560, 540, 540, 540, 135, 540, 135, 135, 34560, 135, 540, 135, 135, 540, 34560, 540, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4510080 . Total input tokens: 1004889616 . Total output tokens: 901721610
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 71.4969420931302,
    "estimated_duration": 3600.012418979939,
    "input_throughput": 6144.361303694509,
    "output_throughput": 5466.39253138356,
    "total_throughput": 11610.753835078069,
    "itl": 153.63292712729623,
    "ttft": 2094601.7359673607,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 519,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6928014879161546,
    "arrivals": 1502157,
    "finished_requests": 89597,
    "scheduler_time": 175.68397426000783
}
#Debug simulation 
Total elapsed time: 71.49705949611962. Arrivals time: 0.40617602970451117 Scheduler time: 70.9461404280737 Scheduler overhead time: 0.056414512917399406 Adapter cache time: 0.01578243402764201 Engine time: 0.05169378640130162 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-32/adapters_384_slots_64_rate_3.2-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-32/adapters_384_slots_64_rate_3.2-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 540, 135, 34560, 34560, 135, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 135, 34560, 135, 34560, 540, 540, 540, 135, 135, 540, 135, 34560, 135, 34560, 540, 34560, 540, 135, 540, 34560, 540, 34560, 135, 34560, 34560, 34560, 34560, 135, 540, 540, 540, 34560, 540, 135, 540, 135, 34560, 540, 34560, 34560, 540, 34560, 34560, 135, 135, 34560, 540, 540, 135, 135, 135, 540, 135, 540, 135, 34560, 135, 540, 34560, 135, 34560, 540, 135, 34560, 34560, 34560, 34560, 540, 135, 540, 34560, 34560, 540, 135, 135, 34560, 540, 540, 135, 135, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 135, 540, 540, 540, 540, 135, 135, 34560, 135, 34560, 135, 135, 135, 540, 540, 34560, 135, 135, 34560, 135, 34560, 540, 135, 34560, 540, 540, 135, 34560, 34560, 34560, 135, 540, 34560, 135, 34560, 540, 540, 34560, 34560, 135, 540, 34560, 135, 540, 540, 135, 540, 135, 540, 34560, 34560, 540, 135, 34560, 135, 34560, 540, 540, 540, 540, 540, 135, 135, 34560, 135, 34560, 135, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 135, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 135, 135, 135, 135, 135, 540, 135, 135, 540, 34560, 34560, 135, 135, 34560, 135, 135, 135, 540, 135, 540, 34560, 34560, 540, 540, 135, 34560, 540, 34560, 135, 540, 540, 135, 135, 540, 135, 34560, 34560, 135, 34560, 34560, 135, 540, 34560, 135, 135, 540, 540, 135, 135, 34560, 34560, 34560, 34560, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 34560, 540, 540, 540, 34560, 135, 540, 540, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 540, 135, 34560, 34560, 34560, 540, 135, 34560, 34560, 540, 540, 34560, 34560, 135, 34560, 34560, 540, 135, 34560, 540, 540, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 540, 34560, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 34560, 135, 135, 135, 540, 135, 540, 540, 135, 34560, 540, 34560, 135, 34560, 135, 540, 540, 540, 540, 135, 540, 34560, 34560, 135, 34560, 34560, 135, 34560, 540, 34560, 540, 540, 540, 135, 540, 135, 135, 34560, 135, 540, 135, 135, 540, 34560, 540, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4510080 . Total input tokens: 1004889616 . Total output tokens: 901721610
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 71.97720532631502,
    "estimated_duration": 3600.0155662075535,
    "input_throughput": 6144.3559321334105,
    "output_throughput": 5466.387752520465,
    "total_throughput": 11610.743684653877,
    "itl": 153.63303804501857,
    "ttft": 2094602.7829673062,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 519,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6959366681240602,
    "arrivals": 1502157,
    "finished_requests": 89597,
    "scheduler_time": 175.68398630738295
}
#Debug simulation 
Total elapsed time: 71.97732262127101. Arrivals time: 0.5314470496959984 Scheduler time: 71.3018192583695 Scheduler overhead time: 0.05633634002879262 Adapter cache time: 0.015843969769775867 Engine time: 0.051109081134200096 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-16/adapters_384_slots_64_rate_3.2-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-16/adapters_384_slots_64_rate_3.2-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 540, 135, 34560, 34560, 135, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 135, 34560, 135, 34560, 540, 540, 540, 135, 135, 540, 135, 34560, 135, 34560, 540, 34560, 540, 135, 540, 34560, 540, 34560, 135, 34560, 34560, 34560, 34560, 135, 540, 540, 540, 34560, 540, 135, 540, 135, 34560, 540, 34560, 34560, 540, 34560, 34560, 135, 135, 34560, 540, 540, 135, 135, 135, 540, 135, 540, 135, 34560, 135, 540, 34560, 135, 34560, 540, 135, 34560, 34560, 34560, 34560, 540, 135, 540, 34560, 34560, 540, 135, 135, 34560, 540, 540, 135, 135, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 135, 540, 540, 540, 540, 135, 135, 34560, 135, 34560, 135, 135, 135, 540, 540, 34560, 135, 135, 34560, 135, 34560, 540, 135, 34560, 540, 540, 135, 34560, 34560, 34560, 135, 540, 34560, 135, 34560, 540, 540, 34560, 34560, 135, 540, 34560, 135, 540, 540, 135, 540, 135, 540, 34560, 34560, 540, 135, 34560, 135, 34560, 540, 540, 540, 540, 540, 135, 135, 34560, 135, 34560, 135, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 135, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 135, 135, 135, 135, 135, 540, 135, 135, 540, 34560, 34560, 135, 135, 34560, 135, 135, 135, 540, 135, 540, 34560, 34560, 540, 540, 135, 34560, 540, 34560, 135, 540, 540, 135, 135, 540, 135, 34560, 34560, 135, 34560, 34560, 135, 540, 34560, 135, 135, 540, 540, 135, 135, 34560, 34560, 34560, 34560, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 34560, 540, 540, 540, 34560, 135, 540, 540, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 540, 135, 34560, 34560, 34560, 540, 135, 34560, 34560, 540, 540, 34560, 34560, 135, 34560, 34560, 540, 135, 34560, 540, 540, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 540, 34560, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 34560, 135, 135, 135, 540, 135, 540, 540, 135, 34560, 540, 34560, 135, 34560, 135, 540, 540, 540, 540, 135, 540, 34560, 34560, 135, 34560, 34560, 135, 34560, 540, 34560, 540, 540, 540, 135, 540, 135, 135, 34560, 135, 540, 135, 135, 540, 34560, 540, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4510080 . Total input tokens: 1004889616 . Total output tokens: 901721610
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 71.92501341830939,
    "estimated_duration": 3600.1173103739275,
    "input_throughput": 6144.478663586218,
    "output_throughput": 5466.571309576548,
    "total_throughput": 11611.049973162766,
    "itl": 153.63178751136547,
    "ttft": 2094619.8915629743,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 519,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6245660697366036,
    "arrivals": 1502157,
    "finished_requests": 89602,
    "scheduler_time": 175.69197696881906
}
#Debug simulation 
Total elapsed time: 71.9251264911145. Arrivals time: 0.4178752740845084 Scheduler time: 71.36360491393134 Scheduler overhead time: 0.05575227830559015 Adapter cache time: 0.01602626871317625 Engine time: 0.05115894740447402 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-32/adapters_384_slots_64_rate_3.2-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-32/adapters_384_slots_64_rate_3.2-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 540, 135, 34560, 34560, 135, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 135, 34560, 135, 34560, 540, 540, 540, 135, 135, 540, 135, 34560, 135, 34560, 540, 34560, 540, 135, 540, 34560, 540, 34560, 135, 34560, 34560, 34560, 34560, 135, 540, 540, 540, 34560, 540, 135, 540, 135, 34560, 540, 34560, 34560, 540, 34560, 34560, 135, 135, 34560, 540, 540, 135, 135, 135, 540, 135, 540, 135, 34560, 135, 540, 34560, 135, 34560, 540, 135, 34560, 34560, 34560, 34560, 540, 135, 540, 34560, 34560, 540, 135, 135, 34560, 540, 540, 135, 135, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 135, 540, 540, 540, 540, 135, 135, 34560, 135, 34560, 135, 135, 135, 540, 540, 34560, 135, 135, 34560, 135, 34560, 540, 135, 34560, 540, 540, 135, 34560, 34560, 34560, 135, 540, 34560, 135, 34560, 540, 540, 34560, 34560, 135, 540, 34560, 135, 540, 540, 135, 540, 135, 540, 34560, 34560, 540, 135, 34560, 135, 34560, 540, 540, 540, 540, 540, 135, 135, 34560, 135, 34560, 135, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 135, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 135, 135, 135, 135, 135, 540, 135, 135, 540, 34560, 34560, 135, 135, 34560, 135, 135, 135, 540, 135, 540, 34560, 34560, 540, 540, 135, 34560, 540, 34560, 135, 540, 540, 135, 135, 540, 135, 34560, 34560, 135, 34560, 34560, 135, 540, 34560, 135, 135, 540, 540, 135, 135, 34560, 34560, 34560, 34560, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 34560, 540, 540, 540, 34560, 135, 540, 540, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 540, 135, 34560, 34560, 34560, 540, 135, 34560, 34560, 540, 540, 34560, 34560, 135, 34560, 34560, 540, 135, 34560, 540, 540, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 540, 34560, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 34560, 135, 135, 135, 540, 135, 540, 540, 135, 34560, 540, 34560, 135, 34560, 135, 540, 540, 540, 540, 135, 540, 34560, 34560, 135, 34560, 34560, 135, 34560, 540, 34560, 540, 540, 540, 135, 540, 135, 135, 34560, 135, 540, 135, 135, 540, 34560, 540, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4510080 . Total input tokens: 1004889616 . Total output tokens: 901721610
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 71.70308130001649,
    "estimated_duration": 3600.0366791669508,
    "input_throughput": 6144.319897629077,
    "output_throughput": 5466.355694063023,
    "total_throughput": 11610.675591692101,
    "itl": 153.6337189250443,
    "ttft": 2094609.9388697608,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 519,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7169375504553357,
    "arrivals": 1502157,
    "finished_requests": 89597,
    "scheduler_time": 175.68409838447886
}
#Debug simulation 
Total elapsed time: 71.7032025391236. Arrivals time: 0.5257522105239332 Scheduler time: 71.03296104911715 Scheduler overhead time: 0.05619655083864927 Adapter cache time: 0.016137562226504087 Engine time: 0.05144960340112448 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-16/adapters_384_slots_64_rate_3.2-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-16/adapters_384_slots_64_rate_3.2-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 540, 135, 34560, 34560, 135, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 135, 34560, 135, 34560, 540, 540, 540, 135, 135, 540, 135, 34560, 135, 34560, 540, 34560, 540, 135, 540, 34560, 540, 34560, 135, 34560, 34560, 34560, 34560, 135, 540, 540, 540, 34560, 540, 135, 540, 135, 34560, 540, 34560, 34560, 540, 34560, 34560, 135, 135, 34560, 540, 540, 135, 135, 135, 540, 135, 540, 135, 34560, 135, 540, 34560, 135, 34560, 540, 135, 34560, 34560, 34560, 34560, 540, 135, 540, 34560, 34560, 540, 135, 135, 34560, 540, 540, 135, 135, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 135, 540, 540, 540, 540, 135, 135, 34560, 135, 34560, 135, 135, 135, 540, 540, 34560, 135, 135, 34560, 135, 34560, 540, 135, 34560, 540, 540, 135, 34560, 34560, 34560, 135, 540, 34560, 135, 34560, 540, 540, 34560, 34560, 135, 540, 34560, 135, 540, 540, 135, 540, 135, 540, 34560, 34560, 540, 135, 34560, 135, 34560, 540, 540, 540, 540, 540, 135, 135, 34560, 135, 34560, 135, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 135, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 135, 135, 135, 135, 135, 540, 135, 135, 540, 34560, 34560, 135, 135, 34560, 135, 135, 135, 540, 135, 540, 34560, 34560, 540, 540, 135, 34560, 540, 34560, 135, 540, 540, 135, 135, 540, 135, 34560, 34560, 135, 34560, 34560, 135, 540, 34560, 135, 135, 540, 540, 135, 135, 34560, 34560, 34560, 34560, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 34560, 540, 540, 540, 34560, 135, 540, 540, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 540, 135, 34560, 34560, 34560, 540, 135, 34560, 34560, 540, 540, 34560, 34560, 135, 34560, 34560, 540, 135, 34560, 540, 540, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 540, 34560, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 34560, 135, 135, 135, 540, 135, 540, 540, 135, 34560, 540, 34560, 135, 34560, 135, 540, 540, 540, 540, 135, 540, 34560, 34560, 135, 34560, 34560, 135, 34560, 540, 34560, 540, 540, 540, 135, 540, 135, 135, 34560, 135, 540, 135, 135, 540, 34560, 540, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4510080 . Total input tokens: 1004889616 . Total output tokens: 901721610
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 71.72866850811988,
    "estimated_duration": 3600.0442149702226,
    "input_throughput": 6144.603421261861,
    "output_throughput": 5466.682303001321,
    "total_throughput": 11611.285724263182,
    "itl": 153.6295355189039,
    "ttft": 2094594.1939693044,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 519,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.551836103054211,
    "arrivals": 1502157,
    "finished_requests": 89602,
    "scheduler_time": 175.69161153177342
}
#Debug simulation 
Total elapsed time: 71.72878666780889. Arrivals time: 0.4137920211069286 Scheduler time: 71.17032500868663 Scheduler overhead time: 0.05647484166547656 Adapter cache time: 0.01600175676867366 Engine time: 0.051240908447653055 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-32/adapters_384_slots_64_rate_3.2-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-32/adapters_384_slots_64_rate_3.2-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 540, 135, 34560, 34560, 135, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 135, 34560, 135, 34560, 540, 540, 540, 135, 135, 540, 135, 34560, 135, 34560, 540, 34560, 540, 135, 540, 34560, 540, 34560, 135, 34560, 34560, 34560, 34560, 135, 540, 540, 540, 34560, 540, 135, 540, 135, 34560, 540, 34560, 34560, 540, 34560, 34560, 135, 135, 34560, 540, 540, 135, 135, 135, 540, 135, 540, 135, 34560, 135, 540, 34560, 135, 34560, 540, 135, 34560, 34560, 34560, 34560, 540, 135, 540, 34560, 34560, 540, 135, 135, 34560, 540, 540, 135, 135, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 135, 540, 540, 540, 540, 135, 135, 34560, 135, 34560, 135, 135, 135, 540, 540, 34560, 135, 135, 34560, 135, 34560, 540, 135, 34560, 540, 540, 135, 34560, 34560, 34560, 135, 540, 34560, 135, 34560, 540, 540, 34560, 34560, 135, 540, 34560, 135, 540, 540, 135, 540, 135, 540, 34560, 34560, 540, 135, 34560, 135, 34560, 540, 540, 540, 540, 540, 135, 135, 34560, 135, 34560, 135, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 135, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 135, 135, 135, 135, 135, 540, 135, 135, 540, 34560, 34560, 135, 135, 34560, 135, 135, 135, 540, 135, 540, 34560, 34560, 540, 540, 135, 34560, 540, 34560, 135, 540, 540, 135, 135, 540, 135, 34560, 34560, 135, 34560, 34560, 135, 540, 34560, 135, 135, 540, 540, 135, 135, 34560, 34560, 34560, 34560, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 34560, 540, 540, 540, 34560, 135, 540, 540, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 540, 135, 34560, 34560, 34560, 540, 135, 34560, 34560, 540, 540, 34560, 34560, 135, 34560, 34560, 540, 135, 34560, 540, 540, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 540, 34560, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 34560, 135, 135, 135, 540, 135, 540, 540, 135, 34560, 540, 34560, 135, 34560, 135, 540, 540, 540, 540, 135, 540, 34560, 34560, 135, 34560, 34560, 135, 34560, 540, 34560, 540, 540, 540, 135, 540, 135, 135, 34560, 135, 540, 135, 135, 540, 34560, 540, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4510080 . Total input tokens: 1004889616 . Total output tokens: 901721610
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 71.664437266998,
    "estimated_duration": 3600.0591688467034,
    "input_throughput": 6144.281513874723,
    "output_throughput": 5466.321545571788,
    "total_throughput": 11610.603059446512,
    "itl": 153.63441179181424,
    "ttft": 2094617.8418365675,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 519,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7393217244371746,
    "arrivals": 1502157,
    "finished_requests": 89597,
    "scheduler_time": 175.68420389027926
}
#Debug simulation 
Total elapsed time: 71.66455252189189. Arrivals time: 0.5202762824483216 Scheduler time: 71.00109867425635 Scheduler overhead time: 0.05541725875809789 Adapter cache time: 0.015951546374708414 Engine time: 0.05134840728715062 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-8/adapters_384_slots_64_rate_3.2-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-8/adapters_384_slots_64_rate_3.2-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 540, 66, 34560, 34560, 66, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 66, 34560, 66, 34560, 540, 540, 540, 66, 66, 540, 66, 34560, 66, 34560, 540, 34560, 540, 66, 540, 34560, 540, 34560, 66, 34560, 34560, 34560, 34560, 66, 540, 540, 540, 34560, 540, 66, 540, 66, 34560, 540, 34560, 34560, 540, 34560, 34560, 66, 66, 34560, 540, 540, 66, 66, 66, 540, 66, 540, 66, 34560, 66, 540, 34560, 66, 34560, 540, 66, 34560, 34560, 34560, 34560, 540, 66, 540, 34560, 34560, 540, 66, 66, 34560, 540, 540, 66, 66, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 66, 540, 540, 540, 540, 66, 66, 34560, 66, 34560, 66, 66, 66, 540, 540, 34560, 66, 66, 34560, 66, 34560, 540, 66, 34560, 540, 540, 66, 34560, 34560, 34560, 66, 540, 34560, 66, 34560, 540, 540, 34560, 34560, 66, 540, 34560, 66, 540, 540, 66, 540, 66, 540, 34560, 34560, 540, 66, 34560, 66, 34560, 540, 540, 540, 540, 540, 66, 66, 34560, 66, 34560, 66, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 66, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 66, 66, 66, 66, 66, 540, 66, 66, 540, 34560, 34560, 66, 66, 34560, 66, 66, 66, 540, 66, 540, 34560, 34560, 540, 540, 66, 34560, 540, 34560, 66, 540, 540, 66, 66, 540, 66, 34560, 34560, 66, 34560, 34560, 66, 540, 34560, 66, 66, 540, 540, 66, 66, 34560, 34560, 34560, 34560, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 34560, 540, 540, 540, 34560, 66, 540, 540, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 540, 66, 34560, 34560, 34560, 540, 66, 34560, 34560, 540, 540, 34560, 34560, 66, 34560, 34560, 540, 66, 34560, 540, 540, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 540, 34560, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 34560, 66, 66, 66, 540, 66, 540, 540, 66, 34560, 540, 34560, 66, 34560, 66, 540, 540, 540, 540, 66, 540, 34560, 34560, 66, 34560, 34560, 66, 34560, 540, 34560, 540, 540, 540, 66, 540, 66, 66, 34560, 66, 540, 66, 66, 540, 34560, 540, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4501248 . Total input tokens: 1002929360 . Total output tokens: 899961256
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 71.95509572606534,
    "estimated_duration": 3600.1259451344754,
    "input_throughput": 6134.481219982726,
    "output_throughput": 5454.924438557787,
    "total_throughput": 11589.405658540512,
    "itl": 153.77203958272904,
    "ttft": 2092580.3537703955,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 438,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3404936318425567,
    "arrivals": 1499241,
    "finished_requests": 89481,
    "scheduler_time": 176.3921448917406
}
#Debug simulation 
Total elapsed time: 71.95521648880094. Arrivals time: 0.41587053425610065 Scheduler time: 71.39663532050326 Scheduler overhead time: 0.055995178408920765 Adapter cache time: 0.014782942365854979 Engine time: 0.05126021662726998 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-16/adapters_384_slots_64_rate_3.2-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-16/adapters_384_slots_64_rate_3.2-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 540, 66, 34560, 34560, 66, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 66, 34560, 66, 34560, 540, 540, 540, 66, 66, 540, 66, 34560, 66, 34560, 540, 34560, 540, 66, 540, 34560, 540, 34560, 66, 34560, 34560, 34560, 34560, 66, 540, 540, 540, 34560, 540, 66, 540, 66, 34560, 540, 34560, 34560, 540, 34560, 34560, 66, 66, 34560, 540, 540, 66, 66, 66, 540, 66, 540, 66, 34560, 66, 540, 34560, 66, 34560, 540, 66, 34560, 34560, 34560, 34560, 540, 66, 540, 34560, 34560, 540, 66, 66, 34560, 540, 540, 66, 66, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 66, 540, 540, 540, 540, 66, 66, 34560, 66, 34560, 66, 66, 66, 540, 540, 34560, 66, 66, 34560, 66, 34560, 540, 66, 34560, 540, 540, 66, 34560, 34560, 34560, 66, 540, 34560, 66, 34560, 540, 540, 34560, 34560, 66, 540, 34560, 66, 540, 540, 66, 540, 66, 540, 34560, 34560, 540, 66, 34560, 66, 34560, 540, 540, 540, 540, 540, 66, 66, 34560, 66, 34560, 66, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 66, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 66, 66, 66, 66, 66, 540, 66, 66, 540, 34560, 34560, 66, 66, 34560, 66, 66, 66, 540, 66, 540, 34560, 34560, 540, 540, 66, 34560, 540, 34560, 66, 540, 540, 66, 66, 540, 66, 34560, 34560, 66, 34560, 34560, 66, 540, 34560, 66, 66, 540, 540, 66, 66, 34560, 34560, 34560, 34560, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 34560, 540, 540, 540, 34560, 66, 540, 540, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 540, 66, 34560, 34560, 34560, 540, 66, 34560, 34560, 540, 540, 34560, 34560, 66, 34560, 34560, 540, 66, 34560, 540, 540, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 540, 34560, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 34560, 66, 66, 66, 540, 66, 540, 540, 66, 34560, 540, 34560, 66, 34560, 66, 540, 540, 540, 540, 66, 540, 34560, 34560, 66, 34560, 34560, 66, 34560, 540, 34560, 540, 540, 540, 66, 540, 66, 66, 34560, 66, 540, 66, 66, 540, 34560, 540, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4501248 . Total input tokens: 1002929360 . Total output tokens: 899961256
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 72.49512262782082,
    "estimated_duration": 3600.0362186548127,
    "input_throughput": 6135.5788271078845,
    "output_throughput": 5454.319847742277,
    "total_throughput": 11589.898674850161,
    "itl": 153.91064736365192,
    "ttft": 2093180.081912993,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 454,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4816958106914595,
    "arrivals": 1499241,
    "finished_requests": 89444,
    "scheduler_time": 176.40354140805854
}
#Debug simulation 
Total elapsed time: 72.49523395393044. Arrivals time: 0.4266906171105802 Scheduler time: 71.92577366158366 Scheduler overhead time: 0.055535332299768925 Adapter cache time: 0.014828910119831562 Engine time: 0.05169465020298958 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-32/adapters_384_slots_64_rate_3.2-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-32/adapters_384_slots_64_rate_3.2-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 540, 66, 34560, 34560, 66, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 66, 34560, 66, 34560, 540, 540, 540, 66, 66, 540, 66, 34560, 66, 34560, 540, 34560, 540, 66, 540, 34560, 540, 34560, 66, 34560, 34560, 34560, 34560, 66, 540, 540, 540, 34560, 540, 66, 540, 66, 34560, 540, 34560, 34560, 540, 34560, 34560, 66, 66, 34560, 540, 540, 66, 66, 66, 540, 66, 540, 66, 34560, 66, 540, 34560, 66, 34560, 540, 66, 34560, 34560, 34560, 34560, 540, 66, 540, 34560, 34560, 540, 66, 66, 34560, 540, 540, 66, 66, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 66, 540, 540, 540, 540, 66, 66, 34560, 66, 34560, 66, 66, 66, 540, 540, 34560, 66, 66, 34560, 66, 34560, 540, 66, 34560, 540, 540, 66, 34560, 34560, 34560, 66, 540, 34560, 66, 34560, 540, 540, 34560, 34560, 66, 540, 34560, 66, 540, 540, 66, 540, 66, 540, 34560, 34560, 540, 66, 34560, 66, 34560, 540, 540, 540, 540, 540, 66, 66, 34560, 66, 34560, 66, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 66, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 66, 66, 66, 66, 66, 540, 66, 66, 540, 34560, 34560, 66, 66, 34560, 66, 66, 66, 540, 66, 540, 34560, 34560, 540, 540, 66, 34560, 540, 34560, 66, 540, 540, 66, 66, 540, 66, 34560, 34560, 66, 34560, 34560, 66, 540, 34560, 66, 66, 540, 540, 66, 66, 34560, 34560, 34560, 34560, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 34560, 540, 540, 540, 34560, 66, 540, 540, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 540, 66, 34560, 34560, 34560, 540, 66, 34560, 34560, 540, 540, 34560, 34560, 66, 34560, 34560, 540, 66, 34560, 540, 540, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 540, 34560, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 34560, 66, 66, 66, 540, 66, 540, 540, 66, 34560, 540, 34560, 66, 34560, 66, 540, 540, 540, 540, 66, 540, 34560, 34560, 66, 34560, 34560, 66, 34560, 540, 34560, 540, 540, 540, 66, 540, 66, 66, 34560, 66, 540, 66, 66, 540, 34560, 540, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4501248 . Total input tokens: 1002929360 . Total output tokens: 899961256
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 72.41808042209595,
    "estimated_duration": 3600.038817695103,
    "input_throughput": 6135.574397539932,
    "output_throughput": 5454.315910007781,
    "total_throughput": 11589.890307547714,
    "itl": 153.91070060096152,
    "ttft": 2093180.8973175033,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 454,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4842807956785051,
    "arrivals": 1499241,
    "finished_requests": 89444,
    "scheduler_time": 176.40355546332952
}
#Debug simulation 
Total elapsed time: 72.41819608910009. Arrivals time: 0.4154011602513492 Scheduler time: 71.86062688799575 Scheduler overhead time: 0.055598544888198376 Adapter cache time: 0.015056203119456768 Engine time: 0.0509708896279335 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-16/adapters_384_slots_64_rate_3.2-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-16/adapters_384_slots_64_rate_3.2-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 540, 66, 34560, 34560, 66, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 66, 34560, 66, 34560, 540, 540, 540, 66, 66, 540, 66, 34560, 66, 34560, 540, 34560, 540, 66, 540, 34560, 540, 34560, 66, 34560, 34560, 34560, 34560, 66, 540, 540, 540, 34560, 540, 66, 540, 66, 34560, 540, 34560, 34560, 540, 34560, 34560, 66, 66, 34560, 540, 540, 66, 66, 66, 540, 66, 540, 66, 34560, 66, 540, 34560, 66, 34560, 540, 66, 34560, 34560, 34560, 34560, 540, 66, 540, 34560, 34560, 540, 66, 66, 34560, 540, 540, 66, 66, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 66, 540, 540, 540, 540, 66, 66, 34560, 66, 34560, 66, 66, 66, 540, 540, 34560, 66, 66, 34560, 66, 34560, 540, 66, 34560, 540, 540, 66, 34560, 34560, 34560, 66, 540, 34560, 66, 34560, 540, 540, 34560, 34560, 66, 540, 34560, 66, 540, 540, 66, 540, 66, 540, 34560, 34560, 540, 66, 34560, 66, 34560, 540, 540, 540, 540, 540, 66, 66, 34560, 66, 34560, 66, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 66, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 66, 66, 66, 66, 66, 540, 66, 66, 540, 34560, 34560, 66, 66, 34560, 66, 66, 66, 540, 66, 540, 34560, 34560, 540, 540, 66, 34560, 540, 34560, 66, 540, 540, 66, 66, 540, 66, 34560, 34560, 66, 34560, 34560, 66, 540, 34560, 66, 66, 540, 540, 66, 66, 34560, 34560, 34560, 34560, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 34560, 540, 540, 540, 34560, 66, 540, 540, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 540, 66, 34560, 34560, 34560, 540, 66, 34560, 34560, 540, 540, 34560, 34560, 66, 34560, 34560, 540, 66, 34560, 540, 540, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 540, 34560, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 34560, 66, 66, 66, 540, 66, 540, 540, 66, 34560, 540, 34560, 66, 34560, 66, 540, 540, 540, 540, 66, 540, 34560, 34560, 66, 34560, 34560, 66, 34560, 540, 34560, 540, 540, 540, 66, 540, 66, 66, 34560, 66, 540, 66, 66, 540, 34560, 540, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4501248 . Total input tokens: 1002929360 . Total output tokens: 899961256
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 72.05509423511103,
    "estimated_duration": 3600.157821269994,
    "input_throughput": 6134.426904709781,
    "output_throughput": 5454.876140144417,
    "total_throughput": 11589.303044854198,
    "itl": 153.77293679212744,
    "ttft": 2092592.0241409794,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 438,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.372157112888524,
    "arrivals": 1499241,
    "finished_requests": 89481,
    "scheduler_time": 176.39235754616524
}
#Debug simulation 
Total elapsed time: 72.05521417595446. Arrivals time: 0.42425467260181904 Scheduler time: 71.48830459453166 Scheduler overhead time: 0.05563011020421982 Adapter cache time: 0.014934815000742674 Engine time: 0.0516267865896225 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-32/adapters_384_slots_64_rate_3.2-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-32/adapters_384_slots_64_rate_3.2-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 540, 66, 34560, 34560, 66, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 66, 34560, 66, 34560, 540, 540, 540, 66, 66, 540, 66, 34560, 66, 34560, 540, 34560, 540, 66, 540, 34560, 540, 34560, 66, 34560, 34560, 34560, 34560, 66, 540, 540, 540, 34560, 540, 66, 540, 66, 34560, 540, 34560, 34560, 540, 34560, 34560, 66, 66, 34560, 540, 540, 66, 66, 66, 540, 66, 540, 66, 34560, 66, 540, 34560, 66, 34560, 540, 66, 34560, 34560, 34560, 34560, 540, 66, 540, 34560, 34560, 540, 66, 66, 34560, 540, 540, 66, 66, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 66, 540, 540, 540, 540, 66, 66, 34560, 66, 34560, 66, 66, 66, 540, 540, 34560, 66, 66, 34560, 66, 34560, 540, 66, 34560, 540, 540, 66, 34560, 34560, 34560, 66, 540, 34560, 66, 34560, 540, 540, 34560, 34560, 66, 540, 34560, 66, 540, 540, 66, 540, 66, 540, 34560, 34560, 540, 66, 34560, 66, 34560, 540, 540, 540, 540, 540, 66, 66, 34560, 66, 34560, 66, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 66, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 66, 66, 66, 66, 66, 540, 66, 66, 540, 34560, 34560, 66, 66, 34560, 66, 66, 66, 540, 66, 540, 34560, 34560, 540, 540, 66, 34560, 540, 34560, 66, 540, 540, 66, 66, 540, 66, 34560, 34560, 66, 34560, 34560, 66, 540, 34560, 66, 66, 540, 540, 66, 66, 34560, 34560, 34560, 34560, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 34560, 540, 540, 540, 34560, 66, 540, 540, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 540, 66, 34560, 34560, 34560, 540, 66, 34560, 34560, 540, 540, 34560, 34560, 66, 34560, 34560, 540, 66, 34560, 540, 540, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 540, 34560, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 34560, 66, 66, 66, 540, 66, 540, 540, 66, 34560, 540, 34560, 66, 34560, 66, 540, 540, 540, 540, 66, 540, 34560, 34560, 66, 34560, 34560, 66, 34560, 540, 34560, 540, 540, 540, 66, 540, 66, 66, 34560, 66, 540, 66, 66, 540, 34560, 540, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4501248 . Total input tokens: 1002929360 . Total output tokens: 899961256
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 72.44981831498444,
    "estimated_duration": 3600.057020611422,
    "input_throughput": 6135.543374323719,
    "output_throughput": 5454.288331429019,
    "total_throughput": 11589.831705752738,
    "itl": 153.91123498883343,
    "ttft": 2093186.819834124,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 454,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.502389340922241,
    "arrivals": 1499241,
    "finished_requests": 89444,
    "scheduler_time": 176.4036498344347
}
#Debug simulation 
Total elapsed time: 72.44993430702016. Arrivals time: 0.4102543434128165 Scheduler time: 71.89761369070038 Scheduler overhead time: 0.05545617686584592 Adapter cache time: 0.014765467029064894 Engine time: 0.05099159758538008 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-16/adapters_384_slots_64_rate_3.2-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-16/adapters_384_slots_64_rate_3.2-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 540, 66, 34560, 34560, 66, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 66, 34560, 66, 34560, 540, 540, 540, 66, 66, 540, 66, 34560, 66, 34560, 540, 34560, 540, 66, 540, 34560, 540, 34560, 66, 34560, 34560, 34560, 34560, 66, 540, 540, 540, 34560, 540, 66, 540, 66, 34560, 540, 34560, 34560, 540, 34560, 34560, 66, 66, 34560, 540, 540, 66, 66, 66, 540, 66, 540, 66, 34560, 66, 540, 34560, 66, 34560, 540, 66, 34560, 34560, 34560, 34560, 540, 66, 540, 34560, 34560, 540, 66, 66, 34560, 540, 540, 66, 66, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 66, 540, 540, 540, 540, 66, 66, 34560, 66, 34560, 66, 66, 66, 540, 540, 34560, 66, 66, 34560, 66, 34560, 540, 66, 34560, 540, 540, 66, 34560, 34560, 34560, 66, 540, 34560, 66, 34560, 540, 540, 34560, 34560, 66, 540, 34560, 66, 540, 540, 66, 540, 66, 540, 34560, 34560, 540, 66, 34560, 66, 34560, 540, 540, 540, 540, 540, 66, 66, 34560, 66, 34560, 66, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 66, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 66, 66, 66, 66, 66, 540, 66, 66, 540, 34560, 34560, 66, 66, 34560, 66, 66, 66, 540, 66, 540, 34560, 34560, 540, 540, 66, 34560, 540, 34560, 66, 540, 540, 66, 66, 540, 66, 34560, 34560, 66, 34560, 34560, 66, 540, 34560, 66, 66, 540, 540, 66, 66, 34560, 34560, 34560, 34560, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 34560, 540, 540, 540, 34560, 66, 540, 540, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 540, 66, 34560, 34560, 34560, 540, 66, 34560, 34560, 540, 540, 34560, 34560, 66, 34560, 34560, 540, 66, 34560, 540, 540, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 540, 34560, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 34560, 66, 66, 66, 540, 66, 540, 540, 66, 34560, 540, 34560, 66, 34560, 66, 540, 540, 540, 540, 66, 540, 34560, 34560, 66, 34560, 34560, 66, 34560, 540, 34560, 540, 540, 540, 66, 540, 66, 66, 34560, 66, 540, 66, 66, 540, 34560, 540, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4501248 . Total input tokens: 1002929360 . Total output tokens: 899961256
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 72.18112590303645,
    "estimated_duration": 3600.094904607119,
    "input_throughput": 6134.53411234728,
    "output_throughput": 5454.971471687676,
    "total_throughput": 11589.505584034956,
    "itl": 153.7711604089814,
    "ttft": 2092569.4323465773,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 438,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3096420291671433,
    "arrivals": 1499241,
    "finished_requests": 89481,
    "scheduler_time": 176.3919559669942
}
#Debug simulation 
Total elapsed time: 72.1812465917319. Arrivals time: 0.41799988597631454 Scheduler time: 71.6200713715516 Scheduler overhead time: 0.055838458240032196 Adapter cache time: 0.015022006817162037 Engine time: 0.05129025550559163 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-32/adapters_384_slots_64_rate_3.2-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-32/adapters_384_slots_64_rate_3.2-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 540, 66, 34560, 34560, 66, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 66, 34560, 66, 34560, 540, 540, 540, 66, 66, 540, 66, 34560, 66, 34560, 540, 34560, 540, 66, 540, 34560, 540, 34560, 66, 34560, 34560, 34560, 34560, 66, 540, 540, 540, 34560, 540, 66, 540, 66, 34560, 540, 34560, 34560, 540, 34560, 34560, 66, 66, 34560, 540, 540, 66, 66, 66, 540, 66, 540, 66, 34560, 66, 540, 34560, 66, 34560, 540, 66, 34560, 34560, 34560, 34560, 540, 66, 540, 34560, 34560, 540, 66, 66, 34560, 540, 540, 66, 66, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 66, 540, 540, 540, 540, 66, 66, 34560, 66, 34560, 66, 66, 66, 540, 540, 34560, 66, 66, 34560, 66, 34560, 540, 66, 34560, 540, 540, 66, 34560, 34560, 34560, 66, 540, 34560, 66, 34560, 540, 540, 34560, 34560, 66, 540, 34560, 66, 540, 540, 66, 540, 66, 540, 34560, 34560, 540, 66, 34560, 66, 34560, 540, 540, 540, 540, 540, 66, 66, 34560, 66, 34560, 66, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 66, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 66, 66, 66, 66, 66, 540, 66, 66, 540, 34560, 34560, 66, 66, 34560, 66, 66, 66, 540, 66, 540, 34560, 34560, 540, 540, 66, 34560, 540, 34560, 66, 540, 540, 66, 66, 540, 66, 34560, 34560, 66, 34560, 34560, 66, 540, 34560, 66, 66, 540, 540, 66, 66, 34560, 34560, 34560, 34560, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 34560, 540, 540, 540, 34560, 66, 540, 540, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 540, 66, 34560, 34560, 34560, 540, 66, 34560, 34560, 540, 540, 34560, 34560, 66, 34560, 34560, 540, 66, 34560, 540, 540, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 540, 34560, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 34560, 66, 66, 66, 540, 66, 540, 540, 66, 34560, 540, 34560, 66, 34560, 66, 540, 540, 540, 540, 66, 540, 34560, 34560, 66, 34560, 34560, 66, 34560, 540, 34560, 540, 540, 540, 66, 540, 66, 66, 34560, 66, 540, 66, 66, 540, 34560, 540, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4501248 . Total input tokens: 1002929360 . Total output tokens: 899961256
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 72.27421812526882,
    "estimated_duration": 3600.077260960826,
    "input_throughput": 6135.508879080235,
    "output_throughput": 5454.257666336696,
    "total_throughput": 11589.766545416931,
    "itl": 153.91183803873074,
    "ttft": 2093193.6334215137,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 454,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.522509946748614,
    "arrivals": 1499241,
    "finished_requests": 89444,
    "scheduler_time": 176.40376957804207
}
#Debug simulation 
Total elapsed time: 72.27433282416314. Arrivals time: 0.40704586962237954 Scheduler time: 71.72361127845943 Scheduler overhead time: 0.05633188923820853 Adapter cache time: 0.014826047699898481 Engine time: 0.05164470011368394 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-8/adapters_384_slots_64_rate_3.2-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-8/adapters_384_slots_64_rate_3.2-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 540, 33, 34560, 34560, 33, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 33, 34560, 33, 34560, 540, 540, 540, 33, 33, 540, 33, 34560, 33, 34560, 540, 34560, 540, 33, 540, 34560, 540, 34560, 33, 34560, 34560, 34560, 34560, 33, 540, 540, 540, 34560, 540, 33, 540, 33, 34560, 540, 34560, 34560, 540, 34560, 34560, 33, 33, 34560, 540, 540, 33, 33, 33, 540, 33, 540, 33, 34560, 33, 540, 34560, 33, 34560, 540, 33, 34560, 34560, 34560, 34560, 540, 33, 540, 34560, 34560, 540, 33, 33, 34560, 540, 540, 33, 33, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 33, 540, 540, 540, 540, 33, 33, 34560, 33, 34560, 33, 33, 33, 540, 540, 34560, 33, 33, 34560, 33, 34560, 540, 33, 34560, 540, 540, 33, 34560, 34560, 34560, 33, 540, 34560, 33, 34560, 540, 540, 34560, 34560, 33, 540, 34560, 33, 540, 540, 33, 540, 33, 540, 34560, 34560, 540, 33, 34560, 33, 34560, 540, 540, 540, 540, 540, 33, 33, 34560, 33, 34560, 33, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 33, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 33, 33, 33, 33, 33, 540, 33, 33, 540, 34560, 34560, 33, 33, 34560, 33, 33, 33, 540, 33, 540, 34560, 34560, 540, 540, 33, 34560, 540, 34560, 33, 540, 540, 33, 33, 540, 33, 34560, 34560, 33, 34560, 34560, 33, 540, 34560, 33, 33, 540, 540, 33, 33, 34560, 34560, 34560, 34560, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 34560, 540, 540, 540, 34560, 33, 540, 540, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 540, 33, 34560, 34560, 34560, 540, 33, 34560, 34560, 540, 540, 34560, 34560, 33, 34560, 34560, 540, 33, 34560, 540, 540, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 540, 34560, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 34560, 33, 33, 33, 540, 33, 540, 540, 33, 34560, 540, 34560, 33, 34560, 33, 540, 540, 540, 540, 33, 540, 34560, 34560, 33, 34560, 34560, 33, 34560, 540, 34560, 540, 540, 540, 33, 540, 33, 33, 34560, 33, 540, 33, 33, 540, 34560, 540, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4497024 . Total input tokens: 1001990086 . Total output tokens: 899106028
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 72.8143065776676,
    "estimated_duration": 3600.0210761733697,
    "input_throughput": 6153.025088271248,
    "output_throughput": 5470.067697751349,
    "total_throughput": 11623.092786022597,
    "itl": 154.26070276658012,
    "ttft": 2093817.3941669788,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 444,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3588565583061538,
    "arrivals": 1497804,
    "finished_requests": 89608,
    "scheduler_time": 175.6193236482047
}
#Debug simulation 
Total elapsed time: 72.81442069867626. Arrivals time: 0.43071938399225473 Scheduler time: 72.24130279757082 Scheduler overhead time: 0.055262107867747545 Adapter cache time: 0.014774422161281109 Engine time: 0.05148910079151392 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-16/adapters_384_slots_64_rate_3.2-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-16/adapters_384_slots_64_rate_3.2-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 540, 33, 34560, 34560, 33, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 33, 34560, 33, 34560, 540, 540, 540, 33, 33, 540, 33, 34560, 33, 34560, 540, 34560, 540, 33, 540, 34560, 540, 34560, 33, 34560, 34560, 34560, 34560, 33, 540, 540, 540, 34560, 540, 33, 540, 33, 34560, 540, 34560, 34560, 540, 34560, 34560, 33, 33, 34560, 540, 540, 33, 33, 33, 540, 33, 540, 33, 34560, 33, 540, 34560, 33, 34560, 540, 33, 34560, 34560, 34560, 34560, 540, 33, 540, 34560, 34560, 540, 33, 33, 34560, 540, 540, 33, 33, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 33, 540, 540, 540, 540, 33, 33, 34560, 33, 34560, 33, 33, 33, 540, 540, 34560, 33, 33, 34560, 33, 34560, 540, 33, 34560, 540, 540, 33, 34560, 34560, 34560, 33, 540, 34560, 33, 34560, 540, 540, 34560, 34560, 33, 540, 34560, 33, 540, 540, 33, 540, 33, 540, 34560, 34560, 540, 33, 34560, 33, 34560, 540, 540, 540, 540, 540, 33, 33, 34560, 33, 34560, 33, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 33, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 33, 33, 33, 33, 33, 540, 33, 33, 540, 34560, 34560, 33, 33, 34560, 33, 33, 33, 540, 33, 540, 34560, 34560, 540, 540, 33, 34560, 540, 34560, 33, 540, 540, 33, 33, 540, 33, 34560, 34560, 33, 34560, 34560, 33, 540, 34560, 33, 33, 540, 540, 33, 33, 34560, 34560, 34560, 34560, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 34560, 540, 540, 540, 34560, 33, 540, 540, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 540, 33, 34560, 34560, 34560, 540, 33, 34560, 34560, 540, 540, 34560, 34560, 33, 34560, 34560, 540, 33, 34560, 540, 540, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 540, 34560, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 34560, 33, 33, 33, 540, 33, 540, 540, 33, 34560, 540, 34560, 33, 34560, 33, 540, 540, 540, 540, 33, 540, 34560, 34560, 33, 34560, 34560, 33, 34560, 540, 34560, 540, 540, 540, 33, 540, 33, 33, 34560, 33, 540, 33, 33, 540, 34560, 540, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4497024 . Total input tokens: 1001990086 . Total output tokens: 899106028
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 73.79104402521625,
    "estimated_duration": 3600.0264288758726,
    "input_throughput": 6162.9550333406705,
    "output_throughput": 5472.219548719111,
    "total_throughput": 11635.174582059783,
    "itl": 154.2393598677708,
    "ttft": 2094686.144038767,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 451,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.47068268321455,
    "arrivals": 1497804,
    "finished_requests": 89723,
    "scheduler_time": 175.37681631941615
}
#Debug simulation 
Total elapsed time: 73.79115838417783. Arrivals time: 0.42383156809955835 Scheduler time: 73.22459611110389 Scheduler overhead time: 0.05583555158227682 Adapter cache time: 0.014810075983405113 Engine time: 0.051248982548713684 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-32/adapters_384_slots_64_rate_3.2-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-32/adapters_384_slots_64_rate_3.2-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 540, 33, 34560, 34560, 33, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 33, 34560, 33, 34560, 540, 540, 540, 33, 33, 540, 33, 34560, 33, 34560, 540, 34560, 540, 33, 540, 34560, 540, 34560, 33, 34560, 34560, 34560, 34560, 33, 540, 540, 540, 34560, 540, 33, 540, 33, 34560, 540, 34560, 34560, 540, 34560, 34560, 33, 33, 34560, 540, 540, 33, 33, 33, 540, 33, 540, 33, 34560, 33, 540, 34560, 33, 34560, 540, 33, 34560, 34560, 34560, 34560, 540, 33, 540, 34560, 34560, 540, 33, 33, 34560, 540, 540, 33, 33, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 33, 540, 540, 540, 540, 33, 33, 34560, 33, 34560, 33, 33, 33, 540, 540, 34560, 33, 33, 34560, 33, 34560, 540, 33, 34560, 540, 540, 33, 34560, 34560, 34560, 33, 540, 34560, 33, 34560, 540, 540, 34560, 34560, 33, 540, 34560, 33, 540, 540, 33, 540, 33, 540, 34560, 34560, 540, 33, 34560, 33, 34560, 540, 540, 540, 540, 540, 33, 33, 34560, 33, 34560, 33, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 33, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 33, 33, 33, 33, 33, 540, 33, 33, 540, 34560, 34560, 33, 33, 34560, 33, 33, 33, 540, 33, 540, 34560, 34560, 540, 540, 33, 34560, 540, 34560, 33, 540, 540, 33, 33, 540, 33, 34560, 34560, 33, 34560, 34560, 33, 540, 34560, 33, 33, 540, 540, 33, 33, 34560, 34560, 34560, 34560, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 34560, 540, 540, 540, 34560, 33, 540, 540, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 540, 33, 34560, 34560, 34560, 540, 33, 34560, 34560, 540, 540, 34560, 34560, 33, 34560, 34560, 540, 33, 34560, 540, 540, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 540, 34560, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 34560, 33, 33, 33, 540, 33, 540, 540, 33, 34560, 540, 34560, 33, 34560, 33, 540, 540, 540, 540, 33, 540, 34560, 34560, 33, 34560, 34560, 33, 34560, 540, 34560, 540, 540, 540, 33, 540, 33, 33, 34560, 33, 540, 33, 33, 540, 34560, 540, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4497024 . Total input tokens: 1001990086 . Total output tokens: 899106028
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 73.8358118319884,
    "estimated_duration": 3600.0292288130117,
    "input_throughput": 6162.950240077731,
    "output_throughput": 5472.215292678458,
    "total_throughput": 11635.16553275619,
    "itl": 154.2394622291283,
    "ttft": 2094687.0990390836,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 451,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4734640016593126,
    "arrivals": 1497804,
    "finished_requests": 89723,
    "scheduler_time": 175.3768349380868
}
#Debug simulation 
Total elapsed time: 73.83592550083995. Arrivals time: 0.527312548365444 Scheduler time: 73.16607392719015 Scheduler overhead time: 0.055484505370259285 Adapter cache time: 0.015021959785372019 Engine time: 0.05111349048092961 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-16/adapters_384_slots_64_rate_3.2-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-16/adapters_384_slots_64_rate_3.2-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 540, 33, 34560, 34560, 33, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 33, 34560, 33, 34560, 540, 540, 540, 33, 33, 540, 33, 34560, 33, 34560, 540, 34560, 540, 33, 540, 34560, 540, 34560, 33, 34560, 34560, 34560, 34560, 33, 540, 540, 540, 34560, 540, 33, 540, 33, 34560, 540, 34560, 34560, 540, 34560, 34560, 33, 33, 34560, 540, 540, 33, 33, 33, 540, 33, 540, 33, 34560, 33, 540, 34560, 33, 34560, 540, 33, 34560, 34560, 34560, 34560, 540, 33, 540, 34560, 34560, 540, 33, 33, 34560, 540, 540, 33, 33, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 33, 540, 540, 540, 540, 33, 33, 34560, 33, 34560, 33, 33, 33, 540, 540, 34560, 33, 33, 34560, 33, 34560, 540, 33, 34560, 540, 540, 33, 34560, 34560, 34560, 33, 540, 34560, 33, 34560, 540, 540, 34560, 34560, 33, 540, 34560, 33, 540, 540, 33, 540, 33, 540, 34560, 34560, 540, 33, 34560, 33, 34560, 540, 540, 540, 540, 540, 33, 33, 34560, 33, 34560, 33, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 33, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 33, 33, 33, 33, 33, 540, 33, 33, 540, 34560, 34560, 33, 33, 34560, 33, 33, 33, 540, 33, 540, 34560, 34560, 540, 540, 33, 34560, 540, 34560, 33, 540, 540, 33, 33, 540, 33, 34560, 34560, 33, 34560, 34560, 33, 540, 34560, 33, 33, 540, 540, 33, 33, 34560, 34560, 34560, 34560, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 34560, 540, 540, 540, 34560, 33, 540, 540, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 540, 33, 34560, 34560, 34560, 540, 33, 34560, 34560, 540, 540, 34560, 34560, 33, 34560, 34560, 540, 33, 34560, 540, 540, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 540, 34560, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 34560, 33, 33, 33, 540, 33, 540, 540, 33, 34560, 540, 34560, 33, 34560, 33, 540, 540, 540, 540, 33, 540, 34560, 34560, 33, 34560, 34560, 33, 34560, 540, 34560, 540, 540, 540, 33, 540, 33, 33, 34560, 33, 540, 33, 33, 540, 34560, 540, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4497024 . Total input tokens: 1001990086 . Total output tokens: 899106028
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 73.60563865303993,
    "estimated_duration": 3600.058588886589,
    "input_throughput": 6158.940042933421,
    "output_throughput": 5470.330138735527,
    "total_throughput": 11629.270181668948,
    "itl": 154.06257143481054,
    "ttft": 2094319.2251080768,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 442,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3828915281128105,
    "arrivals": 1497804,
    "finished_requests": 89689,
    "scheduler_time": 175.459868914992
}
#Debug simulation 
Total elapsed time: 73.60575324995443. Arrivals time: 0.4095486612059176 Scheduler time: 73.05465286551043 Scheduler overhead time: 0.055412606336176395 Adapter cache time: 0.01467999117448926 Engine time: 0.05089360289275646 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-32/adapters_384_slots_64_rate_3.2-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-32/adapters_384_slots_64_rate_3.2-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 540, 33, 34560, 34560, 33, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 33, 34560, 33, 34560, 540, 540, 540, 33, 33, 540, 33, 34560, 33, 34560, 540, 34560, 540, 33, 540, 34560, 540, 34560, 33, 34560, 34560, 34560, 34560, 33, 540, 540, 540, 34560, 540, 33, 540, 33, 34560, 540, 34560, 34560, 540, 34560, 34560, 33, 33, 34560, 540, 540, 33, 33, 33, 540, 33, 540, 33, 34560, 33, 540, 34560, 33, 34560, 540, 33, 34560, 34560, 34560, 34560, 540, 33, 540, 34560, 34560, 540, 33, 33, 34560, 540, 540, 33, 33, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 33, 540, 540, 540, 540, 33, 33, 34560, 33, 34560, 33, 33, 33, 540, 540, 34560, 33, 33, 34560, 33, 34560, 540, 33, 34560, 540, 540, 33, 34560, 34560, 34560, 33, 540, 34560, 33, 34560, 540, 540, 34560, 34560, 33, 540, 34560, 33, 540, 540, 33, 540, 33, 540, 34560, 34560, 540, 33, 34560, 33, 34560, 540, 540, 540, 540, 540, 33, 33, 34560, 33, 34560, 33, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 33, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 33, 33, 33, 33, 33, 540, 33, 33, 540, 34560, 34560, 33, 33, 34560, 33, 33, 33, 540, 33, 540, 34560, 34560, 540, 540, 33, 34560, 540, 34560, 33, 540, 540, 33, 33, 540, 33, 34560, 34560, 33, 34560, 34560, 33, 540, 34560, 33, 33, 540, 540, 33, 33, 34560, 34560, 34560, 34560, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 34560, 540, 540, 540, 34560, 33, 540, 540, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 540, 33, 34560, 34560, 34560, 540, 33, 34560, 34560, 540, 540, 34560, 34560, 33, 34560, 34560, 540, 33, 34560, 540, 540, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 540, 34560, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 34560, 33, 33, 33, 540, 33, 540, 540, 33, 34560, 540, 34560, 33, 34560, 33, 540, 540, 540, 540, 33, 540, 34560, 34560, 33, 34560, 34560, 33, 34560, 540, 34560, 540, 540, 540, 33, 540, 33, 33, 34560, 33, 540, 33, 33, 540, 34560, 540, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4497024 . Total input tokens: 1001990086 . Total output tokens: 899106028
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 73.8642015941441,
    "estimated_duration": 3600.0477135378846,
    "input_throughput": 6162.918595930581,
    "output_throughput": 5472.187195163598,
    "total_throughput": 11635.10579109418,
    "itl": 154.2400317464259,
    "ttft": 2094693.7007959774,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 451,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4918240544758785,
    "arrivals": 1497804,
    "finished_requests": 89723,
    "scheduler_time": 175.3769596101658
}
#Debug simulation 
Total elapsed time: 73.86431458126754. Arrivals time: 0.41584424721077085 Scheduler time: 73.30560425017029 Scheduler overhead time: 0.05563278403133154 Adapter cache time: 0.015011942945420742 Engine time: 0.05172164971008897 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-16/adapters_384_slots_64_rate_3.2-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-16/adapters_384_slots_64_rate_3.2-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 540, 33, 34560, 34560, 33, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 33, 34560, 33, 34560, 540, 540, 540, 33, 33, 540, 33, 34560, 33, 34560, 540, 34560, 540, 33, 540, 34560, 540, 34560, 33, 34560, 34560, 34560, 34560, 33, 540, 540, 540, 34560, 540, 33, 540, 33, 34560, 540, 34560, 34560, 540, 34560, 34560, 33, 33, 34560, 540, 540, 33, 33, 33, 540, 33, 540, 33, 34560, 33, 540, 34560, 33, 34560, 540, 33, 34560, 34560, 34560, 34560, 540, 33, 540, 34560, 34560, 540, 33, 33, 34560, 540, 540, 33, 33, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 33, 540, 540, 540, 540, 33, 33, 34560, 33, 34560, 33, 33, 33, 540, 540, 34560, 33, 33, 34560, 33, 34560, 540, 33, 34560, 540, 540, 33, 34560, 34560, 34560, 33, 540, 34560, 33, 34560, 540, 540, 34560, 34560, 33, 540, 34560, 33, 540, 540, 33, 540, 33, 540, 34560, 34560, 540, 33, 34560, 33, 34560, 540, 540, 540, 540, 540, 33, 33, 34560, 33, 34560, 33, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 33, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 33, 33, 33, 33, 33, 540, 33, 33, 540, 34560, 34560, 33, 33, 34560, 33, 33, 33, 540, 33, 540, 34560, 34560, 540, 540, 33, 34560, 540, 34560, 33, 540, 540, 33, 33, 540, 33, 34560, 34560, 33, 34560, 34560, 33, 540, 34560, 33, 33, 540, 540, 33, 33, 34560, 34560, 34560, 34560, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 34560, 540, 540, 540, 34560, 33, 540, 540, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 540, 33, 34560, 34560, 34560, 540, 33, 34560, 34560, 540, 540, 34560, 34560, 33, 34560, 34560, 540, 33, 34560, 540, 540, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 540, 34560, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 34560, 33, 33, 33, 540, 33, 540, 540, 33, 34560, 540, 34560, 33, 34560, 33, 540, 540, 540, 540, 33, 540, 34560, 34560, 33, 34560, 34560, 33, 34560, 540, 34560, 540, 540, 540, 33, 540, 33, 33, 34560, 33, 540, 33, 33, 540, 34560, 540, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4497024 . Total input tokens: 1001990086 . Total output tokens: 899106028
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 72.47345229191706,
    "estimated_duration": 3600.165681986881,
    "input_throughput": 6152.914603578714,
    "output_throughput": 5470.095751018762,
    "total_throughput": 11623.010354597476,
    "itl": 154.2601337430889,
    "ttft": 2093891.118163377,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 444,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3275823309365558,
    "arrivals": 1497804,
    "finished_requests": 89610,
    "scheduler_time": 175.6275733028921
}
#Debug simulation 
Total elapsed time: 72.47356767300516. Arrivals time: 0.41253875382244587 Scheduler time: 71.91824993491173 Scheduler overhead time: 0.05573738692328334 Adapter cache time: 0.01492612436413765 Engine time: 0.05151581624522805 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-32/adapters_384_slots_64_rate_3.2-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-32/adapters_384_slots_64_rate_3.2-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 540, 33, 34560, 34560, 33, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 33, 34560, 33, 34560, 540, 540, 540, 33, 33, 540, 33, 34560, 33, 34560, 540, 34560, 540, 33, 540, 34560, 540, 34560, 33, 34560, 34560, 34560, 34560, 33, 540, 540, 540, 34560, 540, 33, 540, 33, 34560, 540, 34560, 34560, 540, 34560, 34560, 33, 33, 34560, 540, 540, 33, 33, 33, 540, 33, 540, 33, 34560, 33, 540, 34560, 33, 34560, 540, 33, 34560, 34560, 34560, 34560, 540, 33, 540, 34560, 34560, 540, 33, 33, 34560, 540, 540, 33, 33, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 33, 540, 540, 540, 540, 33, 33, 34560, 33, 34560, 33, 33, 33, 540, 540, 34560, 33, 33, 34560, 33, 34560, 540, 33, 34560, 540, 540, 33, 34560, 34560, 34560, 33, 540, 34560, 33, 34560, 540, 540, 34560, 34560, 33, 540, 34560, 33, 540, 540, 33, 540, 33, 540, 34560, 34560, 540, 33, 34560, 33, 34560, 540, 540, 540, 540, 540, 33, 33, 34560, 33, 34560, 33, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 33, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 33, 33, 33, 33, 33, 540, 33, 33, 540, 34560, 34560, 33, 33, 34560, 33, 33, 33, 540, 33, 540, 34560, 34560, 540, 540, 33, 34560, 540, 34560, 33, 540, 540, 33, 33, 540, 33, 34560, 34560, 33, 34560, 34560, 33, 540, 34560, 33, 33, 540, 540, 33, 33, 34560, 34560, 34560, 34560, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 34560, 540, 540, 540, 34560, 33, 540, 540, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 540, 33, 34560, 34560, 34560, 540, 33, 34560, 34560, 540, 540, 34560, 34560, 33, 34560, 34560, 540, 33, 34560, 540, 540, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 540, 34560, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 34560, 33, 33, 33, 540, 33, 540, 540, 33, 34560, 540, 34560, 33, 34560, 33, 540, 540, 540, 540, 33, 540, 34560, 34560, 33, 34560, 34560, 33, 34560, 540, 34560, 540, 540, 540, 33, 540, 33, 33, 34560, 33, 540, 33, 33, 540, 34560, 540, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4497024 . Total input tokens: 1001990086 . Total output tokens: 899106028
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 73.92878742003813,
    "estimated_duration": 3600.067085840703,
    "input_throughput": 6162.885432680442,
    "output_throughput": 5472.157748804711,
    "total_throughput": 11635.043181485154,
    "itl": 154.24062319744664,
    "ttft": 2094701.1478621995,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 451,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5110643837973479,
    "arrivals": 1497804,
    "finished_requests": 89723,
    "scheduler_time": 175.3770915836843
}
#Debug simulation 
Total elapsed time: 73.9288932052441. Arrivals time: 0.4325262694619596 Scheduler time: 73.35371656483039 Scheduler overhead time: 0.05547424918040633 Adapter cache time: 0.015104069840162992 Engine time: 0.05118508264422417 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-8/adapters_384_slots_64_rate_3.2-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-8/adapters_384_slots_64_rate_3.2-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 270, 135, 34560, 34560, 135, 270, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 135, 34560, 135, 34560, 270, 270, 270, 135, 135, 270, 135, 34560, 135, 34560, 270, 34560, 270, 135, 270, 34560, 270, 34560, 135, 34560, 34560, 34560, 34560, 135, 270, 270, 270, 34560, 270, 135, 270, 135, 34560, 270, 34560, 34560, 270, 34560, 34560, 135, 135, 34560, 270, 270, 135, 135, 135, 270, 135, 270, 135, 34560, 135, 270, 34560, 135, 34560, 270, 135, 34560, 34560, 34560, 34560, 270, 135, 270, 34560, 34560, 270, 135, 135, 34560, 270, 270, 135, 135, 34560, 270, 34560, 270, 34560, 34560, 270, 34560, 34560, 135, 270, 270, 270, 270, 135, 135, 34560, 135, 34560, 135, 135, 135, 270, 270, 34560, 135, 135, 34560, 135, 34560, 270, 135, 34560, 270, 270, 135, 34560, 34560, 34560, 135, 270, 34560, 135, 34560, 270, 270, 34560, 34560, 135, 270, 34560, 135, 270, 270, 135, 270, 135, 270, 34560, 34560, 270, 135, 34560, 135, 34560, 270, 270, 270, 270, 270, 135, 135, 34560, 135, 34560, 135, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 135, 270, 270, 270, 270, 270, 270, 270, 270, 34560, 135, 135, 135, 135, 135, 270, 135, 135, 270, 34560, 34560, 135, 135, 34560, 135, 135, 135, 270, 135, 270, 34560, 34560, 270, 270, 135, 34560, 270, 34560, 135, 270, 270, 135, 135, 270, 135, 34560, 34560, 135, 34560, 34560, 135, 270, 34560, 135, 135, 270, 270, 135, 135, 34560, 34560, 34560, 34560, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 34560, 270, 270, 270, 34560, 135, 270, 270, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 270, 135, 34560, 34560, 34560, 270, 135, 34560, 34560, 270, 270, 34560, 34560, 135, 34560, 34560, 270, 135, 34560, 270, 270, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 270, 34560, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 34560, 135, 135, 135, 270, 135, 270, 270, 135, 34560, 270, 34560, 135, 34560, 135, 270, 270, 270, 270, 135, 270, 34560, 34560, 135, 34560, 34560, 135, 34560, 270, 34560, 270, 270, 270, 135, 270, 135, 135, 34560, 135, 270, 135, 135, 270, 34560, 270, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4475520 . Total input tokens: 997227558 . Total output tokens: 894761538
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 74.04123088391498,
    "estimated_duration": 3600.089189981736,
    "input_throughput": 6166.980546421582,
    "output_throughput": 5432.545686485956,
    "total_throughput": 11599.52623290754,
    "itl": 152.5908562293007,
    "ttft": 2086775.946308485,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 458,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4017033867212139,
    "arrivals": 1490652,
    "finished_requests": 89661,
    "scheduler_time": 177.65612469255174
}
#Debug simulation 
Total elapsed time: 74.04133810894564. Arrivals time: 0.41429785266518593 Scheduler time: 73.48417059797794 Scheduler overhead time: 0.05561594199389219 Adapter cache time: 0.014946109149605036 Engine time: 0.051223569083958864 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-16/adapters_384_slots_64_rate_3.2-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-16/adapters_384_slots_64_rate_3.2-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 270, 135, 34560, 34560, 135, 270, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 135, 34560, 135, 34560, 270, 270, 270, 135, 135, 270, 135, 34560, 135, 34560, 270, 34560, 270, 135, 270, 34560, 270, 34560, 135, 34560, 34560, 34560, 34560, 135, 270, 270, 270, 34560, 270, 135, 270, 135, 34560, 270, 34560, 34560, 270, 34560, 34560, 135, 135, 34560, 270, 270, 135, 135, 135, 270, 135, 270, 135, 34560, 135, 270, 34560, 135, 34560, 270, 135, 34560, 34560, 34560, 34560, 270, 135, 270, 34560, 34560, 270, 135, 135, 34560, 270, 270, 135, 135, 34560, 270, 34560, 270, 34560, 34560, 270, 34560, 34560, 135, 270, 270, 270, 270, 135, 135, 34560, 135, 34560, 135, 135, 135, 270, 270, 34560, 135, 135, 34560, 135, 34560, 270, 135, 34560, 270, 270, 135, 34560, 34560, 34560, 135, 270, 34560, 135, 34560, 270, 270, 34560, 34560, 135, 270, 34560, 135, 270, 270, 135, 270, 135, 270, 34560, 34560, 270, 135, 34560, 135, 34560, 270, 270, 270, 270, 270, 135, 135, 34560, 135, 34560, 135, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 135, 270, 270, 270, 270, 270, 270, 270, 270, 34560, 135, 135, 135, 135, 135, 270, 135, 135, 270, 34560, 34560, 135, 135, 34560, 135, 135, 135, 270, 135, 270, 34560, 34560, 270, 270, 135, 34560, 270, 34560, 135, 270, 270, 135, 135, 270, 135, 34560, 34560, 135, 34560, 34560, 135, 270, 34560, 135, 135, 270, 270, 135, 135, 34560, 34560, 34560, 34560, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 34560, 270, 270, 270, 34560, 135, 270, 270, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 270, 135, 34560, 34560, 34560, 270, 135, 34560, 34560, 270, 270, 34560, 34560, 135, 34560, 34560, 270, 135, 34560, 270, 270, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 270, 34560, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 34560, 135, 135, 135, 270, 135, 270, 270, 135, 34560, 270, 34560, 135, 34560, 135, 270, 270, 270, 270, 135, 270, 34560, 34560, 135, 34560, 34560, 135, 34560, 270, 34560, 270, 270, 270, 135, 270, 135, 135, 34560, 135, 270, 135, 135, 270, 34560, 270, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4475520 . Total input tokens: 997227558 . Total output tokens: 894761538
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 73.93980315094814,
    "estimated_duration": 3600.013813322565,
    "input_throughput": 6171.195209802765,
    "output_throughput": 5437.119137588757,
    "total_throughput": 11608.314347391522,
    "itl": 152.68415803596676,
    "ttft": 2087852.4516166204,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 495,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.616137137017217,
    "arrivals": 1490652,
    "finished_requests": 89730,
    "scheduler_time": 177.3261035760121
}
#Debug simulation 
Total elapsed time: 73.93991523608565. Arrivals time: 0.4150641532614827 Scheduler time: 73.38068163394928 Scheduler overhead time: 0.05612666718661785 Adapter cache time: 0.015295485034584999 Engine time: 0.05124110262840986 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-32/adapters_384_slots_64_rate_3.2-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-32/adapters_384_slots_64_rate_3.2-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 270, 135, 34560, 34560, 135, 270, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 135, 34560, 135, 34560, 270, 270, 270, 135, 135, 270, 135, 34560, 135, 34560, 270, 34560, 270, 135, 270, 34560, 270, 34560, 135, 34560, 34560, 34560, 34560, 135, 270, 270, 270, 34560, 270, 135, 270, 135, 34560, 270, 34560, 34560, 270, 34560, 34560, 135, 135, 34560, 270, 270, 135, 135, 135, 270, 135, 270, 135, 34560, 135, 270, 34560, 135, 34560, 270, 135, 34560, 34560, 34560, 34560, 270, 135, 270, 34560, 34560, 270, 135, 135, 34560, 270, 270, 135, 135, 34560, 270, 34560, 270, 34560, 34560, 270, 34560, 34560, 135, 270, 270, 270, 270, 135, 135, 34560, 135, 34560, 135, 135, 135, 270, 270, 34560, 135, 135, 34560, 135, 34560, 270, 135, 34560, 270, 270, 135, 34560, 34560, 34560, 135, 270, 34560, 135, 34560, 270, 270, 34560, 34560, 135, 270, 34560, 135, 270, 270, 135, 270, 135, 270, 34560, 34560, 270, 135, 34560, 135, 34560, 270, 270, 270, 270, 270, 135, 135, 34560, 135, 34560, 135, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 135, 270, 270, 270, 270, 270, 270, 270, 270, 34560, 135, 135, 135, 135, 135, 270, 135, 135, 270, 34560, 34560, 135, 135, 34560, 135, 135, 135, 270, 135, 270, 34560, 34560, 270, 270, 135, 34560, 270, 34560, 135, 270, 270, 135, 135, 270, 135, 34560, 34560, 135, 34560, 34560, 135, 270, 34560, 135, 135, 270, 270, 135, 135, 34560, 34560, 34560, 34560, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 34560, 270, 270, 270, 34560, 135, 270, 270, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 270, 135, 34560, 34560, 34560, 270, 135, 34560, 34560, 270, 270, 34560, 34560, 135, 34560, 34560, 270, 135, 34560, 270, 270, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 270, 34560, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 34560, 135, 135, 135, 270, 135, 270, 270, 135, 34560, 270, 34560, 135, 34560, 135, 270, 270, 270, 270, 135, 270, 34560, 34560, 135, 34560, 34560, 135, 34560, 270, 34560, 270, 270, 270, 135, 270, 135, 135, 34560, 135, 270, 135, 135, 270, 34560, 270, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4475520 . Total input tokens: 997227558 . Total output tokens: 894761538
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 73.75655641779304,
    "estimated_duration": 3600.0165311058026,
    "input_throughput": 6171.190550943354,
    "output_throughput": 5437.1150329100365,
    "total_throughput": 11608.30558385339,
    "itl": 152.68423137846546,
    "ttft": 2087853.1461975162,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 495,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6188452458195486,
    "arrivals": 1490652,
    "finished_requests": 89730,
    "scheduler_time": 177.32611325041938
}
#Debug simulation 
Total elapsed time: 73.75666601397097. Arrivals time: 0.5118797514587641 Scheduler time: 73.10113450838253 Scheduler overhead time: 0.05594915570691228 Adapter cache time: 0.01543082669377327 Engine time: 0.05144168250262737 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-16/adapters_384_slots_64_rate_3.2-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-16/adapters_384_slots_64_rate_3.2-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 270, 135, 34560, 34560, 135, 270, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 135, 34560, 135, 34560, 270, 270, 270, 135, 135, 270, 135, 34560, 135, 34560, 270, 34560, 270, 135, 270, 34560, 270, 34560, 135, 34560, 34560, 34560, 34560, 135, 270, 270, 270, 34560, 270, 135, 270, 135, 34560, 270, 34560, 34560, 270, 34560, 34560, 135, 135, 34560, 270, 270, 135, 135, 135, 270, 135, 270, 135, 34560, 135, 270, 34560, 135, 34560, 270, 135, 34560, 34560, 34560, 34560, 270, 135, 270, 34560, 34560, 270, 135, 135, 34560, 270, 270, 135, 135, 34560, 270, 34560, 270, 34560, 34560, 270, 34560, 34560, 135, 270, 270, 270, 270, 135, 135, 34560, 135, 34560, 135, 135, 135, 270, 270, 34560, 135, 135, 34560, 135, 34560, 270, 135, 34560, 270, 270, 135, 34560, 34560, 34560, 135, 270, 34560, 135, 34560, 270, 270, 34560, 34560, 135, 270, 34560, 135, 270, 270, 135, 270, 135, 270, 34560, 34560, 270, 135, 34560, 135, 34560, 270, 270, 270, 270, 270, 135, 135, 34560, 135, 34560, 135, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 135, 270, 270, 270, 270, 270, 270, 270, 270, 34560, 135, 135, 135, 135, 135, 270, 135, 135, 270, 34560, 34560, 135, 135, 34560, 135, 135, 135, 270, 135, 270, 34560, 34560, 270, 270, 135, 34560, 270, 34560, 135, 270, 270, 135, 135, 270, 135, 34560, 34560, 135, 34560, 34560, 135, 270, 34560, 135, 135, 270, 270, 135, 135, 34560, 34560, 34560, 34560, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 34560, 270, 270, 270, 34560, 135, 270, 270, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 270, 135, 34560, 34560, 34560, 270, 135, 34560, 34560, 270, 270, 34560, 34560, 135, 34560, 34560, 270, 135, 34560, 270, 270, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 270, 34560, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 34560, 135, 135, 135, 270, 135, 270, 270, 135, 34560, 270, 34560, 135, 34560, 135, 270, 270, 270, 270, 135, 270, 34560, 34560, 135, 34560, 34560, 135, 34560, 270, 34560, 270, 270, 270, 135, 270, 135, 135, 34560, 135, 270, 135, 135, 270, 34560, 270, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4475520 . Total input tokens: 997227558 . Total output tokens: 894761538
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 73.76955890376121,
    "estimated_duration": 3600.120523451166,
    "input_throughput": 6171.449776548398,
    "output_throughput": 5437.4699048226275,
    "total_throughput": 11608.919681371026,
    "itl": 152.68271656631012,
    "ttft": 2087882.2972610628,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 495,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.549536100111429,
    "arrivals": 1490652,
    "finished_requests": 89736,
    "scheduler_time": 177.3341514002284
}
#Debug simulation 
Total elapsed time: 73.76967359567061. Arrivals time: 0.404137478210032 Scheduler time: 73.22268263064325 Scheduler overhead time: 0.05540598090738058 Adapter cache time: 0.015520764514803886 Engine time: 0.05089429020881653 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-32/adapters_384_slots_64_rate_3.2-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-32/adapters_384_slots_64_rate_3.2-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 270, 135, 34560, 34560, 135, 270, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 135, 34560, 135, 34560, 270, 270, 270, 135, 135, 270, 135, 34560, 135, 34560, 270, 34560, 270, 135, 270, 34560, 270, 34560, 135, 34560, 34560, 34560, 34560, 135, 270, 270, 270, 34560, 270, 135, 270, 135, 34560, 270, 34560, 34560, 270, 34560, 34560, 135, 135, 34560, 270, 270, 135, 135, 135, 270, 135, 270, 135, 34560, 135, 270, 34560, 135, 34560, 270, 135, 34560, 34560, 34560, 34560, 270, 135, 270, 34560, 34560, 270, 135, 135, 34560, 270, 270, 135, 135, 34560, 270, 34560, 270, 34560, 34560, 270, 34560, 34560, 135, 270, 270, 270, 270, 135, 135, 34560, 135, 34560, 135, 135, 135, 270, 270, 34560, 135, 135, 34560, 135, 34560, 270, 135, 34560, 270, 270, 135, 34560, 34560, 34560, 135, 270, 34560, 135, 34560, 270, 270, 34560, 34560, 135, 270, 34560, 135, 270, 270, 135, 270, 135, 270, 34560, 34560, 270, 135, 34560, 135, 34560, 270, 270, 270, 270, 270, 135, 135, 34560, 135, 34560, 135, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 135, 270, 270, 270, 270, 270, 270, 270, 270, 34560, 135, 135, 135, 135, 135, 270, 135, 135, 270, 34560, 34560, 135, 135, 34560, 135, 135, 135, 270, 135, 270, 34560, 34560, 270, 270, 135, 34560, 270, 34560, 135, 270, 270, 135, 135, 270, 135, 34560, 34560, 135, 34560, 34560, 135, 270, 34560, 135, 135, 270, 270, 135, 135, 34560, 34560, 34560, 34560, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 34560, 270, 270, 270, 34560, 135, 270, 270, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 270, 135, 34560, 34560, 34560, 270, 135, 34560, 34560, 270, 270, 34560, 34560, 135, 34560, 34560, 270, 135, 34560, 270, 270, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 270, 34560, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 34560, 135, 135, 135, 270, 135, 270, 270, 135, 34560, 270, 34560, 135, 34560, 135, 270, 270, 270, 270, 135, 270, 34560, 34560, 135, 34560, 34560, 135, 34560, 270, 34560, 270, 270, 270, 135, 270, 135, 135, 34560, 135, 270, 135, 135, 270, 34560, 270, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4475520 . Total input tokens: 997227558 . Total output tokens: 894761538
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 74.1528065269813,
    "estimated_duration": 3600.0371350263695,
    "input_throughput": 6171.1552316632615,
    "output_throughput": 5437.083914929291,
    "total_throughput": 11608.239146592552,
    "itl": 152.68474718572736,
    "ttft": 2087860.1198507631,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 495,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6393431130051657,
    "arrivals": 1490652,
    "finished_requests": 89730,
    "scheduler_time": 177.32621930382774
}
#Debug simulation 
Total elapsed time: 74.15292115835473. Arrivals time: 0.41220035357400775 Scheduler time: 73.59555781260133 Scheduler overhead time: 0.056208140682429075 Adapter cache time: 0.01585999969393015 Engine time: 0.052130456548184156 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-16/adapters_384_slots_64_rate_3.2-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-16/adapters_384_slots_64_rate_3.2-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 270, 135, 34560, 34560, 135, 270, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 135, 34560, 135, 34560, 270, 270, 270, 135, 135, 270, 135, 34560, 135, 34560, 270, 34560, 270, 135, 270, 34560, 270, 34560, 135, 34560, 34560, 34560, 34560, 135, 270, 270, 270, 34560, 270, 135, 270, 135, 34560, 270, 34560, 34560, 270, 34560, 34560, 135, 135, 34560, 270, 270, 135, 135, 135, 270, 135, 270, 135, 34560, 135, 270, 34560, 135, 34560, 270, 135, 34560, 34560, 34560, 34560, 270, 135, 270, 34560, 34560, 270, 135, 135, 34560, 270, 270, 135, 135, 34560, 270, 34560, 270, 34560, 34560, 270, 34560, 34560, 135, 270, 270, 270, 270, 135, 135, 34560, 135, 34560, 135, 135, 135, 270, 270, 34560, 135, 135, 34560, 135, 34560, 270, 135, 34560, 270, 270, 135, 34560, 34560, 34560, 135, 270, 34560, 135, 34560, 270, 270, 34560, 34560, 135, 270, 34560, 135, 270, 270, 135, 270, 135, 270, 34560, 34560, 270, 135, 34560, 135, 34560, 270, 270, 270, 270, 270, 135, 135, 34560, 135, 34560, 135, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 135, 270, 270, 270, 270, 270, 270, 270, 270, 34560, 135, 135, 135, 135, 135, 270, 135, 135, 270, 34560, 34560, 135, 135, 34560, 135, 135, 135, 270, 135, 270, 34560, 34560, 270, 270, 135, 34560, 270, 34560, 135, 270, 270, 135, 135, 270, 135, 34560, 34560, 135, 34560, 34560, 135, 270, 34560, 135, 135, 270, 270, 135, 135, 34560, 34560, 34560, 34560, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 34560, 270, 270, 270, 34560, 135, 270, 270, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 270, 135, 34560, 34560, 34560, 270, 135, 34560, 34560, 270, 270, 34560, 34560, 135, 34560, 34560, 270, 135, 34560, 270, 270, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 270, 34560, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 34560, 135, 135, 135, 270, 135, 270, 270, 135, 34560, 270, 34560, 135, 34560, 135, 270, 270, 270, 270, 135, 270, 34560, 34560, 135, 34560, 34560, 135, 34560, 270, 34560, 270, 270, 270, 135, 270, 135, 135, 34560, 135, 270, 135, 135, 270, 34560, 270, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4475520 . Total input tokens: 997227558 . Total output tokens: 894761538
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 74.29581393115222,
    "estimated_duration": 3600.0567589590123,
    "input_throughput": 6167.03610151408,
    "output_throughput": 5432.59462544009,
    "total_throughput": 11599.63072695417,
    "itl": 152.59006924025195,
    "ttft": 2086764.9129776591,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 458,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3694430350651847,
    "arrivals": 1490652,
    "finished_requests": 89661,
    "scheduler_time": 177.65595402140406
}
#Debug simulation 
Total elapsed time: 74.29592467891052. Arrivals time: 0.41727027762681246 Scheduler time: 73.73515155119821 Scheduler overhead time: 0.05587970092892647 Adapter cache time: 0.015207399614155293 Engine time: 0.0516729224473238 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-32/adapters_384_slots_64_rate_3.2-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-32/adapters_384_slots_64_rate_3.2-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 270, 135, 34560, 34560, 135, 270, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 135, 34560, 135, 34560, 270, 270, 270, 135, 135, 270, 135, 34560, 135, 34560, 270, 34560, 270, 135, 270, 34560, 270, 34560, 135, 34560, 34560, 34560, 34560, 135, 270, 270, 270, 34560, 270, 135, 270, 135, 34560, 270, 34560, 34560, 270, 34560, 34560, 135, 135, 34560, 270, 270, 135, 135, 135, 270, 135, 270, 135, 34560, 135, 270, 34560, 135, 34560, 270, 135, 34560, 34560, 34560, 34560, 270, 135, 270, 34560, 34560, 270, 135, 135, 34560, 270, 270, 135, 135, 34560, 270, 34560, 270, 34560, 34560, 270, 34560, 34560, 135, 270, 270, 270, 270, 135, 135, 34560, 135, 34560, 135, 135, 135, 270, 270, 34560, 135, 135, 34560, 135, 34560, 270, 135, 34560, 270, 270, 135, 34560, 34560, 34560, 135, 270, 34560, 135, 34560, 270, 270, 34560, 34560, 135, 270, 34560, 135, 270, 270, 135, 270, 135, 270, 34560, 34560, 270, 135, 34560, 135, 34560, 270, 270, 270, 270, 270, 135, 135, 34560, 135, 34560, 135, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 135, 270, 270, 270, 270, 270, 270, 270, 270, 34560, 135, 135, 135, 135, 135, 270, 135, 135, 270, 34560, 34560, 135, 135, 34560, 135, 135, 135, 270, 135, 270, 34560, 34560, 270, 270, 135, 34560, 270, 34560, 135, 270, 270, 135, 135, 270, 135, 34560, 34560, 135, 34560, 34560, 135, 270, 34560, 135, 135, 270, 270, 135, 135, 34560, 34560, 34560, 34560, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 34560, 270, 270, 270, 34560, 135, 270, 270, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 270, 135, 34560, 34560, 34560, 270, 135, 34560, 34560, 270, 270, 34560, 34560, 135, 34560, 34560, 270, 135, 34560, 270, 270, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 270, 34560, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 34560, 135, 135, 135, 270, 135, 270, 270, 135, 34560, 270, 34560, 135, 34560, 135, 270, 270, 270, 270, 135, 270, 34560, 34560, 135, 34560, 34560, 135, 34560, 270, 34560, 270, 270, 270, 135, 270, 135, 135, 34560, 135, 270, 135, 135, 270, 34560, 270, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4475520 . Total input tokens: 997227558 . Total output tokens: 894761538
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 74.15439891302958,
    "estimated_duration": 3600.058635469147,
    "input_throughput": 6171.118375994129,
    "output_throughput": 5437.051443316068,
    "total_throughput": 11608.169819310197,
    "itl": 152.6853407496967,
    "ttft": 2087867.833591978,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 495,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6607212566956868,
    "arrivals": 1490652,
    "finished_requests": 89730,
    "scheduler_time": 177.3263416029389
}
#Debug simulation 
Total elapsed time: 74.15451001096517. Arrivals time: 0.41181538347154856 Scheduler time: 73.5989849595353 Scheduler overhead time: 0.056161297019571066 Adapter cache time: 0.015497058629989624 Engine time: 0.05110200168564916 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-8/adapters_384_slots_64_rate_3.2-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-8/adapters_384_slots_64_rate_3.2-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 270, 66, 34560, 34560, 66, 270, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 66, 34560, 66, 34560, 270, 270, 270, 66, 66, 270, 66, 34560, 66, 34560, 270, 34560, 270, 66, 270, 34560, 270, 34560, 66, 34560, 34560, 34560, 34560, 66, 270, 270, 270, 34560, 270, 66, 270, 66, 34560, 270, 34560, 34560, 270, 34560, 34560, 66, 66, 34560, 270, 270, 66, 66, 66, 270, 66, 270, 66, 34560, 66, 270, 34560, 66, 34560, 270, 66, 34560, 34560, 34560, 34560, 270, 66, 270, 34560, 34560, 270, 66, 66, 34560, 270, 270, 66, 66, 34560, 270, 34560, 270, 34560, 34560, 270, 34560, 34560, 66, 270, 270, 270, 270, 66, 66, 34560, 66, 34560, 66, 66, 66, 270, 270, 34560, 66, 66, 34560, 66, 34560, 270, 66, 34560, 270, 270, 66, 34560, 34560, 34560, 66, 270, 34560, 66, 34560, 270, 270, 34560, 34560, 66, 270, 34560, 66, 270, 270, 66, 270, 66, 270, 34560, 34560, 270, 66, 34560, 66, 34560, 270, 270, 270, 270, 270, 66, 66, 34560, 66, 34560, 66, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 66, 270, 270, 270, 270, 270, 270, 270, 270, 34560, 66, 66, 66, 66, 66, 270, 66, 66, 270, 34560, 34560, 66, 66, 34560, 66, 66, 66, 270, 66, 270, 34560, 34560, 270, 270, 66, 34560, 270, 34560, 66, 270, 270, 66, 66, 270, 66, 34560, 34560, 66, 34560, 34560, 66, 270, 34560, 66, 66, 270, 270, 66, 66, 34560, 34560, 34560, 34560, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 34560, 270, 270, 270, 34560, 66, 270, 270, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 270, 66, 34560, 34560, 34560, 270, 66, 34560, 34560, 270, 270, 34560, 34560, 66, 34560, 34560, 270, 66, 34560, 270, 270, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 270, 34560, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 34560, 66, 66, 66, 270, 66, 270, 270, 66, 34560, 270, 34560, 66, 34560, 66, 270, 270, 270, 270, 66, 270, 34560, 34560, 66, 34560, 34560, 66, 34560, 270, 34560, 270, 270, 270, 66, 270, 66, 66, 34560, 66, 270, 66, 66, 270, 34560, 270, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4466688 . Total input tokens: 995282892 . Total output tokens: 892945377
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 72.30122929625213,
    "estimated_duration": 3600.1656691197018,
    "input_throughput": 6195.1040729338265,
    "output_throughput": 5467.9972560300175,
    "total_throughput": 11663.101328963843,
    "itl": 154.2768694516544,
    "ttft": 2090474.104248643,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 421,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.288465340195698,
    "arrivals": 1487737,
    "finished_requests": 90067,
    "scheduler_time": 175.70622209369785
}
#Debug simulation 
Total elapsed time: 72.3013449688442. Arrivals time: 0.4121424639597535 Scheduler time: 71.74794055055827 Scheduler overhead time: 0.05539127020165324 Adapter cache time: 0.014726962428539991 Engine time: 0.05078618507832289 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-16/adapters_384_slots_64_rate_3.2-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-16/adapters_384_slots_64_rate_3.2-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 270, 66, 34560, 34560, 66, 270, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 66, 34560, 66, 34560, 270, 270, 270, 66, 66, 270, 66, 34560, 66, 34560, 270, 34560, 270, 66, 270, 34560, 270, 34560, 66, 34560, 34560, 34560, 34560, 66, 270, 270, 270, 34560, 270, 66, 270, 66, 34560, 270, 34560, 34560, 270, 34560, 34560, 66, 66, 34560, 270, 270, 66, 66, 66, 270, 66, 270, 66, 34560, 66, 270, 34560, 66, 34560, 270, 66, 34560, 34560, 34560, 34560, 270, 66, 270, 34560, 34560, 270, 66, 66, 34560, 270, 270, 66, 66, 34560, 270, 34560, 270, 34560, 34560, 270, 34560, 34560, 66, 270, 270, 270, 270, 66, 66, 34560, 66, 34560, 66, 66, 66, 270, 270, 34560, 66, 66, 34560, 66, 34560, 270, 66, 34560, 270, 270, 66, 34560, 34560, 34560, 66, 270, 34560, 66, 34560, 270, 270, 34560, 34560, 66, 270, 34560, 66, 270, 270, 66, 270, 66, 270, 34560, 34560, 270, 66, 34560, 66, 34560, 270, 270, 270, 270, 270, 66, 66, 34560, 66, 34560, 66, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 66, 270, 270, 270, 270, 270, 270, 270, 270, 34560, 66, 66, 66, 66, 66, 270, 66, 66, 270, 34560, 34560, 66, 66, 34560, 66, 66, 66, 270, 66, 270, 34560, 34560, 270, 270, 66, 34560, 270, 34560, 66, 270, 270, 66, 66, 270, 66, 34560, 34560, 66, 34560, 34560, 66, 270, 34560, 66, 66, 270, 270, 66, 66, 34560, 34560, 34560, 34560, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 34560, 270, 270, 270, 34560, 66, 270, 270, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 270, 66, 34560, 34560, 34560, 270, 66, 34560, 34560, 270, 270, 34560, 34560, 66, 34560, 34560, 270, 66, 34560, 270, 270, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 270, 34560, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 34560, 66, 66, 66, 270, 66, 270, 270, 66, 34560, 270, 34560, 66, 34560, 66, 270, 270, 270, 270, 66, 270, 34560, 34560, 66, 34560, 34560, 66, 34560, 270, 34560, 270, 270, 270, 66, 270, 66, 66, 34560, 66, 270, 66, 66, 270, 34560, 270, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4466688 . Total input tokens: 995282892 . Total output tokens: 892945377
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 72.63586680078879,
    "estimated_duration": 3600.078143450617,
    "input_throughput": 6195.037194004711,
    "output_throughput": 5467.919643858703,
    "total_throughput": 11662.956837863414,
    "itl": 154.2803065085743,
    "ttft": 2090466.7662500506,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 421,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.37485224459088,
    "arrivals": 1487737,
    "finished_requests": 90061,
    "scheduler_time": 175.69840828905467
}
#Debug simulation 
Total elapsed time: 72.63598561193794. Arrivals time: 0.7824464947916567 Scheduler time: 71.71201607212424 Scheduler overhead time: 0.055369569920003414 Adapter cache time: 0.014501452445983887 Engine time: 0.050849922467023134 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-32/adapters_384_slots_64_rate_3.2-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-32/adapters_384_slots_64_rate_3.2-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 270, 66, 34560, 34560, 66, 270, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 66, 34560, 66, 34560, 270, 270, 270, 66, 66, 270, 66, 34560, 66, 34560, 270, 34560, 270, 66, 270, 34560, 270, 34560, 66, 34560, 34560, 34560, 34560, 66, 270, 270, 270, 34560, 270, 66, 270, 66, 34560, 270, 34560, 34560, 270, 34560, 34560, 66, 66, 34560, 270, 270, 66, 66, 66, 270, 66, 270, 66, 34560, 66, 270, 34560, 66, 34560, 270, 66, 34560, 34560, 34560, 34560, 270, 66, 270, 34560, 34560, 270, 66, 66, 34560, 270, 270, 66, 66, 34560, 270, 34560, 270, 34560, 34560, 270, 34560, 34560, 66, 270, 270, 270, 270, 66, 66, 34560, 66, 34560, 66, 66, 66, 270, 270, 34560, 66, 66, 34560, 66, 34560, 270, 66, 34560, 270, 270, 66, 34560, 34560, 34560, 66, 270, 34560, 66, 34560, 270, 270, 34560, 34560, 66, 270, 34560, 66, 270, 270, 66, 270, 66, 270, 34560, 34560, 270, 66, 34560, 66, 34560, 270, 270, 270, 270, 270, 66, 66, 34560, 66, 34560, 66, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 66, 270, 270, 270, 270, 270, 270, 270, 270, 34560, 66, 66, 66, 66, 66, 270, 66, 66, 270, 34560, 34560, 66, 66, 34560, 66, 66, 66, 270, 66, 270, 34560, 34560, 270, 270, 66, 34560, 270, 34560, 66, 270, 270, 66, 66, 270, 66, 34560, 34560, 66, 34560, 34560, 66, 270, 34560, 66, 66, 270, 270, 66, 66, 34560, 34560, 34560, 34560, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 34560, 270, 270, 270, 34560, 66, 270, 270, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 270, 66, 34560, 34560, 34560, 270, 66, 34560, 34560, 270, 270, 34560, 34560, 66, 34560, 34560, 270, 66, 34560, 270, 270, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 270, 34560, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 34560, 66, 66, 66, 270, 66, 270, 270, 66, 34560, 270, 34560, 66, 34560, 66, 270, 270, 270, 270, 66, 270, 34560, 34560, 66, 34560, 34560, 66, 34560, 270, 34560, 270, 270, 270, 66, 270, 66, 66, 34560, 66, 270, 66, 66, 270, 34560, 270, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4466688 . Total input tokens: 995282892 . Total output tokens: 892945377
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 72.46577580086887,
    "estimated_duration": 3600.0803962233726,
    "input_throughput": 6195.033317421558,
    "output_throughput": 5467.916222273892,
    "total_throughput": 11662.94953969545,
    "itl": 154.2803527913808,
    "ttft": 2090467.384360244,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 421,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.377099723778673,
    "arrivals": 1487737,
    "finished_requests": 90061,
    "scheduler_time": 175.69841358259828
}
#Debug simulation 
Total elapsed time: 72.46589155402035. Arrivals time: 0.4125458621419966 Scheduler time: 71.91223978158087 Scheduler overhead time: 0.05559076555073261 Adapter cache time: 0.014451025985181332 Engine time: 0.050329772755503654 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-16/adapters_384_slots_64_rate_3.2-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-16/adapters_384_slots_64_rate_3.2-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 270, 66, 34560, 34560, 66, 270, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 66, 34560, 66, 34560, 270, 270, 270, 66, 66, 270, 66, 34560, 66, 34560, 270, 34560, 270, 66, 270, 34560, 270, 34560, 66, 34560, 34560, 34560, 34560, 66, 270, 270, 270, 34560, 270, 66, 270, 66, 34560, 270, 34560, 34560, 270, 34560, 34560, 66, 66, 34560, 270, 270, 66, 66, 66, 270, 66, 270, 66, 34560, 66, 270, 34560, 66, 34560, 270, 66, 34560, 34560, 34560, 34560, 270, 66, 270, 34560, 34560, 270, 66, 66, 34560, 270, 270, 66, 66, 34560, 270, 34560, 270, 34560, 34560, 270, 34560, 34560, 66, 270, 270, 270, 270, 66, 66, 34560, 66, 34560, 66, 66, 66, 270, 270, 34560, 66, 66, 34560, 66, 34560, 270, 66, 34560, 270, 270, 66, 34560, 34560, 34560, 66, 270, 34560, 66, 34560, 270, 270, 34560, 34560, 66, 270, 34560, 66, 270, 270, 66, 270, 66, 270, 34560, 34560, 270, 66, 34560, 66, 34560, 270, 270, 270, 270, 270, 66, 66, 34560, 66, 34560, 66, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 66, 270, 270, 270, 270, 270, 270, 270, 270, 34560, 66, 66, 66, 66, 66, 270, 66, 66, 270, 34560, 34560, 66, 66, 34560, 66, 66, 66, 270, 66, 270, 34560, 34560, 270, 270, 66, 34560, 270, 34560, 66, 270, 270, 66, 66, 270, 66, 34560, 34560, 66, 34560, 34560, 66, 270, 34560, 66, 66, 270, 270, 66, 66, 34560, 34560, 34560, 34560, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 34560, 270, 270, 270, 34560, 66, 270, 270, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 270, 66, 34560, 34560, 34560, 270, 66, 34560, 34560, 270, 270, 34560, 34560, 66, 34560, 34560, 270, 66, 34560, 270, 270, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 270, 34560, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 34560, 66, 66, 66, 270, 66, 270, 270, 66, 34560, 270, 34560, 66, 34560, 66, 270, 270, 270, 270, 66, 270, 34560, 34560, 66, 34560, 34560, 66, 34560, 270, 34560, 270, 270, 270, 66, 270, 66, 66, 34560, 66, 270, 66, 66, 270, 34560, 270, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4466688 . Total input tokens: 995282892 . Total output tokens: 892945377
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 72.27920834394172,
    "estimated_duration": 3600.0226278676128,
    "input_throughput": 6195.132727043558,
    "output_throughput": 5468.00396409172,
    "total_throughput": 11663.136691135278,
    "itl": 154.278554878004,
    "ttft": 2090446.0904006287,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 421,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3196918766014267,
    "arrivals": 1487737,
    "finished_requests": 90061,
    "scheduler_time": 175.69805307402427
}
#Debug simulation 
Total elapsed time: 72.27932368777692. Arrivals time: 0.40607078233733773 Scheduler time: 71.73092942871153 Scheduler overhead time: 0.05582608329132199 Adapter cache time: 0.014551394619047642 Engine time: 0.05128047848120332 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-32/adapters_384_slots_64_rate_3.2-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-32/adapters_384_slots_64_rate_3.2-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 270, 66, 34560, 34560, 66, 270, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 66, 34560, 66, 34560, 270, 270, 270, 66, 66, 270, 66, 34560, 66, 34560, 270, 34560, 270, 66, 270, 34560, 270, 34560, 66, 34560, 34560, 34560, 34560, 66, 270, 270, 270, 34560, 270, 66, 270, 66, 34560, 270, 34560, 34560, 270, 34560, 34560, 66, 66, 34560, 270, 270, 66, 66, 66, 270, 66, 270, 66, 34560, 66, 270, 34560, 66, 34560, 270, 66, 34560, 34560, 34560, 34560, 270, 66, 270, 34560, 34560, 270, 66, 66, 34560, 270, 270, 66, 66, 34560, 270, 34560, 270, 34560, 34560, 270, 34560, 34560, 66, 270, 270, 270, 270, 66, 66, 34560, 66, 34560, 66, 66, 66, 270, 270, 34560, 66, 66, 34560, 66, 34560, 270, 66, 34560, 270, 270, 66, 34560, 34560, 34560, 66, 270, 34560, 66, 34560, 270, 270, 34560, 34560, 66, 270, 34560, 66, 270, 270, 66, 270, 66, 270, 34560, 34560, 270, 66, 34560, 66, 34560, 270, 270, 270, 270, 270, 66, 66, 34560, 66, 34560, 66, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 66, 270, 270, 270, 270, 270, 270, 270, 270, 34560, 66, 66, 66, 66, 66, 270, 66, 66, 270, 34560, 34560, 66, 66, 34560, 66, 66, 66, 270, 66, 270, 34560, 34560, 270, 270, 66, 34560, 270, 34560, 66, 270, 270, 66, 66, 270, 66, 34560, 34560, 66, 34560, 34560, 66, 270, 34560, 66, 66, 270, 270, 66, 66, 34560, 34560, 34560, 34560, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 34560, 270, 270, 270, 34560, 66, 270, 270, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 270, 66, 34560, 34560, 34560, 270, 66, 34560, 34560, 270, 270, 34560, 34560, 66, 34560, 34560, 270, 66, 34560, 270, 270, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 270, 34560, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 34560, 66, 66, 66, 270, 66, 270, 270, 66, 34560, 270, 34560, 66, 34560, 66, 270, 270, 270, 270, 66, 270, 34560, 34560, 66, 34560, 34560, 66, 34560, 270, 34560, 270, 270, 270, 66, 270, 66, 66, 34560, 66, 270, 66, 66, 270, 34560, 270, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4466688 . Total input tokens: 995282892 . Total output tokens: 892945377
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 72.33537425007671,
    "estimated_duration": 3600.0974821410364,
    "input_throughput": 6195.003916042927,
    "output_throughput": 5467.89027176371,
    "total_throughput": 11662.894187806636,
    "itl": 154.28089195640882,
    "ttft": 2090473.7476744377,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 421,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3940764849446765,
    "arrivals": 1487737,
    "finished_requests": 90061,
    "scheduler_time": 175.6985227391184
}
#Debug simulation 
Total elapsed time: 72.3354946328327. Arrivals time: 0.5167474350892007 Scheduler time: 71.67589208064601 Scheduler overhead time: 0.056554488837718964 Adapter cache time: 0.014584320597350597 Engine time: 0.05094787897542119 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-16/adapters_384_slots_64_rate_3.2-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-16/adapters_384_slots_64_rate_3.2-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 270, 66, 34560, 34560, 66, 270, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 66, 34560, 66, 34560, 270, 270, 270, 66, 66, 270, 66, 34560, 66, 34560, 270, 34560, 270, 66, 270, 34560, 270, 34560, 66, 34560, 34560, 34560, 34560, 66, 270, 270, 270, 34560, 270, 66, 270, 66, 34560, 270, 34560, 34560, 270, 34560, 34560, 66, 66, 34560, 270, 270, 66, 66, 66, 270, 66, 270, 66, 34560, 66, 270, 34560, 66, 34560, 270, 66, 34560, 34560, 34560, 34560, 270, 66, 270, 34560, 34560, 270, 66, 66, 34560, 270, 270, 66, 66, 34560, 270, 34560, 270, 34560, 34560, 270, 34560, 34560, 66, 270, 270, 270, 270, 66, 66, 34560, 66, 34560, 66, 66, 66, 270, 270, 34560, 66, 66, 34560, 66, 34560, 270, 66, 34560, 270, 270, 66, 34560, 34560, 34560, 66, 270, 34560, 66, 34560, 270, 270, 34560, 34560, 66, 270, 34560, 66, 270, 270, 66, 270, 66, 270, 34560, 34560, 270, 66, 34560, 66, 34560, 270, 270, 270, 270, 270, 66, 66, 34560, 66, 34560, 66, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 66, 270, 270, 270, 270, 270, 270, 270, 270, 34560, 66, 66, 66, 66, 66, 270, 66, 66, 270, 34560, 34560, 66, 66, 34560, 66, 66, 66, 270, 66, 270, 34560, 34560, 270, 270, 66, 34560, 270, 34560, 66, 270, 270, 66, 66, 270, 66, 34560, 34560, 66, 34560, 34560, 66, 270, 34560, 66, 66, 270, 270, 66, 66, 34560, 34560, 34560, 34560, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 34560, 270, 270, 270, 34560, 66, 270, 270, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 270, 66, 34560, 34560, 34560, 270, 66, 34560, 34560, 270, 270, 34560, 34560, 66, 34560, 34560, 270, 66, 34560, 270, 270, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 270, 34560, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 34560, 66, 66, 66, 270, 66, 270, 270, 66, 34560, 270, 34560, 66, 34560, 66, 270, 270, 270, 270, 66, 270, 34560, 34560, 66, 34560, 34560, 66, 34560, 270, 34560, 270, 270, 270, 66, 270, 66, 66, 34560, 66, 270, 66, 66, 270, 34560, 270, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4466688 . Total input tokens: 995282892 . Total output tokens: 892945377
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 72.90005931770429,
    "estimated_duration": 3600.1358364335265,
    "input_throughput": 6195.15540894003,
    "output_throughput": 5468.042566833153,
    "total_throughput": 11663.197975773182,
    "itl": 154.27600353248573,
    "ttft": 2090463.233438788,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 421,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2588111741538082,
    "arrivals": 1487737,
    "finished_requests": 90067,
    "scheduler_time": 175.7060435735027
}
#Debug simulation 
Total elapsed time: 72.90018222015351. Arrivals time: 0.8035237579606473 Scheduler time: 71.95497975917533 Scheduler overhead time: 0.055608294904232025 Adapter cache time: 0.014620503410696983 Engine time: 0.05043536517769098 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-32/adapters_384_slots_64_rate_3.2-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-32/adapters_384_slots_64_rate_3.2-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 270, 66, 34560, 34560, 66, 270, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 66, 34560, 66, 34560, 270, 270, 270, 66, 66, 270, 66, 34560, 66, 34560, 270, 34560, 270, 66, 270, 34560, 270, 34560, 66, 34560, 34560, 34560, 34560, 66, 270, 270, 270, 34560, 270, 66, 270, 66, 34560, 270, 34560, 34560, 270, 34560, 34560, 66, 66, 34560, 270, 270, 66, 66, 66, 270, 66, 270, 66, 34560, 66, 270, 34560, 66, 34560, 270, 66, 34560, 34560, 34560, 34560, 270, 66, 270, 34560, 34560, 270, 66, 66, 34560, 270, 270, 66, 66, 34560, 270, 34560, 270, 34560, 34560, 270, 34560, 34560, 66, 270, 270, 270, 270, 66, 66, 34560, 66, 34560, 66, 66, 66, 270, 270, 34560, 66, 66, 34560, 66, 34560, 270, 66, 34560, 270, 270, 66, 34560, 34560, 34560, 66, 270, 34560, 66, 34560, 270, 270, 34560, 34560, 66, 270, 34560, 66, 270, 270, 66, 270, 66, 270, 34560, 34560, 270, 66, 34560, 66, 34560, 270, 270, 270, 270, 270, 66, 66, 34560, 66, 34560, 66, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 66, 270, 270, 270, 270, 270, 270, 270, 270, 34560, 66, 66, 66, 66, 66, 270, 66, 66, 270, 34560, 34560, 66, 66, 34560, 66, 66, 66, 270, 66, 270, 34560, 34560, 270, 270, 66, 34560, 270, 34560, 66, 270, 270, 66, 66, 270, 66, 34560, 34560, 66, 34560, 34560, 66, 270, 34560, 66, 66, 270, 270, 66, 66, 34560, 34560, 34560, 34560, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 34560, 270, 270, 270, 34560, 66, 270, 270, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 270, 66, 34560, 34560, 34560, 270, 66, 34560, 34560, 270, 270, 34560, 34560, 66, 34560, 34560, 270, 66, 34560, 270, 270, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 270, 34560, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 34560, 66, 66, 66, 270, 66, 270, 270, 66, 34560, 270, 34560, 66, 34560, 66, 270, 270, 270, 270, 66, 270, 34560, 34560, 66, 34560, 34560, 66, 34560, 270, 34560, 270, 270, 270, 66, 270, 66, 66, 34560, 66, 270, 66, 66, 270, 34560, 270, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4466688 . Total input tokens: 995282892 . Total output tokens: 892945377
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 72.76326347328722,
    "estimated_duration": 3600.1163419368363,
    "input_throughput": 6194.971462505946,
    "output_throughput": 5467.861627329979,
    "total_throughput": 11662.833089835925,
    "itl": 154.28142989561857,
    "ttft": 2090480.8394472506,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 421,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.412813799120487,
    "arrivals": 1487737,
    "finished_requests": 90061,
    "scheduler_time": 175.69864522076557
}
#Debug simulation 
Total elapsed time: 72.7633788282983. Arrivals time: 0.4233129690401256 Scheduler time: 72.19853819115087 Scheduler overhead time: 0.05548785347491503 Adapter cache time: 0.014741668943315744 Engine time: 0.05071149254217744 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-8/adapters_384_slots_64_rate_3.2-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-8/adapters_384_slots_64_rate_3.2-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 270, 33, 34560, 34560, 33, 270, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 33, 34560, 33, 34560, 270, 270, 270, 33, 33, 270, 33, 34560, 33, 34560, 270, 34560, 270, 33, 270, 34560, 270, 34560, 33, 34560, 34560, 34560, 34560, 33, 270, 270, 270, 34560, 270, 33, 270, 33, 34560, 270, 34560, 34560, 270, 34560, 34560, 33, 33, 34560, 270, 270, 33, 33, 33, 270, 33, 270, 33, 34560, 33, 270, 34560, 33, 34560, 270, 33, 34560, 34560, 34560, 34560, 270, 33, 270, 34560, 34560, 270, 33, 33, 34560, 270, 270, 33, 33, 34560, 270, 34560, 270, 34560, 34560, 270, 34560, 34560, 33, 270, 270, 270, 270, 33, 33, 34560, 33, 34560, 33, 33, 33, 270, 270, 34560, 33, 33, 34560, 33, 34560, 270, 33, 34560, 270, 270, 33, 34560, 34560, 34560, 33, 270, 34560, 33, 34560, 270, 270, 34560, 34560, 33, 270, 34560, 33, 270, 270, 33, 270, 33, 270, 34560, 34560, 270, 33, 34560, 33, 34560, 270, 270, 270, 270, 270, 33, 33, 34560, 33, 34560, 33, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 33, 270, 270, 270, 270, 270, 270, 270, 270, 34560, 33, 33, 33, 33, 33, 270, 33, 33, 270, 34560, 34560, 33, 33, 34560, 33, 33, 33, 270, 33, 270, 34560, 34560, 270, 270, 33, 34560, 270, 34560, 33, 270, 270, 33, 33, 270, 33, 34560, 34560, 33, 34560, 34560, 33, 270, 34560, 33, 33, 270, 270, 33, 33, 34560, 34560, 34560, 34560, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 34560, 270, 270, 270, 34560, 33, 270, 270, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 270, 33, 34560, 34560, 34560, 270, 33, 34560, 34560, 270, 270, 34560, 34560, 33, 34560, 34560, 270, 33, 34560, 270, 270, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 270, 34560, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 34560, 33, 33, 33, 270, 33, 270, 270, 33, 34560, 270, 34560, 33, 34560, 33, 270, 270, 270, 270, 33, 270, 34560, 34560, 33, 34560, 34560, 33, 34560, 270, 34560, 270, 270, 270, 33, 270, 33, 33, 34560, 33, 270, 33, 33, 270, 34560, 270, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4462464 . Total input tokens: 994358162 . Total output tokens: 892094577
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 72.11260744510219,
    "estimated_duration": 3600.087326616174,
    "input_throughput": 6187.222136340922,
    "output_throughput": 5461.580294076099,
    "total_throughput": 11648.802430417021,
    "itl": 153.68846171317168,
    "ttft": 2090806.7825368035,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 445,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3619170460500867,
    "arrivals": 1486263,
    "finished_requests": 90028,
    "scheduler_time": 175.94831763650032
}
#Debug simulation 
Total elapsed time: 72.11272594984621. Arrivals time: 0.4096272299066186 Scheduler time: 71.56235220422968 Scheduler overhead time: 0.05466783745214343 Adapter cache time: 0.01426966255530715 Engine time: 0.05117738293483853 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-16/adapters_384_slots_64_rate_3.2-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-16/adapters_384_slots_64_rate_3.2-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 270, 33, 34560, 34560, 33, 270, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 33, 34560, 33, 34560, 270, 270, 270, 33, 33, 270, 33, 34560, 33, 34560, 270, 34560, 270, 33, 270, 34560, 270, 34560, 33, 34560, 34560, 34560, 34560, 33, 270, 270, 270, 34560, 270, 33, 270, 33, 34560, 270, 34560, 34560, 270, 34560, 34560, 33, 33, 34560, 270, 270, 33, 33, 33, 270, 33, 270, 33, 34560, 33, 270, 34560, 33, 34560, 270, 33, 34560, 34560, 34560, 34560, 270, 33, 270, 34560, 34560, 270, 33, 33, 34560, 270, 270, 33, 33, 34560, 270, 34560, 270, 34560, 34560, 270, 34560, 34560, 33, 270, 270, 270, 270, 33, 33, 34560, 33, 34560, 33, 33, 33, 270, 270, 34560, 33, 33, 34560, 33, 34560, 270, 33, 34560, 270, 270, 33, 34560, 34560, 34560, 33, 270, 34560, 33, 34560, 270, 270, 34560, 34560, 33, 270, 34560, 33, 270, 270, 33, 270, 33, 270, 34560, 34560, 270, 33, 34560, 33, 34560, 270, 270, 270, 270, 270, 33, 33, 34560, 33, 34560, 33, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 33, 270, 270, 270, 270, 270, 270, 270, 270, 34560, 33, 33, 33, 33, 33, 270, 33, 33, 270, 34560, 34560, 33, 33, 34560, 33, 33, 33, 270, 33, 270, 34560, 34560, 270, 270, 33, 34560, 270, 34560, 33, 270, 270, 33, 33, 270, 33, 34560, 34560, 33, 34560, 34560, 33, 270, 34560, 33, 33, 270, 270, 33, 33, 34560, 34560, 34560, 34560, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 34560, 270, 270, 270, 34560, 33, 270, 270, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 270, 33, 34560, 34560, 34560, 270, 33, 34560, 34560, 270, 270, 34560, 34560, 33, 34560, 34560, 270, 33, 34560, 270, 270, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 270, 34560, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 34560, 33, 33, 33, 270, 33, 270, 270, 33, 34560, 270, 34560, 33, 34560, 33, 270, 270, 270, 270, 33, 270, 34560, 34560, 33, 34560, 34560, 33, 34560, 270, 34560, 270, 270, 270, 33, 270, 33, 33, 34560, 33, 270, 33, 33, 270, 34560, 270, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4462464 . Total input tokens: 994358162 . Total output tokens: 892094577
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 72.15295751206577,
    "estimated_duration": 3600.0054145594404,
    "input_throughput": 6186.76208372471,
    "output_throughput": 5461.425952440153,
    "total_throughput": 11648.188036164862,
    "itl": 153.69091923769562,
    "ttft": 2090812.3785188673,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 445,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4523337861266967,
    "arrivals": 1486263,
    "finished_requests": 90023,
    "scheduler_time": 175.94055599125704
}
#Debug simulation 
Total elapsed time: 72.15307236462831. Arrivals time: 0.41218144865706563 Scheduler time: 71.60092123039067 Scheduler overhead time: 0.054434675257653 Adapter cache time: 0.014327841810882092 Engine time: 0.050765692722052336 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-32/adapters_384_slots_64_rate_3.2-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-32/adapters_384_slots_64_rate_3.2-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 270, 33, 34560, 34560, 33, 270, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 33, 34560, 33, 34560, 270, 270, 270, 33, 33, 270, 33, 34560, 33, 34560, 270, 34560, 270, 33, 270, 34560, 270, 34560, 33, 34560, 34560, 34560, 34560, 33, 270, 270, 270, 34560, 270, 33, 270, 33, 34560, 270, 34560, 34560, 270, 34560, 34560, 33, 33, 34560, 270, 270, 33, 33, 33, 270, 33, 270, 33, 34560, 33, 270, 34560, 33, 34560, 270, 33, 34560, 34560, 34560, 34560, 270, 33, 270, 34560, 34560, 270, 33, 33, 34560, 270, 270, 33, 33, 34560, 270, 34560, 270, 34560, 34560, 270, 34560, 34560, 33, 270, 270, 270, 270, 33, 33, 34560, 33, 34560, 33, 33, 33, 270, 270, 34560, 33, 33, 34560, 33, 34560, 270, 33, 34560, 270, 270, 33, 34560, 34560, 34560, 33, 270, 34560, 33, 34560, 270, 270, 34560, 34560, 33, 270, 34560, 33, 270, 270, 33, 270, 33, 270, 34560, 34560, 270, 33, 34560, 33, 34560, 270, 270, 270, 270, 270, 33, 33, 34560, 33, 34560, 33, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 33, 270, 270, 270, 270, 270, 270, 270, 270, 34560, 33, 33, 33, 33, 33, 270, 33, 33, 270, 34560, 34560, 33, 33, 34560, 33, 33, 33, 270, 33, 270, 34560, 34560, 270, 270, 33, 34560, 270, 34560, 33, 270, 270, 33, 33, 270, 33, 34560, 34560, 33, 34560, 34560, 33, 270, 34560, 33, 33, 270, 270, 33, 33, 34560, 34560, 34560, 34560, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 34560, 270, 270, 270, 34560, 33, 270, 270, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 270, 33, 34560, 34560, 34560, 270, 33, 34560, 34560, 270, 270, 34560, 34560, 33, 34560, 34560, 270, 33, 34560, 270, 270, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 270, 34560, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 34560, 33, 33, 33, 270, 33, 270, 270, 33, 34560, 270, 34560, 33, 34560, 33, 270, 270, 270, 270, 33, 270, 34560, 34560, 33, 34560, 34560, 33, 34560, 270, 34560, 270, 270, 270, 33, 270, 33, 33, 34560, 33, 270, 33, 33, 270, 34560, 270, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4462464 . Total input tokens: 994358162 . Total output tokens: 892094577
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 72.13392822863534,
    "estimated_duration": 3600.00795590628,
    "input_throughput": 6186.757716315397,
    "output_throughput": 5461.422097066011,
    "total_throughput": 11648.179813381408,
    "itl": 153.6909871222642,
    "ttft": 2090813.1311954868,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 445,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.454865641072401,
    "arrivals": 1486263,
    "finished_requests": 90023,
    "scheduler_time": 175.94056548312835
}
#Debug simulation 
Total elapsed time: 72.13404270075262. Arrivals time: 0.4194575781002641 Scheduler time: 71.57195638492703 Scheduler overhead time: 0.05649148300290108 Adapter cache time: 0.014127782080322504 Engine time: 0.05120543669909239 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-16/adapters_384_slots_64_rate_3.2-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-16/adapters_384_slots_64_rate_3.2-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 270, 33, 34560, 34560, 33, 270, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 33, 34560, 33, 34560, 270, 270, 270, 33, 33, 270, 33, 34560, 33, 34560, 270, 34560, 270, 33, 270, 34560, 270, 34560, 33, 34560, 34560, 34560, 34560, 33, 270, 270, 270, 34560, 270, 33, 270, 33, 34560, 270, 34560, 34560, 270, 34560, 34560, 33, 33, 34560, 270, 270, 33, 33, 33, 270, 33, 270, 33, 34560, 33, 270, 34560, 33, 34560, 270, 33, 34560, 34560, 34560, 34560, 270, 33, 270, 34560, 34560, 270, 33, 33, 34560, 270, 270, 33, 33, 34560, 270, 34560, 270, 34560, 34560, 270, 34560, 34560, 33, 270, 270, 270, 270, 33, 33, 34560, 33, 34560, 33, 33, 33, 270, 270, 34560, 33, 33, 34560, 33, 34560, 270, 33, 34560, 270, 270, 33, 34560, 34560, 34560, 33, 270, 34560, 33, 34560, 270, 270, 34560, 34560, 33, 270, 34560, 33, 270, 270, 33, 270, 33, 270, 34560, 34560, 270, 33, 34560, 33, 34560, 270, 270, 270, 270, 270, 33, 33, 34560, 33, 34560, 33, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 33, 270, 270, 270, 270, 270, 270, 270, 270, 34560, 33, 33, 33, 33, 33, 270, 33, 33, 270, 34560, 34560, 33, 33, 34560, 33, 33, 33, 270, 33, 270, 34560, 34560, 270, 270, 33, 34560, 270, 34560, 33, 270, 270, 33, 33, 270, 33, 34560, 34560, 33, 34560, 34560, 33, 270, 34560, 33, 33, 270, 270, 33, 33, 34560, 34560, 34560, 34560, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 34560, 270, 270, 270, 34560, 33, 270, 270, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 270, 33, 34560, 34560, 34560, 270, 33, 34560, 34560, 270, 270, 34560, 34560, 33, 34560, 34560, 270, 33, 34560, 270, 270, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 270, 34560, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 34560, 33, 33, 33, 270, 33, 270, 270, 33, 34560, 270, 34560, 33, 34560, 33, 270, 270, 270, 270, 33, 270, 34560, 34560, 33, 34560, 34560, 33, 34560, 270, 34560, 270, 270, 270, 33, 270, 33, 33, 34560, 33, 270, 33, 33, 270, 34560, 270, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4462464 . Total input tokens: 994358162 . Total output tokens: 892094577
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 72.2790040881373,
    "estimated_duration": 3600.1199405865195,
    "input_throughput": 6187.166085464116,
    "output_throughput": 5461.5308168862575,
    "total_throughput": 11648.696902350373,
    "itl": 153.68950140057424,
    "ttft": 2090819.24242029,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 445,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.39431325090816,
    "arrivals": 1486263,
    "finished_requests": 90028,
    "scheduler_time": 175.94853540193262
}
#Debug simulation 
Total elapsed time: 72.27912053326145. Arrivals time: 0.430919396225363 Scheduler time: 71.70717301638797 Scheduler overhead time: 0.054889153223484755 Adapter cache time: 0.014554543420672417 Engine time: 0.05090199690312147 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-32/adapters_384_slots_64_rate_3.2-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-32/adapters_384_slots_64_rate_3.2-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 270, 33, 34560, 34560, 33, 270, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 33, 34560, 33, 34560, 270, 270, 270, 33, 33, 270, 33, 34560, 33, 34560, 270, 34560, 270, 33, 270, 34560, 270, 34560, 33, 34560, 34560, 34560, 34560, 33, 270, 270, 270, 34560, 270, 33, 270, 33, 34560, 270, 34560, 34560, 270, 34560, 34560, 33, 33, 34560, 270, 270, 33, 33, 33, 270, 33, 270, 33, 34560, 33, 270, 34560, 33, 34560, 270, 33, 34560, 34560, 34560, 34560, 270, 33, 270, 34560, 34560, 270, 33, 33, 34560, 270, 270, 33, 33, 34560, 270, 34560, 270, 34560, 34560, 270, 34560, 34560, 33, 270, 270, 270, 270, 33, 33, 34560, 33, 34560, 33, 33, 33, 270, 270, 34560, 33, 33, 34560, 33, 34560, 270, 33, 34560, 270, 270, 33, 34560, 34560, 34560, 33, 270, 34560, 33, 34560, 270, 270, 34560, 34560, 33, 270, 34560, 33, 270, 270, 33, 270, 33, 270, 34560, 34560, 270, 33, 34560, 33, 34560, 270, 270, 270, 270, 270, 33, 33, 34560, 33, 34560, 33, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 33, 270, 270, 270, 270, 270, 270, 270, 270, 34560, 33, 33, 33, 33, 33, 270, 33, 33, 270, 34560, 34560, 33, 33, 34560, 33, 33, 33, 270, 33, 270, 34560, 34560, 270, 270, 33, 34560, 270, 34560, 33, 270, 270, 33, 33, 270, 33, 34560, 34560, 33, 34560, 34560, 33, 270, 34560, 33, 33, 270, 270, 33, 33, 34560, 34560, 34560, 34560, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 34560, 270, 270, 270, 34560, 33, 270, 270, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 270, 33, 34560, 34560, 34560, 270, 33, 34560, 34560, 270, 270, 34560, 34560, 33, 34560, 34560, 270, 33, 34560, 270, 270, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 270, 34560, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 34560, 33, 33, 33, 270, 33, 270, 270, 33, 34560, 270, 34560, 33, 34560, 33, 270, 270, 270, 270, 33, 270, 34560, 34560, 33, 34560, 34560, 33, 34560, 270, 34560, 270, 270, 270, 33, 270, 33, 33, 34560, 33, 270, 33, 33, 270, 34560, 270, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4462464 . Total input tokens: 994358162 . Total output tokens: 892094577
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 72.03004146786407,
    "estimated_duration": 3600.025935243042,
    "input_throughput": 6186.726818260093,
    "output_throughput": 5461.3948214994325,
    "total_throughput": 11648.121639759525,
    "itl": 153.69151225659164,
    "ttft": 2090819.9245074266,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 445,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.472722678743308,
    "arrivals": 1486263,
    "finished_requests": 90023,
    "scheduler_time": 175.94068778223954
}
#Debug simulation 
Total elapsed time: 72.03015655791387. Arrivals time: 0.42280483385547996 Scheduler time: 71.46646741125733 Scheduler overhead time: 0.05515846284106374 Adapter cache time: 0.014369440730661154 Engine time: 0.050354125909507275 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-16/adapters_384_slots_64_rate_3.2-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-16/adapters_384_slots_64_rate_3.2-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 270, 33, 34560, 34560, 33, 270, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 33, 34560, 33, 34560, 270, 270, 270, 33, 33, 270, 33, 34560, 33, 34560, 270, 34560, 270, 33, 270, 34560, 270, 34560, 33, 34560, 34560, 34560, 34560, 33, 270, 270, 270, 34560, 270, 33, 270, 33, 34560, 270, 34560, 34560, 270, 34560, 34560, 33, 33, 34560, 270, 270, 33, 33, 33, 270, 33, 270, 33, 34560, 33, 270, 34560, 33, 34560, 270, 33, 34560, 34560, 34560, 34560, 270, 33, 270, 34560, 34560, 270, 33, 33, 34560, 270, 270, 33, 33, 34560, 270, 34560, 270, 34560, 34560, 270, 34560, 34560, 33, 270, 270, 270, 270, 33, 33, 34560, 33, 34560, 33, 33, 33, 270, 270, 34560, 33, 33, 34560, 33, 34560, 270, 33, 34560, 270, 270, 33, 34560, 34560, 34560, 33, 270, 34560, 33, 34560, 270, 270, 34560, 34560, 33, 270, 34560, 33, 270, 270, 33, 270, 33, 270, 34560, 34560, 270, 33, 34560, 33, 34560, 270, 270, 270, 270, 270, 33, 33, 34560, 33, 34560, 33, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 33, 270, 270, 270, 270, 270, 270, 270, 270, 34560, 33, 33, 33, 33, 33, 270, 33, 33, 270, 34560, 34560, 33, 33, 34560, 33, 33, 33, 270, 33, 270, 34560, 34560, 270, 270, 33, 34560, 270, 34560, 33, 270, 270, 33, 33, 270, 33, 34560, 34560, 33, 34560, 34560, 33, 270, 34560, 33, 33, 270, 270, 33, 33, 34560, 34560, 34560, 34560, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 34560, 270, 270, 270, 34560, 33, 270, 270, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 270, 33, 34560, 34560, 34560, 270, 33, 34560, 34560, 270, 270, 34560, 34560, 33, 34560, 34560, 270, 33, 34560, 270, 270, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 270, 34560, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 34560, 33, 33, 33, 270, 33, 270, 270, 33, 34560, 270, 34560, 33, 34560, 33, 270, 270, 270, 270, 33, 270, 34560, 34560, 33, 34560, 34560, 33, 34560, 270, 34560, 270, 270, 270, 33, 270, 33, 33, 34560, 33, 270, 33, 33, 270, 34560, 270, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4462464 . Total input tokens: 994358162 . Total output tokens: 892094577
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 72.19697573594749,
    "estimated_duration": 3600.0557813443806,
    "input_throughput": 6187.276351501961,
    "output_throughput": 5461.628150844233,
    "total_throughput": 11648.904502346193,
    "itl": 153.68752521442093,
    "ttft": 2090795.1766489986,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 445,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3305723812314578,
    "arrivals": 1486263,
    "finished_requests": 90028,
    "scheduler_time": 175.94811702945077
}
#Debug simulation 
Total elapsed time: 72.19709183601663. Arrivals time: 0.4092701436020434 Scheduler time: 71.64804072212428 Scheduler overhead time: 0.054597706999629736 Adapter cache time: 0.01415477879345417 Engine time: 0.05053454963490367 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-32/adapters_384_slots_64_rate_3.2-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-32/adapters_384_slots_64_rate_3.2-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 270, 33, 34560, 34560, 33, 270, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 33, 34560, 33, 34560, 270, 270, 270, 33, 33, 270, 33, 34560, 33, 34560, 270, 34560, 270, 33, 270, 34560, 270, 34560, 33, 34560, 34560, 34560, 34560, 33, 270, 270, 270, 34560, 270, 33, 270, 33, 34560, 270, 34560, 34560, 270, 34560, 34560, 33, 33, 34560, 270, 270, 33, 33, 33, 270, 33, 270, 33, 34560, 33, 270, 34560, 33, 34560, 270, 33, 34560, 34560, 34560, 34560, 270, 33, 270, 34560, 34560, 270, 33, 33, 34560, 270, 270, 33, 33, 34560, 270, 34560, 270, 34560, 34560, 270, 34560, 34560, 33, 270, 270, 270, 270, 33, 33, 34560, 33, 34560, 33, 33, 33, 270, 270, 34560, 33, 33, 34560, 33, 34560, 270, 33, 34560, 270, 270, 33, 34560, 34560, 34560, 33, 270, 34560, 33, 34560, 270, 270, 34560, 34560, 33, 270, 34560, 33, 270, 270, 33, 270, 33, 270, 34560, 34560, 270, 33, 34560, 33, 34560, 270, 270, 270, 270, 270, 33, 33, 34560, 33, 34560, 33, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 33, 270, 270, 270, 270, 270, 270, 270, 270, 34560, 33, 33, 33, 33, 33, 270, 33, 33, 270, 34560, 34560, 33, 33, 34560, 33, 33, 33, 270, 33, 270, 34560, 34560, 270, 270, 33, 34560, 270, 34560, 33, 270, 270, 33, 33, 270, 33, 34560, 34560, 33, 34560, 34560, 33, 270, 34560, 33, 33, 270, 270, 33, 33, 34560, 34560, 34560, 34560, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 34560, 270, 270, 270, 34560, 33, 270, 270, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 270, 33, 34560, 34560, 34560, 270, 33, 34560, 34560, 270, 270, 34560, 34560, 33, 34560, 34560, 270, 33, 34560, 270, 270, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 270, 34560, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 34560, 33, 33, 33, 270, 33, 270, 270, 33, 34560, 270, 34560, 33, 34560, 33, 270, 270, 270, 270, 33, 270, 34560, 34560, 33, 34560, 34560, 33, 34560, 270, 34560, 270, 270, 270, 33, 270, 33, 33, 34560, 33, 270, 33, 33, 270, 34560, 270, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4462464 . Total input tokens: 994358162 . Total output tokens: 892094577
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 72.08266347507015,
    "estimated_duration": 3600.045671847164,
    "input_throughput": 6186.692900640942,
    "output_throughput": 5461.364880382743,
    "total_throughput": 11648.057781023685,
    "itl": 153.6921201542452,
    "ttft": 2090827.3231739071,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 445,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4923402694240215,
    "arrivals": 1486263,
    "finished_requests": 90023,
    "scheduler_time": 175.94080679570294
}
#Debug simulation 
Total elapsed time: 72.08277864009142. Arrivals time: 0.40687769232317805 Scheduler time: 71.53415788337588 Scheduler overhead time: 0.05541324149817228 Adapter cache time: 0.01463918574154377 Engine time: 0.05114526441320777 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-8/adapters_384_slots_64_rate_3.2-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-8/adapters_384_slots_64_rate_3.2-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 135, 66, 34560, 34560, 66, 135, 34560, 34560, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 66, 34560, 66, 34560, 135, 135, 135, 66, 66, 135, 66, 34560, 66, 34560, 135, 34560, 135, 66, 135, 34560, 135, 34560, 66, 34560, 34560, 34560, 34560, 66, 135, 135, 135, 34560, 135, 66, 135, 66, 34560, 135, 34560, 34560, 135, 34560, 34560, 66, 66, 34560, 135, 135, 66, 66, 66, 135, 66, 135, 66, 34560, 66, 135, 34560, 66, 34560, 135, 66, 34560, 34560, 34560, 34560, 135, 66, 135, 34560, 34560, 135, 66, 66, 34560, 135, 135, 66, 66, 34560, 135, 34560, 135, 34560, 34560, 135, 34560, 34560, 66, 135, 135, 135, 135, 66, 66, 34560, 66, 34560, 66, 66, 66, 135, 135, 34560, 66, 66, 34560, 66, 34560, 135, 66, 34560, 135, 135, 66, 34560, 34560, 34560, 66, 135, 34560, 66, 34560, 135, 135, 34560, 34560, 66, 135, 34560, 66, 135, 135, 66, 135, 66, 135, 34560, 34560, 135, 66, 34560, 66, 34560, 135, 135, 135, 135, 135, 66, 66, 34560, 66, 34560, 66, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 66, 135, 135, 135, 135, 135, 135, 135, 135, 34560, 66, 66, 66, 66, 66, 135, 66, 66, 135, 34560, 34560, 66, 66, 34560, 66, 66, 66, 135, 66, 135, 34560, 34560, 135, 135, 66, 34560, 135, 34560, 66, 135, 135, 66, 66, 135, 66, 34560, 34560, 66, 34560, 34560, 66, 135, 34560, 66, 66, 135, 135, 66, 66, 34560, 34560, 34560, 34560, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 34560, 135, 135, 135, 34560, 66, 135, 135, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 135, 66, 34560, 34560, 34560, 135, 66, 34560, 34560, 135, 135, 34560, 34560, 66, 34560, 34560, 135, 66, 34560, 135, 135, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 135, 34560, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 34560, 66, 66, 66, 135, 66, 135, 135, 66, 34560, 135, 34560, 66, 34560, 66, 135, 135, 135, 135, 66, 135, 34560, 34560, 66, 34560, 34560, 66, 34560, 135, 34560, 135, 135, 135, 66, 135, 66, 66, 34560, 66, 135, 66, 66, 135, 34560, 135, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4449408 . Total input tokens: 991485117 . Total output tokens: 889450721
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 73.45421472284943,
    "estimated_duration": 3600.074049539984,
    "input_throughput": 6198.1613969443915,
    "output_throughput": 5468.734734085735,
    "total_throughput": 11666.896131030126,
    "itl": 153.338852363042,
    "ttft": 2093205.6574713583,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 379,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.159924854950518,
    "arrivals": 1482016,
    "finished_requests": 90219,
    "scheduler_time": 175.7876110063634
}
#Debug simulation 
Total elapsed time: 73.45432847272605. Arrivals time: 0.4054444213397801 Scheduler time: 72.90809080423787 Scheduler overhead time: 0.05497587285935879 Adapter cache time: 0.013954283203929663 Engine time: 0.05090368026867509 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-16/adapters_384_slots_64_rate_3.2-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-16/adapters_384_slots_64_rate_3.2-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 135, 66, 34560, 34560, 66, 135, 34560, 34560, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 66, 34560, 66, 34560, 135, 135, 135, 66, 66, 135, 66, 34560, 66, 34560, 135, 34560, 135, 66, 135, 34560, 135, 34560, 66, 34560, 34560, 34560, 34560, 66, 135, 135, 135, 34560, 135, 66, 135, 66, 34560, 135, 34560, 34560, 135, 34560, 34560, 66, 66, 34560, 135, 135, 66, 66, 66, 135, 66, 135, 66, 34560, 66, 135, 34560, 66, 34560, 135, 66, 34560, 34560, 34560, 34560, 135, 66, 135, 34560, 34560, 135, 66, 66, 34560, 135, 135, 66, 66, 34560, 135, 34560, 135, 34560, 34560, 135, 34560, 34560, 66, 135, 135, 135, 135, 66, 66, 34560, 66, 34560, 66, 66, 66, 135, 135, 34560, 66, 66, 34560, 66, 34560, 135, 66, 34560, 135, 135, 66, 34560, 34560, 34560, 66, 135, 34560, 66, 34560, 135, 135, 34560, 34560, 66, 135, 34560, 66, 135, 135, 66, 135, 66, 135, 34560, 34560, 135, 66, 34560, 66, 34560, 135, 135, 135, 135, 135, 66, 66, 34560, 66, 34560, 66, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 66, 135, 135, 135, 135, 135, 135, 135, 135, 34560, 66, 66, 66, 66, 66, 135, 66, 66, 135, 34560, 34560, 66, 66, 34560, 66, 66, 66, 135, 66, 135, 34560, 34560, 135, 135, 66, 34560, 135, 34560, 66, 135, 135, 66, 66, 135, 66, 34560, 34560, 66, 34560, 34560, 66, 135, 34560, 66, 66, 135, 135, 66, 66, 34560, 34560, 34560, 34560, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 34560, 135, 135, 135, 34560, 66, 135, 135, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 135, 66, 34560, 34560, 34560, 135, 66, 34560, 34560, 135, 135, 34560, 34560, 66, 34560, 34560, 135, 66, 34560, 135, 135, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 135, 34560, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 34560, 66, 66, 66, 135, 66, 135, 135, 66, 34560, 135, 34560, 66, 34560, 66, 135, 135, 135, 135, 66, 135, 34560, 34560, 66, 34560, 34560, 66, 34560, 135, 34560, 135, 135, 135, 66, 135, 66, 66, 34560, 66, 135, 66, 66, 135, 34560, 135, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4449408 . Total input tokens: 991485117 . Total output tokens: 889450721
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 73.91191845573485,
    "estimated_duration": 3600.137762074428,
    "input_throughput": 6207.827165792209,
    "output_throughput": 5478.828951432837,
    "total_throughput": 11686.656117225046,
    "itl": 153.53282436339447,
    "ttft": 2094412.177776675,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 376,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2268163358117505,
    "arrivals": 1482016,
    "finished_requests": 90407,
    "scheduler_time": 175.26618579823182
}
#Debug simulation 
Total elapsed time: 73.91204011067748. Arrivals time: 0.40741520607843995 Scheduler time: 73.36472042556852 Scheduler overhead time: 0.05511900642886758 Adapter cache time: 0.013555684592574835 Engine time: 0.05063066491857171 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-32/adapters_384_slots_64_rate_3.2-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-32/adapters_384_slots_64_rate_3.2-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 135, 66, 34560, 34560, 66, 135, 34560, 34560, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 66, 34560, 66, 34560, 135, 135, 135, 66, 66, 135, 66, 34560, 66, 34560, 135, 34560, 135, 66, 135, 34560, 135, 34560, 66, 34560, 34560, 34560, 34560, 66, 135, 135, 135, 34560, 135, 66, 135, 66, 34560, 135, 34560, 34560, 135, 34560, 34560, 66, 66, 34560, 135, 135, 66, 66, 66, 135, 66, 135, 66, 34560, 66, 135, 34560, 66, 34560, 135, 66, 34560, 34560, 34560, 34560, 135, 66, 135, 34560, 34560, 135, 66, 66, 34560, 135, 135, 66, 66, 34560, 135, 34560, 135, 34560, 34560, 135, 34560, 34560, 66, 135, 135, 135, 135, 66, 66, 34560, 66, 34560, 66, 66, 66, 135, 135, 34560, 66, 66, 34560, 66, 34560, 135, 66, 34560, 135, 135, 66, 34560, 34560, 34560, 66, 135, 34560, 66, 34560, 135, 135, 34560, 34560, 66, 135, 34560, 66, 135, 135, 66, 135, 66, 135, 34560, 34560, 135, 66, 34560, 66, 34560, 135, 135, 135, 135, 135, 66, 66, 34560, 66, 34560, 66, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 66, 135, 135, 135, 135, 135, 135, 135, 135, 34560, 66, 66, 66, 66, 66, 135, 66, 66, 135, 34560, 34560, 66, 66, 34560, 66, 66, 66, 135, 66, 135, 34560, 34560, 135, 135, 66, 34560, 135, 34560, 66, 135, 135, 66, 66, 135, 66, 34560, 34560, 66, 34560, 34560, 66, 135, 34560, 66, 66, 135, 135, 66, 66, 34560, 34560, 34560, 34560, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 34560, 135, 135, 135, 34560, 66, 135, 135, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 135, 66, 34560, 34560, 34560, 135, 66, 34560, 34560, 135, 135, 34560, 34560, 66, 34560, 34560, 135, 66, 34560, 135, 135, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 135, 34560, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 34560, 66, 66, 66, 135, 66, 135, 135, 66, 34560, 135, 34560, 66, 34560, 66, 135, 135, 135, 135, 66, 135, 34560, 34560, 66, 34560, 34560, 66, 34560, 135, 34560, 135, 135, 135, 66, 135, 66, 66, 34560, 66, 135, 66, 66, 135, 34560, 135, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4449408 . Total input tokens: 991485117 . Total output tokens: 889450721
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 74.51831951597705,
    "estimated_duration": 3600.1399672562384,
    "input_throughput": 6207.823363332395,
    "output_throughput": 5478.825595503886,
    "total_throughput": 11686.64895883628,
    "itl": 153.53288919384877,
    "ttft": 2094412.7291323426,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 376,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.229012208264328,
    "arrivals": 1482016,
    "finished_requests": 90407,
    "scheduler_time": 175.26619510756714
}
#Debug simulation 
Total elapsed time: 74.51843144092709. Arrivals time: 0.4251563320867717 Scheduler time: 73.95351577550173 Scheduler overhead time: 0.05480050155892968 Adapter cache time: 0.013556059449911118 Engine time: 0.050692257937043905 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-16/adapters_384_slots_64_rate_3.2-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-16/adapters_384_slots_64_rate_3.2-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 135, 66, 34560, 34560, 66, 135, 34560, 34560, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 66, 34560, 66, 34560, 135, 135, 135, 66, 66, 135, 66, 34560, 66, 34560, 135, 34560, 135, 66, 135, 34560, 135, 34560, 66, 34560, 34560, 34560, 34560, 66, 135, 135, 135, 34560, 135, 66, 135, 66, 34560, 135, 34560, 34560, 135, 34560, 34560, 66, 66, 34560, 135, 135, 66, 66, 66, 135, 66, 135, 66, 34560, 66, 135, 34560, 66, 34560, 135, 66, 34560, 34560, 34560, 34560, 135, 66, 135, 34560, 34560, 135, 66, 66, 34560, 135, 135, 66, 66, 34560, 135, 34560, 135, 34560, 34560, 135, 34560, 34560, 66, 135, 135, 135, 135, 66, 66, 34560, 66, 34560, 66, 66, 66, 135, 135, 34560, 66, 66, 34560, 66, 34560, 135, 66, 34560, 135, 135, 66, 34560, 34560, 34560, 66, 135, 34560, 66, 34560, 135, 135, 34560, 34560, 66, 135, 34560, 66, 135, 135, 66, 135, 66, 135, 34560, 34560, 135, 66, 34560, 66, 34560, 135, 135, 135, 135, 135, 66, 66, 34560, 66, 34560, 66, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 66, 135, 135, 135, 135, 135, 135, 135, 135, 34560, 66, 66, 66, 66, 66, 135, 66, 66, 135, 34560, 34560, 66, 66, 34560, 66, 66, 66, 135, 66, 135, 34560, 34560, 135, 135, 66, 34560, 135, 34560, 66, 135, 135, 66, 66, 135, 66, 34560, 34560, 66, 34560, 34560, 66, 135, 34560, 66, 66, 135, 135, 66, 66, 34560, 34560, 34560, 34560, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 34560, 135, 135, 135, 34560, 66, 135, 135, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 135, 66, 34560, 34560, 34560, 135, 66, 34560, 34560, 135, 135, 34560, 34560, 66, 34560, 34560, 135, 66, 34560, 135, 135, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 135, 34560, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 34560, 66, 66, 66, 135, 66, 135, 135, 66, 34560, 135, 34560, 66, 34560, 66, 135, 135, 135, 135, 66, 135, 34560, 34560, 66, 34560, 34560, 66, 34560, 135, 34560, 135, 135, 135, 66, 135, 66, 66, 34560, 66, 135, 66, 66, 135, 34560, 135, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4449408 . Total input tokens: 991485117 . Total output tokens: 889450721
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 74.61777334427461,
    "estimated_duration": 3600.08965596795,
    "input_throughput": 6207.910117724847,
    "output_throughput": 5478.902162145375,
    "total_throughput": 11686.812279870222,
    "itl": 153.53135699500604,
    "ttft": 2094394.6322342386,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 376,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1790106835542262,
    "arrivals": 1482016,
    "finished_requests": 90407,
    "scheduler_time": 175.2658853439975
}
#Debug simulation 
Total elapsed time: 74.61788869835436. Arrivals time: 0.4213881134055555 Scheduler time: 74.05574520863593 Scheduler overhead time: 0.05566689046099782 Adapter cache time: 0.013688171282410622 Engine time: 0.050643110647797585 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-32/adapters_384_slots_64_rate_3.2-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-32/adapters_384_slots_64_rate_3.2-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 135, 66, 34560, 34560, 66, 135, 34560, 34560, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 66, 34560, 66, 34560, 135, 135, 135, 66, 66, 135, 66, 34560, 66, 34560, 135, 34560, 135, 66, 135, 34560, 135, 34560, 66, 34560, 34560, 34560, 34560, 66, 135, 135, 135, 34560, 135, 66, 135, 66, 34560, 135, 34560, 34560, 135, 34560, 34560, 66, 66, 34560, 135, 135, 66, 66, 66, 135, 66, 135, 66, 34560, 66, 135, 34560, 66, 34560, 135, 66, 34560, 34560, 34560, 34560, 135, 66, 135, 34560, 34560, 135, 66, 66, 34560, 135, 135, 66, 66, 34560, 135, 34560, 135, 34560, 34560, 135, 34560, 34560, 66, 135, 135, 135, 135, 66, 66, 34560, 66, 34560, 66, 66, 66, 135, 135, 34560, 66, 66, 34560, 66, 34560, 135, 66, 34560, 135, 135, 66, 34560, 34560, 34560, 66, 135, 34560, 66, 34560, 135, 135, 34560, 34560, 66, 135, 34560, 66, 135, 135, 66, 135, 66, 135, 34560, 34560, 135, 66, 34560, 66, 34560, 135, 135, 135, 135, 135, 66, 66, 34560, 66, 34560, 66, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 66, 135, 135, 135, 135, 135, 135, 135, 135, 34560, 66, 66, 66, 66, 66, 135, 66, 66, 135, 34560, 34560, 66, 66, 34560, 66, 66, 66, 135, 66, 135, 34560, 34560, 135, 135, 66, 34560, 135, 34560, 66, 135, 135, 66, 66, 135, 66, 34560, 34560, 66, 34560, 34560, 66, 135, 34560, 66, 66, 135, 135, 66, 66, 34560, 34560, 34560, 34560, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 34560, 135, 135, 135, 34560, 66, 135, 135, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 135, 66, 34560, 34560, 34560, 135, 66, 34560, 34560, 135, 135, 34560, 34560, 66, 34560, 34560, 135, 66, 34560, 135, 135, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 135, 34560, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 34560, 66, 66, 66, 135, 66, 135, 135, 66, 34560, 135, 34560, 66, 34560, 66, 135, 135, 135, 135, 66, 135, 34560, 34560, 66, 34560, 34560, 66, 34560, 135, 34560, 135, 135, 135, 66, 135, 66, 66, 34560, 66, 135, 66, 66, 135, 34560, 135, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4449408 . Total input tokens: 991485117 . Total output tokens: 889450721
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 74.32301118783653,
    "estimated_duration": 3600.154772082295,
    "input_throughput": 6207.797835056278,
    "output_throughput": 5478.803065066982,
    "total_throughput": 11686.60090012326,
    "itl": 153.53334081644803,
    "ttft": 2094418.1284912701,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 376,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2437254012748655,
    "arrivals": 1482016,
    "finished_requests": 90407,
    "scheduler_time": 175.26628674063255
}
#Debug simulation 
Total elapsed time: 74.32312110811472. Arrivals time: 0.40017081145197153 Scheduler time: 73.78478909749538 Scheduler overhead time: 0.05381610710173845 Adapter cache time: 0.013270250055938959 Engine time: 0.05084359738975763 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-16/adapters_384_slots_64_rate_3.2-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-16/adapters_384_slots_64_rate_3.2-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 135, 66, 34560, 34560, 66, 135, 34560, 34560, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 66, 34560, 66, 34560, 135, 135, 135, 66, 66, 135, 66, 34560, 66, 34560, 135, 34560, 135, 66, 135, 34560, 135, 34560, 66, 34560, 34560, 34560, 34560, 66, 135, 135, 135, 34560, 135, 66, 135, 66, 34560, 135, 34560, 34560, 135, 34560, 34560, 66, 66, 34560, 135, 135, 66, 66, 66, 135, 66, 135, 66, 34560, 66, 135, 34560, 66, 34560, 135, 66, 34560, 34560, 34560, 34560, 135, 66, 135, 34560, 34560, 135, 66, 66, 34560, 135, 135, 66, 66, 34560, 135, 34560, 135, 34560, 34560, 135, 34560, 34560, 66, 135, 135, 135, 135, 66, 66, 34560, 66, 34560, 66, 66, 66, 135, 135, 34560, 66, 66, 34560, 66, 34560, 135, 66, 34560, 135, 135, 66, 34560, 34560, 34560, 66, 135, 34560, 66, 34560, 135, 135, 34560, 34560, 66, 135, 34560, 66, 135, 135, 66, 135, 66, 135, 34560, 34560, 135, 66, 34560, 66, 34560, 135, 135, 135, 135, 135, 66, 66, 34560, 66, 34560, 66, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 66, 135, 135, 135, 135, 135, 135, 135, 135, 34560, 66, 66, 66, 66, 66, 135, 66, 66, 135, 34560, 34560, 66, 66, 34560, 66, 66, 66, 135, 66, 135, 34560, 34560, 135, 135, 66, 34560, 135, 34560, 66, 135, 135, 66, 66, 135, 66, 34560, 34560, 66, 34560, 34560, 66, 135, 34560, 66, 66, 135, 135, 66, 66, 34560, 34560, 34560, 34560, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 34560, 135, 135, 135, 34560, 66, 135, 135, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 135, 66, 34560, 34560, 34560, 135, 66, 34560, 34560, 135, 135, 34560, 34560, 66, 34560, 34560, 135, 66, 34560, 135, 135, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 135, 34560, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 34560, 66, 66, 66, 135, 66, 135, 135, 66, 34560, 135, 34560, 66, 34560, 66, 135, 135, 135, 135, 66, 135, 34560, 34560, 66, 34560, 34560, 66, 34560, 135, 34560, 135, 135, 135, 66, 135, 66, 66, 34560, 66, 135, 66, 66, 135, 34560, 135, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4449408 . Total input tokens: 991485117 . Total output tokens: 889450721
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 72.62552849110216,
    "estimated_duration": 3600.0471650046493,
    "input_throughput": 6198.207683751605,
    "output_throughput": 5468.775573659623,
    "total_throughput": 11666.983257411228,
    "itl": 153.3381301454085,
    "ttft": 2093196.298063025,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 379,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1332290617679213,
    "arrivals": 1482016,
    "finished_requests": 90219,
    "scheduler_time": 175.787422264153
}
#Debug simulation 
Total elapsed time: 72.6256415550597. Arrivals time: 0.3476384379900992 Scheduler time: 72.14231834188104 Scheduler overhead time: 0.0526095163077116 Adapter cache time: 0.013079391326755285 Engine time: 0.050105891190469265 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-32/adapters_384_slots_64_rate_3.2-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-32/adapters_384_slots_64_rate_3.2-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 135, 66, 34560, 34560, 66, 135, 34560, 34560, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 66, 34560, 66, 34560, 135, 135, 135, 66, 66, 135, 66, 34560, 66, 34560, 135, 34560, 135, 66, 135, 34560, 135, 34560, 66, 34560, 34560, 34560, 34560, 66, 135, 135, 135, 34560, 135, 66, 135, 66, 34560, 135, 34560, 34560, 135, 34560, 34560, 66, 66, 34560, 135, 135, 66, 66, 66, 135, 66, 135, 66, 34560, 66, 135, 34560, 66, 34560, 135, 66, 34560, 34560, 34560, 34560, 135, 66, 135, 34560, 34560, 135, 66, 66, 34560, 135, 135, 66, 66, 34560, 135, 34560, 135, 34560, 34560, 135, 34560, 34560, 66, 135, 135, 135, 135, 66, 66, 34560, 66, 34560, 66, 66, 66, 135, 135, 34560, 66, 66, 34560, 66, 34560, 135, 66, 34560, 135, 135, 66, 34560, 34560, 34560, 66, 135, 34560, 66, 34560, 135, 135, 34560, 34560, 66, 135, 34560, 66, 135, 135, 66, 135, 66, 135, 34560, 34560, 135, 66, 34560, 66, 34560, 135, 135, 135, 135, 135, 66, 66, 34560, 66, 34560, 66, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 66, 135, 135, 135, 135, 135, 135, 135, 135, 34560, 66, 66, 66, 66, 66, 135, 66, 66, 135, 34560, 34560, 66, 66, 34560, 66, 66, 66, 135, 66, 135, 34560, 34560, 135, 135, 66, 34560, 135, 34560, 66, 135, 135, 66, 66, 135, 66, 34560, 34560, 66, 34560, 34560, 66, 135, 34560, 66, 66, 135, 135, 66, 66, 34560, 34560, 34560, 34560, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 34560, 135, 135, 135, 34560, 66, 135, 135, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 135, 66, 34560, 34560, 34560, 135, 66, 34560, 34560, 135, 135, 34560, 34560, 66, 34560, 34560, 135, 66, 34560, 135, 135, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 135, 34560, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 34560, 66, 66, 66, 135, 66, 135, 135, 66, 34560, 135, 34560, 66, 34560, 66, 135, 135, 135, 135, 66, 135, 34560, 34560, 66, 34560, 34560, 66, 34560, 135, 34560, 135, 135, 135, 66, 135, 66, 66, 34560, 66, 135, 66, 66, 135, 34560, 135, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4449408 . Total input tokens: 991485117 . Total output tokens: 889450721
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 73.55607008608058,
    "estimated_duration": 3600.1717636423596,
    "input_throughput": 6207.768536407018,
    "output_throughput": 5478.777207019791,
    "total_throughput": 11686.545743426808,
    "itl": 153.5338185311088,
    "ttft": 2094424.302442801,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 376,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.260576408654454,
    "arrivals": 1482016,
    "finished_requests": 90407,
    "scheduler_time": 175.2664272933424
}
#Debug simulation 
Total elapsed time: 73.55618042498827. Arrivals time: 0.3586304276250303 Scheduler time: 73.0618352163583 Scheduler overhead time: 0.05239401711151004 Adapter cache time: 0.013133473694324493 Engine time: 0.05006090272217989 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-8/adapters_384_slots_64_rate_3.2-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-8/adapters_384_slots_64_rate_3.2-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 135, 33, 34560, 34560, 33, 135, 34560, 34560, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 33, 34560, 33, 34560, 135, 135, 135, 33, 33, 135, 33, 34560, 33, 34560, 135, 34560, 135, 33, 135, 34560, 135, 34560, 33, 34560, 34560, 34560, 34560, 33, 135, 135, 135, 34560, 135, 33, 135, 33, 34560, 135, 34560, 34560, 135, 34560, 34560, 33, 33, 34560, 135, 135, 33, 33, 33, 135, 33, 135, 33, 34560, 33, 135, 34560, 33, 34560, 135, 33, 34560, 34560, 34560, 34560, 135, 33, 135, 34560, 34560, 135, 33, 33, 34560, 135, 135, 33, 33, 34560, 135, 34560, 135, 34560, 34560, 135, 34560, 34560, 33, 135, 135, 135, 135, 33, 33, 34560, 33, 34560, 33, 33, 33, 135, 135, 34560, 33, 33, 34560, 33, 34560, 135, 33, 34560, 135, 135, 33, 34560, 34560, 34560, 33, 135, 34560, 33, 34560, 135, 135, 34560, 34560, 33, 135, 34560, 33, 135, 135, 33, 135, 33, 135, 34560, 34560, 135, 33, 34560, 33, 34560, 135, 135, 135, 135, 135, 33, 33, 34560, 33, 34560, 33, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 33, 135, 135, 135, 135, 135, 135, 135, 135, 34560, 33, 33, 33, 33, 33, 135, 33, 33, 135, 34560, 34560, 33, 33, 34560, 33, 33, 33, 135, 33, 135, 34560, 34560, 135, 135, 33, 34560, 135, 34560, 33, 135, 135, 33, 33, 135, 33, 34560, 34560, 33, 34560, 34560, 33, 135, 34560, 33, 33, 135, 135, 33, 33, 34560, 34560, 34560, 34560, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 34560, 135, 135, 135, 34560, 33, 135, 135, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 135, 33, 34560, 34560, 34560, 135, 33, 34560, 34560, 135, 135, 34560, 34560, 33, 34560, 34560, 135, 33, 34560, 135, 135, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 135, 34560, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 34560, 33, 33, 33, 135, 33, 135, 135, 33, 34560, 135, 34560, 33, 34560, 33, 135, 135, 135, 135, 33, 135, 34560, 34560, 33, 34560, 34560, 33, 34560, 135, 34560, 135, 135, 135, 33, 135, 33, 33, 34560, 33, 135, 33, 33, 135, 34560, 135, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4445184 . Total input tokens: 990564360 . Total output tokens: 888598380
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 70.91221740981564,
    "estimated_duration": 3600.132257491726,
    "input_throughput": 6195.14101283021,
    "output_throughput": 5452.1144213950065,
    "total_throughput": 11647.255434225217,
    "itl": 153.83830957219504,
    "ttft": 2090527.049058724,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 366,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1201385142793907,
    "arrivals": 1480643,
    "finished_requests": 90037,
    "scheduler_time": 176.64651888737686
}
#Debug simulation 
Total elapsed time: 70.91232580505311. Arrivals time: 0.3480163449421525 Scheduler time: 70.4286550427787 Scheduler overhead time: 0.05255122156813741 Adapter cache time: 0.013001853134483099 Engine time: 0.04988749139010906 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-16/adapters_384_slots_64_rate_3.2-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-16/adapters_384_slots_64_rate_3.2-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 135, 33, 34560, 34560, 33, 135, 34560, 34560, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 33, 34560, 33, 34560, 135, 135, 135, 33, 33, 135, 33, 34560, 33, 34560, 135, 34560, 135, 33, 135, 34560, 135, 34560, 33, 34560, 34560, 34560, 34560, 33, 135, 135, 135, 34560, 135, 33, 135, 33, 34560, 135, 34560, 34560, 135, 34560, 34560, 33, 33, 34560, 135, 135, 33, 33, 33, 135, 33, 135, 33, 34560, 33, 135, 34560, 33, 34560, 135, 33, 34560, 34560, 34560, 34560, 135, 33, 135, 34560, 34560, 135, 33, 33, 34560, 135, 135, 33, 33, 34560, 135, 34560, 135, 34560, 34560, 135, 34560, 34560, 33, 135, 135, 135, 135, 33, 33, 34560, 33, 34560, 33, 33, 33, 135, 135, 34560, 33, 33, 34560, 33, 34560, 135, 33, 34560, 135, 135, 33, 34560, 34560, 34560, 33, 135, 34560, 33, 34560, 135, 135, 34560, 34560, 33, 135, 34560, 33, 135, 135, 33, 135, 33, 135, 34560, 34560, 135, 33, 34560, 33, 34560, 135, 135, 135, 135, 135, 33, 33, 34560, 33, 34560, 33, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 33, 135, 135, 135, 135, 135, 135, 135, 135, 34560, 33, 33, 33, 33, 33, 135, 33, 33, 135, 34560, 34560, 33, 33, 34560, 33, 33, 33, 135, 33, 135, 34560, 34560, 135, 135, 33, 34560, 135, 34560, 33, 135, 135, 33, 33, 135, 33, 34560, 34560, 33, 34560, 34560, 33, 135, 34560, 33, 33, 135, 135, 33, 33, 34560, 34560, 34560, 34560, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 34560, 135, 135, 135, 34560, 33, 135, 135, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 135, 33, 34560, 34560, 34560, 135, 33, 34560, 34560, 135, 135, 34560, 34560, 33, 34560, 34560, 135, 33, 34560, 135, 135, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 135, 34560, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 34560, 33, 33, 33, 135, 33, 135, 135, 33, 34560, 135, 34560, 33, 34560, 33, 135, 135, 135, 135, 33, 135, 34560, 34560, 33, 34560, 34560, 33, 34560, 135, 34560, 135, 135, 135, 33, 135, 33, 33, 34560, 33, 135, 33, 33, 135, 34560, 135, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4445184 . Total input tokens: 990564360 . Total output tokens: 888598380
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 70.74854531977326,
    "estimated_duration": 3600.037192724389,
    "input_throughput": 6193.837953970019,
    "output_throughput": 5453.5561576080245,
    "total_throughput": 11647.394111578044,
    "itl": 153.8829143879368,
    "ttft": 2090598.6941248216,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 354,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1598094433685824,
    "arrivals": 1480643,
    "finished_requests": 90048,
    "scheduler_time": 176.48673348420476
}
#Debug simulation 
Total elapsed time: 70.74865586590022. Arrivals time: 0.35770646994933486 Scheduler time: 70.25457861693576 Scheduler overhead time: 0.05316459946334362 Adapter cache time: 0.012769973836839199 Engine time: 0.05012005753815174 
