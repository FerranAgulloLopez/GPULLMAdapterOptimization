INFO 06-01 00:47:14 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:47:14 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-32/adapters_256_slots_128_rate_0.8-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-32/adapters_256_slots_128_rate_0.8-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 135, 8640, 8640, 135, 8640, 540, 8640, 135, 540, 135, 8640, 540, 540, 540, 540, 8640, 135, 135, 135, 540, 8640, 135, 8640, 8640, 540, 540, 540, 135, 8640, 135, 540, 540, 135, 540, 135, 135, 540, 540, 8640, 540, 135, 540, 8640, 540, 540, 8640, 540, 8640, 135, 8640, 8640, 540, 135, 135, 8640, 540, 135, 540, 540, 8640, 540, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 8640, 8640, 135, 8640, 135, 540, 8640, 8640, 8640, 540, 135, 8640, 540, 135, 135, 135, 135, 135, 8640, 540, 135, 8640, 135, 8640, 135, 135, 540, 540, 8640, 540, 8640, 135, 540, 135, 8640, 8640, 135, 8640, 540, 135, 8640, 135, 135, 8640, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 135, 540, 8640, 8640, 135, 8640, 540, 135, 540, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 540, 8640, 8640, 540, 135, 8640, 135, 540, 540, 135, 540, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 540, 8640, 540, 135, 540, 8640, 540, 8640, 135, 8640, 135, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 135, 8640, 135, 8640, 540, 540, 135, 540, 8640, 540, 540, 8640, 135, 8640, 8640, 540, 135, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 135, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 8640, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 8640, 540, 135, 135, 135, 135]
Prompts retrieved: 800415 . Total input tokens: 178436095 . Total output tokens: 160189560
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 4.959635230712593,
    "estimated_duration": 3600.057753287968,
    "input_throughput": 4444.858415225547,
    "output_throughput": 3927.2725519714936,
    "total_throughput": 8372.130967197041,
    "itl": 177.98773183554286,
    "ttft": 1986161.3957857185,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2682,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.865850388277034,
    "arrivals": 266663,
    "finished_requests": 64348,
    "scheduler_time": 94.73403125981619
}
#Debug simulation 
Total elapsed time: 4.9597403379157186. Arrivals time: 0.20909170527011156 Scheduler time: 4.618706109467894 Scheduler overhead time: 0.03231717552989721 Adapter cache time: 0.051367613952606916 Engine time: 0.033097339794039726 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-16/adapters_256_slots_128_rate_0.8-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-16/adapters_256_slots_128_rate_0.8-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 135, 8640, 8640, 135, 8640, 540, 8640, 135, 540, 135, 8640, 540, 540, 540, 540, 8640, 135, 135, 135, 540, 8640, 135, 8640, 8640, 540, 540, 540, 135, 8640, 135, 540, 540, 135, 540, 135, 135, 540, 540, 8640, 540, 135, 540, 8640, 540, 540, 8640, 540, 8640, 135, 8640, 8640, 540, 135, 135, 8640, 540, 135, 540, 540, 8640, 540, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 8640, 8640, 135, 8640, 135, 540, 8640, 8640, 8640, 540, 135, 8640, 540, 135, 135, 135, 135, 135, 8640, 540, 135, 8640, 135, 8640, 135, 135, 540, 540, 8640, 540, 8640, 135, 540, 135, 8640, 8640, 135, 8640, 540, 135, 8640, 135, 135, 8640, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 135, 540, 8640, 8640, 135, 8640, 540, 135, 540, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 540, 8640, 8640, 540, 135, 8640, 135, 540, 540, 135, 540, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 540, 8640, 540, 135, 540, 8640, 540, 8640, 135, 8640, 135, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 135, 8640, 135, 8640, 540, 540, 135, 540, 8640, 540, 540, 8640, 135, 8640, 8640, 540, 135, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 135, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 8640, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 8640, 540, 135, 135, 135, 135]
Prompts retrieved: 800415 . Total input tokens: 178436095 . Total output tokens: 160189560
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.392949357163161,
    "estimated_duration": 3600.057952700273,
    "input_throughput": 4636.940354662623,
    "output_throughput": 4092.296066775726,
    "total_throughput": 8729.236421438349,
    "itl": 209.78475446483398,
    "ttft": 1951520.8156015691,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1903,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.690065711198675,
    "arrivals": 266663,
    "finished_requests": 67136,
    "scheduler_time": 91.49969289760428
}
#Debug simulation 
Total elapsed time: 5.393078429158777. Arrivals time: 0.22274672146886587 Scheduler time: 5.0631398037076 Scheduler overhead time: 0.02845273818820715 Adapter cache time: 0.036817123647779226 Engine time: 0.028749458491802216 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-32/adapters_256_slots_128_rate_0.8-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-32/adapters_256_slots_128_rate_0.8-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 135, 8640, 8640, 135, 8640, 540, 8640, 135, 540, 135, 8640, 540, 540, 540, 540, 8640, 135, 135, 135, 540, 8640, 135, 8640, 8640, 540, 540, 540, 135, 8640, 135, 540, 540, 135, 540, 135, 135, 540, 540, 8640, 540, 135, 540, 8640, 540, 540, 8640, 540, 8640, 135, 8640, 8640, 540, 135, 135, 8640, 540, 135, 540, 540, 8640, 540, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 8640, 8640, 135, 8640, 135, 540, 8640, 8640, 8640, 540, 135, 8640, 540, 135, 135, 135, 135, 135, 8640, 540, 135, 8640, 135, 8640, 135, 135, 540, 540, 8640, 540, 8640, 135, 540, 135, 8640, 8640, 135, 8640, 540, 135, 8640, 135, 135, 8640, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 135, 540, 8640, 8640, 135, 8640, 540, 135, 540, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 540, 8640, 8640, 540, 135, 8640, 135, 540, 540, 135, 540, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 540, 8640, 540, 135, 540, 8640, 540, 8640, 135, 8640, 135, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 135, 8640, 135, 8640, 540, 540, 135, 540, 8640, 540, 540, 8640, 135, 8640, 8640, 540, 135, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 135, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 8640, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 8640, 540, 135, 135, 135, 135]
Prompts retrieved: 800415 . Total input tokens: 178436095 . Total output tokens: 160189560
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.954778871964663,
    "estimated_duration": 3600.1055212628767,
    "input_throughput": 4444.873603145575,
    "output_throughput": 3927.4129373408373,
    "total_throughput": 8372.286540486411,
    "itl": 177.9866395516043,
    "ttft": 1986224.3303220223,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2679,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.976803273371921,
    "arrivals": 266663,
    "finished_requests": 64349,
    "scheduler_time": 94.73317481032649
}
#Debug simulation 
Total elapsed time: 4.954867670312524. Arrivals time: 0.21527332300320268 Scheduler time: 4.607624513097107 Scheduler overhead time: 0.03239796496927738 Adapter cache time: 0.05160327488556504 Engine time: 0.03287240723147988 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-8/adapters_256_slots_128_rate_0.8-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-8/adapters_256_slots_128_rate_0.8-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 66, 8640, 8640, 66, 8640, 540, 8640, 66, 540, 66, 8640, 540, 540, 540, 540, 8640, 66, 66, 66, 540, 8640, 66, 8640, 8640, 540, 540, 540, 66, 8640, 66, 540, 540, 66, 540, 66, 66, 540, 540, 8640, 540, 66, 540, 8640, 540, 540, 8640, 540, 8640, 66, 8640, 8640, 540, 66, 66, 8640, 540, 66, 540, 540, 8640, 540, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 8640, 8640, 66, 8640, 66, 540, 8640, 8640, 8640, 540, 66, 8640, 540, 66, 66, 66, 66, 66, 8640, 540, 66, 8640, 66, 8640, 66, 66, 540, 540, 8640, 540, 8640, 66, 540, 66, 8640, 8640, 66, 8640, 540, 66, 8640, 66, 66, 8640, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 66, 540, 8640, 8640, 66, 8640, 540, 66, 540, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 540, 8640, 8640, 540, 66, 8640, 66, 540, 540, 66, 540, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 540, 8640, 540, 66, 540, 8640, 540, 8640, 66, 8640, 66, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 66, 8640, 66, 8640, 540, 540, 66, 540, 8640, 540, 540, 8640, 66, 8640, 8640, 540, 66, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 66, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 8640, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 8640, 540, 66, 66, 66, 66]
Prompts retrieved: 794550 . Total input tokens: 177125970 . Total output tokens: 159040310
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.156933887861669,
    "estimated_duration": 3600.0413583137583,
    "input_throughput": 4646.563840542995,
    "output_throughput": 4090.691337751157,
    "total_throughput": 8737.255178294152,
    "itl": 209.20286244161662,
    "ttft": 1946643.181440183,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2125,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.503536455857292,
    "arrivals": 264754,
    "finished_requests": 67585,
    "scheduler_time": 91.50265503319288
}
#Debug simulation 
Total elapsed time: 5.1570316972211. Arrivals time: 0.21319163590669632 Scheduler time: 4.8348550465889275 Scheduler overhead time: 0.02825532155111432 Adapter cache time: 0.039241233840584755 Engine time: 0.02849825145676732 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-16/adapters_256_slots_128_rate_0.8-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-16/adapters_256_slots_128_rate_0.8-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 66, 8640, 8640, 66, 8640, 540, 8640, 66, 540, 66, 8640, 540, 540, 540, 540, 8640, 66, 66, 66, 540, 8640, 66, 8640, 8640, 540, 540, 540, 66, 8640, 66, 540, 540, 66, 540, 66, 66, 540, 540, 8640, 540, 66, 540, 8640, 540, 540, 8640, 540, 8640, 66, 8640, 8640, 540, 66, 66, 8640, 540, 66, 540, 540, 8640, 540, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 8640, 8640, 66, 8640, 66, 540, 8640, 8640, 8640, 540, 66, 8640, 540, 66, 66, 66, 66, 66, 8640, 540, 66, 8640, 66, 8640, 66, 66, 540, 540, 8640, 540, 8640, 66, 540, 66, 8640, 8640, 66, 8640, 540, 66, 8640, 66, 66, 8640, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 66, 540, 8640, 8640, 66, 8640, 540, 66, 540, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 540, 8640, 8640, 540, 66, 8640, 66, 540, 540, 66, 540, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 540, 8640, 540, 66, 540, 8640, 540, 8640, 66, 8640, 66, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 66, 8640, 66, 8640, 540, 540, 66, 540, 8640, 540, 540, 8640, 66, 8640, 8640, 540, 66, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 66, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 8640, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 8640, 540, 66, 66, 66, 66]
Prompts retrieved: 794550 . Total input tokens: 177125970 . Total output tokens: 159040310
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.15394740505144,
    "estimated_duration": 3600.0906125098295,
    "input_throughput": 4645.921394833873,
    "output_throughput": 4090.022053565686,
    "total_throughput": 8735.94344839956,
    "itl": 209.2215645539788,
    "ttft": 1946721.7011810555,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2126,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.9382780651023825,
    "arrivals": 264754,
    "finished_requests": 67578,
    "scheduler_time": 91.49493840548706
}
#Debug simulation 
Total elapsed time: 5.154036420863122. Arrivals time: 0.21836986672133207 Scheduler time: 4.825839367695153 Scheduler overhead time: 0.028226989787071943 Adapter cache time: 0.039754156954586506 Engine time: 0.028676019050180912 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-32/adapters_256_slots_128_rate_0.8-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-32/adapters_256_slots_128_rate_0.8-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 66, 8640, 8640, 66, 8640, 540, 8640, 66, 540, 66, 8640, 540, 540, 540, 540, 8640, 66, 66, 66, 540, 8640, 66, 8640, 8640, 540, 540, 540, 66, 8640, 66, 540, 540, 66, 540, 66, 66, 540, 540, 8640, 540, 66, 540, 8640, 540, 540, 8640, 540, 8640, 66, 8640, 8640, 540, 66, 66, 8640, 540, 66, 540, 540, 8640, 540, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 8640, 8640, 66, 8640, 66, 540, 8640, 8640, 8640, 540, 66, 8640, 540, 66, 66, 66, 66, 66, 8640, 540, 66, 8640, 66, 8640, 66, 66, 540, 540, 8640, 540, 8640, 66, 540, 66, 8640, 8640, 66, 8640, 540, 66, 8640, 66, 66, 8640, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 66, 540, 8640, 8640, 66, 8640, 540, 66, 540, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 540, 8640, 8640, 540, 66, 8640, 66, 540, 540, 66, 540, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 540, 8640, 540, 66, 540, 8640, 540, 8640, 66, 8640, 66, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 66, 8640, 66, 8640, 540, 540, 66, 540, 8640, 540, 540, 8640, 66, 8640, 8640, 540, 66, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 66, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 8640, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 8640, 540, 66, 66, 66, 66]
Prompts retrieved: 794550 . Total input tokens: 177125970 . Total output tokens: 159040310
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.933528553228825,
    "estimated_duration": 3600.0813664882085,
    "input_throughput": 4505.525666999706,
    "output_throughput": 3973.6332442826347,
    "total_throughput": 8479.15891128234,
    "itl": 176.09681986978293,
    "ttft": 1971037.6058195832,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2618,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.559801698978864,
    "arrivals": 264754,
    "finished_requests": 65560,
    "scheduler_time": 95.72543925351493
}
#Debug simulation 
Total elapsed time: 4.933640378061682. Arrivals time: 0.21167477499693632 Scheduler time: 4.591272161807865 Scheduler overhead time: 0.03193620266392827 Adapter cache time: 0.050974251702427864 Engine time: 0.03267331048846245 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-16/adapters_256_slots_128_rate_0.8-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-16/adapters_256_slots_128_rate_0.8-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 66, 8640, 8640, 66, 8640, 540, 8640, 66, 540, 66, 8640, 540, 540, 540, 540, 8640, 66, 66, 66, 540, 8640, 66, 8640, 8640, 540, 540, 540, 66, 8640, 66, 540, 540, 66, 540, 66, 66, 540, 540, 8640, 540, 66, 540, 8640, 540, 540, 8640, 540, 8640, 66, 8640, 8640, 540, 66, 66, 8640, 540, 66, 540, 540, 8640, 540, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 8640, 8640, 66, 8640, 66, 540, 8640, 8640, 8640, 540, 66, 8640, 540, 66, 66, 66, 66, 66, 8640, 540, 66, 8640, 66, 8640, 66, 66, 540, 540, 8640, 540, 8640, 66, 540, 66, 8640, 8640, 66, 8640, 540, 66, 8640, 66, 66, 8640, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 66, 540, 8640, 8640, 66, 8640, 540, 66, 540, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 540, 8640, 8640, 540, 66, 8640, 66, 540, 540, 66, 540, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 540, 8640, 540, 66, 540, 8640, 540, 8640, 66, 8640, 66, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 66, 8640, 66, 8640, 540, 540, 66, 540, 8640, 540, 540, 8640, 66, 8640, 8640, 540, 66, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 66, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 8640, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 8640, 540, 66, 66, 66, 66]
Prompts retrieved: 794550 . Total input tokens: 177125970 . Total output tokens: 159040310
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.4055289956741035,
    "estimated_duration": 3600.2017968960786,
    "input_throughput": 4646.3567721181425,
    "output_throughput": 4090.509041103368,
    "total_throughput": 8736.86581322151,
    "itl": 209.20897396279938,
    "ttft": 1946712.6351608897,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2125,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.67542139227945,
    "arrivals": 264754,
    "finished_requests": 67585,
    "scheduler_time": 91.50392845146156
}
#Debug simulation 
Total elapsed time: 5.405621804762632. Arrivals time: 0.46312305331230164 Scheduler time: 4.833236197941005 Scheduler overhead time: 0.028195855673402548 Adapter cache time: 0.03946801694110036 Engine time: 0.0285158297047019 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-32/adapters_256_slots_128_rate_0.8-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-32/adapters_256_slots_128_rate_0.8-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 66, 8640, 8640, 66, 8640, 540, 8640, 66, 540, 66, 8640, 540, 540, 540, 540, 8640, 66, 66, 66, 540, 8640, 66, 8640, 8640, 540, 540, 540, 66, 8640, 66, 540, 540, 66, 540, 66, 66, 540, 540, 8640, 540, 66, 540, 8640, 540, 540, 8640, 540, 8640, 66, 8640, 8640, 540, 66, 66, 8640, 540, 66, 540, 540, 8640, 540, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 8640, 8640, 66, 8640, 66, 540, 8640, 8640, 8640, 540, 66, 8640, 540, 66, 66, 66, 66, 66, 8640, 540, 66, 8640, 66, 8640, 66, 66, 540, 540, 8640, 540, 8640, 66, 540, 66, 8640, 8640, 66, 8640, 540, 66, 8640, 66, 66, 8640, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 66, 540, 8640, 8640, 66, 8640, 540, 66, 540, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 540, 8640, 8640, 540, 66, 8640, 66, 540, 540, 66, 540, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 540, 8640, 540, 66, 540, 8640, 540, 8640, 66, 8640, 66, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 66, 8640, 66, 8640, 540, 540, 66, 540, 8640, 540, 540, 8640, 66, 8640, 8640, 540, 66, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 66, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 8640, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 8640, 540, 66, 66, 66, 66]
Prompts retrieved: 794550 . Total input tokens: 177125970 . Total output tokens: 159040310
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 4.946833275724202,
    "estimated_duration": 3600.0406796025027,
    "input_throughput": 4505.132425834359,
    "output_throughput": 3973.283713443863,
    "total_throughput": 8478.416139278223,
    "itl": 176.10208221626635,
    "ttft": 1971145.5798833526,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2620,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.663096413574861,
    "arrivals": 264754,
    "finished_requests": 65555,
    "scheduler_time": 95.72149251611162
}
#Debug simulation 
Total elapsed time: 4.946921236813068. Arrivals time: 0.205082505941391 Scheduler time: 4.611170035786927 Scheduler overhead time: 0.03198995441198349 Adapter cache time: 0.05098787508904934 Engine time: 0.032658116426318884 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-16/adapters_256_slots_128_rate_0.8-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-16/adapters_256_slots_128_rate_0.8-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 66, 8640, 8640, 66, 8640, 540, 8640, 66, 540, 66, 8640, 540, 540, 540, 540, 8640, 66, 66, 66, 540, 8640, 66, 8640, 8640, 540, 540, 540, 66, 8640, 66, 540, 540, 66, 540, 66, 66, 540, 540, 8640, 540, 66, 540, 8640, 540, 540, 8640, 540, 8640, 66, 8640, 8640, 540, 66, 66, 8640, 540, 66, 540, 540, 8640, 540, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 8640, 8640, 66, 8640, 66, 540, 8640, 8640, 8640, 540, 66, 8640, 540, 66, 66, 66, 66, 66, 8640, 540, 66, 8640, 66, 8640, 66, 66, 540, 540, 8640, 540, 8640, 66, 540, 66, 8640, 8640, 66, 8640, 540, 66, 8640, 66, 66, 8640, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 66, 540, 8640, 8640, 66, 8640, 540, 66, 540, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 540, 8640, 8640, 540, 66, 8640, 66, 540, 540, 66, 540, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 540, 8640, 540, 66, 540, 8640, 540, 8640, 66, 8640, 66, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 66, 8640, 66, 8640, 540, 540, 66, 540, 8640, 540, 540, 8640, 66, 8640, 8640, 540, 66, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 66, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 8640, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 8640, 540, 66, 66, 66, 66]
Prompts retrieved: 794550 . Total input tokens: 177125970 . Total output tokens: 159040310
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.1920859212987125,
    "estimated_duration": 3600.0915984281173,
    "input_throughput": 4646.698713806078,
    "output_throughput": 4090.7048049638815,
    "total_throughput": 8737.40351876996,
    "itl": 209.19710449534895,
    "ttft": 1946625.2226323946,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2125,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.353856876666934,
    "arrivals": 264754,
    "finished_requests": 67587,
    "scheduler_time": 91.50742535448106
}
#Debug simulation 
Total elapsed time: 5.1921748500317335. Arrivals time: 0.22771651623770595 Scheduler time: 4.854570193216205 Scheduler overhead time: 0.02855515806004405 Adapter cache time: 0.0395565084181726 Engine time: 0.028681727591902018 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-32/adapters_256_slots_128_rate_0.8-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-32/adapters_256_slots_128_rate_0.8-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 66, 8640, 8640, 66, 8640, 540, 8640, 66, 540, 66, 8640, 540, 540, 540, 540, 8640, 66, 66, 66, 540, 8640, 66, 8640, 8640, 540, 540, 540, 66, 8640, 66, 540, 540, 66, 540, 66, 66, 540, 540, 8640, 540, 66, 540, 8640, 540, 540, 8640, 540, 8640, 66, 8640, 8640, 540, 66, 66, 8640, 540, 66, 540, 540, 8640, 540, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 8640, 8640, 66, 8640, 66, 540, 8640, 8640, 8640, 540, 66, 8640, 540, 66, 66, 66, 66, 66, 8640, 540, 66, 8640, 66, 8640, 66, 66, 540, 540, 8640, 540, 8640, 66, 540, 66, 8640, 8640, 66, 8640, 540, 66, 8640, 66, 66, 8640, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 66, 540, 8640, 8640, 66, 8640, 540, 66, 540, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 540, 8640, 8640, 540, 66, 8640, 66, 540, 540, 66, 540, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 540, 8640, 540, 66, 540, 8640, 540, 8640, 66, 8640, 66, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 66, 8640, 66, 8640, 540, 540, 66, 540, 8640, 540, 540, 8640, 66, 8640, 8640, 540, 66, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 66, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 8640, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 8640, 540, 66, 66, 66, 66]
Prompts retrieved: 794550 . Total input tokens: 177125970 . Total output tokens: 159040310
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.958943096920848,
    "estimated_duration": 3600.0702229787516,
    "input_throughput": 4505.167953801808,
    "output_throughput": 3973.342216687207,
    "total_throughput": 8478.510170489015,
    "itl": 176.10361319781435,
    "ttft": 1971165.3405920647,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2617,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.7765300727259,
    "arrivals": 264754,
    "finished_requests": 65556,
    "scheduler_time": 95.71928529521013
}
#Debug simulation 
Total elapsed time: 4.959033884108067. Arrivals time: 0.20928481919690967 Scheduler time: 4.617783277761191 Scheduler overhead time: 0.0321996109560132 Adapter cache time: 0.051506387535482645 Engine time: 0.03308193804696202 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-8/adapters_256_slots_128_rate_0.8-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-8/adapters_256_slots_128_rate_0.8-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 33, 8640, 8640, 33, 8640, 540, 8640, 33, 540, 33, 8640, 540, 540, 540, 540, 8640, 33, 33, 33, 540, 8640, 33, 8640, 8640, 540, 540, 540, 33, 8640, 33, 540, 540, 33, 540, 33, 33, 540, 540, 8640, 540, 33, 540, 8640, 540, 540, 8640, 540, 8640, 33, 8640, 8640, 540, 33, 33, 8640, 540, 33, 540, 540, 8640, 540, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 8640, 8640, 33, 8640, 33, 540, 8640, 8640, 8640, 540, 33, 8640, 540, 33, 33, 33, 33, 33, 8640, 540, 33, 8640, 33, 8640, 33, 33, 540, 540, 8640, 540, 8640, 33, 540, 33, 8640, 8640, 33, 8640, 540, 33, 8640, 33, 33, 8640, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 33, 540, 8640, 8640, 33, 8640, 540, 33, 540, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 540, 8640, 8640, 540, 33, 8640, 33, 540, 540, 33, 540, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 540, 8640, 540, 33, 540, 8640, 540, 8640, 33, 8640, 33, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 33, 8640, 33, 8640, 540, 540, 33, 540, 8640, 540, 540, 8640, 33, 8640, 8640, 540, 33, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 33, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 8640, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 8640, 540, 33, 33, 33, 33]
Prompts retrieved: 791745 . Total input tokens: 176476708 . Total output tokens: 158497887
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.113021865021437,
    "estimated_duration": 3600.2311329150134,
    "input_throughput": 4671.44479870732,
    "output_throughput": 4094.092144596746,
    "total_throughput": 8765.536943304065,
    "itl": 208.77628956700627,
    "ttft": 1942944.3554442795,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2198,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.726952061164391,
    "arrivals": 263766,
    "finished_requests": 67681,
    "scheduler_time": 91.64399911495124
}
#Debug simulation 
Total elapsed time: 5.113109657075256. Arrivals time: 0.22517435997724533 Scheduler time: 4.77693582419306 Scheduler overhead time: 0.02809079270809889 Adapter cache time: 0.041353185661137104 Engine time: 0.02852690825238824 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-16/adapters_256_slots_128_rate_0.8-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-16/adapters_256_slots_128_rate_0.8-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 33, 8640, 8640, 33, 8640, 540, 8640, 33, 540, 33, 8640, 540, 540, 540, 540, 8640, 33, 33, 33, 540, 8640, 33, 8640, 8640, 540, 540, 540, 33, 8640, 33, 540, 540, 33, 540, 33, 33, 540, 540, 8640, 540, 33, 540, 8640, 540, 540, 8640, 540, 8640, 33, 8640, 8640, 540, 33, 33, 8640, 540, 33, 540, 540, 8640, 540, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 8640, 8640, 33, 8640, 33, 540, 8640, 8640, 8640, 540, 33, 8640, 540, 33, 33, 33, 33, 33, 8640, 540, 33, 8640, 33, 8640, 33, 33, 540, 540, 8640, 540, 8640, 33, 540, 33, 8640, 8640, 33, 8640, 540, 33, 8640, 33, 33, 8640, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 33, 540, 8640, 8640, 33, 8640, 540, 33, 540, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 540, 8640, 8640, 540, 33, 8640, 33, 540, 540, 33, 540, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 540, 8640, 540, 33, 540, 8640, 540, 8640, 33, 8640, 33, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 33, 8640, 33, 8640, 540, 540, 33, 540, 8640, 540, 540, 8640, 33, 8640, 8640, 540, 33, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 33, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 8640, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 8640, 540, 33, 33, 33, 33]
Prompts retrieved: 791745 . Total input tokens: 176476708 . Total output tokens: 158497887
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.110121322330087,
    "estimated_duration": 3600.0570722518155,
    "input_throughput": 4671.275388831864,
    "output_throughput": 4093.692045493535,
    "total_throughput": 8764.967434325397,
    "itl": 208.79984317298292,
    "ttft": 1942802.3045819378,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2197,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.171818592599312,
    "arrivals": 263766,
    "finished_requests": 67673,
    "scheduler_time": 91.62852443311834
}
#Debug simulation 
Total elapsed time: 5.110239610075951. Arrivals time: 0.21592796314507723 Scheduler time: 4.7836545733734965 Scheduler overhead time: 0.028111088555306196 Adapter cache time: 0.04110072599723935 Engine time: 0.028396427165716887 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-32/adapters_256_slots_128_rate_0.8-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-32/adapters_256_slots_128_rate_0.8-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 33, 8640, 8640, 33, 8640, 540, 8640, 33, 540, 33, 8640, 540, 540, 540, 540, 8640, 33, 33, 33, 540, 8640, 33, 8640, 8640, 540, 540, 540, 33, 8640, 33, 540, 540, 33, 540, 33, 33, 540, 540, 8640, 540, 33, 540, 8640, 540, 540, 8640, 540, 8640, 33, 8640, 8640, 540, 33, 33, 8640, 540, 33, 540, 540, 8640, 540, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 8640, 8640, 33, 8640, 33, 540, 8640, 8640, 8640, 540, 33, 8640, 540, 33, 33, 33, 33, 33, 8640, 540, 33, 8640, 33, 8640, 33, 33, 540, 540, 8640, 540, 8640, 33, 540, 33, 8640, 8640, 33, 8640, 540, 33, 8640, 33, 33, 8640, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 33, 540, 8640, 8640, 33, 8640, 540, 33, 540, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 540, 8640, 8640, 540, 33, 8640, 33, 540, 540, 33, 540, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 540, 8640, 540, 33, 540, 8640, 540, 8640, 33, 8640, 33, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 33, 8640, 33, 8640, 540, 540, 33, 540, 8640, 540, 540, 8640, 33, 8640, 8640, 540, 33, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 33, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 8640, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 8640, 540, 33, 33, 33, 33]
Prompts retrieved: 791745 . Total input tokens: 176476708 . Total output tokens: 158497887
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.989688133820891,
    "estimated_duration": 3600.151873782816,
    "input_throughput": 4560.166508406138,
    "output_throughput": 4004.987707601865,
    "total_throughput": 8565.154216008004,
    "itl": 174.4668894621364,
    "ttft": 1963604.3005004607,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2450,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.012405050471395,
    "arrivals": 263766,
    "finished_requests": 66096,
    "scheduler_time": 96.54903525954487
}
#Debug simulation 
Total elapsed time: 4.989779248833656. Arrivals time: 0.23339552991092205 Scheduler time: 4.624853138811886 Scheduler overhead time: 0.0323639577254653 Adapter cache time: 0.05081415455788374 Engine time: 0.03309279214590788 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-16/adapters_256_slots_128_rate_0.8-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-16/adapters_256_slots_128_rate_0.8-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 33, 8640, 8640, 33, 8640, 540, 8640, 33, 540, 33, 8640, 540, 540, 540, 540, 8640, 33, 33, 33, 540, 8640, 33, 8640, 8640, 540, 540, 540, 33, 8640, 33, 540, 540, 33, 540, 33, 33, 540, 540, 8640, 540, 33, 540, 8640, 540, 540, 8640, 540, 8640, 33, 8640, 8640, 540, 33, 33, 8640, 540, 33, 540, 540, 8640, 540, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 8640, 8640, 33, 8640, 33, 540, 8640, 8640, 8640, 540, 33, 8640, 540, 33, 33, 33, 33, 33, 8640, 540, 33, 8640, 33, 8640, 33, 33, 540, 540, 8640, 540, 8640, 33, 540, 33, 8640, 8640, 33, 8640, 540, 33, 8640, 33, 33, 8640, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 33, 540, 8640, 8640, 33, 8640, 540, 33, 540, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 540, 8640, 8640, 540, 33, 8640, 33, 540, 540, 33, 540, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 540, 8640, 540, 33, 540, 8640, 540, 8640, 33, 8640, 33, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 33, 8640, 33, 8640, 540, 540, 33, 540, 8640, 540, 540, 8640, 33, 8640, 8640, 540, 33, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 33, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 8640, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 8640, 540, 33, 33, 33, 33]
Prompts retrieved: 791745 . Total input tokens: 176476708 . Total output tokens: 158497887
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.126425284892321,
    "estimated_duration": 3600.01935450271,
    "input_throughput": 4671.563773390635,
    "output_throughput": 4093.9432677122027,
    "total_throughput": 8765.50704110284,
    "itl": 208.7876306628045,
    "ttft": 1942919.081685401,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2197,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.909908993479092,
    "arrivals": 263766,
    "finished_requests": 67676,
    "scheduler_time": 91.63386083707069
}
#Debug simulation 
Total elapsed time: 5.12651443714276. Arrivals time: 0.24821340339258313 Scheduler time: 4.767587841488421 Scheduler overhead time: 0.028224749490618706 Adapter cache time: 0.04082163982093334 Engine time: 0.028608500957489014 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-32/adapters_256_slots_128_rate_0.8-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-32/adapters_256_slots_128_rate_0.8-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 33, 8640, 8640, 33, 8640, 540, 8640, 33, 540, 33, 8640, 540, 540, 540, 540, 8640, 33, 33, 33, 540, 8640, 33, 8640, 8640, 540, 540, 540, 33, 8640, 33, 540, 540, 33, 540, 33, 33, 540, 540, 8640, 540, 33, 540, 8640, 540, 540, 8640, 540, 8640, 33, 8640, 8640, 540, 33, 33, 8640, 540, 33, 540, 540, 8640, 540, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 8640, 8640, 33, 8640, 33, 540, 8640, 8640, 8640, 540, 33, 8640, 540, 33, 33, 33, 33, 33, 8640, 540, 33, 8640, 33, 8640, 33, 33, 540, 540, 8640, 540, 8640, 33, 540, 33, 8640, 8640, 33, 8640, 540, 33, 8640, 33, 33, 8640, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 33, 540, 8640, 8640, 33, 8640, 540, 33, 540, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 540, 8640, 8640, 540, 33, 8640, 33, 540, 540, 33, 540, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 540, 8640, 540, 33, 540, 8640, 540, 8640, 33, 8640, 33, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 33, 8640, 33, 8640, 540, 540, 33, 540, 8640, 540, 540, 8640, 33, 8640, 8640, 540, 33, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 33, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 8640, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 8640, 540, 33, 33, 33, 33]
Prompts retrieved: 791745 . Total input tokens: 176476708 . Total output tokens: 158497887
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 4.984794138930738,
    "estimated_duration": 3600.1261771852237,
    "input_throughput": 4559.811015522475,
    "output_throughput": 4004.6726949087815,
    "total_throughput": 8564.483710431257,
    "itl": 174.46309397935025,
    "ttft": 1963631.3882076258,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2451,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.105528294257644,
    "arrivals": 263766,
    "finished_requests": 66093,
    "scheduler_time": 96.54757995205426
}
#Debug simulation 
Total elapsed time: 4.984898567199707. Arrivals time: 0.23581049917265773 Scheduler time: 4.618366023991257 Scheduler overhead time: 0.032086570747196674 Adapter cache time: 0.050547870341688395 Engine time: 0.032939058262854815 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-16/adapters_256_slots_128_rate_0.8-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-16/adapters_256_slots_128_rate_0.8-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 33, 8640, 8640, 33, 8640, 540, 8640, 33, 540, 33, 8640, 540, 540, 540, 540, 8640, 33, 33, 33, 540, 8640, 33, 8640, 8640, 540, 540, 540, 33, 8640, 33, 540, 540, 33, 540, 33, 33, 540, 540, 8640, 540, 33, 540, 8640, 540, 540, 8640, 540, 8640, 33, 8640, 8640, 540, 33, 33, 8640, 540, 33, 540, 540, 8640, 540, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 8640, 8640, 33, 8640, 33, 540, 8640, 8640, 8640, 540, 33, 8640, 540, 33, 33, 33, 33, 33, 8640, 540, 33, 8640, 33, 8640, 33, 33, 540, 540, 8640, 540, 8640, 33, 540, 33, 8640, 8640, 33, 8640, 540, 33, 8640, 33, 33, 8640, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 33, 540, 8640, 8640, 33, 8640, 540, 33, 540, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 540, 8640, 8640, 540, 33, 8640, 33, 540, 540, 33, 540, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 540, 8640, 540, 33, 540, 8640, 540, 8640, 33, 8640, 33, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 33, 8640, 33, 8640, 540, 540, 33, 540, 8640, 540, 540, 8640, 33, 8640, 8640, 540, 33, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 33, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 8640, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 8640, 540, 33, 33, 33, 33]
Prompts retrieved: 791745 . Total input tokens: 176476708 . Total output tokens: 158497887
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.12121546221897,
    "estimated_duration": 3600.0198617688343,
    "input_throughput": 4671.70505879835,
    "output_throughput": 4094.331855368655,
    "total_throughput": 8766.036914167005,
    "itl": 208.76831089186567,
    "ttft": 1942878.2686968867,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2198,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.572130548194785,
    "arrivals": 263766,
    "finished_requests": 67680,
    "scheduler_time": 91.64140279267338
}
#Debug simulation 
Total elapsed time: 5.121305183973163. Arrivals time: 0.21857550786808133 Scheduler time: 4.791610410902649 Scheduler overhead time: 0.028122028335928917 Adapter cache time: 0.0412475261837244 Engine time: 0.02868540585041046 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-32/adapters_256_slots_128_rate_0.8-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-32/adapters_256_slots_128_rate_0.8-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 33, 8640, 8640, 33, 8640, 540, 8640, 33, 540, 33, 8640, 540, 540, 540, 540, 8640, 33, 33, 33, 540, 8640, 33, 8640, 8640, 540, 540, 540, 33, 8640, 33, 540, 540, 33, 540, 33, 33, 540, 540, 8640, 540, 33, 540, 8640, 540, 540, 8640, 540, 8640, 33, 8640, 8640, 540, 33, 33, 8640, 540, 33, 540, 540, 8640, 540, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 8640, 8640, 33, 8640, 33, 540, 8640, 8640, 8640, 540, 33, 8640, 540, 33, 33, 33, 33, 33, 8640, 540, 33, 8640, 33, 8640, 33, 33, 540, 540, 8640, 540, 8640, 33, 540, 33, 8640, 8640, 33, 8640, 540, 33, 8640, 33, 33, 8640, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 33, 540, 8640, 8640, 33, 8640, 540, 33, 540, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 540, 8640, 8640, 540, 33, 8640, 33, 540, 540, 33, 540, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 540, 8640, 540, 33, 540, 8640, 540, 8640, 33, 8640, 33, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 33, 8640, 33, 8640, 540, 540, 33, 540, 8640, 540, 540, 8640, 33, 8640, 8640, 540, 33, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 33, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 8640, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 8640, 540, 33, 33, 33, 33]
Prompts retrieved: 791745 . Total input tokens: 176476708 . Total output tokens: 158497887
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.9986903187818825,
    "estimated_duration": 3600.072365826655,
    "input_throughput": 4559.049189065742,
    "output_throughput": 4004.408393798977,
    "total_throughput": 8563.45758286472,
    "itl": 174.4662346734454,
    "ttft": 1963710.5103529035,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2453,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.228314845747892,
    "arrivals": 263766,
    "finished_requests": 66087,
    "scheduler_time": 96.54440401990874
}
#Debug simulation 
Total elapsed time: 4.998777862638235. Arrivals time: 0.24231677129864693 Scheduler time: 4.626242772676051 Scheduler overhead time: 0.03208497678861022 Adapter cache time: 0.04997728206217289 Engine time: 0.03302864031866193 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-8/adapters_256_slots_128_rate_0.8-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-8/adapters_256_slots_128_rate_0.8-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 8640, 135, 8640, 8640, 135, 8640, 270, 8640, 135, 270, 135, 8640, 270, 270, 270, 270, 8640, 135, 135, 135, 270, 8640, 135, 8640, 8640, 270, 270, 270, 135, 8640, 135, 270, 270, 135, 270, 135, 135, 270, 270, 8640, 270, 135, 270, 8640, 270, 270, 8640, 270, 8640, 135, 8640, 8640, 270, 135, 135, 8640, 270, 135, 270, 270, 8640, 270, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 8640, 8640, 135, 8640, 135, 270, 8640, 8640, 8640, 270, 135, 8640, 270, 135, 135, 135, 135, 135, 8640, 270, 135, 8640, 135, 8640, 135, 135, 270, 270, 8640, 270, 8640, 135, 270, 135, 8640, 8640, 135, 8640, 270, 135, 8640, 135, 135, 8640, 8640, 270, 8640, 8640, 135, 8640, 270, 270, 135, 270, 8640, 8640, 135, 8640, 270, 135, 270, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 270, 8640, 8640, 270, 135, 8640, 135, 270, 270, 135, 270, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 270, 8640, 270, 135, 270, 8640, 270, 8640, 135, 8640, 135, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 270, 135, 8640, 135, 8640, 270, 270, 135, 270, 8640, 270, 270, 8640, 135, 8640, 8640, 270, 135, 8640, 8640, 270, 270, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 8640, 135, 8640, 270, 8640, 8640, 135, 8640, 270, 270, 8640, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 8640, 270, 135, 135, 135, 135]
Prompts retrieved: 777465 . Total input tokens: 173287228 . Total output tokens: 155617124
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.122712236829102,
    "estimated_duration": 3600.1140098010615,
    "input_throughput": 4718.360016864762,
    "output_throughput": 4176.99216165406,
    "total_throughput": 8895.35217851882,
    "itl": 205.82231276837004,
    "ttft": 1919981.365732437,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2311,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.072787176228804,
    "arrivals": 258949,
    "finished_requests": 68526,
    "scheduler_time": 93.19617201418744
}
#Debug simulation 
Total elapsed time: 5.122803564649075. Arrivals time: 0.22052512783557177 Scheduler time: 4.788490477949381 Scheduler overhead time: 0.028409237507730722 Adapter cache time: 0.04338965704664588 Engine time: 0.028704509139060974 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-16/adapters_256_slots_128_rate_0.8-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-16/adapters_256_slots_128_rate_0.8-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 8640, 135, 8640, 8640, 135, 8640, 270, 8640, 135, 270, 135, 8640, 270, 270, 270, 270, 8640, 135, 135, 135, 270, 8640, 135, 8640, 8640, 270, 270, 270, 135, 8640, 135, 270, 270, 135, 270, 135, 135, 270, 270, 8640, 270, 135, 270, 8640, 270, 270, 8640, 270, 8640, 135, 8640, 8640, 270, 135, 135, 8640, 270, 135, 270, 270, 8640, 270, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 8640, 8640, 135, 8640, 135, 270, 8640, 8640, 8640, 270, 135, 8640, 270, 135, 135, 135, 135, 135, 8640, 270, 135, 8640, 135, 8640, 135, 135, 270, 270, 8640, 270, 8640, 135, 270, 135, 8640, 8640, 135, 8640, 270, 135, 8640, 135, 135, 8640, 8640, 270, 8640, 8640, 135, 8640, 270, 270, 135, 270, 8640, 8640, 135, 8640, 270, 135, 270, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 270, 8640, 8640, 270, 135, 8640, 135, 270, 270, 135, 270, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 270, 8640, 270, 135, 270, 8640, 270, 8640, 135, 8640, 135, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 270, 135, 8640, 135, 8640, 270, 270, 135, 270, 8640, 270, 270, 8640, 135, 8640, 8640, 270, 135, 8640, 8640, 270, 270, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 8640, 135, 8640, 270, 8640, 8640, 135, 8640, 270, 270, 8640, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 8640, 270, 135, 135, 135, 135]
Prompts retrieved: 777465 . Total input tokens: 173287228 . Total output tokens: 155617124
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.1210338501259685,
    "estimated_duration": 3600.1950650129975,
    "input_throughput": 4717.8535310665675,
    "output_throughput": 4176.567860482225,
    "total_throughput": 8894.421391548793,
    "itl": 205.84856542901252,
    "ttft": 1920084.9195012713,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2309,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.536123088556027,
    "arrivals": 258949,
    "finished_requests": 68519,
    "scheduler_time": 93.18777450056503
}
#Debug simulation 
Total elapsed time: 5.121132995001972. Arrivals time: 0.22446346655488014 Scheduler time: 4.7830933830700815 Scheduler overhead time: 0.028055039700120687 Adapter cache time: 0.043532985262572765 Engine time: 0.0289296074770391 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-32/adapters_256_slots_128_rate_0.8-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-32/adapters_256_slots_128_rate_0.8-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 8640, 135, 8640, 8640, 135, 8640, 270, 8640, 135, 270, 135, 8640, 270, 270, 270, 270, 8640, 135, 135, 135, 270, 8640, 135, 8640, 8640, 270, 270, 270, 135, 8640, 135, 270, 270, 135, 270, 135, 135, 270, 270, 8640, 270, 135, 270, 8640, 270, 270, 8640, 270, 8640, 135, 8640, 8640, 270, 135, 135, 8640, 270, 135, 270, 270, 8640, 270, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 8640, 8640, 135, 8640, 135, 270, 8640, 8640, 8640, 270, 135, 8640, 270, 135, 135, 135, 135, 135, 8640, 270, 135, 8640, 135, 8640, 135, 135, 270, 270, 8640, 270, 8640, 135, 270, 135, 8640, 8640, 135, 8640, 270, 135, 8640, 135, 135, 8640, 8640, 270, 8640, 8640, 135, 8640, 270, 270, 135, 270, 8640, 8640, 135, 8640, 270, 135, 270, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 270, 8640, 8640, 270, 135, 8640, 135, 270, 270, 135, 270, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 270, 8640, 270, 135, 270, 8640, 270, 8640, 135, 8640, 135, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 270, 135, 8640, 135, 8640, 270, 270, 135, 270, 8640, 270, 270, 8640, 135, 8640, 8640, 270, 135, 8640, 8640, 270, 270, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 8640, 135, 8640, 270, 8640, 8640, 135, 8640, 270, 270, 8640, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 8640, 270, 135, 135, 135, 135]
Prompts retrieved: 777465 . Total input tokens: 173287228 . Total output tokens: 155617124
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.069252902176231,
    "estimated_duration": 3600.036958275749,
    "input_throughput": 4642.13095412337,
    "output_throughput": 4117.831614456585,
    "total_throughput": 8759.962568579956,
    "itl": 170.36582383302252,
    "ttft": 1934465.3037145897,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2292,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.493757352977953,
    "arrivals": 258949,
    "finished_requests": 67439,
    "scheduler_time": 98.95371430675311
}
#Debug simulation 
Total elapsed time: 5.069334520958364. Arrivals time: 0.20954977488145232 Scheduler time: 4.728941175621003 Scheduler overhead time: 0.032898195553570986 Adapter cache time: 0.048494561575353146 Engine time: 0.03395028132945299 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-16/adapters_256_slots_128_rate_0.8-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-16/adapters_256_slots_128_rate_0.8-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 8640, 135, 8640, 8640, 135, 8640, 270, 8640, 135, 270, 135, 8640, 270, 270, 270, 270, 8640, 135, 135, 135, 270, 8640, 135, 8640, 8640, 270, 270, 270, 135, 8640, 135, 270, 270, 135, 270, 135, 135, 270, 270, 8640, 270, 135, 270, 8640, 270, 270, 8640, 270, 8640, 135, 8640, 8640, 270, 135, 135, 8640, 270, 135, 270, 270, 8640, 270, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 8640, 8640, 135, 8640, 135, 270, 8640, 8640, 8640, 270, 135, 8640, 270, 135, 135, 135, 135, 135, 8640, 270, 135, 8640, 135, 8640, 135, 135, 270, 270, 8640, 270, 8640, 135, 270, 135, 8640, 8640, 135, 8640, 270, 135, 8640, 135, 135, 8640, 8640, 270, 8640, 8640, 135, 8640, 270, 270, 135, 270, 8640, 8640, 135, 8640, 270, 135, 270, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 270, 8640, 8640, 270, 135, 8640, 135, 270, 270, 135, 270, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 270, 8640, 270, 135, 270, 8640, 270, 8640, 135, 8640, 135, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 270, 135, 8640, 135, 8640, 270, 270, 135, 270, 8640, 270, 270, 8640, 135, 8640, 8640, 270, 135, 8640, 8640, 270, 270, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 8640, 135, 8640, 270, 8640, 8640, 135, 8640, 270, 270, 8640, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 8640, 270, 135, 135, 135, 135]
Prompts retrieved: 777465 . Total input tokens: 173287228 . Total output tokens: 155617124
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.143449211958796,
    "estimated_duration": 3600.076043651672,
    "input_throughput": 4718.265334965103,
    "output_throughput": 4176.93315854162,
    "total_throughput": 8895.198493506723,
    "itl": 205.8297064151447,
    "ttft": 1920010.3389399557,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2310,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.259633941037786,
    "arrivals": 258949,
    "finished_requests": 68525,
    "scheduler_time": 93.19165744310908
}
#Debug simulation 
Total elapsed time: 5.143542403820902. Arrivals time: 0.2206590441055596 Scheduler time: 4.809618167579174 Scheduler overhead time: 0.027962724212557077 Adapter cache time: 0.043430997990071774 Engine time: 0.028865591622889042 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-32/adapters_256_slots_128_rate_0.8-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-32/adapters_256_slots_128_rate_0.8-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 8640, 135, 8640, 8640, 135, 8640, 270, 8640, 135, 270, 135, 8640, 270, 270, 270, 270, 8640, 135, 135, 135, 270, 8640, 135, 8640, 8640, 270, 270, 270, 135, 8640, 135, 270, 270, 135, 270, 135, 135, 270, 270, 8640, 270, 135, 270, 8640, 270, 270, 8640, 270, 8640, 135, 8640, 8640, 270, 135, 135, 8640, 270, 135, 270, 270, 8640, 270, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 8640, 8640, 135, 8640, 135, 270, 8640, 8640, 8640, 270, 135, 8640, 270, 135, 135, 135, 135, 135, 8640, 270, 135, 8640, 135, 8640, 135, 135, 270, 270, 8640, 270, 8640, 135, 270, 135, 8640, 8640, 135, 8640, 270, 135, 8640, 135, 135, 8640, 8640, 270, 8640, 8640, 135, 8640, 270, 270, 135, 270, 8640, 8640, 135, 8640, 270, 135, 270, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 270, 8640, 8640, 270, 135, 8640, 135, 270, 270, 135, 270, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 270, 8640, 270, 135, 270, 8640, 270, 8640, 135, 8640, 135, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 270, 135, 8640, 135, 8640, 270, 270, 135, 270, 8640, 270, 270, 8640, 135, 8640, 8640, 270, 135, 8640, 8640, 270, 270, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 8640, 135, 8640, 270, 8640, 8640, 135, 8640, 270, 270, 8640, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 8640, 270, 135, 135, 135, 135]
Prompts retrieved: 777465 . Total input tokens: 173287228 . Total output tokens: 155617124
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 5.08619935112074,
    "estimated_duration": 3600.071332502033,
    "input_throughput": 4641.969132424285,
    "output_throughput": 4117.700076153041,
    "total_throughput": 8759.669208577325,
    "itl": 170.37397323040813,
    "ttft": 1934449.6045561905,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2291,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.575306118521693,
    "arrivals": 258949,
    "finished_requests": 67439,
    "scheduler_time": 98.95274211709578
}
#Debug simulation 
Total elapsed time: 5.086289570201188. Arrivals time: 0.21318281767889857 Scheduler time: 4.7428270052187145 Scheduler overhead time: 0.032800122164189816 Adapter cache time: 0.04795501567423344 Engine time: 0.03399654338136315 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-16/adapters_256_slots_128_rate_0.8-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-16/adapters_256_slots_128_rate_0.8-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 8640, 135, 8640, 8640, 135, 8640, 270, 8640, 135, 270, 135, 8640, 270, 270, 270, 270, 8640, 135, 135, 135, 270, 8640, 135, 8640, 8640, 270, 270, 270, 135, 8640, 135, 270, 270, 135, 270, 135, 135, 270, 270, 8640, 270, 135, 270, 8640, 270, 270, 8640, 270, 8640, 135, 8640, 8640, 270, 135, 135, 8640, 270, 135, 270, 270, 8640, 270, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 8640, 8640, 135, 8640, 135, 270, 8640, 8640, 8640, 270, 135, 8640, 270, 135, 135, 135, 135, 135, 8640, 270, 135, 8640, 135, 8640, 135, 135, 270, 270, 8640, 270, 8640, 135, 270, 135, 8640, 8640, 135, 8640, 270, 135, 8640, 135, 135, 8640, 8640, 270, 8640, 8640, 135, 8640, 270, 270, 135, 270, 8640, 8640, 135, 8640, 270, 135, 270, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 270, 8640, 8640, 270, 135, 8640, 135, 270, 270, 135, 270, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 270, 8640, 270, 135, 270, 8640, 270, 8640, 135, 8640, 135, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 270, 135, 8640, 135, 8640, 270, 270, 135, 270, 8640, 270, 270, 8640, 135, 8640, 8640, 270, 135, 8640, 8640, 270, 270, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 8640, 135, 8640, 270, 8640, 8640, 135, 8640, 270, 270, 8640, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 8640, 270, 135, 135, 135, 135]
Prompts retrieved: 777465 . Total input tokens: 173287228 . Total output tokens: 155617124
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.146348554175347,
    "estimated_duration": 3600.151935720257,
    "input_throughput": 4718.670018186704,
    "output_throughput": 4177.3023107124145,
    "total_throughput": 8895.972328899117,
    "itl": 205.81419934659934,
    "ttft": 1919929.7285833969,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2311,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.910006231518719,
    "arrivals": 258949,
    "finished_requests": 68530,
    "scheduler_time": 93.20171828219648
}
#Debug simulation 
Total elapsed time: 5.146438402123749. Arrivals time: 0.2307219160720706 Scheduler time: 4.802032784093171 Scheduler overhead time: 0.028060802724212408 Adapter cache time: 0.04361985856667161 Engine time: 0.028868683613836765 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-32/adapters_256_slots_128_rate_0.8-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-32/adapters_256_slots_128_rate_0.8-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 8640, 135, 8640, 8640, 135, 8640, 270, 8640, 135, 270, 135, 8640, 270, 270, 270, 270, 8640, 135, 135, 135, 270, 8640, 135, 8640, 8640, 270, 270, 270, 135, 8640, 135, 270, 270, 135, 270, 135, 135, 270, 270, 8640, 270, 135, 270, 8640, 270, 270, 8640, 270, 8640, 135, 8640, 8640, 270, 135, 135, 8640, 270, 135, 270, 270, 8640, 270, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 8640, 8640, 135, 8640, 135, 270, 8640, 8640, 8640, 270, 135, 8640, 270, 135, 135, 135, 135, 135, 8640, 270, 135, 8640, 135, 8640, 135, 135, 270, 270, 8640, 270, 8640, 135, 270, 135, 8640, 8640, 135, 8640, 270, 135, 8640, 135, 135, 8640, 8640, 270, 8640, 8640, 135, 8640, 270, 270, 135, 270, 8640, 8640, 135, 8640, 270, 135, 270, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 270, 8640, 8640, 270, 135, 8640, 135, 270, 270, 135, 270, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 270, 8640, 270, 135, 270, 8640, 270, 8640, 135, 8640, 135, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 270, 135, 8640, 135, 8640, 270, 270, 135, 270, 8640, 270, 270, 8640, 135, 8640, 8640, 270, 135, 8640, 8640, 270, 270, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 8640, 135, 8640, 270, 8640, 8640, 135, 8640, 270, 270, 8640, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 8640, 270, 135, 135, 135, 135]
Prompts retrieved: 777465 . Total input tokens: 173287228 . Total output tokens: 155617124
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.066371701657772,
    "estimated_duration": 3600.087979997991,
    "input_throughput": 4641.947389299448,
    "output_throughput": 4117.6402027842305,
    "total_throughput": 8759.587592083679,
    "itl": 170.38352733385932,
    "ttft": 1934493.562495149,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2294,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.693928209170396,
    "arrivals": 258949,
    "finished_requests": 67438,
    "scheduler_time": 98.94941060872178
}
#Debug simulation 
Total elapsed time: 5.066484960727394. Arrivals time: 0.21282334253191948 Scheduler time: 4.724113151431084 Scheduler overhead time: 0.03273176588118076 Adapter cache time: 0.04788727266713977 Engine time: 0.03349865414202213 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-8/adapters_256_slots_128_rate_0.8-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-8/adapters_256_slots_128_rate_0.8-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 8640, 66, 8640, 8640, 66, 8640, 270, 8640, 66, 270, 66, 8640, 270, 270, 270, 270, 8640, 66, 66, 66, 270, 8640, 66, 8640, 8640, 270, 270, 270, 66, 8640, 66, 270, 270, 66, 270, 66, 66, 270, 270, 8640, 270, 66, 270, 8640, 270, 270, 8640, 270, 8640, 66, 8640, 8640, 270, 66, 66, 8640, 270, 66, 270, 270, 8640, 270, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 8640, 8640, 66, 8640, 66, 270, 8640, 8640, 8640, 270, 66, 8640, 270, 66, 66, 66, 66, 66, 8640, 270, 66, 8640, 66, 8640, 66, 66, 270, 270, 8640, 270, 8640, 66, 270, 66, 8640, 8640, 66, 8640, 270, 66, 8640, 66, 66, 8640, 8640, 270, 8640, 8640, 66, 8640, 270, 270, 66, 270, 8640, 8640, 66, 8640, 270, 66, 270, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 270, 8640, 8640, 270, 66, 8640, 66, 270, 270, 66, 270, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 270, 8640, 270, 66, 270, 8640, 270, 8640, 66, 8640, 66, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 270, 66, 8640, 66, 8640, 270, 270, 66, 270, 8640, 270, 270, 8640, 66, 8640, 8640, 270, 66, 8640, 8640, 270, 270, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 8640, 66, 8640, 270, 8640, 8640, 66, 8640, 270, 270, 8640, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 8640, 270, 66, 66, 66, 66]
Prompts retrieved: 771600 . Total input tokens: 171990632 . Total output tokens: 154422380
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.197345071006566,
    "estimated_duration": 3600.098371903278,
    "input_throughput": 4855.5217647451655,
    "output_throughput": 4279.278622004805,
    "total_throughput": 9134.80038674997,
    "itl": 200.28709923146764,
    "ttft": 1901171.4173316553,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1906,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.8332896399359955,
    "arrivals": 257044,
    "finished_requests": 70442,
    "scheduler_time": 95.51247862927305
}
#Debug simulation 
Total elapsed time: 5.197433308232576. Arrivals time: 0.22013929206877947 Scheduler time: 4.867689697537571 Scheduler overhead time: 0.02848781179636717 Adapter cache time: 0.03860508929938078 Engine time: 0.029280415270477533 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-16/adapters_256_slots_128_rate_0.8-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-16/adapters_256_slots_128_rate_0.8-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 8640, 66, 8640, 8640, 66, 8640, 270, 8640, 66, 270, 66, 8640, 270, 270, 270, 270, 8640, 66, 66, 66, 270, 8640, 66, 8640, 8640, 270, 270, 270, 66, 8640, 66, 270, 270, 66, 270, 66, 66, 270, 270, 8640, 270, 66, 270, 8640, 270, 270, 8640, 270, 8640, 66, 8640, 8640, 270, 66, 66, 8640, 270, 66, 270, 270, 8640, 270, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 8640, 8640, 66, 8640, 66, 270, 8640, 8640, 8640, 270, 66, 8640, 270, 66, 66, 66, 66, 66, 8640, 270, 66, 8640, 66, 8640, 66, 66, 270, 270, 8640, 270, 8640, 66, 270, 66, 8640, 8640, 66, 8640, 270, 66, 8640, 66, 66, 8640, 8640, 270, 8640, 8640, 66, 8640, 270, 270, 66, 270, 8640, 8640, 66, 8640, 270, 66, 270, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 270, 8640, 8640, 270, 66, 8640, 66, 270, 270, 66, 270, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 270, 8640, 270, 66, 270, 8640, 270, 8640, 66, 8640, 66, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 270, 66, 8640, 66, 8640, 270, 270, 66, 270, 8640, 270, 270, 8640, 66, 8640, 8640, 270, 66, 8640, 8640, 270, 270, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 8640, 66, 8640, 270, 8640, 8640, 66, 8640, 270, 270, 8640, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 8640, 270, 66, 66, 66, 66]
Prompts retrieved: 771600 . Total input tokens: 171990632 . Total output tokens: 154422380
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.249003106262535,
    "estimated_duration": 3600.196907051138,
    "input_throughput": 4855.020281187004,
    "output_throughput": 4278.887626904232,
    "total_throughput": 9133.907908091236,
    "itl": 200.30758221573578,
    "ttft": 1901284.9996697612,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1907,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.219307585523731,
    "arrivals": 257044,
    "finished_requests": 70435,
    "scheduler_time": 95.50588771830968
}
#Debug simulation 
Total elapsed time: 5.249093889258802. Arrivals time: 0.2254747743718326 Scheduler time: 4.912856035865843 Scheduler overhead time: 0.028596218209713697 Adapter cache time: 0.038849337957799435 Engine time: 0.029717255849391222 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-32/adapters_256_slots_128_rate_0.8-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-32/adapters_256_slots_128_rate_0.8-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 8640, 66, 8640, 8640, 66, 8640, 270, 8640, 66, 270, 66, 8640, 270, 270, 270, 270, 8640, 66, 66, 66, 270, 8640, 66, 8640, 8640, 270, 270, 270, 66, 8640, 66, 270, 270, 66, 270, 66, 66, 270, 270, 8640, 270, 66, 270, 8640, 270, 270, 8640, 270, 8640, 66, 8640, 8640, 270, 66, 66, 8640, 270, 66, 270, 270, 8640, 270, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 8640, 8640, 66, 8640, 66, 270, 8640, 8640, 8640, 270, 66, 8640, 270, 66, 66, 66, 66, 66, 8640, 270, 66, 8640, 66, 8640, 66, 66, 270, 270, 8640, 270, 8640, 66, 270, 66, 8640, 8640, 66, 8640, 270, 66, 8640, 66, 66, 8640, 8640, 270, 8640, 8640, 66, 8640, 270, 270, 66, 270, 8640, 8640, 66, 8640, 270, 66, 270, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 270, 8640, 8640, 270, 66, 8640, 66, 270, 270, 66, 270, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 270, 8640, 270, 66, 270, 8640, 270, 8640, 66, 8640, 66, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 270, 66, 8640, 66, 8640, 270, 270, 66, 270, 8640, 270, 270, 8640, 66, 8640, 8640, 270, 66, 8640, 8640, 270, 270, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 8640, 66, 8640, 270, 8640, 8640, 66, 8640, 270, 270, 8640, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 8640, 270, 66, 66, 66, 66]
Prompts retrieved: 771600 . Total input tokens: 171990632 . Total output tokens: 154422380
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.186357464175671,
    "estimated_duration": 3600.1262943101233,
    "input_throughput": 4763.204287333488,
    "output_throughput": 4205.311636963321,
    "total_throughput": 8968.51592429681,
    "itl": 166.31962830257675,
    "ttft": 1919260.846014822,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1880,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.141351318880869,
    "arrivals": 257044,
    "finished_requests": 69102,
    "scheduler_time": 101.1068477417307
}
#Debug simulation 
Total elapsed time: 5.186446296051145. Arrivals time: 0.21696809493005276 Scheduler time: 4.843988147098571 Scheduler overhead time: 0.03341192379593849 Adapter cache time: 0.04195595346391201 Engine time: 0.03437778912484646 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-16/adapters_256_slots_128_rate_0.8-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-16/adapters_256_slots_128_rate_0.8-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 8640, 66, 8640, 8640, 66, 8640, 270, 8640, 66, 270, 66, 8640, 270, 270, 270, 270, 8640, 66, 66, 66, 270, 8640, 66, 8640, 8640, 270, 270, 270, 66, 8640, 66, 270, 270, 66, 270, 66, 66, 270, 270, 8640, 270, 66, 270, 8640, 270, 270, 8640, 270, 8640, 66, 8640, 8640, 270, 66, 66, 8640, 270, 66, 270, 270, 8640, 270, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 8640, 8640, 66, 8640, 66, 270, 8640, 8640, 8640, 270, 66, 8640, 270, 66, 66, 66, 66, 66, 8640, 270, 66, 8640, 66, 8640, 66, 66, 270, 270, 8640, 270, 8640, 66, 270, 66, 8640, 8640, 66, 8640, 270, 66, 8640, 66, 66, 8640, 8640, 270, 8640, 8640, 66, 8640, 270, 270, 66, 270, 8640, 8640, 66, 8640, 270, 66, 270, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 270, 8640, 8640, 270, 66, 8640, 66, 270, 270, 66, 270, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 270, 8640, 270, 66, 270, 8640, 270, 8640, 66, 8640, 66, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 270, 66, 8640, 66, 8640, 270, 270, 66, 270, 8640, 270, 270, 8640, 66, 8640, 8640, 270, 66, 8640, 8640, 270, 270, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 8640, 66, 8640, 270, 8640, 8640, 66, 8640, 270, 270, 8640, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 8640, 270, 66, 66, 66, 66]
Prompts retrieved: 771600 . Total input tokens: 171990632 . Total output tokens: 154422380
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.225794964935631,
    "estimated_duration": 3600.0443457820534,
    "input_throughput": 4855.400745404656,
    "output_throughput": 4279.193676613848,
    "total_throughput": 9134.594422018505,
    "itl": 200.2954790276794,
    "ttft": 1901190.272935105,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1905,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.980836748741385,
    "arrivals": 257044,
    "finished_requests": 70437,
    "scheduler_time": 95.50699078374836
}
#Debug simulation 
Total elapsed time: 5.225915809161961. Arrivals time: 0.22293730080127716 Scheduler time: 4.89336276287213 Scheduler overhead time: 0.02844405174255371 Adapter cache time: 0.03875159611925483 Engine time: 0.02909339079633355 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-32/adapters_256_slots_128_rate_0.8-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-32/adapters_256_slots_128_rate_0.8-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 8640, 66, 8640, 8640, 66, 8640, 270, 8640, 66, 270, 66, 8640, 270, 270, 270, 270, 8640, 66, 66, 66, 270, 8640, 66, 8640, 8640, 270, 270, 270, 66, 8640, 66, 270, 270, 66, 270, 66, 66, 270, 270, 8640, 270, 66, 270, 8640, 270, 270, 8640, 270, 8640, 66, 8640, 8640, 270, 66, 66, 8640, 270, 66, 270, 270, 8640, 270, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 8640, 8640, 66, 8640, 66, 270, 8640, 8640, 8640, 270, 66, 8640, 270, 66, 66, 66, 66, 66, 8640, 270, 66, 8640, 66, 8640, 66, 66, 270, 270, 8640, 270, 8640, 66, 270, 66, 8640, 8640, 66, 8640, 270, 66, 8640, 66, 66, 8640, 8640, 270, 8640, 8640, 66, 8640, 270, 270, 66, 270, 8640, 8640, 66, 8640, 270, 66, 270, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 270, 8640, 8640, 270, 66, 8640, 66, 270, 270, 66, 270, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 270, 8640, 270, 66, 270, 8640, 270, 8640, 66, 8640, 66, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 270, 66, 8640, 66, 8640, 270, 270, 66, 270, 8640, 270, 270, 8640, 66, 8640, 8640, 270, 66, 8640, 8640, 270, 270, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 8640, 66, 8640, 270, 8640, 8640, 66, 8640, 270, 270, 8640, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 8640, 270, 66, 66, 66, 66]
Prompts retrieved: 771600 . Total input tokens: 171990632 . Total output tokens: 154422380
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 5.156627136282623,
    "estimated_duration": 3600.0793843124334,
    "input_throughput": 4762.904694468234,
    "output_throughput": 4205.281712945175,
    "total_throughput": 8968.18640741341,
    "itl": 166.32515857771523,
    "ttft": 1919257.5135417103,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1879,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.208855674210847,
    "arrivals": 257044,
    "finished_requests": 69100,
    "scheduler_time": 101.10374305722392
}
#Debug simulation 
Total elapsed time: 5.156713946256787. Arrivals time: 0.21862452710047364 Scheduler time: 4.812671524006873 Scheduler overhead time: 0.033220112323760986 Adapter cache time: 0.0420435918495059 Engine time: 0.034429138991981745 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-16/adapters_256_slots_128_rate_0.8-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-16/adapters_256_slots_128_rate_0.8-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 8640, 66, 8640, 8640, 66, 8640, 270, 8640, 66, 270, 66, 8640, 270, 270, 270, 270, 8640, 66, 66, 66, 270, 8640, 66, 8640, 8640, 270, 270, 270, 66, 8640, 66, 270, 270, 66, 270, 66, 66, 270, 270, 8640, 270, 66, 270, 8640, 270, 270, 8640, 270, 8640, 66, 8640, 8640, 270, 66, 66, 8640, 270, 66, 270, 270, 8640, 270, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 8640, 8640, 66, 8640, 66, 270, 8640, 8640, 8640, 270, 66, 8640, 270, 66, 66, 66, 66, 66, 8640, 270, 66, 8640, 66, 8640, 66, 66, 270, 270, 8640, 270, 8640, 66, 270, 66, 8640, 8640, 66, 8640, 270, 66, 8640, 66, 66, 8640, 8640, 270, 8640, 8640, 66, 8640, 270, 270, 66, 270, 8640, 8640, 66, 8640, 270, 66, 270, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 270, 8640, 8640, 270, 66, 8640, 66, 270, 270, 66, 270, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 270, 8640, 270, 66, 270, 8640, 270, 8640, 66, 8640, 66, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 270, 66, 8640, 66, 8640, 270, 270, 66, 270, 8640, 270, 270, 8640, 66, 8640, 8640, 270, 66, 8640, 8640, 270, 270, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 8640, 66, 8640, 270, 8640, 8640, 66, 8640, 270, 270, 8640, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 8640, 270, 66, 66, 66, 66]
Prompts retrieved: 771600 . Total input tokens: 171990632 . Total output tokens: 154422380
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.2313478561118245,
    "estimated_duration": 3600.1876861270553,
    "input_throughput": 4855.689626227742,
    "output_throughput": 4279.625492685009,
    "total_throughput": 9135.315118912751,
    "itl": 200.28142370626833,
    "ttft": 1901149.4221513616,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1907,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.702025912378283,
    "arrivals": 257044,
    "finished_requests": 70448,
    "scheduler_time": 95.51825652548675
}
#Debug simulation 
Total elapsed time: 5.231439718045294. Arrivals time: 0.22576220706105232 Scheduler time: 4.895486011635512 Scheduler overhead time: 0.02868657559156418 Adapter cache time: 0.038670824840664864 Engine time: 0.029403305146843195 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-32/adapters_256_slots_128_rate_0.8-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-32/adapters_256_slots_128_rate_0.8-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 8640, 66, 8640, 8640, 66, 8640, 270, 8640, 66, 270, 66, 8640, 270, 270, 270, 270, 8640, 66, 66, 66, 270, 8640, 66, 8640, 8640, 270, 270, 270, 66, 8640, 66, 270, 270, 66, 270, 66, 66, 270, 270, 8640, 270, 66, 270, 8640, 270, 270, 8640, 270, 8640, 66, 8640, 8640, 270, 66, 66, 8640, 270, 66, 270, 270, 8640, 270, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 8640, 8640, 66, 8640, 66, 270, 8640, 8640, 8640, 270, 66, 8640, 270, 66, 66, 66, 66, 66, 8640, 270, 66, 8640, 66, 8640, 66, 66, 270, 270, 8640, 270, 8640, 66, 270, 66, 8640, 8640, 66, 8640, 270, 66, 8640, 66, 66, 8640, 8640, 270, 8640, 8640, 66, 8640, 270, 270, 66, 270, 8640, 8640, 66, 8640, 270, 66, 270, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 270, 8640, 8640, 270, 66, 8640, 66, 270, 270, 66, 270, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 270, 8640, 270, 66, 270, 8640, 270, 8640, 66, 8640, 66, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 270, 66, 8640, 66, 8640, 270, 270, 66, 270, 8640, 270, 270, 8640, 66, 8640, 8640, 270, 66, 8640, 8640, 270, 270, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 8640, 66, 8640, 270, 8640, 8640, 66, 8640, 270, 270, 8640, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 8640, 270, 66, 66, 66, 66]
Prompts retrieved: 771600 . Total input tokens: 171990632 . Total output tokens: 154422380
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.206745023373514,
    "estimated_duration": 3600.185397208827,
    "input_throughput": 4763.126091588147,
    "output_throughput": 4205.242599933204,
    "total_throughput": 8968.36869152135,
    "itl": 166.32977642667825,
    "ttft": 1919291.309659301,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1879,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.294282509051097,
    "arrivals": 257044,
    "finished_requests": 69102,
    "scheduler_time": 101.10477776837091
}
#Debug simulation 
Total elapsed time: 5.2068446022458375. Arrivals time: 0.22022274788469076 Scheduler time: 4.860709964763373 Scheduler overhead time: 0.03320391057059169 Adapter cache time: 0.04226338863372803 Engine time: 0.03464698093011975 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-8/adapters_256_slots_128_rate_0.8-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-8/adapters_256_slots_128_rate_0.8-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 8640, 33, 8640, 8640, 33, 8640, 270, 8640, 33, 270, 33, 8640, 270, 270, 270, 270, 8640, 33, 33, 33, 270, 8640, 33, 8640, 8640, 270, 270, 270, 33, 8640, 33, 270, 270, 33, 270, 33, 33, 270, 270, 8640, 270, 33, 270, 8640, 270, 270, 8640, 270, 8640, 33, 8640, 8640, 270, 33, 33, 8640, 270, 33, 270, 270, 8640, 270, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 8640, 8640, 33, 8640, 33, 270, 8640, 8640, 8640, 270, 33, 8640, 270, 33, 33, 33, 33, 33, 8640, 270, 33, 8640, 33, 8640, 33, 33, 270, 270, 8640, 270, 8640, 33, 270, 33, 8640, 8640, 33, 8640, 270, 33, 8640, 33, 33, 8640, 8640, 270, 8640, 8640, 33, 8640, 270, 270, 33, 270, 8640, 8640, 33, 8640, 270, 33, 270, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 270, 8640, 8640, 270, 33, 8640, 33, 270, 270, 33, 270, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 270, 8640, 270, 33, 270, 8640, 270, 8640, 33, 8640, 33, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 270, 33, 8640, 33, 8640, 270, 270, 33, 270, 8640, 270, 270, 8640, 33, 8640, 8640, 270, 33, 8640, 8640, 270, 270, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 8640, 33, 8640, 270, 8640, 8640, 33, 8640, 270, 270, 8640, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 8640, 270, 33, 33, 33, 33]
Prompts retrieved: 768795 . Total input tokens: 171373016 . Total output tokens: 153854187
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.326549559831619,
    "estimated_duration": 3600.007054198016,
    "input_throughput": 4956.456676714763,
    "output_throughput": 4358.578403812465,
    "total_throughput": 9315.035080527226,
    "itl": 196.35329094308494,
    "ttft": 1889670.2776494825,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1631,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.991655510354459,
    "arrivals": 255937,
    "finished_requests": 71664,
    "scheduler_time": 97.28100492585824
}
#Debug simulation 
Total elapsed time: 5.326643257867545. Arrivals time: 0.2237824397161603 Scheduler time: 4.994639679789543 Scheduler overhead time: 0.0289434683509171 Adapter cache time: 0.03581224614754319 Engine time: 0.02992519037798047 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-16/adapters_256_slots_128_rate_0.8-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-16/adapters_256_slots_128_rate_0.8-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 8640, 33, 8640, 8640, 33, 8640, 270, 8640, 33, 270, 33, 8640, 270, 270, 270, 270, 8640, 33, 33, 33, 270, 8640, 33, 8640, 8640, 270, 270, 270, 33, 8640, 33, 270, 270, 33, 270, 33, 33, 270, 270, 8640, 270, 33, 270, 8640, 270, 270, 8640, 270, 8640, 33, 8640, 8640, 270, 33, 33, 8640, 270, 33, 270, 270, 8640, 270, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 8640, 8640, 33, 8640, 33, 270, 8640, 8640, 8640, 270, 33, 8640, 270, 33, 33, 33, 33, 33, 8640, 270, 33, 8640, 33, 8640, 33, 33, 270, 270, 8640, 270, 8640, 33, 270, 33, 8640, 8640, 33, 8640, 270, 33, 8640, 33, 33, 8640, 8640, 270, 8640, 8640, 33, 8640, 270, 270, 33, 270, 8640, 8640, 33, 8640, 270, 33, 270, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 270, 8640, 8640, 270, 33, 8640, 33, 270, 270, 33, 270, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 270, 8640, 270, 33, 270, 8640, 270, 8640, 33, 8640, 33, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 270, 33, 8640, 33, 8640, 270, 270, 33, 270, 8640, 270, 270, 8640, 33, 8640, 8640, 270, 33, 8640, 8640, 270, 270, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 8640, 33, 8640, 270, 8640, 8640, 33, 8640, 270, 270, 8640, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 8640, 270, 33, 33, 33, 33]
Prompts retrieved: 768795 . Total input tokens: 171373016 . Total output tokens: 153854187
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.325761727057397,
    "estimated_duration": 3600.0701108720446,
    "input_throughput": 4956.015147071159,
    "output_throughput": 4358.181512248236,
    "total_throughput": 9314.196659319394,
    "itl": 196.37139233339528,
    "ttft": 1889738.5727500042,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1630,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.3318173326620615,
    "arrivals": 255937,
    "finished_requests": 71659,
    "scheduler_time": 97.27346138835641
}
#Debug simulation 
Total elapsed time: 5.325857340358198. Arrivals time: 0.22336079878732562 Scheduler time: 4.9945860812440515 Scheduler overhead time: 0.028961283154785633 Adapter cache time: 0.03567664185538888 Engine time: 0.02977363020181656 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-32/adapters_256_slots_128_rate_0.8-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-32/adapters_256_slots_128_rate_0.8-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 8640, 33, 8640, 8640, 33, 8640, 270, 8640, 33, 270, 33, 8640, 270, 270, 270, 270, 8640, 33, 33, 33, 270, 8640, 33, 8640, 8640, 270, 270, 270, 33, 8640, 33, 270, 270, 33, 270, 33, 33, 270, 270, 8640, 270, 33, 270, 8640, 270, 270, 8640, 270, 8640, 33, 8640, 8640, 270, 33, 33, 8640, 270, 33, 270, 270, 8640, 270, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 8640, 8640, 33, 8640, 33, 270, 8640, 8640, 8640, 270, 33, 8640, 270, 33, 33, 33, 33, 33, 8640, 270, 33, 8640, 33, 8640, 33, 33, 270, 270, 8640, 270, 8640, 33, 270, 33, 8640, 8640, 33, 8640, 270, 33, 8640, 33, 33, 8640, 8640, 270, 8640, 8640, 33, 8640, 270, 270, 33, 270, 8640, 8640, 33, 8640, 270, 33, 270, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 270, 8640, 8640, 270, 33, 8640, 33, 270, 270, 33, 270, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 270, 8640, 270, 33, 270, 8640, 270, 8640, 33, 8640, 33, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 270, 33, 8640, 33, 8640, 270, 270, 33, 270, 8640, 270, 270, 8640, 33, 8640, 8640, 270, 33, 8640, 8640, 270, 270, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 8640, 33, 8640, 270, 8640, 8640, 33, 8640, 270, 270, 8640, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 8640, 270, 33, 33, 33, 33]
Prompts retrieved: 768795 . Total input tokens: 171373016 . Total output tokens: 153854187
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.2646303293295205,
    "estimated_duration": 3600.168578588476,
    "input_throughput": 4850.106771068493,
    "output_throughput": 4270.870561852533,
    "total_throughput": 9120.977332921026,
    "itl": 162.99037881536455,
    "ttft": 1909992.9116763994,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1619,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.299103755131312,
    "arrivals": 255937,
    "finished_requests": 70095,
    "scheduler_time": 102.82265679784209
}
#Debug simulation 
Total elapsed time: 5.264720716979355. Arrivals time: 0.21996518317610025 Scheduler time: 4.919996730517596 Scheduler overhead time: 0.03393665095791221 Adapter cache time: 0.039424784015864134 Engine time: 0.03522623796015978 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-16-16/adapters_256_slots_128_rate_0.8-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-16-16/adapters_256_slots_128_rate_0.8-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 8640, 33, 8640, 8640, 33, 8640, 270, 8640, 33, 270, 33, 8640, 270, 270, 270, 270, 8640, 33, 33, 33, 270, 8640, 33, 8640, 8640, 270, 270, 270, 33, 8640, 33, 270, 270, 33, 270, 33, 33, 270, 270, 8640, 270, 33, 270, 8640, 270, 270, 8640, 270, 8640, 33, 8640, 8640, 270, 33, 33, 8640, 270, 33, 270, 270, 8640, 270, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 8640, 8640, 33, 8640, 33, 270, 8640, 8640, 8640, 270, 33, 8640, 270, 33, 33, 33, 33, 33, 8640, 270, 33, 8640, 33, 8640, 33, 33, 270, 270, 8640, 270, 8640, 33, 270, 33, 8640, 8640, 33, 8640, 270, 33, 8640, 33, 33, 8640, 8640, 270, 8640, 8640, 33, 8640, 270, 270, 33, 270, 8640, 8640, 33, 8640, 270, 33, 270, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 270, 8640, 8640, 270, 33, 8640, 33, 270, 270, 33, 270, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 270, 8640, 270, 33, 270, 8640, 270, 8640, 33, 8640, 33, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 270, 33, 8640, 33, 8640, 270, 270, 33, 270, 8640, 270, 270, 8640, 33, 8640, 8640, 270, 33, 8640, 8640, 270, 270, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 8640, 33, 8640, 270, 8640, 8640, 33, 8640, 270, 270, 8640, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 8640, 270, 33, 33, 33, 33]
Prompts retrieved: 768795 . Total input tokens: 171373016 . Total output tokens: 153854187
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.345055116806179,
    "estimated_duration": 3600.216154773901,
    "input_throughput": 4956.285187582192,
    "output_throughput": 4358.385253950239,
    "total_throughput": 9314.67044153243,
    "itl": 196.3632820230654,
    "ttft": 1889742.6386922437,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1629,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.130658552923592,
    "arrivals": 255937,
    "finished_requests": 71665,
    "scheduler_time": 97.28246029631276
}
#Debug simulation 
Total elapsed time: 5.345167173072696. Arrivals time: 0.24176395079120994 Scheduler time: 4.995220644865185 Scheduler overhead time: 0.02875546831637621 Adapter cache time: 0.035936478059738874 Engine time: 0.029953337274491787 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-16-32/adapters_256_slots_128_rate_0.8-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-16-32/adapters_256_slots_128_rate_0.8-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 8640, 33, 8640, 8640, 33, 8640, 270, 8640, 33, 270, 33, 8640, 270, 270, 270, 270, 8640, 33, 33, 33, 270, 8640, 33, 8640, 8640, 270, 270, 270, 33, 8640, 33, 270, 270, 33, 270, 33, 33, 270, 270, 8640, 270, 33, 270, 8640, 270, 270, 8640, 270, 8640, 33, 8640, 8640, 270, 33, 33, 8640, 270, 33, 270, 270, 8640, 270, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 8640, 8640, 33, 8640, 33, 270, 8640, 8640, 8640, 270, 33, 8640, 270, 33, 33, 33, 33, 33, 8640, 270, 33, 8640, 33, 8640, 33, 33, 270, 270, 8640, 270, 8640, 33, 270, 33, 8640, 8640, 33, 8640, 270, 33, 8640, 33, 33, 8640, 8640, 270, 8640, 8640, 33, 8640, 270, 270, 33, 270, 8640, 8640, 33, 8640, 270, 33, 270, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 270, 8640, 8640, 270, 33, 8640, 33, 270, 270, 33, 270, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 270, 8640, 270, 33, 270, 8640, 270, 8640, 33, 8640, 33, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 270, 33, 8640, 33, 8640, 270, 270, 33, 270, 8640, 270, 270, 8640, 33, 8640, 8640, 270, 33, 8640, 8640, 270, 270, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 8640, 33, 8640, 270, 8640, 8640, 33, 8640, 270, 270, 8640, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 8640, 270, 33, 33, 33, 33]
Prompts retrieved: 768795 . Total input tokens: 171373016 . Total output tokens: 153854187
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 5.256496645975858,
    "estimated_duration": 3600.0957025579833,
    "input_throughput": 4850.204950827629,
    "output_throughput": 4270.957016246808,
    "total_throughput": 9121.161967074437,
    "itl": 162.98693945107235,
    "ttft": 1909900.0147224208,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1617,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.353504288699419,
    "arrivals": 255937,
    "finished_requests": 70095,
    "scheduler_time": 102.82241428424874
}
#Debug simulation 
Total elapsed time: 5.256599724758416. Arrivals time: 0.21572826709598303 Scheduler time: 4.916596337221563 Scheduler overhead time: 0.034069787710905075 Adapter cache time: 0.03901906358078122 Engine time: 0.03505500126630068 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_16-16-16/adapters_256_slots_128_rate_0.8-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_16-16-16/adapters_256_slots_128_rate_0.8-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 8640, 33, 8640, 8640, 33, 8640, 270, 8640, 33, 270, 33, 8640, 270, 270, 270, 270, 8640, 33, 33, 33, 270, 8640, 33, 8640, 8640, 270, 270, 270, 33, 8640, 33, 270, 270, 33, 270, 33, 33, 270, 270, 8640, 270, 33, 270, 8640, 270, 270, 8640, 270, 8640, 33, 8640, 8640, 270, 33, 33, 8640, 270, 33, 270, 270, 8640, 270, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 8640, 8640, 33, 8640, 33, 270, 8640, 8640, 8640, 270, 33, 8640, 270, 33, 33, 33, 33, 33, 8640, 270, 33, 8640, 33, 8640, 33, 33, 270, 270, 8640, 270, 8640, 33, 270, 33, 8640, 8640, 33, 8640, 270, 33, 8640, 33, 33, 8640, 8640, 270, 8640, 8640, 33, 8640, 270, 270, 33, 270, 8640, 8640, 33, 8640, 270, 33, 270, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 270, 8640, 8640, 270, 33, 8640, 33, 270, 270, 33, 270, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 270, 8640, 270, 33, 270, 8640, 270, 8640, 33, 8640, 33, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 270, 33, 8640, 33, 8640, 270, 270, 33, 270, 8640, 270, 270, 8640, 33, 8640, 8640, 270, 33, 8640, 8640, 270, 270, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 8640, 33, 8640, 270, 8640, 8640, 33, 8640, 270, 270, 8640, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 8640, 270, 33, 33, 33, 33]
Prompts retrieved: 768795 . Total input tokens: 171373016 . Total output tokens: 153854187
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.336914223153144,
    "estimated_duration": 3600.114107357043,
    "input_throughput": 4956.985380972022,
    "output_throughput": 4358.807118899945,
    "total_throughput": 9315.792499871966,
    "itl": 196.35024778555814,
    "ttft": 1889571.8838726438,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1631,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.876772030985312,
    "arrivals": 255937,
    "finished_requests": 71672,
    "scheduler_time": 97.2866716100765
}
#Debug simulation 
Total elapsed time: 5.337005456909537. Arrivals time: 0.22214715369045734 Scheduler time: 5.006794035900384 Scheduler overhead time: 0.028813458047807217 Adapter cache time: 0.03588034398853779 Engine time: 0.029851160012185574 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_16-16-32/adapters_256_slots_128_rate_0.8-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_16-16-32/adapters_256_slots_128_rate_0.8-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 8640, 33, 8640, 8640, 33, 8640, 270, 8640, 33, 270, 33, 8640, 270, 270, 270, 270, 8640, 33, 33, 33, 270, 8640, 33, 8640, 8640, 270, 270, 270, 33, 8640, 33, 270, 270, 33, 270, 33, 33, 270, 270, 8640, 270, 33, 270, 8640, 270, 270, 8640, 270, 8640, 33, 8640, 8640, 270, 33, 33, 8640, 270, 33, 270, 270, 8640, 270, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 8640, 8640, 33, 8640, 33, 270, 8640, 8640, 8640, 270, 33, 8640, 270, 33, 33, 33, 33, 33, 8640, 270, 33, 8640, 33, 8640, 33, 33, 270, 270, 8640, 270, 8640, 33, 270, 33, 8640, 8640, 33, 8640, 270, 33, 8640, 33, 33, 8640, 8640, 270, 8640, 8640, 33, 8640, 270, 270, 33, 270, 8640, 8640, 33, 8640, 270, 33, 270, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 270, 8640, 8640, 270, 33, 8640, 33, 270, 270, 33, 270, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 270, 8640, 270, 33, 270, 8640, 270, 8640, 33, 8640, 33, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 270, 33, 8640, 33, 8640, 270, 270, 33, 270, 8640, 270, 270, 8640, 33, 8640, 8640, 270, 33, 8640, 8640, 270, 270, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 8640, 33, 8640, 270, 8640, 8640, 33, 8640, 270, 270, 8640, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 8640, 270, 33, 33, 33, 33]
Prompts retrieved: 768795 . Total input tokens: 171373016 . Total output tokens: 153854187
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.283359921071678,
    "estimated_duration": 3600.1099318604265,
    "input_throughput": 4849.983008984663,
    "output_throughput": 4270.8404162687375,
    "total_throughput": 9120.8234252534,
    "itl": 162.9956503457545,
    "ttft": 1909863.7109088623,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1618,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.434640908911749,
    "arrivals": 255937,
    "finished_requests": 70092,
    "scheduler_time": 102.81840491792352
}
#Debug simulation 
Total elapsed time: 5.28344804700464. Arrivals time: 0.2280340101569891 Scheduler time: 4.930944804567844 Scheduler overhead time: 0.03407059982419014 Adapter cache time: 0.039062564726918936 Engine time: 0.03520842595025897 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-8/adapters_256_slots_128_rate_0.8-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-8/adapters_256_slots_128_rate_0.8-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 8640, 66, 8640, 8640, 66, 8640, 135, 8640, 66, 135, 66, 8640, 135, 135, 135, 135, 8640, 66, 66, 66, 135, 8640, 66, 8640, 8640, 135, 135, 135, 66, 8640, 66, 135, 135, 66, 135, 66, 66, 135, 135, 8640, 135, 66, 135, 8640, 135, 135, 8640, 135, 8640, 66, 8640, 8640, 135, 66, 66, 8640, 135, 66, 135, 135, 8640, 135, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 8640, 8640, 66, 8640, 66, 135, 8640, 8640, 8640, 135, 66, 8640, 135, 66, 66, 66, 66, 66, 8640, 135, 66, 8640, 66, 8640, 66, 66, 135, 135, 8640, 135, 8640, 66, 135, 66, 8640, 8640, 66, 8640, 135, 66, 8640, 66, 66, 8640, 8640, 135, 8640, 8640, 66, 8640, 135, 135, 66, 135, 8640, 8640, 66, 8640, 135, 66, 135, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 135, 8640, 8640, 135, 66, 8640, 66, 135, 135, 66, 135, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 135, 8640, 135, 66, 135, 8640, 135, 8640, 66, 8640, 66, 135, 8640, 135, 8640, 135, 8640, 135, 8640, 135, 66, 8640, 66, 8640, 135, 135, 66, 135, 8640, 135, 135, 8640, 66, 8640, 8640, 135, 66, 8640, 8640, 135, 135, 8640, 8640, 135, 135, 135, 135, 8640, 8640, 135, 135, 8640, 66, 8640, 135, 8640, 8640, 66, 8640, 135, 135, 8640, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 8640, 135, 66, 66, 66, 66]
Prompts retrieved: 760125 . Total input tokens: 169433666 . Total output tokens: 152092898
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.45685861306265,
    "estimated_duration": 3600.1810566550334,
    "input_throughput": 5128.27485880777,
    "output_throughput": 4478.923905838738,
    "total_throughput": 9607.19876464651,
    "itl": 190.3353709432841,
    "ttft": 1858397.5603222763,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1396,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.272440890530237,
    "arrivals": 253041,
    "finished_requests": 74170,
    "scheduler_time": 99.92740588697677
}
#Debug simulation 
Total elapsed time: 5.456948920153081. Arrivals time: 0.2320052939467132 Scheduler time: 5.119785766582936 Scheduler overhead time: 0.02969477279111743 Adapter cache time: 0.030932550318539143 Engine time: 0.030687224119901657 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-16/adapters_256_slots_128_rate_0.8-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-16/adapters_256_slots_128_rate_0.8-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 8640, 66, 8640, 8640, 66, 8640, 135, 8640, 66, 135, 66, 8640, 135, 135, 135, 135, 8640, 66, 66, 66, 135, 8640, 66, 8640, 8640, 135, 135, 135, 66, 8640, 66, 135, 135, 66, 135, 66, 66, 135, 135, 8640, 135, 66, 135, 8640, 135, 135, 8640, 135, 8640, 66, 8640, 8640, 135, 66, 66, 8640, 135, 66, 135, 135, 8640, 135, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 8640, 8640, 66, 8640, 66, 135, 8640, 8640, 8640, 135, 66, 8640, 135, 66, 66, 66, 66, 66, 8640, 135, 66, 8640, 66, 8640, 66, 66, 135, 135, 8640, 135, 8640, 66, 135, 66, 8640, 8640, 66, 8640, 135, 66, 8640, 66, 66, 8640, 8640, 135, 8640, 8640, 66, 8640, 135, 135, 66, 135, 8640, 8640, 66, 8640, 135, 66, 135, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 135, 8640, 8640, 135, 66, 8640, 66, 135, 135, 66, 135, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 135, 8640, 135, 66, 135, 8640, 135, 8640, 66, 8640, 66, 135, 8640, 135, 8640, 135, 8640, 135, 8640, 135, 66, 8640, 66, 8640, 135, 135, 66, 135, 8640, 135, 135, 8640, 66, 8640, 8640, 135, 66, 8640, 8640, 135, 135, 8640, 8640, 135, 135, 135, 135, 8640, 8640, 135, 135, 8640, 66, 8640, 135, 8640, 8640, 66, 8640, 135, 135, 8640, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 8640, 135, 66, 66, 66, 66]
Prompts retrieved: 760125 . Total input tokens: 169433666 . Total output tokens: 152092898
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.679239870980382,
    "estimated_duration": 3600.099711579125,
    "input_throughput": 5127.818249206918,
    "output_throughput": 4478.427346927011,
    "total_throughput": 9606.24559613393,
    "itl": 190.34820418552965,
    "ttft": 1858483.9405469103,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1395,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.551930998174894,
    "arrivals": 253041,
    "finished_requests": 74161,
    "scheduler_time": 99.91813408200947
}
#Debug simulation 
Total elapsed time: 5.679333467036486. Arrivals time: 0.4658086667768657 Scheduler time: 5.107858281116933 Scheduler overhead time: 0.029867390636354685 Adapter cache time: 0.03108983626589179 Engine time: 0.030742346309125423 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-32/adapters_256_slots_128_rate_0.8-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-32/adapters_256_slots_128_rate_0.8-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 8640, 66, 8640, 8640, 66, 8640, 135, 8640, 66, 135, 66, 8640, 135, 135, 135, 135, 8640, 66, 66, 66, 135, 8640, 66, 8640, 8640, 135, 135, 135, 66, 8640, 66, 135, 135, 66, 135, 66, 66, 135, 135, 8640, 135, 66, 135, 8640, 135, 135, 8640, 135, 8640, 66, 8640, 8640, 135, 66, 66, 8640, 135, 66, 135, 135, 8640, 135, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 8640, 8640, 66, 8640, 66, 135, 8640, 8640, 8640, 135, 66, 8640, 135, 66, 66, 66, 66, 66, 8640, 135, 66, 8640, 66, 8640, 66, 66, 135, 135, 8640, 135, 8640, 66, 135, 66, 8640, 8640, 66, 8640, 135, 66, 8640, 66, 66, 8640, 8640, 135, 8640, 8640, 66, 8640, 135, 135, 66, 135, 8640, 8640, 66, 8640, 135, 66, 135, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 135, 8640, 8640, 135, 66, 8640, 66, 135, 135, 66, 135, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 135, 8640, 135, 66, 135, 8640, 135, 8640, 66, 8640, 66, 135, 8640, 135, 8640, 135, 8640, 135, 8640, 135, 66, 8640, 66, 8640, 135, 135, 66, 135, 8640, 135, 135, 8640, 66, 8640, 8640, 135, 66, 8640, 8640, 135, 135, 8640, 8640, 135, 135, 135, 135, 8640, 8640, 135, 135, 8640, 66, 8640, 135, 8640, 8640, 66, 8640, 135, 135, 8640, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 8640, 135, 66, 66, 66, 66]
Prompts retrieved: 760125 . Total input tokens: 169433666 . Total output tokens: 152092898
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.3723922851495445,
    "estimated_duration": 3600.055246913251,
    "input_throughput": 5004.69152951145,
    "output_throughput": 4376.624501390511,
    "total_throughput": 9381.316030901962,
    "itl": 159.4888390972063,
    "ttft": 1880544.920663857,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1358,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.4379703316836965,
    "arrivals": 253041,
    "finished_requests": 72377,
    "scheduler_time": 105.08643761130524
}
#Debug simulation 
Total elapsed time: 5.372479617130011. Arrivals time: 0.2245525186881423 Scheduler time: 5.0281755439937115 Scheduler overhead time: 0.0345890405587852 Adapter cache time: 0.03307065740227699 Engine time: 0.03577829850837588 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-16-16/adapters_256_slots_128_rate_0.8-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-16-16/adapters_256_slots_128_rate_0.8-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 8640, 66, 8640, 8640, 66, 8640, 135, 8640, 66, 135, 66, 8640, 135, 135, 135, 135, 8640, 66, 66, 66, 135, 8640, 66, 8640, 8640, 135, 135, 135, 66, 8640, 66, 135, 135, 66, 135, 66, 66, 135, 135, 8640, 135, 66, 135, 8640, 135, 135, 8640, 135, 8640, 66, 8640, 8640, 135, 66, 66, 8640, 135, 66, 135, 135, 8640, 135, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 8640, 8640, 66, 8640, 66, 135, 8640, 8640, 8640, 135, 66, 8640, 135, 66, 66, 66, 66, 66, 8640, 135, 66, 8640, 66, 8640, 66, 66, 135, 135, 8640, 135, 8640, 66, 135, 66, 8640, 8640, 66, 8640, 135, 66, 8640, 66, 66, 8640, 8640, 135, 8640, 8640, 66, 8640, 135, 135, 66, 135, 8640, 8640, 66, 8640, 135, 66, 135, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 135, 8640, 8640, 135, 66, 8640, 66, 135, 135, 66, 135, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 135, 8640, 135, 66, 135, 8640, 135, 8640, 66, 8640, 66, 135, 8640, 135, 8640, 135, 8640, 135, 8640, 135, 66, 8640, 66, 8640, 135, 135, 66, 135, 8640, 135, 135, 8640, 66, 8640, 8640, 135, 66, 8640, 8640, 135, 135, 8640, 8640, 135, 135, 135, 135, 8640, 8640, 135, 135, 8640, 66, 8640, 135, 8640, 8640, 66, 8640, 135, 135, 8640, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 8640, 135, 66, 66, 66, 66]
Prompts retrieved: 760125 . Total input tokens: 169433666 . Total output tokens: 152092898
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.448717133607715,
    "estimated_duration": 3600.1360855177245,
    "input_throughput": 5128.176424848956,
    "output_throughput": 4478.7918059161975,
    "total_throughput": 9606.968230765155,
    "itl": 190.34120565712257,
    "ttft": 1858376.6152606644,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1395,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.37541782060864,
    "arrivals": 253041,
    "finished_requests": 74167,
    "scheduler_time": 99.9234502105796
}
#Debug simulation 
Total elapsed time: 5.448808206710964. Arrivals time: 0.23089536326006055 Scheduler time: 5.113008945714682 Scheduler overhead time: 0.029620081186294556 Adapter cache time: 0.03079168125987053 Engine time: 0.030535136349499226 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-16-32/adapters_256_slots_128_rate_0.8-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-16-32/adapters_256_slots_128_rate_0.8-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 8640, 66, 8640, 8640, 66, 8640, 135, 8640, 66, 135, 66, 8640, 135, 135, 135, 135, 8640, 66, 66, 66, 135, 8640, 66, 8640, 8640, 135, 135, 135, 66, 8640, 66, 135, 135, 66, 135, 66, 66, 135, 135, 8640, 135, 66, 135, 8640, 135, 135, 8640, 135, 8640, 66, 8640, 8640, 135, 66, 66, 8640, 135, 66, 135, 135, 8640, 135, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 8640, 8640, 66, 8640, 66, 135, 8640, 8640, 8640, 135, 66, 8640, 135, 66, 66, 66, 66, 66, 8640, 135, 66, 8640, 66, 8640, 66, 66, 135, 135, 8640, 135, 8640, 66, 135, 66, 8640, 8640, 66, 8640, 135, 66, 8640, 66, 66, 8640, 8640, 135, 8640, 8640, 66, 8640, 135, 135, 66, 135, 8640, 8640, 66, 8640, 135, 66, 135, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 135, 8640, 8640, 135, 66, 8640, 66, 135, 135, 66, 135, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 135, 8640, 135, 66, 135, 8640, 135, 8640, 66, 8640, 66, 135, 8640, 135, 8640, 135, 8640, 135, 8640, 135, 66, 8640, 66, 8640, 135, 135, 66, 135, 8640, 135, 135, 8640, 66, 8640, 8640, 135, 66, 8640, 8640, 135, 135, 8640, 8640, 135, 135, 135, 135, 8640, 8640, 135, 135, 8640, 66, 8640, 135, 8640, 8640, 66, 8640, 135, 135, 8640, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 8640, 135, 66, 66, 66, 66]
Prompts retrieved: 760125 . Total input tokens: 169433666 . Total output tokens: 152092898
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 5.349873322993517,
    "estimated_duration": 3600.076399341426,
    "input_throughput": 5004.609903083142,
    "output_throughput": 4376.654340691867,
    "total_throughput": 9381.26424377501,
    "itl": 159.4951106811311,
    "ttft": 1880653.9403323154,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1358,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.490198166910534,
    "arrivals": 253041,
    "finished_requests": 72377,
    "scheduler_time": 105.08559917611981
}
#Debug simulation 
Total elapsed time: 5.349952944088727. Arrivals time: 0.21959569910541177 Scheduler time: 5.010271937586367 Scheduler overhead time: 0.03467324236407876 Adapter cache time: 0.03303528157994151 Engine time: 0.036001807544380426 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_16-16-16/adapters_256_slots_128_rate_0.8-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_16-16-16/adapters_256_slots_128_rate_0.8-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 8640, 66, 8640, 8640, 66, 8640, 135, 8640, 66, 135, 66, 8640, 135, 135, 135, 135, 8640, 66, 66, 66, 135, 8640, 66, 8640, 8640, 135, 135, 135, 66, 8640, 66, 135, 135, 66, 135, 66, 66, 135, 135, 8640, 135, 66, 135, 8640, 135, 135, 8640, 135, 8640, 66, 8640, 8640, 135, 66, 66, 8640, 135, 66, 135, 135, 8640, 135, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 8640, 8640, 66, 8640, 66, 135, 8640, 8640, 8640, 135, 66, 8640, 135, 66, 66, 66, 66, 66, 8640, 135, 66, 8640, 66, 8640, 66, 66, 135, 135, 8640, 135, 8640, 66, 135, 66, 8640, 8640, 66, 8640, 135, 66, 8640, 66, 66, 8640, 8640, 135, 8640, 8640, 66, 8640, 135, 135, 66, 135, 8640, 8640, 66, 8640, 135, 66, 135, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 135, 8640, 8640, 135, 66, 8640, 66, 135, 135, 66, 135, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 135, 8640, 135, 66, 135, 8640, 135, 8640, 66, 8640, 66, 135, 8640, 135, 8640, 135, 8640, 135, 8640, 135, 66, 8640, 66, 8640, 135, 135, 66, 135, 8640, 135, 135, 8640, 66, 8640, 8640, 135, 66, 8640, 8640, 135, 135, 8640, 8640, 135, 135, 135, 135, 8640, 8640, 135, 135, 8640, 66, 8640, 135, 8640, 8640, 66, 8640, 135, 135, 8640, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 8640, 135, 66, 66, 66, 66]
Prompts retrieved: 760125 . Total input tokens: 169433666 . Total output tokens: 152092898
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.471864466089755,
    "estimated_duration": 3600.0398327351177,
    "input_throughput": 5128.468533075378,
    "output_throughput": 4479.014330169055,
    "total_throughput": 9607.482863244433,
    "itl": 190.3283909418901,
    "ttft": 1858369.2764862818,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1395,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.171120161388424,
    "arrivals": 253041,
    "finished_requests": 74169,
    "scheduler_time": 99.92587669672281
}
#Debug simulation 
Total elapsed time: 5.471970295067877. Arrivals time: 0.2429375136271119 Scheduler time: 5.123990746680647 Scheduler overhead time: 0.029644048307090998 Adapter cache time: 0.03067289339378476 Engine time: 0.030742797534912825 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_16-16-32/adapters_256_slots_128_rate_0.8-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_16-16-32/adapters_256_slots_128_rate_0.8-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 8640, 66, 8640, 8640, 66, 8640, 135, 8640, 66, 135, 66, 8640, 135, 135, 135, 135, 8640, 66, 66, 66, 135, 8640, 66, 8640, 8640, 135, 135, 135, 66, 8640, 66, 135, 135, 66, 135, 66, 66, 135, 135, 8640, 135, 66, 135, 8640, 135, 135, 8640, 135, 8640, 66, 8640, 8640, 135, 66, 66, 8640, 135, 66, 135, 135, 8640, 135, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 8640, 8640, 66, 8640, 66, 135, 8640, 8640, 8640, 135, 66, 8640, 135, 66, 66, 66, 66, 66, 8640, 135, 66, 8640, 66, 8640, 66, 66, 135, 135, 8640, 135, 8640, 66, 135, 66, 8640, 8640, 66, 8640, 135, 66, 8640, 66, 66, 8640, 8640, 135, 8640, 8640, 66, 8640, 135, 135, 66, 135, 8640, 8640, 66, 8640, 135, 66, 135, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 135, 8640, 8640, 135, 66, 8640, 66, 135, 135, 66, 135, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 135, 8640, 135, 66, 135, 8640, 135, 8640, 66, 8640, 66, 135, 8640, 135, 8640, 135, 8640, 135, 8640, 135, 66, 8640, 66, 8640, 135, 135, 66, 135, 8640, 135, 135, 8640, 66, 8640, 8640, 135, 66, 8640, 8640, 135, 135, 8640, 8640, 135, 135, 135, 135, 8640, 8640, 135, 135, 8640, 66, 8640, 135, 8640, 8640, 66, 8640, 135, 135, 8640, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 8640, 135, 66, 66, 66, 66]
Prompts retrieved: 760125 . Total input tokens: 169433666 . Total output tokens: 152092898
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.372237119358033,
    "estimated_duration": 3600.123913630508,
    "input_throughput": 5004.361358726574,
    "output_throughput": 4376.595188944687,
    "total_throughput": 9380.956547671261,
    "itl": 159.48681833564314,
    "ttft": 1880690.9353763629,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1358,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.551651754602796,
    "arrivals": 253041,
    "finished_requests": 72376,
    "scheduler_time": 105.08806720743092
}
#Debug simulation 
Total elapsed time: 5.372352262027562. Arrivals time: 0.23855468817055225 Scheduler time: 5.0143281244672835 Scheduler overhead time: 0.034496058244258165 Adapter cache time: 0.03289233334362507 Engine time: 0.03567885560914874 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-8/adapters_256_slots_128_rate_0.8-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-8/adapters_256_slots_128_rate_0.8-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 8640, 33, 8640, 8640, 33, 8640, 135, 8640, 33, 135, 33, 8640, 135, 135, 135, 135, 8640, 33, 33, 33, 135, 8640, 33, 8640, 8640, 135, 135, 135, 33, 8640, 33, 135, 135, 33, 135, 33, 33, 135, 135, 8640, 135, 33, 135, 8640, 135, 135, 8640, 135, 8640, 33, 8640, 8640, 135, 33, 33, 8640, 135, 33, 135, 135, 8640, 135, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 8640, 8640, 33, 8640, 33, 135, 8640, 8640, 8640, 135, 33, 8640, 135, 33, 33, 33, 33, 33, 8640, 135, 33, 8640, 33, 8640, 33, 33, 135, 135, 8640, 135, 8640, 33, 135, 33, 8640, 8640, 33, 8640, 135, 33, 8640, 33, 33, 8640, 8640, 135, 8640, 8640, 33, 8640, 135, 135, 33, 135, 8640, 8640, 33, 8640, 135, 33, 135, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 135, 8640, 8640, 135, 33, 8640, 33, 135, 135, 33, 135, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 135, 8640, 135, 33, 135, 8640, 135, 8640, 33, 8640, 33, 135, 8640, 135, 8640, 135, 8640, 135, 8640, 135, 33, 8640, 33, 8640, 135, 135, 33, 135, 8640, 135, 135, 8640, 33, 8640, 8640, 135, 33, 8640, 8640, 135, 135, 8640, 8640, 135, 135, 135, 135, 8640, 8640, 135, 135, 8640, 33, 8640, 135, 8640, 8640, 33, 8640, 135, 135, 8640, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 8640, 135, 33, 33, 33, 33]
Prompts retrieved: 757320 . Total input tokens: 168812283 . Total output tokens: 151525896
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.572186359204352,
    "estimated_duration": 3600.110317704839,
    "input_throughput": 5183.781149211453,
    "output_throughput": 4577.147516553129,
    "total_throughput": 9760.928665764583,
    "itl": 187.67867685463239,
    "ttft": 1840329.6316968072,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1019,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1186370110675483,
    "arrivals": 252137,
    "finished_requests": 75092,
    "scheduler_time": 101.85682457495768
}
#Debug simulation 
Total elapsed time: 5.5722766714170575. Arrivals time: 0.23671728745102882 Scheduler time: 5.233666700776666 Scheduler overhead time: 0.030685504898428917 Adapter cache time: 0.025646493770182133 Engine time: 0.03137703472748399 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-16/adapters_256_slots_128_rate_0.8-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-16/adapters_256_slots_128_rate_0.8-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 8640, 33, 8640, 8640, 33, 8640, 135, 8640, 33, 135, 33, 8640, 135, 135, 135, 135, 8640, 33, 33, 33, 135, 8640, 33, 8640, 8640, 135, 135, 135, 33, 8640, 33, 135, 135, 33, 135, 33, 33, 135, 135, 8640, 135, 33, 135, 8640, 135, 135, 8640, 135, 8640, 33, 8640, 8640, 135, 33, 33, 8640, 135, 33, 135, 135, 8640, 135, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 8640, 8640, 33, 8640, 33, 135, 8640, 8640, 8640, 135, 33, 8640, 135, 33, 33, 33, 33, 33, 8640, 135, 33, 8640, 33, 8640, 33, 33, 135, 135, 8640, 135, 8640, 33, 135, 33, 8640, 8640, 33, 8640, 135, 33, 8640, 33, 33, 8640, 8640, 135, 8640, 8640, 33, 8640, 135, 135, 33, 135, 8640, 8640, 33, 8640, 135, 33, 135, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 135, 8640, 8640, 135, 33, 8640, 33, 135, 135, 33, 135, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 135, 8640, 135, 33, 135, 8640, 135, 8640, 33, 8640, 33, 135, 8640, 135, 8640, 135, 8640, 135, 8640, 135, 33, 8640, 33, 8640, 135, 135, 33, 135, 8640, 135, 135, 8640, 33, 8640, 8640, 135, 33, 8640, 8640, 135, 135, 8640, 8640, 135, 135, 135, 135, 8640, 8640, 135, 135, 8640, 33, 8640, 135, 8640, 8640, 33, 8640, 135, 135, 8640, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 8640, 135, 33, 33, 33, 33]
Prompts retrieved: 757320 . Total input tokens: 168812283 . Total output tokens: 151525896
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.591833921149373,
    "estimated_duration": 3600.127126468471,
    "input_throughput": 5183.72389208002,
    "output_throughput": 4576.948096875575,
    "total_throughput": 9760.671988955595,
    "itl": 187.68544090779739,
    "ttft": 1840379.1347719352,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1019,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3247060670447595,
    "arrivals": 252137,
    "finished_requests": 75090,
    "scheduler_time": 101.8534571468581
}
#Debug simulation 
Total elapsed time: 5.591923539061099. Arrivals time: 0.23865119786933064 Scheduler time: 5.25236876681447 Scheduler overhead time: 0.030061190016567707 Adapter cache time: 0.025626033078879118 Engine time: 0.03102408954873681 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-32/adapters_256_slots_128_rate_0.8-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-32/adapters_256_slots_128_rate_0.8-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 8640, 33, 8640, 8640, 33, 8640, 135, 8640, 33, 135, 33, 8640, 135, 135, 135, 135, 8640, 33, 33, 33, 135, 8640, 33, 8640, 8640, 135, 135, 135, 33, 8640, 33, 135, 135, 33, 135, 33, 33, 135, 135, 8640, 135, 33, 135, 8640, 135, 135, 8640, 135, 8640, 33, 8640, 8640, 135, 33, 33, 8640, 135, 33, 135, 135, 8640, 135, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 8640, 8640, 33, 8640, 33, 135, 8640, 8640, 8640, 135, 33, 8640, 135, 33, 33, 33, 33, 33, 8640, 135, 33, 8640, 33, 8640, 33, 33, 135, 135, 8640, 135, 8640, 33, 135, 33, 8640, 8640, 33, 8640, 135, 33, 8640, 33, 33, 8640, 8640, 135, 8640, 8640, 33, 8640, 135, 135, 33, 135, 8640, 8640, 33, 8640, 135, 33, 135, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 135, 8640, 8640, 135, 33, 8640, 33, 135, 135, 33, 135, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 135, 8640, 135, 33, 135, 8640, 135, 8640, 33, 8640, 33, 135, 8640, 135, 8640, 135, 8640, 135, 8640, 135, 33, 8640, 33, 8640, 135, 135, 33, 135, 8640, 135, 135, 8640, 33, 8640, 8640, 135, 33, 8640, 8640, 135, 135, 8640, 8640, 135, 135, 135, 135, 8640, 8640, 135, 135, 8640, 33, 8640, 135, 8640, 8640, 33, 8640, 135, 135, 8640, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 8640, 135, 33, 33, 33, 33]
Prompts retrieved: 757320 . Total input tokens: 168812283 . Total output tokens: 151525896
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.479825913906097,
    "estimated_duration": 3600.1723453965724,
    "input_throughput": 5035.772807705113,
    "output_throughput": 4453.413187427253,
    "total_throughput": 9489.185995132366,
    "itl": 156.81862135343226,
    "ttft": 1866692.4457294417,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 995,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.250884600914978,
    "arrivals": 252137,
    "finished_requests": 72945,
    "scheduler_time": 106.9133275953992
}
#Debug simulation 
Total elapsed time: 5.47990988008678. Arrivals time: 0.2307985033839941 Scheduler time: 5.133346602786332 Scheduler overhead time: 0.035172213800251484 Adapter cache time: 0.027553987689316273 Engine time: 0.03641379019245505 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-16/adapters_256_slots_128_rate_0.8-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-16/adapters_256_slots_128_rate_0.8-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 8640, 33, 8640, 8640, 33, 8640, 135, 8640, 33, 135, 33, 8640, 135, 135, 135, 135, 8640, 33, 33, 33, 135, 8640, 33, 8640, 8640, 135, 135, 135, 33, 8640, 33, 135, 135, 33, 135, 33, 33, 135, 135, 8640, 135, 33, 135, 8640, 135, 135, 8640, 135, 8640, 33, 8640, 8640, 135, 33, 33, 8640, 135, 33, 135, 135, 8640, 135, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 8640, 8640, 33, 8640, 33, 135, 8640, 8640, 8640, 135, 33, 8640, 135, 33, 33, 33, 33, 33, 8640, 135, 33, 8640, 33, 8640, 33, 33, 135, 135, 8640, 135, 8640, 33, 135, 33, 8640, 8640, 33, 8640, 135, 33, 8640, 33, 33, 8640, 8640, 135, 8640, 8640, 33, 8640, 135, 135, 33, 135, 8640, 8640, 33, 8640, 135, 33, 135, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 135, 8640, 8640, 135, 33, 8640, 33, 135, 135, 33, 135, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 135, 8640, 135, 33, 135, 8640, 135, 8640, 33, 8640, 33, 135, 8640, 135, 8640, 135, 8640, 135, 8640, 135, 33, 8640, 33, 8640, 135, 135, 33, 135, 8640, 135, 135, 8640, 33, 8640, 8640, 135, 33, 8640, 8640, 135, 135, 8640, 8640, 135, 135, 135, 135, 8640, 8640, 135, 135, 8640, 33, 8640, 135, 8640, 8640, 33, 8640, 135, 135, 8640, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 8640, 135, 33, 33, 33, 33]
Prompts retrieved: 757320 . Total input tokens: 168812283 . Total output tokens: 151525896
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.574739841744304,
    "estimated_duration": 3600.184911127273,
    "input_throughput": 5183.673744734568,
    "output_throughput": 4577.052681119207,
    "total_throughput": 9760.726425853774,
    "itl": 187.68212771896847,
    "ttft": 1840376.6574660107,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1019,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.202536066831062,
    "arrivals": 252137,
    "finished_requests": 75092,
    "scheduler_time": 101.85690298357437
}
#Debug simulation 
Total elapsed time: 5.57482928596437. Arrivals time: 0.23574837483465672 Scheduler time: 5.238320142496377 Scheduler overhead time: 0.03017745167016983 Adapter cache time: 0.025238404981791973 Engine time: 0.031230999156832695 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-32/adapters_256_slots_128_rate_0.8-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-32/adapters_256_slots_128_rate_0.8-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 8640, 33, 8640, 8640, 33, 8640, 135, 8640, 33, 135, 33, 8640, 135, 135, 135, 135, 8640, 33, 33, 33, 135, 8640, 33, 8640, 8640, 135, 135, 135, 33, 8640, 33, 135, 135, 33, 135, 33, 33, 135, 135, 8640, 135, 33, 135, 8640, 135, 135, 8640, 135, 8640, 33, 8640, 8640, 135, 33, 33, 8640, 135, 33, 135, 135, 8640, 135, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 8640, 8640, 33, 8640, 33, 135, 8640, 8640, 8640, 135, 33, 8640, 135, 33, 33, 33, 33, 33, 8640, 135, 33, 8640, 33, 8640, 33, 33, 135, 135, 8640, 135, 8640, 33, 135, 33, 8640, 8640, 33, 8640, 135, 33, 8640, 33, 33, 8640, 8640, 135, 8640, 8640, 33, 8640, 135, 135, 33, 135, 8640, 8640, 33, 8640, 135, 33, 135, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 135, 8640, 8640, 135, 33, 8640, 33, 135, 135, 33, 135, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 135, 8640, 135, 33, 135, 8640, 135, 8640, 33, 8640, 33, 135, 8640, 135, 8640, 135, 8640, 135, 8640, 135, 33, 8640, 33, 8640, 135, 135, 33, 135, 8640, 135, 135, 8640, 33, 8640, 8640, 135, 33, 8640, 8640, 135, 135, 8640, 8640, 135, 135, 135, 135, 8640, 8640, 135, 135, 8640, 33, 8640, 135, 8640, 8640, 33, 8640, 135, 135, 8640, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 8640, 135, 33, 33, 33, 33]
Prompts retrieved: 757320 . Total input tokens: 168812283 . Total output tokens: 151525896
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 5.5019506542012095,
    "estimated_duration": 3600.0454457807714,
    "input_throughput": 5035.950038144053,
    "output_throughput": 4453.47766895283,
    "total_throughput": 9489.427707096882,
    "itl": 156.81862280916565,
    "ttft": 1866747.2486544307,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 994,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2841839263401864,
    "arrivals": 252137,
    "finished_requests": 72944,
    "scheduler_time": 106.90982290217494
}
#Debug simulation 
Total elapsed time: 5.502043669112027. Arrivals time: 0.24452405981719494 Scheduler time: 5.141095811966807 Scheduler overhead time: 0.035321698524057865 Adapter cache time: 0.027439566794782877 Engine time: 0.03670583013445139 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-16/adapters_256_slots_128_rate_0.8-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-16/adapters_256_slots_128_rate_0.8-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 8640, 33, 8640, 8640, 33, 8640, 135, 8640, 33, 135, 33, 8640, 135, 135, 135, 135, 8640, 33, 33, 33, 135, 8640, 33, 8640, 8640, 135, 135, 135, 33, 8640, 33, 135, 135, 33, 135, 33, 33, 135, 135, 8640, 135, 33, 135, 8640, 135, 135, 8640, 135, 8640, 33, 8640, 8640, 135, 33, 33, 8640, 135, 33, 135, 135, 8640, 135, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 8640, 8640, 33, 8640, 33, 135, 8640, 8640, 8640, 135, 33, 8640, 135, 33, 33, 33, 33, 33, 8640, 135, 33, 8640, 33, 8640, 33, 33, 135, 135, 8640, 135, 8640, 33, 135, 33, 8640, 8640, 33, 8640, 135, 33, 8640, 33, 33, 8640, 8640, 135, 8640, 8640, 33, 8640, 135, 135, 33, 135, 8640, 8640, 33, 8640, 135, 33, 135, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 135, 8640, 8640, 135, 33, 8640, 33, 135, 135, 33, 135, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 135, 8640, 135, 33, 135, 8640, 135, 8640, 33, 8640, 33, 135, 8640, 135, 8640, 135, 8640, 135, 8640, 135, 33, 8640, 33, 8640, 135, 135, 33, 135, 8640, 135, 135, 8640, 33, 8640, 8640, 135, 33, 8640, 8640, 135, 135, 8640, 8640, 135, 135, 135, 135, 8640, 8640, 135, 135, 8640, 33, 8640, 135, 8640, 8640, 33, 8640, 135, 135, 8640, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 8640, 135, 33, 33, 33, 33]
Prompts retrieved: 757320 . Total input tokens: 168812283 . Total output tokens: 151525896
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.571436776779592,
    "estimated_duration": 3600.182581150605,
    "input_throughput": 5184.27068052614,
    "output_throughput": 4577.432568637445,
    "total_throughput": 9761.703249163584,
    "itl": 187.67487889094565,
    "ttft": 1840278.3807849505,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1019,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0468612505052457,
    "arrivals": 252137,
    "finished_requests": 75100,
    "scheduler_time": 101.86112157042677
}
#Debug simulation 
Total elapsed time: 5.571553872898221. Arrivals time: 0.2332115052267909 Scheduler time: 5.237659057602286 Scheduler overhead time: 0.03019703272730112 Adapter cache time: 0.025117789395153522 Engine time: 0.031119043473154306 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-32/adapters_256_slots_128_rate_0.8-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-32/adapters_256_slots_128_rate_0.8-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 8640, 33, 8640, 8640, 33, 8640, 135, 8640, 33, 135, 33, 8640, 135, 135, 135, 135, 8640, 33, 33, 33, 135, 8640, 33, 8640, 8640, 135, 135, 135, 33, 8640, 33, 135, 135, 33, 135, 33, 33, 135, 135, 8640, 135, 33, 135, 8640, 135, 135, 8640, 135, 8640, 33, 8640, 8640, 135, 33, 33, 8640, 135, 33, 135, 135, 8640, 135, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 8640, 8640, 33, 8640, 33, 135, 8640, 8640, 8640, 135, 33, 8640, 135, 33, 33, 33, 33, 33, 8640, 135, 33, 8640, 33, 8640, 33, 33, 135, 135, 8640, 135, 8640, 33, 135, 33, 8640, 8640, 33, 8640, 135, 33, 8640, 33, 33, 8640, 8640, 135, 8640, 8640, 33, 8640, 135, 135, 33, 135, 8640, 8640, 33, 8640, 135, 33, 135, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 135, 8640, 8640, 135, 33, 8640, 33, 135, 135, 33, 135, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 135, 8640, 135, 33, 135, 8640, 135, 8640, 33, 8640, 33, 135, 8640, 135, 8640, 135, 8640, 135, 8640, 135, 33, 8640, 33, 8640, 135, 135, 33, 135, 8640, 135, 135, 8640, 33, 8640, 8640, 135, 33, 8640, 8640, 135, 135, 8640, 8640, 135, 135, 135, 135, 8640, 8640, 135, 135, 8640, 33, 8640, 135, 8640, 8640, 33, 8640, 135, 135, 8640, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 8640, 135, 33, 33, 33, 33]
Prompts retrieved: 757320 . Total input tokens: 168812283 . Total output tokens: 151525896
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.678812322206795,
    "estimated_duration": 3600.1329048168895,
    "input_throughput": 5035.827698400516,
    "output_throughput": 4453.369479373556,
    "total_throughput": 9489.197177774073,
    "itl": 156.82084133514215,
    "ttft": 1866720.1526022756,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 994,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3308385811001475,
    "arrivals": 252137,
    "finished_requests": 72944,
    "scheduler_time": 106.91117216735904
}
#Debug simulation 
Total elapsed time: 5.678873321041465. Arrivals time: 0.2328952425159514 Scheduler time: 5.330420853570104 Scheduler overhead time: 0.03558692801743746 Adapter cache time: 0.02708461182191968 Engine time: 0.03631009720265865 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-8/adapters_256_slots_128_rate_0.8-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-8/adapters_256_slots_128_rate_0.8-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 8640, 33, 8640, 8640, 33, 8640, 66, 8640, 33, 66, 33, 8640, 66, 66, 66, 66, 8640, 33, 33, 33, 66, 8640, 33, 8640, 8640, 66, 66, 66, 33, 8640, 33, 66, 66, 33, 66, 33, 33, 66, 66, 8640, 66, 33, 66, 8640, 66, 66, 8640, 66, 8640, 33, 8640, 8640, 66, 33, 33, 8640, 66, 33, 66, 66, 8640, 66, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 8640, 8640, 33, 8640, 33, 66, 8640, 8640, 8640, 66, 33, 8640, 66, 33, 33, 33, 33, 33, 8640, 66, 33, 8640, 33, 8640, 33, 33, 66, 66, 8640, 66, 8640, 33, 66, 33, 8640, 8640, 33, 8640, 66, 33, 8640, 33, 33, 8640, 8640, 66, 8640, 8640, 33, 8640, 66, 66, 33, 66, 8640, 8640, 33, 8640, 66, 33, 66, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 66, 8640, 8640, 66, 33, 8640, 33, 66, 66, 33, 66, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 66, 8640, 66, 33, 66, 8640, 66, 8640, 33, 8640, 33, 66, 8640, 66, 8640, 66, 8640, 66, 8640, 66, 33, 8640, 33, 8640, 66, 66, 33, 66, 8640, 66, 66, 8640, 33, 8640, 8640, 66, 33, 8640, 8640, 66, 66, 8640, 8640, 66, 66, 66, 66, 8640, 8640, 66, 66, 8640, 33, 8640, 66, 8640, 8640, 33, 8640, 66, 66, 8640, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 8640, 66, 33, 33, 33, 33]
Prompts retrieved: 751455 . Total input tokens: 167503193 . Total output tokens: 150337789
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.7141727288253605,
    "estimated_duration": 3600.1162029514503,
    "input_throughput": 5350.082029077144,
    "output_throughput": 4713.689237610658,
    "total_throughput": 10063.771266687803,
    "itl": 181.85620863286337,
    "ttft": 1806392.5102293147,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 728,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.228035077583086,
    "arrivals": 250206,
    "finished_requests": 77786,
    "scheduler_time": 104.80522218207015
}
#Debug simulation 
Total elapsed time: 5.714263755828142. Arrivals time: 0.23797613754868507 Scheduler time: 5.37910869717598 Scheduler overhead time: 0.03101519402116537 Adapter cache time: 0.019814719446003437 Engine time: 0.03190050134435296 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-16/adapters_256_slots_128_rate_0.8-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-16/adapters_256_slots_128_rate_0.8-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 8640, 33, 8640, 8640, 33, 8640, 66, 8640, 33, 66, 33, 8640, 66, 66, 66, 66, 8640, 33, 33, 33, 66, 8640, 33, 8640, 8640, 66, 66, 66, 33, 8640, 33, 66, 66, 33, 66, 33, 33, 66, 66, 8640, 66, 33, 66, 8640, 66, 66, 8640, 66, 8640, 33, 8640, 8640, 66, 33, 33, 8640, 66, 33, 66, 66, 8640, 66, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 8640, 8640, 33, 8640, 33, 66, 8640, 8640, 8640, 66, 33, 8640, 66, 33, 33, 33, 33, 33, 8640, 66, 33, 8640, 33, 8640, 33, 33, 66, 66, 8640, 66, 8640, 33, 66, 33, 8640, 8640, 33, 8640, 66, 33, 8640, 33, 33, 8640, 8640, 66, 8640, 8640, 33, 8640, 66, 66, 33, 66, 8640, 8640, 33, 8640, 66, 33, 66, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 66, 8640, 8640, 66, 33, 8640, 33, 66, 66, 33, 66, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 66, 8640, 66, 33, 66, 8640, 66, 8640, 33, 8640, 33, 66, 8640, 66, 8640, 66, 8640, 66, 8640, 66, 33, 8640, 33, 8640, 66, 66, 33, 66, 8640, 66, 66, 8640, 33, 8640, 8640, 66, 33, 8640, 8640, 66, 66, 8640, 8640, 66, 66, 66, 66, 8640, 8640, 66, 66, 8640, 33, 8640, 66, 8640, 8640, 33, 8640, 66, 66, 8640, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 8640, 66, 33, 33, 33, 33]
Prompts retrieved: 751455 . Total input tokens: 167503193 . Total output tokens: 150337789
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.975072118919343,
    "estimated_duration": 3600.130380262695,
    "input_throughput": 5350.060960457373,
    "output_throughput": 4713.670675105312,
    "total_throughput": 10063.731635562684,
    "itl": 181.8615254660803,
    "ttft": 1806416.143210609,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 728,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3736995581770373,
    "arrivals": 250206,
    "finished_requests": 77786,
    "scheduler_time": 104.80276067515186
}
#Debug simulation 
Total elapsed time: 5.975164344068617. Arrivals time: 0.47391921281814575 Scheduler time: 5.403786146547645 Scheduler overhead time: 0.031043078284710646 Adapter cache time: 0.01956900069490075 Engine time: 0.03222895134240389 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-32/adapters_256_slots_128_rate_0.8-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-32/adapters_256_slots_128_rate_0.8-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 8640, 33, 8640, 8640, 33, 8640, 66, 8640, 33, 66, 33, 8640, 66, 66, 66, 66, 8640, 33, 33, 33, 66, 8640, 33, 8640, 8640, 66, 66, 66, 33, 8640, 33, 66, 66, 33, 66, 33, 33, 66, 66, 8640, 66, 33, 66, 8640, 66, 66, 8640, 66, 8640, 33, 8640, 8640, 66, 33, 33, 8640, 66, 33, 66, 66, 8640, 66, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 8640, 8640, 33, 8640, 33, 66, 8640, 8640, 8640, 66, 33, 8640, 66, 33, 33, 33, 33, 33, 8640, 66, 33, 8640, 33, 8640, 33, 33, 66, 66, 8640, 66, 8640, 33, 66, 33, 8640, 8640, 33, 8640, 66, 33, 8640, 33, 33, 8640, 8640, 66, 8640, 8640, 33, 8640, 66, 66, 33, 66, 8640, 8640, 33, 8640, 66, 33, 66, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 66, 8640, 8640, 66, 33, 8640, 33, 66, 66, 33, 66, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 66, 8640, 66, 33, 66, 8640, 66, 8640, 33, 8640, 33, 66, 8640, 66, 8640, 66, 8640, 66, 8640, 66, 33, 8640, 33, 8640, 66, 66, 33, 66, 8640, 66, 66, 8640, 33, 8640, 8640, 66, 33, 8640, 8640, 66, 66, 8640, 8640, 66, 66, 66, 66, 8640, 8640, 66, 66, 8640, 33, 8640, 66, 8640, 8640, 33, 8640, 66, 66, 8640, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 8640, 66, 33, 33, 33, 33]
Prompts retrieved: 751455 . Total input tokens: 167503193 . Total output tokens: 150337789
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.559129749890417,
    "estimated_duration": 3600.070869022303,
    "input_throughput": 5171.856243223486,
    "output_throughput": 4568.405622655566,
    "total_throughput": 9740.261865879052,
    "itl": 153.13220938983298,
    "ttft": 1836536.5504888648,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 704,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2994573544897148,
    "arrivals": 250206,
    "finished_requests": 75280,
    "scheduler_time": 109.38913959630088
}
#Debug simulation 
Total elapsed time: 5.559248209930956. Arrivals time: 0.23807255364954472 Scheduler time: 5.210500270593911 Scheduler overhead time: 0.03590071387588978 Adapter cache time: 0.020704657305032015 Engine time: 0.03704667976126075 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-16/adapters_256_slots_128_rate_0.8-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-16/adapters_256_slots_128_rate_0.8-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 8640, 33, 8640, 8640, 33, 8640, 66, 8640, 33, 66, 33, 8640, 66, 66, 66, 66, 8640, 33, 33, 33, 66, 8640, 33, 8640, 8640, 66, 66, 66, 33, 8640, 33, 66, 66, 33, 66, 33, 33, 66, 66, 8640, 66, 33, 66, 8640, 66, 66, 8640, 66, 8640, 33, 8640, 8640, 66, 33, 33, 8640, 66, 33, 66, 66, 8640, 66, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 8640, 8640, 33, 8640, 33, 66, 8640, 8640, 8640, 66, 33, 8640, 66, 33, 33, 33, 33, 33, 8640, 66, 33, 8640, 33, 8640, 33, 33, 66, 66, 8640, 66, 8640, 33, 66, 33, 8640, 8640, 33, 8640, 66, 33, 8640, 33, 33, 8640, 8640, 66, 8640, 8640, 33, 8640, 66, 66, 33, 66, 8640, 8640, 33, 8640, 66, 33, 66, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 66, 8640, 8640, 66, 33, 8640, 33, 66, 66, 33, 66, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 66, 8640, 66, 33, 66, 8640, 66, 8640, 33, 8640, 33, 66, 8640, 66, 8640, 66, 8640, 66, 8640, 66, 33, 8640, 33, 8640, 66, 66, 33, 66, 8640, 66, 66, 8640, 33, 8640, 8640, 66, 33, 8640, 8640, 66, 66, 8640, 8640, 66, 66, 66, 66, 8640, 8640, 66, 66, 8640, 33, 8640, 66, 8640, 8640, 33, 8640, 66, 66, 8640, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 8640, 66, 33, 33, 33, 33]
Prompts retrieved: 751455 . Total input tokens: 167503193 . Total output tokens: 150337789
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.9160749129951,
    "estimated_duration": 3600.0026827795286,
    "input_throughput": 5350.189624061334,
    "output_throughput": 4713.692042834301,
    "total_throughput": 10063.881666895635,
    "itl": 181.85816162667805,
    "ttft": 1806415.1006822854,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 728,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2793140396172955,
    "arrivals": 250206,
    "finished_requests": 77784,
    "scheduler_time": 104.80039284520167
}
#Debug simulation 
Total elapsed time: 5.916139559820294. Arrivals time: 0.47423606691882014 Scheduler time: 5.34473327267915 Scheduler overhead time: 0.03099282644689083 Adapter cache time: 0.019651563838124275 Engine time: 0.032145177479833364 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-32/adapters_256_slots_128_rate_0.8-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-32/adapters_256_slots_128_rate_0.8-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 8640, 33, 8640, 8640, 33, 8640, 66, 8640, 33, 66, 33, 8640, 66, 66, 66, 66, 8640, 33, 33, 33, 66, 8640, 33, 8640, 8640, 66, 66, 66, 33, 8640, 33, 66, 66, 33, 66, 33, 33, 66, 66, 8640, 66, 33, 66, 8640, 66, 66, 8640, 66, 8640, 33, 8640, 8640, 66, 33, 33, 8640, 66, 33, 66, 66, 8640, 66, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 8640, 8640, 33, 8640, 33, 66, 8640, 8640, 8640, 66, 33, 8640, 66, 33, 33, 33, 33, 33, 8640, 66, 33, 8640, 33, 8640, 33, 33, 66, 66, 8640, 66, 8640, 33, 66, 33, 8640, 8640, 33, 8640, 66, 33, 8640, 33, 33, 8640, 8640, 66, 8640, 8640, 33, 8640, 66, 66, 33, 66, 8640, 8640, 33, 8640, 66, 33, 66, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 66, 8640, 8640, 66, 33, 8640, 33, 66, 66, 33, 66, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 66, 8640, 66, 33, 66, 8640, 66, 8640, 33, 8640, 33, 66, 8640, 66, 8640, 66, 8640, 66, 8640, 66, 33, 8640, 33, 8640, 66, 66, 33, 66, 8640, 66, 66, 8640, 33, 8640, 8640, 66, 33, 8640, 8640, 66, 66, 8640, 8640, 66, 66, 66, 66, 8640, 8640, 66, 66, 8640, 33, 8640, 66, 8640, 8640, 33, 8640, 66, 66, 8640, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 8640, 66, 33, 33, 33, 33]
Prompts retrieved: 751455 . Total input tokens: 167503193 . Total output tokens: 150337789
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 5.582562090829015,
    "estimated_duration": 3600.120386610751,
    "input_throughput": 5171.887048346406,
    "output_throughput": 4568.553057605933,
    "total_throughput": 9740.440105952339,
    "itl": 153.14148394102156,
    "ttft": 1836505.116484541,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 704,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3276262026466457,
    "arrivals": 250206,
    "finished_requests": 75282,
    "scheduler_time": 109.38812269780388
}
#Debug simulation 
Total elapsed time: 5.582646970171481. Arrivals time: 0.24843742698431015 Scheduler time: 5.221119701396674 Scheduler overhead time: 0.03591332770884037 Adapter cache time: 0.021077284589409828 Engine time: 0.03721576649695635 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-16/adapters_256_slots_128_rate_0.8-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-16/adapters_256_slots_128_rate_0.8-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 8640, 33, 8640, 8640, 33, 8640, 66, 8640, 33, 66, 33, 8640, 66, 66, 66, 66, 8640, 33, 33, 33, 66, 8640, 33, 8640, 8640, 66, 66, 66, 33, 8640, 33, 66, 66, 33, 66, 33, 33, 66, 66, 8640, 66, 33, 66, 8640, 66, 66, 8640, 66, 8640, 33, 8640, 8640, 66, 33, 33, 8640, 66, 33, 66, 66, 8640, 66, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 8640, 8640, 33, 8640, 33, 66, 8640, 8640, 8640, 66, 33, 8640, 66, 33, 33, 33, 33, 33, 8640, 66, 33, 8640, 33, 8640, 33, 33, 66, 66, 8640, 66, 8640, 33, 66, 33, 8640, 8640, 33, 8640, 66, 33, 8640, 33, 33, 8640, 8640, 66, 8640, 8640, 33, 8640, 66, 66, 33, 66, 8640, 8640, 33, 8640, 66, 33, 66, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 66, 8640, 8640, 66, 33, 8640, 33, 66, 66, 33, 66, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 66, 8640, 66, 33, 66, 8640, 66, 8640, 33, 8640, 33, 66, 8640, 66, 8640, 66, 8640, 66, 8640, 66, 33, 8640, 33, 8640, 66, 66, 33, 66, 8640, 66, 66, 8640, 33, 8640, 8640, 66, 33, 8640, 8640, 66, 66, 8640, 8640, 66, 66, 66, 66, 8640, 8640, 66, 66, 8640, 33, 8640, 66, 8640, 8640, 33, 8640, 66, 66, 8640, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 8640, 66, 33, 33, 33, 33]
Prompts retrieved: 751455 . Total input tokens: 167503193 . Total output tokens: 150337789
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.938143631909043,
    "estimated_duration": 3600.184288345634,
    "input_throughput": 5350.20472767276,
    "output_throughput": 4713.909522614614,
    "total_throughput": 10064.114250287374,
    "itl": 181.85157058320772,
    "ttft": 1806367.4724016378,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 728,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1767566146887436,
    "arrivals": 250206,
    "finished_requests": 77791,
    "scheduler_time": 104.80893979134534
}
#Debug simulation 
Total elapsed time: 5.938242681790143. Arrivals time: 0.47097568213939667 Scheduler time: 5.36840954888612 Scheduler overhead time: 0.031094121281057596 Adapter cache time: 0.020036255475133657 Engine time: 0.03277225000783801 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-32/adapters_256_slots_128_rate_0.8-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-32/adapters_256_slots_128_rate_0.8-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 8640, 33, 8640, 8640, 33, 8640, 66, 8640, 33, 66, 33, 8640, 66, 66, 66, 66, 8640, 33, 33, 33, 66, 8640, 33, 8640, 8640, 66, 66, 66, 33, 8640, 33, 66, 66, 33, 66, 33, 33, 66, 66, 8640, 66, 33, 66, 8640, 66, 66, 8640, 66, 8640, 33, 8640, 8640, 66, 33, 33, 8640, 66, 33, 66, 66, 8640, 66, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 8640, 8640, 33, 8640, 33, 66, 8640, 8640, 8640, 66, 33, 8640, 66, 33, 33, 33, 33, 33, 8640, 66, 33, 8640, 33, 8640, 33, 33, 66, 66, 8640, 66, 8640, 33, 66, 33, 8640, 8640, 33, 8640, 66, 33, 8640, 33, 33, 8640, 8640, 66, 8640, 8640, 33, 8640, 66, 66, 33, 66, 8640, 8640, 33, 8640, 66, 33, 66, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 66, 8640, 8640, 66, 33, 8640, 33, 66, 66, 33, 66, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 66, 8640, 66, 33, 66, 8640, 66, 8640, 33, 8640, 33, 66, 8640, 66, 8640, 66, 8640, 66, 8640, 66, 33, 8640, 33, 8640, 66, 66, 33, 66, 8640, 66, 66, 8640, 33, 8640, 8640, 66, 33, 8640, 8640, 66, 66, 8640, 8640, 66, 66, 66, 66, 8640, 8640, 66, 66, 8640, 33, 8640, 66, 8640, 8640, 33, 8640, 66, 66, 8640, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 8640, 66, 33, 33, 33, 33]
Prompts retrieved: 751455 . Total input tokens: 167503193 . Total output tokens: 150337789
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.59735522326082,
    "estimated_duration": 3600.116618712442,
    "input_throughput": 5171.721355698442,
    "output_throughput": 4568.466175376887,
    "total_throughput": 9740.18753107533,
    "itl": 153.13331825804363,
    "ttft": 1836480.5170212116,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 704,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3579328651726312,
    "arrivals": 250206,
    "finished_requests": 75280,
    "scheduler_time": 109.38934904020108
}
#Debug simulation 
Total elapsed time: 5.597443934995681. Arrivals time: 0.23979110410436988 Scheduler time: 5.246141593437642 Scheduler overhead time: 0.03635820560157299 Adapter cache time: 0.020828496664762497 Engine time: 0.03726606676355004 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-8/adapters_256_slots_128_rate_0.4-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-8/adapters_256_slots_128_rate_0.4-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 540, 4320, 4320, 540, 4320, 1080, 4320, 540, 1080, 540, 4320, 1080, 1080, 1080, 1080, 4320, 540, 540, 540, 1080, 4320, 540, 4320, 4320, 1080, 1080, 1080, 540, 4320, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 4320, 1080, 540, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 540, 4320, 4320, 1080, 540, 540, 4320, 1080, 540, 1080, 1080, 4320, 1080, 540, 540, 4320, 4320, 4320, 4320, 4320, 4320, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 4320, 4320, 540, 4320, 540, 1080, 4320, 4320, 4320, 1080, 540, 4320, 1080, 540, 540, 540, 540, 540, 4320, 1080, 540, 4320, 540, 4320, 540, 540, 1080, 1080, 4320, 1080, 4320, 540, 1080, 540, 4320, 4320, 540, 4320, 1080, 540, 4320, 540, 540, 4320, 4320, 1080, 4320, 4320, 540, 4320, 1080, 1080, 540, 1080, 4320, 4320, 540, 4320, 1080, 540, 1080, 4320, 540, 540, 540, 540, 540, 540, 4320, 540, 540, 540, 4320, 540, 1080, 4320, 4320, 1080, 540, 4320, 540, 1080, 1080, 540, 1080, 540, 4320, 540, 540, 4320, 540, 4320, 4320, 1080, 4320, 1080, 540, 1080, 4320, 1080, 4320, 540, 4320, 540, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 540, 4320, 540, 4320, 1080, 1080, 540, 1080, 4320, 1080, 1080, 4320, 540, 4320, 4320, 1080, 540, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 540, 4320, 1080, 4320, 4320, 540, 4320, 1080, 1080, 4320, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 540, 540, 540, 540]
Prompts retrieved: 509220 . Total input tokens: 113498046 . Total output tokens: 101959663
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 12.290680189151317,
    "estimated_duration": 3600.1269769969795,
    "input_throughput": 4617.7546253846895,
    "output_throughput": 4094.960565056861,
    "total_throughput": 8712.71519044155,
    "itl": 209.60762937580344,
    "ttft": 1759558.3036844973,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 757,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.316789222157139,
    "arrivals": 169450,
    "finished_requests": 67165,
    "scheduler_time": 89.07839726663144
}
#Debug simulation 
Total elapsed time: 12.290769197046757. Arrivals time: 0.2545258719474077 Scheduler time: 11.937570036388934 Scheduler overhead time: 0.032752353232353926 Adapter cache time: 0.020125778391957283 Engine time: 0.032034116331487894 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-16/adapters_256_slots_128_rate_0.4-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-16/adapters_256_slots_128_rate_0.4-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 540, 4320, 4320, 540, 4320, 1080, 4320, 540, 1080, 540, 4320, 1080, 1080, 1080, 1080, 4320, 540, 540, 540, 1080, 4320, 540, 4320, 4320, 1080, 1080, 1080, 540, 4320, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 4320, 1080, 540, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 540, 4320, 4320, 1080, 540, 540, 4320, 1080, 540, 1080, 1080, 4320, 1080, 540, 540, 4320, 4320, 4320, 4320, 4320, 4320, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 4320, 4320, 540, 4320, 540, 1080, 4320, 4320, 4320, 1080, 540, 4320, 1080, 540, 540, 540, 540, 540, 4320, 1080, 540, 4320, 540, 4320, 540, 540, 1080, 1080, 4320, 1080, 4320, 540, 1080, 540, 4320, 4320, 540, 4320, 1080, 540, 4320, 540, 540, 4320, 4320, 1080, 4320, 4320, 540, 4320, 1080, 1080, 540, 1080, 4320, 4320, 540, 4320, 1080, 540, 1080, 4320, 540, 540, 540, 540, 540, 540, 4320, 540, 540, 540, 4320, 540, 1080, 4320, 4320, 1080, 540, 4320, 540, 1080, 1080, 540, 1080, 540, 4320, 540, 540, 4320, 540, 4320, 4320, 1080, 4320, 1080, 540, 1080, 4320, 1080, 4320, 540, 4320, 540, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 540, 4320, 540, 4320, 1080, 1080, 540, 1080, 4320, 1080, 1080, 4320, 540, 4320, 4320, 1080, 540, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 540, 4320, 1080, 4320, 4320, 540, 4320, 1080, 1080, 4320, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 540, 540, 540, 540]
Prompts retrieved: 509220 . Total input tokens: 113498046 . Total output tokens: 101959663
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 12.368791723623872,
    "estimated_duration": 3600.010596923731,
    "input_throughput": 4617.611129868621,
    "output_throughput": 4094.7965577092177,
    "total_throughput": 8712.40768757784,
    "itl": 209.61725085852098,
    "ttft": 1759594.5530451597,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 757,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4694001137348884,
    "arrivals": 169450,
    "finished_requests": 67161,
    "scheduler_time": 89.07252609195008
}
#Debug simulation 
Total elapsed time: 12.368916178587824. Arrivals time: 0.2540109851397574 Scheduler time: 12.015253944788128 Scheduler overhead time: 0.03282590443268418 Adapter cache time: 0.020260758232325315 Engine time: 0.03280084067955613 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-32/adapters_256_slots_128_rate_0.4-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-32/adapters_256_slots_128_rate_0.4-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 540, 4320, 4320, 540, 4320, 1080, 4320, 540, 1080, 540, 4320, 1080, 1080, 1080, 1080, 4320, 540, 540, 540, 1080, 4320, 540, 4320, 4320, 1080, 1080, 1080, 540, 4320, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 4320, 1080, 540, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 540, 4320, 4320, 1080, 540, 540, 4320, 1080, 540, 1080, 1080, 4320, 1080, 540, 540, 4320, 4320, 4320, 4320, 4320, 4320, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 4320, 4320, 540, 4320, 540, 1080, 4320, 4320, 4320, 1080, 540, 4320, 1080, 540, 540, 540, 540, 540, 4320, 1080, 540, 4320, 540, 4320, 540, 540, 1080, 1080, 4320, 1080, 4320, 540, 1080, 540, 4320, 4320, 540, 4320, 1080, 540, 4320, 540, 540, 4320, 4320, 1080, 4320, 4320, 540, 4320, 1080, 1080, 540, 1080, 4320, 4320, 540, 4320, 1080, 540, 1080, 4320, 540, 540, 540, 540, 540, 540, 4320, 540, 540, 540, 4320, 540, 1080, 4320, 4320, 1080, 540, 4320, 540, 1080, 1080, 540, 1080, 540, 4320, 540, 540, 4320, 540, 4320, 4320, 1080, 4320, 1080, 540, 1080, 4320, 1080, 4320, 540, 4320, 540, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 540, 4320, 540, 4320, 1080, 1080, 540, 1080, 4320, 1080, 1080, 4320, 540, 4320, 4320, 1080, 540, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 540, 4320, 1080, 4320, 4320, 540, 4320, 1080, 1080, 4320, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 540, 540, 540, 540]
Prompts retrieved: 509220 . Total input tokens: 113498046 . Total output tokens: 101959663
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 8.8151591187343,
    "estimated_duration": 3600.059006462543,
    "input_throughput": 4423.891933829531,
    "output_throughput": 3929.0986549409413,
    "total_throughput": 8352.990588770472,
    "itl": 177.28971548134467,
    "ttft": 1807038.748583958,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1146,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.744517944026685,
    "arrivals": 169450,
    "finished_requests": 64345,
    "scheduler_time": 92.06908497329901
}
#Debug simulation 
Total elapsed time: 8.815247166901827. Arrivals time: 0.23254769062623382 Scheduler time: 8.470211885869503 Scheduler overhead time: 0.034132000524550676 Adapter cache time: 0.028593802824616432 Engine time: 0.03432832472026348 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-16-16/adapters_256_slots_128_rate_0.4-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-16-16/adapters_256_slots_128_rate_0.4-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 540, 4320, 4320, 540, 4320, 1080, 4320, 540, 1080, 540, 4320, 1080, 1080, 1080, 1080, 4320, 540, 540, 540, 1080, 4320, 540, 4320, 4320, 1080, 1080, 1080, 540, 4320, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 4320, 1080, 540, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 540, 4320, 4320, 1080, 540, 540, 4320, 1080, 540, 1080, 1080, 4320, 1080, 540, 540, 4320, 4320, 4320, 4320, 4320, 4320, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 4320, 4320, 540, 4320, 540, 1080, 4320, 4320, 4320, 1080, 540, 4320, 1080, 540, 540, 540, 540, 540, 4320, 1080, 540, 4320, 540, 4320, 540, 540, 1080, 1080, 4320, 1080, 4320, 540, 1080, 540, 4320, 4320, 540, 4320, 1080, 540, 4320, 540, 540, 4320, 4320, 1080, 4320, 4320, 540, 4320, 1080, 1080, 540, 1080, 4320, 4320, 540, 4320, 1080, 540, 1080, 4320, 540, 540, 540, 540, 540, 540, 4320, 540, 540, 540, 4320, 540, 1080, 4320, 4320, 1080, 540, 4320, 540, 1080, 1080, 540, 1080, 540, 4320, 540, 540, 4320, 540, 4320, 4320, 1080, 4320, 1080, 540, 1080, 4320, 1080, 4320, 540, 4320, 540, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 540, 4320, 540, 4320, 1080, 1080, 540, 1080, 4320, 1080, 1080, 4320, 540, 4320, 4320, 1080, 540, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 540, 4320, 1080, 4320, 4320, 540, 4320, 1080, 1080, 4320, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 540, 540, 540, 540]
Prompts retrieved: 509220 . Total input tokens: 113498046 . Total output tokens: 101959663
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 12.385365017689764,
    "estimated_duration": 3600.2035960031008,
    "input_throughput": 4617.8460624996505,
    "output_throughput": 4095.1925653227145,
    "total_throughput": 8713.038627822365,
    "itl": 209.61199370223753,
    "ttft": 1759558.7350138326,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 758,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.375144478240964,
    "arrivals": 169450,
    "finished_requests": 67169,
    "scheduler_time": 89.07912463149484
}
#Debug simulation 
Total elapsed time: 12.385453706141561. Arrivals time: 0.2577080950140953 Scheduler time: 12.02878031739965 Scheduler overhead time: 0.03270752262324095 Adapter cache time: 0.020065901335328817 Engine time: 0.03232414135709405 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-16-32/adapters_256_slots_128_rate_0.4-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-16-32/adapters_256_slots_128_rate_0.4-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 540, 4320, 4320, 540, 4320, 1080, 4320, 540, 1080, 540, 4320, 1080, 1080, 1080, 1080, 4320, 540, 540, 540, 1080, 4320, 540, 4320, 4320, 1080, 1080, 1080, 540, 4320, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 4320, 1080, 540, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 540, 4320, 4320, 1080, 540, 540, 4320, 1080, 540, 1080, 1080, 4320, 1080, 540, 540, 4320, 4320, 4320, 4320, 4320, 4320, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 4320, 4320, 540, 4320, 540, 1080, 4320, 4320, 4320, 1080, 540, 4320, 1080, 540, 540, 540, 540, 540, 4320, 1080, 540, 4320, 540, 4320, 540, 540, 1080, 1080, 4320, 1080, 4320, 540, 1080, 540, 4320, 4320, 540, 4320, 1080, 540, 4320, 540, 540, 4320, 4320, 1080, 4320, 4320, 540, 4320, 1080, 1080, 540, 1080, 4320, 4320, 540, 4320, 1080, 540, 1080, 4320, 540, 540, 540, 540, 540, 540, 4320, 540, 540, 540, 4320, 540, 1080, 4320, 4320, 1080, 540, 4320, 540, 1080, 1080, 540, 1080, 540, 4320, 540, 540, 4320, 540, 4320, 4320, 1080, 4320, 1080, 540, 1080, 4320, 1080, 4320, 540, 4320, 540, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 540, 4320, 540, 4320, 1080, 1080, 540, 1080, 4320, 1080, 1080, 4320, 540, 4320, 4320, 1080, 540, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 540, 4320, 1080, 4320, 4320, 540, 4320, 1080, 1080, 4320, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 540, 540, 540, 540]
Prompts retrieved: 509220 . Total input tokens: 113498046 . Total output tokens: 101959663
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 8.833954615984112,
    "estimated_duration": 3600.190540940253,
    "input_throughput": 4422.808409424197,
    "output_throughput": 3928.3509689757575,
    "total_throughput": 8351.159378399954,
    "itl": 177.26582156906173,
    "ttft": 1806233.9680463232,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1120,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.707456821966913,
    "arrivals": 169450,
    "finished_requests": 64311,
    "scheduler_time": 92.0795505036957
}
#Debug simulation 
Total elapsed time: 8.834074012003839. Arrivals time: 0.24149099364876747 Scheduler time: 8.479125873651356 Scheduler overhead time: 0.034378932788968086 Adapter cache time: 0.02901536226272583 Engine time: 0.03451295988634229 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_16-16-16/adapters_256_slots_128_rate_0.4-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_16-16-16/adapters_256_slots_128_rate_0.4-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 540, 4320, 4320, 540, 4320, 1080, 4320, 540, 1080, 540, 4320, 1080, 1080, 1080, 1080, 4320, 540, 540, 540, 1080, 4320, 540, 4320, 4320, 1080, 1080, 1080, 540, 4320, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 4320, 1080, 540, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 540, 4320, 4320, 1080, 540, 540, 4320, 1080, 540, 1080, 1080, 4320, 1080, 540, 540, 4320, 4320, 4320, 4320, 4320, 4320, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 4320, 4320, 540, 4320, 540, 1080, 4320, 4320, 4320, 1080, 540, 4320, 1080, 540, 540, 540, 540, 540, 4320, 1080, 540, 4320, 540, 4320, 540, 540, 1080, 1080, 4320, 1080, 4320, 540, 1080, 540, 4320, 4320, 540, 4320, 1080, 540, 4320, 540, 540, 4320, 4320, 1080, 4320, 4320, 540, 4320, 1080, 1080, 540, 1080, 4320, 4320, 540, 4320, 1080, 540, 1080, 4320, 540, 540, 540, 540, 540, 540, 4320, 540, 540, 540, 4320, 540, 1080, 4320, 4320, 1080, 540, 4320, 540, 1080, 1080, 540, 1080, 540, 4320, 540, 540, 4320, 540, 4320, 4320, 1080, 4320, 1080, 540, 1080, 4320, 1080, 4320, 540, 4320, 540, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 540, 4320, 540, 4320, 1080, 1080, 540, 1080, 4320, 1080, 1080, 4320, 540, 4320, 4320, 1080, 540, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 540, 4320, 1080, 4320, 4320, 540, 4320, 1080, 1080, 4320, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 540, 540, 540, 540]
Prompts retrieved: 509220 . Total input tokens: 113498046 . Total output tokens: 101959663
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 12.33126877201721,
    "estimated_duration": 3600.0673382808327,
    "input_throughput": 4617.831123108609,
    "output_throughput": 4095.0284021742877,
    "total_throughput": 8712.859525282898,
    "itl": 209.6063076312375,
    "ttft": 1759537.1655651743,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 758,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2664581235358057,
    "arrivals": 169450,
    "finished_requests": 67165,
    "scheduler_time": 89.07795113390884
}
#Debug simulation 
Total elapsed time: 12.331359679810703. Arrivals time: 0.2514889216981828 Scheduler time: 11.981730820145458 Scheduler overhead time: 0.03283432172611356 Adapter cache time: 0.01974473102018237 Engine time: 0.031929357908666134 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_16-16-32/adapters_256_slots_128_rate_0.4-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_16-16-32/adapters_256_slots_128_rate_0.4-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 540, 4320, 4320, 540, 4320, 1080, 4320, 540, 1080, 540, 4320, 1080, 1080, 1080, 1080, 4320, 540, 540, 540, 1080, 4320, 540, 4320, 4320, 1080, 1080, 1080, 540, 4320, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 4320, 1080, 540, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 540, 4320, 4320, 1080, 540, 540, 4320, 1080, 540, 1080, 1080, 4320, 1080, 540, 540, 4320, 4320, 4320, 4320, 4320, 4320, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 4320, 4320, 540, 4320, 540, 1080, 4320, 4320, 4320, 1080, 540, 4320, 1080, 540, 540, 540, 540, 540, 4320, 1080, 540, 4320, 540, 4320, 540, 540, 1080, 1080, 4320, 1080, 4320, 540, 1080, 540, 4320, 4320, 540, 4320, 1080, 540, 4320, 540, 540, 4320, 4320, 1080, 4320, 4320, 540, 4320, 1080, 1080, 540, 1080, 4320, 4320, 540, 4320, 1080, 540, 1080, 4320, 540, 540, 540, 540, 540, 540, 4320, 540, 540, 540, 4320, 540, 1080, 4320, 4320, 1080, 540, 4320, 540, 1080, 1080, 540, 1080, 540, 4320, 540, 540, 4320, 540, 4320, 4320, 1080, 4320, 1080, 540, 1080, 4320, 1080, 4320, 540, 4320, 540, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 540, 4320, 540, 4320, 1080, 1080, 540, 1080, 4320, 1080, 1080, 4320, 540, 4320, 4320, 1080, 540, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 540, 4320, 1080, 4320, 4320, 540, 4320, 1080, 1080, 4320, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 540, 540, 540, 540]
Prompts retrieved: 509220 . Total input tokens: 113498046 . Total output tokens: 101959663
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 8.778416756074876,
    "estimated_duration": 3600.0892604775927,
    "input_throughput": 4421.280653993682,
    "output_throughput": 3928.0348282597856,
    "total_throughput": 8349.315482253467,
    "itl": 177.24923715455495,
    "ttft": 1806328.6905894543,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1133,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7969468202069954,
    "arrivals": 169450,
    "finished_requests": 64300,
    "scheduler_time": 92.07757831545422
}
#Debug simulation 
Total elapsed time: 8.778519181068987. Arrivals time: 0.23452607402577996 Scheduler time: 8.431552519090474 Scheduler overhead time: 0.03414798807352781 Adapter cache time: 0.028532650787383318 Engine time: 0.03433614782989025 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-8/adapters_256_slots_128_rate_0.4-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-8/adapters_256_slots_128_rate_0.4-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 270, 4320, 4320, 270, 4320, 1080, 4320, 270, 1080, 270, 4320, 1080, 1080, 1080, 1080, 4320, 270, 270, 270, 1080, 4320, 270, 4320, 4320, 1080, 1080, 1080, 270, 4320, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 4320, 1080, 270, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 270, 4320, 4320, 1080, 270, 270, 4320, 1080, 270, 1080, 1080, 4320, 1080, 270, 270, 4320, 4320, 4320, 4320, 4320, 4320, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 4320, 4320, 270, 4320, 270, 1080, 4320, 4320, 4320, 1080, 270, 4320, 1080, 270, 270, 270, 270, 270, 4320, 1080, 270, 4320, 270, 4320, 270, 270, 1080, 1080, 4320, 1080, 4320, 270, 1080, 270, 4320, 4320, 270, 4320, 1080, 270, 4320, 270, 270, 4320, 4320, 1080, 4320, 4320, 270, 4320, 1080, 1080, 270, 1080, 4320, 4320, 270, 4320, 1080, 270, 1080, 4320, 270, 270, 270, 270, 270, 270, 4320, 270, 270, 270, 4320, 270, 1080, 4320, 4320, 1080, 270, 4320, 270, 1080, 1080, 270, 1080, 270, 4320, 270, 270, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 4320, 270, 4320, 270, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 1080, 1080, 270, 1080, 4320, 1080, 1080, 4320, 270, 4320, 4320, 1080, 270, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 270, 4320, 1080, 4320, 4320, 270, 4320, 1080, 1080, 4320, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 270, 270, 270, 270]
Prompts retrieved: 486270 . Total input tokens: 108366334 . Total output tokens: 97337453
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 10.278272341005504,
    "estimated_duration": 3600.0903562592725,
    "input_throughput": 4627.064143275722,
    "output_throughput": 4093.013380728268,
    "total_throughput": 8720.07752400399,
    "itl": 209.53604385650732,
    "ttft": 1731882.3351863201,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 840,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5708097049035663,
    "arrivals": 161934,
    "finished_requests": 67438,
    "scheduler_time": 88.69347328632422
}
#Debug simulation 
Total elapsed time: 10.278389973100275. Arrivals time: 0.24302849499508739 Scheduler time: 9.93880925886333 Scheduler overhead time: 0.030779678374528885 Adapter cache time: 0.021140267606824636 Engine time: 0.031099972315132618 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-16/adapters_256_slots_128_rate_0.4-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-16/adapters_256_slots_128_rate_0.4-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 270, 4320, 4320, 270, 4320, 1080, 4320, 270, 1080, 270, 4320, 1080, 1080, 1080, 1080, 4320, 270, 270, 270, 1080, 4320, 270, 4320, 4320, 1080, 1080, 1080, 270, 4320, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 4320, 1080, 270, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 270, 4320, 4320, 1080, 270, 270, 4320, 1080, 270, 1080, 1080, 4320, 1080, 270, 270, 4320, 4320, 4320, 4320, 4320, 4320, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 4320, 4320, 270, 4320, 270, 1080, 4320, 4320, 4320, 1080, 270, 4320, 1080, 270, 270, 270, 270, 270, 4320, 1080, 270, 4320, 270, 4320, 270, 270, 1080, 1080, 4320, 1080, 4320, 270, 1080, 270, 4320, 4320, 270, 4320, 1080, 270, 4320, 270, 270, 4320, 4320, 1080, 4320, 4320, 270, 4320, 1080, 1080, 270, 1080, 4320, 4320, 270, 4320, 1080, 270, 1080, 4320, 270, 270, 270, 270, 270, 270, 4320, 270, 270, 270, 4320, 270, 1080, 4320, 4320, 1080, 270, 4320, 270, 1080, 1080, 270, 1080, 270, 4320, 270, 270, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 4320, 270, 4320, 270, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 1080, 1080, 270, 1080, 4320, 1080, 1080, 4320, 270, 4320, 4320, 1080, 270, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 270, 4320, 1080, 4320, 4320, 270, 4320, 1080, 1080, 4320, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 270, 270, 270, 270]
Prompts retrieved: 486270 . Total input tokens: 108366334 . Total output tokens: 97337453
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 10.283918088302016,
    "estimated_duration": 3600.19730692592,
    "input_throughput": 4625.490932945319,
    "output_throughput": 4092.4976449639826,
    "total_throughput": 8717.988577909302,
    "itl": 209.55256471141178,
    "ttft": 1732063.6810153495,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 840,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7408642213628682,
    "arrivals": 161934,
    "finished_requests": 67429,
    "scheduler_time": 88.691675111556
}
#Debug simulation 
Total elapsed time: 10.28401008201763. Arrivals time: 0.24053342314437032 Scheduler time: 9.945944029837847 Scheduler overhead time: 0.03171584056690335 Adapter cache time: 0.02080911584198475 Engine time: 0.03144596656784415 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-32/adapters_256_slots_128_rate_0.4-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-32/adapters_256_slots_128_rate_0.4-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 270, 4320, 4320, 270, 4320, 1080, 4320, 270, 1080, 270, 4320, 1080, 1080, 1080, 1080, 4320, 270, 270, 270, 1080, 4320, 270, 4320, 4320, 1080, 1080, 1080, 270, 4320, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 4320, 1080, 270, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 270, 4320, 4320, 1080, 270, 270, 4320, 1080, 270, 1080, 1080, 4320, 1080, 270, 270, 4320, 4320, 4320, 4320, 4320, 4320, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 4320, 4320, 270, 4320, 270, 1080, 4320, 4320, 4320, 1080, 270, 4320, 1080, 270, 270, 270, 270, 270, 4320, 1080, 270, 4320, 270, 4320, 270, 270, 1080, 1080, 4320, 1080, 4320, 270, 1080, 270, 4320, 4320, 270, 4320, 1080, 270, 4320, 270, 270, 4320, 4320, 1080, 4320, 4320, 270, 4320, 1080, 1080, 270, 1080, 4320, 4320, 270, 4320, 1080, 270, 1080, 4320, 270, 270, 270, 270, 270, 270, 4320, 270, 270, 270, 4320, 270, 1080, 4320, 4320, 1080, 270, 4320, 270, 1080, 1080, 270, 1080, 270, 4320, 270, 270, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 4320, 270, 4320, 270, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 1080, 1080, 270, 1080, 4320, 1080, 1080, 4320, 270, 4320, 4320, 1080, 270, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 270, 4320, 1080, 4320, 4320, 270, 4320, 1080, 1080, 4320, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 270, 270, 270, 270]
Prompts retrieved: 486270 . Total input tokens: 108366334 . Total output tokens: 97337453
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 7.755576696712524,
    "estimated_duration": 3600.1018007376097,
    "input_throughput": 4439.078082938014,
    "output_throughput": 3932.1660284994155,
    "total_throughput": 8371.244111437429,
    "itl": 178.2749721581892,
    "ttft": 1775532.832968624,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1212,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9605663252993804,
    "arrivals": 161934,
    "finished_requests": 64724,
    "scheduler_time": 91.51294319670909
}
#Debug simulation 
Total elapsed time: 7.755676690954715. Arrivals time: 0.2222642987035215 Scheduler time: 7.421060535125434 Scheduler overhead time: 0.033470069989562035 Adapter cache time: 0.0296075944788754 Engine time: 0.03393508214503527 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-16-16/adapters_256_slots_128_rate_0.4-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-16-16/adapters_256_slots_128_rate_0.4-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 270, 4320, 4320, 270, 4320, 1080, 4320, 270, 1080, 270, 4320, 1080, 1080, 1080, 1080, 4320, 270, 270, 270, 1080, 4320, 270, 4320, 4320, 1080, 1080, 1080, 270, 4320, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 4320, 1080, 270, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 270, 4320, 4320, 1080, 270, 270, 4320, 1080, 270, 1080, 1080, 4320, 1080, 270, 270, 4320, 4320, 4320, 4320, 4320, 4320, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 4320, 4320, 270, 4320, 270, 1080, 4320, 4320, 4320, 1080, 270, 4320, 1080, 270, 270, 270, 270, 270, 4320, 1080, 270, 4320, 270, 4320, 270, 270, 1080, 1080, 4320, 1080, 4320, 270, 1080, 270, 4320, 4320, 270, 4320, 1080, 270, 4320, 270, 270, 4320, 4320, 1080, 4320, 4320, 270, 4320, 1080, 1080, 270, 1080, 4320, 4320, 270, 4320, 1080, 270, 1080, 4320, 270, 270, 270, 270, 270, 270, 4320, 270, 270, 270, 4320, 270, 1080, 4320, 4320, 1080, 270, 4320, 270, 1080, 1080, 270, 1080, 270, 4320, 270, 270, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 4320, 270, 4320, 270, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 1080, 1080, 270, 1080, 4320, 1080, 1080, 4320, 270, 4320, 4320, 1080, 270, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 270, 4320, 1080, 4320, 4320, 270, 4320, 1080, 1080, 4320, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 270, 270, 270, 270]
Prompts retrieved: 486270 . Total input tokens: 108366334 . Total output tokens: 97337453
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 10.345014930237085,
    "estimated_duration": 3600.0962876137337,
    "input_throughput": 4625.838496958225,
    "output_throughput": 4092.962471780692,
    "total_throughput": 8718.800968738917,
    "itl": 209.54383186491071,
    "ttft": 1732115.0117702156,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 830,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.601460173071806,
    "arrivals": 161934,
    "finished_requests": 67416,
    "scheduler_time": 88.69440991430547
}
#Debug simulation 
Total elapsed time: 10.345136728137732. Arrivals time: 0.24250555131584406 Scheduler time: 10.00497298547998 Scheduler overhead time: 0.03135709324851632 Adapter cache time: 0.021289534866809845 Engine time: 0.03139524534344673 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-16-32/adapters_256_slots_128_rate_0.4-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-16-32/adapters_256_slots_128_rate_0.4-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 270, 4320, 4320, 270, 4320, 1080, 4320, 270, 1080, 270, 4320, 1080, 1080, 1080, 1080, 4320, 270, 270, 270, 1080, 4320, 270, 4320, 4320, 1080, 1080, 1080, 270, 4320, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 4320, 1080, 270, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 270, 4320, 4320, 1080, 270, 270, 4320, 1080, 270, 1080, 1080, 4320, 1080, 270, 270, 4320, 4320, 4320, 4320, 4320, 4320, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 4320, 4320, 270, 4320, 270, 1080, 4320, 4320, 4320, 1080, 270, 4320, 1080, 270, 270, 270, 270, 270, 4320, 1080, 270, 4320, 270, 4320, 270, 270, 1080, 1080, 4320, 1080, 4320, 270, 1080, 270, 4320, 4320, 270, 4320, 1080, 270, 4320, 270, 270, 4320, 4320, 1080, 4320, 4320, 270, 4320, 1080, 1080, 270, 1080, 4320, 4320, 270, 4320, 1080, 270, 1080, 4320, 270, 270, 270, 270, 270, 270, 4320, 270, 270, 270, 4320, 270, 1080, 4320, 4320, 1080, 270, 4320, 270, 1080, 1080, 270, 1080, 270, 4320, 270, 270, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 4320, 270, 4320, 270, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 1080, 1080, 270, 1080, 4320, 1080, 1080, 4320, 270, 4320, 4320, 1080, 270, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 270, 4320, 1080, 4320, 4320, 270, 4320, 1080, 1080, 4320, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 270, 270, 270, 270]
Prompts retrieved: 486270 . Total input tokens: 108366334 . Total output tokens: 97337453
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 7.835358961950988,
    "estimated_duration": 3600.0349795909674,
    "input_throughput": 4440.115468493629,
    "output_throughput": 3933.3334482235673,
    "total_throughput": 8373.448916717196,
    "itl": 178.29379531419664,
    "ttft": 1775858.7254604546,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1208,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9949154386855636,
    "arrivals": 161934,
    "finished_requests": 64731,
    "scheduler_time": 91.51076007555015
}
#Debug simulation 
Total elapsed time: 7.835442188195884. Arrivals time: 0.2294647889211774 Scheduler time: 7.493553618900478 Scheduler overhead time: 0.03365475032478571 Adapter cache time: 0.029009311459958553 Engine time: 0.03425835398957133 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_16-16-16/adapters_256_slots_128_rate_0.4-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_16-16-16/adapters_256_slots_128_rate_0.4-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 270, 4320, 4320, 270, 4320, 1080, 4320, 270, 1080, 270, 4320, 1080, 1080, 1080, 1080, 4320, 270, 270, 270, 1080, 4320, 270, 4320, 4320, 1080, 1080, 1080, 270, 4320, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 4320, 1080, 270, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 270, 4320, 4320, 1080, 270, 270, 4320, 1080, 270, 1080, 1080, 4320, 1080, 270, 270, 4320, 4320, 4320, 4320, 4320, 4320, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 4320, 4320, 270, 4320, 270, 1080, 4320, 4320, 4320, 1080, 270, 4320, 1080, 270, 270, 270, 270, 270, 4320, 1080, 270, 4320, 270, 4320, 270, 270, 1080, 1080, 4320, 1080, 4320, 270, 1080, 270, 4320, 4320, 270, 4320, 1080, 270, 4320, 270, 270, 4320, 4320, 1080, 4320, 4320, 270, 4320, 1080, 1080, 270, 1080, 4320, 4320, 270, 4320, 1080, 270, 1080, 4320, 270, 270, 270, 270, 270, 270, 4320, 270, 270, 270, 4320, 270, 1080, 4320, 4320, 1080, 270, 4320, 270, 1080, 1080, 270, 1080, 270, 4320, 270, 270, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 4320, 270, 4320, 270, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 1080, 1080, 270, 1080, 4320, 1080, 1080, 4320, 270, 4320, 4320, 1080, 270, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 270, 4320, 1080, 4320, 4320, 270, 4320, 1080, 1080, 4320, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 270, 270, 270, 270]
Prompts retrieved: 486270 . Total input tokens: 108366334 . Total output tokens: 97337453
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 10.282165908254683,
    "estimated_duration": 3600.0526892842336,
    "input_throughput": 4625.175361894647,
    "output_throughput": 4092.823986676013,
    "total_throughput": 8717.99934857066,
    "itl": 209.54308715286282,
    "ttft": 1731969.1469951405,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 851,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.544532800961698,
    "arrivals": 161934,
    "finished_requests": 67435,
    "scheduler_time": 88.69120075429076
}
#Debug simulation 
Total elapsed time: 10.282267866190523. Arrivals time: 0.24908306449651718 Scheduler time: 9.935008217580616 Scheduler overhead time: 0.031751107424497604 Adapter cache time: 0.02183715905994177 Engine time: 0.031064835842698812 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_16-16-32/adapters_256_slots_128_rate_0.4-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_16-16-32/adapters_256_slots_128_rate_0.4-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 270, 4320, 4320, 270, 4320, 1080, 4320, 270, 1080, 270, 4320, 1080, 1080, 1080, 1080, 4320, 270, 270, 270, 1080, 4320, 270, 4320, 4320, 1080, 1080, 1080, 270, 4320, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 4320, 1080, 270, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 270, 4320, 4320, 1080, 270, 270, 4320, 1080, 270, 1080, 1080, 4320, 1080, 270, 270, 4320, 4320, 4320, 4320, 4320, 4320, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 4320, 4320, 270, 4320, 270, 1080, 4320, 4320, 4320, 1080, 270, 4320, 1080, 270, 270, 270, 270, 270, 4320, 1080, 270, 4320, 270, 4320, 270, 270, 1080, 1080, 4320, 1080, 4320, 270, 1080, 270, 4320, 4320, 270, 4320, 1080, 270, 4320, 270, 270, 4320, 4320, 1080, 4320, 4320, 270, 4320, 1080, 1080, 270, 1080, 4320, 4320, 270, 4320, 1080, 270, 1080, 4320, 270, 270, 270, 270, 270, 270, 4320, 270, 270, 270, 4320, 270, 1080, 4320, 4320, 1080, 270, 4320, 270, 1080, 1080, 270, 1080, 270, 4320, 270, 270, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 4320, 270, 4320, 270, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 1080, 1080, 270, 1080, 4320, 1080, 1080, 4320, 270, 4320, 4320, 1080, 270, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 270, 4320, 1080, 4320, 4320, 270, 4320, 1080, 1080, 4320, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 270, 270, 270, 270]
Prompts retrieved: 486270 . Total input tokens: 108366334 . Total output tokens: 97337453
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 7.782763108145446,
    "estimated_duration": 3600.1421043349465,
    "input_throughput": 4440.03918088474,
    "output_throughput": 3933.5213970994077,
    "total_throughput": 8373.560577984148,
    "itl": 178.29548737353073,
    "ttft": 1776183.115062673,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1215,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.071054433696026,
    "arrivals": 161934,
    "finished_requests": 64739,
    "scheduler_time": 91.51042701452852
}
#Debug simulation 
Total elapsed time: 7.7828519330359995. Arrivals time: 0.22794593358412385 Scheduler time: 7.443060836289078 Scheduler overhead time: 0.03334208019077778 Adapter cache time: 0.029393262695521116 Engine time: 0.03370545618236065 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-8/adapters_256_slots_128_rate_0.4-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-8/adapters_256_slots_128_rate_0.4-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 135, 4320, 4320, 135, 4320, 1080, 4320, 135, 1080, 135, 4320, 1080, 1080, 1080, 1080, 4320, 135, 135, 135, 1080, 4320, 135, 4320, 4320, 1080, 1080, 1080, 135, 4320, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 4320, 1080, 135, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 135, 4320, 4320, 1080, 135, 135, 4320, 1080, 135, 1080, 1080, 4320, 1080, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 4320, 4320, 135, 4320, 135, 1080, 4320, 4320, 4320, 1080, 135, 4320, 1080, 135, 135, 135, 135, 135, 4320, 1080, 135, 4320, 135, 4320, 135, 135, 1080, 1080, 4320, 1080, 4320, 135, 1080, 135, 4320, 4320, 135, 4320, 1080, 135, 4320, 135, 135, 4320, 4320, 1080, 4320, 4320, 135, 4320, 1080, 1080, 135, 1080, 4320, 4320, 135, 4320, 1080, 135, 1080, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 1080, 4320, 4320, 1080, 135, 4320, 135, 1080, 1080, 135, 1080, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 4320, 135, 4320, 135, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 1080, 1080, 135, 1080, 4320, 1080, 1080, 4320, 135, 4320, 4320, 1080, 135, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 135, 4320, 1080, 4320, 4320, 135, 4320, 1080, 1080, 4320, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 135, 135, 135, 135]
Prompts retrieved: 474795 . Total input tokens: 105806663 . Total output tokens: 95022632
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 8.720880297012627,
    "estimated_duration": 3600.1104068528434,
    "input_throughput": 4633.9367726735145,
    "output_throughput": 4093.7558392504106,
    "total_throughput": 8727.692611923925,
    "itl": 209.1415468831681,
    "ttft": 1720715.8145781886,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 901,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.757499457283471,
    "arrivals": 158124,
    "finished_requests": 67496,
    "scheduler_time": 88.5387798561412
}
#Debug simulation 
Total elapsed time: 8.720965055283159. Arrivals time: 0.25520935049280524 Scheduler time: 8.370823030360043 Scheduler overhead time: 0.02982641151174903 Adapter cache time: 0.021517137996852398 Engine time: 0.03018136415630579 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-16/adapters_256_slots_128_rate_0.4-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-16/adapters_256_slots_128_rate_0.4-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 135, 4320, 4320, 135, 4320, 1080, 4320, 135, 1080, 135, 4320, 1080, 1080, 1080, 1080, 4320, 135, 135, 135, 1080, 4320, 135, 4320, 4320, 1080, 1080, 1080, 135, 4320, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 4320, 1080, 135, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 135, 4320, 4320, 1080, 135, 135, 4320, 1080, 135, 1080, 1080, 4320, 1080, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 4320, 4320, 135, 4320, 135, 1080, 4320, 4320, 4320, 1080, 135, 4320, 1080, 135, 135, 135, 135, 135, 4320, 1080, 135, 4320, 135, 4320, 135, 135, 1080, 1080, 4320, 1080, 4320, 135, 1080, 135, 4320, 4320, 135, 4320, 1080, 135, 4320, 135, 135, 4320, 4320, 1080, 4320, 4320, 135, 4320, 1080, 1080, 135, 1080, 4320, 4320, 135, 4320, 1080, 135, 1080, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 1080, 4320, 4320, 1080, 135, 4320, 135, 1080, 1080, 135, 1080, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 4320, 135, 4320, 135, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 1080, 1080, 135, 1080, 4320, 1080, 1080, 4320, 135, 4320, 4320, 1080, 135, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 135, 4320, 1080, 4320, 4320, 135, 4320, 1080, 1080, 4320, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 135, 135, 135, 135]
Prompts retrieved: 474795 . Total input tokens: 105806663 . Total output tokens: 95022632
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 8.718207790050656,
    "estimated_duration": 3600.015470015073,
    "input_throughput": 4633.72036563225,
    "output_throughput": 4093.737408283497,
    "total_throughput": 8727.457773915747,
    "itl": 209.1551477520653,
    "ttft": 1720758.4924485998,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 902,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9405481757922143,
    "arrivals": 158124,
    "finished_requests": 67490,
    "scheduler_time": 88.53293891371275
}
#Debug simulation 
Total elapsed time: 8.71829641237855. Arrivals time: 0.25526943150907755 Scheduler time: 8.367628367617726 Scheduler overhead time: 0.029980494175106287 Adapter cache time: 0.021631277166306973 Engine time: 0.03038487583398819 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-32/adapters_256_slots_128_rate_0.4-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-32/adapters_256_slots_128_rate_0.4-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 135, 4320, 4320, 135, 4320, 1080, 4320, 135, 1080, 135, 4320, 1080, 1080, 1080, 1080, 4320, 135, 135, 135, 1080, 4320, 135, 4320, 4320, 1080, 1080, 1080, 135, 4320, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 4320, 1080, 135, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 135, 4320, 4320, 1080, 135, 135, 4320, 1080, 135, 1080, 1080, 4320, 1080, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 4320, 4320, 135, 4320, 135, 1080, 4320, 4320, 4320, 1080, 135, 4320, 1080, 135, 135, 135, 135, 135, 4320, 1080, 135, 4320, 135, 4320, 135, 135, 1080, 1080, 4320, 1080, 4320, 135, 1080, 135, 4320, 4320, 135, 4320, 1080, 135, 4320, 135, 135, 4320, 4320, 1080, 4320, 4320, 135, 4320, 1080, 1080, 135, 1080, 4320, 4320, 135, 4320, 1080, 135, 1080, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 1080, 4320, 4320, 1080, 135, 4320, 135, 1080, 1080, 135, 1080, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 4320, 135, 4320, 135, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 1080, 1080, 135, 1080, 4320, 1080, 1080, 4320, 135, 4320, 4320, 1080, 135, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 135, 4320, 1080, 4320, 4320, 135, 4320, 1080, 1080, 4320, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 135, 135, 135, 135]
Prompts retrieved: 474795 . Total input tokens: 105806663 . Total output tokens: 95022632
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 7.002440623939037,
    "estimated_duration": 3600.0392108371034,
    "input_throughput": 4440.400246719237,
    "output_throughput": 3929.8730295524447,
    "total_throughput": 8370.273276271682,
    "itl": 177.59720565411794,
    "ttft": 1765484.139804192,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1257,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.107979345824503,
    "arrivals": 158124,
    "finished_requests": 64642,
    "scheduler_time": 91.42368985608309
}
#Debug simulation 
Total elapsed time: 7.002560307271779. Arrivals time: 0.21866515837609768 Scheduler time: 6.672431099228561 Scheduler overhead time: 0.03331379871815443 Adapter cache time: 0.029157382436096668 Engine time: 0.033621656242758036 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-16/adapters_256_slots_128_rate_0.4-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-16/adapters_256_slots_128_rate_0.4-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 135, 4320, 4320, 135, 4320, 1080, 4320, 135, 1080, 135, 4320, 1080, 1080, 1080, 1080, 4320, 135, 135, 135, 1080, 4320, 135, 4320, 4320, 1080, 1080, 1080, 135, 4320, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 4320, 1080, 135, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 135, 4320, 4320, 1080, 135, 135, 4320, 1080, 135, 1080, 1080, 4320, 1080, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 4320, 4320, 135, 4320, 135, 1080, 4320, 4320, 4320, 1080, 135, 4320, 1080, 135, 135, 135, 135, 135, 4320, 1080, 135, 4320, 135, 4320, 135, 135, 1080, 1080, 4320, 1080, 4320, 135, 1080, 135, 4320, 4320, 135, 4320, 1080, 135, 4320, 135, 135, 4320, 4320, 1080, 4320, 4320, 135, 4320, 1080, 1080, 135, 1080, 4320, 4320, 135, 4320, 1080, 135, 1080, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 1080, 4320, 4320, 1080, 135, 4320, 135, 1080, 1080, 135, 1080, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 4320, 135, 4320, 135, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 1080, 1080, 135, 1080, 4320, 1080, 1080, 4320, 135, 4320, 4320, 1080, 135, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 135, 4320, 1080, 4320, 4320, 135, 4320, 1080, 1080, 4320, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 135, 135, 135, 135]
Prompts retrieved: 474795 . Total input tokens: 105806663 . Total output tokens: 95022632
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 8.715839007869363,
    "estimated_duration": 3600.1568847578374,
    "input_throughput": 4633.582239325684,
    "output_throughput": 4093.7474315071004,
    "total_throughput": 8727.329670832785,
    "itl": 209.17192695743876,
    "ttft": 1720609.1977275552,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 916,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8680021907575166,
    "arrivals": 158124,
    "finished_requests": 67493,
    "scheduler_time": 88.53540514162073
}
#Debug simulation 
Total elapsed time: 8.715927261859179. Arrivals time: 0.23487285850569606 Scheduler time: 8.384692242369056 Scheduler overhead time: 0.030666901264339685 Adapter cache time: 0.021964150480926037 Engine time: 0.030275551602244377 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-32/adapters_256_slots_128_rate_0.4-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-32/adapters_256_slots_128_rate_0.4-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 135, 4320, 4320, 135, 4320, 1080, 4320, 135, 1080, 135, 4320, 1080, 1080, 1080, 1080, 4320, 135, 135, 135, 1080, 4320, 135, 4320, 4320, 1080, 1080, 1080, 135, 4320, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 4320, 1080, 135, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 135, 4320, 4320, 1080, 135, 135, 4320, 1080, 135, 1080, 1080, 4320, 1080, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 4320, 4320, 135, 4320, 135, 1080, 4320, 4320, 4320, 1080, 135, 4320, 1080, 135, 135, 135, 135, 135, 4320, 1080, 135, 4320, 135, 4320, 135, 135, 1080, 1080, 4320, 1080, 4320, 135, 1080, 135, 4320, 4320, 135, 4320, 1080, 135, 4320, 135, 135, 4320, 4320, 1080, 4320, 4320, 135, 4320, 1080, 1080, 135, 1080, 4320, 4320, 135, 4320, 1080, 135, 1080, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 1080, 4320, 4320, 1080, 135, 4320, 135, 1080, 1080, 135, 1080, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 4320, 135, 4320, 135, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 1080, 1080, 135, 1080, 4320, 1080, 1080, 4320, 135, 4320, 4320, 1080, 135, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 135, 4320, 1080, 4320, 4320, 135, 4320, 1080, 1080, 4320, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 135, 135, 135, 135]
Prompts retrieved: 474795 . Total input tokens: 105806663 . Total output tokens: 95022632
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 7.040037869010121,
    "estimated_duration": 3600.0020072823386,
    "input_throughput": 4438.977524921893,
    "output_throughput": 3930.289475222042,
    "total_throughput": 8369.267000143935,
    "itl": 177.60190352917883,
    "ttft": 1765656.3316450566,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1223,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.046381456553928,
    "arrivals": 158124,
    "finished_requests": 64614,
    "scheduler_time": 91.42558891934293
}
#Debug simulation 
Total elapsed time: 7.040123914834112. Arrivals time: 0.23167760809883475 Scheduler time: 6.697686139494181 Scheduler overhead time: 0.033330575563013554 Adapter cache time: 0.028314515482634306 Engine time: 0.03370604710653424 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-16/adapters_256_slots_128_rate_0.4-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-16/adapters_256_slots_128_rate_0.4-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 135, 4320, 4320, 135, 4320, 1080, 4320, 135, 1080, 135, 4320, 1080, 1080, 1080, 1080, 4320, 135, 135, 135, 1080, 4320, 135, 4320, 4320, 1080, 1080, 1080, 135, 4320, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 4320, 1080, 135, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 135, 4320, 4320, 1080, 135, 135, 4320, 1080, 135, 1080, 1080, 4320, 1080, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 4320, 4320, 135, 4320, 135, 1080, 4320, 4320, 4320, 1080, 135, 4320, 1080, 135, 135, 135, 135, 135, 4320, 1080, 135, 4320, 135, 4320, 135, 135, 1080, 1080, 4320, 1080, 4320, 135, 1080, 135, 4320, 4320, 135, 4320, 1080, 135, 4320, 135, 135, 4320, 4320, 1080, 4320, 4320, 135, 4320, 1080, 1080, 135, 1080, 4320, 4320, 135, 4320, 1080, 135, 1080, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 1080, 4320, 4320, 1080, 135, 4320, 135, 1080, 1080, 135, 1080, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 4320, 135, 4320, 135, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 1080, 1080, 135, 1080, 4320, 1080, 1080, 4320, 135, 4320, 4320, 1080, 135, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 135, 4320, 1080, 4320, 4320, 135, 4320, 1080, 1080, 4320, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 135, 135, 135, 135]
Prompts retrieved: 474795 . Total input tokens: 105806663 . Total output tokens: 95022632
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 8.81016525812447,
    "estimated_duration": 3600.1895605648356,
    "input_throughput": 4633.058543001575,
    "output_throughput": 4093.8933220193057,
    "total_throughput": 8726.951865020881,
    "itl": 209.17486251604754,
    "ttft": 1720299.80895507,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 879,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.628254209218956,
    "arrivals": 158124,
    "finished_requests": 67474,
    "scheduler_time": 88.54137370144426
}
#Debug simulation 
Total elapsed time: 8.810275375843048. Arrivals time: 0.25443126959726214 Scheduler time: 8.46028435928747 Scheduler overhead time: 0.03038564370945096 Adapter cache time: 0.02146156132221222 Engine time: 0.030206653755158186 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-32/adapters_256_slots_128_rate_0.4-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-32/adapters_256_slots_128_rate_0.4-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 135, 4320, 4320, 135, 4320, 1080, 4320, 135, 1080, 135, 4320, 1080, 1080, 1080, 1080, 4320, 135, 135, 135, 1080, 4320, 135, 4320, 4320, 1080, 1080, 1080, 135, 4320, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 4320, 1080, 135, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 135, 4320, 4320, 1080, 135, 135, 4320, 1080, 135, 1080, 1080, 4320, 1080, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 4320, 4320, 135, 4320, 135, 1080, 4320, 4320, 4320, 1080, 135, 4320, 1080, 135, 135, 135, 135, 135, 4320, 1080, 135, 4320, 135, 4320, 135, 135, 1080, 1080, 4320, 1080, 4320, 135, 1080, 135, 4320, 4320, 135, 4320, 1080, 135, 4320, 135, 135, 4320, 4320, 1080, 4320, 4320, 135, 4320, 1080, 1080, 135, 1080, 4320, 4320, 135, 4320, 1080, 135, 1080, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 1080, 4320, 4320, 1080, 135, 4320, 135, 1080, 1080, 135, 1080, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 4320, 135, 4320, 135, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 1080, 1080, 135, 1080, 4320, 1080, 1080, 4320, 135, 4320, 4320, 1080, 135, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 135, 4320, 1080, 4320, 4320, 135, 4320, 1080, 1080, 4320, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 135, 135, 135, 135]
Prompts retrieved: 474795 . Total input tokens: 105806663 . Total output tokens: 95022632
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 7.014739078003913,
    "estimated_duration": 3600.12618805338,
    "input_throughput": 4439.330502645989,
    "output_throughput": 3930.716941800202,
    "total_throughput": 8370.04744444619,
    "itl": 177.61527767898522,
    "ttft": 1765661.840621888,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1231,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.126695754490843,
    "arrivals": 158124,
    "finished_requests": 64631,
    "scheduler_time": 91.42637389685513
}
#Debug simulation 
Total elapsed time: 7.0148244998417795. Arrivals time: 0.21551521541550756 Scheduler time: 6.688704697415233 Scheduler overhead time: 0.033117244485765696 Adapter cache time: 0.028820928186178207 Engine time: 0.03345951996743679 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-8/adapters_256_slots_128_rate_0.4-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-8/adapters_256_slots_128_rate_0.4-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 66, 4320, 4320, 66, 4320, 1080, 4320, 66, 1080, 66, 4320, 1080, 1080, 1080, 1080, 4320, 66, 66, 66, 1080, 4320, 66, 4320, 4320, 1080, 1080, 1080, 66, 4320, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 4320, 1080, 66, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 66, 4320, 4320, 1080, 66, 66, 4320, 1080, 66, 1080, 1080, 4320, 1080, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 4320, 4320, 66, 4320, 66, 1080, 4320, 4320, 4320, 1080, 66, 4320, 1080, 66, 66, 66, 66, 66, 4320, 1080, 66, 4320, 66, 4320, 66, 66, 1080, 1080, 4320, 1080, 4320, 66, 1080, 66, 4320, 4320, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 66, 1080, 4320, 4320, 66, 4320, 1080, 66, 1080, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 1080, 4320, 4320, 1080, 66, 4320, 66, 1080, 1080, 66, 1080, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 4320, 66, 4320, 66, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 1080, 1080, 66, 1080, 4320, 1080, 1080, 4320, 66, 4320, 4320, 1080, 66, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 66, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 4320, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 66, 66, 66, 66]
Prompts retrieved: 468930 . Total input tokens: 104482091 . Total output tokens: 93835645
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 8.000086035113782,
    "estimated_duration": 3600.042571798013,
    "input_throughput": 4628.1463809686375,
    "output_throughput": 4097.037106045519,
    "total_throughput": 8725.183487014157,
    "itl": 209.45630807598712,
    "ttft": 1712414.534991646,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 863,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.641200923014022,
    "arrivals": 156118,
    "finished_requests": 67417,
    "scheduler_time": 88.36881543105783
}
#Debug simulation 
Total elapsed time: 8.000189333688468. Arrivals time: 0.22981142299249768 Scheduler time: 7.676539289299399 Scheduler overhead time: 0.02947833761572838 Adapter cache time: 0.021144643425941467 Engine time: 0.029853445012122393 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-16/adapters_256_slots_128_rate_0.4-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-16/adapters_256_slots_128_rate_0.4-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 66, 4320, 4320, 66, 4320, 1080, 4320, 66, 1080, 66, 4320, 1080, 1080, 1080, 1080, 4320, 66, 66, 66, 1080, 4320, 66, 4320, 4320, 1080, 1080, 1080, 66, 4320, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 4320, 1080, 66, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 66, 4320, 4320, 1080, 66, 66, 4320, 1080, 66, 1080, 1080, 4320, 1080, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 4320, 4320, 66, 4320, 66, 1080, 4320, 4320, 4320, 1080, 66, 4320, 1080, 66, 66, 66, 66, 66, 4320, 1080, 66, 4320, 66, 4320, 66, 66, 1080, 1080, 4320, 1080, 4320, 66, 1080, 66, 4320, 4320, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 66, 1080, 4320, 4320, 66, 4320, 1080, 66, 1080, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 1080, 4320, 4320, 1080, 66, 4320, 66, 1080, 1080, 66, 1080, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 4320, 66, 4320, 66, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 1080, 1080, 66, 1080, 4320, 1080, 1080, 4320, 66, 4320, 4320, 1080, 66, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 66, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 4320, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 66, 66, 66, 66]
Prompts retrieved: 468930 . Total input tokens: 104482091 . Total output tokens: 93835645
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 8.03490239707753,
    "estimated_duration": 3600.191493397656,
    "input_throughput": 4627.708006797338,
    "output_throughput": 4097.869523622714,
    "total_throughput": 8725.577530420052,
    "itl": 209.50733348920215,
    "ttft": 1712133.132633971,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 851,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7778407277911965,
    "arrivals": 156118,
    "finished_requests": 67425,
    "scheduler_time": 88.36689072063473
}
#Debug simulation 
Total elapsed time: 8.034992428962141. Arrivals time: 0.22767059179022908 Scheduler time: 7.713223758153617 Scheduler overhead time: 0.02965102205052972 Adapter cache time: 0.021199905779212713 Engine time: 0.029881495982408524 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-32/adapters_256_slots_128_rate_0.4-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-32/adapters_256_slots_128_rate_0.4-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 66, 4320, 4320, 66, 4320, 1080, 4320, 66, 1080, 66, 4320, 1080, 1080, 1080, 1080, 4320, 66, 66, 66, 1080, 4320, 66, 4320, 4320, 1080, 1080, 1080, 66, 4320, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 4320, 1080, 66, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 66, 4320, 4320, 1080, 66, 66, 4320, 1080, 66, 1080, 1080, 4320, 1080, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 4320, 4320, 66, 4320, 66, 1080, 4320, 4320, 4320, 1080, 66, 4320, 1080, 66, 66, 66, 66, 66, 4320, 1080, 66, 4320, 66, 4320, 66, 66, 1080, 1080, 4320, 1080, 4320, 66, 1080, 66, 4320, 4320, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 66, 1080, 4320, 4320, 66, 4320, 1080, 66, 1080, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 1080, 4320, 4320, 1080, 66, 4320, 66, 1080, 1080, 66, 1080, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 4320, 66, 4320, 66, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 1080, 1080, 66, 1080, 4320, 1080, 1080, 4320, 66, 4320, 4320, 1080, 66, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 66, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 4320, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 66, 66, 66, 66]
Prompts retrieved: 468930 . Total input tokens: 104482091 . Total output tokens: 93835645
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 6.58604011265561,
    "estimated_duration": 3600.1089463458384,
    "input_throughput": 4438.8931663361,
    "output_throughput": 3929.638577843466,
    "total_throughput": 8368.531744179567,
    "itl": 177.66935362451298,
    "ttft": 1758862.809158702,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1149,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.756009233035093,
    "arrivals": 156118,
    "finished_requests": 64599,
    "scheduler_time": 91.22526710253877
}
#Debug simulation 
Total elapsed time: 6.586126115638763. Arrivals time: 0.21513060061261058 Scheduler time: 6.2607968067750335 Scheduler overhead time: 0.03334660455584526 Adapter cache time: 0.02801073808223009 Engine time: 0.03350988728925586 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-16/adapters_256_slots_128_rate_0.4-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-16/adapters_256_slots_128_rate_0.4-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 66, 4320, 4320, 66, 4320, 1080, 4320, 66, 1080, 66, 4320, 1080, 1080, 1080, 1080, 4320, 66, 66, 66, 1080, 4320, 66, 4320, 4320, 1080, 1080, 1080, 66, 4320, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 4320, 1080, 66, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 66, 4320, 4320, 1080, 66, 66, 4320, 1080, 66, 1080, 1080, 4320, 1080, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 4320, 4320, 66, 4320, 66, 1080, 4320, 4320, 4320, 1080, 66, 4320, 1080, 66, 66, 66, 66, 66, 4320, 1080, 66, 4320, 66, 4320, 66, 66, 1080, 1080, 4320, 1080, 4320, 66, 1080, 66, 4320, 4320, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 66, 1080, 4320, 4320, 66, 4320, 1080, 66, 1080, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 1080, 4320, 4320, 1080, 66, 4320, 66, 1080, 1080, 66, 1080, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 4320, 66, 4320, 66, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 1080, 1080, 66, 1080, 4320, 1080, 1080, 4320, 66, 4320, 4320, 1080, 66, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 66, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 4320, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 66, 66, 66, 66]
Prompts retrieved: 468930 . Total input tokens: 104482091 . Total output tokens: 93835645
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 7.994208469055593,
    "estimated_duration": 3600.1172568698757,
    "input_throughput": 4628.050369250021,
    "output_throughput": 4096.952112283134,
    "total_throughput": 8725.002481533154,
    "itl": 209.4593812715697,
    "ttft": 1712440.7495585456,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 863,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7070779532170635,
    "arrivals": 156118,
    "finished_requests": 67417,
    "scheduler_time": 88.36938487169485
}
#Debug simulation 
Total elapsed time: 7.994299627374858. Arrivals time: 0.23249084874987602 Scheduler time: 7.667926959693432 Scheduler overhead time: 0.0296187661588192 Adapter cache time: 0.02122892066836357 Engine time: 0.029817117378115654 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-32/adapters_256_slots_128_rate_0.4-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-32/adapters_256_slots_128_rate_0.4-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 66, 4320, 4320, 66, 4320, 1080, 4320, 66, 1080, 66, 4320, 1080, 1080, 1080, 1080, 4320, 66, 66, 66, 1080, 4320, 66, 4320, 4320, 1080, 1080, 1080, 66, 4320, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 4320, 1080, 66, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 66, 4320, 4320, 1080, 66, 66, 4320, 1080, 66, 1080, 1080, 4320, 1080, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 4320, 4320, 66, 4320, 66, 1080, 4320, 4320, 4320, 1080, 66, 4320, 1080, 66, 66, 66, 66, 66, 4320, 1080, 66, 4320, 66, 4320, 66, 66, 1080, 1080, 4320, 1080, 4320, 66, 1080, 66, 4320, 4320, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 66, 1080, 4320, 4320, 66, 4320, 1080, 66, 1080, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 1080, 4320, 4320, 1080, 66, 4320, 66, 1080, 1080, 66, 1080, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 4320, 66, 4320, 66, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 1080, 1080, 66, 1080, 4320, 1080, 1080, 4320, 66, 4320, 4320, 1080, 66, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 66, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 4320, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 66, 66, 66, 66]
Prompts retrieved: 468930 . Total input tokens: 104482091 . Total output tokens: 93835645
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 6.547524671070278,
    "estimated_duration": 3600.024461357117,
    "input_throughput": 4437.570403057121,
    "output_throughput": 3929.981629809969,
    "total_throughput": 8367.552032867092,
    "itl": 177.66899462054695,
    "ttft": 1758904.4309343274,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.8385147519782112,
    "arrivals": 156118,
    "finished_requests": 64589,
    "scheduler_time": 91.22231018173454
}
#Debug simulation 
Total elapsed time: 6.54763971734792. Arrivals time: 0.21272067865356803 Scheduler time: 6.225638013333082 Scheduler overhead time: 0.03315996006131172 Adapter cache time: 0.027445628307759762 Engine time: 0.033379359636455774 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-16/adapters_256_slots_128_rate_0.4-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-16/adapters_256_slots_128_rate_0.4-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 66, 4320, 4320, 66, 4320, 1080, 4320, 66, 1080, 66, 4320, 1080, 1080, 1080, 1080, 4320, 66, 66, 66, 1080, 4320, 66, 4320, 4320, 1080, 1080, 1080, 66, 4320, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 4320, 1080, 66, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 66, 4320, 4320, 1080, 66, 66, 4320, 1080, 66, 1080, 1080, 4320, 1080, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 4320, 4320, 66, 4320, 66, 1080, 4320, 4320, 4320, 1080, 66, 4320, 1080, 66, 66, 66, 66, 66, 4320, 1080, 66, 4320, 66, 4320, 66, 66, 1080, 1080, 4320, 1080, 4320, 66, 1080, 66, 4320, 4320, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 66, 1080, 4320, 4320, 66, 4320, 1080, 66, 1080, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 1080, 4320, 4320, 1080, 66, 4320, 66, 1080, 1080, 66, 1080, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 4320, 66, 4320, 66, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 1080, 1080, 66, 1080, 4320, 1080, 1080, 4320, 66, 4320, 4320, 1080, 66, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 66, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 4320, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 66, 66, 66, 66]
Prompts retrieved: 468930 . Total input tokens: 104482091 . Total output tokens: 93835645
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 8.039758287370205,
    "estimated_duration": 3600.2017768663927,
    "input_throughput": 4628.071156195739,
    "output_throughput": 4098.081139452627,
    "total_throughput": 8726.152295648366,
    "itl": 209.49533124735356,
    "ttft": 1712062.2038403002,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 850,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.541542750666796,
    "arrivals": 156118,
    "finished_requests": 67428,
    "scheduler_time": 88.3717796147187
}
#Debug simulation 
Total elapsed time: 8.03984679793939. Arrivals time: 0.22961461963132024 Scheduler time: 7.716482917778194 Scheduler overhead time: 0.029521310236305 Adapter cache time: 0.020699135959148407 Engine time: 0.030228441581130028 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-32/adapters_256_slots_128_rate_0.4-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-32/adapters_256_slots_128_rate_0.4-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 66, 4320, 4320, 66, 4320, 1080, 4320, 66, 1080, 66, 4320, 1080, 1080, 1080, 1080, 4320, 66, 66, 66, 1080, 4320, 66, 4320, 4320, 1080, 1080, 1080, 66, 4320, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 4320, 1080, 66, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 66, 4320, 4320, 1080, 66, 66, 4320, 1080, 66, 1080, 1080, 4320, 1080, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 4320, 4320, 66, 4320, 66, 1080, 4320, 4320, 4320, 1080, 66, 4320, 1080, 66, 66, 66, 66, 66, 4320, 1080, 66, 4320, 66, 4320, 66, 66, 1080, 1080, 4320, 1080, 4320, 66, 1080, 66, 4320, 4320, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 66, 1080, 4320, 4320, 66, 4320, 1080, 66, 1080, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 1080, 4320, 4320, 1080, 66, 4320, 66, 1080, 1080, 66, 1080, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 4320, 66, 4320, 66, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 1080, 1080, 66, 1080, 4320, 1080, 1080, 4320, 66, 4320, 4320, 1080, 66, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 66, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 4320, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 66, 66, 66, 66]
Prompts retrieved: 468930 . Total input tokens: 104482091 . Total output tokens: 93835645
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 6.567797019146383,
    "estimated_duration": 3600.0458765623716,
    "input_throughput": 4436.6940165917285,
    "output_throughput": 3929.2918715545497,
    "total_throughput": 8365.985888146279,
    "itl": 177.6632723035033,
    "ttft": 1758873.6496455856,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1158,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.884609823450505,
    "arrivals": 156118,
    "finished_requests": 64575,
    "scheduler_time": 91.22457223990018
}
#Debug simulation 
Total elapsed time: 6.56788675300777. Arrivals time: 0.21813932107761502 Scheduler time: 6.23998179892078 Scheduler overhead time: 0.0331936227157712 Adapter cache time: 0.027541249059140682 Engine time: 0.03368156123906374 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-8/adapters_256_slots_128_rate_0.4-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-8/adapters_256_slots_128_rate_0.4-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 33, 4320, 4320, 33, 4320, 1080, 4320, 33, 1080, 33, 4320, 1080, 1080, 1080, 1080, 4320, 33, 33, 33, 1080, 4320, 33, 4320, 4320, 1080, 1080, 1080, 33, 4320, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 4320, 1080, 33, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 33, 4320, 4320, 1080, 33, 33, 4320, 1080, 33, 1080, 1080, 4320, 1080, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 4320, 4320, 33, 4320, 33, 1080, 4320, 4320, 4320, 1080, 33, 4320, 1080, 33, 33, 33, 33, 33, 4320, 1080, 33, 4320, 33, 4320, 33, 33, 1080, 1080, 4320, 1080, 4320, 33, 1080, 33, 4320, 4320, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 33, 1080, 4320, 4320, 33, 4320, 1080, 33, 1080, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 1080, 4320, 4320, 1080, 33, 4320, 33, 1080, 1080, 33, 1080, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 4320, 33, 4320, 33, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 1080, 1080, 33, 1080, 4320, 1080, 1080, 4320, 33, 4320, 4320, 1080, 33, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 33, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 4320, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 33, 33, 33, 33]
Prompts retrieved: 466125 . Total input tokens: 103857742 . Total output tokens: 93269464
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 7.7053280510008335,
    "estimated_duration": 3600.083147979276,
    "input_throughput": 4616.143382501583,
    "output_throughput": 4099.134212575957,
    "total_throughput": 8715.27759507754,
    "itl": 209.62286722517086,
    "ttft": 1713598.9136168943,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 726,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2219141020952202,
    "arrivals": 155196,
    "finished_requests": 67351,
    "scheduler_time": 88.33971341248363
}
#Debug simulation 
Total elapsed time: 7.70543157774955. Arrivals time: 0.2300185547210276 Scheduler time: 7.385327755473554 Scheduler overhead time: 0.029160503298044205 Adapter cache time: 0.018017421010881662 Engine time: 0.029671351891011 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-16/adapters_256_slots_128_rate_0.4-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-16/adapters_256_slots_128_rate_0.4-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 33, 4320, 4320, 33, 4320, 1080, 4320, 33, 1080, 33, 4320, 1080, 1080, 1080, 1080, 4320, 33, 33, 33, 1080, 4320, 33, 4320, 4320, 1080, 1080, 1080, 33, 4320, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 4320, 1080, 33, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 33, 4320, 4320, 1080, 33, 33, 4320, 1080, 33, 1080, 1080, 4320, 1080, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 4320, 4320, 33, 4320, 33, 1080, 4320, 4320, 4320, 1080, 33, 4320, 1080, 33, 33, 33, 33, 33, 4320, 1080, 33, 4320, 33, 4320, 33, 33, 1080, 1080, 4320, 1080, 4320, 33, 1080, 33, 4320, 4320, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 33, 1080, 4320, 4320, 33, 4320, 1080, 33, 1080, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 1080, 4320, 4320, 1080, 33, 4320, 33, 1080, 1080, 33, 1080, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 4320, 33, 4320, 33, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 1080, 1080, 33, 1080, 4320, 1080, 1080, 4320, 33, 4320, 4320, 1080, 33, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 33, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 4320, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 33, 33, 33, 33]
Prompts retrieved: 466125 . Total input tokens: 103857742 . Total output tokens: 93269464
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 7.588231293018907,
    "estimated_duration": 3600.033883247834,
    "input_throughput": 4615.609335601383,
    "output_throughput": 4098.375037150805,
    "total_throughput": 8713.984372752187,
    "itl": 209.63462923142262,
    "ttft": 1713779.9945280193,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 754,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.460021367531741,
    "arrivals": 155196,
    "finished_requests": 67338,
    "scheduler_time": 88.33327242518943
}
#Debug simulation 
Total elapsed time: 7.588345963973552. Arrivals time: 0.22621255833655596 Scheduler time: 7.271195103414357 Scheduler overhead time: 0.029291375540196896 Adapter cache time: 0.018631041515618563 Engine time: 0.029763521160930395 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-32/adapters_256_slots_128_rate_0.4-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-32/adapters_256_slots_128_rate_0.4-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 33, 4320, 4320, 33, 4320, 1080, 4320, 33, 1080, 33, 4320, 1080, 1080, 1080, 1080, 4320, 33, 33, 33, 1080, 4320, 33, 4320, 4320, 1080, 1080, 1080, 33, 4320, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 4320, 1080, 33, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 33, 4320, 4320, 1080, 33, 33, 4320, 1080, 33, 1080, 1080, 4320, 1080, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 4320, 4320, 33, 4320, 33, 1080, 4320, 4320, 4320, 1080, 33, 4320, 1080, 33, 33, 33, 33, 33, 4320, 1080, 33, 4320, 33, 4320, 33, 33, 1080, 1080, 4320, 1080, 4320, 33, 1080, 33, 4320, 4320, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 33, 1080, 4320, 4320, 33, 4320, 1080, 33, 1080, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 1080, 4320, 4320, 1080, 33, 4320, 33, 1080, 1080, 33, 1080, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 4320, 33, 4320, 33, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 1080, 1080, 33, 1080, 4320, 1080, 1080, 4320, 33, 4320, 4320, 1080, 33, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 33, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 4320, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 33, 33, 33, 33]
Prompts retrieved: 466125 . Total input tokens: 103857742 . Total output tokens: 93269464
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 6.11976127885282,
    "estimated_duration": 3600.0644460319245,
    "input_throughput": 4417.078426895191,
    "output_throughput": 3931.114904234273,
    "total_throughput": 8348.193331129463,
    "itl": 177.4978221438937,
    "ttft": 1761069.5092908144,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1084,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5433416181057225,
    "arrivals": 155196,
    "finished_requests": 64478,
    "scheduler_time": 91.22676196240425
}
#Debug simulation 
Total elapsed time: 6.119849153794348. Arrivals time: 0.21269898628816009 Scheduler time: 5.80047404486686 Scheduler overhead time: 0.03281846642494202 Adapter cache time: 0.02548752026632428 Engine time: 0.0332138161174953 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-16/adapters_256_slots_128_rate_0.4-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-16/adapters_256_slots_128_rate_0.4-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 33, 4320, 4320, 33, 4320, 1080, 4320, 33, 1080, 33, 4320, 1080, 1080, 1080, 1080, 4320, 33, 33, 33, 1080, 4320, 33, 4320, 4320, 1080, 1080, 1080, 33, 4320, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 4320, 1080, 33, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 33, 4320, 4320, 1080, 33, 33, 4320, 1080, 33, 1080, 1080, 4320, 1080, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 4320, 4320, 33, 4320, 33, 1080, 4320, 4320, 4320, 1080, 33, 4320, 1080, 33, 33, 33, 33, 33, 4320, 1080, 33, 4320, 33, 4320, 33, 33, 1080, 1080, 4320, 1080, 4320, 33, 1080, 33, 4320, 4320, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 33, 1080, 4320, 4320, 33, 4320, 1080, 33, 1080, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 1080, 4320, 4320, 1080, 33, 4320, 33, 1080, 1080, 33, 1080, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 4320, 33, 4320, 33, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 1080, 1080, 33, 1080, 4320, 1080, 1080, 4320, 33, 4320, 4320, 1080, 33, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 33, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 4320, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 33, 33, 33, 33]
Prompts retrieved: 466125 . Total input tokens: 103857742 . Total output tokens: 93269464
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 7.60194166470319,
    "estimated_duration": 3600.034318325453,
    "input_throughput": 4615.551278335857,
    "output_throughput": 4098.83231526073,
    "total_throughput": 8714.383593596587,
    "itl": 209.63631468033918,
    "ttft": 1713569.4683794717,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 750,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3520412665186283,
    "arrivals": 155196,
    "finished_requests": 67344,
    "scheduler_time": 88.334663651124
}
#Debug simulation 
Total elapsed time: 7.602029129862785. Arrivals time: 0.2259048274718225 Scheduler time: 7.285116672050208 Scheduler overhead time: 0.029174561612308025 Adapter cache time: 0.01841171458363533 Engine time: 0.030126668978482485 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-32/adapters_256_slots_128_rate_0.4-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-32/adapters_256_slots_128_rate_0.4-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 33, 4320, 4320, 33, 4320, 1080, 4320, 33, 1080, 33, 4320, 1080, 1080, 1080, 1080, 4320, 33, 33, 33, 1080, 4320, 33, 4320, 4320, 1080, 1080, 1080, 33, 4320, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 4320, 1080, 33, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 33, 4320, 4320, 1080, 33, 33, 4320, 1080, 33, 1080, 1080, 4320, 1080, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 4320, 4320, 33, 4320, 33, 1080, 4320, 4320, 4320, 1080, 33, 4320, 1080, 33, 33, 33, 33, 33, 4320, 1080, 33, 4320, 33, 4320, 33, 33, 1080, 1080, 4320, 1080, 4320, 33, 1080, 33, 4320, 4320, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 33, 1080, 4320, 4320, 33, 4320, 1080, 33, 1080, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 1080, 4320, 4320, 1080, 33, 4320, 33, 1080, 1080, 33, 1080, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 4320, 33, 4320, 33, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 1080, 1080, 33, 1080, 4320, 1080, 1080, 4320, 33, 4320, 4320, 1080, 33, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 33, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 4320, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 33, 33, 33, 33]
Prompts retrieved: 466125 . Total input tokens: 103857742 . Total output tokens: 93269464
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 6.1778502790257335,
    "estimated_duration": 3600.1918347388705,
    "input_throughput": 4416.151619085373,
    "output_throughput": 3930.2880650598204,
    "total_throughput": 8346.439684145193,
    "itl": 177.50007727228353,
    "ttft": 1760996.3468875452,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1096,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.6230088174156783,
    "arrivals": 155196,
    "finished_requests": 64466,
    "scheduler_time": 91.2295838002084
}
#Debug simulation 
Total elapsed time: 6.177970973774791. Arrivals time: 0.21212173951789737 Scheduler time: 5.858293361030519 Scheduler overhead time: 0.03306991374120116 Adapter cache time: 0.02580436086282134 Engine time: 0.033423745073378086 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-16/adapters_256_slots_128_rate_0.4-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-16/adapters_256_slots_128_rate_0.4-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 33, 4320, 4320, 33, 4320, 1080, 4320, 33, 1080, 33, 4320, 1080, 1080, 1080, 1080, 4320, 33, 33, 33, 1080, 4320, 33, 4320, 4320, 1080, 1080, 1080, 33, 4320, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 4320, 1080, 33, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 33, 4320, 4320, 1080, 33, 33, 4320, 1080, 33, 1080, 1080, 4320, 1080, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 4320, 4320, 33, 4320, 33, 1080, 4320, 4320, 4320, 1080, 33, 4320, 1080, 33, 33, 33, 33, 33, 4320, 1080, 33, 4320, 33, 4320, 33, 33, 1080, 1080, 4320, 1080, 4320, 33, 1080, 33, 4320, 4320, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 33, 1080, 4320, 4320, 33, 4320, 1080, 33, 1080, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 1080, 4320, 4320, 1080, 33, 4320, 33, 1080, 1080, 33, 1080, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 4320, 33, 4320, 33, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 1080, 1080, 33, 1080, 4320, 1080, 1080, 4320, 33, 4320, 4320, 1080, 33, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 33, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 4320, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 33, 33, 33, 33]
Prompts retrieved: 466125 . Total input tokens: 103857742 . Total output tokens: 93269464
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 7.752981995232403,
    "estimated_duration": 3600.1101891048547,
    "input_throughput": 4615.732054615737,
    "output_throughput": 4099.108145261881,
    "total_throughput": 8714.840199877617,
    "itl": 209.62049881047656,
    "ttft": 1713609.2634199562,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 722,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.158816312919331,
    "arrivals": 155196,
    "finished_requests": 67349,
    "scheduler_time": 88.34050070325212
}
#Debug simulation 
Total elapsed time: 7.753070586826652. Arrivals time: 0.22935820184648037 Scheduler time: 7.433262488339096 Scheduler overhead time: 0.02924254536628723 Adapter cache time: 0.01808985834941268 Engine time: 0.02989238826557994 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-32/adapters_256_slots_128_rate_0.4-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-32/adapters_256_slots_128_rate_0.4-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 33, 4320, 4320, 33, 4320, 1080, 4320, 33, 1080, 33, 4320, 1080, 1080, 1080, 1080, 4320, 33, 33, 33, 1080, 4320, 33, 4320, 4320, 1080, 1080, 1080, 33, 4320, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 4320, 1080, 33, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 33, 4320, 4320, 1080, 33, 33, 4320, 1080, 33, 1080, 1080, 4320, 1080, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 4320, 4320, 33, 4320, 33, 1080, 4320, 4320, 4320, 1080, 33, 4320, 1080, 33, 33, 33, 33, 33, 4320, 1080, 33, 4320, 33, 4320, 33, 33, 1080, 1080, 4320, 1080, 4320, 33, 1080, 33, 4320, 4320, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 33, 1080, 4320, 4320, 33, 4320, 1080, 33, 1080, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 1080, 4320, 4320, 1080, 33, 4320, 33, 1080, 1080, 33, 1080, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 4320, 33, 4320, 33, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 1080, 1080, 33, 1080, 4320, 1080, 1080, 4320, 33, 4320, 4320, 1080, 33, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 33, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 4320, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 33, 33, 33, 33]
Prompts retrieved: 466125 . Total input tokens: 103857742 . Total output tokens: 93269464
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 6.1523868278600276,
    "estimated_duration": 3600.096855975981,
    "input_throughput": 4415.84702745177,
    "output_throughput": 3930.3884217759514,
    "total_throughput": 8346.235449227723,
    "itl": 177.50414219381219,
    "ttft": 1760878.275659175,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1082,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.6278373204917216,
    "arrivals": 155196,
    "finished_requests": 64472,
    "scheduler_time": 91.22393608179713
}
#Debug simulation 
Total elapsed time: 6.152475574053824. Arrivals time: 0.2129005049355328 Scheduler time: 5.83250792697072 Scheduler overhead time: 0.03282707929611206 Adapter cache time: 0.02566862152889371 Engine time: 0.03339702449738979 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-8/adapters_256_slots_128_rate_0.4-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-8/adapters_256_slots_128_rate_0.4-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 270, 4320, 4320, 270, 4320, 540, 4320, 270, 540, 270, 4320, 540, 540, 540, 540, 4320, 270, 270, 270, 540, 4320, 270, 4320, 4320, 540, 540, 540, 270, 4320, 270, 540, 540, 270, 540, 270, 270, 540, 540, 4320, 540, 270, 540, 4320, 540, 540, 4320, 540, 4320, 270, 4320, 4320, 540, 270, 270, 4320, 540, 270, 540, 540, 4320, 540, 270, 270, 4320, 4320, 4320, 4320, 4320, 4320, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 4320, 4320, 270, 4320, 270, 540, 4320, 4320, 4320, 540, 270, 4320, 540, 270, 270, 270, 270, 270, 4320, 540, 270, 4320, 270, 4320, 270, 270, 540, 540, 4320, 540, 4320, 270, 540, 270, 4320, 4320, 270, 4320, 540, 270, 4320, 270, 270, 4320, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 270, 540, 4320, 4320, 270, 4320, 540, 270, 540, 4320, 270, 270, 270, 270, 270, 270, 4320, 270, 270, 270, 4320, 270, 540, 4320, 4320, 540, 270, 4320, 270, 540, 540, 270, 540, 270, 4320, 270, 270, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 540, 4320, 540, 4320, 270, 4320, 270, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 540, 540, 270, 540, 4320, 540, 540, 4320, 270, 4320, 4320, 540, 270, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 270, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 4320, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 4320, 540, 270, 270, 270, 270]
Prompts retrieved: 440370 . Total input tokens: 98122611 . Total output tokens: 88123439
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 7.776369465980679,
    "estimated_duration": 3600.2129432454726,
    "input_throughput": 4602.323323981855,
    "output_throughput": 4095.506080456493,
    "total_throughput": 8697.829404438347,
    "itl": 210.10656450130008,
    "ttft": 1688641.95468792,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1084,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3175687144231842,
    "arrivals": 146502,
    "finished_requests": 67080,
    "scheduler_time": 87.79935043338287
}
#Debug simulation 
Total elapsed time: 7.776474022772163. Arrivals time: 0.2307850276120007 Scheduler time: 7.447261613793671 Scheduler overhead time: 0.02973492257297039 Adapter cache time: 0.025525944773107767 Engine time: 0.029794647824019194 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-16/adapters_256_slots_128_rate_0.4-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-16/adapters_256_slots_128_rate_0.4-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 270, 4320, 4320, 270, 4320, 540, 4320, 270, 540, 270, 4320, 540, 540, 540, 540, 4320, 270, 270, 270, 540, 4320, 270, 4320, 4320, 540, 540, 540, 270, 4320, 270, 540, 540, 270, 540, 270, 270, 540, 540, 4320, 540, 270, 540, 4320, 540, 540, 4320, 540, 4320, 270, 4320, 4320, 540, 270, 270, 4320, 540, 270, 540, 540, 4320, 540, 270, 270, 4320, 4320, 4320, 4320, 4320, 4320, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 4320, 4320, 270, 4320, 270, 540, 4320, 4320, 4320, 540, 270, 4320, 540, 270, 270, 270, 270, 270, 4320, 540, 270, 4320, 270, 4320, 270, 270, 540, 540, 4320, 540, 4320, 270, 540, 270, 4320, 4320, 270, 4320, 540, 270, 4320, 270, 270, 4320, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 270, 540, 4320, 4320, 270, 4320, 540, 270, 540, 4320, 270, 270, 270, 270, 270, 270, 4320, 270, 270, 270, 4320, 270, 540, 4320, 4320, 540, 270, 4320, 270, 540, 540, 270, 540, 270, 4320, 270, 270, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 540, 4320, 540, 4320, 270, 4320, 270, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 540, 540, 270, 540, 4320, 540, 540, 4320, 270, 4320, 4320, 540, 270, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 270, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 4320, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 4320, 540, 270, 270, 270, 270]
Prompts retrieved: 440370 . Total input tokens: 98122611 . Total output tokens: 88123439
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 7.76117311604321,
    "estimated_duration": 3600.1502872949663,
    "input_throughput": 4601.618731991195,
    "output_throughput": 4095.5862459504983,
    "total_throughput": 8697.204977941694,
    "itl": 210.1292055988211,
    "ttft": 1688673.6328715428,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1088,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.549814922041266,
    "arrivals": 146502,
    "finished_requests": 67083,
    "scheduler_time": 87.79166824861596
}
#Debug simulation 
Total elapsed time: 7.761283684056252. Arrivals time: 0.2295827753841877 Scheduler time: 7.433754435740411 Scheduler overhead time: 0.029277729336172342 Adapter cache time: 0.025643935427069664 Engine time: 0.029744963627308607 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-32/adapters_256_slots_128_rate_0.4-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-32/adapters_256_slots_128_rate_0.4-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 270, 4320, 4320, 270, 4320, 540, 4320, 270, 540, 270, 4320, 540, 540, 540, 540, 4320, 270, 270, 270, 540, 4320, 270, 4320, 4320, 540, 540, 540, 270, 4320, 270, 540, 540, 270, 540, 270, 270, 540, 540, 4320, 540, 270, 540, 4320, 540, 540, 4320, 540, 4320, 270, 4320, 4320, 540, 270, 270, 4320, 540, 270, 540, 540, 4320, 540, 270, 270, 4320, 4320, 4320, 4320, 4320, 4320, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 4320, 4320, 270, 4320, 270, 540, 4320, 4320, 4320, 540, 270, 4320, 540, 270, 270, 270, 270, 270, 4320, 540, 270, 4320, 270, 4320, 270, 270, 540, 540, 4320, 540, 4320, 270, 540, 270, 4320, 4320, 270, 4320, 540, 270, 4320, 270, 270, 4320, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 270, 540, 4320, 4320, 270, 4320, 540, 270, 540, 4320, 270, 270, 270, 270, 270, 270, 4320, 270, 270, 270, 4320, 270, 540, 4320, 4320, 540, 270, 4320, 270, 540, 540, 270, 540, 270, 4320, 270, 270, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 540, 4320, 540, 4320, 270, 4320, 270, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 540, 540, 270, 540, 4320, 540, 540, 4320, 270, 4320, 4320, 540, 270, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 270, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 4320, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 4320, 540, 270, 270, 270, 270]
Prompts retrieved: 440370 . Total input tokens: 98122611 . Total output tokens: 88123439
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 6.519952177070081,
    "estimated_duration": 3600.072727498355,
    "input_throughput": 4409.368421573715,
    "output_throughput": 3931.244191790141,
    "total_throughput": 8340.612613363855,
    "itl": 177.81937076874846,
    "ttft": 1737206.233289931,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1461,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.773711107745709,
    "arrivals": 146502,
    "finished_requests": 64220,
    "scheduler_time": 90.63154367119307
}
#Debug simulation 
Total elapsed time: 6.520044869277626. Arrivals time: 0.216935392934829 Scheduler time: 6.188584404066205 Scheduler overhead time: 0.03294080263003707 Adapter cache time: 0.03286655433475971 Engine time: 0.033530913293361664 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-16/adapters_256_slots_128_rate_0.4-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-16/adapters_256_slots_128_rate_0.4-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 270, 4320, 4320, 270, 4320, 540, 4320, 270, 540, 270, 4320, 540, 540, 540, 540, 4320, 270, 270, 270, 540, 4320, 270, 4320, 4320, 540, 540, 540, 270, 4320, 270, 540, 540, 270, 540, 270, 270, 540, 540, 4320, 540, 270, 540, 4320, 540, 540, 4320, 540, 4320, 270, 4320, 4320, 540, 270, 270, 4320, 540, 270, 540, 540, 4320, 540, 270, 270, 4320, 4320, 4320, 4320, 4320, 4320, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 4320, 4320, 270, 4320, 270, 540, 4320, 4320, 4320, 540, 270, 4320, 540, 270, 270, 270, 270, 270, 4320, 540, 270, 4320, 270, 4320, 270, 270, 540, 540, 4320, 540, 4320, 270, 540, 270, 4320, 4320, 270, 4320, 540, 270, 4320, 270, 270, 4320, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 270, 540, 4320, 4320, 270, 4320, 540, 270, 540, 4320, 270, 270, 270, 270, 270, 270, 4320, 270, 270, 270, 4320, 270, 540, 4320, 4320, 540, 270, 4320, 270, 540, 540, 270, 540, 270, 4320, 270, 270, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 540, 4320, 540, 4320, 270, 4320, 270, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 540, 540, 270, 540, 4320, 540, 540, 4320, 270, 4320, 4320, 540, 270, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 270, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 4320, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 4320, 540, 270, 270, 270, 270]
Prompts retrieved: 440370 . Total input tokens: 98122611 . Total output tokens: 88123439
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 7.753345943056047,
    "estimated_duration": 3600.0476017823244,
    "input_throughput": 4602.05470388715,
    "output_throughput": 4095.9008410610395,
    "total_throughput": 8697.95554494819,
    "itl": 210.11713665210561,
    "ttft": 1688680.5518250652,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1088,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.411709704408388,
    "arrivals": 146502,
    "finished_requests": 67083,
    "scheduler_time": 87.79199306319441
}
#Debug simulation 
Total elapsed time: 7.753438291139901. Arrivals time: 0.22728306567296386 Scheduler time: 7.428057867102325 Scheduler overhead time: 0.029291559476405382 Adapter cache time: 0.025460704695433378 Engine time: 0.02997841313481331 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-32/adapters_256_slots_128_rate_0.4-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-32/adapters_256_slots_128_rate_0.4-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 270, 4320, 4320, 270, 4320, 540, 4320, 270, 540, 270, 4320, 540, 540, 540, 540, 4320, 270, 270, 270, 540, 4320, 270, 4320, 4320, 540, 540, 540, 270, 4320, 270, 540, 540, 270, 540, 270, 270, 540, 540, 4320, 540, 270, 540, 4320, 540, 540, 4320, 540, 4320, 270, 4320, 4320, 540, 270, 270, 4320, 540, 270, 540, 540, 4320, 540, 270, 270, 4320, 4320, 4320, 4320, 4320, 4320, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 4320, 4320, 270, 4320, 270, 540, 4320, 4320, 4320, 540, 270, 4320, 540, 270, 270, 270, 270, 270, 4320, 540, 270, 4320, 270, 4320, 270, 270, 540, 540, 4320, 540, 4320, 270, 540, 270, 4320, 4320, 270, 4320, 540, 270, 4320, 270, 270, 4320, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 270, 540, 4320, 4320, 270, 4320, 540, 270, 540, 4320, 270, 270, 270, 270, 270, 270, 4320, 270, 270, 270, 4320, 270, 540, 4320, 4320, 540, 270, 4320, 270, 540, 540, 270, 540, 270, 4320, 270, 270, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 540, 4320, 540, 4320, 270, 4320, 270, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 540, 540, 270, 540, 4320, 540, 540, 4320, 270, 4320, 4320, 540, 270, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 270, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 4320, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 4320, 540, 270, 270, 270, 270]
Prompts retrieved: 440370 . Total input tokens: 98122611 . Total output tokens: 88123439
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 6.499766048975289,
    "estimated_duration": 3600.0193765896397,
    "input_throughput": 4408.987935791678,
    "output_throughput": 3931.336895582844,
    "total_throughput": 8340.324831374523,
    "itl": 177.8307554305306,
    "ttft": 1737184.5251514432,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1476,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.8810060945897895,
    "arrivals": 146502,
    "finished_requests": 64213,
    "scheduler_time": 90.6291109237006
}
#Debug simulation 
Total elapsed time: 6.4998788316734135. Arrivals time: 0.21318857464939356 Scheduler time: 6.171241365373135 Scheduler overhead time: 0.03320284700021148 Adapter cache time: 0.033239878714084625 Engine time: 0.03360722679644823 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-16/adapters_256_slots_128_rate_0.4-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-16/adapters_256_slots_128_rate_0.4-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 270, 4320, 4320, 270, 4320, 540, 4320, 270, 540, 270, 4320, 540, 540, 540, 540, 4320, 270, 270, 270, 540, 4320, 270, 4320, 4320, 540, 540, 540, 270, 4320, 270, 540, 540, 270, 540, 270, 270, 540, 540, 4320, 540, 270, 540, 4320, 540, 540, 4320, 540, 4320, 270, 4320, 4320, 540, 270, 270, 4320, 540, 270, 540, 540, 4320, 540, 270, 270, 4320, 4320, 4320, 4320, 4320, 4320, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 4320, 4320, 270, 4320, 270, 540, 4320, 4320, 4320, 540, 270, 4320, 540, 270, 270, 270, 270, 270, 4320, 540, 270, 4320, 270, 4320, 270, 270, 540, 540, 4320, 540, 4320, 270, 540, 270, 4320, 4320, 270, 4320, 540, 270, 4320, 270, 270, 4320, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 270, 540, 4320, 4320, 270, 4320, 540, 270, 540, 4320, 270, 270, 270, 270, 270, 270, 4320, 270, 270, 270, 4320, 270, 540, 4320, 4320, 540, 270, 4320, 270, 540, 540, 270, 540, 270, 4320, 270, 270, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 540, 4320, 540, 4320, 270, 4320, 270, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 540, 540, 270, 540, 4320, 540, 540, 4320, 270, 4320, 4320, 540, 270, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 270, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 4320, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 4320, 540, 270, 270, 270, 270]
Prompts retrieved: 440370 . Total input tokens: 98122611 . Total output tokens: 88123439
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 7.728124821092933,
    "estimated_duration": 3600.114697290946,
    "input_throughput": 4601.8567165281365,
    "output_throughput": 4095.6278451615103,
    "total_throughput": 8697.484561689647,
    "itl": 210.11041665240418,
    "ttft": 1688601.2538968609,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1088,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2531747208534885,
    "arrivals": 146502,
    "finished_requests": 67085,
    "scheduler_time": 87.79693090916925
}
#Debug simulation 
Total elapsed time: 7.728242825716734. Arrivals time: 0.2273083319887519 Scheduler time: 7.403294054791331 Scheduler overhead time: 0.029466130770742893 Adapter cache time: 0.025335558224469423 Engine time: 0.02962075872346759 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-32/adapters_256_slots_128_rate_0.4-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-32/adapters_256_slots_128_rate_0.4-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 270, 4320, 4320, 270, 4320, 540, 4320, 270, 540, 270, 4320, 540, 540, 540, 540, 4320, 270, 270, 270, 540, 4320, 270, 4320, 4320, 540, 540, 540, 270, 4320, 270, 540, 540, 270, 540, 270, 270, 540, 540, 4320, 540, 270, 540, 4320, 540, 540, 4320, 540, 4320, 270, 4320, 4320, 540, 270, 270, 4320, 540, 270, 540, 540, 4320, 540, 270, 270, 4320, 4320, 4320, 4320, 4320, 4320, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 4320, 4320, 270, 4320, 270, 540, 4320, 4320, 4320, 540, 270, 4320, 540, 270, 270, 270, 270, 270, 4320, 540, 270, 4320, 270, 4320, 270, 270, 540, 540, 4320, 540, 4320, 270, 540, 270, 4320, 4320, 270, 4320, 540, 270, 4320, 270, 270, 4320, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 270, 540, 4320, 4320, 270, 4320, 540, 270, 540, 4320, 270, 270, 270, 270, 270, 270, 4320, 270, 270, 270, 4320, 270, 540, 4320, 4320, 540, 270, 4320, 270, 540, 540, 270, 540, 270, 4320, 270, 270, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 540, 4320, 540, 4320, 270, 4320, 270, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 540, 540, 270, 540, 4320, 540, 540, 4320, 270, 4320, 4320, 540, 270, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 270, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 4320, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 4320, 540, 270, 270, 270, 270]
Prompts retrieved: 440370 . Total input tokens: 98122611 . Total output tokens: 88123439
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 6.506426608655602,
    "estimated_duration": 3600.097586903261,
    "input_throughput": 4408.704102283129,
    "output_throughput": 3931.192879739096,
    "total_throughput": 8339.896982022225,
    "itl": 177.83424791005967,
    "ttft": 1736965.5792695319,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1474,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.9394250371306825,
    "arrivals": 146502,
    "finished_requests": 64213,
    "scheduler_time": 90.62864301046103
}
#Debug simulation 
Total elapsed time: 6.506514918990433. Arrivals time: 0.21581403724849224 Scheduler time: 6.175889032892883 Scheduler overhead time: 0.03310859389603138 Adapter cache time: 0.03299054456874728 Engine time: 0.033425294794142246 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-8/adapters_256_slots_128_rate_0.4-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-8/adapters_256_slots_128_rate_0.4-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 135, 4320, 4320, 135, 4320, 540, 4320, 135, 540, 135, 4320, 540, 540, 540, 540, 4320, 135, 135, 135, 540, 4320, 135, 4320, 4320, 540, 540, 540, 135, 4320, 135, 540, 540, 135, 540, 135, 135, 540, 540, 4320, 540, 135, 540, 4320, 540, 540, 4320, 540, 4320, 135, 4320, 4320, 540, 135, 135, 4320, 540, 135, 540, 540, 4320, 540, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 4320, 4320, 135, 4320, 135, 540, 4320, 4320, 4320, 540, 135, 4320, 540, 135, 135, 135, 135, 135, 4320, 540, 135, 4320, 135, 4320, 135, 135, 540, 540, 4320, 540, 4320, 135, 540, 135, 4320, 4320, 135, 4320, 540, 135, 4320, 135, 135, 4320, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 135, 540, 4320, 4320, 135, 4320, 540, 135, 540, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 540, 4320, 4320, 540, 135, 4320, 135, 540, 540, 135, 540, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 540, 4320, 540, 4320, 135, 4320, 135, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 540, 540, 135, 540, 4320, 540, 540, 4320, 135, 4320, 4320, 540, 135, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 135, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 4320, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 4320, 540, 135, 135, 135, 135]
Prompts retrieved: 428895 . Total input tokens: 95549549 . Total output tokens: 85845104
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 6.88275667373091,
    "estimated_duration": 3600.011273536393,
    "input_throughput": 4636.555758227756,
    "output_throughput": 4093.5546808784243,
    "total_throughput": 8730.11043910618,
    "itl": 208.65607745158127,
    "ttft": 1668027.4169923603,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1193,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.651161878511866,
    "arrivals": 142715,
    "finished_requests": 67289,
    "scheduler_time": 87.43603316280822
}
#Debug simulation 
Total elapsed time: 6.882861307822168. Arrivals time: 0.23366912454366684 Scheduler time: 6.550801946781576 Scheduler overhead time: 0.02929099090397358 Adapter cache time: 0.026352278422564268 Engine time: 0.02947930246591568 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-16/adapters_256_slots_128_rate_0.4-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-16/adapters_256_slots_128_rate_0.4-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 135, 4320, 4320, 135, 4320, 540, 4320, 135, 540, 135, 4320, 540, 540, 540, 540, 4320, 135, 135, 135, 540, 4320, 135, 4320, 4320, 540, 540, 540, 135, 4320, 135, 540, 540, 135, 540, 135, 135, 540, 540, 4320, 540, 135, 540, 4320, 540, 540, 4320, 540, 4320, 135, 4320, 4320, 540, 135, 135, 4320, 540, 135, 540, 540, 4320, 540, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 4320, 4320, 135, 4320, 135, 540, 4320, 4320, 4320, 540, 135, 4320, 540, 135, 135, 135, 135, 135, 4320, 540, 135, 4320, 135, 4320, 135, 135, 540, 540, 4320, 540, 4320, 135, 540, 135, 4320, 4320, 135, 4320, 540, 135, 4320, 135, 135, 4320, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 135, 540, 4320, 4320, 135, 4320, 540, 135, 540, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 540, 4320, 4320, 540, 135, 4320, 135, 540, 540, 135, 540, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 540, 4320, 540, 4320, 135, 4320, 135, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 540, 540, 135, 540, 4320, 540, 540, 4320, 135, 4320, 4320, 540, 135, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 135, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 4320, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 4320, 540, 135, 135, 135, 135]
Prompts retrieved: 428895 . Total input tokens: 95549549 . Total output tokens: 85845104
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 6.886233488097787,
    "estimated_duration": 3600.0521346454047,
    "input_throughput": 4636.558687404704,
    "output_throughput": 4093.920990244683,
    "total_throughput": 8730.479677649388,
    "itl": 208.68312013633957,
    "ttft": 1668131.3364344863,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1177,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.837584950164896,
    "arrivals": 142715,
    "finished_requests": 67285,
    "scheduler_time": 87.43282697949267
}
#Debug simulation 
Total elapsed time: 6.886356209404767. Arrivals time: 0.2230065674521029 Scheduler time: 6.564974922686815 Scheduler overhead time: 0.029184676706790924 Adapter cache time: 0.026371142826974392 Engine time: 0.029365224298089743 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-32/adapters_256_slots_128_rate_0.4-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-32/adapters_256_slots_128_rate_0.4-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 135, 4320, 4320, 135, 4320, 540, 4320, 135, 540, 135, 4320, 540, 540, 540, 540, 4320, 135, 135, 135, 540, 4320, 135, 4320, 4320, 540, 540, 540, 135, 4320, 135, 540, 540, 135, 540, 135, 135, 540, 540, 4320, 540, 135, 540, 4320, 540, 540, 4320, 540, 4320, 135, 4320, 4320, 540, 135, 135, 4320, 540, 135, 540, 540, 4320, 540, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 4320, 4320, 135, 4320, 135, 540, 4320, 4320, 4320, 540, 135, 4320, 540, 135, 135, 135, 135, 135, 4320, 540, 135, 4320, 135, 4320, 135, 135, 540, 540, 4320, 540, 4320, 135, 540, 135, 4320, 4320, 135, 4320, 540, 135, 4320, 135, 135, 4320, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 135, 540, 4320, 4320, 135, 4320, 540, 135, 540, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 540, 4320, 4320, 540, 135, 4320, 135, 540, 540, 135, 540, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 540, 4320, 540, 4320, 135, 4320, 135, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 540, 540, 135, 540, 4320, 540, 540, 4320, 135, 4320, 4320, 540, 135, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 135, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 4320, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 4320, 540, 135, 135, 135, 135]
Prompts retrieved: 428895 . Total input tokens: 95549549 . Total output tokens: 85845104
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.948932142928243,
    "estimated_duration": 3600.0437548652194,
    "input_throughput": 4438.399388453602,
    "output_throughput": 3927.2472677291994,
    "total_throughput": 8365.646656182802,
    "itl": 176.6013385555896,
    "ttft": 1718530.7964224073,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1646,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.378580784089808,
    "arrivals": 142715,
    "finished_requests": 64429,
    "scheduler_time": 90.1797888371509
}
#Debug simulation 
Total elapsed time: 5.949016668833792. Arrivals time: 0.21245788829401135 Scheduler time: 5.618418495636433 Scheduler overhead time: 0.03344105742871761 Adapter cache time: 0.03585435776039958 Engine time: 0.03354019531980157 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-16/adapters_256_slots_128_rate_0.4-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-16/adapters_256_slots_128_rate_0.4-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 135, 4320, 4320, 135, 4320, 540, 4320, 135, 540, 135, 4320, 540, 540, 540, 540, 4320, 135, 135, 135, 540, 4320, 135, 4320, 4320, 540, 540, 540, 135, 4320, 135, 540, 540, 135, 540, 135, 135, 540, 540, 4320, 540, 135, 540, 4320, 540, 540, 4320, 540, 4320, 135, 4320, 4320, 540, 135, 135, 4320, 540, 135, 540, 540, 4320, 540, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 4320, 4320, 135, 4320, 135, 540, 4320, 4320, 4320, 540, 135, 4320, 540, 135, 135, 135, 135, 135, 4320, 540, 135, 4320, 135, 4320, 135, 135, 540, 540, 4320, 540, 4320, 135, 540, 135, 4320, 4320, 135, 4320, 540, 135, 4320, 135, 135, 4320, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 135, 540, 4320, 4320, 135, 4320, 540, 135, 540, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 540, 4320, 4320, 540, 135, 4320, 135, 540, 540, 135, 540, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 540, 4320, 540, 4320, 135, 4320, 135, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 540, 540, 135, 540, 4320, 540, 540, 4320, 135, 4320, 4320, 540, 135, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 135, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 4320, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 4320, 540, 135, 135, 135, 135]
Prompts retrieved: 428895 . Total input tokens: 95549549 . Total output tokens: 85845104
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 6.871413129847497,
    "estimated_duration": 3600.1433317540077,
    "input_throughput": 4636.609285182918,
    "output_throughput": 4093.6003491893734,
    "total_throughput": 8730.209634372291,
    "itl": 208.67283005745622,
    "ttft": 1668143.4543683727,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1179,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.6976965220714537,
    "arrivals": 142715,
    "finished_requests": 67290,
    "scheduler_time": 87.4379666846479
}
#Debug simulation 
Total elapsed time: 6.871502656023949. Arrivals time: 0.22377734072506428 Scheduler time: 6.549345796462148 Scheduler overhead time: 0.029301535803824663 Adapter cache time: 0.026446856558322906 Engine time: 0.029363146051764488 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-32/adapters_256_slots_128_rate_0.4-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-32/adapters_256_slots_128_rate_0.4-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 135, 4320, 4320, 135, 4320, 540, 4320, 135, 540, 135, 4320, 540, 540, 540, 540, 4320, 135, 135, 135, 540, 4320, 135, 4320, 4320, 540, 540, 540, 135, 4320, 135, 540, 540, 135, 540, 135, 135, 540, 540, 4320, 540, 135, 540, 4320, 540, 540, 4320, 540, 4320, 135, 4320, 4320, 540, 135, 135, 4320, 540, 135, 540, 540, 4320, 540, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 4320, 4320, 135, 4320, 135, 540, 4320, 4320, 4320, 540, 135, 4320, 540, 135, 135, 135, 135, 135, 4320, 540, 135, 4320, 135, 4320, 135, 135, 540, 540, 4320, 540, 4320, 135, 540, 135, 4320, 4320, 135, 4320, 540, 135, 4320, 135, 135, 4320, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 135, 540, 4320, 4320, 135, 4320, 540, 135, 540, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 540, 4320, 4320, 540, 135, 4320, 135, 540, 540, 135, 540, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 540, 4320, 540, 4320, 135, 4320, 135, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 540, 540, 135, 540, 4320, 540, 540, 4320, 135, 4320, 4320, 540, 135, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 135, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 4320, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 4320, 540, 135, 135, 135, 135]
Prompts retrieved: 428895 . Total input tokens: 95549549 . Total output tokens: 85845104
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 5.936390533577651,
    "estimated_duration": 3600.1834671789406,
    "input_throughput": 4437.672731306368,
    "output_throughput": 3926.652385601148,
    "total_throughput": 8364.325116907516,
    "itl": 176.5828489037403,
    "ttft": 1718769.8237630168,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1636,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.408032987415722,
    "arrivals": 142715,
    "finished_requests": 64416,
    "scheduler_time": 90.18499140847696
}
#Debug simulation 
Total elapsed time: 5.936480451840907. Arrivals time: 0.21525106532499194 Scheduler time: 5.603032934479415 Scheduler overhead time: 0.03351366613060236 Adapter cache time: 0.0356605825945735 Engine time: 0.0336539838463068 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-16/adapters_256_slots_128_rate_0.4-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-16/adapters_256_slots_128_rate_0.4-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 135, 4320, 4320, 135, 4320, 540, 4320, 135, 540, 135, 4320, 540, 540, 540, 540, 4320, 135, 135, 135, 540, 4320, 135, 4320, 4320, 540, 540, 540, 135, 4320, 135, 540, 540, 135, 540, 135, 135, 540, 540, 4320, 540, 135, 540, 4320, 540, 540, 4320, 540, 4320, 135, 4320, 4320, 540, 135, 135, 4320, 540, 135, 540, 540, 4320, 540, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 4320, 4320, 135, 4320, 135, 540, 4320, 4320, 4320, 540, 135, 4320, 540, 135, 135, 135, 135, 135, 4320, 540, 135, 4320, 135, 4320, 135, 135, 540, 540, 4320, 540, 4320, 135, 540, 135, 4320, 4320, 135, 4320, 540, 135, 4320, 135, 135, 4320, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 135, 540, 4320, 4320, 135, 4320, 540, 135, 540, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 540, 4320, 4320, 540, 135, 4320, 135, 540, 540, 135, 540, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 540, 4320, 540, 4320, 135, 4320, 135, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 540, 540, 135, 540, 4320, 540, 540, 4320, 135, 4320, 4320, 540, 135, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 135, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 4320, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 4320, 540, 135, 135, 135, 135]
Prompts retrieved: 428895 . Total input tokens: 95549549 . Total output tokens: 85845104
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 6.87651935312897,
    "estimated_duration": 3600.201538376216,
    "input_throughput": 4636.912356725825,
    "output_throughput": 4093.7144331779014,
    "total_throughput": 8730.626789903727,
    "itl": 208.66164224660884,
    "ttft": 1668059.3336933558,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1179,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5252692976895768,
    "arrivals": 142715,
    "finished_requests": 67295,
    "scheduler_time": 87.44299846070994
}
#Debug simulation 
Total elapsed time: 6.87663718406111. Arrivals time: 0.2236989913508296 Scheduler time: 6.554593162145466 Scheduler overhead time: 0.029295395594090223 Adapter cache time: 0.02622738527134061 Engine time: 0.029416684992611408 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-32/adapters_256_slots_128_rate_0.4-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-32/adapters_256_slots_128_rate_0.4-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 135, 4320, 4320, 135, 4320, 540, 4320, 135, 540, 135, 4320, 540, 540, 540, 540, 4320, 135, 135, 135, 540, 4320, 135, 4320, 4320, 540, 540, 540, 135, 4320, 135, 540, 540, 135, 540, 135, 135, 540, 540, 4320, 540, 135, 540, 4320, 540, 540, 4320, 540, 4320, 135, 4320, 4320, 540, 135, 135, 4320, 540, 135, 540, 540, 4320, 540, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 4320, 4320, 135, 4320, 135, 540, 4320, 4320, 4320, 540, 135, 4320, 540, 135, 135, 135, 135, 135, 4320, 540, 135, 4320, 135, 4320, 135, 135, 540, 540, 4320, 540, 4320, 135, 540, 135, 4320, 4320, 135, 4320, 540, 135, 4320, 135, 135, 4320, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 135, 540, 4320, 4320, 135, 4320, 540, 135, 540, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 540, 4320, 4320, 540, 135, 4320, 135, 540, 540, 135, 540, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 540, 4320, 540, 4320, 135, 4320, 135, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 540, 540, 135, 540, 4320, 540, 540, 4320, 135, 4320, 4320, 540, 135, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 135, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 4320, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 4320, 540, 135, 135, 135, 135]
Prompts retrieved: 428895 . Total input tokens: 95549549 . Total output tokens: 85845104
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.956981462426484,
    "estimated_duration": 3600.176824353154,
    "input_throughput": 4437.147612289891,
    "output_throughput": 3925.9721645865266,
    "total_throughput": 8363.119776876418,
    "itl": 176.60909781834903,
    "ttft": 1718484.098526825,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1627,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.454161556772806,
    "arrivals": 142715,
    "finished_requests": 64409,
    "scheduler_time": 90.18328155983286
}
#Debug simulation 
Total elapsed time: 5.9570973492227495. Arrivals time: 0.21317760972306132 Scheduler time: 5.626325781457126 Scheduler overhead time: 0.03330261306837201 Adapter cache time: 0.03563398448750377 Engine time: 0.03329881187528372 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-8/adapters_256_slots_128_rate_0.4-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-8/adapters_256_slots_128_rate_0.4-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 66, 4320, 4320, 66, 4320, 540, 4320, 66, 540, 66, 4320, 540, 540, 540, 540, 4320, 66, 66, 66, 540, 4320, 66, 4320, 4320, 540, 540, 540, 66, 4320, 66, 540, 540, 66, 540, 66, 66, 540, 540, 4320, 540, 66, 540, 4320, 540, 540, 4320, 540, 4320, 66, 4320, 4320, 540, 66, 66, 4320, 540, 66, 540, 540, 4320, 540, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 4320, 4320, 66, 4320, 66, 540, 4320, 4320, 4320, 540, 66, 4320, 540, 66, 66, 66, 66, 66, 4320, 540, 66, 4320, 66, 4320, 66, 66, 540, 540, 4320, 540, 4320, 66, 540, 66, 4320, 4320, 66, 4320, 540, 66, 4320, 66, 66, 4320, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 66, 540, 4320, 4320, 66, 4320, 540, 66, 540, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 540, 4320, 4320, 540, 66, 4320, 66, 540, 540, 66, 540, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 540, 4320, 540, 4320, 66, 4320, 66, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 540, 540, 66, 540, 4320, 540, 540, 4320, 66, 4320, 4320, 540, 66, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 66, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 4320, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 4320, 540, 66, 66, 66, 66]
Prompts retrieved: 423030 . Total input tokens: 94249363 . Total output tokens: 84650939
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 6.220332798548043,
    "estimated_duration": 3600.113341893561,
    "input_throughput": 4654.968999166435,
    "output_throughput": 4091.7375651990014,
    "total_throughput": 8746.706564365437,
    "itl": 208.5009436988924,
    "ttft": 1660856.3764672775,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1260,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.8562145573553677,
    "arrivals": 140795,
    "finished_requests": 67199,
    "scheduler_time": 87.31456824960267
}
#Debug simulation 
Total elapsed time: 6.2204212988726795. Arrivals time: 0.21792679373174906 Scheduler time: 5.903466919437051 Scheduler overhead time: 0.028918204363435507 Adapter cache time: 0.027461200952529907 Engine time: 0.02937041874974966 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-16/adapters_256_slots_128_rate_0.4-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-16/adapters_256_slots_128_rate_0.4-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 66, 4320, 4320, 66, 4320, 540, 4320, 66, 540, 66, 4320, 540, 540, 540, 540, 4320, 66, 66, 66, 540, 4320, 66, 4320, 4320, 540, 540, 540, 66, 4320, 66, 540, 540, 66, 540, 66, 66, 540, 540, 4320, 540, 66, 540, 4320, 540, 540, 4320, 540, 4320, 66, 4320, 4320, 540, 66, 66, 4320, 540, 66, 540, 540, 4320, 540, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 4320, 4320, 66, 4320, 66, 540, 4320, 4320, 4320, 540, 66, 4320, 540, 66, 66, 66, 66, 66, 4320, 540, 66, 4320, 66, 4320, 66, 66, 540, 540, 4320, 540, 4320, 66, 540, 66, 4320, 4320, 66, 4320, 540, 66, 4320, 66, 66, 4320, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 66, 540, 4320, 4320, 66, 4320, 540, 66, 540, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 540, 4320, 4320, 540, 66, 4320, 66, 540, 540, 66, 540, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 540, 4320, 540, 4320, 66, 4320, 66, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 540, 540, 66, 540, 4320, 540, 540, 4320, 66, 4320, 4320, 540, 66, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 66, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 4320, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 4320, 540, 66, 66, 66, 66]
Prompts retrieved: 423030 . Total input tokens: 94249363 . Total output tokens: 84650939
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 6.239695830736309,
    "estimated_duration": 3600.1874105801267,
    "input_throughput": 4654.671851457783,
    "output_throughput": 4091.532834293866,
    "total_throughput": 8746.204685751649,
    "itl": 208.52324699239153,
    "ttft": 1660961.6308958952,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1263,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.121696566543538,
    "arrivals": 140795,
    "finished_requests": 67192,
    "scheduler_time": 87.3112398626337
}
#Debug simulation 
Total elapsed time: 6.239783457946032. Arrivals time: 0.22412586910650134 Scheduler time: 5.916753731202334 Scheduler overhead time: 0.029003937263041735 Adapter cache time: 0.0274399328045547 Engine time: 0.029196070972830057 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-32/adapters_256_slots_128_rate_0.4-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-32/adapters_256_slots_128_rate_0.4-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 66, 4320, 4320, 66, 4320, 540, 4320, 66, 540, 66, 4320, 540, 540, 540, 540, 4320, 66, 66, 66, 540, 4320, 66, 4320, 4320, 540, 540, 540, 66, 4320, 66, 540, 540, 66, 540, 66, 66, 540, 540, 4320, 540, 66, 540, 4320, 540, 540, 4320, 540, 4320, 66, 4320, 4320, 540, 66, 66, 4320, 540, 66, 540, 540, 4320, 540, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 4320, 4320, 66, 4320, 66, 540, 4320, 4320, 4320, 540, 66, 4320, 540, 66, 66, 66, 66, 66, 4320, 540, 66, 4320, 66, 4320, 66, 66, 540, 540, 4320, 540, 4320, 66, 540, 66, 4320, 4320, 66, 4320, 540, 66, 4320, 66, 66, 4320, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 66, 540, 4320, 4320, 66, 4320, 540, 66, 540, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 540, 4320, 4320, 540, 66, 4320, 66, 540, 540, 66, 540, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 540, 4320, 540, 4320, 66, 4320, 66, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 540, 540, 66, 540, 4320, 540, 540, 4320, 66, 4320, 4320, 540, 66, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 66, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 4320, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 4320, 540, 66, 66, 66, 66]
Prompts retrieved: 423030 . Total input tokens: 94249363 . Total output tokens: 84650939
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.533346880227327,
    "estimated_duration": 3600.057541938185,
    "input_throughput": 4453.207153841453,
    "output_throughput": 3921.656761185852,
    "total_throughput": 8374.863915027305,
    "itl": 176.14644343616462,
    "ttft": 1710008.4766626337,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1726,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.641622646674462,
    "arrivals": 140795,
    "finished_requests": 64287,
    "scheduler_time": 90.18811524450544
}
#Debug simulation 
Total elapsed time: 5.533466272056103. Arrivals time: 0.2090245853178203 Scheduler time: 5.2056830576621 Scheduler overhead time: 0.03335063485428691 Adapter cache time: 0.03651567315682769 Engine time: 0.03341058315709233 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-16/adapters_256_slots_128_rate_0.4-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-16/adapters_256_slots_128_rate_0.4-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 66, 4320, 4320, 66, 4320, 540, 4320, 66, 540, 66, 4320, 540, 540, 540, 540, 4320, 66, 66, 66, 540, 4320, 66, 4320, 4320, 540, 540, 540, 66, 4320, 66, 540, 540, 66, 540, 66, 66, 540, 540, 4320, 540, 66, 540, 4320, 540, 540, 4320, 540, 4320, 66, 4320, 4320, 540, 66, 66, 4320, 540, 66, 540, 540, 4320, 540, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 4320, 4320, 66, 4320, 66, 540, 4320, 4320, 4320, 540, 66, 4320, 540, 66, 66, 66, 66, 66, 4320, 540, 66, 4320, 66, 4320, 66, 66, 540, 540, 4320, 540, 4320, 66, 540, 66, 4320, 4320, 66, 4320, 540, 66, 4320, 66, 66, 4320, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 66, 540, 4320, 4320, 66, 4320, 540, 66, 540, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 540, 4320, 4320, 540, 66, 4320, 66, 540, 540, 66, 540, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 540, 4320, 540, 4320, 66, 4320, 66, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 540, 540, 66, 540, 4320, 540, 540, 4320, 66, 4320, 4320, 540, 66, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 66, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 4320, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 4320, 540, 66, 66, 66, 66]
Prompts retrieved: 423030 . Total input tokens: 94249363 . Total output tokens: 84650939
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 6.224943481851369,
    "estimated_duration": 3600.1124917357815,
    "input_throughput": 4655.112316204248,
    "output_throughput": 4091.7554753678282,
    "total_throughput": 8746.867791572076,
    "itl": 208.51317992004735,
    "ttft": 1660888.3534560297,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1261,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9584072683541613,
    "arrivals": 140795,
    "finished_requests": 67194,
    "scheduler_time": 87.3122453955362
}
#Debug simulation 
Total elapsed time: 6.2250290317460895. Arrivals time: 0.22081499034538865 Scheduler time: 5.9046098734252155 Scheduler overhead time: 0.029396223835647106 Adapter cache time: 0.027558665722608566 Engine time: 0.029382403939962387 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-32/adapters_256_slots_128_rate_0.4-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-32/adapters_256_slots_128_rate_0.4-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 66, 4320, 4320, 66, 4320, 540, 4320, 66, 540, 66, 4320, 540, 540, 540, 540, 4320, 66, 66, 66, 540, 4320, 66, 4320, 4320, 540, 540, 540, 66, 4320, 66, 540, 540, 66, 540, 66, 66, 540, 540, 4320, 540, 66, 540, 4320, 540, 540, 4320, 540, 4320, 66, 4320, 4320, 540, 66, 66, 4320, 540, 66, 540, 540, 4320, 540, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 4320, 4320, 66, 4320, 66, 540, 4320, 4320, 4320, 540, 66, 4320, 540, 66, 66, 66, 66, 66, 4320, 540, 66, 4320, 66, 4320, 66, 66, 540, 540, 4320, 540, 4320, 66, 540, 66, 4320, 4320, 66, 4320, 540, 66, 4320, 66, 66, 4320, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 66, 540, 4320, 4320, 66, 4320, 540, 66, 540, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 540, 4320, 4320, 540, 66, 4320, 66, 540, 540, 66, 540, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 540, 4320, 540, 4320, 66, 4320, 66, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 540, 540, 66, 540, 4320, 540, 540, 4320, 66, 4320, 4320, 540, 66, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 66, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 4320, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 4320, 540, 66, 66, 66, 66]
Prompts retrieved: 423030 . Total input tokens: 94249363 . Total output tokens: 84650939
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 5.528964566998184,
    "estimated_duration": 3600.1387912287896,
    "input_throughput": 4453.055543041476,
    "output_throughput": 3922.0187939422926,
    "total_throughput": 8375.074336983767,
    "itl": 176.14620518283343,
    "ttft": 1710177.1192054944,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1725,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.702959354277626,
    "arrivals": 140795,
    "finished_requests": 64293,
    "scheduler_time": 90.1872695199877
}
#Debug simulation 
Total elapsed time: 5.529047242831439. Arrivals time: 0.20965714240446687 Scheduler time: 5.201201959513128 Scheduler overhead time: 0.03340245923027396 Adapter cache time: 0.03605648363009095 Engine time: 0.0333599136210978 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-16/adapters_256_slots_128_rate_0.4-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-16/adapters_256_slots_128_rate_0.4-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 66, 4320, 4320, 66, 4320, 540, 4320, 66, 540, 66, 4320, 540, 540, 540, 540, 4320, 66, 66, 66, 540, 4320, 66, 4320, 4320, 540, 540, 540, 66, 4320, 66, 540, 540, 66, 540, 66, 66, 540, 540, 4320, 540, 66, 540, 4320, 540, 540, 4320, 540, 4320, 66, 4320, 4320, 540, 66, 66, 4320, 540, 66, 540, 540, 4320, 540, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 4320, 4320, 66, 4320, 66, 540, 4320, 4320, 4320, 540, 66, 4320, 540, 66, 66, 66, 66, 66, 4320, 540, 66, 4320, 66, 4320, 66, 66, 540, 540, 4320, 540, 4320, 66, 540, 66, 4320, 4320, 66, 4320, 540, 66, 4320, 66, 66, 4320, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 66, 540, 4320, 4320, 66, 4320, 540, 66, 540, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 540, 4320, 4320, 540, 66, 4320, 66, 540, 540, 66, 540, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 540, 4320, 540, 4320, 66, 4320, 66, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 540, 540, 66, 540, 4320, 540, 540, 4320, 66, 4320, 4320, 540, 66, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 66, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 4320, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 4320, 540, 66, 66, 66, 66]
Prompts retrieved: 423030 . Total input tokens: 94249363 . Total output tokens: 84650939
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 6.236780420877039,
    "estimated_duration": 3600.233606444497,
    "input_throughput": 4654.815723624726,
    "output_throughput": 4091.744761681787,
    "total_throughput": 8746.560485306514,
    "itl": 208.49776168368643,
    "ttft": 1660844.9689924375,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1261,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7704534218715464,
    "arrivals": 140795,
    "finished_requests": 67200,
    "scheduler_time": 87.31950561082307
}
#Debug simulation 
Total elapsed time: 6.236882326193154. Arrivals time: 0.21934356028214097 Scheduler time: 5.918701602611691 Scheduler overhead time: 0.0290140719152987 Adapter cache time: 0.027359800413250923 Engine time: 0.029200858436524868 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-32/adapters_256_slots_128_rate_0.4-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-32/adapters_256_slots_128_rate_0.4-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 66, 4320, 4320, 66, 4320, 540, 4320, 66, 540, 66, 4320, 540, 540, 540, 540, 4320, 66, 66, 66, 540, 4320, 66, 4320, 4320, 540, 540, 540, 66, 4320, 66, 540, 540, 66, 540, 66, 66, 540, 540, 4320, 540, 66, 540, 4320, 540, 540, 4320, 540, 4320, 66, 4320, 4320, 540, 66, 66, 4320, 540, 66, 540, 540, 4320, 540, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 4320, 4320, 66, 4320, 66, 540, 4320, 4320, 4320, 540, 66, 4320, 540, 66, 66, 66, 66, 66, 4320, 540, 66, 4320, 66, 4320, 66, 66, 540, 540, 4320, 540, 4320, 66, 540, 66, 4320, 4320, 66, 4320, 540, 66, 4320, 66, 66, 4320, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 66, 540, 4320, 4320, 66, 4320, 540, 66, 540, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 540, 4320, 4320, 540, 66, 4320, 66, 540, 540, 66, 540, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 540, 4320, 540, 4320, 66, 4320, 66, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 540, 540, 66, 540, 4320, 540, 540, 4320, 66, 4320, 4320, 540, 66, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 66, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 4320, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 4320, 540, 66, 66, 66, 66]
Prompts retrieved: 423030 . Total input tokens: 94249363 . Total output tokens: 84650939
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.50407401798293,
    "estimated_duration": 3600.132818378835,
    "input_throughput": 4452.969323287078,
    "output_throughput": 3921.610871667112,
    "total_throughput": 8374.58019495419,
    "itl": 176.12986651774733,
    "ttft": 1710322.901596175,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1730,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.800517089143279,
    "arrivals": 140795,
    "finished_requests": 64283,
    "scheduler_time": 90.18904209184684
}
#Debug simulation 
Total elapsed time: 5.504184728022665. Arrivals time: 0.21185775892809033 Scheduler time: 5.17324892571196 Scheduler overhead time: 0.03315777890384197 Adapter cache time: 0.03720385441556573 Engine time: 0.03330658422783017 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-8/adapters_256_slots_128_rate_0.4-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-8/adapters_256_slots_128_rate_0.4-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 33, 4320, 4320, 33, 4320, 540, 4320, 33, 540, 33, 4320, 540, 540, 540, 540, 4320, 33, 33, 33, 540, 4320, 33, 4320, 4320, 540, 540, 540, 33, 4320, 33, 540, 540, 33, 540, 33, 33, 540, 540, 4320, 540, 33, 540, 4320, 540, 540, 4320, 540, 4320, 33, 4320, 4320, 540, 33, 33, 4320, 540, 33, 540, 540, 4320, 540, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 4320, 4320, 33, 4320, 33, 540, 4320, 4320, 4320, 540, 33, 4320, 540, 33, 33, 33, 33, 33, 4320, 540, 33, 4320, 33, 4320, 33, 33, 540, 540, 4320, 540, 4320, 33, 540, 33, 4320, 4320, 33, 4320, 540, 33, 4320, 33, 33, 4320, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 33, 540, 4320, 4320, 33, 4320, 540, 33, 540, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 540, 4320, 4320, 540, 33, 4320, 33, 540, 540, 33, 540, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 540, 4320, 540, 4320, 33, 4320, 33, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 540, 540, 33, 540, 4320, 540, 540, 4320, 33, 4320, 4320, 540, 33, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 33, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 4320, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 4320, 540, 33, 33, 33, 33]
Prompts retrieved: 420225 . Total input tokens: 93627813 . Total output tokens: 84090312
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.87439930299297,
    "estimated_duration": 3600.050235428513,
    "input_throughput": 4639.477203854052,
    "output_throughput": 4091.757346893419,
    "total_throughput": 8731.234550747471,
    "itl": 208.64369187626892,
    "ttft": 1654207.492053075,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1292,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.954150165161219,
    "arrivals": 139799,
    "finished_requests": 67331,
    "scheduler_time": 87.22298484196415
}
#Debug simulation 
Total elapsed time: 5.874485505744815. Arrivals time: 0.21839157538488507 Scheduler time: 5.557052933610976 Scheduler overhead time: 0.029125169850885868 Adapter cache time: 0.027453408110886812 Engine time: 0.029214642476290464 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-16/adapters_256_slots_128_rate_0.4-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-16/adapters_256_slots_128_rate_0.4-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 33, 4320, 4320, 33, 4320, 540, 4320, 33, 540, 33, 4320, 540, 540, 540, 540, 4320, 33, 33, 33, 540, 4320, 33, 4320, 4320, 540, 540, 540, 33, 4320, 33, 540, 540, 33, 540, 33, 33, 540, 540, 4320, 540, 33, 540, 4320, 540, 540, 4320, 540, 4320, 33, 4320, 4320, 540, 33, 33, 4320, 540, 33, 540, 540, 4320, 540, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 4320, 4320, 33, 4320, 33, 540, 4320, 4320, 4320, 540, 33, 4320, 540, 33, 33, 33, 33, 33, 4320, 540, 33, 4320, 33, 4320, 33, 33, 540, 540, 4320, 540, 4320, 33, 540, 33, 4320, 4320, 33, 4320, 540, 33, 4320, 33, 33, 4320, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 33, 540, 4320, 4320, 33, 4320, 540, 33, 540, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 540, 4320, 4320, 540, 33, 4320, 33, 540, 540, 33, 540, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 540, 4320, 540, 4320, 33, 4320, 33, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 540, 540, 33, 540, 4320, 540, 540, 4320, 33, 4320, 4320, 540, 33, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 33, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 4320, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 4320, 540, 33, 33, 33, 33]
Prompts retrieved: 420225 . Total input tokens: 93627813 . Total output tokens: 84090312
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.855422798078507,
    "estimated_duration": 3600.045586854246,
    "input_throughput": 4639.0059784196155,
    "output_throughput": 4091.314024962186,
    "total_throughput": 8730.320003381801,
    "itl": 208.65778210923108,
    "ttft": 1654327.010617434,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1293,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.220387172396283,
    "arrivals": 139799,
    "finished_requests": 67323,
    "scheduler_time": 87.21774170559493
}
#Debug simulation 
Total elapsed time: 5.855510573834181. Arrivals time: 0.21613895054906607 Scheduler time: 5.540418054908514 Scheduler overhead time: 0.029055454768240452 Adapter cache time: 0.027576187625527382 Engine time: 0.029126005712896585 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-32/adapters_256_slots_128_rate_0.4-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-32/adapters_256_slots_128_rate_0.4-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 33, 4320, 4320, 33, 4320, 540, 4320, 33, 540, 33, 4320, 540, 540, 540, 540, 4320, 33, 33, 33, 540, 4320, 33, 4320, 4320, 540, 540, 540, 33, 4320, 33, 540, 540, 33, 540, 33, 33, 540, 540, 4320, 540, 33, 540, 4320, 540, 540, 4320, 540, 4320, 33, 4320, 4320, 540, 33, 33, 4320, 540, 33, 540, 540, 4320, 540, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 4320, 4320, 33, 4320, 33, 540, 4320, 4320, 4320, 540, 33, 4320, 540, 33, 33, 33, 33, 33, 4320, 540, 33, 4320, 33, 4320, 33, 33, 540, 540, 4320, 540, 4320, 33, 540, 33, 4320, 4320, 33, 4320, 540, 33, 4320, 33, 33, 4320, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 33, 540, 4320, 4320, 33, 4320, 540, 33, 540, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 540, 4320, 4320, 540, 33, 4320, 33, 540, 540, 33, 540, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 540, 4320, 540, 4320, 33, 4320, 33, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 540, 540, 33, 540, 4320, 540, 540, 4320, 33, 4320, 4320, 540, 33, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 33, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 4320, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 4320, 540, 33, 33, 33, 33]
Prompts retrieved: 420225 . Total input tokens: 93627813 . Total output tokens: 84090312
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.335083188954741,
    "estimated_duration": 3600.0711409913893,
    "input_throughput": 4448.230707904864,
    "output_throughput": 3929.7423428427296,
    "total_throughput": 8377.973050747594,
    "itl": 177.08418344706988,
    "ttft": 1703365.7636191333,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1673,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.467163495402728,
    "arrivals": 139799,
    "finished_requests": 64594,
    "scheduler_time": 89.92691008797433
}
#Debug simulation 
Total elapsed time: 5.335181756876409. Arrivals time: 0.20960777113214135 Scheduler time: 5.008638869039714 Scheduler overhead time: 0.032952025067061186 Adapter cache time: 0.035388259682804346 Engine time: 0.03323054825887084 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-16/adapters_256_slots_128_rate_0.4-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-16/adapters_256_slots_128_rate_0.4-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 33, 4320, 4320, 33, 4320, 540, 4320, 33, 540, 33, 4320, 540, 540, 540, 540, 4320, 33, 33, 33, 540, 4320, 33, 4320, 4320, 540, 540, 540, 33, 4320, 33, 540, 540, 33, 540, 33, 33, 540, 540, 4320, 540, 33, 540, 4320, 540, 540, 4320, 540, 4320, 33, 4320, 4320, 540, 33, 33, 4320, 540, 33, 540, 540, 4320, 540, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 4320, 4320, 33, 4320, 33, 540, 4320, 4320, 4320, 540, 33, 4320, 540, 33, 33, 33, 33, 33, 4320, 540, 33, 4320, 33, 4320, 33, 33, 540, 540, 4320, 540, 4320, 33, 540, 33, 4320, 4320, 33, 4320, 540, 33, 4320, 33, 33, 4320, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 33, 540, 4320, 4320, 33, 4320, 540, 33, 540, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 540, 4320, 4320, 540, 33, 4320, 33, 540, 540, 33, 540, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 540, 4320, 540, 4320, 33, 4320, 33, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 540, 540, 33, 540, 4320, 540, 540, 4320, 33, 4320, 4320, 540, 33, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 33, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 4320, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 4320, 540, 33, 33, 33, 33]
Prompts retrieved: 420225 . Total input tokens: 93627813 . Total output tokens: 84090312
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.866934400051832,
    "estimated_duration": 3600.1587385148014,
    "input_throughput": 4639.3373773541825,
    "output_throughput": 4091.6340278031435,
    "total_throughput": 8730.971405157326,
    "itl": 208.64829344263288,
    "ttft": 1654244.6875067635,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1292,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.055184780680528,
    "arrivals": 139799,
    "finished_requests": 67331,
    "scheduler_time": 87.22374948648628
}
#Debug simulation 
Total elapsed time: 5.867054467089474. Arrivals time: 0.217272506095469 Scheduler time: 5.550267579033971 Scheduler overhead time: 0.029180985409766436 Adapter cache time: 0.02784843184053898 Engine time: 0.029143179766833782 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-32/adapters_256_slots_128_rate_0.4-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-32/adapters_256_slots_128_rate_0.4-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 33, 4320, 4320, 33, 4320, 540, 4320, 33, 540, 33, 4320, 540, 540, 540, 540, 4320, 33, 33, 33, 540, 4320, 33, 4320, 4320, 540, 540, 540, 33, 4320, 33, 540, 540, 33, 540, 33, 33, 540, 540, 4320, 540, 33, 540, 4320, 540, 540, 4320, 540, 4320, 33, 4320, 4320, 540, 33, 33, 4320, 540, 33, 540, 540, 4320, 540, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 4320, 4320, 33, 4320, 33, 540, 4320, 4320, 4320, 540, 33, 4320, 540, 33, 33, 33, 33, 33, 4320, 540, 33, 4320, 33, 4320, 33, 33, 540, 540, 4320, 540, 4320, 33, 540, 33, 4320, 4320, 33, 4320, 540, 33, 4320, 33, 33, 4320, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 33, 540, 4320, 4320, 33, 4320, 540, 33, 540, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 540, 4320, 4320, 540, 33, 4320, 33, 540, 540, 33, 540, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 540, 4320, 540, 4320, 33, 4320, 33, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 540, 540, 33, 540, 4320, 540, 540, 4320, 33, 4320, 4320, 540, 33, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 33, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 4320, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 4320, 540, 33, 33, 33, 33]
Prompts retrieved: 420225 . Total input tokens: 93627813 . Total output tokens: 84090312
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 5.338410083670169,
    "estimated_duration": 3600.0395574533613,
    "input_throughput": 4448.562785051418,
    "output_throughput": 3929.2998796953516,
    "total_throughput": 8377.86266474677,
    "itl": 177.08158293300326,
    "ttft": 1703480.4469651529,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1699,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.618729137927227,
    "arrivals": 139799,
    "finished_requests": 64594,
    "scheduler_time": 89.92235339707011
}
#Debug simulation 
Total elapsed time: 5.338493363931775. Arrivals time: 0.21005534380674362 Scheduler time: 5.010933897923678 Scheduler overhead time: 0.0330607439391315 Adapter cache time: 0.03587429923936725 Engine time: 0.03324605384841561 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-16/adapters_256_slots_128_rate_0.4-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-16/adapters_256_slots_128_rate_0.4-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 33, 4320, 4320, 33, 4320, 540, 4320, 33, 540, 33, 4320, 540, 540, 540, 540, 4320, 33, 33, 33, 540, 4320, 33, 4320, 4320, 540, 540, 540, 33, 4320, 33, 540, 540, 33, 540, 33, 33, 540, 540, 4320, 540, 33, 540, 4320, 540, 540, 4320, 540, 4320, 33, 4320, 4320, 540, 33, 33, 4320, 540, 33, 540, 540, 4320, 540, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 4320, 4320, 33, 4320, 33, 540, 4320, 4320, 4320, 540, 33, 4320, 540, 33, 33, 33, 33, 33, 4320, 540, 33, 4320, 33, 4320, 33, 33, 540, 540, 4320, 540, 4320, 33, 540, 33, 4320, 4320, 33, 4320, 540, 33, 4320, 33, 33, 4320, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 33, 540, 4320, 4320, 33, 4320, 540, 33, 540, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 540, 4320, 4320, 540, 33, 4320, 33, 540, 540, 33, 540, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 540, 4320, 540, 4320, 33, 4320, 33, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 540, 540, 33, 540, 4320, 540, 540, 4320, 33, 4320, 4320, 540, 33, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 33, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 4320, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 4320, 540, 33, 33, 33, 33]
Prompts retrieved: 420225 . Total input tokens: 93627813 . Total output tokens: 84090312
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.860051687806845,
    "estimated_duration": 3600.2345740576893,
    "input_throughput": 4639.297983624208,
    "output_throughput": 4091.7747710524454,
    "total_throughput": 8731.072754676654,
    "itl": 208.64524002322267,
    "ttft": 1654138.9100416831,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1292,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.8631449810135106,
    "arrivals": 139799,
    "finished_requests": 67335,
    "scheduler_time": 87.22968573006233
}
#Debug simulation 
Total elapsed time: 5.860135389957577. Arrivals time: 0.21776812430471182 Scheduler time: 5.543559934012592 Scheduler overhead time: 0.028953409753739834 Adapter cache time: 0.027621455024927855 Engine time: 0.029035585932433605 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-32/adapters_256_slots_128_rate_0.4-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-32/adapters_256_slots_128_rate_0.4-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 33, 4320, 4320, 33, 4320, 540, 4320, 33, 540, 33, 4320, 540, 540, 540, 540, 4320, 33, 33, 33, 540, 4320, 33, 4320, 4320, 540, 540, 540, 33, 4320, 33, 540, 540, 33, 540, 33, 33, 540, 540, 4320, 540, 33, 540, 4320, 540, 540, 4320, 540, 4320, 33, 4320, 4320, 540, 33, 33, 4320, 540, 33, 540, 540, 4320, 540, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 4320, 4320, 33, 4320, 33, 540, 4320, 4320, 4320, 540, 33, 4320, 540, 33, 33, 33, 33, 33, 4320, 540, 33, 4320, 33, 4320, 33, 33, 540, 540, 4320, 540, 4320, 33, 540, 33, 4320, 4320, 33, 4320, 540, 33, 4320, 33, 33, 4320, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 33, 540, 4320, 4320, 33, 4320, 540, 33, 540, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 540, 4320, 4320, 540, 33, 4320, 33, 540, 540, 33, 540, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 540, 4320, 540, 4320, 33, 4320, 33, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 540, 540, 33, 540, 4320, 540, 540, 4320, 33, 4320, 4320, 540, 33, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 33, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 4320, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 4320, 540, 33, 33, 33, 33]
Prompts retrieved: 420225 . Total input tokens: 93627813 . Total output tokens: 84090312
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.340425209142268,
    "estimated_duration": 3600.071936342015,
    "input_throughput": 4448.502775273028,
    "output_throughput": 3929.369815419182,
    "total_throughput": 8377.87259069221,
    "itl": 177.10012130485376,
    "ttft": 1703613.402787891,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1693,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.674016853310064,
    "arrivals": 139799,
    "finished_requests": 64598,
    "scheduler_time": 89.91990655682075
}
#Debug simulation 
Total elapsed time: 5.340525893960148. Arrivals time: 0.20789903867989779 Scheduler time: 5.015212654601783 Scheduler overhead time: 0.033024321775883436 Adapter cache time: 0.03591638011857867 Engine time: 0.03314711106941104 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-8/adapters_256_slots_128_rate_0.4-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-8/adapters_256_slots_128_rate_0.4-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 135, 4320, 4320, 135, 4320, 270, 4320, 135, 270, 135, 4320, 270, 270, 270, 270, 4320, 135, 135, 135, 270, 4320, 135, 4320, 4320, 270, 270, 270, 135, 4320, 135, 270, 270, 135, 270, 135, 135, 270, 270, 4320, 270, 135, 270, 4320, 270, 270, 4320, 270, 4320, 135, 4320, 4320, 270, 135, 135, 4320, 270, 135, 270, 270, 4320, 270, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 4320, 4320, 135, 4320, 135, 270, 4320, 4320, 4320, 270, 135, 4320, 270, 135, 135, 135, 135, 135, 4320, 270, 135, 4320, 135, 4320, 135, 135, 270, 270, 4320, 270, 4320, 135, 270, 135, 4320, 4320, 135, 4320, 270, 135, 4320, 135, 135, 4320, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 135, 270, 4320, 4320, 135, 4320, 270, 135, 270, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 270, 4320, 4320, 270, 135, 4320, 135, 270, 270, 135, 270, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 270, 4320, 270, 4320, 135, 4320, 135, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 270, 270, 135, 270, 4320, 270, 270, 4320, 135, 4320, 4320, 270, 135, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 135, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 4320, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 4320, 270, 135, 135, 135, 135]
Prompts retrieved: 405945 . Total input tokens: 90403984 . Total output tokens: 81246146
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.829163786955178,
    "estimated_duration": 3600.061195155163,
    "input_throughput": 4635.48981402266,
    "output_throughput": 4089.2615991672046,
    "total_throughput": 8724.751413189864,
    "itl": 208.83767387548514,
    "ttft": 1633783.8707048546,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1706,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.221192091149423,
    "arrivals": 135085,
    "finished_requests": 67207,
    "scheduler_time": 86.70199086879376
}
#Debug simulation 
Total elapsed time: 5.829279541037977. Arrivals time: 0.21552714239805937 Scheduler time: 5.5076056737452745 Scheduler overhead time: 0.029208878055214882 Adapter cache time: 0.03431481122970581 Engine time: 0.029252856969833374 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-16/adapters_256_slots_128_rate_0.4-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-16/adapters_256_slots_128_rate_0.4-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 135, 4320, 4320, 135, 4320, 270, 4320, 135, 270, 135, 4320, 270, 270, 270, 270, 4320, 135, 135, 135, 270, 4320, 135, 4320, 4320, 270, 270, 270, 135, 4320, 135, 270, 270, 135, 270, 135, 135, 270, 270, 4320, 270, 135, 270, 4320, 270, 270, 4320, 270, 4320, 135, 4320, 4320, 270, 135, 135, 4320, 270, 135, 270, 270, 4320, 270, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 4320, 4320, 135, 4320, 135, 270, 4320, 4320, 4320, 270, 135, 4320, 270, 135, 135, 135, 135, 135, 4320, 270, 135, 4320, 135, 4320, 135, 135, 270, 270, 4320, 270, 4320, 135, 270, 135, 4320, 4320, 135, 4320, 270, 135, 4320, 135, 135, 4320, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 135, 270, 4320, 4320, 135, 4320, 270, 135, 270, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 270, 4320, 4320, 270, 135, 4320, 135, 270, 270, 135, 270, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 270, 4320, 270, 4320, 135, 4320, 135, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 270, 270, 135, 270, 4320, 270, 270, 4320, 135, 4320, 4320, 270, 135, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 135, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 4320, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 4320, 270, 135, 135, 135, 135]
Prompts retrieved: 405945 . Total input tokens: 90403984 . Total output tokens: 81246146
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.8267183704301715,
    "estimated_duration": 3600.072682739975,
    "input_throughput": 4635.219472096773,
    "output_throughput": 4088.816059345987,
    "total_throughput": 8724.03553144276,
    "itl": 208.85396896522334,
    "ttft": 1633939.374077088,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1706,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.5623299176221295,
    "arrivals": 135085,
    "finished_requests": 67201,
    "scheduler_time": 86.69555128626088
}
#Debug simulation 
Total elapsed time: 5.826810703147203. Arrivals time: 0.21472703153267503 Scheduler time: 5.50651675183326 Scheduler overhead time: 0.029061944223940372 Adapter cache time: 0.034310052171349525 Engine time: 0.028978165239095688 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-32/adapters_256_slots_128_rate_0.4-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-32/adapters_256_slots_128_rate_0.4-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 135, 4320, 4320, 135, 4320, 270, 4320, 135, 270, 135, 4320, 270, 270, 270, 270, 4320, 135, 135, 135, 270, 4320, 135, 4320, 4320, 270, 270, 270, 135, 4320, 135, 270, 270, 135, 270, 135, 135, 270, 270, 4320, 270, 135, 270, 4320, 270, 270, 4320, 270, 4320, 135, 4320, 4320, 270, 135, 135, 4320, 270, 135, 270, 270, 4320, 270, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 4320, 4320, 135, 4320, 135, 270, 4320, 4320, 4320, 270, 135, 4320, 270, 135, 135, 135, 135, 135, 4320, 270, 135, 4320, 135, 4320, 135, 135, 270, 270, 4320, 270, 4320, 135, 270, 135, 4320, 4320, 135, 4320, 270, 135, 4320, 135, 135, 4320, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 135, 270, 4320, 4320, 135, 4320, 270, 135, 270, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 270, 4320, 4320, 270, 135, 4320, 135, 270, 270, 135, 270, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 270, 4320, 270, 4320, 135, 4320, 135, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 270, 270, 135, 270, 4320, 270, 270, 4320, 135, 4320, 4320, 270, 135, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 135, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 4320, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 4320, 270, 135, 135, 135, 135]
Prompts retrieved: 405945 . Total input tokens: 90403984 . Total output tokens: 81246146
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.256617147941142,
    "estimated_duration": 3600.037006436848,
    "input_throughput": 4440.512131241178,
    "output_throughput": 3924.809376886015,
    "total_throughput": 8365.321508127194,
    "itl": 177.12747753136588,
    "ttft": 1684602.2485139016,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2375,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.758510327227371,
    "arrivals": 135085,
    "finished_requests": 64381,
    "scheduler_time": 89.37847168838184
}
#Debug simulation 
Total elapsed time: 5.256703904364258. Arrivals time: 0.20485782250761986 Scheduler time: 4.92371831368655 Scheduler overhead time: 0.032892716117203236 Adapter cache time: 0.046593339182436466 Engine time: 0.03338510822504759 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-16/adapters_256_slots_128_rate_0.4-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-16/adapters_256_slots_128_rate_0.4-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 135, 4320, 4320, 135, 4320, 270, 4320, 135, 270, 135, 4320, 270, 270, 270, 270, 4320, 135, 135, 135, 270, 4320, 135, 4320, 4320, 270, 270, 270, 135, 4320, 135, 270, 270, 135, 270, 135, 135, 270, 270, 4320, 270, 135, 270, 4320, 270, 270, 4320, 270, 4320, 135, 4320, 4320, 270, 135, 135, 4320, 270, 135, 270, 270, 4320, 270, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 4320, 4320, 135, 4320, 135, 270, 4320, 4320, 4320, 270, 135, 4320, 270, 135, 135, 135, 135, 135, 4320, 270, 135, 4320, 135, 4320, 135, 135, 270, 270, 4320, 270, 4320, 135, 270, 135, 4320, 4320, 135, 4320, 270, 135, 4320, 135, 135, 4320, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 135, 270, 4320, 4320, 135, 4320, 270, 135, 270, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 270, 4320, 4320, 270, 135, 4320, 135, 270, 270, 135, 270, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 270, 4320, 270, 4320, 135, 4320, 135, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 270, 270, 135, 270, 4320, 270, 270, 4320, 135, 4320, 4320, 270, 135, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 135, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 4320, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 4320, 270, 135, 135, 135, 135]
Prompts retrieved: 405945 . Total input tokens: 90403984 . Total output tokens: 81246146
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.819377601146698,
    "estimated_duration": 3600.055990687568,
    "input_throughput": 4635.204575474667,
    "output_throughput": 4089.054736392724,
    "total_throughput": 8724.25931186739,
    "itl": 208.85014559094714,
    "ttft": 1633871.218539295,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1698,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.326757140310814,
    "arrivals": 135085,
    "finished_requests": 67203,
    "scheduler_time": 86.69939870671968
}
#Debug simulation 
Total elapsed time: 5.819481698796153. Arrivals time: 0.21485474659129977 Scheduler time: 5.49859926244244 Scheduler overhead time: 0.028959274757653475 Adapter cache time: 0.03463463066145778 Engine time: 0.02917664172127843 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-32/adapters_256_slots_128_rate_0.4-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-32/adapters_256_slots_128_rate_0.4-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 135, 4320, 4320, 135, 4320, 270, 4320, 135, 270, 135, 4320, 270, 270, 270, 270, 4320, 135, 135, 135, 270, 4320, 135, 4320, 4320, 270, 270, 270, 135, 4320, 135, 270, 270, 135, 270, 135, 135, 270, 270, 4320, 270, 135, 270, 4320, 270, 270, 4320, 270, 4320, 135, 4320, 4320, 270, 135, 135, 4320, 270, 135, 270, 270, 4320, 270, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 4320, 4320, 135, 4320, 135, 270, 4320, 4320, 4320, 270, 135, 4320, 270, 135, 135, 135, 135, 135, 4320, 270, 135, 4320, 135, 4320, 135, 135, 270, 270, 4320, 270, 4320, 135, 270, 135, 4320, 4320, 135, 4320, 270, 135, 4320, 135, 135, 4320, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 135, 270, 4320, 4320, 135, 4320, 270, 135, 270, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 270, 4320, 4320, 270, 135, 4320, 135, 270, 270, 135, 270, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 270, 4320, 270, 4320, 135, 4320, 135, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 270, 270, 135, 270, 4320, 270, 270, 4320, 135, 4320, 4320, 270, 135, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 135, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 4320, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 4320, 270, 135, 135, 135, 135]
Prompts retrieved: 405945 . Total input tokens: 90403984 . Total output tokens: 81246146
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 5.286028360016644,
    "estimated_duration": 3600.0682837972886,
    "input_throughput": 4440.86354471498,
    "output_throughput": 3924.9166643850317,
    "total_throughput": 8365.780209100012,
    "itl": 177.1252865573169,
    "ttft": 1684704.6001091993,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2370,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.832657949067485,
    "arrivals": 135085,
    "finished_requests": 64387,
    "scheduler_time": 89.37891472939204
}
#Debug simulation 
Total elapsed time: 5.286147597711533. Arrivals time: 0.21091777132824063 Scheduler time: 4.945629148744047 Scheduler overhead time: 0.03314941423013806 Adapter cache time: 0.04726048232987523 Engine time: 0.033708726055920124 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-16/adapters_256_slots_128_rate_0.4-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-16/adapters_256_slots_128_rate_0.4-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 135, 4320, 4320, 135, 4320, 270, 4320, 135, 270, 135, 4320, 270, 270, 270, 270, 4320, 135, 135, 135, 270, 4320, 135, 4320, 4320, 270, 270, 270, 135, 4320, 135, 270, 270, 135, 270, 135, 135, 270, 270, 4320, 270, 135, 270, 4320, 270, 270, 4320, 270, 4320, 135, 4320, 4320, 270, 135, 135, 4320, 270, 135, 270, 270, 4320, 270, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 4320, 4320, 135, 4320, 135, 270, 4320, 4320, 4320, 270, 135, 4320, 270, 135, 135, 135, 135, 135, 4320, 270, 135, 4320, 135, 4320, 135, 135, 270, 270, 4320, 270, 4320, 135, 270, 135, 4320, 4320, 135, 4320, 270, 135, 4320, 135, 135, 4320, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 135, 270, 4320, 4320, 135, 4320, 270, 135, 270, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 270, 4320, 4320, 270, 135, 4320, 135, 270, 270, 135, 270, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 270, 4320, 270, 4320, 135, 4320, 135, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 270, 270, 135, 270, 4320, 270, 270, 4320, 135, 4320, 4320, 270, 135, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 135, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 4320, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 4320, 270, 135, 135, 135, 135]
Prompts retrieved: 405945 . Total input tokens: 90403984 . Total output tokens: 81246146
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.83197734085843,
    "estimated_duration": 3600.108461108586,
    "input_throughput": 4635.9703270885975,
    "output_throughput": 4089.667063937916,
    "total_throughput": 8725.637391026514,
    "itl": 208.8339521994195,
    "ttft": 1633835.2186300165,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1698,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.077105400743751,
    "arrivals": 135085,
    "finished_requests": 67207,
    "scheduler_time": 86.70614221820145
}
#Debug simulation 
Total elapsed time: 5.832062900066376. Arrivals time: 0.2149651413783431 Scheduler time: 5.511475144419819 Scheduler overhead time: 0.02908811718225479 Adapter cache time: 0.03439099434763193 Engine time: 0.028946951031684875 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-32/adapters_256_slots_128_rate_0.4-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-32/adapters_256_slots_128_rate_0.4-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 135, 4320, 4320, 135, 4320, 270, 4320, 135, 270, 135, 4320, 270, 270, 270, 270, 4320, 135, 135, 135, 270, 4320, 135, 4320, 4320, 270, 270, 270, 135, 4320, 135, 270, 270, 135, 270, 135, 135, 270, 270, 4320, 270, 135, 270, 4320, 270, 270, 4320, 270, 4320, 135, 4320, 4320, 270, 135, 135, 4320, 270, 135, 270, 270, 4320, 270, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 4320, 4320, 135, 4320, 135, 270, 4320, 4320, 4320, 270, 135, 4320, 270, 135, 135, 135, 135, 135, 4320, 270, 135, 4320, 135, 4320, 135, 135, 270, 270, 4320, 270, 4320, 135, 270, 135, 4320, 4320, 135, 4320, 270, 135, 4320, 135, 135, 4320, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 135, 270, 4320, 4320, 135, 4320, 270, 135, 270, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 270, 4320, 4320, 270, 135, 4320, 135, 270, 270, 135, 270, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 270, 4320, 270, 4320, 135, 4320, 135, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 270, 270, 135, 270, 4320, 270, 270, 4320, 135, 4320, 4320, 270, 135, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 135, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 4320, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 4320, 270, 135, 135, 135, 135]
Prompts retrieved: 405945 . Total input tokens: 90403984 . Total output tokens: 81246146
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.307555986568332,
    "estimated_duration": 3600.044693677212,
    "input_throughput": 4440.79542347855,
    "output_throughput": 3924.67960878789,
    "total_throughput": 8365.47503226644,
    "itl": 177.1344469378733,
    "ttft": 1684846.723493411,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2378,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.966251838579443,
    "arrivals": 135085,
    "finished_requests": 64384,
    "scheduler_time": 89.37440787704686
}
#Debug simulation 
Total elapsed time: 5.307644854765385. Arrivals time: 0.20679688220843673 Scheduler time: 4.9717412535101175 Scheduler overhead time: 0.03301942301914096 Adapter cache time: 0.047511547803878784 Engine time: 0.03327532997354865 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_256_slots_128_rate_0.4-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_256_slots_128_rate_0.4-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 66, 4320, 4320, 66, 4320, 270, 4320, 66, 270, 66, 4320, 270, 270, 270, 270, 4320, 66, 66, 66, 270, 4320, 66, 4320, 4320, 270, 270, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 66, 270, 270, 4320, 270, 66, 270, 4320, 270, 270, 4320, 270, 4320, 66, 4320, 4320, 270, 66, 66, 4320, 270, 66, 270, 270, 4320, 270, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 4320, 4320, 66, 4320, 66, 270, 4320, 4320, 4320, 270, 66, 4320, 270, 66, 66, 66, 66, 66, 4320, 270, 66, 4320, 66, 4320, 66, 66, 270, 270, 4320, 270, 4320, 66, 270, 66, 4320, 4320, 66, 4320, 270, 66, 4320, 66, 66, 4320, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 66, 270, 4320, 4320, 66, 4320, 270, 66, 270, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 270, 4320, 4320, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 270, 4320, 270, 4320, 66, 4320, 66, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 270, 270, 66, 270, 4320, 270, 270, 4320, 66, 4320, 4320, 270, 66, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 66, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 4320, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 4320, 270, 66, 66, 66, 66]
Prompts retrieved: 400080 . Total input tokens: 89083538 . Total output tokens: 80076302
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.439197591971606,
    "estimated_duration": 3600.153123264627,
    "input_throughput": 4664.943802382132,
    "output_throughput": 4091.0637674889235,
    "total_throughput": 8756.007569871055,
    "itl": 208.38268559539446,
    "ttft": 1611574.216985598,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1779,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.444607696456522,
    "arrivals": 133166,
    "finished_requests": 67824,
    "scheduler_time": 86.35886491373032
}
#Debug simulation 
Total elapsed time: 5.439281854312867. Arrivals time: 0.21316860988736153 Scheduler time: 5.119491063524038 Scheduler overhead time: 0.028795309364795685 Adapter cache time: 0.03555872058495879 Engine time: 0.028970714192837477 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_256_slots_128_rate_0.4-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_256_slots_128_rate_0.4-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 66, 4320, 4320, 66, 4320, 270, 4320, 66, 270, 66, 4320, 270, 270, 270, 270, 4320, 66, 66, 66, 270, 4320, 66, 4320, 4320, 270, 270, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 66, 270, 270, 4320, 270, 66, 270, 4320, 270, 270, 4320, 270, 4320, 66, 4320, 4320, 270, 66, 66, 4320, 270, 66, 270, 270, 4320, 270, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 4320, 4320, 66, 4320, 66, 270, 4320, 4320, 4320, 270, 66, 4320, 270, 66, 66, 66, 66, 66, 4320, 270, 66, 4320, 66, 4320, 66, 66, 270, 270, 4320, 270, 4320, 66, 270, 66, 4320, 4320, 66, 4320, 270, 66, 4320, 66, 66, 4320, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 66, 270, 4320, 4320, 66, 4320, 270, 66, 270, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 270, 4320, 4320, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 270, 4320, 270, 4320, 66, 4320, 66, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 270, 270, 66, 270, 4320, 270, 270, 4320, 66, 4320, 4320, 270, 66, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 66, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 4320, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 4320, 270, 66, 66, 66, 66]
Prompts retrieved: 400080 . Total input tokens: 89083538 . Total output tokens: 80076302
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.4511930528096855,
    "estimated_duration": 3600.1462568384954,
    "input_throughput": 4664.690488087959,
    "output_throughput": 4090.7818597717264,
    "total_throughput": 8755.472347859686,
    "itl": 208.4011259787714,
    "ttft": 1611649.016512765,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1770,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.7724885211441075,
    "arrivals": 133166,
    "finished_requests": 67822,
    "scheduler_time": 86.35242363305224
}
#Debug simulation 
Total elapsed time: 5.451314935926348. Arrivals time: 0.2177843451499939 Scheduler time: 5.126646788325161 Scheduler overhead time: 0.028873091097921133 Adapter cache time: 0.035465468652546406 Engine time: 0.029150790069252253 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-32/adapters_256_slots_128_rate_0.4-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-32/adapters_256_slots_128_rate_0.4-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 66, 4320, 4320, 66, 4320, 270, 4320, 66, 270, 66, 4320, 270, 270, 270, 270, 4320, 66, 66, 66, 270, 4320, 66, 4320, 4320, 270, 270, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 66, 270, 270, 4320, 270, 66, 270, 4320, 270, 270, 4320, 270, 4320, 66, 4320, 4320, 270, 66, 66, 4320, 270, 66, 270, 270, 4320, 270, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 4320, 4320, 66, 4320, 66, 270, 4320, 4320, 4320, 270, 66, 4320, 270, 66, 66, 66, 66, 66, 4320, 270, 66, 4320, 66, 4320, 66, 66, 270, 270, 4320, 270, 4320, 66, 270, 66, 4320, 4320, 66, 4320, 270, 66, 4320, 66, 66, 4320, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 66, 270, 4320, 4320, 66, 4320, 270, 66, 270, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 270, 4320, 4320, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 270, 4320, 270, 4320, 66, 4320, 66, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 270, 270, 66, 270, 4320, 270, 270, 4320, 66, 4320, 4320, 270, 66, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 66, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 4320, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 4320, 270, 66, 66, 66, 66]
Prompts retrieved: 400080 . Total input tokens: 89083538 . Total output tokens: 80076302
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.021297095809132,
    "estimated_duration": 3600.1524047610305,
    "input_throughput": 4469.163577275833,
    "output_throughput": 3926.052125267793,
    "total_throughput": 8395.215702543626,
    "itl": 177.0958231608179,
    "ttft": 1662881.78293725,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2561,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.376540947258361,
    "arrivals": 133166,
    "finished_requests": 64969,
    "scheduler_time": 89.01443434592744
}
#Debug simulation 
Total elapsed time: 5.021380370017141. Arrivals time: 0.20766785833984613 Scheduler time: 4.682964031584561 Scheduler overhead time: 0.032783081755042076 Adapter cache time: 0.04958015540614724 Engine time: 0.03305230522528291 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_256_slots_128_rate_0.4-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_256_slots_128_rate_0.4-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 66, 4320, 4320, 66, 4320, 270, 4320, 66, 270, 66, 4320, 270, 270, 270, 270, 4320, 66, 66, 66, 270, 4320, 66, 4320, 4320, 270, 270, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 66, 270, 270, 4320, 270, 66, 270, 4320, 270, 270, 4320, 270, 4320, 66, 4320, 4320, 270, 66, 66, 4320, 270, 66, 270, 270, 4320, 270, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 4320, 4320, 66, 4320, 66, 270, 4320, 4320, 4320, 270, 66, 4320, 270, 66, 66, 66, 66, 66, 4320, 270, 66, 4320, 66, 4320, 66, 66, 270, 270, 4320, 270, 4320, 66, 270, 66, 4320, 4320, 66, 4320, 270, 66, 4320, 66, 66, 4320, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 66, 270, 4320, 4320, 66, 4320, 270, 66, 270, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 270, 4320, 4320, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 270, 4320, 270, 4320, 66, 4320, 66, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 270, 270, 66, 270, 4320, 270, 270, 4320, 66, 4320, 4320, 270, 66, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 66, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 4320, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 4320, 270, 66, 66, 66, 66]
Prompts retrieved: 400080 . Total input tokens: 89083538 . Total output tokens: 80076302
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.460683258250356,
    "estimated_duration": 3600.06466134571,
    "input_throughput": 4664.926488770999,
    "output_throughput": 4090.9584647556735,
    "total_throughput": 8755.884953526673,
    "itl": 208.3889578654989,
    "ttft": 1611602.7610399562,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1778,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.579853404729945,
    "arrivals": 133166,
    "finished_requests": 67823,
    "scheduler_time": 86.35371573001511
}
#Debug simulation 
Total elapsed time: 5.460769980214536. Arrivals time: 0.21680066920816898 Scheduler time: 5.138017601333559 Scheduler overhead time: 0.028579710982739925 Adapter cache time: 0.03525785868987441 Engine time: 0.028945760801434517 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-32/adapters_256_slots_128_rate_0.4-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-32/adapters_256_slots_128_rate_0.4-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 66, 4320, 4320, 66, 4320, 270, 4320, 66, 270, 66, 4320, 270, 270, 270, 270, 4320, 66, 66, 66, 270, 4320, 66, 4320, 4320, 270, 270, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 66, 270, 270, 4320, 270, 66, 270, 4320, 270, 270, 4320, 270, 4320, 66, 4320, 4320, 270, 66, 66, 4320, 270, 66, 270, 270, 4320, 270, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 4320, 4320, 66, 4320, 66, 270, 4320, 4320, 4320, 270, 66, 4320, 270, 66, 66, 66, 66, 66, 4320, 270, 66, 4320, 66, 4320, 66, 66, 270, 270, 4320, 270, 4320, 66, 270, 66, 4320, 4320, 66, 4320, 270, 66, 4320, 66, 66, 4320, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 66, 270, 4320, 4320, 66, 4320, 270, 66, 270, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 270, 4320, 4320, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 270, 4320, 270, 4320, 66, 4320, 66, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 270, 270, 66, 270, 4320, 270, 270, 4320, 66, 4320, 4320, 270, 66, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 66, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 4320, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 4320, 270, 66, 66, 66, 66]
Prompts retrieved: 400080 . Total input tokens: 89083538 . Total output tokens: 80076302
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 5.01985304011032,
    "estimated_duration": 3600.114360755318,
    "input_throughput": 4469.214971444496,
    "output_throughput": 3926.1211127289107,
    "total_throughput": 8395.336084173407,
    "itl": 177.10032141403647,
    "ttft": 1662943.6773940139,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2571,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.505784310195343,
    "arrivals": 133166,
    "finished_requests": 64969,
    "scheduler_time": 89.00995139945425
}
#Debug simulation 
Total elapsed time: 5.019939368125051. Arrivals time: 0.20632151467725635 Scheduler time: 4.683088436257094 Scheduler overhead time: 0.032678873278200626 Adapter cache time: 0.049340867437422276 Engine time: 0.03326364094391465 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_256_slots_128_rate_0.4-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_256_slots_128_rate_0.4-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 66, 4320, 4320, 66, 4320, 270, 4320, 66, 270, 66, 4320, 270, 270, 270, 270, 4320, 66, 66, 66, 270, 4320, 66, 4320, 4320, 270, 270, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 66, 270, 270, 4320, 270, 66, 270, 4320, 270, 270, 4320, 270, 4320, 66, 4320, 4320, 270, 66, 66, 4320, 270, 66, 270, 270, 4320, 270, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 4320, 4320, 66, 4320, 66, 270, 4320, 4320, 4320, 270, 66, 4320, 270, 66, 66, 66, 66, 66, 4320, 270, 66, 4320, 66, 4320, 66, 66, 270, 270, 4320, 270, 4320, 66, 270, 66, 4320, 4320, 66, 4320, 270, 66, 4320, 66, 66, 4320, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 66, 270, 4320, 4320, 66, 4320, 270, 66, 270, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 270, 4320, 4320, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 270, 4320, 270, 4320, 66, 4320, 66, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 270, 270, 66, 270, 4320, 270, 270, 4320, 66, 4320, 4320, 270, 66, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 66, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 4320, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 4320, 270, 66, 66, 66, 66]
Prompts retrieved: 400080 . Total input tokens: 89083538 . Total output tokens: 80076302
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.442449359688908,
    "estimated_duration": 3600.1969362816426,
    "input_throughput": 4665.153406120808,
    "output_throughput": 4091.051200996796,
    "total_throughput": 8756.204607117603,
    "itl": 208.37119769959685,
    "ttft": 1611558.3602174995,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1779,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.319299474630818,
    "arrivals": 133166,
    "finished_requests": 67827,
    "scheduler_time": 86.36262704186765
}
#Debug simulation 
Total elapsed time: 5.442567788995802. Arrivals time: 0.21430589305236936 Scheduler time: 5.121701076161116 Scheduler overhead time: 0.028760674875229597 Adapter cache time: 0.035138639621436596 Engine time: 0.02936209039762616 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-32/adapters_256_slots_128_rate_0.4-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-32/adapters_256_slots_128_rate_0.4-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 66, 4320, 4320, 66, 4320, 270, 4320, 66, 270, 66, 4320, 270, 270, 270, 270, 4320, 66, 66, 66, 270, 4320, 66, 4320, 4320, 270, 270, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 66, 270, 270, 4320, 270, 66, 270, 4320, 270, 270, 4320, 270, 4320, 66, 4320, 4320, 270, 66, 66, 4320, 270, 66, 270, 270, 4320, 270, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 4320, 4320, 66, 4320, 66, 270, 4320, 4320, 4320, 270, 66, 4320, 270, 66, 66, 66, 66, 66, 4320, 270, 66, 4320, 66, 4320, 66, 66, 270, 270, 4320, 270, 4320, 66, 270, 66, 4320, 4320, 66, 4320, 270, 66, 4320, 66, 66, 4320, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 66, 270, 4320, 4320, 66, 4320, 270, 66, 270, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 270, 4320, 4320, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 270, 4320, 270, 4320, 66, 4320, 66, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 270, 270, 66, 270, 4320, 270, 270, 4320, 66, 4320, 4320, 270, 66, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 66, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 4320, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 4320, 270, 66, 66, 66, 66]
Prompts retrieved: 400080 . Total input tokens: 89083538 . Total output tokens: 80076302
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.020383371971548,
    "estimated_duration": 3600.1189958316963,
    "input_throughput": 4470.068355693965,
    "output_throughput": 3926.857700083896,
    "total_throughput": 8396.926055777862,
    "itl": 177.33257451715448,
    "ttft": 1662676.391586091,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2558,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.583535423501935,
    "arrivals": 133166,
    "finished_requests": 64979,
    "scheduler_time": 88.98587851652414
}
#Debug simulation 
Total elapsed time: 5.020473293028772. Arrivals time: 0.20654413709416986 Scheduler time: 4.683182685635984 Scheduler overhead time: 0.032605032436549664 Adapter cache time: 0.049861435778439045 Engine time: 0.03303998848423362 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_256_slots_128_rate_0.4-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_256_slots_128_rate_0.4-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 33, 4320, 4320, 33, 4320, 270, 4320, 33, 270, 33, 4320, 270, 270, 270, 270, 4320, 33, 33, 33, 270, 4320, 33, 4320, 4320, 270, 270, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 33, 270, 270, 4320, 270, 33, 270, 4320, 270, 270, 4320, 270, 4320, 33, 4320, 4320, 270, 33, 33, 4320, 270, 33, 270, 270, 4320, 270, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 4320, 4320, 33, 4320, 33, 270, 4320, 4320, 4320, 270, 33, 4320, 270, 33, 33, 33, 33, 33, 4320, 270, 33, 4320, 33, 4320, 33, 33, 270, 270, 4320, 270, 4320, 33, 270, 33, 4320, 4320, 33, 4320, 270, 33, 4320, 33, 33, 4320, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 33, 270, 4320, 4320, 33, 4320, 270, 33, 270, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 270, 4320, 4320, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 270, 4320, 270, 4320, 33, 4320, 33, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 270, 270, 33, 270, 4320, 270, 270, 4320, 33, 4320, 4320, 270, 33, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 33, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 4320, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 4320, 270, 33, 33, 33, 33]
Prompts retrieved: 397275 . Total input tokens: 88477227 . Total output tokens: 79493181
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.223546234890819,
    "estimated_duration": 3600.0209139932113,
    "input_throughput": 4632.590031678757,
    "output_throughput": 4094.239270307693,
    "total_throughput": 8726.82930198645,
    "itl": 208.8800267254059,
    "ttft": 1611895.131016846,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2003,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.130156951097483,
    "arrivals": 132222,
    "finished_requests": 67534,
    "scheduler_time": 86.25758659520109
}
#Debug simulation 
Total elapsed time: 5.223635157570243. Arrivals time: 0.209985735360533 Scheduler time: 4.904703262727708 Scheduler overhead time: 0.028487178031355143 Adapter cache time: 0.03839460061863065 Engine time: 0.028899329714477062 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_256_slots_128_rate_0.4-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_256_slots_128_rate_0.4-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 33, 4320, 4320, 33, 4320, 270, 4320, 33, 270, 33, 4320, 270, 270, 270, 270, 4320, 33, 33, 33, 270, 4320, 33, 4320, 4320, 270, 270, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 33, 270, 270, 4320, 270, 33, 270, 4320, 270, 270, 4320, 270, 4320, 33, 4320, 4320, 270, 33, 33, 4320, 270, 33, 270, 270, 4320, 270, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 4320, 4320, 33, 4320, 33, 270, 4320, 4320, 4320, 270, 33, 4320, 270, 33, 33, 33, 33, 33, 4320, 270, 33, 4320, 33, 4320, 33, 33, 270, 270, 4320, 270, 4320, 33, 270, 33, 4320, 4320, 33, 4320, 270, 33, 4320, 33, 33, 4320, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 33, 270, 4320, 4320, 33, 4320, 270, 33, 270, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 270, 4320, 4320, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 270, 4320, 270, 4320, 33, 4320, 33, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 270, 270, 33, 270, 4320, 270, 270, 4320, 33, 4320, 4320, 270, 33, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 33, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 4320, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 4320, 270, 33, 33, 33, 33]
Prompts retrieved: 397275 . Total input tokens: 88477227 . Total output tokens: 79493181
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.226454979740083,
    "estimated_duration": 3600.062072254316,
    "input_throughput": 4632.094020967199,
    "output_throughput": 4093.5269182100233,
    "total_throughput": 8725.620939177223,
    "itl": 208.90230208354527,
    "ttft": 1612028.0322123363,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2003,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.530050942303855,
    "arrivals": 132222,
    "finished_requests": 67527,
    "scheduler_time": 86.25042183667121
}
#Debug simulation 
Total elapsed time: 5.226539899595082. Arrivals time: 0.2159600700251758 Scheduler time: 4.901356844231486 Scheduler overhead time: 0.02845013700425625 Adapter cache time: 0.03882471192628145 Engine time: 0.028755619190633297 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-32/adapters_256_slots_128_rate_0.4-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-32/adapters_256_slots_128_rate_0.4-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 33, 4320, 4320, 33, 4320, 270, 4320, 33, 270, 33, 4320, 270, 270, 270, 270, 4320, 33, 33, 33, 270, 4320, 33, 4320, 4320, 270, 270, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 33, 270, 270, 4320, 270, 33, 270, 4320, 270, 270, 4320, 270, 4320, 33, 4320, 4320, 270, 33, 33, 4320, 270, 33, 270, 270, 4320, 270, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 4320, 4320, 33, 4320, 33, 270, 4320, 4320, 4320, 270, 33, 4320, 270, 33, 33, 33, 33, 33, 4320, 270, 33, 4320, 33, 4320, 33, 33, 270, 270, 4320, 270, 4320, 33, 270, 33, 4320, 4320, 33, 4320, 270, 33, 4320, 33, 33, 4320, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 33, 270, 4320, 4320, 33, 4320, 270, 33, 270, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 270, 4320, 4320, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 270, 4320, 270, 4320, 33, 4320, 33, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 270, 270, 33, 270, 4320, 270, 270, 4320, 33, 4320, 4320, 270, 33, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 33, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 4320, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 4320, 270, 33, 33, 33, 33]
Prompts retrieved: 397275 . Total input tokens: 88477227 . Total output tokens: 79493181
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.9500904232263565,
    "estimated_duration": 3600.0078789085733,
    "input_throughput": 4472.197989989143,
    "output_throughput": 3956.3418967621974,
    "total_throughput": 8428.539886751341,
    "itl": 176.43810069439402,
    "ttft": 1654838.5254419062,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2673,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.72888147313131,
    "arrivals": 132222,
    "finished_requests": 65212,
    "scheduler_time": 89.35550230319389
}
#Debug simulation 
Total elapsed time: 4.9501748462207615. Arrivals time: 0.2063986686989665 Scheduler time: 4.610789523925632 Scheduler overhead time: 0.03226361609995365 Adapter cache time: 0.05253031384199858 Engine time: 0.03300778940320015 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_256_slots_128_rate_0.4-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_256_slots_128_rate_0.4-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 33, 4320, 4320, 33, 4320, 270, 4320, 33, 270, 33, 4320, 270, 270, 270, 270, 4320, 33, 33, 33, 270, 4320, 33, 4320, 4320, 270, 270, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 33, 270, 270, 4320, 270, 33, 270, 4320, 270, 270, 4320, 270, 4320, 33, 4320, 4320, 270, 33, 33, 4320, 270, 33, 270, 270, 4320, 270, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 4320, 4320, 33, 4320, 33, 270, 4320, 4320, 4320, 270, 33, 4320, 270, 33, 33, 33, 33, 33, 4320, 270, 33, 4320, 33, 4320, 33, 33, 270, 270, 4320, 270, 4320, 33, 270, 33, 4320, 4320, 33, 4320, 270, 33, 4320, 33, 33, 4320, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 33, 270, 4320, 4320, 33, 4320, 270, 33, 270, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 270, 4320, 4320, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 270, 4320, 270, 4320, 33, 4320, 33, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 270, 270, 33, 270, 4320, 270, 270, 4320, 33, 4320, 4320, 270, 33, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 33, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 4320, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 4320, 270, 33, 33, 33, 33]
Prompts retrieved: 397275 . Total input tokens: 88477227 . Total output tokens: 79493181
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.206591152120382,
    "estimated_duration": 3600.190540736967,
    "input_throughput": 4632.382872875969,
    "output_throughput": 4094.0469214673353,
    "total_throughput": 8726.429794343305,
    "itl": 208.88685930142282,
    "ttft": 1611955.641857646,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2003,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.293474252926924,
    "arrivals": 132222,
    "finished_requests": 67535,
    "scheduler_time": 86.258615214897
}
#Debug simulation 
Total elapsed time: 5.20666784606874. Arrivals time: 0.2078339927829802 Scheduler time: 4.890070511028171 Scheduler overhead time: 0.028574276249855757 Adapter cache time: 0.03805425204336643 Engine time: 0.028980319388210773 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-32/adapters_256_slots_128_rate_0.4-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-32/adapters_256_slots_128_rate_0.4-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 33, 4320, 4320, 33, 4320, 270, 4320, 33, 270, 33, 4320, 270, 270, 270, 270, 4320, 33, 33, 33, 270, 4320, 33, 4320, 4320, 270, 270, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 33, 270, 270, 4320, 270, 33, 270, 4320, 270, 270, 4320, 270, 4320, 33, 4320, 4320, 270, 33, 33, 4320, 270, 33, 270, 270, 4320, 270, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 4320, 4320, 33, 4320, 33, 270, 4320, 4320, 4320, 270, 33, 4320, 270, 33, 33, 33, 33, 33, 4320, 270, 33, 4320, 33, 4320, 33, 33, 270, 270, 4320, 270, 4320, 33, 270, 33, 4320, 4320, 33, 4320, 270, 33, 4320, 33, 33, 4320, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 33, 270, 4320, 4320, 33, 4320, 270, 33, 270, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 270, 4320, 4320, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 270, 4320, 270, 4320, 33, 4320, 33, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 270, 270, 33, 270, 4320, 270, 270, 4320, 33, 4320, 4320, 270, 33, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 33, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 4320, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 4320, 270, 33, 33, 33, 33]
Prompts retrieved: 397275 . Total input tokens: 88477227 . Total output tokens: 79493181
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 4.924428079742938,
    "estimated_duration": 3600.0792565069823,
    "input_throughput": 4472.193763762149,
    "output_throughput": 3956.297066031656,
    "total_throughput": 8428.490829793805,
    "itl": 176.45108157347275,
    "ttft": 1654904.418490599,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2672,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.822674082014423,
    "arrivals": 132222,
    "finished_requests": 65214,
    "scheduler_time": 89.35489858969362
}
#Debug simulation 
Total elapsed time: 4.924536816775799. Arrivals time: 0.20290659461170435 Scheduler time: 4.589599414262921 Scheduler overhead time: 0.03196803713217378 Adapter cache time: 0.05213547358289361 Engine time: 0.032900681253522635 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_256_slots_128_rate_0.4-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_256_slots_128_rate_0.4-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 33, 4320, 4320, 33, 4320, 270, 4320, 33, 270, 33, 4320, 270, 270, 270, 270, 4320, 33, 33, 33, 270, 4320, 33, 4320, 4320, 270, 270, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 33, 270, 270, 4320, 270, 33, 270, 4320, 270, 270, 4320, 270, 4320, 33, 4320, 4320, 270, 33, 33, 4320, 270, 33, 270, 270, 4320, 270, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 4320, 4320, 33, 4320, 33, 270, 4320, 4320, 4320, 270, 33, 4320, 270, 33, 33, 33, 33, 33, 4320, 270, 33, 4320, 33, 4320, 33, 33, 270, 270, 4320, 270, 4320, 33, 270, 33, 4320, 4320, 33, 4320, 270, 33, 4320, 33, 33, 4320, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 33, 270, 4320, 4320, 33, 4320, 270, 33, 270, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 270, 4320, 4320, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 270, 4320, 270, 4320, 33, 4320, 33, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 270, 270, 33, 270, 4320, 270, 270, 4320, 33, 4320, 4320, 270, 33, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 33, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 4320, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 4320, 270, 33, 33, 33, 33]
Prompts retrieved: 397275 . Total input tokens: 88477227 . Total output tokens: 79493181
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.2336099171079695,
    "estimated_duration": 3600.0104166098477,
    "input_throughput": 4632.764095084418,
    "output_throughput": 4094.399263955641,
    "total_throughput": 8727.16335904006,
    "itl": 208.86907488631303,
    "ttft": 1611846.9451096067,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2004,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.992060790983784,
    "arrivals": 132222,
    "finished_requests": 67537,
    "scheduler_time": 86.26003673379536
}
#Debug simulation 
Total elapsed time: 5.233708396088332. Arrivals time: 0.22012902004644275 Scheduler time: 4.904668668285012 Scheduler overhead time: 0.02853918308392167 Adapter cache time: 0.03832359379157424 Engine time: 0.02883117739111185 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-32/adapters_256_slots_128_rate_0.4-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-32/adapters_256_slots_128_rate_0.4-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 33, 4320, 4320, 33, 4320, 270, 4320, 33, 270, 33, 4320, 270, 270, 270, 270, 4320, 33, 33, 33, 270, 4320, 33, 4320, 4320, 270, 270, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 33, 270, 270, 4320, 270, 33, 270, 4320, 270, 270, 4320, 270, 4320, 33, 4320, 4320, 270, 33, 33, 4320, 270, 33, 270, 270, 4320, 270, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 4320, 4320, 33, 4320, 33, 270, 4320, 4320, 4320, 270, 33, 4320, 270, 33, 33, 33, 33, 33, 4320, 270, 33, 4320, 33, 4320, 33, 33, 270, 270, 4320, 270, 4320, 33, 270, 33, 4320, 4320, 33, 4320, 270, 33, 4320, 33, 33, 4320, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 33, 270, 4320, 4320, 33, 4320, 270, 33, 270, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 270, 4320, 4320, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 270, 4320, 270, 4320, 33, 4320, 33, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 270, 270, 33, 270, 4320, 270, 270, 4320, 33, 4320, 4320, 270, 33, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 33, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 4320, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 4320, 270, 33, 33, 33, 33]
Prompts retrieved: 397275 . Total input tokens: 88477227 . Total output tokens: 79493181
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.957751363981515,
    "estimated_duration": 3600.1961439516426,
    "input_throughput": 4471.905795201655,
    "output_throughput": 3955.9716833559555,
    "total_throughput": 8427.87747855761,
    "itl": 176.44507014864476,
    "ttft": 1654923.2203822844,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2677,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.964697219021188,
    "arrivals": 132222,
    "finished_requests": 65211,
    "scheduler_time": 89.3557299489482
}
#Debug simulation 
Total elapsed time: 4.957832949236035. Arrivals time: 0.20750520611181855 Scheduler time: 4.617278938181698 Scheduler overhead time: 0.032328165136277676 Adapter cache time: 0.052301399409770966 Engine time: 0.03321754653006792 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_256_slots_128_rate_0.4-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_256_slots_128_rate_0.4-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 66, 4320, 4320, 66, 4320, 135, 4320, 66, 135, 66, 4320, 135, 135, 135, 135, 4320, 66, 66, 66, 135, 4320, 66, 4320, 4320, 135, 135, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 66, 135, 135, 4320, 135, 66, 135, 4320, 135, 135, 4320, 135, 4320, 66, 4320, 4320, 135, 66, 66, 4320, 135, 66, 135, 135, 4320, 135, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 4320, 4320, 66, 4320, 66, 135, 4320, 4320, 4320, 135, 66, 4320, 135, 66, 66, 66, 66, 66, 4320, 135, 66, 4320, 66, 4320, 66, 66, 135, 135, 4320, 135, 4320, 66, 135, 66, 4320, 4320, 66, 4320, 135, 66, 4320, 66, 66, 4320, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 66, 135, 4320, 4320, 66, 4320, 135, 66, 135, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 135, 4320, 4320, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 135, 4320, 135, 4320, 66, 4320, 66, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 135, 135, 66, 135, 4320, 135, 135, 4320, 66, 4320, 4320, 135, 66, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 66, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 4320, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 4320, 135, 66, 66, 66, 66]
Prompts retrieved: 388605 . Total input tokens: 86555962 . Total output tokens: 77766423
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.137385547161102,
    "estimated_duration": 3600.0078585877636,
    "input_throughput": 4767.721259012237,
    "output_throughput": 4167.655624475697,
    "total_throughput": 8935.376883487934,
    "itl": 203.69231601987372,
    "ttft": 1570504.6428725629,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2365,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.238053514401178,
    "arrivals": 129353,
    "finished_requests": 68986,
    "scheduler_time": 87.31135380884697
}
#Debug simulation 
Total elapsed time: 5.137461313046515. Arrivals time: 0.2106418921612203 Scheduler time: 4.810938351787627 Scheduler overhead time: 0.028320884332060814 Adapter cache time: 0.045481760054826736 Engine time: 0.028948064893484116 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_256_slots_128_rate_0.4-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_256_slots_128_rate_0.4-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 66, 4320, 4320, 66, 4320, 135, 4320, 66, 135, 66, 4320, 135, 135, 135, 135, 4320, 66, 66, 66, 135, 4320, 66, 4320, 4320, 135, 135, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 66, 135, 135, 4320, 135, 66, 135, 4320, 135, 135, 4320, 135, 4320, 66, 4320, 4320, 135, 66, 66, 4320, 135, 66, 135, 135, 4320, 135, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 4320, 4320, 66, 4320, 66, 135, 4320, 4320, 4320, 135, 66, 4320, 135, 66, 66, 66, 66, 66, 4320, 135, 66, 4320, 66, 4320, 66, 66, 135, 135, 4320, 135, 4320, 66, 135, 66, 4320, 4320, 66, 4320, 135, 66, 4320, 66, 66, 4320, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 66, 135, 4320, 4320, 66, 4320, 135, 66, 135, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 135, 4320, 4320, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 135, 4320, 135, 4320, 66, 4320, 66, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 135, 135, 66, 135, 4320, 135, 135, 4320, 66, 4320, 4320, 135, 66, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 66, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 4320, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 4320, 135, 66, 66, 66, 66]
Prompts retrieved: 388605 . Total input tokens: 86555962 . Total output tokens: 77766423
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.14440550794825,
    "estimated_duration": 3600.2090823704452,
    "input_throughput": 4767.172574516055,
    "output_throughput": 4167.107425361557,
    "total_throughput": 8934.279999877612,
    "itl": 203.71882578180836,
    "ttft": 1570703.194663717,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2364,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.709156356462877,
    "arrivals": 129353,
    "finished_requests": 68982,
    "scheduler_time": 87.30735317792455
}
#Debug simulation 
Total elapsed time: 5.144479098729789. Arrivals time: 0.2114894250407815 Scheduler time: 4.816932196263224 Scheduler overhead time: 0.02837125863879919 Adapter cache time: 0.04525915486738086 Engine time: 0.029240312986075878 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-32/adapters_256_slots_128_rate_0.4-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-32/adapters_256_slots_128_rate_0.4-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 66, 4320, 4320, 66, 4320, 135, 4320, 66, 135, 66, 4320, 135, 135, 135, 135, 4320, 66, 66, 66, 135, 4320, 66, 4320, 4320, 135, 135, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 66, 135, 135, 4320, 135, 66, 135, 4320, 135, 135, 4320, 135, 4320, 66, 4320, 4320, 135, 66, 66, 4320, 135, 66, 135, 135, 4320, 135, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 4320, 4320, 66, 4320, 66, 135, 4320, 4320, 4320, 135, 66, 4320, 135, 66, 66, 66, 66, 66, 4320, 135, 66, 4320, 66, 4320, 66, 66, 135, 135, 4320, 135, 4320, 66, 135, 66, 4320, 4320, 66, 4320, 135, 66, 4320, 66, 66, 4320, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 66, 135, 4320, 4320, 66, 4320, 135, 66, 135, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 135, 4320, 4320, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 135, 4320, 135, 4320, 66, 4320, 66, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 135, 135, 66, 135, 4320, 135, 135, 4320, 66, 4320, 4320, 135, 66, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 66, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 4320, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 4320, 135, 66, 66, 66, 66]
Prompts retrieved: 388605 . Total input tokens: 86555962 . Total output tokens: 77766423
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.075079269241542,
    "estimated_duration": 3600.099632501988,
    "input_throughput": 4695.0017292308,
    "output_throughput": 4109.370436983824,
    "total_throughput": 8804.372166214625,
    "itl": 169.23978744285,
    "ttft": 1590791.1089028004,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2336,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.632056399751421,
    "arrivals": 129353,
    "finished_requests": 67913,
    "scheduler_time": 91.97410016681366
}
#Debug simulation 
Total elapsed time: 5.075180153362453. Arrivals time: 0.21983763901516795 Scheduler time: 4.723438168410212 Scheduler overhead time: 0.03301413496956229 Adapter cache time: 0.049075535498559475 Engine time: 0.03424877533689141 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_256_slots_128_rate_0.4-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_256_slots_128_rate_0.4-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 66, 4320, 4320, 66, 4320, 135, 4320, 66, 135, 66, 4320, 135, 135, 135, 135, 4320, 66, 66, 66, 135, 4320, 66, 4320, 4320, 135, 135, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 66, 135, 135, 4320, 135, 66, 135, 4320, 135, 135, 4320, 135, 4320, 66, 4320, 4320, 135, 66, 66, 4320, 135, 66, 135, 135, 4320, 135, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 4320, 4320, 66, 4320, 66, 135, 4320, 4320, 4320, 135, 66, 4320, 135, 66, 66, 66, 66, 66, 4320, 135, 66, 4320, 66, 4320, 66, 66, 135, 135, 4320, 135, 4320, 66, 135, 66, 4320, 4320, 66, 4320, 135, 66, 4320, 66, 66, 4320, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 66, 135, 4320, 4320, 66, 4320, 135, 66, 135, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 135, 4320, 4320, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 135, 4320, 135, 4320, 66, 4320, 66, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 135, 135, 66, 135, 4320, 135, 135, 4320, 66, 4320, 4320, 135, 66, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 66, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 4320, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 4320, 135, 66, 66, 66, 66]
Prompts retrieved: 388605 . Total input tokens: 86555962 . Total output tokens: 77766423
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.1411252040416,
    "estimated_duration": 3600.231113988884,
    "input_throughput": 4767.5283770832375,
    "output_throughput": 4167.544672813004,
    "total_throughput": 8935.073049896242,
    "itl": 203.70139103235056,
    "ttft": 1570557.5645879612,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2362,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.426557225289015,
    "arrivals": 129353,
    "finished_requests": 68990,
    "scheduler_time": 87.31449980516781
}
#Debug simulation 
Total elapsed time: 5.1411980437114835. Arrivals time: 0.21145283430814743 Scheduler time: 4.813929328229278 Scheduler overhead time: 0.028275114949792624 Adapter cache time: 0.045270300935953856 Engine time: 0.02901683608070016 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-32/adapters_256_slots_128_rate_0.4-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-32/adapters_256_slots_128_rate_0.4-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 66, 4320, 4320, 66, 4320, 135, 4320, 66, 135, 66, 4320, 135, 135, 135, 135, 4320, 66, 66, 66, 135, 4320, 66, 4320, 4320, 135, 135, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 66, 135, 135, 4320, 135, 66, 135, 4320, 135, 135, 4320, 135, 4320, 66, 4320, 4320, 135, 66, 66, 4320, 135, 66, 135, 135, 4320, 135, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 4320, 4320, 66, 4320, 66, 135, 4320, 4320, 4320, 135, 66, 4320, 135, 66, 66, 66, 66, 66, 4320, 135, 66, 4320, 66, 4320, 66, 66, 135, 135, 4320, 135, 4320, 66, 135, 66, 4320, 4320, 66, 4320, 135, 66, 4320, 66, 66, 4320, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 66, 135, 4320, 4320, 66, 4320, 135, 66, 135, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 135, 4320, 4320, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 135, 4320, 135, 4320, 66, 4320, 66, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 135, 135, 66, 135, 4320, 135, 135, 4320, 66, 4320, 4320, 135, 66, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 66, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 4320, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 4320, 135, 66, 66, 66, 66]
Prompts retrieved: 388605 . Total input tokens: 86555962 . Total output tokens: 77766423
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 5.071802627295256,
    "estimated_duration": 3600.1779864294444,
    "input_throughput": 4694.904547417506,
    "output_throughput": 4109.281556568934,
    "total_throughput": 8804.186103986442,
    "itl": 169.2437840763895,
    "ttft": 1590875.4904100925,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2331,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.7002078537082586,
    "arrivals": 129353,
    "finished_requests": 67914,
    "scheduler_time": 91.97587808730633
}
#Debug simulation 
Total elapsed time: 5.07187765231356. Arrivals time: 0.20720550557598472 Scheduler time: 4.732842076104134 Scheduler overhead time: 0.033076001796871424 Adapter cache time: 0.04915424436330795 Engine time: 0.03404434258118272 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_256_slots_128_rate_0.4-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_256_slots_128_rate_0.4-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 66, 4320, 4320, 66, 4320, 135, 4320, 66, 135, 66, 4320, 135, 135, 135, 135, 4320, 66, 66, 66, 135, 4320, 66, 4320, 4320, 135, 135, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 66, 135, 135, 4320, 135, 66, 135, 4320, 135, 135, 4320, 135, 4320, 66, 4320, 4320, 135, 66, 66, 4320, 135, 66, 135, 135, 4320, 135, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 4320, 4320, 66, 4320, 66, 135, 4320, 4320, 4320, 135, 66, 4320, 135, 66, 66, 66, 66, 66, 4320, 135, 66, 4320, 66, 4320, 66, 66, 135, 135, 4320, 135, 4320, 66, 135, 66, 4320, 4320, 66, 4320, 135, 66, 4320, 66, 66, 4320, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 66, 135, 4320, 4320, 66, 4320, 135, 66, 135, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 135, 4320, 4320, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 135, 4320, 135, 4320, 66, 4320, 66, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 135, 135, 66, 135, 4320, 135, 135, 4320, 66, 4320, 4320, 135, 66, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 66, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 4320, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 4320, 135, 66, 66, 66, 66]
Prompts retrieved: 388605 . Total input tokens: 86555962 . Total output tokens: 77766423
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.135246700141579,
    "estimated_duration": 3600.167040980452,
    "input_throughput": 4768.227364062803,
    "output_throughput": 4168.23187068377,
    "total_throughput": 8936.459234746571,
    "itl": 203.68068450206385,
    "ttft": 1570328.4103621333,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2363,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.0654888468536265,
    "arrivals": 129353,
    "finished_requests": 68998,
    "scheduler_time": 87.32012437569931
}
#Debug simulation 
Total elapsed time: 5.135337841231376. Arrivals time: 0.21260725799947977 Scheduler time: 4.806995861232281 Scheduler overhead time: 0.028220563661307096 Adapter cache time: 0.04535810509696603 Engine time: 0.02904036082327366 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-32/adapters_256_slots_128_rate_0.4-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-32/adapters_256_slots_128_rate_0.4-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 66, 4320, 4320, 66, 4320, 135, 4320, 66, 135, 66, 4320, 135, 135, 135, 135, 4320, 66, 66, 66, 135, 4320, 66, 4320, 4320, 135, 135, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 66, 135, 135, 4320, 135, 66, 135, 4320, 135, 135, 4320, 135, 4320, 66, 4320, 4320, 135, 66, 66, 4320, 135, 66, 135, 135, 4320, 135, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 4320, 4320, 66, 4320, 66, 135, 4320, 4320, 4320, 135, 66, 4320, 135, 66, 66, 66, 66, 66, 4320, 135, 66, 4320, 66, 4320, 66, 66, 135, 135, 4320, 135, 4320, 66, 135, 66, 4320, 4320, 66, 4320, 135, 66, 4320, 66, 66, 4320, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 66, 135, 4320, 4320, 66, 4320, 135, 66, 135, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 135, 4320, 4320, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 135, 4320, 135, 4320, 66, 4320, 66, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 135, 135, 66, 135, 4320, 135, 135, 4320, 66, 4320, 4320, 135, 66, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 66, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 4320, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 4320, 135, 66, 66, 66, 66]
Prompts retrieved: 388605 . Total input tokens: 86555962 . Total output tokens: 77766423
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.092067045159638,
    "estimated_duration": 3600.043276651548,
    "input_throughput": 4694.613564679058,
    "output_throughput": 4109.055603842345,
    "total_throughput": 8803.669168521403,
    "itl": 169.253451267518,
    "ttft": 1591018.521482516,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2334,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.820761977210327,
    "arrivals": 129353,
    "finished_requests": 67909,
    "scheduler_time": 91.96827972976602
}
#Debug simulation 
Total elapsed time: 5.092144297901541. Arrivals time: 0.2085939389653504 Scheduler time: 4.752185395453125 Scheduler overhead time: 0.03277928940951824 Adapter cache time: 0.04917554324492812 Engine time: 0.033923637587577105 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_256_slots_128_rate_0.4-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_256_slots_128_rate_0.4-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 33, 4320, 4320, 33, 4320, 135, 4320, 33, 135, 33, 4320, 135, 135, 135, 135, 4320, 33, 33, 33, 135, 4320, 33, 4320, 4320, 135, 135, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 33, 135, 135, 4320, 135, 33, 135, 4320, 135, 135, 4320, 135, 4320, 33, 4320, 4320, 135, 33, 33, 4320, 135, 33, 135, 135, 4320, 135, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 4320, 4320, 33, 4320, 33, 135, 4320, 4320, 4320, 135, 33, 4320, 135, 33, 33, 33, 33, 33, 4320, 135, 33, 4320, 33, 4320, 33, 33, 135, 135, 4320, 135, 4320, 33, 135, 33, 4320, 4320, 33, 4320, 135, 33, 4320, 33, 33, 4320, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 33, 135, 4320, 4320, 33, 4320, 135, 33, 135, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 135, 4320, 4320, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 135, 4320, 135, 4320, 33, 4320, 33, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 135, 135, 33, 135, 4320, 135, 135, 4320, 33, 4320, 4320, 135, 33, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 33, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 4320, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 4320, 135, 33, 33, 33, 33]
Prompts retrieved: 385800 . Total input tokens: 85943615 . Total output tokens: 77196567
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.234623036812991,
    "estimated_duration": 3600.1813014338436,
    "input_throughput": 4865.259978163871,
    "output_throughput": 4280.327214038549,
    "total_throughput": 9145.58719220242,
    "itl": 199.27806396086646,
    "ttft": 1538232.9650594827,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1889,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.781261348289137,
    "arrivals": 128453,
    "finished_requests": 70595,
    "scheduler_time": 89.25508116167646
}
#Debug simulation 
Total elapsed time: 5.234698486048728. Arrivals time: 0.2179233687929809 Scheduler time: 4.9060271247290075 Scheduler overhead time: 0.028898435179144144 Adapter cache time: 0.038786749355494976 Engine time: 0.02959604701027274 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_256_slots_128_rate_0.4-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_256_slots_128_rate_0.4-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 33, 4320, 4320, 33, 4320, 135, 4320, 33, 135, 33, 4320, 135, 135, 135, 135, 4320, 33, 33, 33, 135, 4320, 33, 4320, 4320, 135, 135, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 33, 135, 135, 4320, 135, 33, 135, 4320, 135, 135, 4320, 135, 4320, 33, 4320, 4320, 135, 33, 33, 4320, 135, 33, 135, 135, 4320, 135, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 4320, 4320, 33, 4320, 33, 135, 4320, 4320, 4320, 135, 33, 4320, 135, 33, 33, 33, 33, 33, 4320, 135, 33, 4320, 33, 4320, 33, 33, 135, 135, 4320, 135, 4320, 33, 135, 33, 4320, 4320, 33, 4320, 135, 33, 4320, 33, 33, 4320, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 33, 135, 4320, 4320, 33, 4320, 135, 33, 135, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 135, 4320, 4320, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 135, 4320, 135, 4320, 33, 4320, 33, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 135, 135, 33, 135, 4320, 135, 135, 4320, 33, 4320, 4320, 135, 33, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 33, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 4320, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 4320, 135, 33, 33, 33, 33]
Prompts retrieved: 385800 . Total input tokens: 85943615 . Total output tokens: 77196567
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.244171096011996,
    "estimated_duration": 3600.082924596544,
    "input_throughput": 4864.843495782184,
    "output_throughput": 4279.964190471189,
    "total_throughput": 9144.807686253373,
    "itl": 199.30180109616393,
    "ttft": 1538312.9550240245,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1888,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.164948201831237,
    "arrivals": 128453,
    "finished_requests": 70588,
    "scheduler_time": 89.24454748646185
}
#Debug simulation 
Total elapsed time: 5.244246625341475. Arrivals time: 0.21335818571969867 Scheduler time: 4.920286078937352 Scheduler overhead time: 0.028693842701613903 Adapter cache time: 0.0388642274774611 Engine time: 0.029576085042208433 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-32/adapters_256_slots_128_rate_0.4-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-32/adapters_256_slots_128_rate_0.4-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 33, 4320, 4320, 33, 4320, 135, 4320, 33, 135, 33, 4320, 135, 135, 135, 135, 4320, 33, 33, 33, 135, 4320, 33, 4320, 4320, 135, 135, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 33, 135, 135, 4320, 135, 33, 135, 4320, 135, 135, 4320, 135, 4320, 33, 4320, 4320, 135, 33, 33, 4320, 135, 33, 135, 135, 4320, 135, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 4320, 4320, 33, 4320, 33, 135, 4320, 4320, 4320, 135, 33, 4320, 135, 33, 33, 33, 33, 33, 4320, 135, 33, 4320, 33, 4320, 33, 33, 135, 135, 4320, 135, 4320, 33, 135, 33, 4320, 4320, 33, 4320, 135, 33, 4320, 33, 33, 4320, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 33, 135, 4320, 4320, 33, 4320, 135, 33, 135, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 135, 4320, 4320, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 135, 4320, 135, 4320, 33, 4320, 33, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 135, 135, 33, 135, 4320, 135, 135, 4320, 33, 4320, 4320, 135, 33, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 33, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 4320, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 4320, 135, 33, 33, 33, 33]
Prompts retrieved: 385800 . Total input tokens: 85943615 . Total output tokens: 77196567
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.196633735671639,
    "estimated_duration": 3600.1377056043066,
    "input_throughput": 4772.344950376291,
    "output_throughput": 4207.24545520059,
    "total_throughput": 8979.590405576882,
    "itl": 165.46725639796213,
    "ttft": 1563533.500323154,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1854,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.062557076308834,
    "arrivals": 128453,
    "finished_requests": 69249,
    "scheduler_time": 93.89907799518161
}
#Debug simulation 
Total elapsed time: 5.196708783973008. Arrivals time: 0.2096600690856576 Scheduler time: 4.86122061451897 Scheduler overhead time: 0.03345158416777849 Adapter cache time: 0.042001976165920496 Engine time: 0.03449392691254616 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_256_slots_128_rate_0.4-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_256_slots_128_rate_0.4-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 33, 4320, 4320, 33, 4320, 135, 4320, 33, 135, 33, 4320, 135, 135, 135, 135, 4320, 33, 33, 33, 135, 4320, 33, 4320, 4320, 135, 135, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 33, 135, 135, 4320, 135, 33, 135, 4320, 135, 135, 4320, 135, 4320, 33, 4320, 4320, 135, 33, 33, 4320, 135, 33, 135, 135, 4320, 135, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 4320, 4320, 33, 4320, 33, 135, 4320, 4320, 4320, 135, 33, 4320, 135, 33, 33, 33, 33, 33, 4320, 135, 33, 4320, 33, 4320, 33, 33, 135, 135, 4320, 135, 4320, 33, 135, 33, 4320, 4320, 33, 4320, 135, 33, 4320, 33, 33, 4320, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 33, 135, 4320, 4320, 33, 4320, 135, 33, 135, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 135, 4320, 4320, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 135, 4320, 135, 4320, 33, 4320, 33, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 135, 135, 33, 135, 4320, 135, 135, 4320, 33, 4320, 4320, 135, 33, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 33, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 4320, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 4320, 135, 33, 33, 33, 33]
Prompts retrieved: 385800 . Total input tokens: 85943615 . Total output tokens: 77196567
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.2009984431788325,
    "estimated_duration": 3600.0163534390317,
    "input_throughput": 4865.052066574345,
    "output_throughput": 4280.112779287949,
    "total_throughput": 9145.164845862293,
    "itl": 199.29156726424995,
    "ttft": 1538266.2088222858,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1886,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.927294555685778,
    "arrivals": 128453,
    "finished_requests": 70590,
    "scheduler_time": 89.24695682908457
}
#Debug simulation 
Total elapsed time: 5.201101951301098. Arrivals time: 0.21222727419808507 Scheduler time: 4.878788995090872 Scheduler overhead time: 0.02855497458949685 Adapter cache time: 0.0386759820394218 Engine time: 0.029451686423271894 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-32/adapters_256_slots_128_rate_0.4-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-32/adapters_256_slots_128_rate_0.4-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 33, 4320, 4320, 33, 4320, 135, 4320, 33, 135, 33, 4320, 135, 135, 135, 135, 4320, 33, 33, 33, 135, 4320, 33, 4320, 4320, 135, 135, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 33, 135, 135, 4320, 135, 33, 135, 4320, 135, 135, 4320, 135, 4320, 33, 4320, 4320, 135, 33, 33, 4320, 135, 33, 135, 135, 4320, 135, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 4320, 4320, 33, 4320, 33, 135, 4320, 4320, 4320, 135, 33, 4320, 135, 33, 33, 33, 33, 33, 4320, 135, 33, 4320, 33, 4320, 33, 33, 135, 135, 4320, 135, 4320, 33, 135, 33, 4320, 4320, 33, 4320, 135, 33, 4320, 33, 33, 4320, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 33, 135, 4320, 4320, 33, 4320, 135, 33, 135, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 135, 4320, 4320, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 135, 4320, 135, 4320, 33, 4320, 33, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 135, 135, 33, 135, 4320, 135, 135, 4320, 33, 4320, 4320, 135, 33, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 33, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 4320, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 4320, 135, 33, 33, 33, 33]
Prompts retrieved: 385800 . Total input tokens: 85943615 . Total output tokens: 77196567
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 5.170240281149745,
    "estimated_duration": 3600.001910852608,
    "input_throughput": 4772.444966822524,
    "output_throughput": 4207.308322348311,
    "total_throughput": 8979.753289170836,
    "itl": 165.4594007184446,
    "ttft": 1563527.9434372003,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1858,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.1454962317831,
    "arrivals": 128453,
    "finished_requests": 69247,
    "scheduler_time": 93.89528786691388
}
#Debug simulation 
Total elapsed time: 5.1703204130753875. Arrivals time: 0.21175588108599186 Scheduler time: 4.83266492234543 Scheduler overhead time: 0.03371069999411702 Adapter cache time: 0.041525210719555616 Engine time: 0.034764815121889114 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_256_slots_128_rate_0.4-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_256_slots_128_rate_0.4-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 33, 4320, 4320, 33, 4320, 135, 4320, 33, 135, 33, 4320, 135, 135, 135, 135, 4320, 33, 33, 33, 135, 4320, 33, 4320, 4320, 135, 135, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 33, 135, 135, 4320, 135, 33, 135, 4320, 135, 135, 4320, 135, 4320, 33, 4320, 4320, 135, 33, 33, 4320, 135, 33, 135, 135, 4320, 135, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 4320, 4320, 33, 4320, 33, 135, 4320, 4320, 4320, 135, 33, 4320, 135, 33, 33, 33, 33, 33, 4320, 135, 33, 4320, 33, 4320, 33, 33, 135, 135, 4320, 135, 4320, 33, 135, 33, 4320, 4320, 33, 4320, 135, 33, 4320, 33, 33, 4320, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 33, 135, 4320, 4320, 33, 4320, 135, 33, 135, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 135, 4320, 4320, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 135, 4320, 135, 4320, 33, 4320, 33, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 135, 135, 33, 135, 4320, 135, 135, 4320, 33, 4320, 4320, 135, 33, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 33, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 4320, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 4320, 135, 33, 33, 33, 33]
Prompts retrieved: 385800 . Total input tokens: 85943615 . Total output tokens: 77196567
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.230628395918757,
    "estimated_duration": 3600.0451413047567,
    "input_throughput": 4865.443990975007,
    "output_throughput": 4280.489103649129,
    "total_throughput": 9145.933094624137,
    "itl": 199.2721582275232,
    "ttft": 1538187.1270169977,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1889,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.648205007070046,
    "arrivals": 128453,
    "finished_requests": 70595,
    "scheduler_time": 89.25396374410904
}
#Debug simulation 
Total elapsed time: 5.230711554642767. Arrivals time: 0.21216137893497944 Scheduler time: 4.908336209598929 Scheduler overhead time: 0.028566122986376286 Adapter cache time: 0.03877708036452532 Engine time: 0.029488629661500454 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-32/adapters_256_slots_128_rate_0.4-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-32/adapters_256_slots_128_rate_0.4-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 33, 4320, 4320, 33, 4320, 135, 4320, 33, 135, 33, 4320, 135, 135, 135, 135, 4320, 33, 33, 33, 135, 4320, 33, 4320, 4320, 135, 135, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 33, 135, 135, 4320, 135, 33, 135, 4320, 135, 135, 4320, 135, 4320, 33, 4320, 4320, 135, 33, 33, 4320, 135, 33, 135, 135, 4320, 135, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 4320, 4320, 33, 4320, 33, 135, 4320, 4320, 4320, 135, 33, 4320, 135, 33, 33, 33, 33, 33, 4320, 135, 33, 4320, 33, 4320, 33, 33, 135, 135, 4320, 135, 4320, 33, 135, 33, 4320, 4320, 33, 4320, 135, 33, 4320, 33, 33, 4320, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 33, 135, 4320, 4320, 33, 4320, 135, 33, 135, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 135, 4320, 4320, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 135, 4320, 135, 4320, 33, 4320, 33, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 135, 135, 33, 135, 4320, 135, 135, 4320, 33, 4320, 4320, 135, 33, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 33, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 4320, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 4320, 135, 33, 33, 33, 33]
Prompts retrieved: 385800 . Total input tokens: 85943615 . Total output tokens: 77196567
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.189686834812164,
    "estimated_duration": 3600.0975359421636,
    "input_throughput": 4772.490697395378,
    "output_throughput": 4207.238511952175,
    "total_throughput": 8979.729209347553,
    "itl": 165.4695078748644,
    "ttft": 1563601.270580936,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1853,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.21561402026548,
    "arrivals": 128453,
    "finished_requests": 69248,
    "scheduler_time": 93.89570775671122
}
#Debug simulation 
Total elapsed time: 5.189765655901283. Arrivals time: 0.21146184485405684 Scheduler time: 4.852034374140203 Scheduler overhead time: 0.033656459767371416 Adapter cache time: 0.0419825823046267 Engine time: 0.03477918170392513 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_256_slots_128_rate_0.4-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_256_slots_128_rate_0.4-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 4320, 33, 4320, 4320, 33, 4320, 66, 4320, 33, 66, 33, 4320, 66, 66, 66, 66, 4320, 33, 33, 33, 66, 4320, 33, 4320, 4320, 66, 66, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 33, 66, 66, 4320, 66, 33, 66, 4320, 66, 66, 4320, 66, 4320, 33, 4320, 4320, 66, 33, 33, 4320, 66, 33, 66, 66, 4320, 66, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 4320, 4320, 33, 4320, 33, 66, 4320, 4320, 4320, 66, 33, 4320, 66, 33, 33, 33, 33, 33, 4320, 66, 33, 4320, 33, 4320, 33, 33, 66, 66, 4320, 66, 4320, 33, 66, 33, 4320, 4320, 33, 4320, 66, 33, 4320, 33, 33, 4320, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 33, 66, 4320, 4320, 33, 4320, 66, 33, 66, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 66, 4320, 4320, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 66, 4320, 66, 4320, 33, 4320, 33, 66, 4320, 66, 4320, 66, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 66, 66, 33, 66, 4320, 66, 66, 4320, 33, 4320, 4320, 66, 33, 4320, 4320, 66, 66, 4320, 4320, 66, 66, 66, 66, 4320, 4320, 66, 66, 4320, 33, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 4320, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 4320, 66, 33, 33, 33, 33]
Prompts retrieved: 379935 . Total input tokens: 84650362 . Total output tokens: 76040480
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.489960517734289,
    "estimated_duration": 3600.1080418176075,
    "input_throughput": 5121.949615348295,
    "output_throughput": 4513.681203799622,
    "total_throughput": 9635.630819147918,
    "itl": 189.4852829134534,
    "ttft": 1456879.0909595168,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1315,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.024541383271675,
    "arrivals": 126425,
    "finished_requests": 74614,
    "scheduler_time": 93.02164044008168
}
#Debug simulation 
Total elapsed time: 5.490068187005818. Arrivals time: 0.22040960099548101 Scheduler time: 5.164039838593453 Scheduler overhead time: 0.030416940804570913 Adapter cache time: 0.029964377637952566 Engine time: 0.03109836671501398 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_256_slots_128_rate_0.4-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_256_slots_128_rate_0.4-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 4320, 33, 4320, 4320, 33, 4320, 66, 4320, 33, 66, 33, 4320, 66, 66, 66, 66, 4320, 33, 33, 33, 66, 4320, 33, 4320, 4320, 66, 66, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 33, 66, 66, 4320, 66, 33, 66, 4320, 66, 66, 4320, 66, 4320, 33, 4320, 4320, 66, 33, 33, 4320, 66, 33, 66, 66, 4320, 66, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 4320, 4320, 33, 4320, 33, 66, 4320, 4320, 4320, 66, 33, 4320, 66, 33, 33, 33, 33, 33, 4320, 66, 33, 4320, 33, 4320, 33, 33, 66, 66, 4320, 66, 4320, 33, 66, 33, 4320, 4320, 33, 4320, 66, 33, 4320, 33, 33, 4320, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 33, 66, 4320, 4320, 33, 4320, 66, 33, 66, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 66, 4320, 4320, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 66, 4320, 66, 4320, 33, 4320, 33, 66, 4320, 66, 4320, 66, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 66, 66, 33, 66, 4320, 66, 66, 4320, 33, 4320, 4320, 66, 33, 4320, 4320, 66, 66, 4320, 4320, 66, 66, 66, 66, 4320, 4320, 66, 66, 4320, 33, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 4320, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 4320, 66, 33, 33, 33, 33]
Prompts retrieved: 379935 . Total input tokens: 84650362 . Total output tokens: 76040480
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.4871104820631444,
    "estimated_duration": 3600.069581351774,
    "input_throughput": 5121.646285813368,
    "output_throughput": 4513.356376267306,
    "total_throughput": 9635.002662080673,
    "itl": 189.4980611953574,
    "ttft": 1456980.375388221,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1316,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.287932543223702,
    "arrivals": 126425,
    "finished_requests": 74606,
    "scheduler_time": 93.01520969027176
}
#Debug simulation 
Total elapsed time: 5.487212965730578. Arrivals time: 0.2203534417785704 Scheduler time: 5.161844494286925 Scheduler overhead time: 0.030162548646330833 Adapter cache time: 0.029997007455676794 Engine time: 0.030904832296073437 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-32/adapters_256_slots_128_rate_0.4-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-32/adapters_256_slots_128_rate_0.4-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 4320, 33, 4320, 4320, 33, 4320, 66, 4320, 33, 66, 33, 4320, 66, 66, 66, 66, 4320, 33, 33, 33, 66, 4320, 33, 4320, 4320, 66, 66, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 33, 66, 66, 4320, 66, 33, 66, 4320, 66, 66, 4320, 66, 4320, 33, 4320, 4320, 66, 33, 33, 4320, 66, 33, 66, 66, 4320, 66, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 4320, 4320, 33, 4320, 33, 66, 4320, 4320, 4320, 66, 33, 4320, 66, 33, 33, 33, 33, 33, 4320, 66, 33, 4320, 33, 4320, 33, 33, 66, 66, 4320, 66, 4320, 33, 66, 33, 4320, 4320, 33, 4320, 66, 33, 4320, 33, 33, 4320, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 33, 66, 4320, 4320, 33, 4320, 66, 33, 66, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 66, 4320, 4320, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 66, 4320, 66, 4320, 33, 4320, 33, 66, 4320, 66, 4320, 66, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 66, 66, 33, 66, 4320, 66, 66, 4320, 33, 4320, 4320, 66, 33, 4320, 4320, 66, 66, 4320, 4320, 66, 66, 66, 66, 4320, 4320, 66, 66, 4320, 33, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 4320, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 4320, 66, 33, 33, 33, 33]
Prompts retrieved: 379935 . Total input tokens: 84650362 . Total output tokens: 76040480
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.400634928606451,
    "estimated_duration": 3600.1786144507164,
    "input_throughput": 4996.352105364754,
    "output_throughput": 4407.6696462519985,
    "total_throughput": 9404.021751616752,
    "itl": 158.57212881378413,
    "ttft": 1491535.9359693707,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1284,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.193864077180565,
    "arrivals": 126425,
    "finished_requests": 72782,
    "scheduler_time": 97.22258088043036
}
#Debug simulation 
Total elapsed time: 5.4007107126526535. Arrivals time: 0.21627972088754177 Scheduler time: 5.0657365238294005 Scheduler overhead time: 0.03488099155947566 Adapter cache time: 0.03187021519988775 Engine time: 0.03568755788728595 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_256_slots_128_rate_0.4-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_256_slots_128_rate_0.4-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 4320, 33, 4320, 4320, 33, 4320, 66, 4320, 33, 66, 33, 4320, 66, 66, 66, 66, 4320, 33, 33, 33, 66, 4320, 33, 4320, 4320, 66, 66, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 33, 66, 66, 4320, 66, 33, 66, 4320, 66, 66, 4320, 66, 4320, 33, 4320, 4320, 66, 33, 33, 4320, 66, 33, 66, 66, 4320, 66, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 4320, 4320, 33, 4320, 33, 66, 4320, 4320, 4320, 66, 33, 4320, 66, 33, 33, 33, 33, 33, 4320, 66, 33, 4320, 33, 4320, 33, 33, 66, 66, 4320, 66, 4320, 33, 66, 33, 4320, 4320, 33, 4320, 66, 33, 4320, 33, 33, 4320, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 33, 66, 4320, 4320, 33, 4320, 66, 33, 66, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 66, 4320, 4320, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 66, 4320, 66, 4320, 33, 4320, 33, 66, 4320, 66, 4320, 66, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 66, 66, 33, 66, 4320, 66, 66, 4320, 33, 4320, 4320, 66, 33, 4320, 4320, 66, 66, 4320, 4320, 66, 66, 66, 66, 4320, 4320, 66, 66, 4320, 33, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 4320, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 4320, 66, 33, 33, 33, 33]
Prompts retrieved: 379935 . Total input tokens: 84650362 . Total output tokens: 76040480
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.46226006699726,
    "estimated_duration": 3600.0846125405524,
    "input_throughput": 5121.809064089684,
    "output_throughput": 4513.591970421213,
    "total_throughput": 9635.401034510896,
    "itl": 189.49319252347868,
    "ttft": 1456861.481505599,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1318,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.130883111755775,
    "arrivals": 126425,
    "finished_requests": 74611,
    "scheduler_time": 93.01837220178687
}
#Debug simulation 
Total elapsed time: 5.462338034063578. Arrivals time: 0.21905851643532515 Scheduler time: 5.138944672420621 Scheduler overhead time: 0.02965105837211013 Adapter cache time: 0.02983343368396163 Engine time: 0.031013717409223318 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-32/adapters_256_slots_128_rate_0.4-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-32/adapters_256_slots_128_rate_0.4-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 4320, 33, 4320, 4320, 33, 4320, 66, 4320, 33, 66, 33, 4320, 66, 66, 66, 66, 4320, 33, 33, 33, 66, 4320, 33, 4320, 4320, 66, 66, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 33, 66, 66, 4320, 66, 33, 66, 4320, 66, 66, 4320, 66, 4320, 33, 4320, 4320, 66, 33, 33, 4320, 66, 33, 66, 66, 4320, 66, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 4320, 4320, 33, 4320, 33, 66, 4320, 4320, 4320, 66, 33, 4320, 66, 33, 33, 33, 33, 33, 4320, 66, 33, 4320, 33, 4320, 33, 33, 66, 66, 4320, 66, 4320, 33, 66, 33, 4320, 4320, 33, 4320, 66, 33, 4320, 33, 33, 4320, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 33, 66, 4320, 4320, 33, 4320, 66, 33, 66, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 66, 4320, 4320, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 66, 4320, 66, 4320, 33, 4320, 33, 66, 4320, 66, 4320, 66, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 66, 66, 33, 66, 4320, 66, 66, 4320, 33, 4320, 4320, 66, 33, 4320, 4320, 66, 66, 4320, 4320, 66, 66, 66, 66, 4320, 4320, 66, 66, 4320, 33, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 4320, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 4320, 66, 33, 33, 33, 33]
Prompts retrieved: 379935 . Total input tokens: 84650362 . Total output tokens: 76040480
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 5.352622135076672,
    "estimated_duration": 3600.1630302986205,
    "input_throughput": 4996.373733249514,
    "output_throughput": 4407.688725886332,
    "total_throughput": 9404.062459135845,
    "itl": 158.57694527719022,
    "ttft": 1491517.8767564013,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1283,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.240156056471155,
    "arrivals": 126425,
    "finished_requests": 72782,
    "scheduler_time": 97.22137911444456
}
#Debug simulation 
Total elapsed time: 5.3526970078237355. Arrivals time: 0.21554288500919938 Scheduler time: 5.018737477250397 Scheduler overhead time: 0.03464693250134587 Adapter cache time: 0.031544013880193233 Engine time: 0.03593570040538907 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_256_slots_128_rate_0.4-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_256_slots_128_rate_0.4-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 4320, 33, 4320, 4320, 33, 4320, 66, 4320, 33, 66, 33, 4320, 66, 66, 66, 66, 4320, 33, 33, 33, 66, 4320, 33, 4320, 4320, 66, 66, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 33, 66, 66, 4320, 66, 33, 66, 4320, 66, 66, 4320, 66, 4320, 33, 4320, 4320, 66, 33, 33, 4320, 66, 33, 66, 66, 4320, 66, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 4320, 4320, 33, 4320, 33, 66, 4320, 4320, 4320, 66, 33, 4320, 66, 33, 33, 33, 33, 33, 4320, 66, 33, 4320, 33, 4320, 33, 33, 66, 66, 4320, 66, 4320, 33, 66, 33, 4320, 4320, 33, 4320, 66, 33, 4320, 33, 33, 4320, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 33, 66, 4320, 4320, 33, 4320, 66, 33, 66, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 66, 4320, 4320, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 66, 4320, 66, 4320, 33, 4320, 33, 66, 4320, 66, 4320, 66, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 66, 66, 33, 66, 4320, 66, 66, 4320, 33, 4320, 4320, 66, 33, 4320, 4320, 66, 66, 4320, 4320, 66, 66, 66, 66, 4320, 4320, 66, 66, 4320, 33, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 4320, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 4320, 66, 33, 33, 33, 33]
Prompts retrieved: 379935 . Total input tokens: 84650362 . Total output tokens: 76040480
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.430465745739639,
    "estimated_duration": 3600.179838538292,
    "input_throughput": 5100.40131980054,
    "output_throughput": 4495.558479259523,
    "total_throughput": 9595.959799060063,
    "itl": 190.19569133094998,
    "ttft": 1462595.7400850474,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1309,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9139758360268457,
    "arrivals": 126425,
    "finished_requests": 74304,
    "scheduler_time": 92.72056596101052
}
#Debug simulation 
Total elapsed time: 5.430547115858644. Arrivals time: 0.21942579513415694 Scheduler time: 5.107298464048654 Scheduler overhead time: 0.029723590705543756 Adapter cache time: 0.02937428979203105 Engine time: 0.030794403981417418 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-32/adapters_256_slots_128_rate_0.4-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-32/adapters_256_slots_128_rate_0.4-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 4320, 33, 4320, 4320, 33, 4320, 66, 4320, 33, 66, 33, 4320, 66, 66, 66, 66, 4320, 33, 33, 33, 66, 4320, 33, 4320, 4320, 66, 66, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 33, 66, 66, 4320, 66, 33, 66, 4320, 66, 66, 4320, 66, 4320, 33, 4320, 4320, 66, 33, 33, 4320, 66, 33, 66, 66, 4320, 66, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 4320, 4320, 33, 4320, 33, 66, 4320, 4320, 4320, 66, 33, 4320, 66, 33, 33, 33, 33, 33, 4320, 66, 33, 4320, 33, 4320, 33, 33, 66, 66, 4320, 66, 4320, 33, 66, 33, 4320, 4320, 33, 4320, 66, 33, 4320, 33, 33, 4320, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 33, 66, 4320, 4320, 33, 4320, 66, 33, 66, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 66, 4320, 4320, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 66, 4320, 66, 4320, 33, 4320, 33, 66, 4320, 66, 4320, 66, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 66, 66, 33, 66, 4320, 66, 66, 4320, 33, 4320, 4320, 66, 33, 4320, 4320, 66, 66, 4320, 4320, 66, 66, 66, 66, 4320, 4320, 66, 66, 4320, 33, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 4320, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 4320, 66, 33, 33, 33, 33]
Prompts retrieved: 379935 . Total input tokens: 84650362 . Total output tokens: 76040480
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.283559211995453,
    "estimated_duration": 3600.021117610499,
    "input_throughput": 4996.29430283416,
    "output_throughput": 4407.553311946084,
    "total_throughput": 9403.847614780245,
    "itl": 158.5721868817525,
    "ttft": 1491594.381087184,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1285,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.303546806909173,
    "arrivals": 126425,
    "finished_requests": 72778,
    "scheduler_time": 97.21794913736265
}
#Debug simulation 
Total elapsed time: 5.283633449114859. Arrivals time: 0.2036162498407066 Scheduler time: 4.963449288159609 Scheduler overhead time: 0.034178067464381456 Adapter cache time: 0.031046802643686533 Engine time: 0.03523586131632328 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_256_slots_128_rate_0.1-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_256_slots_128_rate_0.1-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 270, 1080, 1080, 270, 1080, 540, 1080, 270, 540, 270, 1080, 540, 540, 540, 540, 1080, 270, 270, 270, 540, 1080, 270, 1080, 1080, 540, 540, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 270, 540, 540, 1080, 540, 270, 540, 1080, 540, 540, 1080, 540, 1080, 270, 1080, 1080, 540, 270, 270, 1080, 540, 270, 540, 540, 1080, 540, 270, 270, 1080, 1080, 1080, 1080, 1080, 1080, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 1080, 1080, 270, 1080, 270, 540, 1080, 1080, 1080, 540, 270, 1080, 540, 270, 270, 270, 270, 270, 1080, 540, 270, 1080, 270, 1080, 270, 270, 540, 540, 1080, 540, 1080, 270, 540, 270, 1080, 1080, 270, 1080, 540, 270, 1080, 270, 270, 1080, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 270, 540, 1080, 1080, 270, 1080, 540, 270, 540, 1080, 270, 270, 270, 270, 270, 270, 1080, 270, 270, 270, 1080, 270, 540, 1080, 1080, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 1080, 270, 270, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 540, 1080, 540, 1080, 270, 1080, 270, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 540, 540, 270, 540, 1080, 540, 540, 1080, 270, 1080, 1080, 540, 270, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 270, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 1080, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 1080, 540, 270, 270, 270, 270]
Prompts retrieved: 161730 . Total input tokens: 36052490 . Total output tokens: 32364050
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 6.207866968587041,
    "estimated_duration": 3600.0876787683405,
    "input_throughput": 3699.3546236508178,
    "output_throughput": 3259.4542264077686,
    "total_throughput": 6958.808850058586,
    "itl": 106.65820915293487,
    "ttft": 67630.8912149435,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4707,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.405715810690078,
    "arrivals": 54189,
    "finished_requests": 53463,
    "scheduler_time": 42.50782961812581
}
#Debug simulation 
Total elapsed time: 6.207937209866941. Arrivals time: 0.12633849401026964 Scheduler time: 5.873300366103649 Scheduler overhead time: 0.04942614957690239 Adapter cache time: 0.0868911873549223 Engine time: 0.04940817318856716 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_256_slots_128_rate_0.1-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_256_slots_128_rate_0.1-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 270, 1080, 1080, 270, 1080, 540, 1080, 270, 540, 270, 1080, 540, 540, 540, 540, 1080, 270, 270, 270, 540, 1080, 270, 1080, 1080, 540, 540, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 270, 540, 540, 1080, 540, 270, 540, 1080, 540, 540, 1080, 540, 1080, 270, 1080, 1080, 540, 270, 270, 1080, 540, 270, 540, 540, 1080, 540, 270, 270, 1080, 1080, 1080, 1080, 1080, 1080, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 1080, 1080, 270, 1080, 270, 540, 1080, 1080, 1080, 540, 270, 1080, 540, 270, 270, 270, 270, 270, 1080, 540, 270, 1080, 270, 1080, 270, 270, 540, 540, 1080, 540, 1080, 270, 540, 270, 1080, 1080, 270, 1080, 540, 270, 1080, 270, 270, 1080, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 270, 540, 1080, 1080, 270, 1080, 540, 270, 540, 1080, 270, 270, 270, 270, 270, 270, 1080, 270, 270, 270, 1080, 270, 540, 1080, 1080, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 1080, 270, 270, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 540, 1080, 540, 1080, 270, 1080, 270, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 540, 540, 270, 540, 1080, 540, 540, 1080, 270, 1080, 1080, 540, 270, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 270, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 1080, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 1080, 540, 270, 270, 270, 270]
Prompts retrieved: 161730 . Total input tokens: 36052490 . Total output tokens: 32364050
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 6.364618600346148,
    "estimated_duration": 3600.0617016307374,
    "input_throughput": 3698.3377240365026,
    "output_throughput": 3259.3246928753742,
    "total_throughput": 6957.662416911877,
    "itl": 106.70797655681473,
    "ttft": 68946.74765783097,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4681,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.274102991201012,
    "arrivals": 54189,
    "finished_requests": 53443,
    "scheduler_time": 42.503424640067756
}
#Debug simulation 
Total elapsed time: 6.364692041184753. Arrivals time: 0.12808954808861017 Scheduler time: 6.025401547551155 Scheduler overhead time: 0.05018417816609144 Adapter cache time: 0.08795985952019691 Engine time: 0.05016876524314284 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-32/adapters_256_slots_128_rate_0.1-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-32/adapters_256_slots_128_rate_0.1-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 270, 1080, 1080, 270, 1080, 540, 1080, 270, 540, 270, 1080, 540, 540, 540, 540, 1080, 270, 270, 270, 540, 1080, 270, 1080, 1080, 540, 540, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 270, 540, 540, 1080, 540, 270, 540, 1080, 540, 540, 1080, 540, 1080, 270, 1080, 1080, 540, 270, 270, 1080, 540, 270, 540, 540, 1080, 540, 270, 270, 1080, 1080, 1080, 1080, 1080, 1080, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 1080, 1080, 270, 1080, 270, 540, 1080, 1080, 1080, 540, 270, 1080, 540, 270, 270, 270, 270, 270, 1080, 540, 270, 1080, 270, 1080, 270, 270, 540, 540, 1080, 540, 1080, 270, 540, 270, 1080, 1080, 270, 1080, 540, 270, 1080, 270, 270, 1080, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 270, 540, 1080, 1080, 270, 1080, 540, 270, 540, 1080, 270, 270, 270, 270, 270, 270, 1080, 270, 270, 270, 1080, 270, 540, 1080, 1080, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 1080, 270, 270, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 540, 1080, 540, 1080, 270, 1080, 270, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 540, 540, 270, 540, 1080, 540, 540, 1080, 270, 1080, 1080, 540, 270, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 270, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 1080, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 1080, 540, 270, 270, 270, 270]
Prompts retrieved: 161730 . Total input tokens: 36052490 . Total output tokens: 32364050
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 6.216393225360662,
    "estimated_duration": 3600.043329472326,
    "input_throughput": 3699.3929742373607,
    "output_throughput": 3259.2977156527295,
    "total_throughput": 6958.690689890091,
    "itl": 106.73790124120363,
    "ttft": 67803.79159251624,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4694,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.343885618968473,
    "arrivals": 54189,
    "finished_requests": 53460,
    "scheduler_time": 42.508685504659915
}
#Debug simulation 
Total elapsed time: 6.216470641084015. Arrivals time: 0.12865228857845068 Scheduler time: 5.877041142433882 Scheduler overhead time: 0.04989156033843756 Adapter cache time: 0.08772601280361414 Engine time: 0.05027676047757268 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_256_slots_128_rate_0.1-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_256_slots_128_rate_0.1-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 270, 1080, 1080, 270, 1080, 540, 1080, 270, 540, 270, 1080, 540, 540, 540, 540, 1080, 270, 270, 270, 540, 1080, 270, 1080, 1080, 540, 540, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 270, 540, 540, 1080, 540, 270, 540, 1080, 540, 540, 1080, 540, 1080, 270, 1080, 1080, 540, 270, 270, 1080, 540, 270, 540, 540, 1080, 540, 270, 270, 1080, 1080, 1080, 1080, 1080, 1080, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 1080, 1080, 270, 1080, 270, 540, 1080, 1080, 1080, 540, 270, 1080, 540, 270, 270, 270, 270, 270, 1080, 540, 270, 1080, 270, 1080, 270, 270, 540, 540, 1080, 540, 1080, 270, 540, 270, 1080, 1080, 270, 1080, 540, 270, 1080, 270, 270, 1080, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 270, 540, 1080, 1080, 270, 1080, 540, 270, 540, 1080, 270, 270, 270, 270, 270, 270, 1080, 270, 270, 270, 1080, 270, 540, 1080, 1080, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 1080, 270, 270, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 540, 1080, 540, 1080, 270, 1080, 270, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 540, 540, 270, 540, 1080, 540, 540, 1080, 270, 1080, 1080, 540, 270, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 270, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 1080, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 1080, 540, 270, 270, 270, 270]
Prompts retrieved: 161730 . Total input tokens: 36052490 . Total output tokens: 32364050
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 6.243570344056934,
    "estimated_duration": 3600.0614968573564,
    "input_throughput": 3699.9117964033403,
    "output_throughput": 3259.5693185362707,
    "total_throughput": 6959.481114939611,
    "itl": 106.68567033178827,
    "ttft": 67366.44066908688,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4698,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.69896581836394,
    "arrivals": 54189,
    "finished_requests": 53466,
    "scheduler_time": 42.50756364668331
}
#Debug simulation 
Total elapsed time: 6.2436400428414345. Arrivals time: 0.12790657300502062 Scheduler time: 5.90582258766517 Scheduler overhead time: 0.04946022806689143 Adapter cache time: 0.08780206320807338 Engine time: 0.04997969092801213 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-32/adapters_256_slots_128_rate_0.1-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-32/adapters_256_slots_128_rate_0.1-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 270, 1080, 1080, 270, 1080, 540, 1080, 270, 540, 270, 1080, 540, 540, 540, 540, 1080, 270, 270, 270, 540, 1080, 270, 1080, 1080, 540, 540, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 270, 540, 540, 1080, 540, 270, 540, 1080, 540, 540, 1080, 540, 1080, 270, 1080, 1080, 540, 270, 270, 1080, 540, 270, 540, 540, 1080, 540, 270, 270, 1080, 1080, 1080, 1080, 1080, 1080, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 1080, 1080, 270, 1080, 270, 540, 1080, 1080, 1080, 540, 270, 1080, 540, 270, 270, 270, 270, 270, 1080, 540, 270, 1080, 270, 1080, 270, 270, 540, 540, 1080, 540, 1080, 270, 540, 270, 1080, 1080, 270, 1080, 540, 270, 1080, 270, 270, 1080, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 270, 540, 1080, 1080, 270, 1080, 540, 270, 540, 1080, 270, 270, 270, 270, 270, 270, 1080, 270, 270, 270, 1080, 270, 540, 1080, 1080, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 1080, 270, 270, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 540, 1080, 540, 1080, 270, 1080, 270, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 540, 540, 270, 540, 1080, 540, 540, 1080, 270, 1080, 1080, 540, 270, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 270, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 1080, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 1080, 540, 270, 270, 270, 270]
Prompts retrieved: 161730 . Total input tokens: 36052490 . Total output tokens: 32364050
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 6.243875513784587,
    "estimated_duration": 3600.0295881846746,
    "input_throughput": 3699.4059836923802,
    "output_throughput": 3259.6501535748002,
    "total_throughput": 6959.05613726718,
    "itl": 106.74139480240407,
    "ttft": 68063.96523906343,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4684,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.504121760165972,
    "arrivals": 54189,
    "finished_requests": 53457,
    "scheduler_time": 42.508822137525534
}
#Debug simulation 
Total elapsed time: 6.2439481928013265. Arrivals time: 0.12783262925222516 Scheduler time: 5.906458750367165 Scheduler overhead time: 0.049961543176323175 Adapter cache time: 0.08709444245323539 Engine time: 0.049830418545752764 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_256_slots_128_rate_0.1-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_256_slots_128_rate_0.1-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 270, 1080, 1080, 270, 1080, 540, 1080, 270, 540, 270, 1080, 540, 540, 540, 540, 1080, 270, 270, 270, 540, 1080, 270, 1080, 1080, 540, 540, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 270, 540, 540, 1080, 540, 270, 540, 1080, 540, 540, 1080, 540, 1080, 270, 1080, 1080, 540, 270, 270, 1080, 540, 270, 540, 540, 1080, 540, 270, 270, 1080, 1080, 1080, 1080, 1080, 1080, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 1080, 1080, 270, 1080, 270, 540, 1080, 1080, 1080, 540, 270, 1080, 540, 270, 270, 270, 270, 270, 1080, 540, 270, 1080, 270, 1080, 270, 270, 540, 540, 1080, 540, 1080, 270, 540, 270, 1080, 1080, 270, 1080, 540, 270, 1080, 270, 270, 1080, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 270, 540, 1080, 1080, 270, 1080, 540, 270, 540, 1080, 270, 270, 270, 270, 270, 270, 1080, 270, 270, 270, 1080, 270, 540, 1080, 1080, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 1080, 270, 270, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 540, 1080, 540, 1080, 270, 1080, 270, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 540, 540, 270, 540, 1080, 540, 540, 1080, 270, 1080, 1080, 540, 270, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 270, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 1080, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 1080, 540, 270, 270, 270, 270]
Prompts retrieved: 161730 . Total input tokens: 36052490 . Total output tokens: 32364050
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 6.2240054700523615,
    "estimated_duration": 3600.0500073119038,
    "input_throughput": 3699.728329592073,
    "output_throughput": 3259.5680549343347,
    "total_throughput": 6959.296384526408,
    "itl": 106.6351502309511,
    "ttft": 67696.16633337995,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4706,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.071176687810977,
    "arrivals": 54189,
    "finished_requests": 53461,
    "scheduler_time": 42.503283895577674
}
#Debug simulation 
Total elapsed time: 6.224076274782419. Arrivals time: 0.12727288575842977 Scheduler time: 5.886563061270863 Scheduler overhead time: 0.049611599650233984 Adapter cache time: 0.08820910705253482 Engine time: 0.049806219059973955 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-32/adapters_256_slots_128_rate_0.1-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-32/adapters_256_slots_128_rate_0.1-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 270, 1080, 1080, 270, 1080, 540, 1080, 270, 540, 270, 1080, 540, 540, 540, 540, 1080, 270, 270, 270, 540, 1080, 270, 1080, 1080, 540, 540, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 270, 540, 540, 1080, 540, 270, 540, 1080, 540, 540, 1080, 540, 1080, 270, 1080, 1080, 540, 270, 270, 1080, 540, 270, 540, 540, 1080, 540, 270, 270, 1080, 1080, 1080, 1080, 1080, 1080, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 1080, 1080, 270, 1080, 270, 540, 1080, 1080, 1080, 540, 270, 1080, 540, 270, 270, 270, 270, 270, 1080, 540, 270, 1080, 270, 1080, 270, 270, 540, 540, 1080, 540, 1080, 270, 540, 270, 1080, 1080, 270, 1080, 540, 270, 1080, 270, 270, 1080, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 270, 540, 1080, 1080, 270, 1080, 540, 270, 540, 1080, 270, 270, 270, 270, 270, 270, 1080, 270, 270, 270, 1080, 270, 540, 1080, 1080, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 1080, 270, 270, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 540, 1080, 540, 1080, 270, 1080, 270, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 540, 540, 270, 540, 1080, 540, 540, 1080, 270, 1080, 1080, 540, 270, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 270, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 1080, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 1080, 540, 270, 270, 270, 270]
Prompts retrieved: 161730 . Total input tokens: 36052490 . Total output tokens: 32364050
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 6.262558675836772,
    "estimated_duration": 3600.026140449797,
    "input_throughput": 3699.856745577913,
    "output_throughput": 3259.8132741707664,
    "total_throughput": 6959.67001974868,
    "itl": 106.77394052402649,
    "ttft": 67792.88965987322,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4686,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.71204933725188,
    "arrivals": 54189,
    "finished_requests": 53461,
    "scheduler_time": 42.513035273413124
}
#Debug simulation 
Total elapsed time: 6.262634788174182. Arrivals time: 0.12923359777778387 Scheduler time: 5.922361196950078 Scheduler overhead time: 0.05014662491157651 Adapter cache time: 0.08768000826239586 Engine time: 0.050360698252916336 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_256_slots_128_rate_0.1-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_256_slots_128_rate_0.1-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 135, 1080, 1080, 135, 1080, 540, 1080, 135, 540, 135, 1080, 540, 540, 540, 540, 1080, 135, 135, 135, 540, 1080, 135, 1080, 1080, 540, 540, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 135, 540, 540, 1080, 540, 135, 540, 1080, 540, 540, 1080, 540, 1080, 135, 1080, 1080, 540, 135, 135, 1080, 540, 135, 540, 540, 1080, 540, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 1080, 1080, 135, 1080, 135, 540, 1080, 1080, 1080, 540, 135, 1080, 540, 135, 135, 135, 135, 135, 1080, 540, 135, 1080, 135, 1080, 135, 135, 540, 540, 1080, 540, 1080, 135, 540, 135, 1080, 1080, 135, 1080, 540, 135, 1080, 135, 135, 1080, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 135, 540, 1080, 1080, 135, 1080, 540, 135, 540, 1080, 135, 135, 135, 135, 135, 135, 1080, 135, 135, 135, 1080, 135, 540, 1080, 1080, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 1080, 135, 135, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 540, 1080, 540, 1080, 135, 1080, 135, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 540, 540, 135, 540, 1080, 540, 540, 1080, 135, 1080, 1080, 540, 135, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 135, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 1080, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 1080, 540, 135, 135, 135, 135]
Prompts retrieved: 150255 . Total input tokens: 33450605 . Total output tokens: 30090347
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.853335114195943,
    "estimated_duration": 3599.9682396453713,
    "input_throughput": 3457.5796705434705,
    "output_throughput": 3026.726424973506,
    "total_throughput": 6484.306095516976,
    "itl": 94.05654019323674,
    "ttft": 35180.34526343816,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6631,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.294094230017684,
    "arrivals": 50289,
    "finished_requests": 49915,
    "scheduler_time": 37.764086871312124
}
#Debug simulation 
Total elapsed time: 4.853399939835072. Arrivals time: 0.11873356346040964 Scheduler time: 4.483041270636022 Scheduler overhead time: 0.05424237949773669 Adapter cache time: 0.11798502085730433 Engine time: 0.054394736886024475 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_256_slots_128_rate_0.1-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_256_slots_128_rate_0.1-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 135, 1080, 1080, 135, 1080, 540, 1080, 135, 540, 135, 1080, 540, 540, 540, 540, 1080, 135, 135, 135, 540, 1080, 135, 1080, 1080, 540, 540, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 135, 540, 540, 1080, 540, 135, 540, 1080, 540, 540, 1080, 540, 1080, 135, 1080, 1080, 540, 135, 135, 1080, 540, 135, 540, 540, 1080, 540, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 1080, 1080, 135, 1080, 135, 540, 1080, 1080, 1080, 540, 135, 1080, 540, 135, 135, 135, 135, 135, 1080, 540, 135, 1080, 135, 1080, 135, 135, 540, 540, 1080, 540, 1080, 135, 540, 135, 1080, 1080, 135, 1080, 540, 135, 1080, 135, 135, 1080, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 135, 540, 1080, 1080, 135, 1080, 540, 135, 540, 1080, 135, 135, 135, 135, 135, 135, 1080, 135, 135, 135, 1080, 135, 540, 1080, 1080, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 1080, 135, 135, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 540, 1080, 540, 1080, 135, 1080, 135, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 540, 540, 135, 540, 1080, 540, 540, 1080, 135, 1080, 1080, 540, 135, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 135, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 1080, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 1080, 540, 135, 135, 135, 135]
Prompts retrieved: 150255 . Total input tokens: 33450605 . Total output tokens: 30090347
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.732326734811068,
    "estimated_duration": 3599.956860231841,
    "input_throughput": 3457.8128247898885,
    "output_throughput": 3026.9918288126983,
    "total_throughput": 6484.804653602587,
    "itl": 94.16034413200684,
    "ttft": 34777.62976189706,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6669,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.766657894811516,
    "arrivals": 50289,
    "finished_requests": 49920,
    "scheduler_time": 37.77006338172741
}
#Debug simulation 
Total elapsed time: 4.7323916726745665. Arrivals time: 0.11687714792788029 Scheduler time: 4.367888350505382 Scheduler overhead time: 0.05328371888026595 Adapter cache time: 0.11657825810834765 Engine time: 0.05329600954428315 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-32/adapters_256_slots_128_rate_0.1-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-32/adapters_256_slots_128_rate_0.1-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 135, 1080, 1080, 135, 1080, 540, 1080, 135, 540, 135, 1080, 540, 540, 540, 540, 1080, 135, 135, 135, 540, 1080, 135, 1080, 1080, 540, 540, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 135, 540, 540, 1080, 540, 135, 540, 1080, 540, 540, 1080, 540, 1080, 135, 1080, 1080, 540, 135, 135, 1080, 540, 135, 540, 540, 1080, 540, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 1080, 1080, 135, 1080, 135, 540, 1080, 1080, 1080, 540, 135, 1080, 540, 135, 135, 135, 135, 135, 1080, 540, 135, 1080, 135, 1080, 135, 135, 540, 540, 1080, 540, 1080, 135, 540, 135, 1080, 1080, 135, 1080, 540, 135, 1080, 135, 135, 1080, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 135, 540, 1080, 1080, 135, 1080, 540, 135, 540, 1080, 135, 135, 135, 135, 135, 135, 1080, 135, 135, 135, 1080, 135, 540, 1080, 1080, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 1080, 135, 135, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 540, 1080, 540, 1080, 135, 1080, 135, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 540, 540, 135, 540, 1080, 540, 540, 1080, 135, 1080, 1080, 540, 135, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 135, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 1080, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 1080, 540, 135, 135, 135, 135]
Prompts retrieved: 150255 . Total input tokens: 33450605 . Total output tokens: 30090347
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.7974228309467435,
    "estimated_duration": 3599.964748499407,
    "input_throughput": 3457.805248006597,
    "output_throughput": 3026.9851960473425,
    "total_throughput": 6484.79044405394,
    "itl": 94.16549162801927,
    "ttft": 34772.09454174833,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6670,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.80844151683121,
    "arrivals": 50289,
    "finished_requests": 49920,
    "scheduler_time": 37.770149245678915
}
#Debug simulation 
Total elapsed time: 4.79748800676316. Arrivals time: 0.1173574929125607 Scheduler time: 4.431178905535489 Scheduler overhead time: 0.05348100559785962 Adapter cache time: 0.11701879231259227 Engine time: 0.05390638904646039 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_256_slots_128_rate_0.1-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_256_slots_128_rate_0.1-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 135, 1080, 1080, 135, 1080, 540, 1080, 135, 540, 135, 1080, 540, 540, 540, 540, 1080, 135, 135, 135, 540, 1080, 135, 1080, 1080, 540, 540, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 135, 540, 540, 1080, 540, 135, 540, 1080, 540, 540, 1080, 540, 1080, 135, 1080, 1080, 540, 135, 135, 1080, 540, 135, 540, 540, 1080, 540, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 1080, 1080, 135, 1080, 135, 540, 1080, 1080, 1080, 540, 135, 1080, 540, 135, 135, 135, 135, 135, 1080, 540, 135, 1080, 135, 1080, 135, 135, 540, 540, 1080, 540, 1080, 135, 540, 135, 1080, 1080, 135, 1080, 540, 135, 1080, 135, 135, 1080, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 135, 540, 1080, 1080, 135, 1080, 540, 135, 540, 1080, 135, 135, 135, 135, 135, 135, 1080, 135, 135, 135, 1080, 135, 540, 1080, 1080, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 1080, 135, 135, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 540, 1080, 540, 1080, 135, 1080, 135, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 540, 540, 135, 540, 1080, 540, 540, 1080, 135, 1080, 1080, 540, 135, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 135, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 1080, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 1080, 540, 135, 135, 135, 135]
Prompts retrieved: 150255 . Total input tokens: 33450605 . Total output tokens: 30090347
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.833773788996041,
    "estimated_duration": 3599.9969828879834,
    "input_throughput": 3457.5976199887023,
    "output_throughput": 3026.7317033301647,
    "total_throughput": 6484.329323318867,
    "itl": 94.07626176132261,
    "ttft": 35194.865331931054,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6571,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.580852195119785,
    "arrivals": 50289,
    "finished_requests": 49917,
    "scheduler_time": 37.770640747123636
}
#Debug simulation 
Total elapsed time: 4.833840237930417. Arrivals time: 0.1194500089623034 Scheduler time: 4.463935890235007 Scheduler overhead time: 0.0541916792280972 Adapter cache time: 0.11688223946839571 Engine time: 0.054381285328418016 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-32/adapters_256_slots_128_rate_0.1-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-32/adapters_256_slots_128_rate_0.1-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 135, 1080, 1080, 135, 1080, 540, 1080, 135, 540, 135, 1080, 540, 540, 540, 540, 1080, 135, 135, 135, 540, 1080, 135, 1080, 1080, 540, 540, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 135, 540, 540, 1080, 540, 135, 540, 1080, 540, 540, 1080, 540, 1080, 135, 1080, 1080, 540, 135, 135, 1080, 540, 135, 540, 540, 1080, 540, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 1080, 1080, 135, 1080, 135, 540, 1080, 1080, 1080, 540, 135, 1080, 540, 135, 135, 135, 135, 135, 1080, 540, 135, 1080, 135, 1080, 135, 135, 540, 540, 1080, 540, 1080, 135, 540, 135, 1080, 1080, 135, 1080, 540, 135, 1080, 135, 135, 1080, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 135, 540, 1080, 1080, 135, 1080, 540, 135, 540, 1080, 135, 135, 135, 135, 135, 135, 1080, 135, 135, 135, 1080, 135, 540, 1080, 1080, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 1080, 135, 135, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 540, 1080, 540, 1080, 135, 1080, 135, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 540, 540, 135, 540, 1080, 540, 540, 1080, 135, 1080, 1080, 540, 135, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 135, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 1080, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 1080, 540, 135, 135, 135, 135]
Prompts retrieved: 150255 . Total input tokens: 33450605 . Total output tokens: 30090347
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 4.78150140075013,
    "estimated_duration": 3599.9599831257137,
    "input_throughput": 3457.666768060106,
    "output_throughput": 3026.9855918060816,
    "total_throughput": 6484.652359866188,
    "itl": 94.1784659285614,
    "ttft": 34783.84177676304,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6658,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.041100996918004,
    "arrivals": 50289,
    "finished_requests": 49920,
    "scheduler_time": 37.77182355003499
}
#Debug simulation 
Total elapsed time: 4.781566165853292. Arrivals time: 0.11788362171500921 Scheduler time: 4.415465885773301 Scheduler overhead time: 0.053272065706551075 Adapter cache time: 0.11711830319836736 Engine time: 0.05310807330533862 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_256_slots_128_rate_0.1-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_256_slots_128_rate_0.1-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 135, 1080, 1080, 135, 1080, 540, 1080, 135, 540, 135, 1080, 540, 540, 540, 540, 1080, 135, 135, 135, 540, 1080, 135, 1080, 1080, 540, 540, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 135, 540, 540, 1080, 540, 135, 540, 1080, 540, 540, 1080, 540, 1080, 135, 1080, 1080, 540, 135, 135, 1080, 540, 135, 540, 540, 1080, 540, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 1080, 1080, 135, 1080, 135, 540, 1080, 1080, 1080, 540, 135, 1080, 540, 135, 135, 135, 135, 135, 1080, 540, 135, 1080, 135, 1080, 135, 135, 540, 540, 1080, 540, 1080, 135, 540, 135, 1080, 1080, 135, 1080, 540, 135, 1080, 135, 135, 1080, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 135, 540, 1080, 1080, 135, 1080, 540, 135, 540, 1080, 135, 135, 135, 135, 135, 135, 1080, 135, 135, 135, 1080, 135, 540, 1080, 1080, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 1080, 135, 135, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 540, 1080, 540, 1080, 135, 1080, 135, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 540, 540, 135, 540, 1080, 540, 540, 1080, 135, 1080, 1080, 540, 135, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 135, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 1080, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 1080, 540, 135, 135, 135, 135]
Prompts retrieved: 150255 . Total input tokens: 33450605 . Total output tokens: 30090347
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.815487226005644,
    "estimated_duration": 3599.975463358538,
    "input_throughput": 3457.61856620752,
    "output_throughput": 3026.842296817833,
    "total_throughput": 6484.460863025352,
    "itl": 94.02064351861847,
    "ttft": 35090.98838857215,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6582,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.68051104104674,
    "arrivals": 50289,
    "finished_requests": 49918,
    "scheduler_time": 37.765069826824394
}
#Debug simulation 
Total elapsed time: 4.815550591796637. Arrivals time: 0.11816758569329977 Scheduler time: 4.448776726145297 Scheduler overhead time: 0.054008989594876766 Adapter cache time: 0.11575265089049935 Engine time: 0.05396055057644844 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-32/adapters_256_slots_128_rate_0.1-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-32/adapters_256_slots_128_rate_0.1-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 135, 1080, 1080, 135, 1080, 540, 1080, 135, 540, 135, 1080, 540, 540, 540, 540, 1080, 135, 135, 135, 540, 1080, 135, 1080, 1080, 540, 540, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 135, 540, 540, 1080, 540, 135, 540, 1080, 540, 540, 1080, 540, 1080, 135, 1080, 1080, 540, 135, 135, 1080, 540, 135, 540, 540, 1080, 540, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 1080, 1080, 135, 1080, 135, 540, 1080, 1080, 1080, 540, 135, 1080, 540, 135, 135, 135, 135, 135, 1080, 540, 135, 1080, 135, 1080, 135, 135, 540, 540, 1080, 540, 1080, 135, 540, 135, 1080, 1080, 135, 1080, 540, 135, 1080, 135, 135, 1080, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 135, 540, 1080, 1080, 135, 1080, 540, 135, 540, 1080, 135, 135, 135, 135, 135, 135, 1080, 135, 135, 135, 1080, 135, 540, 1080, 1080, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 1080, 135, 135, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 540, 1080, 540, 1080, 135, 1080, 135, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 540, 540, 135, 540, 1080, 540, 540, 1080, 135, 1080, 1080, 540, 135, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 135, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 1080, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 1080, 540, 135, 135, 135, 135]
Prompts retrieved: 150255 . Total input tokens: 33450605 . Total output tokens: 30090347
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.848551971837878,
    "estimated_duration": 3600.0266428776495,
    "input_throughput": 3457.7457988060387,
    "output_throughput": 3026.933153830647,
    "total_throughput": 6484.678952636686,
    "itl": 94.20228914724382,
    "ttft": 34781.06416975963,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6669,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.36823193210934,
    "arrivals": 50289,
    "finished_requests": 49920,
    "scheduler_time": 37.77349884799768
}
#Debug simulation 
Total elapsed time: 4.848617197945714. Arrivals time: 0.11870464729145169 Scheduler time: 4.479081955272704 Scheduler overhead time: 0.05414248676970601 Adapter cache time: 0.11790398601442575 Engine time: 0.054023541044443846 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_256_slots_128_rate_0.1-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_256_slots_128_rate_0.1-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 66, 1080, 1080, 66, 1080, 540, 1080, 66, 540, 66, 1080, 540, 540, 540, 540, 1080, 66, 66, 66, 540, 1080, 66, 1080, 1080, 540, 540, 540, 66, 1080, 66, 540, 540, 66, 540, 66, 66, 540, 540, 1080, 540, 66, 540, 1080, 540, 540, 1080, 540, 1080, 66, 1080, 1080, 540, 66, 66, 1080, 540, 66, 540, 540, 1080, 540, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 1080, 1080, 66, 1080, 66, 540, 1080, 1080, 1080, 540, 66, 1080, 540, 66, 66, 66, 66, 66, 1080, 540, 66, 1080, 66, 1080, 66, 66, 540, 540, 1080, 540, 1080, 66, 540, 66, 1080, 1080, 66, 1080, 540, 66, 1080, 66, 66, 1080, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 66, 540, 1080, 1080, 66, 1080, 540, 66, 540, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 540, 1080, 1080, 540, 66, 1080, 66, 540, 540, 66, 540, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 540, 1080, 540, 1080, 66, 1080, 66, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 540, 540, 66, 540, 1080, 540, 540, 1080, 66, 1080, 1080, 540, 66, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 66, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 1080, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 1080, 540, 66, 66, 66, 66]
Prompts retrieved: 144390 . Total input tokens: 32113289 . Total output tokens: 28897004
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.178820367902517,
    "estimated_duration": 3600.089007505975,
    "input_throughput": 3304.614406809289,
    "output_throughput": 2930.9339235781345,
    "total_throughput": 6235.548330387423,
    "itl": 89.91773774229185,
    "ttft": 30642.74973849375,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7421,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.711879547725346,
    "arrivals": 48457,
    "finished_requests": 48099,
    "scheduler_time": 35.86641845163515
}
#Debug simulation 
Total elapsed time: 4.178884087130427. Arrivals time: 0.11565856402739882 Scheduler time: 3.8037418671883643 Scheduler overhead time: 0.05454235663637519 Adapter cache time: 0.12507588230073452 Engine time: 0.05455563310533762 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_256_slots_128_rate_0.1-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_256_slots_128_rate_0.1-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 66, 1080, 1080, 66, 1080, 540, 1080, 66, 540, 66, 1080, 540, 540, 540, 540, 1080, 66, 66, 66, 540, 1080, 66, 1080, 1080, 540, 540, 540, 66, 1080, 66, 540, 540, 66, 540, 66, 66, 540, 540, 1080, 540, 66, 540, 1080, 540, 540, 1080, 540, 1080, 66, 1080, 1080, 540, 66, 66, 1080, 540, 66, 540, 540, 1080, 540, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 1080, 1080, 66, 1080, 66, 540, 1080, 1080, 1080, 540, 66, 1080, 540, 66, 66, 66, 66, 66, 1080, 540, 66, 1080, 66, 1080, 66, 66, 540, 540, 1080, 540, 1080, 66, 540, 66, 1080, 1080, 66, 1080, 540, 66, 1080, 66, 66, 1080, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 66, 540, 1080, 1080, 66, 1080, 540, 66, 540, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 540, 1080, 1080, 540, 66, 1080, 66, 540, 540, 66, 540, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 540, 1080, 540, 1080, 66, 1080, 66, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 540, 540, 66, 540, 1080, 540, 540, 1080, 66, 1080, 1080, 540, 66, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 66, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 1080, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 1080, 540, 66, 66, 66, 66]
Prompts retrieved: 144390 . Total input tokens: 32113289 . Total output tokens: 28897004
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.227023837156594,
    "estimated_duration": 3600.0571215456716,
    "input_throughput": 3304.773951723273,
    "output_throughput": 2930.93905006422,
    "total_throughput": 6235.713001787492,
    "itl": 89.99720759021996,
    "ttft": 30658.681088804093,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7395,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.13110858985037,
    "arrivals": 48457,
    "finished_requests": 48099,
    "scheduler_time": 35.8730386689293
}
#Debug simulation 
Total elapsed time: 4.227089245803654. Arrivals time: 0.11480673402547836 Scheduler time: 3.850226396229118 Scheduler overhead time: 0.055106275249272585 Adapter cache time: 0.12620929023250937 Engine time: 0.05526127852499485 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-32/adapters_256_slots_128_rate_0.1-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-32/adapters_256_slots_128_rate_0.1-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 66, 1080, 1080, 66, 1080, 540, 1080, 66, 540, 66, 1080, 540, 540, 540, 540, 1080, 66, 66, 66, 540, 1080, 66, 1080, 1080, 540, 540, 540, 66, 1080, 66, 540, 540, 66, 540, 66, 66, 540, 540, 1080, 540, 66, 540, 1080, 540, 540, 1080, 540, 1080, 66, 1080, 1080, 540, 66, 66, 1080, 540, 66, 540, 540, 1080, 540, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 1080, 1080, 66, 1080, 66, 540, 1080, 1080, 1080, 540, 66, 1080, 540, 66, 66, 66, 66, 66, 1080, 540, 66, 1080, 66, 1080, 66, 66, 540, 540, 1080, 540, 1080, 66, 540, 66, 1080, 1080, 66, 1080, 540, 66, 1080, 66, 66, 1080, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 66, 540, 1080, 1080, 66, 1080, 540, 66, 540, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 540, 1080, 1080, 540, 66, 1080, 66, 540, 540, 66, 540, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 540, 1080, 540, 1080, 66, 1080, 66, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 540, 540, 66, 540, 1080, 540, 540, 1080, 66, 1080, 1080, 540, 66, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 66, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 1080, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 1080, 540, 66, 66, 66, 66]
Prompts retrieved: 144390 . Total input tokens: 32113289 . Total output tokens: 28897004
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.2056364100426435,
    "estimated_duration": 3600.0107225898378,
    "input_throughput": 3304.816545502137,
    "output_throughput": 2930.976825649354,
    "total_throughput": 6235.793371151492,
    "itl": 90.00436969601387,
    "ttft": 30519.636895050477,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7400,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.190402836334048,
    "arrivals": 48457,
    "finished_requests": 48099,
    "scheduler_time": 35.87330309875353
}
#Debug simulation 
Total elapsed time: 4.205699888058007. Arrivals time: 0.11425660224631429 Scheduler time: 3.830393456388265 Scheduler overhead time: 0.05451671592891216 Adapter cache time: 0.12621671706438065 Engine time: 0.054869274608790874 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_256_slots_128_rate_0.1-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_256_slots_128_rate_0.1-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 66, 1080, 1080, 66, 1080, 540, 1080, 66, 540, 66, 1080, 540, 540, 540, 540, 1080, 66, 66, 66, 540, 1080, 66, 1080, 1080, 540, 540, 540, 66, 1080, 66, 540, 540, 66, 540, 66, 66, 540, 540, 1080, 540, 66, 540, 1080, 540, 540, 1080, 540, 1080, 66, 1080, 1080, 540, 66, 66, 1080, 540, 66, 540, 540, 1080, 540, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 1080, 1080, 66, 1080, 66, 540, 1080, 1080, 1080, 540, 66, 1080, 540, 66, 66, 66, 66, 66, 1080, 540, 66, 1080, 66, 1080, 66, 66, 540, 540, 1080, 540, 1080, 66, 540, 66, 1080, 1080, 66, 1080, 540, 66, 1080, 66, 66, 1080, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 66, 540, 1080, 1080, 66, 1080, 540, 66, 540, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 540, 1080, 1080, 540, 66, 1080, 66, 540, 540, 66, 540, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 540, 1080, 540, 1080, 66, 1080, 66, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 540, 540, 66, 540, 1080, 540, 540, 1080, 66, 1080, 1080, 540, 66, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 66, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 1080, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 1080, 540, 66, 66, 66, 66]
Prompts retrieved: 144390 . Total input tokens: 32113289 . Total output tokens: 28897004
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.203666273970157,
    "estimated_duration": 3600.0457109111812,
    "input_throughput": 3304.784426470169,
    "output_throughput": 2930.9483399113215,
    "total_throughput": 6235.73276638149,
    "itl": 89.94614841471564,
    "ttft": 30574.87938950678,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7420,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.226865464240618,
    "arrivals": 48457,
    "finished_requests": 48099,
    "scheduler_time": 35.868533211586325
}
#Debug simulation 
Total elapsed time: 4.203730334993452. Arrivals time: 0.11411662911996245 Scheduler time: 3.8272631517611444 Scheduler overhead time: 0.05479492852464318 Adapter cache time: 0.12715037632733583 Engine time: 0.05503695271909237 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-32/adapters_256_slots_128_rate_0.1-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-32/adapters_256_slots_128_rate_0.1-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 66, 1080, 1080, 66, 1080, 540, 1080, 66, 540, 66, 1080, 540, 540, 540, 540, 1080, 66, 66, 66, 540, 1080, 66, 1080, 1080, 540, 540, 540, 66, 1080, 66, 540, 540, 66, 540, 66, 66, 540, 540, 1080, 540, 66, 540, 1080, 540, 540, 1080, 540, 1080, 66, 1080, 1080, 540, 66, 66, 1080, 540, 66, 540, 540, 1080, 540, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 1080, 1080, 66, 1080, 66, 540, 1080, 1080, 1080, 540, 66, 1080, 540, 66, 66, 66, 66, 66, 1080, 540, 66, 1080, 66, 1080, 66, 66, 540, 540, 1080, 540, 1080, 66, 540, 66, 1080, 1080, 66, 1080, 540, 66, 1080, 66, 66, 1080, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 66, 540, 1080, 1080, 66, 1080, 540, 66, 540, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 540, 1080, 1080, 540, 66, 1080, 66, 540, 540, 66, 540, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 540, 1080, 540, 1080, 66, 1080, 66, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 540, 540, 66, 540, 1080, 540, 540, 1080, 66, 1080, 1080, 540, 66, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 66, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 1080, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 1080, 540, 66, 66, 66, 66]
Prompts retrieved: 144390 . Total input tokens: 32113289 . Total output tokens: 28897004
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 4.280232694000006,
    "estimated_duration": 3600.0338616905497,
    "input_throughput": 3304.795303901136,
    "output_throughput": 2930.9579868910096,
    "total_throughput": 6235.753290792145,
    "itl": 90.02430738907206,
    "ttft": 30508.413536414435,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7412,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.533489916509982,
    "arrivals": 48457,
    "finished_requests": 48099,
    "scheduler_time": 35.87442171274096
}
#Debug simulation 
Total elapsed time: 4.280295763164759. Arrivals time: 0.11606687121093273 Scheduler time: 3.899227086920291 Scheduler overhead time: 0.0559536530636251 Adapter cache time: 0.12736981688067317 Engine time: 0.05573551310226321 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_256_slots_128_rate_0.1-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_256_slots_128_rate_0.1-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 66, 1080, 1080, 66, 1080, 540, 1080, 66, 540, 66, 1080, 540, 540, 540, 540, 1080, 66, 66, 66, 540, 1080, 66, 1080, 1080, 540, 540, 540, 66, 1080, 66, 540, 540, 66, 540, 66, 66, 540, 540, 1080, 540, 66, 540, 1080, 540, 540, 1080, 540, 1080, 66, 1080, 1080, 540, 66, 66, 1080, 540, 66, 540, 540, 1080, 540, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 1080, 1080, 66, 1080, 66, 540, 1080, 1080, 1080, 540, 66, 1080, 540, 66, 66, 66, 66, 66, 1080, 540, 66, 1080, 66, 1080, 66, 66, 540, 540, 1080, 540, 1080, 66, 540, 66, 1080, 1080, 66, 1080, 540, 66, 1080, 66, 66, 1080, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 66, 540, 1080, 1080, 66, 1080, 540, 66, 540, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 540, 1080, 1080, 540, 66, 1080, 66, 540, 540, 66, 540, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 540, 1080, 540, 1080, 66, 1080, 66, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 540, 540, 66, 540, 1080, 540, 540, 1080, 66, 1080, 1080, 540, 66, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 66, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 1080, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 1080, 540, 66, 66, 66, 66]
Prompts retrieved: 144390 . Total input tokens: 32113289 . Total output tokens: 28897004
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.22608777275309,
    "estimated_duration": 3600.076753379975,
    "input_throughput": 3304.5623232423204,
    "output_throughput": 2930.943344497721,
    "total_throughput": 6235.505667740042,
    "itl": 89.8796171655489,
    "ttft": 30755.570530208606,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7369,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.033680623133968,
    "arrivals": 48457,
    "finished_requests": 48098,
    "scheduler_time": 35.86442429166722
}
#Debug simulation 
Total elapsed time: 4.226149910595268. Arrivals time: 0.11454704171046615 Scheduler time: 3.849640675354749 Scheduler overhead time: 0.0549162644892931 Adapter cache time: 0.12607964593917131 Engine time: 0.05554628884419799 
