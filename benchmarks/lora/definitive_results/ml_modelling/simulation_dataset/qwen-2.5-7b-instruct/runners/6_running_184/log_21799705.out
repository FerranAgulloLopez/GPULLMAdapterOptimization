INFO 06-01 00:46:59 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:46:59 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_16-16-16/adapters_32_slots_16_rate_1.6-0.8-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_16-16-16/adapters_32_slots_16_rate_1.6-0.8-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 1080, 1080, 8640, 1080, 17280, 8640, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 8640, 8640, 8640, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 8640, 1080, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 295920 . Total input tokens: 66039020 . Total output tokens: 59116830
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 57.51088253222406,
    "estimated_duration": 3600.0436630474005,
    "input_throughput": 6498.24257414624,
    "output_throughput": 5703.091107128516,
    "total_throughput": 12201.333681274757,
    "itl": 66.81840833998727,
    "ttft": 294308.20417003456,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 92,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.27508462713100046,
    "arrivals": 98647,
    "finished_requests": 93837,
    "scheduler_time": 93.65636213569293
}
#Debug simulation 
Total elapsed time: 57.51108498033136. Arrivals time: 0.2920248215086758 Scheduler time: 56.931742375250906 Scheduler overhead time: 0.11466459091752768 Adapter cache time: 0.018336884677410126 Engine time: 0.1084554623812437 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_16-16-32/adapters_32_slots_16_rate_1.6-0.8-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_16-16-32/adapters_32_slots_16_rate_1.6-0.8-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 1080, 1080, 8640, 1080, 17280, 8640, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 8640, 8640, 8640, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 8640, 1080, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 295920 . Total input tokens: 66039020 . Total output tokens: 59116830
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 57.69252877216786,
    "estimated_duration": 3600.0027876722024,
    "input_throughput": 6491.769695298354,
    "output_throughput": 5700.63225236276,
    "total_throughput": 12192.401947661114,
    "itl": 66.88666843511417,
    "ttft": 295069.26821598504,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 91,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.30751829978078565,
    "arrivals": 98647,
    "finished_requests": 93803,
    "scheduler_time": 93.59070240873262
}
#Debug simulation 
Total elapsed time: 57.69272634293884. Arrivals time: 0.2977530173957348 Scheduler time: 57.111288307700306 Scheduler overhead time: 0.11352228419855237 Adapter cache time: 0.018251352477818727 Engine time: 0.1065364251844585 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-8/adapters_32_slots_16_rate_1.6-0.8-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-8/adapters_32_slots_16_rate_1.6-0.8-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 540, 540, 8640, 540, 17280, 8640, 540, 540, 540, 17280, 17280, 540, 540, 8640, 8640, 8640, 17280, 17280, 540, 17280, 17280, 17280, 17280, 8640, 540, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 290520 . Total input tokens: 64833163 . Total output tokens: 58016128
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 73.91828220291063,
    "estimated_duration": 3600.0333616019084,
    "input_throughput": 6325.921376980366,
    "output_throughput": 5574.4608408490485,
    "total_throughput": 11900.382217829414,
    "itl": 65.50398532772526,
    "ttft": 348751.66523323196,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 57,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.17444780140416682,
    "arrivals": 96919,
    "finished_requests": 91648,
    "scheduler_time": 98.79119694716097
}
#Debug simulation 
Total elapsed time: 73.91844368493184. Arrivals time: 0.32282857736572623 Scheduler time: 73.28218493796885 Scheduler overhead time: 0.12785883573815227 Adapter cache time: 0.020094807725399733 Engine time: 0.11807921715080738 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-16/adapters_32_slots_16_rate_1.6-0.8-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-16/adapters_32_slots_16_rate_1.6-0.8-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 540, 540, 8640, 540, 17280, 8640, 540, 540, 540, 17280, 17280, 540, 540, 8640, 8640, 8640, 17280, 17280, 540, 17280, 17280, 17280, 17280, 8640, 540, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 290520 . Total input tokens: 64833163 . Total output tokens: 58016128
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 74.1447673770599,
    "estimated_duration": 3600.0173546135466,
    "input_throughput": 6325.863671411287,
    "output_throughput": 5574.485071379407,
    "total_throughput": 11900.348742790695,
    "itl": 65.50524856313758,
    "ttft": 348791.60943710996,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 57,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.18718527486547826,
    "arrivals": 96919,
    "finished_requests": 91647,
    "scheduler_time": 98.7911222147219
}
#Debug simulation 
Total elapsed time: 74.14493018528447. Arrivals time: 0.3109234687872231 Scheduler time: 73.52096281060949 Scheduler overhead time: 0.1286953049711883 Adapter cache time: 0.020249121822416782 Engine time: 0.11643117247149348 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-32/adapters_32_slots_16_rate_1.6-0.8-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-32/adapters_32_slots_16_rate_1.6-0.8-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 540, 540, 8640, 540, 17280, 8640, 540, 540, 540, 17280, 17280, 540, 540, 8640, 8640, 8640, 17280, 17280, 540, 17280, 17280, 17280, 17280, 8640, 540, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 290520 . Total input tokens: 64833163 . Total output tokens: 58016128
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 74.1868676431477,
    "estimated_duration": 3600.019061780329,
    "input_throughput": 6325.860671620412,
    "output_throughput": 5574.482427900142,
    "total_throughput": 11900.343099520554,
    "itl": 65.5053317986982,
    "ttft": 348791.74447672727,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 57,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.18730772165581577,
    "arrivals": 96919,
    "finished_requests": 91647,
    "scheduler_time": 98.79120635601232
}
#Debug simulation 
Total elapsed time: 74.1870308262296. Arrivals time: 0.3061790904030204 Scheduler time: 73.56703954050317 Scheduler overhead time: 0.1271618497557938 Adapter cache time: 0.02040791418403387 Engine time: 0.1182773057371378 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-16-16/adapters_32_slots_16_rate_1.6-0.8-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-16-16/adapters_32_slots_16_rate_1.6-0.8-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 540, 540, 8640, 540, 17280, 8640, 540, 540, 540, 17280, 17280, 540, 540, 8640, 8640, 8640, 17280, 17280, 540, 17280, 17280, 17280, 17280, 8640, 540, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 290520 . Total input tokens: 64833163 . Total output tokens: 58016128
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 73.86773397028446,
    "estimated_duration": 3600.000391957449,
    "input_throughput": 6325.863755702939,
    "output_throughput": 5574.510781952493,
    "total_throughput": 11900.37453765543,
    "itl": 65.50566956847113,
    "ttft": 348793.1229654721,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 57,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.1790133684966714,
    "arrivals": 96919,
    "finished_requests": 91646,
    "scheduler_time": 98.79048038483822
}
#Debug simulation 
Total elapsed time: 73.86789121711627. Arrivals time: 0.31626515183597803 Scheduler time: 73.23997785011306 Scheduler overhead time: 0.12586730998009443 Adapter cache time: 0.019817997701466084 Engine time: 0.11859421152621508 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-16-32/adapters_32_slots_16_rate_1.6-0.8-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-16-32/adapters_32_slots_16_rate_1.6-0.8-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 540, 540, 8640, 540, 17280, 8640, 540, 540, 540, 17280, 17280, 540, 540, 8640, 8640, 8640, 17280, 17280, 540, 17280, 17280, 17280, 17280, 8640, 540, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 290520 . Total input tokens: 64833163 . Total output tokens: 58016128
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 78.85576718626544,
    "estimated_duration": 3600.0912711615442,
    "input_throughput": 6191.665522082196,
    "output_throughput": 5425.392171709626,
    "total_throughput": 11617.057693791823,
    "itl": 64.44297195834064,
    "ttft": 435067.6775085426,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 68,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.22570225104689579,
    "arrivals": 96919,
    "finished_requests": 89736,
    "scheduler_time": 99.86054079644177
}
#Debug simulation 
Total elapsed time: 78.8560341950506. Arrivals time: 0.3293855497613549 Scheduler time: 78.2054777815938 Scheduler overhead time: 0.1303948829881847 Adapter cache time: 0.020111773163080215 Engine time: 0.12133398279547691 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_16-16-16/adapters_32_slots_16_rate_1.6-0.8-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_16-16-16/adapters_32_slots_16_rate_1.6-0.8-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 540, 540, 8640, 540, 17280, 8640, 540, 540, 540, 17280, 17280, 540, 540, 8640, 8640, 8640, 17280, 17280, 540, 17280, 17280, 17280, 17280, 8640, 540, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 290520 . Total input tokens: 64833163 . Total output tokens: 58016128
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 73.77350856084377,
    "estimated_duration": 3600.0282796853685,
    "input_throughput": 6325.930306855906,
    "output_throughput": 5574.468709938552,
    "total_throughput": 11900.399016794458,
    "itl": 65.50363706690169,
    "ttft": 348751.6225778421,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 57,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.17043286680942416,
    "arrivals": 96919,
    "finished_requests": 91648,
    "scheduler_time": 98.79120990529171
}
#Debug simulation 
Total elapsed time: 73.77366695692763. Arrivals time: 0.3114244951866567 Scheduler time: 73.15255967853591 Scheduler overhead time: 0.12668105214834213 Adapter cache time: 0.01919653732329607 Engine time: 0.11649943515658379 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_16-16-32/adapters_32_slots_16_rate_1.6-0.8-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_16-16-32/adapters_32_slots_16_rate_1.6-0.8-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 540, 540, 8640, 540, 17280, 8640, 540, 540, 540, 17280, 17280, 540, 540, 8640, 8640, 8640, 17280, 17280, 540, 17280, 17280, 17280, 17280, 8640, 540, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 290520 . Total input tokens: 64833163 . Total output tokens: 58016128
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 79.46087315492332,
    "estimated_duration": 3600.0954705677614,
    "input_throughput": 6191.658299685207,
    "output_throughput": 5425.385843148119,
    "total_throughput": 11617.044142833327,
    "itl": 64.4427681106249,
    "ttft": 435068.3771847605,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 68,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2287203419208524,
    "arrivals": 96919,
    "finished_requests": 89736,
    "scheduler_time": 99.86072825921016
}
#Debug simulation 
Total elapsed time: 79.46102962084115. Arrivals time: 0.3242445639334619 Scheduler time: 78.80867307260633 Scheduler overhead time: 0.13516181148588657 Adapter cache time: 0.02132918080314994 Engine time: 0.12263025948777795 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-8/adapters_32_slots_16_rate_1.6-0.8-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-8/adapters_32_slots_16_rate_1.6-0.8-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 270, 270, 8640, 270, 17280, 8640, 270, 270, 270, 17280, 17280, 270, 270, 8640, 8640, 8640, 17280, 17280, 270, 17280, 17280, 17280, 17280, 8640, 270, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 287820 . Total input tokens: 64223371 . Total output tokens: 57461548
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 90.66540130088106,
    "estimated_duration": 3600.0176915590864,
    "input_throughput": 6150.8747726209795,
    "output_throughput": 5450.739046646692,
    "total_throughput": 11601.613819267672,
    "itl": 67.78522778338865,
    "ttft": 474860.76532527886,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 78,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23871804402675456,
    "arrivals": 96050,
    "finished_requests": 89626,
    "scheduler_time": 106.77925641477064
}
#Debug simulation 
Total elapsed time: 90.66556175611913. Arrivals time: 0.3377365148626268 Scheduler time: 90.00097599811852 Scheduler overhead time: 0.1333769392222166 Adapter cache time: 0.021457921713590622 Engine time: 0.12344530783593655 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-16/adapters_32_slots_16_rate_1.6-0.8-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-16/adapters_32_slots_16_rate_1.6-0.8-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 270, 270, 8640, 270, 17280, 8640, 270, 270, 270, 17280, 17280, 270, 270, 8640, 8640, 8640, 17280, 17280, 270, 17280, 17280, 17280, 17280, 8640, 270, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 287820 . Total input tokens: 64223371 . Total output tokens: 57461548
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 82.46136722806841,
    "estimated_duration": 3600.0290881671795,
    "input_throughput": 6153.398058035713,
    "output_throughput": 5454.81648038508,
    "total_throughput": 11608.214538420792,
    "itl": 66.82558886996735,
    "ttft": 444476.77474137425,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 73,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2403378187236376,
    "arrivals": 96050,
    "finished_requests": 89682,
    "scheduler_time": 102.45091470915168
}
#Debug simulation 
Total elapsed time: 82.46152146393433. Arrivals time: 0.32714092917740345 Scheduler time: 81.80668271938339 Scheduler overhead time: 0.1344264280050993 Adapter cache time: 0.021524077281355858 Engine time: 0.12319577904418111 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-32/adapters_32_slots_16_rate_1.6-0.8-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-32/adapters_32_slots_16_rate_1.6-0.8-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 270, 270, 8640, 270, 17280, 8640, 270, 270, 270, 17280, 17280, 270, 270, 8640, 8640, 8640, 17280, 17280, 270, 17280, 17280, 17280, 17280, 8640, 270, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 287820 . Total input tokens: 64223371 . Total output tokens: 57461548
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 82.98069738317281,
    "estimated_duration": 3600.029240157962,
    "input_throughput": 6153.397798243438,
    "output_throughput": 5454.816250086443,
    "total_throughput": 11608.21404832988,
    "itl": 66.82558549933303,
    "ttft": 444476.81984142604,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 73,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2403882406651973,
    "arrivals": 96050,
    "finished_requests": 89682,
    "scheduler_time": 102.45091623940581
}
#Debug simulation 
Total elapsed time: 82.98085385607556. Arrivals time: 0.3271957980468869 Scheduler time: 82.32324068294838 Scheduler overhead time: 0.13580828998237848 Adapter cache time: 0.02073876466602087 Engine time: 0.1253164396621287 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-16-16/adapters_32_slots_16_rate_1.6-0.8-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-16-16/adapters_32_slots_16_rate_1.6-0.8-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 270, 270, 8640, 270, 17280, 8640, 270, 270, 270, 17280, 17280, 270, 270, 8640, 8640, 8640, 17280, 17280, 270, 17280, 17280, 17280, 17280, 8640, 270, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 287820 . Total input tokens: 64223371 . Total output tokens: 57461548
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 92.84431478986517,
    "estimated_duration": 3600.0246427138313,
    "input_throughput": 6150.862896123843,
    "output_throughput": 5450.728522015795,
    "total_throughput": 11601.591418139638,
    "itl": 67.78522595804682,
    "ttft": 474926.45572736894,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 78,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24507318723713992,
    "arrivals": 96050,
    "finished_requests": 89626,
    "scheduler_time": 106.7795189101167
}
#Debug simulation 
Total elapsed time: 92.84447525581345. Arrivals time: 0.34365929989144206 Scheduler time: 92.16909218439832 Scheduler overhead time: 0.13553508883342147 Adapter cache time: 0.021265122573822737 Engine time: 0.12537454906851053 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-16-32/adapters_32_slots_16_rate_1.6-0.8-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-16-32/adapters_32_slots_16_rate_1.6-0.8-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 270, 270, 8640, 270, 17280, 8640, 270, 270, 270, 17280, 17280, 270, 270, 8640, 8640, 8640, 17280, 17280, 270, 17280, 17280, 17280, 17280, 8640, 270, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 287820 . Total input tokens: 64223371 . Total output tokens: 57461548
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 83.28142671426758,
    "estimated_duration": 3600.0332638448667,
    "input_throughput": 6153.390920710836,
    "output_throughput": 5454.810153344801,
    "total_throughput": 11608.201074055636,
    "itl": 66.82579544884528,
    "ttft": 444477.3899981616,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 73,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24365783911198358,
    "arrivals": 96050,
    "finished_requests": 89682,
    "scheduler_time": 102.45105049670316
}
#Debug simulation 
Total elapsed time: 83.2816967992112. Arrivals time: 0.32358400942757726 Scheduler time: 82.62900258833542 Scheduler overhead time: 0.13367340480908751 Adapter cache time: 0.021253254264593124 Engine time: 0.12485073460265994 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_16-16-16/adapters_32_slots_16_rate_1.6-0.8-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_16-16-16/adapters_32_slots_16_rate_1.6-0.8-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 270, 270, 8640, 270, 17280, 8640, 270, 270, 270, 17280, 17280, 270, 270, 8640, 8640, 8640, 17280, 17280, 270, 17280, 17280, 17280, 17280, 8640, 270, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 287820 . Total input tokens: 64223371 . Total output tokens: 57461548
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 83.21986704925075,
    "estimated_duration": 3600.0227050355015,
    "input_throughput": 6153.408968508587,
    "output_throughput": 5454.826152216267,
    "total_throughput": 11608.235120724854,
    "itl": 66.82326039678588,
    "ttft": 444445.7727899088,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 73,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21827367152785904,
    "arrivals": 96050,
    "finished_requests": 89682,
    "scheduler_time": 102.45162822246698
}
#Debug simulation 
Total elapsed time: 83.22001893585548. Arrivals time: 0.32598371151834726 Scheduler time: 82.56888272194192 Scheduler overhead time: 0.13287547137588263 Adapter cache time: 0.020794393960386515 Engine time: 0.12221081741154194 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_16-16-32/adapters_32_slots_16_rate_1.6-0.8-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_16-16-32/adapters_32_slots_16_rate_1.6-0.8-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 270, 270, 8640, 270, 17280, 8640, 270, 270, 270, 17280, 17280, 270, 270, 8640, 8640, 8640, 17280, 17280, 270, 17280, 17280, 17280, 17280, 8640, 270, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 287820 . Total input tokens: 64223371 . Total output tokens: 57461548
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 84.48709808196872,
    "estimated_duration": 3600.034992503603,
    "input_throughput": 6153.387965985953,
    "output_throughput": 5454.807534063253,
    "total_throughput": 11608.195500049205,
    "itl": 66.82575109993435,
    "ttft": 444477.7253569536,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 73,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2471789451315996,
    "arrivals": 96050,
    "finished_requests": 89682,
    "scheduler_time": 102.4511358710904
}
#Debug simulation 
Total elapsed time: 84.48725581588224. Arrivals time: 0.3406717455945909 Scheduler time: 83.81708750827238 Scheduler overhead time: 0.13364036846905947 Adapter cache time: 0.021511020604521036 Engine time: 0.124603564850986 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-8/adapters_32_slots_16_rate_1.6-0.8-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-8/adapters_32_slots_16_rate_1.6-0.8-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 135, 135, 8640, 135, 17280, 8640, 135, 135, 135, 17280, 17280, 135, 135, 8640, 8640, 8640, 17280, 17280, 135, 17280, 17280, 17280, 17280, 8640, 135, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 286470 . Total input tokens: 63900674 . Total output tokens: 57178861
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 120.7641717181541,
    "estimated_duration": 3600.0080607837704,
    "input_throughput": 6010.4215420254395,
    "output_throughput": 5340.720263780216,
    "total_throughput": 11351.141805805655,
    "itl": 60.6792506424547,
    "ttft": 565817.718145642,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 52,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.15914536268450308,
    "arrivals": 95612,
    "finished_requests": 87605,
    "scheduler_time": 112.51211105344188
}
#Debug simulation 
Total elapsed time: 120.76432388694957. Arrivals time: 0.37031715316697955 Scheduler time: 120.0309354509227 Scheduler overhead time: 0.1500246897339821 Adapter cache time: 0.02378807356581092 Engine time: 0.13738607987761497 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-16/adapters_32_slots_16_rate_1.6-0.8-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-16/adapters_32_slots_16_rate_1.6-0.8-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 135, 135, 8640, 135, 17280, 8640, 135, 135, 135, 17280, 17280, 135, 135, 8640, 8640, 8640, 17280, 17280, 135, 17280, 17280, 17280, 17280, 8640, 135, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 286470 . Total input tokens: 63900674 . Total output tokens: 57178861
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 120.65420923614874,
    "estimated_duration": 3600.048766242836,
    "input_throughput": 6019.983174455179,
    "output_throughput": 5341.811805530086,
    "total_throughput": 11361.794979985265,
    "itl": 60.67323976031873,
    "ttft": 575769.0824056535,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 55,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.17957079300191253,
    "arrivals": 95612,
    "finished_requests": 87681,
    "scheduler_time": 112.48813217259983
}
#Debug simulation 
Total elapsed time: 120.6543615553528. Arrivals time: 0.36495954915881157 Scheduler time: 119.92601444432512 Scheduler overhead time: 0.1483153011649847 Adapter cache time: 0.023860590998083353 Engine time: 0.13849250972270966 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-32/adapters_32_slots_16_rate_1.6-0.8-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-32/adapters_32_slots_16_rate_1.6-0.8-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 135, 135, 8640, 135, 17280, 8640, 135, 135, 135, 17280, 17280, 135, 135, 8640, 8640, 8640, 17280, 17280, 135, 17280, 17280, 17280, 17280, 8640, 135, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 286470 . Total input tokens: 63900674 . Total output tokens: 57178861
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 119.04732424393296,
    "estimated_duration": 3600.0490675163455,
    "input_throughput": 6019.9826706671965,
    "output_throughput": 5341.8113584955145,
    "total_throughput": 11361.794029162711,
    "itl": 60.67325951199033,
    "ttft": 575769.1132016589,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 55,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.1798716939799487,
    "arrivals": 95612,
    "finished_requests": 87681,
    "scheduler_time": 112.4881325451263
}
#Debug simulation 
Total elapsed time: 119.04747367976233. Arrivals time: 0.36657162895426154 Scheduler time: 118.32668066490442 Scheduler overhead time: 0.1440623765811324 Adapter cache time: 0.02299866545945406 Engine time: 0.13575908821076155 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-16/adapters_32_slots_16_rate_1.6-0.8-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-16/adapters_32_slots_16_rate_1.6-0.8-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 135, 135, 8640, 135, 17280, 8640, 135, 135, 135, 17280, 17280, 135, 135, 8640, 8640, 8640, 17280, 17280, 135, 17280, 17280, 17280, 17280, 8640, 135, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 286470 . Total input tokens: 63900674 . Total output tokens: 57178861
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 123.47774411691353,
    "estimated_duration": 3600.0393854908043,
    "input_throughput": 6010.230634476838,
    "output_throughput": 5340.546294434175,
    "total_throughput": 11350.776928911013,
    "itl": 60.69136292776717,
    "ttft": 565948.8557648985,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 52,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.16283733106683945,
    "arrivals": 95612,
    "finished_requests": 87604,
    "scheduler_time": 112.50619813616035
}
#Debug simulation 
Total elapsed time: 123.47790948394686. Arrivals time: 0.3692021267488599 Scheduler time: 122.74695900222287 Scheduler overhead time: 0.14852956123650074 Adapter cache time: 0.023410344496369362 Engine time: 0.13688259478658438 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-32/adapters_32_slots_16_rate_1.6-0.8-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-32/adapters_32_slots_16_rate_1.6-0.8-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 135, 135, 8640, 135, 17280, 8640, 135, 135, 135, 17280, 17280, 135, 135, 8640, 8640, 8640, 17280, 17280, 135, 17280, 17280, 17280, 17280, 8640, 135, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 286470 . Total input tokens: 63900674 . Total output tokens: 57178861
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 119.90920932497829,
    "estimated_duration": 3600.0057171543576,
    "input_throughput": 6012.98545078723,
    "output_throughput": 5340.546240909108,
    "total_throughput": 11353.531691696337,
    "itl": 60.69351050507212,
    "ttft": 574497.7615241533,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 53,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.17571097694337356,
    "arrivals": 95612,
    "finished_requests": 87613,
    "scheduler_time": 112.4954843665269
}
#Debug simulation 
Total elapsed time: 119.90946624381468. Arrivals time: 0.3683920339681208 Scheduler time: 119.17942466167733 Scheduler overhead time: 0.14762659184634686 Adapter cache time: 0.024621425196528435 Engine time: 0.13710923306643963 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-16/adapters_32_slots_16_rate_1.6-0.8-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-16/adapters_32_slots_16_rate_1.6-0.8-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 135, 135, 8640, 135, 17280, 8640, 135, 135, 135, 17280, 17280, 135, 135, 8640, 8640, 8640, 17280, 17280, 135, 17280, 17280, 17280, 17280, 8640, 135, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 286470 . Total input tokens: 63900674 . Total output tokens: 57178861
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 122.59868808789179,
    "estimated_duration": 3600.0045090557487,
    "input_throughput": 6010.427471846516,
    "output_throughput": 5340.725532880787,
    "total_throughput": 11351.153004727303,
    "itl": 60.67919209998285,
    "ttft": 565817.0015393771,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 52,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.15548261533491325,
    "arrivals": 95612,
    "finished_requests": 87605,
    "scheduler_time": 112.51201131111412
}
#Debug simulation 
Total elapsed time: 122.59884179895744. Arrivals time: 0.3677249075844884 Scheduler time: 121.86873935395852 Scheduler overhead time: 0.1502758921124041 Adapter cache time: 0.02469152817502618 Engine time: 0.13565213745459914 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-32/adapters_32_slots_16_rate_1.6-0.8-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-32/adapters_32_slots_16_rate_1.6-0.8-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 135, 135, 8640, 135, 17280, 8640, 135, 135, 135, 17280, 17280, 135, 135, 8640, 8640, 8640, 17280, 17280, 135, 17280, 17280, 17280, 17280, 8640, 135, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 286470 . Total input tokens: 63900674 . Total output tokens: 57178861
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 119.83397921361029,
    "estimated_duration": 3600.056866261597,
    "input_throughput": 6019.96962967562,
    "output_throughput": 5341.799786615537,
    "total_throughput": 11361.769416291158,
    "itl": 60.6731482487402,
    "ttft": 575769.4217398808,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 55,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.18452458407729846,
    "arrivals": 95612,
    "finished_requests": 87681,
    "scheduler_time": 112.4883610164068
}
#Debug simulation 
Total elapsed time: 119.8341301549226. Arrivals time: 0.366922527551651 Scheduler time: 119.10338232666254 Scheduler overhead time: 0.14769634138792753 Adapter cache time: 0.02432130603119731 Engine time: 0.13911900110542774 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-8/adapters_32_slots_16_rate_1.6-0.8-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-8/adapters_32_slots_16_rate_1.6-0.8-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 66, 66, 8640, 66, 17280, 8640, 66, 66, 66, 17280, 17280, 66, 66, 8640, 8640, 8640, 17280, 17280, 66, 17280, 17280, 17280, 17280, 8640, 66, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 285780 . Total input tokens: 63750125 . Total output tokens: 57041866
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 89.31230372423306,
    "estimated_duration": 3600.1125948137637,
    "input_throughput": 5981.398479320048,
    "output_throughput": 5268.619661319567,
    "total_throughput": 11250.018140639615,
    "itl": 62.59422394513517,
    "ttft": 529966.4053722338,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 101,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3091092621372078,
    "arrivals": 95376,
    "finished_requests": 86746,
    "scheduler_time": 101.48322845199465
}
#Debug simulation 
Total elapsed time: 89.31245936220512. Arrivals time: 0.33488161163404584 Scheduler time: 88.63856504485011 Scheduler overhead time: 0.14025667076930404 Adapter cache time: 0.021670492365956306 Engine time: 0.12632503360509872 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-16/adapters_32_slots_16_rate_1.6-0.8-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-16/adapters_32_slots_16_rate_1.6-0.8-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 66, 66, 8640, 66, 17280, 8640, 66, 66, 66, 17280, 17280, 66, 66, 8640, 8640, 8640, 17280, 17280, 66, 17280, 17280, 17280, 17280, 8640, 66, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 285780 . Total input tokens: 63750125 . Total output tokens: 57041866
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 67.89067737571895,
    "estimated_duration": 3600.014283965929,
    "input_throughput": 6002.506461222839,
    "output_throughput": 5322.024716772298,
    "total_throughput": 11324.531177995137,
    "itl": 60.5121241489876,
    "ttft": 397646.83538056136,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 78,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.25487947487970813,
    "arrivals": 95376,
    "finished_requests": 87031,
    "scheduler_time": 90.79632473118447
}
#Debug simulation 
Total elapsed time: 67.89084354182705. Arrivals time: 0.31590884178876877 Scheduler time: 67.25182823324576 Scheduler overhead time: 0.13183323619887233 Adapter cache time: 0.020903275348246098 Engine time: 0.12069686502218246 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-32/adapters_32_slots_16_rate_1.6-0.8-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-32/adapters_32_slots_16_rate_1.6-0.8-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 66, 66, 8640, 66, 17280, 8640, 66, 66, 66, 17280, 17280, 66, 66, 8640, 8640, 8640, 17280, 17280, 66, 17280, 17280, 17280, 17280, 8640, 66, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 285780 . Total input tokens: 63750125 . Total output tokens: 57041866
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 68.21204748703167,
    "estimated_duration": 3600.014136592816,
    "input_throughput": 6002.506706946336,
    "output_throughput": 5322.024934639039,
    "total_throughput": 11324.531641585374,
    "itl": 60.51212525845248,
    "ttft": 397646.73876791133,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 78,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2552685874141752,
    "arrivals": 95376,
    "finished_requests": 87031,
    "scheduler_time": 90.79629007174246
}
#Debug simulation 
Total elapsed time: 68.21221738914028. Arrivals time: 0.3181672040373087 Scheduler time: 67.57228009589016 Scheduler overhead time: 0.13245370518416166 Adapter cache time: 0.020063508301973343 Engine time: 0.1196730975061655 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-16/adapters_32_slots_16_rate_1.6-0.8-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-16/adapters_32_slots_16_rate_1.6-0.8-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 66, 66, 8640, 66, 17280, 8640, 66, 66, 66, 17280, 17280, 66, 66, 8640, 8640, 8640, 17280, 17280, 66, 17280, 17280, 17280, 17280, 8640, 66, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 285780 . Total input tokens: 63750125 . Total output tokens: 57041866
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 89.57032426213846,
    "estimated_duration": 3600.1138637115246,
    "input_throughput": 5981.396371113635,
    "output_throughput": 5268.617804339498,
    "total_throughput": 11250.014175453132,
    "itl": 62.593909051671254,
    "ttft": 529966.6759798717,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 101,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3146615346567707,
    "arrivals": 95376,
    "finished_requests": 86746,
    "scheduler_time": 101.4832906092946
}
#Debug simulation 
Total elapsed time: 89.57048702705652. Arrivals time: 0.32651016348972917 Scheduler time: 88.91186133399606 Scheduler overhead time: 0.13730692444369197 Adapter cache time: 0.021091454196721315 Engine time: 0.12381001049652696 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-32/adapters_32_slots_16_rate_1.6-0.8-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-32/adapters_32_slots_16_rate_1.6-0.8-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 66, 66, 8640, 66, 17280, 8640, 66, 66, 66, 17280, 17280, 66, 66, 8640, 8640, 8640, 17280, 17280, 66, 17280, 17280, 17280, 17280, 8640, 66, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 285780 . Total input tokens: 63750125 . Total output tokens: 57041866
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 67.91293064225465,
    "estimated_duration": 3599.980379737909,
    "input_throughput": 6002.491602905125,
    "output_throughput": 5322.074283470086,
    "total_throughput": 11324.56588637521,
    "itl": 60.512879055206795,
    "ttft": 397685.24004270317,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 78,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2581609245017169,
    "arrivals": 95376,
    "finished_requests": 87030,
    "scheduler_time": 90.79534930473487
}
#Debug simulation 
Total elapsed time: 67.91320108016953. Arrivals time: 0.3076552855782211 Scheduler time: 67.28502901038155 Scheduler overhead time: 0.13134757708758116 Adapter cache time: 0.02022600593045354 Engine time: 0.1192421205341816 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-16/adapters_32_slots_16_rate_1.6-0.8-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-16/adapters_32_slots_16_rate_1.6-0.8-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 66, 66, 8640, 66, 17280, 8640, 66, 66, 66, 17280, 17280, 66, 66, 8640, 8640, 8640, 17280, 17280, 66, 17280, 17280, 17280, 17280, 8640, 66, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 285780 . Total input tokens: 63750125 . Total output tokens: 57041866
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 90.11876904498786,
    "estimated_duration": 3600.1041375782206,
    "input_throughput": 5981.412530606868,
    "output_throughput": 5268.632038171947,
    "total_throughput": 11250.044568778814,
    "itl": 62.59404907782276,
    "ttft": 529965.4886864199,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 101,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3019950797851201,
    "arrivals": 95376,
    "finished_requests": 86746,
    "scheduler_time": 101.48293320698112
}
#Debug simulation 
Total elapsed time: 90.1189286489971. Arrivals time: 0.33295470057055354 Scheduler time: 89.45273369085044 Scheduler overhead time: 0.13604255532845855 Adapter cache time: 0.0216999021358788 Engine time: 0.12569046206772327 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-32/adapters_32_slots_16_rate_1.6-0.8-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-32/adapters_32_slots_16_rate_1.6-0.8-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 66, 66, 8640, 66, 17280, 8640, 66, 66, 66, 17280, 17280, 66, 66, 8640, 8640, 8640, 17280, 17280, 66, 17280, 17280, 17280, 17280, 8640, 66, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 285780 . Total input tokens: 63750125 . Total output tokens: 57041866
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 68.0446464130655,
    "estimated_duration": 3599.984498725435,
    "input_throughput": 6002.484735045542,
    "output_throughput": 5322.068194122314,
    "total_throughput": 11324.552929167856,
    "itl": 60.51272708465054,
    "ttft": 397685.33192636824,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 78,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.26193353809416264,
    "arrivals": 95376,
    "finished_requests": 87030,
    "scheduler_time": 90.79544572912027
}
#Debug simulation 
Total elapsed time: 68.04481633007526. Arrivals time: 0.31780979270115495 Scheduler time: 67.41103592794389 Scheduler overhead time: 0.1298881252296269 Adapter cache time: 0.019985776394605637 Engine time: 0.11704199854284525 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-8/adapters_32_slots_16_rate_1.6-0.8-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-8/adapters_32_slots_16_rate_1.6-0.8-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 33, 33, 8640, 33, 17280, 8640, 33, 33, 33, 17280, 17280, 33, 33, 8640, 8640, 8640, 17280, 17280, 33, 17280, 17280, 17280, 17280, 8640, 33, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 285450 . Total input tokens: 63682818 . Total output tokens: 56975482
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 67.78292001457885,
    "estimated_duration": 3600.000436851577,
    "input_throughput": 6371.0345046676475,
    "output_throughput": 5579.800711793127,
    "total_throughput": 11950.835216460775,
    "itl": 65.30028533370097,
    "ttft": 283937.4897027878,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 75,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2295365807949563,
    "arrivals": 95267,
    "finished_requests": 91769,
    "scheduler_time": 95.54088864182476
}
#Debug simulation 
Total elapsed time: 67.78308000182733. Arrivals time: 0.3215711237862706 Scheduler time: 67.15417062304914 Scheduler overhead time: 0.12477338081225753 Adapter cache time: 0.019418949261307716 Engine time: 0.11588518787175417 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-16/adapters_32_slots_16_rate_1.6-0.8-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-16/adapters_32_slots_16_rate_1.6-0.8-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 33, 33, 8640, 33, 17280, 8640, 33, 33, 33, 17280, 17280, 33, 33, 8640, 8640, 8640, 17280, 17280, 33, 17280, 17280, 17280, 17280, 8640, 33, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 285450 . Total input tokens: 63682818 . Total output tokens: 56975482
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 68.10974105587229,
    "estimated_duration": 3600.1162564515444,
    "input_throughput": 6356.615278462193,
    "output_throughput": 5555.6911430727305,
    "total_throughput": 11912.306421534922,
    "itl": 65.0701209474713,
    "ttft": 291714.2359542953,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 76,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24849077897146346,
    "arrivals": 95267,
    "finished_requests": 91613,
    "scheduler_time": 95.62544818791056
}
#Debug simulation 
Total elapsed time: 68.10990275721997. Arrivals time: 0.3266350384801626 Scheduler time: 67.47503869887441 Scheduler overhead time: 0.12457835813984275 Adapter cache time: 0.019848615396767855 Engine time: 0.11588314967229962 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-32/adapters_32_slots_16_rate_1.6-0.8-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-32/adapters_32_slots_16_rate_1.6-0.8-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 33, 33, 8640, 33, 17280, 8640, 33, 33, 33, 17280, 17280, 33, 33, 8640, 8640, 8640, 17280, 17280, 33, 17280, 17280, 17280, 17280, 8640, 33, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 285450 . Total input tokens: 63682818 . Total output tokens: 56975482
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 68.4112590351142,
    "estimated_duration": 3600.0006098842064,
    "input_throughput": 6356.154200967206,
    "output_throughput": 5555.581836593995,
    "total_throughput": 11911.7360375612,
    "itl": 65.06814320198858,
    "ttft": 291714.31593085954,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 76,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24884430222213255,
    "arrivals": 95267,
    "finished_requests": 91609,
    "scheduler_time": 95.62170399117343
}
#Debug simulation 
Total elapsed time: 68.41141624515876. Arrivals time: 0.3182091321796179 Scheduler time: 67.77867723535746 Scheduler overhead time: 0.12800731509923935 Adapter cache time: 0.020110958255827427 Engine time: 0.11858783755451441 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-16/adapters_32_slots_16_rate_1.6-0.8-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-16/adapters_32_slots_16_rate_1.6-0.8-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 33, 33, 8640, 33, 17280, 8640, 33, 33, 33, 17280, 17280, 33, 33, 8640, 8640, 8640, 17280, 17280, 33, 17280, 17280, 17280, 17280, 8640, 33, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 285450 . Total input tokens: 63682818 . Total output tokens: 56975482
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 68.3077031080611,
    "estimated_duration": 3600.006117851939,
    "input_throughput": 6371.1147284620565,
    "output_throughput": 5579.8546842431115,
    "total_throughput": 11950.969412705168,
    "itl": 65.30036098864177,
    "ttft": 283929.5674730686,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 75,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23569444103399304,
    "arrivals": 95267,
    "finished_requests": 91770,
    "scheduler_time": 95.54039955796358
}
#Debug simulation 
Total elapsed time: 68.30786702223122. Arrivals time: 0.3174765151925385 Scheduler time: 67.67917015356943 Scheduler overhead time: 0.12648817198351026 Adapter cache time: 0.019708285573869944 Engine time: 0.11765159526839852 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-32/adapters_32_slots_16_rate_1.6-0.8-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-32/adapters_32_slots_16_rate_1.6-0.8-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 33, 33, 8640, 33, 17280, 8640, 33, 33, 33, 17280, 17280, 33, 33, 8640, 8640, 8640, 17280, 17280, 33, 17280, 17280, 17280, 17280, 8640, 33, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 285450 . Total input tokens: 63682818 . Total output tokens: 56975482
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 68.87126163719222,
    "estimated_duration": 3600.004816390634,
    "input_throughput": 6356.146773976169,
    "output_throughput": 5555.575345049706,
    "total_throughput": 11911.722119025875,
    "itl": 65.06817559926753,
    "ttft": 291713.4789750027,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 76,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.25161088552325944,
    "arrivals": 95267,
    "finished_requests": 91609,
    "scheduler_time": 95.6218008931378
}
#Debug simulation 
Total elapsed time: 68.87153247511014. Arrivals time: 0.3195670461282134 Scheduler time: 68.23869904875755 Scheduler overhead time: 0.12641869811341166 Adapter cache time: 0.020859098061919212 Engine time: 0.11856812052428722 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-16/adapters_32_slots_16_rate_1.6-0.8-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-16/adapters_32_slots_16_rate_1.6-0.8-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 33, 33, 8640, 33, 17280, 8640, 33, 33, 33, 17280, 17280, 33, 33, 8640, 8640, 8640, 17280, 17280, 33, 17280, 17280, 17280, 17280, 8640, 33, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 285450 . Total input tokens: 63682818 . Total output tokens: 56975482
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 66.98177327075973,
    "estimated_duration": 3600.0593612696875,
    "input_throughput": 6400.832232908777,
    "output_throughput": 5606.739771335657,
    "total_throughput": 12007.572004244434,
    "itl": 65.57190319602046,
    "ttft": 268885.39187181334,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 76,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.22724382241256558,
    "arrivals": 95267,
    "finished_requests": 92194,
    "scheduler_time": 95.65218264973647
}
#Debug simulation 
Total elapsed time: 66.98192751593888. Arrivals time: 0.30596437165513635 Scheduler time: 66.36737887235358 Scheduler overhead time: 0.12439504219219089 Adapter cache time: 0.019026170950382948 Engine time: 0.11749646626412868 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-32/adapters_32_slots_16_rate_1.6-0.8-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-32/adapters_32_slots_16_rate_1.6-0.8-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 8640, 33, 33, 8640, 33, 17280, 8640, 33, 33, 33, 17280, 17280, 33, 33, 8640, 8640, 8640, 17280, 17280, 33, 17280, 17280, 17280, 17280, 8640, 33, 8640, 8640, 8640, 8640, 17280]
Prompts retrieved: 285450 . Total input tokens: 63682818 . Total output tokens: 56975482
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 68.1403885516338,
    "estimated_duration": 3600.006770050263,
    "input_throughput": 6356.1433246083925,
    "output_throughput": 5555.572330137801,
    "total_throughput": 11911.715654746193,
    "itl": 65.06817982795278,
    "ttft": 291713.8729925468,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 76,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2553834991157052,
    "arrivals": 95267,
    "finished_requests": 91609,
    "scheduler_time": 95.62182306801506
}
#Debug simulation 
Total elapsed time: 68.14054451463744. Arrivals time: 0.31414961349219084 Scheduler time: 67.51919794920832 Scheduler overhead time: 0.12377108633518219 Adapter cache time: 0.019930236507207155 Engine time: 0.11614705575630069 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-8/adapters_32_slots_16_rate_1.6-0.4-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-8/adapters_32_slots_16_rate_1.6-0.4-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 1080, 1080, 4320, 1080, 17280, 4320, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 4320, 4320, 4320, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 4320, 1080, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 248400 . Total input tokens: 55382994 . Total output tokens: 49632071
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 17.572387252934277,
    "estimated_duration": 3600.0113649604236,
    "input_throughput": 5667.362386291881,
    "output_throughput": 5004.357534909631,
    "total_throughput": 10671.719921201511,
    "itl": 42.38402372722381,
    "ttft": 74477.87280640844,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 172,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.526403891956433,
    "arrivals": 83017,
    "finished_requests": 81998,
    "scheduler_time": 62.79717747563017
}
#Debug simulation 
Total elapsed time: 17.57252771081403. Arrivals time: 0.21890796441584826 Scheduler time: 17.060870931018144 Scheduler overhead time: 0.11420079693198204 Adapter cache time: 0.01856539584696293 Engine time: 0.10986976372078061 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-16/adapters_32_slots_16_rate_1.6-0.4-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-16/adapters_32_slots_16_rate_1.6-0.4-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 1080, 1080, 4320, 1080, 17280, 4320, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 4320, 4320, 4320, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 4320, 1080, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 248400 . Total input tokens: 55382994 . Total output tokens: 49632071
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 17.62160496087745,
    "estimated_duration": 3600.0273907341157,
    "input_throughput": 5667.337157631881,
    "output_throughput": 5004.335257662092,
    "total_throughput": 10671.672415293973,
    "itl": 42.38374713313771,
    "ttft": 74482.49351016205,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 172,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5563739685225307,
    "arrivals": 83017,
    "finished_requests": 81998,
    "scheduler_time": 62.79834093203527
}
#Debug simulation 
Total elapsed time: 17.621691306121647. Arrivals time: 0.2200877359136939 Scheduler time: 17.104506181553006 Scheduler overhead time: 0.11688962206244469 Adapter cache time: 0.018800273071974516 Engine time: 0.11096707498654723 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-32/adapters_32_slots_16_rate_1.6-0.4-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-32/adapters_32_slots_16_rate_1.6-0.4-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 1080, 1080, 4320, 1080, 17280, 4320, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 4320, 4320, 4320, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 4320, 1080, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 248400 . Total input tokens: 55382994 . Total output tokens: 49632071
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 17.57057417789474,
    "estimated_duration": 3600.0329972360973,
    "input_throughput": 5667.328331619166,
    "output_throughput": 5004.327464173654,
    "total_throughput": 10671.655795792822,
    "itl": 42.38386805840304,
    "ttft": 74482.54386893965,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 172,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5582217339240034,
    "arrivals": 83017,
    "finished_requests": 81998,
    "scheduler_time": 62.798498279709364
}
#Debug simulation 
Total elapsed time: 17.570712537970394. Arrivals time: 0.2163908858783543 Scheduler time: 17.05839217128232 Scheduler overhead time: 0.11586357187479734 Adapter cache time: 0.01877204468473792 Engine time: 0.11097984621301293 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-16-16/adapters_32_slots_16_rate_1.6-0.4-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-16-16/adapters_32_slots_16_rate_1.6-0.4-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 1080, 1080, 4320, 1080, 17280, 4320, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 4320, 4320, 4320, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 4320, 1080, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 248400 . Total input tokens: 55382994 . Total output tokens: 49632071
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 17.643938686698675,
    "estimated_duration": 3600.0207226682423,
    "input_throughput": 5667.347654842982,
    "output_throughput": 5004.344526841278,
    "total_throughput": 10671.69218168426,
    "itl": 42.38386193756201,
    "ttft": 74477.60007485178,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 172,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5318582494161097,
    "arrivals": 83017,
    "finished_requests": 81998,
    "scheduler_time": 62.797280993225186
}
#Debug simulation 
Total elapsed time: 17.644027397967875. Arrivals time: 0.22220335248857737 Scheduler time: 17.12565009156242 Scheduler overhead time: 0.11598475649952888 Adapter cache time: 0.018887642305344343 Engine time: 0.11086004553362727 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-16-32/adapters_32_slots_16_rate_1.6-0.4-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-16-32/adapters_32_slots_16_rate_1.6-0.4-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 1080, 1080, 4320, 1080, 17280, 4320, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 4320, 4320, 4320, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 4320, 1080, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 248400 . Total input tokens: 55382994 . Total output tokens: 49632071
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 17.472843918018043,
    "estimated_duration": 3600.0283737612453,
    "input_throughput": 5669.355594182765,
    "output_throughput": 5009.33468509268,
    "total_throughput": 10678.690279275444,
    "itl": 42.471088881664876,
    "ttft": 72471.5079176982,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 174,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5727800013683749,
    "arrivals": 83017,
    "finished_requests": 82031,
    "scheduler_time": 62.71282702615071
}
#Debug simulation 
Total elapsed time: 17.473064790014178. Arrivals time: 0.2196300569921732 Scheduler time: 16.958583519328386 Scheduler overhead time: 0.11473228642717004 Adapter cache time: 0.018646756187081337 Engine time: 0.11106633162125945 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_16-16-16/adapters_32_slots_16_rate_1.6-0.4-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_16-16-16/adapters_32_slots_16_rate_1.6-0.4-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 1080, 1080, 4320, 1080, 17280, 4320, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 4320, 4320, 4320, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 4320, 1080, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 248400 . Total input tokens: 55382994 . Total output tokens: 49632071
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 17.445543805602938,
    "estimated_duration": 3600.0085561515302,
    "input_throughput": 5669.386803296507,
    "output_throughput": 5009.362260871508,
    "total_throughput": 10678.749064168014,
    "itl": 42.47111097191779,
    "ttft": 72466.52331966582,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 174,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5202687513129792,
    "arrivals": 83017,
    "finished_requests": 82031,
    "scheduler_time": 62.711391325384426
}
#Debug simulation 
Total elapsed time: 17.445625135675073. Arrivals time: 0.22270306618884206 Scheduler time: 16.92479260219261 Scheduler overhead time: 0.11674933321774006 Adapter cache time: 0.018828920554369688 Engine time: 0.11177251720800996 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_16-16-32/adapters_32_slots_16_rate_1.6-0.4-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_16-16-32/adapters_32_slots_16_rate_1.6-0.4-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 1080, 1080, 4320, 1080, 17280, 4320, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 4320, 4320, 4320, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 4320, 1080, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 248400 . Total input tokens: 55382994 . Total output tokens: 49632071
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 17.375241994857788,
    "estimated_duration": 3599.995461683496,
    "input_throughput": 5669.373535947635,
    "output_throughput": 5009.257425998791,
    "total_throughput": 10678.630961946426,
    "itl": 42.47105902198085,
    "ttft": 72514.95528488493,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 174,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5781874141842135,
    "arrivals": 83017,
    "finished_requests": 82030,
    "scheduler_time": 62.71231343614336
}
#Debug simulation 
Total elapsed time: 17.375352011062205. Arrivals time: 0.22201900323852897 Scheduler time: 16.859654309228063 Scheduler overhead time: 0.11460757022723556 Adapter cache time: 0.018783959094434977 Engine time: 0.11000328743830323 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-8/adapters_32_slots_16_rate_1.6-0.4-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-8/adapters_32_slots_16_rate_1.6-0.4-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 540, 540, 4320, 540, 17280, 4320, 540, 540, 540, 17280, 17280, 540, 540, 4320, 4320, 4320, 17280, 17280, 540, 17280, 17280, 17280, 17280, 4320, 540, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 243000 . Total input tokens: 54202232 . Total output tokens: 48558410
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 14.408711068797857,
    "estimated_duration": 3600.0089798841063,
    "input_throughput": 5567.83055597969,
    "output_throughput": 4938.541570130291,
    "total_throughput": 10506.37212610998,
    "itl": 41.64865425718264,
    "ttft": 56524.36474322291,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 188,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.575371695859357,
    "arrivals": 81259,
    "finished_requests": 80500,
    "scheduler_time": 60.12597720444383
}
#Debug simulation 
Total elapsed time: 14.40880761994049. Arrivals time: 0.21741308737546206 Scheduler time: 13.89422981441021 Scheduler overhead time: 0.11629531998187304 Adapter cache time: 0.018910839688032866 Engine time: 0.11129082040861249 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-16/adapters_32_slots_16_rate_1.6-0.4-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-16/adapters_32_slots_16_rate_1.6-0.4-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 540, 540, 4320, 540, 17280, 4320, 540, 540, 540, 17280, 17280, 540, 540, 4320, 4320, 4320, 17280, 17280, 540, 17280, 17280, 17280, 17280, 4320, 540, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 243000 . Total input tokens: 54202232 . Total output tokens: 48558410
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 14.429485838394612,
    "estimated_duration": 3599.9920422724094,
    "input_throughput": 5567.856752079804,
    "output_throughput": 4938.564805487058,
    "total_throughput": 10506.421557566862,
    "itl": 41.64942472088668,
    "ttft": 56524.40313136932,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 188,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6087093217438099,
    "arrivals": 81259,
    "finished_requests": 80500,
    "scheduler_time": 60.12595392038444
}
#Debug simulation 
Total elapsed time: 14.429575076326728. Arrivals time: 0.21430301200598478 Scheduler time: 13.918679215945303 Scheduler overhead time: 0.11578619061037898 Adapter cache time: 0.018895788118243217 Engine time: 0.11135738343000412 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-32/adapters_32_slots_16_rate_1.6-0.4-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-32/adapters_32_slots_16_rate_1.6-0.4-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 540, 540, 4320, 540, 17280, 4320, 540, 540, 540, 17280, 17280, 540, 540, 4320, 4320, 4320, 17280, 17280, 540, 17280, 17280, 17280, 17280, 4320, 540, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 243000 . Total input tokens: 54202232 . Total output tokens: 48558410
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 14.390995319001377,
    "estimated_duration": 3599.9969699068565,
    "input_throughput": 5567.849130861521,
    "output_throughput": 4938.558045636353,
    "total_throughput": 10506.407176497874,
    "itl": 41.649438703514036,
    "ttft": 56524.35778119845,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 188,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.610627757944169,
    "arrivals": 81259,
    "finished_requests": 80500,
    "scheduler_time": 60.126061999787034
}
#Debug simulation 
Total elapsed time: 14.391083563677967. Arrivals time: 0.21518340101465583 Scheduler time: 13.881412649992853 Scheduler overhead time: 0.11471499176695943 Adapter cache time: 0.01869311323389411 Engine time: 0.11059122858569026 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-16-16/adapters_32_slots_16_rate_1.6-0.4-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-16-16/adapters_32_slots_16_rate_1.6-0.4-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 540, 540, 4320, 540, 17280, 4320, 540, 540, 540, 17280, 17280, 540, 540, 4320, 4320, 4320, 17280, 17280, 540, 17280, 17280, 17280, 17280, 4320, 540, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 243000 . Total input tokens: 54202232 . Total output tokens: 48558410
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 14.39305581804365,
    "estimated_duration": 3600.0177298576873,
    "input_throughput": 5567.817023165709,
    "output_throughput": 4938.529566825999,
    "total_throughput": 10506.346589991706,
    "itl": 41.64858693494084,
    "ttft": 56524.3647102778,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 188,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5813334354083061,
    "arrivals": 81259,
    "finished_requests": 80500,
    "scheduler_time": 60.12607256331992
}
#Debug simulation 
Total elapsed time: 14.393195861950517. Arrivals time: 0.21373135410249233 Scheduler time: 13.884576829150319 Scheduler overhead time: 0.11506199277937412 Adapter cache time: 0.018983862828463316 Engine time: 0.1100817322731018 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-16-32/adapters_32_slots_16_rate_1.6-0.4-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-16-32/adapters_32_slots_16_rate_1.6-0.4-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 540, 540, 4320, 540, 17280, 4320, 540, 540, 540, 17280, 17280, 540, 540, 4320, 4320, 4320, 17280, 17280, 540, 17280, 17280, 17280, 17280, 4320, 540, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 243000 . Total input tokens: 54202232 . Total output tokens: 48558410
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 14.388711858075112,
    "estimated_duration": 3600.011449745949,
    "input_throughput": 5567.826736055106,
    "output_throughput": 4938.538181942349,
    "total_throughput": 10506.364917997456,
    "itl": 41.649488613410675,
    "ttft": 56524.653792879486,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 188,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6190532616339641,
    "arrivals": 81259,
    "finished_requests": 80500,
    "scheduler_time": 60.12631981409842
}
#Debug simulation 
Total elapsed time: 14.38890308700502. Arrivals time: 0.2103468575514853 Scheduler time: 13.882600263692439 Scheduler overhead time: 0.11546616163104773 Adapter cache time: 0.018856104463338852 Engine time: 0.11096224654465914 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_16-16-16/adapters_32_slots_16_rate_1.6-0.4-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_16-16-16/adapters_32_slots_16_rate_1.6-0.4-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 540, 540, 4320, 540, 17280, 4320, 540, 540, 540, 17280, 17280, 540, 540, 4320, 4320, 4320, 17280, 17280, 540, 17280, 17280, 17280, 17280, 4320, 540, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 243000 . Total input tokens: 54202232 . Total output tokens: 48558410
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 14.370184859260917,
    "estimated_duration": 3599.9791383733464,
    "input_throughput": 5567.876709712547,
    "output_throughput": 4938.582507462353,
    "total_throughput": 10506.459217174901,
    "itl": 41.64841192662007,
    "ttft": 56524.15266493022,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 188,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5621294554416097,
    "arrivals": 81259,
    "finished_requests": 80500,
    "scheduler_time": 60.12528406828323
}
#Debug simulation 
Total elapsed time: 14.370288724079728. Arrivals time: 0.2148346360772848 Scheduler time: 13.860139469616115 Scheduler overhead time: 0.11557533126324415 Adapter cache time: 0.01872318610548973 Engine time: 0.11057446943596005 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_16-16-32/adapters_32_slots_16_rate_1.6-0.4-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_16-16-32/adapters_32_slots_16_rate_1.6-0.4-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 540, 540, 4320, 540, 17280, 4320, 540, 540, 540, 17280, 17280, 540, 540, 4320, 4320, 4320, 17280, 17280, 540, 17280, 17280, 17280, 17280, 4320, 540, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 243000 . Total input tokens: 54202232 . Total output tokens: 48558410
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 14.405424486845732,
    "estimated_duration": 3600.020363393072,
    "input_throughput": 5567.812950121207,
    "output_throughput": 4938.525954126333,
    "total_throughput": 10506.338904247541,
    "itl": 41.64963278369071,
    "ttft": 56524.53659906367,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 188,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6249636895954622,
    "arrivals": 81259,
    "finished_requests": 80500,
    "scheduler_time": 60.12642273111338
}
#Debug simulation 
Total elapsed time: 14.40551376901567. Arrivals time: 0.21409642323851585 Scheduler time: 13.896553395316005 Scheduler overhead time: 0.11490270122885704 Adapter cache time: 0.01880232896655798 Engine time: 0.11068378482013941 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-8/adapters_32_slots_16_rate_1.6-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-8/adapters_32_slots_16_rate_1.6-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 270, 270, 4320, 270, 17280, 4320, 270, 270, 270, 17280, 17280, 270, 270, 4320, 4320, 4320, 17280, 17280, 270, 17280, 17280, 17280, 17280, 4320, 270, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 240300 . Total input tokens: 53596823 . Total output tokens: 48032691
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 12.845487494021654,
    "estimated_duration": 3600.045901278895,
    "input_throughput": 5483.279252908264,
    "output_throughput": 4859.518317192897,
    "total_throughput": 10342.79757010116,
    "itl": 40.93242643696173,
    "ttft": 41013.26601970975,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 207,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6335209629940792,
    "arrivals": 80362,
    "finished_requests": 79880,
    "scheduler_time": 58.05061428250033
}
#Debug simulation 
Total elapsed time: 12.845619454048574. Arrivals time: 0.20412614522501826 Scheduler time: 12.344023749232292 Scheduler overhead time: 0.11588209820911288 Adapter cache time: 0.01904066978022456 Engine time: 0.11145561328157783 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-16/adapters_32_slots_16_rate_1.6-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-16/adapters_32_slots_16_rate_1.6-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 270, 270, 4320, 270, 17280, 4320, 270, 270, 270, 17280, 17280, 270, 270, 4320, 4320, 4320, 17280, 17280, 270, 17280, 17280, 17280, 17280, 4320, 270, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 240300 . Total input tokens: 53596823 . Total output tokens: 48032691
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 12.884665512945503,
    "estimated_duration": 3600.0333999564123,
    "input_throughput": 5483.298293909997,
    "output_throughput": 4859.535192148999,
    "total_throughput": 10342.833486058997,
    "itl": 40.93308313107924,
    "ttft": 41013.47054585649,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 207,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.670423421168236,
    "arrivals": 80362,
    "finished_requests": 79880,
    "scheduler_time": 58.05071223342991
}
#Debug simulation 
Total elapsed time: 12.884766422677785. Arrivals time: 0.21216799272224307 Scheduler time: 12.374441896565259 Scheduler overhead time: 0.11636195471510291 Adapter cache time: 0.019023085478693247 Engine time: 0.11130999494343996 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-32/adapters_32_slots_16_rate_1.6-0.4-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-32/adapters_32_slots_16_rate_1.6-0.4-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 270, 270, 4320, 270, 17280, 4320, 270, 270, 270, 17280, 17280, 270, 270, 4320, 4320, 4320, 17280, 17280, 270, 17280, 17280, 17280, 17280, 4320, 270, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 240300 . Total input tokens: 53596823 . Total output tokens: 48032691
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 12.8716632691212,
    "estimated_duration": 3600.0353365032784,
    "input_throughput": 5483.295344310025,
    "output_throughput": 4859.532578086423,
    "total_throughput": 10342.827922396447,
    "itl": 40.93311925081845,
    "ttft": 41010.29452789573,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 207,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6725015860050945,
    "arrivals": 80362,
    "finished_requests": 79880,
    "scheduler_time": 58.05017046109772
}
#Debug simulation 
Total elapsed time: 12.871751408092678. Arrivals time: 0.20949787367135286 Scheduler time: 12.365554898511618 Scheduler overhead time: 0.11607668967917562 Adapter cache time: 0.01896286988630891 Engine time: 0.11064555123448372 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-16-16/adapters_32_slots_16_rate_1.6-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-16-16/adapters_32_slots_16_rate_1.6-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 270, 270, 4320, 270, 17280, 4320, 270, 270, 270, 17280, 17280, 270, 270, 4320, 4320, 4320, 17280, 17280, 270, 17280, 17280, 17280, 17280, 4320, 270, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 240300 . Total input tokens: 53596823 . Total output tokens: 48032691
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 12.865109496749938,
    "estimated_duration": 3600.0108707675718,
    "input_throughput": 5483.332608879358,
    "output_throughput": 4859.565603553285,
    "total_throughput": 10342.898212432643,
    "itl": 40.93267502201355,
    "ttft": 41010.45745609666,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 207,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6401873676036495,
    "arrivals": 80362,
    "finished_requests": 79880,
    "scheduler_time": 58.04952434728133
}
#Debug simulation 
Total elapsed time: 12.865252646617591. Arrivals time: 0.20488862367346883 Scheduler time: 12.362666833680123 Scheduler overhead time: 0.11625168845057487 Adapter cache time: 0.018937290646135807 Engine time: 0.1114624859765172 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-16-32/adapters_32_slots_16_rate_1.6-0.4-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-16-32/adapters_32_slots_16_rate_1.6-0.4-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 270, 270, 4320, 270, 17280, 4320, 270, 270, 270, 17280, 17280, 270, 270, 4320, 4320, 4320, 17280, 17280, 270, 17280, 17280, 17280, 17280, 4320, 270, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 240300 . Total input tokens: 53596823 . Total output tokens: 48032691
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 12.796484810300171,
    "estimated_duration": 3600.0268941910417,
    "input_throughput": 5480.18517079252,
    "output_throughput": 4859.090088528575,
    "total_throughput": 10339.275259321095,
    "itl": 40.85128065757611,
    "ttft": 42719.42138328472,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 204,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6722138083726191,
    "arrivals": 80362,
    "finished_requests": 79836,
    "scheduler_time": 57.98638504463405
}
#Debug simulation 
Total elapsed time: 12.796629357151687. Arrivals time: 0.20939225936308503 Scheduler time: 12.289884759113193 Scheduler overhead time: 0.11547303711995482 Adapter cache time: 0.019061787519603968 Engine time: 0.1119293668307364 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_16-16-16/adapters_32_slots_16_rate_1.6-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_16-16-16/adapters_32_slots_16_rate_1.6-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 270, 270, 4320, 270, 17280, 4320, 270, 270, 270, 17280, 17280, 270, 270, 4320, 4320, 4320, 17280, 17280, 270, 17280, 17280, 17280, 17280, 4320, 270, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 240300 . Total input tokens: 53596823 . Total output tokens: 48032691
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 12.889403157867491,
    "estimated_duration": 3600.0151213492404,
    "input_throughput": 5483.326134641811,
    "output_throughput": 4859.559865805032,
    "total_throughput": 10342.886000446842,
    "itl": 40.93203063242508,
    "ttft": 41010.33418125267,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 207,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6189404110447512,
    "arrivals": 80362,
    "finished_requests": 79880,
    "scheduler_time": 58.04951093048631
}
#Debug simulation 
Total elapsed time: 12.889532485045493. Arrivals time: 0.21172692207619548 Scheduler time: 12.381267060525715 Scheduler overhead time: 0.11585902655497193 Adapter cache time: 0.018936666194349527 Engine time: 0.11056674597784877 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_16-16-32/adapters_32_slots_16_rate_1.6-0.4-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_16-16-32/adapters_32_slots_16_rate_1.6-0.4-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 270, 270, 4320, 270, 17280, 4320, 270, 270, 270, 17280, 17280, 270, 270, 4320, 4320, 4320, 17280, 17280, 270, 17280, 17280, 17280, 17280, 4320, 270, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 240300 . Total input tokens: 53596823 . Total output tokens: 48032691
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 12.883657284080982,
    "estimated_duration": 3600.0273226084105,
    "input_throughput": 5483.307550481945,
    "output_throughput": 4859.543395721874,
    "total_throughput": 10342.850946203818,
    "itl": 40.93358659040281,
    "ttft": 41013.86878748863,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 207,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6883465630933662,
    "arrivals": 80362,
    "finished_requests": 79880,
    "scheduler_time": 58.05081650982751
}
#Debug simulation 
Total elapsed time: 12.883751295041293. Arrivals time: 0.21361121674999595 Scheduler time: 12.3738860222511 Scheduler overhead time: 0.11594082787632942 Adapter cache time: 0.018937678076326847 Engine time: 0.11061559664085507 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-8/adapters_32_slots_16_rate_1.6-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-8/adapters_32_slots_16_rate_1.6-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 135, 135, 4320, 135, 17280, 4320, 135, 135, 135, 17280, 17280, 135, 135, 4320, 4320, 4320, 17280, 17280, 135, 17280, 17280, 17280, 17280, 4320, 135, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 238950 . Total input tokens: 53317414 . Total output tokens: 47749740
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 11.395699371118098,
    "estimated_duration": 3600.0362377281635,
    "input_throughput": 5455.490640392549,
    "output_throughput": 4856.461392464506,
    "total_throughput": 10311.952032857054,
    "itl": 40.533169751496594,
    "ttft": 42314.45064085039,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 203,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6212790120183482,
    "arrivals": 79870,
    "finished_requests": 79264,
    "scheduler_time": 57.24549279309889
}
#Debug simulation 
Total elapsed time: 11.395776946097612. Arrivals time: 0.20254897652193904 Scheduler time: 10.89709751913324 Scheduler overhead time: 0.11531665874645114 Adapter cache time: 0.018935756757855415 Engine time: 0.11121367430314422 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-16/adapters_32_slots_16_rate_1.6-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-16/adapters_32_slots_16_rate_1.6-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 135, 135, 4320, 135, 17280, 4320, 135, 135, 135, 17280, 17280, 135, 135, 4320, 4320, 4320, 17280, 17280, 135, 17280, 17280, 17280, 17280, 4320, 135, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 238950 . Total input tokens: 53317414 . Total output tokens: 47749740
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 11.386559790931642,
    "estimated_duration": 3600.0268864333234,
    "input_throughput": 5455.504811370457,
    "output_throughput": 4856.474007426504,
    "total_throughput": 10311.97881879696,
    "itl": 40.53408149036351,
    "ttft": 42314.55110684091,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 203,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6584632199886272,
    "arrivals": 79870,
    "finished_requests": 79264,
    "scheduler_time": 57.24567842596305
}
#Debug simulation 
Total elapsed time: 11.38669901387766. Arrivals time: 0.20514900656417012 Scheduler time: 10.885573144536465 Scheduler overhead time: 0.11448361678048968 Adapter cache time: 0.018911802675575018 Engine time: 0.11170438444241881 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-32/adapters_32_slots_16_rate_1.6-0.4-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-32/adapters_32_slots_16_rate_1.6-0.4-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 135, 135, 4320, 135, 17280, 4320, 135, 135, 135, 17280, 17280, 135, 135, 4320, 4320, 4320, 17280, 17280, 135, 17280, 17280, 17280, 17280, 4320, 135, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 238950 . Total input tokens: 53317414 . Total output tokens: 47749740
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 11.443673303816468,
    "estimated_duration": 3600.028247629481,
    "input_throughput": 5455.502748605479,
    "output_throughput": 4856.472171159312,
    "total_throughput": 10311.97491976479,
    "itl": 40.534137625153996,
    "ttft": 42314.625241808804,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 203,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6603275106102255,
    "arrivals": 79870,
    "finished_requests": 79264,
    "scheduler_time": 57.24567552440517
}
#Debug simulation 
Total elapsed time: 11.443766343872994. Arrivals time: 0.20663921255618334 Scheduler time: 10.940998817794025 Scheduler overhead time: 0.11548543302342296 Adapter cache time: 0.01889741886407137 Engine time: 0.11086964420974255 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-16/adapters_32_slots_16_rate_1.6-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-16/adapters_32_slots_16_rate_1.6-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 135, 135, 4320, 135, 17280, 4320, 135, 135, 135, 17280, 17280, 135, 135, 4320, 4320, 4320, 17280, 17280, 135, 17280, 17280, 17280, 17280, 4320, 135, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 238950 . Total input tokens: 53317414 . Total output tokens: 47749740
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 11.436284488998353,
    "estimated_duration": 3600.0112181461927,
    "input_throughput": 5455.528555300863,
    "output_throughput": 4856.49514420208,
    "total_throughput": 10312.023699502943,
    "itl": 40.5334380681544,
    "ttft": 42314.45311235094,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 203,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6274099757871601,
    "arrivals": 79870,
    "finished_requests": 79264,
    "scheduler_time": 57.24526597014662
}
#Debug simulation 
Total elapsed time: 11.436377765145153. Arrivals time: 0.20360057102516294 Scheduler time: 10.93716796906665 Scheduler overhead time: 0.11562957102432847 Adapter cache time: 0.01877470128238201 Engine time: 0.11044783098623157 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-32/adapters_32_slots_16_rate_1.6-0.4-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-32/adapters_32_slots_16_rate_1.6-0.4-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 135, 135, 4320, 135, 17280, 4320, 135, 135, 135, 17280, 17280, 135, 135, 4320, 4320, 4320, 17280, 17280, 135, 17280, 17280, 17280, 17280, 4320, 135, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 238950 . Total input tokens: 53317414 . Total output tokens: 47749740
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 11.404549623373896,
    "estimated_duration": 3600.0075491543776,
    "input_throughput": 5455.534115369653,
    "output_throughput": 4856.500093758627,
    "total_throughput": 10312.03420912828,
    "itl": 40.53443282959927,
    "ttft": 42314.75724073167,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 203,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6698847983777544,
    "arrivals": 79870,
    "finished_requests": 79264,
    "scheduler_time": 57.245522691395884
}
#Debug simulation 
Total elapsed time: 11.404737965203822. Arrivals time: 0.2056630509905517 Scheduler time: 10.903360346332192 Scheduler overhead time: 0.11475651990622282 Adapter cache time: 0.018921419978141785 Engine time: 0.11124970531091094 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-16/adapters_32_slots_16_rate_1.6-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-16/adapters_32_slots_16_rate_1.6-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 135, 135, 4320, 135, 17280, 4320, 135, 135, 135, 17280, 17280, 135, 135, 4320, 4320, 4320, 17280, 17280, 135, 17280, 17280, 17280, 17280, 4320, 135, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 238950 . Total input tokens: 53317414 . Total output tokens: 47749740
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 11.435055834241211,
    "estimated_duration": 3600.0112917416327,
    "input_throughput": 5455.528443772873,
    "output_throughput": 4856.495044920198,
    "total_throughput": 10312.02348869307,
    "itl": 40.533276573915046,
    "ttft": 42314.726067013544,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 203,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6069802098651425,
    "arrivals": 79870,
    "finished_requests": 79264,
    "scheduler_time": 57.245140599284696
}
#Debug simulation 
Total elapsed time: 11.435141367372125. Arrivals time: 0.2103424700908363 Scheduler time: 10.929606716614217 Scheduler overhead time: 0.11492243595421314 Adapter cache time: 0.01886461954563856 Engine time: 0.1106497305445373 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-32/adapters_32_slots_16_rate_1.6-0.4-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-32/adapters_32_slots_16_rate_1.6-0.4-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 135, 135, 4320, 135, 17280, 4320, 135, 135, 135, 17280, 17280, 135, 135, 4320, 4320, 4320, 17280, 17280, 135, 17280, 17280, 17280, 17280, 4320, 135, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 238950 . Total input tokens: 53317414 . Total output tokens: 47749740
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 11.433272038120776,
    "estimated_duration": 3600.019076549238,
    "input_throughput": 5455.516646546687,
    "output_throughput": 4856.484543064858,
    "total_throughput": 10312.001189611545,
    "itl": 40.53454450622532,
    "ttft": 42314.926080841935,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 203,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6761724876984971,
    "arrivals": 79870,
    "finished_requests": 79264,
    "scheduler_time": 57.245760467930836
}
#Debug simulation 
Total elapsed time: 11.43338076211512. Arrivals time: 0.2026294288225472 Scheduler time: 10.935091766063124 Scheduler overhead time: 0.11494704009965062 Adapter cache time: 0.018905806355178356 Engine time: 0.11089836340397596 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-8/adapters_32_slots_16_rate_1.6-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-8/adapters_32_slots_16_rate_1.6-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 66, 66, 4320, 66, 17280, 4320, 66, 66, 66, 17280, 17280, 66, 66, 4320, 4320, 4320, 17280, 17280, 66, 17280, 17280, 17280, 17280, 4320, 66, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 238260 . Total input tokens: 53168695 . Total output tokens: 47604318
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 11.45318527938798,
    "estimated_duration": 3599.9829929936027,
    "input_throughput": 5487.586757617526,
    "output_throughput": 4818.583597133907,
    "total_throughput": 10306.170354751432,
    "itl": 40.33796939029571,
    "ttft": 44820.743146921785,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 182,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5570087693957605,
    "arrivals": 79675,
    "finished_requests": 79019,
    "scheduler_time": 56.62462873723975
}
#Debug simulation 
Total elapsed time: 11.453273968305439. Arrivals time: 0.20710174553096294 Scheduler time: 10.9518848140724 Scheduler overhead time: 0.11419829493388534 Adapter cache time: 0.01866829814389348 Engine time: 0.11043147463351488 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-16/adapters_32_slots_16_rate_1.6-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-16/adapters_32_slots_16_rate_1.6-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 66, 66, 4320, 66, 17280, 4320, 66, 66, 66, 17280, 17280, 66, 66, 4320, 4320, 4320, 17280, 17280, 66, 17280, 17280, 17280, 17280, 4320, 66, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 238260 . Total input tokens: 53168695 . Total output tokens: 47604318
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 11.45668931864202,
    "estimated_duration": 3600.019015147122,
    "input_throughput": 5488.092123089128,
    "output_throughput": 4817.669275363874,
    "total_throughput": 10305.761398453002,
    "itl": 40.331700988813274,
    "ttft": 44224.96294958256,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 183,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.597436428135262,
    "arrivals": 79675,
    "finished_requests": 79033,
    "scheduler_time": 56.62726432711848
}
#Debug simulation 
Total elapsed time: 11.456787916831672. Arrivals time: 0.2080058348365128 Scheduler time: 10.955044967588037 Scheduler overhead time: 0.11479562148451805 Adapter cache time: 0.01864283112809062 Engine time: 0.1094838553108275 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-32/adapters_32_slots_16_rate_1.6-0.4-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-32/adapters_32_slots_16_rate_1.6-0.4-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 66, 66, 4320, 66, 17280, 4320, 66, 66, 66, 17280, 17280, 66, 66, 4320, 4320, 4320, 17280, 17280, 66, 17280, 17280, 17280, 17280, 4320, 66, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 238260 . Total input tokens: 53168695 . Total output tokens: 47604318
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 11.248357726726681,
    "estimated_duration": 3600.011951813695,
    "input_throughput": 5484.1887372216515,
    "output_throughput": 4810.872361486063,
    "total_throughput": 10295.061098707714,
    "itl": 40.249672381092545,
    "ttft": 46569.64894063443,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 182,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5957391197979474,
    "arrivals": 79675,
    "finished_requests": 78965,
    "scheduler_time": 56.50221252897727
}
#Debug simulation 
Total elapsed time: 11.248460551723838. Arrivals time: 0.20207986747846007 Scheduler time: 10.752657517325133 Scheduler overhead time: 0.1139342961832881 Adapter cache time: 0.018805798143148422 Engine time: 0.1101333973929286 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-16/adapters_32_slots_16_rate_1.6-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-16/adapters_32_slots_16_rate_1.6-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 66, 66, 4320, 66, 17280, 4320, 66, 66, 66, 17280, 17280, 66, 66, 4320, 4320, 4320, 17280, 17280, 66, 17280, 17280, 17280, 17280, 4320, 66, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 238260 . Total input tokens: 53168695 . Total output tokens: 47604318
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 11.456306618172675,
    "estimated_duration": 3599.987756141898,
    "input_throughput": 5488.139776667964,
    "output_throughput": 4817.711107603105,
    "total_throughput": 10305.850884271069,
    "itl": 40.33079841931541,
    "ttft": 44224.906538738105,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 183,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5663831839337952,
    "arrivals": 79675,
    "finished_requests": 79033,
    "scheduler_time": 56.62630906898819
}
#Debug simulation 
Total elapsed time: 11.456393857020885. Arrivals time: 0.20575612783432007 Scheduler time: 10.95694472733885 Scheduler overhead time: 0.1143590621650219 Adapter cache time: 0.018731065560132265 Engine time: 0.1098618395626545 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-32/adapters_32_slots_16_rate_1.6-0.4-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-32/adapters_32_slots_16_rate_1.6-0.4-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 66, 66, 4320, 66, 17280, 4320, 66, 66, 66, 17280, 17280, 66, 66, 4320, 4320, 4320, 17280, 17280, 66, 17280, 17280, 17280, 17280, 4320, 66, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 238260 . Total input tokens: 53168695 . Total output tokens: 47604318
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 11.289871413260698,
    "estimated_duration": 3599.991756060542,
    "input_throughput": 5484.2195032148775,
    "output_throughput": 4810.899350211939,
    "total_throughput": 10295.118853426817,
    "itl": 40.249756689291424,
    "ttft": 46569.67108339217,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 182,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.605296407565476,
    "arrivals": 79675,
    "finished_requests": 78965,
    "scheduler_time": 56.50206222499874
}
#Debug simulation 
Total elapsed time: 11.290066381450742. Arrivals time: 0.2107230518013239 Scheduler time: 10.783232950605452 Scheduler overhead time: 0.11554231168702245 Adapter cache time: 0.018862897995859385 Engine time: 0.11061008041724563 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-16/adapters_32_slots_16_rate_1.6-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-16/adapters_32_slots_16_rate_1.6-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 66, 66, 4320, 66, 17280, 4320, 66, 66, 66, 17280, 17280, 66, 66, 4320, 4320, 4320, 17280, 17280, 66, 17280, 17280, 17280, 17280, 4320, 66, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 238260 . Total input tokens: 53168695 . Total output tokens: 47604318
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 11.259890285786241,
    "estimated_duration": 3599.997846177815,
    "input_throughput": 5484.210225559347,
    "output_throughput": 4810.891211612284,
    "total_throughput": 10295.10143717163,
    "itl": 40.24864181349126,
    "ttft": 46569.67714806477,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 182,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5441891536721967,
    "arrivals": 79675,
    "finished_requests": 78965,
    "scheduler_time": 56.5017282980581
}
#Debug simulation 
Total elapsed time: 11.259978001005948. Arrivals time: 0.2044068118557334 Scheduler time: 10.760630645323545 Scheduler overhead time: 0.11492117727175355 Adapter cache time: 0.018776806071400642 Engine time: 0.11023430293425918 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-32/adapters_32_slots_16_rate_1.6-0.4-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-32/adapters_32_slots_16_rate_1.6-0.4-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 66, 66, 4320, 66, 17280, 4320, 66, 66, 66, 17280, 17280, 66, 66, 4320, 4320, 4320, 17280, 17280, 66, 17280, 17280, 17280, 17280, 4320, 66, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 238260 . Total input tokens: 53168695 . Total output tokens: 47604318
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 11.46241238201037,
    "estimated_duration": 3599.997853087182,
    "input_throughput": 5488.124384034607,
    "output_throughput": 4817.697595326867,
    "total_throughput": 10305.821979361473,
    "itl": 40.33175996327699,
    "ttft": 44225.06375909236,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 183,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6139131068810831,
    "arrivals": 79675,
    "finished_requests": 79033,
    "scheduler_time": 56.62683167013703
}
#Debug simulation 
Total elapsed time: 11.462499816901982. Arrivals time: 0.20782741392031312 Scheduler time: 10.95978019433096 Scheduler overhead time: 0.11460908781737089 Adapter cache time: 0.018744290806353092 Engine time: 0.11060410924255848 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-8/adapters_32_slots_16_rate_1.6-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-8/adapters_32_slots_16_rate_1.6-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 33, 33, 4320, 33, 17280, 4320, 33, 33, 33, 17280, 17280, 33, 33, 4320, 4320, 4320, 17280, 17280, 33, 17280, 17280, 17280, 17280, 4320, 33, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 237930 . Total input tokens: 53094608 . Total output tokens: 47535877
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 11.540757669135928,
    "estimated_duration": 3600.016082314856,
    "input_throughput": 5468.971957297513,
    "output_throughput": 4839.924767446114,
    "total_throughput": 10308.896724743627,
    "itl": 40.45392223964543,
    "ttft": 34336.55228043342,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 169,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5172224287246348,
    "arrivals": 79540,
    "finished_requests": 79134,
    "scheduler_time": 57.06215444492349
}
#Debug simulation 
Total elapsed time: 11.540896945167333. Arrivals time: 0.206661784555763 Scheduler time: 11.03961216006428 Scheduler overhead time: 0.11457030568271875 Adapter cache time: 0.018633199855685234 Engine time: 0.11067175678908825 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-16/adapters_32_slots_16_rate_1.6-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-16/adapters_32_slots_16_rate_1.6-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 33, 33, 4320, 33, 17280, 4320, 33, 33, 33, 17280, 17280, 33, 33, 4320, 4320, 4320, 17280, 17280, 33, 17280, 17280, 17280, 17280, 4320, 33, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 237930 . Total input tokens: 53094608 . Total output tokens: 47535877
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 11.587622778024524,
    "estimated_duration": 3599.997894330082,
    "input_throughput": 5468.942087718566,
    "output_throughput": 4839.940886477202,
    "total_throughput": 10308.882974195769,
    "itl": 40.45438256886972,
    "ttft": 34381.92671390196,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 169,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5510811755037873,
    "arrivals": 79540,
    "finished_requests": 79133,
    "scheduler_time": 57.062128443927044
}
#Debug simulation 
Total elapsed time: 11.587710105348378. Arrivals time: 0.20290938764810562 Scheduler time: 11.088405596558005 Scheduler overhead time: 0.11552917305380106 Adapter cache time: 0.018824465107172728 Engine time: 0.11124341934919357 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-32/adapters_32_slots_16_rate_1.6-0.4-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-32/adapters_32_slots_16_rate_1.6-0.4-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 33, 33, 4320, 33, 17280, 4320, 33, 33, 33, 17280, 17280, 33, 33, 4320, 4320, 4320, 17280, 17280, 33, 17280, 17280, 17280, 17280, 4320, 33, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 237930 . Total input tokens: 53094608 . Total output tokens: 47535877
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 11.601133082993329,
    "estimated_duration": 3600.003630203632,
    "input_throughput": 5468.990874013741,
    "output_throughput": 4839.941508340766,
    "total_throughput": 10308.932382354507,
    "itl": 40.45446669884936,
    "ttft": 34336.713497563804,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 169,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5521264048293253,
    "arrivals": 79540,
    "finished_requests": 79134,
    "scheduler_time": 57.06231735202928
}
#Debug simulation 
Total elapsed time: 11.601224482990801. Arrivals time: 0.20426568761467934 Scheduler time: 11.101863899733871 Scheduler overhead time: 0.11524972040206194 Adapter cache time: 0.018727497663348913 Engine time: 0.110438983887434 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-16/adapters_32_slots_16_rate_1.6-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-16/adapters_32_slots_16_rate_1.6-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 33, 33, 4320, 33, 17280, 4320, 33, 33, 33, 17280, 17280, 33, 33, 4320, 4320, 4320, 17280, 17280, 33, 17280, 17280, 17280, 17280, 4320, 33, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 237930 . Total input tokens: 53094608 . Total output tokens: 47535877
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 11.55595903005451,
    "estimated_duration": 3599.9834147739552,
    "input_throughput": 5468.964084445992,
    "output_throughput": 4839.960353287918,
    "total_throughput": 10308.924437733911,
    "itl": 40.45413363626244,
    "ttft": 34381.722066610404,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 169,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5232966938498435,
    "arrivals": 79540,
    "finished_requests": 79133,
    "scheduler_time": 57.06163672817041
}
#Debug simulation 
Total elapsed time: 11.556044187862426. Arrivals time: 0.20618648920208216 Scheduler time: 11.054475304670632 Scheduler overhead time: 0.11583314882591367 Adapter cache time: 0.01846060110256076 Engine time: 0.11010708333924413 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-32/adapters_32_slots_16_rate_1.6-0.4-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-32/adapters_32_slots_16_rate_1.6-0.4-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 33, 33, 4320, 33, 17280, 4320, 33, 33, 33, 17280, 17280, 33, 33, 4320, 4320, 4320, 17280, 17280, 33, 17280, 17280, 17280, 17280, 4320, 33, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 237930 . Total input tokens: 53094608 . Total output tokens: 47535877
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 11.376504121813923,
    "estimated_duration": 3599.992127310789,
    "input_throughput": 5470.328629499218,
    "output_throughput": 4840.618641301709,
    "total_throughput": 10310.947270800927,
    "itl": 40.47466924554431,
    "ttft": 33258.4394200593,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 171,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5675649487786006,
    "arrivals": 79540,
    "finished_requests": 79151,
    "scheduler_time": 57.032166370036016
}
#Debug simulation 
Total elapsed time: 11.37665838887915. Arrivals time: 0.20583770936354995 Scheduler time: 10.880072067026049 Scheduler overhead time: 0.11341874208301306 Adapter cache time: 0.018410709220916033 Engine time: 0.10837695933878422 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-16/adapters_32_slots_16_rate_1.6-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-16/adapters_32_slots_16_rate_1.6-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 33, 33, 4320, 33, 17280, 4320, 33, 33, 33, 17280, 17280, 33, 33, 4320, 4320, 4320, 17280, 17280, 33, 17280, 17280, 17280, 17280, 4320, 33, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 237930 . Total input tokens: 53094608 . Total output tokens: 47535877
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 11.352936462964863,
    "estimated_duration": 3600.010999897537,
    "input_throughput": 5470.299952016952,
    "output_throughput": 4840.593264991685,
    "total_throughput": 10310.893217008637,
    "itl": 40.474082037276716,
    "ttft": 33257.48141804358,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 171,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5112986004282727,
    "arrivals": 79540,
    "finished_requests": 79151,
    "scheduler_time": 57.03198426826607
}
#Debug simulation 
Total elapsed time: 11.353030460886657. Arrivals time: 0.19945858232676983 Scheduler time: 10.860966116655618 Scheduler overhead time: 0.11462565697729588 Adapter cache time: 0.01843294780701399 Engine time: 0.10902838641777635 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-32/adapters_32_slots_16_rate_1.6-0.4-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-32/adapters_32_slots_16_rate_1.6-0.4-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 4320, 33, 33, 4320, 33, 17280, 4320, 33, 33, 33, 17280, 17280, 33, 33, 4320, 4320, 4320, 17280, 17280, 33, 17280, 17280, 17280, 17280, 4320, 33, 4320, 4320, 4320, 4320, 17280]
Prompts retrieved: 237930 . Total input tokens: 53094608 . Total output tokens: 47535877
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 11.356305316090584,
    "estimated_duration": 3600.0026776283817,
    "input_throughput": 5470.312597926592,
    "output_throughput": 4840.604455183368,
    "total_throughput": 10310.91705310996,
    "itl": 40.47515836196613,
    "ttft": 33257.83917435011,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 171,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.573223869167269,
    "arrivals": 79540,
    "finished_requests": 79151,
    "scheduler_time": 57.03225673204398
}
#Debug simulation 
Total elapsed time: 11.356390024069697. Arrivals time: 0.2023715996183455 Scheduler time: 10.862004768103361 Scheduler overhead time: 0.11402222514152527 Adapter cache time: 0.01854542177170515 Engine time: 0.10888860002160072 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-8/adapters_32_slots_16_rate_1.6-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-8/adapters_32_slots_16_rate_1.6-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [10 11 11]
Adapter prompts. [17280, 1080, 540, 540, 1080, 540, 17280, 1080, 540, 540, 540, 17280, 17280, 540, 540, 1080, 1080, 1080, 17280, 17280, 540, 17280, 17280, 17280, 17280, 1080, 540, 1080, 1080, 1080, 1080, 17280]
Prompts retrieved: 207360 . Total input tokens: 46296826 . Total output tokens: 41478695
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 5.818516988772899,
    "estimated_duration": 3600.0241632848565,
    "input_throughput": 4815.889064527972,
    "output_throughput": 4248.813981860404,
    "total_throughput": 9064.703046388375,
    "itl": 35.16154497270345,
    "ttft": 11836.947850688259,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 778,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.381059464779729,
    "arrivals": 69453,
    "finished_requests": 69271,
    "scheduler_time": 44.00293703716488
}
#Debug simulation 
Total elapsed time: 5.818595695775002. Arrivals time: 0.17035193089395761 Scheduler time: 5.349359123501927 Scheduler overhead time: 0.1131283575668931 Adapter cache time: 0.022077864035964012 Engine time: 0.11120144836604595 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-16/adapters_32_slots_16_rate_1.6-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-16/adapters_32_slots_16_rate_1.6-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [10 11 11]
Adapter prompts. [17280, 1080, 540, 540, 1080, 540, 17280, 1080, 540, 540, 540, 17280, 17280, 540, 540, 1080, 1080, 1080, 17280, 17280, 540, 17280, 17280, 17280, 17280, 1080, 540, 1080, 1080, 1080, 1080, 17280]
Prompts retrieved: 207360 . Total input tokens: 46296826 . Total output tokens: 41478695
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 5.826856615953147,
    "estimated_duration": 3600.0109878227854,
    "input_throughput": 4815.906689908539,
    "output_throughput": 4248.829531837238,
    "total_throughput": 9064.736221745778,
    "itl": 35.1640803386784,
    "ttft": 11785.422734439284,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 778,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5236106682405817,
    "arrivals": 69453,
    "finished_requests": 69271,
    "scheduler_time": 44.004061670948616
}
#Debug simulation 
Total elapsed time: 5.826940053142607. Arrivals time: 0.17245896393433213 Scheduler time: 5.3563158474862576 Scheduler overhead time: 0.11352658085525036 Adapter cache time: 0.021920420695096254 Engine time: 0.11021034931764007 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-32/adapters_32_slots_16_rate_1.6-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-32/adapters_32_slots_16_rate_1.6-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [10 11 11]
Adapter prompts. [17280, 1080, 540, 540, 1080, 540, 17280, 1080, 540, 540, 540, 17280, 17280, 540, 540, 1080, 1080, 1080, 17280, 17280, 540, 17280, 17280, 17280, 17280, 1080, 540, 1080, 1080, 1080, 1080, 17280]
Prompts retrieved: 207360 . Total input tokens: 46296826 . Total output tokens: 41478695
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 5.7708525457419455,
    "estimated_duration": 3600.021991252056,
    "input_throughput": 4815.891970140503,
    "output_throughput": 4248.816545334559,
    "total_throughput": 9064.708515475062,
    "itl": 35.16425426495348,
    "ttft": 11837.17224609999,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 778,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5307482041977285,
    "arrivals": 69453,
    "finished_requests": 69271,
    "scheduler_time": 44.00422613677424
}
#Debug simulation 
Total elapsed time: 5.770936177112162. Arrivals time: 0.1687452127225697 Scheduler time: 5.306888661812991 Scheduler overhead time: 0.11242278851568699 Adapter cache time: 0.021708817221224308 Engine time: 0.10897941142320633 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-16-16/adapters_32_slots_16_rate_1.6-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-16-16/adapters_32_slots_16_rate_1.6-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [10 11 11]
Adapter prompts. [17280, 1080, 540, 540, 1080, 540, 17280, 1080, 540, 540, 540, 17280, 17280, 540, 540, 1080, 1080, 1080, 17280, 17280, 540, 17280, 17280, 17280, 17280, 1080, 540, 1080, 1080, 1080, 1080, 17280]
Prompts retrieved: 207360 . Total input tokens: 46296826 . Total output tokens: 41478695
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 5.794899268075824,
    "estimated_duration": 3600.0255508982746,
    "input_throughput": 4815.887208265511,
    "output_throughput": 4248.8123441744465,
    "total_throughput": 9064.699552439957,
    "itl": 35.161742991024795,
    "ttft": 11837.153479219589,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 778,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.403075049300649,
    "arrivals": 69453,
    "finished_requests": 69271,
    "scheduler_time": 44.00315012518272
}
#Debug simulation 
Total elapsed time: 5.794970849063247. Arrivals time: 0.16716551641002297 Scheduler time: 5.332670504692942 Scheduler overhead time: 0.11273465910926461 Adapter cache time: 0.021681136451661587 Engine time: 0.10831119492650032 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-16-32/adapters_32_slots_16_rate_1.6-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-16-32/adapters_32_slots_16_rate_1.6-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [10 11 11]
Adapter prompts. [17280, 1080, 540, 540, 1080, 540, 17280, 1080, 540, 540, 540, 17280, 17280, 540, 540, 1080, 1080, 1080, 17280, 17280, 540, 17280, 17280, 17280, 17280, 1080, 540, 1080, 1080, 1080, 1080, 17280]
Prompts retrieved: 207360 . Total input tokens: 46296826 . Total output tokens: 41478695
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 5.799233019351959,
    "estimated_duration": 3600.0096310733,
    "input_throughput": 4815.908504897829,
    "output_throughput": 4248.831133109977,
    "total_throughput": 9064.739638007806,
    "itl": 35.16479983512708,
    "ttft": 11785.6030233944,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 778,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.567845571190125,
    "arrivals": 69453,
    "finished_requests": 69271,
    "scheduler_time": 44.00437036128622
}
#Debug simulation 
Total elapsed time: 5.799358780030161. Arrivals time: 0.16989914467558265 Scheduler time: 5.331905412487686 Scheduler overhead time: 0.11324019869789481 Adapter cache time: 0.021888327319175005 Engine time: 0.10982697643339634 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_16-16-16/adapters_32_slots_16_rate_1.6-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_16-16-16/adapters_32_slots_16_rate_1.6-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [10 11 11]
Adapter prompts. [17280, 1080, 540, 540, 1080, 540, 17280, 1080, 540, 540, 540, 17280, 17280, 540, 540, 1080, 1080, 1080, 17280, 17280, 540, 17280, 17280, 17280, 17280, 1080, 540, 1080, 1080, 1080, 1080, 17280]
Prompts retrieved: 207360 . Total input tokens: 46296826 . Total output tokens: 41478695
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 5.823577689938247,
    "estimated_duration": 3600.003221878844,
    "input_throughput": 4815.91707880518,
    "output_throughput": 4248.838697432358,
    "total_throughput": 9064.755776237538,
    "itl": 35.160556663155035,
    "ttft": 11785.136913549537,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 778,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.326259129433847,
    "arrivals": 69453,
    "finished_requests": 69271,
    "scheduler_time": 44.00218691679636
}
#Debug simulation 
Total elapsed time: 5.8236475717276335. Arrivals time: 0.17072439519688487 Scheduler time: 5.352984372060746 Scheduler overhead time: 0.11411245632916689 Adapter cache time: 0.02192086400464177 Engine time: 0.11108341068029404 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_16-16-32/adapters_32_slots_16_rate_1.6-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_16-16-32/adapters_32_slots_16_rate_1.6-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [10 11 11]
Adapter prompts. [17280, 1080, 540, 540, 1080, 540, 17280, 1080, 540, 540, 540, 17280, 17280, 540, 540, 1080, 1080, 1080, 17280, 17280, 540, 17280, 17280, 17280, 17280, 1080, 540, 1080, 1080, 1080, 1080, 17280]
Prompts retrieved: 207360 . Total input tokens: 46296826 . Total output tokens: 41478695
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 5.781630609650165,
    "estimated_duration": 3600.0129868540434,
    "input_throughput": 4815.9040157104055,
    "output_throughput": 4248.8271725282375,
    "total_throughput": 9064.731188238644,
    "itl": 35.16535771231262,
    "ttft": 11785.480955237976,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 778,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5914872830361273,
    "arrivals": 69453,
    "finished_requests": 69271,
    "scheduler_time": 44.00459345617807
}
#Debug simulation 
Total elapsed time: 5.781713298056275. Arrivals time: 0.1689100624062121 Scheduler time: 5.3168772011995316 Scheduler overhead time: 0.11256062425673008 Adapter cache time: 0.021711476147174835 Engine time: 0.10956320026889443 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-8/adapters_32_slots_16_rate_1.6-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-8/adapters_32_slots_16_rate_1.6-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [10 11 11]
Adapter prompts. [17280, 1080, 270, 270, 1080, 270, 17280, 1080, 270, 270, 270, 17280, 17280, 270, 270, 1080, 1080, 1080, 17280, 17280, 270, 17280, 17280, 17280, 17280, 1080, 270, 1080, 1080, 1080, 1080, 17280]
Prompts retrieved: 204660 . Total input tokens: 45688111 . Total output tokens: 40931793
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 5.37769175786525,
    "estimated_duration": 3599.9495035925224,
    "input_throughput": 4736.768386051819,
    "output_throughput": 4187.595405145536,
    "total_throughput": 8924.363791197355,
    "itl": 34.80731180012417,
    "ttft": 12282.986596938501,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 998,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0543667684449582,
    "arrivals": 68538,
    "finished_requests": 68329,
    "scheduler_time": 42.7529381086704
}
#Debug simulation 
Total elapsed time: 5.3777748118154705. Arrivals time: 0.16752507211640477 Scheduler time: 4.910713687073439 Scheduler overhead time: 0.11381315439939499 Adapter cache time: 0.022864022757858038 Engine time: 0.11020445264875889 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-16/adapters_32_slots_16_rate_1.6-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-16/adapters_32_slots_16_rate_1.6-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [10 11 11]
Adapter prompts. [17280, 1080, 270, 270, 1080, 270, 17280, 1080, 270, 270, 270, 17280, 17280, 270, 270, 1080, 1080, 1080, 17280, 17280, 270, 17280, 17280, 17280, 17280, 1080, 270, 1080, 1080, 1080, 1080, 17280]
Prompts retrieved: 204660 . Total input tokens: 45688111 . Total output tokens: 40931793
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 5.406795871909708,
    "estimated_duration": 3599.950644663554,
    "input_throughput": 4736.766884645349,
    "output_throughput": 4187.594077809614,
    "total_throughput": 8924.360962454963,
    "itl": 34.810168276748385,
    "ttft": 12283.13869038326,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 998,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2480227700248387,
    "arrivals": 68538,
    "finished_requests": 68329,
    "scheduler_time": 42.754723396909675
}
#Debug simulation 
Total elapsed time: 5.406871248967946. Arrivals time: 0.1668344079516828 Scheduler time: 4.939950925763696 Scheduler overhead time: 0.11333199217915535 Adapter cache time: 0.02306367363780737 Engine time: 0.11068128747865558 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-32/adapters_32_slots_16_rate_1.6-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-32/adapters_32_slots_16_rate_1.6-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [10 11 11]
Adapter prompts. [17280, 1080, 270, 270, 1080, 270, 17280, 1080, 270, 270, 270, 17280, 17280, 270, 270, 1080, 1080, 1080, 17280, 17280, 270, 17280, 17280, 17280, 17280, 1080, 270, 1080, 1080, 1080, 1080, 17280]
Prompts retrieved: 204660 . Total input tokens: 45688111 . Total output tokens: 40931793
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 5.411675967276096,
    "estimated_duration": 3599.963012412532,
    "input_throughput": 4736.750611382654,
    "output_throughput": 4187.579691241697,
    "total_throughput": 8924.33030262435,
    "itl": 34.81083127003512,
    "ttft": 12283.13165492784,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 998,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.25529369253662,
    "arrivals": 68538,
    "finished_requests": 68329,
    "scheduler_time": 42.7549183328968
}
#Debug simulation 
Total elapsed time: 5.41175149101764. Arrivals time: 0.16732069896534085 Scheduler time: 4.945021737832576 Scheduler overhead time: 0.11375095136463642 Adapter cache time: 0.02304908912628889 Engine time: 0.10984291415661573 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-16-16/adapters_32_slots_16_rate_1.6-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-16-16/adapters_32_slots_16_rate_1.6-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [10 11 11]
Adapter prompts. [17280, 1080, 270, 270, 1080, 270, 17280, 1080, 270, 270, 270, 17280, 17280, 270, 270, 1080, 1080, 1080, 17280, 17280, 270, 17280, 17280, 17280, 17280, 1080, 270, 1080, 1080, 1080, 1080, 17280]
Prompts retrieved: 204660 . Total input tokens: 45688111 . Total output tokens: 40931793
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 5.368175780400634,
    "estimated_duration": 3599.9545139217444,
    "input_throughput": 4736.761793532672,
    "output_throughput": 4187.589576952,
    "total_throughput": 8924.351370484672,
    "itl": 34.81056234796921,
    "ttft": 12294.765360856707,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 974,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.012006244934123,
    "arrivals": 68538,
    "finished_requests": 68329,
    "scheduler_time": 42.75469417048465
}
#Debug simulation 
Total elapsed time: 5.368243338074535. Arrivals time: 0.16454153647646308 Scheduler time: 4.9068845035508275 Scheduler overhead time: 0.11284436983987689 Adapter cache time: 0.022909987717866898 Engine time: 0.10863204021006823 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-16-32/adapters_32_slots_16_rate_1.6-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-16-32/adapters_32_slots_16_rate_1.6-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [10 11 11]
Adapter prompts. [17280, 1080, 270, 270, 1080, 270, 17280, 1080, 270, 270, 270, 17280, 17280, 270, 270, 1080, 1080, 1080, 17280, 17280, 270, 17280, 17280, 17280, 17280, 1080, 270, 1080, 1080, 1080, 1080, 17280]
Prompts retrieved: 204660 . Total input tokens: 45688111 . Total output tokens: 40931793
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 5.404586512595415,
    "estimated_duration": 3599.965195691128,
    "input_throughput": 4736.7477386753735,
    "output_throughput": 4187.57715159128,
    "total_throughput": 8924.324890266655,
    "itl": 34.81099103848489,
    "ttft": 12288.284902105677,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 989,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2764372722618376,
    "arrivals": 68538,
    "finished_requests": 68329,
    "scheduler_time": 42.756095961125226
}
#Debug simulation 
Total elapsed time: 5.40469513181597. Arrivals time: 0.16711969953030348 Scheduler time: 4.938573068473488 Scheduler overhead time: 0.11336357705295086 Adapter cache time: 0.023069894406944513 Engine time: 0.11011931346729398 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_16-16-16/adapters_32_slots_16_rate_1.6-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_16-16-16/adapters_32_slots_16_rate_1.6-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [10 11 11]
Adapter prompts. [17280, 1080, 270, 270, 1080, 270, 17280, 1080, 270, 270, 270, 17280, 17280, 270, 270, 1080, 1080, 1080, 17280, 17280, 270, 17280, 17280, 17280, 17280, 1080, 270, 1080, 1080, 1080, 1080, 17280]
Prompts retrieved: 204660 . Total input tokens: 45688111 . Total output tokens: 40931793
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 5.431445993948728,
    "estimated_duration": 3599.9800971528607,
    "input_throughput": 4736.728131771097,
    "output_throughput": 4187.559817878595,
    "total_throughput": 8924.287949649692,
    "itl": 34.80579917422043,
    "ttft": 12282.838988190411,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 998,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9840701943123022,
    "arrivals": 68538,
    "finished_requests": 68329,
    "scheduler_time": 42.752715735042635
}
#Debug simulation 
Total elapsed time: 5.43152716383338. Arrivals time: 0.1719949566759169 Scheduler time: 4.958565351553261 Scheduler overhead time: 0.11432956671342254 Adapter cache time: 0.023285642731934786 Engine time: 0.11037400690838695 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_16-16-32/adapters_32_slots_16_rate_1.6-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_16-16-32/adapters_32_slots_16_rate_1.6-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [10 11 11]
Adapter prompts. [17280, 1080, 270, 270, 1080, 270, 17280, 1080, 270, 270, 270, 17280, 17280, 270, 270, 1080, 1080, 1080, 17280, 17280, 270, 17280, 17280, 17280, 17280, 1080, 270, 1080, 1080, 1080, 1080, 17280]
Prompts retrieved: 204660 . Total input tokens: 45688111 . Total output tokens: 40931793
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 5.401380496099591,
    "estimated_duration": 3599.985509051318,
    "input_throughput": 4736.721010994747,
    "output_throughput": 4187.553522673112,
    "total_throughput": 8924.27453366786,
    "itl": 34.8113667231841,
    "ttft": 12288.31716696615,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 989,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.307749965079166,
    "arrivals": 68538,
    "finished_requests": 68329,
    "scheduler_time": 42.75670222087208
}
#Debug simulation 
Total elapsed time: 5.4014590182341635. Arrivals time: 0.16652724146842957 Scheduler time: 4.935318050906062 Scheduler overhead time: 0.11429566144943237 Adapter cache time: 0.023056249599903822 Engine time: 0.10951315890997648 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-8/adapters_32_slots_16_rate_1.6-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-8/adapters_32_slots_16_rate_1.6-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 1080, 135, 135, 1080, 135, 17280, 1080, 135, 135, 135, 17280, 17280, 135, 135, 1080, 1080, 1080, 17280, 17280, 135, 17280, 17280, 17280, 17280, 1080, 135, 1080, 1080, 1080, 1080, 17280]
Prompts retrieved: 203310 . Total input tokens: 45377207 . Total output tokens: 40662412
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 5.136693705338985,
    "estimated_duration": 3600.0238642590843,
    "input_throughput": 4741.079960455412,
    "output_throughput": 4120.612684619808,
    "total_throughput": 8861.69264507522,
    "itl": 34.32111185899821,
    "ttft": 10424.391384428378,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1081,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3083872511913857,
    "arrivals": 68105,
    "finished_requests": 67923,
    "scheduler_time": 41.480618666160595
}
#Debug simulation 
Total elapsed time: 5.1367710549384356. Arrivals time: 0.16469249036163092 Scheduler time: 4.673832224216312 Scheduler overhead time: 0.11384553834795952 Adapter cache time: 0.02331320010125637 Engine time: 0.10845453524962068 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-16/adapters_32_slots_16_rate_1.6-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-16/adapters_32_slots_16_rate_1.6-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 1080, 135, 135, 1080, 135, 17280, 1080, 135, 135, 135, 17280, 17280, 135, 135, 1080, 1080, 1080, 17280, 17280, 135, 17280, 17280, 17280, 17280, 1080, 135, 1080, 1080, 1080, 1080, 17280]
Prompts retrieved: 203310 . Total input tokens: 45377207 . Total output tokens: 40662412
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 5.1613441640511155,
    "estimated_duration": 3600.035202529554,
    "input_throughput": 4741.065028477283,
    "output_throughput": 4120.5997067964,
    "total_throughput": 8861.664735273682,
    "itl": 34.32472157844448,
    "ttft": 10425.661580185873,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1080,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.536517997961501,
    "arrivals": 68105,
    "finished_requests": 67923,
    "scheduler_time": 41.482689585383994
}
#Debug simulation 
Total elapsed time: 5.1614254410378635. Arrivals time: 0.1659197029657662 Scheduler time: 4.694101803004742 Scheduler overhead time: 0.11474142828956246 Adapter cache time: 0.0234625693410635 Engine time: 0.11026997910812497 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-32/adapters_32_slots_16_rate_1.6-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-32/adapters_32_slots_16_rate_1.6-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 1080, 135, 135, 1080, 135, 17280, 1080, 135, 135, 135, 17280, 17280, 135, 135, 1080, 1080, 1080, 17280, 17280, 135, 17280, 17280, 17280, 17280, 1080, 135, 1080, 1080, 1080, 1080, 17280]
Prompts retrieved: 203310 . Total input tokens: 45377207 . Total output tokens: 40662412
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 5.151995545718819,
    "estimated_duration": 3600.013425571306,
    "input_throughput": 4740.831208786822,
    "output_throughput": 4120.739076867691,
    "total_throughput": 8861.570285654512,
    "itl": 34.32517854475796,
    "ttft": 10478.302863269342,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1080,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5406104725598806,
    "arrivals": 68105,
    "finished_requests": 67922,
    "scheduler_time": 41.48370349825088
}
#Debug simulation 
Total elapsed time: 5.152083119843155. Arrivals time: 0.1647410993464291 Scheduler time: 4.688592569902539 Scheduler overhead time: 0.1139248963445425 Adapter cache time: 0.023393234703689814 Engine time: 0.10858899960294366 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-16/adapters_32_slots_16_rate_1.6-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-16/adapters_32_slots_16_rate_1.6-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 1080, 135, 135, 1080, 135, 17280, 1080, 135, 135, 135, 17280, 17280, 135, 135, 1080, 1080, 1080, 17280, 17280, 135, 17280, 17280, 17280, 17280, 1080, 135, 1080, 1080, 1080, 1080, 17280]
Prompts retrieved: 203310 . Total input tokens: 45377207 . Total output tokens: 40662412
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 5.152536841109395,
    "estimated_duration": 3600.035740012751,
    "input_throughput": 4740.801823245108,
    "output_throughput": 4120.713534901589,
    "total_throughput": 8861.515358146697,
    "itl": 34.32166138786434,
    "ttft": 10478.232949637255,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1080,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3383492685178746,
    "arrivals": 68105,
    "finished_requests": 67922,
    "scheduler_time": 41.482139273280325
}
#Debug simulation 
Total elapsed time: 5.152618972118944. Arrivals time: 0.16800107108429074 Scheduler time: 4.683132929727435 Scheduler overhead time: 0.11486398056149483 Adapter cache time: 0.023532951716333628 Engine time: 0.11024995194748044 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-32/adapters_32_slots_16_rate_1.6-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-32/adapters_32_slots_16_rate_1.6-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 1080, 135, 135, 1080, 135, 17280, 1080, 135, 135, 135, 17280, 17280, 135, 135, 1080, 1080, 1080, 17280, 17280, 135, 17280, 17280, 17280, 17280, 1080, 135, 1080, 1080, 1080, 1080, 17280]
Prompts retrieved: 203310 . Total input tokens: 45377207 . Total output tokens: 40662412
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 5.176325807813555,
    "estimated_duration": 3600.013859632508,
    "input_throughput": 4741.093136164291,
    "output_throughput": 4120.624136017715,
    "total_throughput": 8861.717272182006,
    "itl": 34.325610422699896,
    "ttft": 10424.705390259443,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1081,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.6045188240334536,
    "arrivals": 68105,
    "finished_requests": 67923,
    "scheduler_time": 41.48315448556257
}
#Debug simulation 
Total elapsed time: 5.176425699610263. Arrivals time: 0.17238724092021585 Scheduler time: 4.703103684820235 Scheduler overhead time: 0.11345759313553572 Adapter cache time: 0.02349129319190979 Engine time: 0.11101883463561535 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-16/adapters_32_slots_16_rate_1.6-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-16/adapters_32_slots_16_rate_1.6-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 1080, 135, 135, 1080, 135, 17280, 1080, 135, 135, 135, 17280, 17280, 135, 135, 1080, 1080, 1080, 17280, 17280, 135, 17280, 17280, 17280, 17280, 1080, 135, 1080, 1080, 1080, 1080, 17280]
Prompts retrieved: 203310 . Total input tokens: 45377207 . Total output tokens: 40662412
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 5.174073443282396,
    "estimated_duration": 3600.0224450392916,
    "input_throughput": 4741.081829508903,
    "output_throughput": 4120.614309069424,
    "total_throughput": 8861.696138578327,
    "itl": 34.31952030552612,
    "ttft": 10425.004684732234,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1080,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.229254318494272,
    "arrivals": 68105,
    "finished_requests": 67923,
    "scheduler_time": 41.47962565607904
}
#Debug simulation 
Total elapsed time: 5.174157023429871. Arrivals time: 0.1656964411959052 Scheduler time: 4.708631511311978 Scheduler overhead time: 0.11351974867284298 Adapter cache time: 0.023380018770694733 Engine time: 0.11012133304029703 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-32/adapters_32_slots_16_rate_1.6-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-32/adapters_32_slots_16_rate_1.6-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 1080, 135, 135, 1080, 135, 17280, 1080, 135, 135, 135, 17280, 17280, 135, 135, 1080, 1080, 1080, 17280, 17280, 135, 17280, 17280, 17280, 17280, 1080, 135, 1080, 1080, 1080, 1080, 17280]
Prompts retrieved: 203310 . Total input tokens: 45377207 . Total output tokens: 40662412
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 5.158993247896433,
    "estimated_duration": 3600.011720229817,
    "input_throughput": 4740.894565451709,
    "output_throughput": 4120.648529181179,
    "total_throughput": 8861.543094632889,
    "itl": 34.32645072935522,
    "ttft": 10477.51894888472,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1080,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.635177319943955,
    "arrivals": 68105,
    "finished_requests": 67922,
    "scheduler_time": 41.48498471999201
}
#Debug simulation 
Total elapsed time: 5.159076824784279. Arrivals time: 0.16515455534681678 Scheduler time: 4.693817799445242 Scheduler overhead time: 0.1143911019898951 Adapter cache time: 0.023617346305400133 Engine time: 0.10917164804413915 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-8/adapters_32_slots_16_rate_1.6-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-8/adapters_32_slots_16_rate_1.6-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 1080, 66, 66, 1080, 66, 17280, 1080, 66, 66, 66, 17280, 17280, 66, 66, 1080, 1080, 1080, 17280, 17280, 66, 17280, 17280, 17280, 17280, 1080, 66, 1080, 1080, 1080, 1080, 17280]
Prompts retrieved: 202620 . Total input tokens: 45215902 . Total output tokens: 40517626
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 5.107611352112144,
    "estimated_duration": 3599.969932679068,
    "input_throughput": 4709.496000535466,
    "output_throughput": 4134.895645898446,
    "total_throughput": 8844.391646433913,
    "itl": 34.44143461935414,
    "ttft": 9003.557417677865,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1075,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2900243247277885,
    "arrivals": 67887,
    "finished_requests": 67728,
    "scheduler_time": 41.67053222059919
}
#Debug simulation 
Total elapsed time: 5.107687069103122. Arrivals time: 0.1653416403569281 Scheduler time: 4.644641124177724 Scheduler overhead time: 0.11352869030088186 Adapter cache time: 0.023243474774062634 Engine time: 0.10831200471147895 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-16/adapters_32_slots_16_rate_1.6-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-16/adapters_32_slots_16_rate_1.6-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 1080, 66, 66, 1080, 66, 17280, 1080, 66, 66, 66, 17280, 17280, 66, 66, 1080, 1080, 1080, 17280, 17280, 66, 17280, 17280, 17280, 17280, 1080, 66, 1080, 1080, 1080, 1080, 17280]
Prompts retrieved: 202620 . Total input tokens: 45215902 . Total output tokens: 40517626
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 5.099222017917782,
    "estimated_duration": 3599.9481845610653,
    "input_throughput": 4709.409727814492,
    "output_throughput": 4134.853680349549,
    "total_throughput": 8844.26340816404,
    "itl": 34.44612475146507,
    "ttft": 9109.755589702709,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1075,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5370943685877285,
    "arrivals": 67887,
    "finished_requests": 67726,
    "scheduler_time": 41.67243825390247
}
#Debug simulation 
Total elapsed time: 5.099296277854592. Arrivals time: 0.1642620493657887 Scheduler time: 4.63657715683803 Scheduler overhead time: 0.11324370140209794 Adapter cache time: 0.023440490011125803 Engine time: 0.10923122148960829 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-32/adapters_32_slots_16_rate_1.6-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-32/adapters_32_slots_16_rate_1.6-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 1080, 66, 66, 1080, 66, 17280, 1080, 66, 66, 66, 17280, 17280, 66, 66, 1080, 1080, 1080, 17280, 17280, 66, 17280, 17280, 17280, 17280, 1080, 66, 1080, 1080, 1080, 1080, 17280]
Prompts retrieved: 202620 . Total input tokens: 45215902 . Total output tokens: 40517626
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 5.096282477024943,
    "estimated_duration": 3599.951378373929,
    "input_throughput": 4709.443050216386,
    "output_throughput": 4134.9164017664225,
    "total_throughput": 8844.35945198281,
    "itl": 34.446388670381644,
    "ttft": 9056.72556023213,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1075,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5382082831114015,
    "arrivals": 67887,
    "finished_requests": 67727,
    "scheduler_time": 41.6725173805626
}
#Debug simulation 
Total elapsed time: 5.096372806001455. Arrivals time: 0.1636112229898572 Scheduler time: 4.634662477765232 Scheduler overhead time: 0.11332279955968261 Adapter cache time: 0.02345604356378317 Engine time: 0.10899690026417375 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-16/adapters_32_slots_16_rate_1.6-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-16/adapters_32_slots_16_rate_1.6-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 1080, 66, 66, 1080, 66, 17280, 1080, 66, 66, 66, 17280, 17280, 66, 66, 1080, 1080, 1080, 17280, 17280, 66, 17280, 17280, 17280, 17280, 1080, 66, 1080, 1080, 1080, 1080, 17280]
Prompts retrieved: 202620 . Total input tokens: 45215902 . Total output tokens: 40517626
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 5.069371616933495,
    "estimated_duration": 3599.9564028442082,
    "input_throughput": 4709.436477232163,
    "output_throughput": 4134.910630650819,
    "total_throughput": 8844.347107882983,
    "itl": 34.44281328158304,
    "ttft": 9056.538135236611,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1075,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3254419936355664,
    "arrivals": 67887,
    "finished_requests": 67727,
    "scheduler_time": 41.67066717209701
}
#Debug simulation 
Total elapsed time: 5.069467762950808. Arrivals time: 0.16256524343043566 Scheduler time: 4.61111454712227 Scheduler overhead time: 0.11197930620983243 Adapter cache time: 0.023424644954502583 Engine time: 0.10787323163822293 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-32/adapters_32_slots_16_rate_1.6-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-32/adapters_32_slots_16_rate_1.6-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 1080, 66, 66, 1080, 66, 17280, 1080, 66, 66, 66, 17280, 17280, 66, 66, 1080, 1080, 1080, 17280, 17280, 66, 17280, 17280, 17280, 17280, 1080, 66, 1080, 1080, 1080, 1080, 17280]
Prompts retrieved: 202620 . Total input tokens: 45215902 . Total output tokens: 40517626
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 5.078801448922604,
    "estimated_duration": 3599.95345207861,
    "input_throughput": 4709.440337405171,
    "output_throughput": 4134.914019903543,
    "total_throughput": 8844.354357308714,
    "itl": 34.44713052776895,
    "ttft": 9056.761243102404,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1075,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.603348744474368,
    "arrivals": 67887,
    "finished_requests": 67727,
    "scheduler_time": 41.6731476509951
}
#Debug simulation 
Total elapsed time: 5.078899838961661. Arrivals time: 0.16463786363601685 Scheduler time: 4.614917108789086 Scheduler overhead time: 0.11316002625972033 Adapter cache time: 0.02345638908445835 Engine time: 0.11031454289332032 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-16/adapters_32_slots_16_rate_1.6-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-16/adapters_32_slots_16_rate_1.6-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 1080, 66, 66, 1080, 66, 17280, 1080, 66, 66, 66, 17280, 17280, 66, 66, 1080, 1080, 1080, 17280, 17280, 66, 17280, 17280, 17280, 17280, 1080, 66, 1080, 1080, 1080, 1080, 17280]
Prompts retrieved: 202620 . Total input tokens: 45215902 . Total output tokens: 40517626
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 5.077894113026559,
    "estimated_duration": 3599.9490687302496,
    "input_throughput": 4709.446071685626,
    "output_throughput": 4134.919054632714,
    "total_throughput": 8844.365126318338,
    "itl": 34.44076648180052,
    "ttft": 9056.492131612138,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1075,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2143040670197616,
    "arrivals": 67887,
    "finished_requests": 67727,
    "scheduler_time": 41.669587200192225
}
#Debug simulation 
Total elapsed time: 5.077970803249627. Arrivals time: 0.16383020067587495 Scheduler time: 4.6151532949879766 Scheduler overhead time: 0.11273950664326549 Adapter cache time: 0.023328375071287155 Engine time: 0.11047357274219394 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-32/adapters_32_slots_16_rate_1.6-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-32/adapters_32_slots_16_rate_1.6-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 1080, 66, 66, 1080, 66, 17280, 1080, 66, 66, 66, 17280, 17280, 66, 66, 1080, 1080, 1080, 17280, 17280, 66, 17280, 17280, 17280, 17280, 1080, 66, 1080, 1080, 1080, 1080, 17280]
Prompts retrieved: 202620 . Total input tokens: 45215902 . Total output tokens: 40517626
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 5.105810649693012,
    "estimated_duration": 3599.936713333159,
    "input_throughput": 4709.424734387272,
    "output_throughput": 4134.866856094765,
    "total_throughput": 8844.291590482037,
    "itl": 34.447692189860284,
    "ttft": 9109.80894893258,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1075,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.637553774379246,
    "arrivals": 67887,
    "finished_requests": 67726,
    "scheduler_time": 41.67324770216206
}
#Debug simulation 
Total elapsed time: 5.1058832397684455. Arrivals time: 0.1642535445280373 Scheduler time: 4.643562435172498 Scheduler overhead time: 0.11328008258715272 Adapter cache time: 0.023306312039494514 Engine time: 0.1089749364182353 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-8/adapters_32_slots_16_rate_1.6-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-8/adapters_32_slots_16_rate_1.6-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 1080, 33, 33, 1080, 33, 17280, 1080, 33, 33, 33, 17280, 17280, 33, 33, 1080, 1080, 1080, 17280, 17280, 33, 17280, 17280, 17280, 17280, 1080, 33, 1080, 1080, 1080, 1080, 17280]
Prompts retrieved: 202290 . Total input tokens: 45146373 . Total output tokens: 40445837
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 5.098290324211121,
    "estimated_duration": 3600.0046617596845,
    "input_throughput": 4674.4706135392635,
    "output_throughput": 4157.221283342617,
    "total_throughput": 8831.69189688188,
    "itl": 34.59610885238745,
    "ttft": 9084.55821537243,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1007,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.081911158140354,
    "arrivals": 67772,
    "finished_requests": 67610,
    "scheduler_time": 42.04044891865607
}
#Debug simulation 
Total elapsed time: 5.0983684048987925. Arrivals time: 0.16576122399419546 Scheduler time: 4.636750840116292 Scheduler overhead time: 0.1126022357493639 Adapter cache time: 0.022920836228877306 Engine time: 0.10807863483205438 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-16/adapters_32_slots_16_rate_1.6-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-16/adapters_32_slots_16_rate_1.6-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 1080, 33, 33, 1080, 33, 17280, 1080, 33, 33, 33, 17280, 17280, 33, 33, 1080, 1080, 1080, 17280, 17280, 33, 17280, 17280, 17280, 17280, 1080, 33, 1080, 1080, 1080, 1080, 17280]
Prompts retrieved: 202290 . Total input tokens: 45146373 . Total output tokens: 40445837
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 5.078499422874302,
    "estimated_duration": 3600.0303986442636,
    "input_throughput": 4674.538861210017,
    "output_throughput": 4157.1921186099025,
    "total_throughput": 8831.73097981992,
    "itl": 34.600028047068214,
    "ttft": 9084.012073834463,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1008,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3314492596895615,
    "arrivals": 67772,
    "finished_requests": 67611,
    "scheduler_time": 42.04295255983021
}
#Debug simulation 
Total elapsed time: 5.078575097955763. Arrivals time: 0.16584536992013454 Scheduler time: 4.616569969803095 Scheduler overhead time: 0.11248014541342854 Adapter cache time: 0.022801996674388647 Engine time: 0.1087236157618463 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-32/adapters_32_slots_16_rate_1.6-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-32/adapters_32_slots_16_rate_1.6-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 1080, 33, 33, 1080, 33, 17280, 1080, 33, 33, 33, 17280, 17280, 33, 33, 1080, 1080, 1080, 17280, 17280, 33, 17280, 17280, 17280, 17280, 1080, 33, 1080, 1080, 1080, 1080, 17280]
Prompts retrieved: 202290 . Total input tokens: 45146373 . Total output tokens: 40445837
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 5.094279819633812,
    "estimated_duration": 3600.027188105261,
    "input_throughput": 4674.543030008904,
    "output_throughput": 4157.19582603397,
    "total_throughput": 8831.738856042874,
    "itl": 34.59983108561622,
    "ttft": 9084.010097987019,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1008,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3299083028174477,
    "arrivals": 67772,
    "finished_requests": 67611,
    "scheduler_time": 42.0428884948228
}
#Debug simulation 
Total elapsed time: 5.094356234651059. Arrivals time: 0.16473714401945472 Scheduler time: 4.632033125497401 Scheduler overhead time: 0.11216396698728204 Adapter cache time: 0.023120110854506493 Engine time: 0.11035702237859368 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-16/adapters_32_slots_16_rate_1.6-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-16/adapters_32_slots_16_rate_1.6-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 1080, 33, 33, 1080, 33, 17280, 1080, 33, 33, 33, 17280, 17280, 33, 33, 1080, 1080, 1080, 17280, 17280, 33, 17280, 17280, 17280, 17280, 1080, 33, 1080, 1080, 1080, 1080, 17280]
Prompts retrieved: 202290 . Total input tokens: 45146373 . Total output tokens: 40445837
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 5.131197488866746,
    "estimated_duration": 3600.0041362744364,
    "input_throughput": 4674.471295862188,
    "output_throughput": 4157.221890163713,
    "total_throughput": 8831.693186025901,
    "itl": 34.596706564544064,
    "ttft": 9084.04115514412,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1008,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.125517219195568,
    "arrivals": 67772,
    "finished_requests": 67610,
    "scheduler_time": 42.04069590615995
}
#Debug simulation 
Total elapsed time: 5.131278919056058. Arrivals time: 0.17378929536789656 Scheduler time: 4.6593727371655405 Scheduler overhead time: 0.11269354494288564 Adapter cache time: 0.023083179723471403 Engine time: 0.1099625900387764 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-32/adapters_32_slots_16_rate_1.6-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-32/adapters_32_slots_16_rate_1.6-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 1080, 33, 33, 1080, 33, 17280, 1080, 33, 33, 33, 17280, 17280, 33, 33, 1080, 1080, 1080, 17280, 17280, 33, 17280, 17280, 17280, 17280, 1080, 33, 1080, 1080, 1080, 1080, 17280]
Prompts retrieved: 202290 . Total input tokens: 45146373 . Total output tokens: 40445837
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 5.106700663920492,
    "estimated_duration": 3600.0108595309093,
    "input_throughput": 4674.3792328984,
    "output_throughput": 4157.176904169142,
    "total_throughput": 8831.556137067542,
    "itl": 34.60081526918174,
    "ttft": 9084.023522573063,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1008,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3937512124516203,
    "arrivals": 67772,
    "finished_requests": 67610,
    "scheduler_time": 42.041896311254646
}
#Debug simulation 
Total elapsed time: 5.106793985236436. Arrivals time: 0.16383923962712288 Scheduler time: 4.64610371273011 Scheduler overhead time: 0.11225271923467517 Adapter cache time: 0.023012984078377485 Engine time: 0.10937648499384522 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-16/adapters_32_slots_16_rate_1.6-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-16/adapters_32_slots_16_rate_1.6-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 1080, 33, 33, 1080, 33, 17280, 1080, 33, 33, 33, 17280, 17280, 33, 33, 1080, 1080, 1080, 17280, 17280, 33, 17280, 17280, 17280, 17280, 1080, 33, 1080, 1080, 1080, 1080, 17280]
Prompts retrieved: 202290 . Total input tokens: 45146373 . Total output tokens: 40445837
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 5.113467111252248,
    "estimated_duration": 3600.0362002544116,
    "input_throughput": 4674.53132799352,
    "output_throughput": 4157.185419119498,
    "total_throughput": 8831.716747113018,
    "itl": 34.59458636840983,
    "ttft": 9083.89924744169,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1008,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.013970697261323,
    "arrivals": 67772,
    "finished_requests": 67611,
    "scheduler_time": 42.040100761067116
}
#Debug simulation 
Total elapsed time: 5.113541140221059. Arrivals time: 0.16587140737101436 Scheduler time: 4.649075105320662 Scheduler overhead time: 0.11292392667382956 Adapter cache time: 0.02306092483922839 Engine time: 0.10981187550351024 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-32/adapters_32_slots_16_rate_1.6-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-32/adapters_32_slots_16_rate_1.6-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 1080, 33, 33, 1080, 33, 17280, 1080, 33, 33, 33, 17280, 17280, 33, 33, 1080, 1080, 1080, 17280, 17280, 33, 17280, 17280, 17280, 17280, 1080, 33, 1080, 1080, 1080, 1080, 17280]
Prompts retrieved: 202290 . Total input tokens: 45146373 . Total output tokens: 40445837
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 5.114247257821262,
    "estimated_duration": 3600.0034006315786,
    "input_throughput": 4674.472251067236,
    "output_throughput": 4157.222739671409,
    "total_throughput": 8831.694990738644,
    "itl": 34.60172508963249,
    "ttft": 9084.757778942778,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1007,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4245754760131697,
    "arrivals": 67772,
    "finished_requests": 67610,
    "scheduler_time": 42.043511544606844
}
#Debug simulation 
Total elapsed time: 5.1143348179757595. Arrivals time: 0.16545941028743982 Scheduler time: 4.65080699743703 Scheduler overhead time: 0.1132918638177216 Adapter cache time: 0.023043946363031864 Engine time: 0.10940844425931573 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-8/adapters_32_slots_16_rate_1.6-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-8/adapters_32_slots_16_rate_1.6-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [10 11 11]
Adapter prompts. [17280, 540, 270, 270, 540, 270, 17280, 540, 270, 270, 270, 17280, 17280, 270, 270, 540, 540, 540, 17280, 17280, 270, 17280, 17280, 17280, 17280, 540, 270, 540, 540, 540, 540, 17280]
Prompts retrieved: 198720 . Total input tokens: 44354450 . Total output tokens: 39727035
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 4.9336935873143375,
    "estimated_duration": 3599.936345267505,
    "input_throughput": 4610.722637310024,
    "output_throughput": 4054.0414052558817,
    "total_throughput": 8664.764042565905,
    "itl": 33.854004379427074,
    "ttft": 7302.654072199744,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1494,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.572368689435657,
    "arrivals": 66605,
    "finished_requests": 66478,
    "scheduler_time": 40.12189435397742
}
#Debug simulation 
Total elapsed time: 4.933769654948264. Arrivals time: 0.16025509778410196 Scheduler time: 4.472587670665234 Scheduler overhead time: 0.1137073035351932 Adapter cache time: 0.02518496848642826 Engine time: 0.10949851293116808 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-16/adapters_32_slots_16_rate_1.6-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-16/adapters_32_slots_16_rate_1.6-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [10 11 11]
Adapter prompts. [17280, 540, 270, 270, 540, 270, 17280, 540, 270, 270, 270, 17280, 17280, 270, 270, 540, 540, 540, 17280, 17280, 270, 17280, 17280, 17280, 17280, 540, 270, 540, 540, 540, 540, 17280]
Prompts retrieved: 198720 . Total input tokens: 44354450 . Total output tokens: 39727035
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.9223200851120055,
    "estimated_duration": 3599.957955935967,
    "input_throughput": 4610.694958987247,
    "output_throughput": 4054.0170687092295,
    "total_throughput": 8664.712027696478,
    "itl": 33.85741829937467,
    "ttft": 7297.969562085989,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1492,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.868115977160558,
    "arrivals": 66605,
    "finished_requests": 66478,
    "scheduler_time": 40.12310338417322
}
#Debug simulation 
Total elapsed time: 4.922391758300364. Arrivals time: 0.15982924588024616 Scheduler time: 4.462383105419576 Scheduler overhead time: 0.11281711515039206 Adapter cache time: 0.02536422573029995 Engine time: 0.10931607242673635 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-32/adapters_32_slots_16_rate_1.6-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-32/adapters_32_slots_16_rate_1.6-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [10 11 11]
Adapter prompts. [17280, 540, 270, 270, 540, 270, 17280, 540, 270, 270, 270, 17280, 17280, 270, 270, 540, 540, 540, 17280, 17280, 270, 17280, 17280, 17280, 17280, 540, 270, 540, 540, 540, 540, 17280]
Prompts retrieved: 198720 . Total input tokens: 44354450 . Total output tokens: 39727035
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.956368527375162,
    "estimated_duration": 3599.936023931882,
    "input_throughput": 4610.723048869958,
    "output_throughput": 4054.041767125624,
    "total_throughput": 8664.76481599558,
    "itl": 33.85742613112019,
    "ttft": 7298.009332819076,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1492,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.876828626915758,
    "arrivals": 66605,
    "finished_requests": 66478,
    "scheduler_time": 40.123019804229266
}
#Debug simulation 
Total elapsed time: 4.95644539501518. Arrivals time: 0.1612143712118268 Scheduler time: 4.4940868280828 Scheduler overhead time: 0.11341654602438211 Adapter cache time: 0.025334039237350225 Engine time: 0.10968033783137798 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-16-16/adapters_32_slots_16_rate_1.6-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-16-16/adapters_32_slots_16_rate_1.6-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [10 11 11]
Adapter prompts. [17280, 540, 270, 270, 540, 270, 17280, 540, 270, 270, 270, 17280, 17280, 270, 270, 540, 540, 540, 17280, 17280, 270, 17280, 17280, 17280, 17280, 540, 270, 540, 540, 540, 540, 17280]
Prompts retrieved: 198720 . Total input tokens: 44354450 . Total output tokens: 39727035
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 4.906621609814465,
    "estimated_duration": 3599.9402768216855,
    "input_throughput": 4610.717601863748,
    "output_throughput": 4054.036977770366,
    "total_throughput": 8664.754579634115,
    "itl": 33.85498535512662,
    "ttft": 7302.50671300033,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1496,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.620209555812083,
    "arrivals": 66605,
    "finished_requests": 66478,
    "scheduler_time": 40.1223209186587
}
#Debug simulation 
Total elapsed time: 4.906699625775218. Arrivals time: 0.16039584297686815 Scheduler time: 4.447501135990024 Scheduler overhead time: 0.1124587431550026 Adapter cache time: 0.025187400169670582 Engine time: 0.10891338530927896 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-16-32/adapters_32_slots_16_rate_1.6-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-16-32/adapters_32_slots_16_rate_1.6-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [10 11 11]
Adapter prompts. [17280, 540, 270, 270, 540, 270, 17280, 540, 270, 270, 270, 17280, 17280, 270, 270, 540, 540, 540, 17280, 17280, 270, 17280, 17280, 17280, 17280, 540, 270, 540, 540, 540, 540, 17280]
Prompts retrieved: 198720 . Total input tokens: 44354450 . Total output tokens: 39727035
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 4.924389129970223,
    "estimated_duration": 3599.956499544128,
    "input_throughput": 4610.696824281596,
    "output_throughput": 4054.0187087949853,
    "total_throughput": 8664.715533076582,
    "itl": 33.85845337194016,
    "ttft": 7297.86925253309,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1491,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.954141777586149,
    "arrivals": 66605,
    "finished_requests": 66478,
    "scheduler_time": 40.12386357279739
}
#Debug simulation 
Total elapsed time: 4.924490357283503. Arrivals time: 0.16002959851175547 Scheduler time: 4.4634164003655314 Scheduler overhead time: 0.11329502798616886 Adapter cache time: 0.025072227232158184 Engine time: 0.11029855953529477 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_16-16-16/adapters_32_slots_16_rate_1.6-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_16-16-16/adapters_32_slots_16_rate_1.6-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [10 11 11]
Adapter prompts. [17280, 540, 270, 270, 540, 270, 17280, 540, 270, 270, 270, 17280, 17280, 270, 270, 540, 540, 540, 17280, 17280, 270, 17280, 17280, 17280, 17280, 540, 270, 540, 540, 540, 540, 17280]
Prompts retrieved: 198720 . Total input tokens: 44354450 . Total output tokens: 39727035
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 4.9607226783409715,
    "estimated_duration": 3599.942581944055,
    "input_throughput": 4610.714649519915,
    "output_throughput": 4054.034381881373,
    "total_throughput": 8664.749031401288,
    "itl": 33.85059235343827,
    "ttft": 7297.6008682134625,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1495,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.470125190878631,
    "arrivals": 66605,
    "finished_requests": 66478,
    "scheduler_time": 40.11935576909868
}
#Debug simulation 
Total elapsed time: 4.960801430046558. Arrivals time: 0.16274808906018734 Scheduler time: 4.497508538886905 Scheduler overhead time: 0.11320196837186813 Adapter cache time: 0.025331485085189342 Engine time: 0.10923476703464985 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_16-16-32/adapters_32_slots_16_rate_1.6-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_16-16-32/adapters_32_slots_16_rate_1.6-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [10 11 11]
Adapter prompts. [17280, 540, 270, 270, 540, 270, 17280, 540, 270, 270, 270, 17280, 17280, 270, 270, 540, 540, 540, 17280, 17280, 270, 17280, 17280, 17280, 17280, 540, 270, 540, 540, 540, 540, 17280]
Prompts retrieved: 198720 . Total input tokens: 44354450 . Total output tokens: 39727035
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.947728439234197,
    "estimated_duration": 3599.937263310564,
    "input_throughput": 4610.721461500113,
    "output_throughput": 4054.040371408817,
    "total_throughput": 8664.76183290893,
    "itl": 33.85958613826251,
    "ttft": 7297.965755646833,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1495,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.013524961136244,
    "arrivals": 66605,
    "finished_requests": 66478,
    "scheduler_time": 40.12438016729347
}
#Debug simulation 
Total elapsed time: 4.947804025374353. Arrivals time: 0.16152129508554935 Scheduler time: 4.485131978522986 Scheduler overhead time: 0.11338056297972798 Adapter cache time: 0.02519699279218912 Engine time: 0.1097288760356605 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-8/adapters_32_slots_16_rate_1.6-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-8/adapters_32_slots_16_rate_1.6-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 540, 135, 135, 540, 135, 17280, 540, 135, 135, 135, 17280, 17280, 135, 135, 540, 540, 540, 17280, 17280, 135, 17280, 17280, 17280, 17280, 540, 135, 540, 540, 540, 540, 17280]
Prompts retrieved: 197370 . Total input tokens: 44032375 . Total output tokens: 39454431
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 4.819854757282883,
    "estimated_duration": 3600.0075496774493,
    "input_throughput": 4560.799879842221,
    "output_throughput": 4065.0859194201403,
    "total_throughput": 8625.885799262362,
    "itl": 33.80203792095378,
    "ttft": 8006.816743290385,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1488,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.55400576297206,
    "arrivals": 66148,
    "finished_requests": 66001,
    "scheduler_time": 40.188104131366885
}
#Debug simulation 
Total elapsed time: 4.819931549951434. Arrivals time: 0.15549780754372478 Scheduler time: 4.369613009970635 Scheduler overhead time: 0.11077358806505799 Adapter cache time: 0.025003556162118912 Engine time: 0.10751040233299136 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-16/adapters_32_slots_16_rate_1.6-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-16/adapters_32_slots_16_rate_1.6-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 540, 135, 135, 540, 135, 17280, 540, 135, 135, 135, 17280, 17280, 135, 135, 540, 540, 540, 17280, 17280, 135, 17280, 17280, 17280, 17280, 540, 135, 540, 540, 540, 540, 17280]
Prompts retrieved: 197370 . Total input tokens: 44032375 . Total output tokens: 39454431
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.820604719687253,
    "estimated_duration": 3600.0186278165875,
    "input_throughput": 4560.836122661451,
    "output_throughput": 4065.198409508232,
    "total_throughput": 8626.034532169682,
    "itl": 33.80737559745243,
    "ttft": 8061.098005319272,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1487,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.880133016703117,
    "arrivals": 66148,
    "finished_requests": 66002,
    "scheduler_time": 40.19147762563292
}
#Debug simulation 
Total elapsed time: 4.82068190490827. Arrivals time: 0.1562625141814351 Scheduler time: 4.367256966885179 Scheduler overhead time: 0.11131286201998591 Adapter cache time: 0.025066669564694166 Engine time: 0.10910178581252694 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-32/adapters_32_slots_16_rate_1.6-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-32/adapters_32_slots_16_rate_1.6-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 540, 135, 135, 540, 135, 17280, 540, 135, 135, 135, 17280, 17280, 135, 135, 540, 540, 540, 17280, 17280, 135, 17280, 17280, 17280, 17280, 540, 135, 540, 540, 540, 540, 17280]
Prompts retrieved: 197370 . Total input tokens: 44032375 . Total output tokens: 39454431
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.8122262340039015,
    "estimated_duration": 3600.0285317808066,
    "input_throughput": 4560.82440876602,
    "output_throughput": 4065.30555822025,
    "total_throughput": 8626.129966986271,
    "itl": 33.807410244803876,
    "ttft": 8060.974548364073,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1488,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.8872501336596335,
    "arrivals": 66148,
    "finished_requests": 66003,
    "scheduler_time": 40.191628494241264
}
#Debug simulation 
Total elapsed time: 4.812301184982061. Arrivals time: 0.15565611654892564 Scheduler time: 4.3625354170799255 Scheduler overhead time: 0.11050720000639558 Adapter cache time: 0.024986266624182463 Engine time: 0.10688516357913613 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-16/adapters_32_slots_16_rate_1.6-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-16/adapters_32_slots_16_rate_1.6-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 540, 135, 135, 540, 135, 17280, 540, 135, 135, 135, 17280, 17280, 135, 135, 540, 540, 540, 17280, 17280, 135, 17280, 17280, 17280, 17280, 540, 135, 540, 540, 540, 540, 17280]
Prompts retrieved: 197370 . Total input tokens: 44032375 . Total output tokens: 39454431
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 4.818592115771025,
    "estimated_duration": 3600.0046164242926,
    "input_throughput": 4560.803595943191,
    "output_throughput": 4065.0892316175887,
    "total_throughput": 8625.89282756078,
    "itl": 33.80318794486967,
    "ttft": 8006.804307744415,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1487,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.605965558029615,
    "arrivals": 66148,
    "finished_requests": 66001,
    "scheduler_time": 40.18865876535619
}
#Debug simulation 
Total elapsed time: 4.8186717890203. Arrivals time: 0.15606885217130184 Scheduler time: 4.367685637902468 Scheduler overhead time: 0.11030589416623116 Adapter cache time: 0.024981939233839512 Engine time: 0.10753128817304969 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-32/adapters_32_slots_16_rate_1.6-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-32/adapters_32_slots_16_rate_1.6-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 540, 135, 135, 540, 135, 17280, 540, 135, 135, 135, 17280, 17280, 135, 135, 540, 540, 540, 17280, 17280, 135, 17280, 17280, 17280, 17280, 540, 135, 540, 540, 540, 540, 17280]
Prompts retrieved: 197370 . Total input tokens: 44032375 . Total output tokens: 39454431
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 4.851718307007104,
    "estimated_duration": 3600.0263213161543,
    "input_throughput": 4560.82720917364,
    "output_throughput": 4065.308054372621,
    "total_throughput": 8626.13526354626,
    "itl": 33.80888365692973,
    "ttft": 8006.678333012614,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1487,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.968250158000701,
    "arrivals": 66148,
    "finished_requests": 66003,
    "scheduler_time": 40.192373407636765
}
#Debug simulation 
Total elapsed time: 4.851829375140369. Arrivals time: 0.157472622115165 Scheduler time: 4.396191206295043 Scheduler overhead time: 0.11261275503784418 Adapter cache time: 0.02527868514880538 Engine time: 0.10835006413981318 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-16/adapters_32_slots_16_rate_1.6-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-16/adapters_32_slots_16_rate_1.6-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 540, 135, 135, 540, 135, 17280, 540, 135, 135, 135, 17280, 17280, 135, 135, 540, 540, 540, 17280, 17280, 135, 17280, 17280, 17280, 17280, 540, 135, 540, 540, 540, 540, 17280]
Prompts retrieved: 197370 . Total input tokens: 44032375 . Total output tokens: 39454431
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 4.834151891991496,
    "estimated_duration": 3600.0071013612987,
    "input_throughput": 4560.800447807836,
    "output_throughput": 4065.0864256534946,
    "total_throughput": 8625.88687346133,
    "itl": 33.80041360843696,
    "ttft": 8006.757402404021,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1489,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.452184889109218,
    "arrivals": 66148,
    "finished_requests": 66001,
    "scheduler_time": 40.187130988005
}
#Debug simulation 
Total elapsed time: 4.834227960091084. Arrivals time: 0.15818284638226032 Scheduler time: 4.378570776432753 Scheduler overhead time: 0.11112854024395347 Adapter cache time: 0.02505790302529931 Engine time: 0.10964403580874205 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-32/adapters_32_slots_16_rate_1.6-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-32/adapters_32_slots_16_rate_1.6-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 540, 135, 135, 540, 135, 17280, 540, 135, 135, 135, 17280, 17280, 135, 135, 540, 540, 540, 17280, 17280, 135, 17280, 17280, 17280, 17280, 540, 135, 540, 540, 540, 540, 17280]
Prompts retrieved: 197370 . Total input tokens: 44032375 . Total output tokens: 39454431
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.830717018339783,
    "estimated_duration": 3600.028896165344,
    "input_throughput": 4560.823947132533,
    "output_throughput": 4065.3051467417513,
    "total_throughput": 8626.129093874284,
    "itl": 33.81005109528826,
    "ttft": 8060.872744997628,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1488,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.020926408618655,
    "arrivals": 66148,
    "finished_requests": 66003,
    "scheduler_time": 40.192769462008684
}
#Debug simulation 
Total elapsed time: 4.830793138127774. Arrivals time: 0.1590076582506299 Scheduler time: 4.376792692113668 Scheduler overhead time: 0.1104472428560257 Adapter cache time: 0.02517964132130146 Engine time: 0.10779203148558736 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-8/adapters_32_slots_16_rate_1.6-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-8/adapters_32_slots_16_rate_1.6-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 540, 66, 66, 540, 66, 17280, 540, 66, 66, 66, 17280, 17280, 66, 66, 540, 540, 540, 17280, 17280, 66, 17280, 17280, 17280, 17280, 540, 66, 540, 540, 540, 540, 17280]
Prompts retrieved: 196680 . Total input tokens: 43870822 . Total output tokens: 39320436
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 4.793181979097426,
    "estimated_duration": 3600.026843371844,
    "input_throughput": 4524.1937653845725,
    "output_throughput": 4060.215558367778,
    "total_throughput": 8584.40932375235,
    "itl": 33.598748595295135,
    "ttft": 8409.695647001205,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1280,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.917424312234025,
    "arrivals": 65922,
    "finished_requests": 65770,
    "scheduler_time": 39.98571808509408
}
#Debug simulation 
Total elapsed time: 4.7932578842155635. Arrivals time: 0.15511011704802513 Scheduler time: 4.346418644767255 Scheduler overhead time: 0.10970609076321125 Adapter cache time: 0.024254268035292625 Engine time: 0.10627891356125474 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-16/adapters_32_slots_16_rate_1.6-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-16/adapters_32_slots_16_rate_1.6-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 540, 66, 66, 540, 66, 17280, 540, 66, 66, 66, 17280, 17280, 66, 66, 540, 540, 540, 17280, 17280, 66, 17280, 17280, 17280, 17280, 540, 66, 540, 540, 540, 540, 17280]
Prompts retrieved: 196680 . Total input tokens: 43870822 . Total output tokens: 39320436
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.752553895115852,
    "estimated_duration": 3600.01752296048,
    "input_throughput": 4524.205478479499,
    "output_throughput": 4060.2260702275084,
    "total_throughput": 8584.431548707007,
    "itl": 33.60394944667593,
    "ttft": 8355.164730102137,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1282,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.223861602493555,
    "arrivals": 65922,
    "finished_requests": 65770,
    "scheduler_time": 39.98844433585791
}
#Debug simulation 
Total elapsed time: 4.75263246987015. Arrivals time: 0.1615021307952702 Scheduler time: 4.301748648751527 Scheduler overhead time: 0.10894194059073925 Adapter cache time: 0.02417005691677332 Engine time: 0.10529204737395048 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-32/adapters_32_slots_16_rate_1.6-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-32/adapters_32_slots_16_rate_1.6-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 540, 66, 66, 540, 66, 17280, 540, 66, 66, 66, 17280, 17280, 66, 66, 540, 540, 540, 17280, 17280, 66, 17280, 17280, 17280, 17280, 540, 66, 540, 540, 540, 540, 17280]
Prompts retrieved: 196680 . Total input tokens: 43870822 . Total output tokens: 39320436
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.770064702257514,
    "estimated_duration": 3600.0179317017432,
    "input_throughput": 4524.204964807207,
    "output_throughput": 4060.2256092348234,
    "total_throughput": 8584.430574042031,
    "itl": 33.60395268840804,
    "ttft": 8355.165942393827,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1282,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.2241997689008075,
    "arrivals": 65922,
    "finished_requests": 65770,
    "scheduler_time": 39.98846135327488
}
#Debug simulation 
Total elapsed time: 4.770137350074947. Arrivals time: 0.15387201542034745 Scheduler time: 4.324902406428009 Scheduler overhead time: 0.10863269865512848 Adapter cache time: 0.024177594110369682 Engine time: 0.10739407781511545 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-16/adapters_32_slots_16_rate_1.6-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-16/adapters_32_slots_16_rate_1.6-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 540, 66, 66, 540, 66, 17280, 540, 66, 66, 66, 17280, 17280, 66, 66, 540, 540, 540, 17280, 17280, 66, 17280, 17280, 17280, 17280, 540, 66, 540, 540, 540, 540, 17280]
Prompts retrieved: 196680 . Total input tokens: 43870822 . Total output tokens: 39320436
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 4.80360785825178,
    "estimated_duration": 3600.031907812725,
    "input_throughput": 4524.1874008543555,
    "output_throughput": 4060.2098465512754,
    "total_throughput": 8584.397247405632,
    "itl": 33.599613225598326,
    "ttft": 8409.588037232274,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1280,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9633266185153615,
    "arrivals": 65922,
    "finished_requests": 65770,
    "scheduler_time": 39.98616511141963
}
#Debug simulation 
Total elapsed time: 4.803688409272581. Arrivals time: 0.1557335895486176 Scheduler time: 4.353914360515773 Scheduler overhead time: 0.11020947806537151 Adapter cache time: 0.02433580532670021 Engine time: 0.10772849107161164 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-32/adapters_32_slots_16_rate_1.6-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-32/adapters_32_slots_16_rate_1.6-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 540, 66, 66, 540, 66, 17280, 540, 66, 66, 66, 17280, 17280, 66, 66, 540, 540, 540, 17280, 17280, 66, 17280, 17280, 17280, 17280, 540, 66, 540, 540, 540, 540, 17280]
Prompts retrieved: 196680 . Total input tokens: 43870822 . Total output tokens: 39320436
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 4.77469728467986,
    "estimated_duration": 3600.0023729820464,
    "input_throughput": 4524.074795681037,
    "output_throughput": 4060.1401014890093,
    "total_throughput": 8584.214897170046,
    "itl": 33.6046091710091,
    "ttft": 8464.405338391129,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1280,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.295531337577855,
    "arrivals": 65922,
    "finished_requests": 65768,
    "scheduler_time": 39.989003920300874
}
#Debug simulation 
Total elapsed time: 4.774790222756565. Arrivals time: 0.15389229077845812 Scheduler time: 4.3286999627016485 Scheduler overhead time: 0.10962054366245866 Adapter cache time: 0.024186202324926853 Engine time: 0.10678020911291242 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-16/adapters_32_slots_16_rate_1.6-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-16/adapters_32_slots_16_rate_1.6-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 540, 66, 66, 540, 66, 17280, 540, 66, 66, 66, 17280, 17280, 66, 66, 540, 540, 540, 17280, 17280, 66, 17280, 17280, 17280, 17280, 540, 66, 540, 540, 540, 540, 17280]
Prompts retrieved: 196680 . Total input tokens: 43870822 . Total output tokens: 39320436
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 4.743445714004338,
    "estimated_duration": 3600.008166288171,
    "input_throughput": 4524.092237488632,
    "output_throughput": 4060.2171786379117,
    "total_throughput": 8584.309416126544,
    "itl": 33.59713435796994,
    "ttft": 8409.746284742823,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1280,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.8272643774746857,
    "arrivals": 65922,
    "finished_requests": 65769,
    "scheduler_time": 39.98459482237503
}
#Debug simulation 
Total elapsed time: 4.743521221913397. Arrivals time: 0.15395817998796701 Scheduler time: 4.2992855864576995 Scheduler overhead time: 0.10921734338626266 Adapter cache time: 0.024043503683060408 Engine time: 0.10598864359781146 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-32/adapters_32_slots_16_rate_1.6-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-32/adapters_32_slots_16_rate_1.6-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 540, 66, 66, 540, 66, 17280, 540, 66, 66, 66, 17280, 17280, 66, 66, 540, 540, 540, 17280, 17280, 66, 17280, 17280, 17280, 17280, 540, 66, 540, 540, 540, 540, 17280]
Prompts retrieved: 196680 . Total input tokens: 43870822 . Total output tokens: 39320436
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.764422787819058,
    "estimated_duration": 3600.0098705432233,
    "input_throughput": 4524.065373615885,
    "output_throughput": 4060.1316456375275,
    "total_throughput": 8584.197019253412,
    "itl": 33.605609785454455,
    "ttft": 8464.475870032571,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1281,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.340913868583775,
    "arrivals": 65922,
    "finished_requests": 65768,
    "scheduler_time": 39.98946378595538
}
#Debug simulation 
Total elapsed time: 4.764499872922897. Arrivals time: 0.15594899794086814 Scheduler time: 4.31886491086334 Scheduler overhead time: 0.10865800036117435 Adapter cache time: 0.02410864131525159 Engine time: 0.10592152550816536 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-8/adapters_32_slots_16_rate_1.6-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-8/adapters_32_slots_16_rate_1.6-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 540, 33, 33, 540, 33, 17280, 540, 33, 33, 33, 17280, 17280, 33, 33, 540, 540, 540, 17280, 17280, 33, 17280, 17280, 17280, 17280, 540, 33, 540, 540, 540, 540, 17280]
Prompts retrieved: 196350 . Total input tokens: 43796335 . Total output tokens: 39251512
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 4.742500629276037,
    "estimated_duration": 3599.951160461709,
    "input_throughput": 4556.948766464936,
    "output_throughput": 4029.467165921095,
    "total_throughput": 8586.415932386031,
    "itl": 33.22984652480957,
    "ttft": 8020.929506247766,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1163,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.55934724619388,
    "arrivals": 65819,
    "finished_requests": 65674,
    "scheduler_time": 39.34259801599014
}
#Debug simulation 
Total elapsed time: 4.742575349286199. Arrivals time: 0.15289840148761868 Scheduler time: 4.295168336946517 Scheduler overhead time: 0.11044153477996588 Adapter cache time: 0.023798366077244282 Engine time: 0.10847702668979764 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-16/adapters_32_slots_16_rate_1.6-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-16/adapters_32_slots_16_rate_1.6-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 540, 33, 33, 540, 33, 17280, 540, 33, 33, 33, 17280, 17280, 33, 33, 540, 540, 540, 17280, 17280, 33, 17280, 17280, 17280, 17280, 540, 33, 540, 540, 540, 540, 17280]
Prompts retrieved: 196350 . Total input tokens: 43796335 . Total output tokens: 39251512
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.7279205629602075,
    "estimated_duration": 3599.967765840777,
    "input_throughput": 4557.100248415279,
    "output_throughput": 4029.457746161826,
    "total_throughput": 8586.557994577104,
    "itl": 33.23477390027237,
    "ttft": 7966.357673964335,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1163,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.840261135746279,
    "arrivals": 65819,
    "finished_requests": 65675,
    "scheduler_time": 39.345398364545524
}
#Debug simulation 
Total elapsed time: 4.727994067594409. Arrivals time: 0.1516640530899167 Scheduler time: 4.285535471513867 Scheduler overhead time: 0.10888844123110175 Adapter cache time: 0.023629268631339073 Engine time: 0.1069871005602181 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-32/adapters_32_slots_16_rate_1.6-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-32/adapters_32_slots_16_rate_1.6-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 540, 33, 33, 540, 33, 17280, 540, 33, 33, 33, 17280, 17280, 33, 33, 540, 540, 540, 17280, 17280, 33, 17280, 17280, 17280, 17280, 540, 33, 540, 540, 540, 540, 17280]
Prompts retrieved: 196350 . Total input tokens: 43796335 . Total output tokens: 39251512
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.723771839868277,
    "estimated_duration": 3599.964323402678,
    "input_throughput": 4557.104606107218,
    "output_throughput": 4029.461599299695,
    "total_throughput": 8586.566205406914,
    "itl": 33.23476198135878,
    "ttft": 7966.32587761885,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1163,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.8390881962701,
    "arrivals": 65819,
    "finished_requests": 65675,
    "scheduler_time": 39.34535884778148
}
#Debug simulation 
Total elapsed time: 4.723857991863042. Arrivals time: 0.15134679293259978 Scheduler time: 4.282767831347883 Scheduler overhead time: 0.10953946132212877 Adapter cache time: 0.023642046842724085 Engine time: 0.10525027196854353 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-16/adapters_32_slots_16_rate_1.6-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-16/adapters_32_slots_16_rate_1.6-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 540, 33, 33, 540, 33, 17280, 540, 33, 33, 33, 17280, 17280, 33, 33, 540, 540, 540, 17280, 17280, 33, 17280, 17280, 17280, 17280, 540, 33, 540, 540, 540, 540, 17280]
Prompts retrieved: 196350 . Total input tokens: 43796335 . Total output tokens: 39251512
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 4.713596611749381,
    "estimated_duration": 3599.9350074746017,
    "input_throughput": 4556.969213593709,
    "output_throughput": 4029.485246228391,
    "total_throughput": 8586.4544598221,
    "itl": 33.23023734438641,
    "ttft": 8021.02133082159,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1163,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5951039446819966,
    "arrivals": 65819,
    "finished_requests": 65674,
    "scheduler_time": 39.34272248212046
}
#Debug simulation 
Total elapsed time: 4.713680964894593. Arrivals time: 0.15184226026758552 Scheduler time: 4.270383931696415 Scheduler overhead time: 0.10925624845549464 Adapter cache time: 0.023990849498659372 Engine time: 0.10703673958778381 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-32/adapters_32_slots_16_rate_1.6-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-32/adapters_32_slots_16_rate_1.6-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 540, 33, 33, 540, 33, 17280, 540, 33, 33, 33, 17280, 17280, 33, 33, 540, 540, 540, 17280, 17280, 33, 17280, 17280, 17280, 17280, 540, 33, 540, 540, 540, 540, 17280]
Prompts retrieved: 196350 . Total input tokens: 43796335 . Total output tokens: 39251512
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 4.741340056061745,
    "estimated_duration": 3599.9493383924246,
    "input_throughput": 4556.951072907499,
    "output_throughput": 4029.46920538545,
    "total_throughput": 8586.42027829295,
    "itl": 33.235295769477965,
    "ttft": 8021.028336021513,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1162,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.911033947989368,
    "arrivals": 65819,
    "finished_requests": 65674,
    "scheduler_time": 39.34588979902582
}
#Debug simulation 
Total elapsed time: 4.74143622815609. Arrivals time: 0.15456926031038165 Scheduler time: 4.294698664452881 Scheduler overhead time: 0.10961857018992305 Adapter cache time: 0.02374457288533449 Engine time: 0.10710371844470501 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-16/adapters_32_slots_16_rate_1.6-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-16/adapters_32_slots_16_rate_1.6-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 540, 33, 33, 540, 33, 17280, 540, 33, 33, 33, 17280, 17280, 33, 33, 540, 540, 540, 17280, 17280, 33, 17280, 17280, 17280, 17280, 540, 33, 540, 540, 540, 540, 17280]
Prompts retrieved: 196350 . Total input tokens: 43796335 . Total output tokens: 39251512
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 4.7640107767656446,
    "estimated_duration": 3599.952224773496,
    "input_throughput": 4556.947419220867,
    "output_throughput": 4029.4659746248967,
    "total_throughput": 8586.413393845763,
    "itl": 33.22850841832158,
    "ttft": 8020.92670399089,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1163,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4774284929711436,
    "arrivals": 65819,
    "finished_requests": 65674,
    "scheduler_time": 39.341872168907415
}
#Debug simulation 
Total elapsed time: 4.764086210168898. Arrivals time: 0.15284257335588336 Scheduler time: 4.319121272303164 Scheduler overhead time: 0.10948894079774618 Adapter cache time: 0.02369429962709546 Engine time: 0.10730367712676525 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-32/adapters_32_slots_16_rate_1.6-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-32/adapters_32_slots_16_rate_1.6-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 540, 33, 33, 540, 33, 17280, 540, 33, 33, 33, 17280, 17280, 33, 33, 540, 540, 540, 17280, 17280, 33, 17280, 17280, 17280, 17280, 540, 33, 540, 540, 540, 540, 17280]
Prompts retrieved: 196350 . Total input tokens: 43796335 . Total output tokens: 39251512
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.7212823810987175,
    "estimated_duration": 3599.9424595343967,
    "input_throughput": 4556.959780440973,
    "output_throughput": 4029.476904993681,
    "total_throughput": 8586.436685434654,
    "itl": 33.236146020759925,
    "ttft": 8021.0371825243565,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1162,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.94725103847689,
    "arrivals": 65819,
    "finished_requests": 65674,
    "scheduler_time": 39.34618321577683
}
#Debug simulation 
Total elapsed time: 4.721356911119074. Arrivals time: 0.1523803500458598 Scheduler time: 4.27693726727739 Scheduler overhead time: 0.10932455770671368 Adapter cache time: 0.023733798414468765 Engine time: 0.10754986852407455 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-8/adapters_32_slots_16_rate_1.6-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-8/adapters_32_slots_16_rate_1.6-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 270, 135, 135, 270, 135, 17280, 270, 135, 135, 135, 17280, 17280, 135, 135, 270, 270, 270, 17280, 17280, 135, 17280, 17280, 17280, 17280, 270, 135, 270, 270, 270, 270, 17280]
Prompts retrieved: 194400 . Total input tokens: 43353626 . Total output tokens: 38858598
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 4.665288973134011,
    "estimated_duration": 3599.9932911015608,
    "input_throughput": 4463.876929915825,
    "output_throughput": 4013.9072024710463,
    "total_throughput": 8477.78413238687,
    "itl": 32.7537198711497,
    "ttft": 8957.131930668194,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1049,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.210451643385534,
    "arrivals": 65160,
    "finished_requests": 64999,
    "scheduler_time": 38.822558294142425
}
#Debug simulation 
Total elapsed time: 4.665362684056163. Arrivals time: 0.14989500865340233 Scheduler time: 4.223745298571885 Scheduler overhead time: 0.10957784624770284 Adapter cache time: 0.023049126844853163 Engine time: 0.10740502644330263 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-16/adapters_32_slots_16_rate_1.6-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-16/adapters_32_slots_16_rate_1.6-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 270, 135, 135, 270, 135, 17280, 270, 135, 135, 135, 17280, 17280, 135, 135, 270, 270, 270, 17280, 17280, 135, 17280, 17280, 17280, 17280, 270, 135, 270, 270, 270, 270, 17280]
Prompts retrieved: 194400 . Total input tokens: 43353626 . Total output tokens: 38858598
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.654340968001634,
    "estimated_duration": 3599.9788449607463,
    "input_throughput": 4463.89484274184,
    "output_throughput": 4013.923309640327,
    "total_throughput": 8477.818152382166,
    "itl": 32.7570742986244,
    "ttft": 8957.22350714311,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1049,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4250310541712734,
    "arrivals": 65160,
    "finished_requests": 64999,
    "scheduler_time": 38.82444143853813
}
#Debug simulation 
Total elapsed time: 4.654417370911688. Arrivals time: 0.150869261007756 Scheduler time: 4.213697494007647 Scheduler overhead time: 0.10882225167006254 Adapter cache time: 0.022957072127610445 Engine time: 0.10639039101079106 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-32/adapters_32_slots_16_rate_1.6-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-32/adapters_32_slots_16_rate_1.6-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 270, 135, 135, 270, 135, 17280, 270, 135, 135, 135, 17280, 17280, 135, 135, 270, 270, 270, 17280, 17280, 135, 17280, 17280, 17280, 17280, 270, 135, 270, 270, 270, 270, 17280]
Prompts retrieved: 194400 . Total input tokens: 43353626 . Total output tokens: 38858598
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.66921928524971,
    "estimated_duration": 3599.9900333158184,
    "input_throughput": 4463.880969469958,
    "output_throughput": 4013.910834828229,
    "total_throughput": 8477.791804298186,
    "itl": 32.7570788749997,
    "ttft": 8957.246843965424,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1049,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.430748003497679,
    "arrivals": 65160,
    "finished_requests": 64999,
    "scheduler_time": 38.824660137567285
}
#Debug simulation 
Total elapsed time: 4.66929469211027. Arrivals time: 0.15082055190578103 Scheduler time: 4.225209759082645 Scheduler overhead time: 0.11005687294527888 Adapter cache time: 0.023177494760602713 Engine time: 0.10828912863507867 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-16/adapters_32_slots_16_rate_1.6-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-16/adapters_32_slots_16_rate_1.6-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 270, 135, 135, 270, 135, 17280, 270, 135, 135, 135, 17280, 17280, 135, 135, 270, 270, 270, 17280, 17280, 135, 17280, 17280, 17280, 17280, 270, 135, 270, 270, 270, 270, 17280]
Prompts retrieved: 194400 . Total input tokens: 43353626 . Total output tokens: 38858598
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 4.669838189147413,
    "estimated_duration": 3599.98144553413,
    "input_throughput": 4463.891618090187,
    "output_throughput": 4013.920410041459,
    "total_throughput": 8477.812028131646,
    "itl": 32.753956153521,
    "ttft": 8957.302556143071,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1049,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2415717561915036,
    "arrivals": 65160,
    "finished_requests": 64999,
    "scheduler_time": 38.822737990611174
}
#Debug simulation 
Total elapsed time: 4.669913782272488. Arrivals time: 0.14994622999802232 Scheduler time: 4.229545380920172 Scheduler overhead time: 0.10946583235636353 Adapter cache time: 0.02308009983971715 Engine time: 0.10607732878997922 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-32/adapters_32_slots_16_rate_1.6-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-32/adapters_32_slots_16_rate_1.6-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 270, 135, 135, 270, 135, 17280, 270, 135, 135, 135, 17280, 17280, 135, 135, 270, 270, 270, 17280, 17280, 135, 17280, 17280, 17280, 17280, 270, 135, 270, 270, 270, 270, 17280]
Prompts retrieved: 194400 . Total input tokens: 43353626 . Total output tokens: 38858598
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 4.67925231391564,
    "estimated_duration": 3599.982012809543,
    "input_throughput": 4463.89091468224,
    "output_throughput": 4013.9197775387547,
    "total_throughput": 8477.810692220994,
    "itl": 32.757951550630494,
    "ttft": 8957.186012969658,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1049,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4872114535980048,
    "arrivals": 65160,
    "finished_requests": 64999,
    "scheduler_time": 38.82507434396907
}
#Debug simulation 
Total elapsed time: 4.6793513828888535. Arrivals time: 0.1517789294011891 Scheduler time: 4.2372538899071515 Scheduler overhead time: 0.1087904660962522 Adapter cache time: 0.02309432765468955 Engine time: 0.10694602457806468 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-16/adapters_32_slots_16_rate_1.6-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-16/adapters_32_slots_16_rate_1.6-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 270, 135, 135, 270, 135, 17280, 270, 135, 135, 135, 17280, 17280, 135, 135, 270, 270, 270, 17280, 17280, 135, 17280, 17280, 17280, 17280, 270, 135, 270, 270, 270, 270, 17280]
Prompts retrieved: 194400 . Total input tokens: 43353626 . Total output tokens: 38858598
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 4.692188178189099,
    "estimated_duration": 3599.97479782763,
    "input_throughput": 4463.899861103817,
    "output_throughput": 4013.927822139126,
    "total_throughput": 8477.827683242944,
    "itl": 32.75244289371082,
    "ttft": 8957.196188692966,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1049,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1365627593523078,
    "arrivals": 65160,
    "finished_requests": 64999,
    "scheduler_time": 38.821657411131575
}
#Debug simulation 
Total elapsed time: 4.692261829972267. Arrivals time: 0.15323639614507556 Scheduler time: 4.247745686210692 Scheduler overhead time: 0.10925494786351919 Adapter cache time: 0.022987897507846355 Engine time: 0.10737940855324268 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-32/adapters_32_slots_16_rate_1.6-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-32/adapters_32_slots_16_rate_1.6-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 270, 135, 135, 270, 135, 17280, 270, 135, 135, 135, 17280, 17280, 135, 135, 270, 270, 270, 17280, 17280, 135, 17280, 17280, 17280, 17280, 270, 135, 270, 270, 270, 270, 17280]
Prompts retrieved: 194400 . Total input tokens: 43353626 . Total output tokens: 38858598
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.675248756073415,
    "estimated_duration": 3600.0064479618845,
    "input_throughput": 4463.860893665305,
    "output_throughput": 4014.0211438179613,
    "total_throughput": 8477.882037483267,
    "itl": 32.758598586551834,
    "ttft": 8901.960699745407,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1049,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5195301767066574,
    "arrivals": 65160,
    "finished_requests": 65000,
    "scheduler_time": 38.825700268966465
}
#Debug simulation 
Total elapsed time: 4.675329141784459. Arrivals time: 0.15270511014387012 Scheduler time: 4.2310901107266545 Scheduler overhead time: 0.10870021535083652 Adapter cache time: 0.022921119816601276 Engine time: 0.10817138105630875 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-8/adapters_32_slots_16_rate_1.6-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-8/adapters_32_slots_16_rate_1.6-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 270, 66, 66, 270, 66, 17280, 270, 66, 66, 66, 17280, 17280, 66, 66, 270, 270, 270, 17280, 17280, 66, 17280, 17280, 17280, 17280, 270, 66, 270, 270, 270, 270, 17280]
Prompts retrieved: 193710 . Total input tokens: 43205196 . Total output tokens: 38713514
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 4.623111362103373,
    "estimated_duration": 3600.0007895026574,
    "input_throughput": 4484.380405436043,
    "output_throughput": 3970.5491292335864,
    "total_throughput": 8454.929534669629,
    "itl": 32.314605799001015,
    "ttft": 7094.731486691455,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 873,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6718058004533507,
    "arrivals": 64957,
    "finished_requests": 64830,
    "scheduler_time": 37.90181680264121
}
#Debug simulation 
Total elapsed time: 4.623188319150358. Arrivals time: 0.14909372199326754 Scheduler time: 4.182216717861593 Scheduler overhead time: 0.11049042083323002 Adapter cache time: 0.02255483902990818 Engine time: 0.10683279344812036 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-16/adapters_32_slots_16_rate_1.6-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-16/adapters_32_slots_16_rate_1.6-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 270, 66, 66, 270, 66, 17280, 270, 66, 66, 66, 17280, 17280, 66, 66, 270, 270, 270, 17280, 17280, 66, 17280, 17280, 17280, 17280, 270, 66, 270, 270, 270, 270, 17280]
Prompts retrieved: 193710 . Total input tokens: 43205196 . Total output tokens: 38713514
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.616074518300593,
    "estimated_duration": 3600.031393366055,
    "input_throughput": 4484.428394082744,
    "output_throughput": 3970.5425975841104,
    "total_throughput": 8454.970991666854,
    "itl": 32.31731504489713,
    "ttft": 7039.329362405006,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 873,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8726321018883154,
    "arrivals": 64957,
    "finished_requests": 64831,
    "scheduler_time": 37.904027616876405
}
#Debug simulation 
Total elapsed time: 4.61615537526086. Arrivals time: 0.15439785504713655 Scheduler time: 4.170465427916497 Scheduler overhead time: 0.10980852134525776 Adapter cache time: 0.022540102247148752 Engine time: 0.10684970719739795 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-32/adapters_32_slots_16_rate_1.6-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-32/adapters_32_slots_16_rate_1.6-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 270, 66, 66, 270, 66, 17280, 270, 66, 66, 66, 17280, 17280, 66, 66, 270, 270, 270, 17280, 17280, 66, 17280, 17280, 17280, 17280, 270, 66, 270, 270, 270, 270, 17280]
Prompts retrieved: 193710 . Total input tokens: 43205196 . Total output tokens: 38713514
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.625587804242969,
    "estimated_duration": 3600.032246240157,
    "input_throughput": 4484.427331688694,
    "output_throughput": 3970.541656933383,
    "total_throughput": 8454.968988622077,
    "itl": 32.31742681350317,
    "ttft": 7039.334740005206,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 873,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8735048464685433,
    "arrivals": 64957,
    "finished_requests": 64831,
    "scheduler_time": 37.90403993756381
}
#Debug simulation 
Total elapsed time: 4.625672326888889. Arrivals time: 0.14899744000285864 Scheduler time: 4.184228871483356 Scheduler overhead time: 0.10963744530454278 Adapter cache time: 0.022594783920794725 Engine time: 0.10807496774941683 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-16/adapters_32_slots_16_rate_1.6-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-16/adapters_32_slots_16_rate_1.6-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 270, 66, 66, 270, 66, 17280, 270, 66, 66, 66, 17280, 17280, 66, 66, 270, 270, 270, 17280, 17280, 66, 17280, 17280, 17280, 17280, 270, 66, 270, 270, 270, 270, 17280]
Prompts retrieved: 193710 . Total input tokens: 43205196 . Total output tokens: 38713514
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 4.650586023926735,
    "estimated_duration": 3600.0210292574834,
    "input_throughput": 4484.441304313651,
    "output_throughput": 3970.5540283880514,
    "total_throughput": 8454.995332701703,
    "itl": 32.31489269199087,
    "ttft": 7039.297042360972,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 873,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7018392587802045,
    "arrivals": 64957,
    "finished_requests": 64831,
    "scheduler_time": 37.90233021806651
}
#Debug simulation 
Total elapsed time: 4.650663460139185. Arrivals time: 0.14901451487094164 Scheduler time: 4.208090405911207 Scheduler overhead time: 0.10959144774824381 Adapter cache time: 0.02237782347947359 Engine time: 0.10943000856786966 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-32/adapters_32_slots_16_rate_1.6-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-32/adapters_32_slots_16_rate_1.6-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 270, 66, 66, 270, 66, 17280, 270, 66, 66, 66, 17280, 17280, 66, 66, 270, 270, 270, 17280, 17280, 66, 17280, 17280, 17280, 17280, 270, 66, 270, 270, 270, 270, 17280]
Prompts retrieved: 193710 . Total input tokens: 43205196 . Total output tokens: 38713514
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 4.633336354978383,
    "estimated_duration": 3600.0193187772356,
    "input_throughput": 4484.44343501007,
    "output_throughput": 3970.5559149207716,
    "total_throughput": 8454.999349930842,
    "itl": 32.31834629889254,
    "ttft": 7039.30288212619,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 873,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.926069929189988,
    "arrivals": 64957,
    "finished_requests": 64831,
    "scheduler_time": 37.90444981976224
}
#Debug simulation 
Total elapsed time: 4.63345781294629. Arrivals time: 0.14941045083105564 Scheduler time: 4.192761921323836 Scheduler overhead time: 0.10980689153075218 Adapter cache time: 0.0225065927952528 Engine time: 0.1069101826287806 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-16/adapters_32_slots_16_rate_1.6-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-16/adapters_32_slots_16_rate_1.6-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 270, 66, 66, 270, 66, 17280, 270, 66, 66, 66, 17280, 17280, 66, 66, 270, 270, 270, 17280, 17280, 66, 17280, 17280, 17280, 17280, 270, 66, 270, 270, 270, 270, 17280]
Prompts retrieved: 193710 . Total input tokens: 43205196 . Total output tokens: 38713514
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 4.617830330971628,
    "estimated_duration": 3600.004891562067,
    "input_throughput": 4484.461406660748,
    "output_throughput": 3970.571827139296,
    "total_throughput": 8455.033233800044,
    "itl": 32.313436562787935,
    "ttft": 7039.352457749151,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 874,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6133039577444457,
    "arrivals": 64957,
    "finished_requests": 64831,
    "scheduler_time": 37.901314728041925
}
#Debug simulation 
Total elapsed time: 4.617905972991139. Arrivals time: 0.14924740931019187 Scheduler time: 4.177438118495047 Scheduler overhead time: 0.10980566218495369 Adapter cache time: 0.022506535053253174 Engine time: 0.10689452337101102 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-32/adapters_32_slots_16_rate_1.6-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-32/adapters_32_slots_16_rate_1.6-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 270, 66, 66, 270, 66, 17280, 270, 66, 66, 66, 17280, 17280, 66, 66, 270, 270, 270, 17280, 17280, 66, 17280, 17280, 17280, 17280, 270, 66, 270, 270, 270, 270, 17280]
Prompts retrieved: 193710 . Total input tokens: 43205196 . Total output tokens: 38713514
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.639795233961195,
    "estimated_duration": 3600.0291823254383,
    "input_throughput": 4484.431148297451,
    "output_throughput": 3970.5450361840517,
    "total_throughput": 8454.976184481504,
    "itl": 32.31876592594066,
    "ttft": 7039.25304445058,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 873,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9542387773469367,
    "arrivals": 64957,
    "finished_requests": 64831,
    "scheduler_time": 37.904764387671996
}
#Debug simulation 
Total elapsed time: 4.639870891813189. Arrivals time: 0.15210492489859462 Scheduler time: 4.194905215408653 Scheduler overhead time: 0.11013349797576666 Adapter cache time: 0.022411532700061798 Engine time: 0.10817562974989414 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-8/adapters_32_slots_16_rate_1.6-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-8/adapters_32_slots_16_rate_1.6-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 270, 33, 33, 270, 33, 17280, 270, 33, 33, 33, 17280, 17280, 33, 33, 270, 270, 270, 17280, 17280, 33, 17280, 17280, 17280, 17280, 270, 33, 270, 270, 270, 270, 17280]
Prompts retrieved: 193380 . Total input tokens: 43129627 . Total output tokens: 38646207
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 4.608312464784831,
    "estimated_duration": 3599.989321721344,
    "input_throughput": 4463.941852004166,
    "output_throughput": 3961.9523074529893,
    "total_throughput": 8425.894159457155,
    "itl": 32.152242318526774,
    "ttft": 6385.24864375042,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 757,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.316789222157139,
    "arrivals": 64833,
    "finished_requests": 64719,
    "scheduler_time": 37.67593187999903
}
#Debug simulation 
Total elapsed time: 4.608394824899733. Arrivals time: 0.14869884261861444 Scheduler time: 4.1669060764834285 Scheduler overhead time: 0.11016921838745475 Adapter cache time: 0.021858553402125835 Engine time: 0.1085519976913929 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-16/adapters_32_slots_16_rate_1.6-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-16/adapters_32_slots_16_rate_1.6-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 270, 33, 33, 270, 33, 17280, 270, 33, 33, 33, 17280, 17280, 33, 33, 270, 270, 270, 17280, 17280, 33, 17280, 17280, 17280, 17280, 270, 33, 270, 270, 270, 270, 17280]
Prompts retrieved: 193380 . Total input tokens: 43129627 . Total output tokens: 38646207
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.613261502701789,
    "estimated_duration": 3599.980048323222,
    "input_throughput": 4463.953350931781,
    "output_throughput": 3961.96251327652,
    "total_throughput": 8425.9158642083,
    "itl": 32.15476310757148,
    "ttft": 6385.1778022819735,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 755,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4940646620281175,
    "arrivals": 64833,
    "finished_requests": 64719,
    "scheduler_time": 37.677594972977644
}
#Debug simulation 
Total elapsed time: 4.613337516784668. Arrivals time: 0.14792286092415452 Scheduler time: 4.1734978267923 Scheduler overhead time: 0.11072204308584332 Adapter cache time: 0.02202143846079707 Engine time: 0.10687769250944257 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-32/adapters_32_slots_16_rate_1.6-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-32/adapters_32_slots_16_rate_1.6-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 270, 33, 33, 270, 33, 17280, 270, 33, 33, 33, 17280, 17280, 33, 33, 270, 270, 270, 17280, 17280, 33, 17280, 17280, 17280, 17280, 270, 33, 270, 270, 270, 270, 17280]
Prompts retrieved: 193380 . Total input tokens: 43129627 . Total output tokens: 38646207
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.633311856072396,
    "estimated_duration": 3599.979643805404,
    "input_throughput": 4463.953852531469,
    "output_throughput": 3961.962958469157,
    "total_throughput": 8425.916811000627,
    "itl": 32.15482969441115,
    "ttft": 6385.188234228204,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 755,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4931230301596132,
    "arrivals": 64833,
    "finished_requests": 64719,
    "scheduler_time": 37.67760296946217
}
#Debug simulation 
Total elapsed time: 4.633389084134251. Arrivals time: 0.14882879937067628 Scheduler time: 4.193288253620267 Scheduler overhead time: 0.11008750321343541 Adapter cache time: 0.021910125389695168 Engine time: 0.10732127772644162 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-16/adapters_32_slots_16_rate_1.6-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-16/adapters_32_slots_16_rate_1.6-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 270, 33, 33, 270, 33, 17280, 270, 33, 33, 33, 17280, 17280, 33, 33, 270, 270, 270, 17280, 17280, 33, 17280, 17280, 17280, 17280, 270, 33, 270, 270, 270, 270, 17280]
Prompts retrieved: 193380 . Total input tokens: 43129627 . Total output tokens: 38646207
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 4.63212934974581,
    "estimated_duration": 3600.0010317089072,
    "input_throughput": 4463.927331812892,
    "output_throughput": 3961.9394201199475,
    "total_throughput": 8425.86675193284,
    "itl": 32.15243368681599,
    "ttft": 6385.300805907495,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 755,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3396156316576278,
    "arrivals": 64833,
    "finished_requests": 64719,
    "scheduler_time": 37.67634426835486
}
#Debug simulation 
Total elapsed time: 4.632209260948002. Arrivals time: 0.1516026398167014 Scheduler time: 4.181619972456247 Scheduler overhead time: 0.11558199115097523 Adapter cache time: 0.022362394258379936 Engine time: 0.1083533470518887 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-32/adapters_32_slots_16_rate_1.6-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-32/adapters_32_slots_16_rate_1.6-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 270, 33, 33, 270, 33, 17280, 270, 33, 33, 33, 17280, 17280, 33, 33, 270, 270, 270, 17280, 17280, 33, 17280, 17280, 17280, 17280, 270, 33, 270, 270, 270, 270, 17280]
Prompts retrieved: 193380 . Total input tokens: 43129627 . Total output tokens: 38646207
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 4.622712017968297,
    "estimated_duration": 3599.9893641918193,
    "input_throughput": 4463.941799341308,
    "output_throughput": 3961.9522607122963,
    "total_throughput": 8425.894060053604,
    "itl": 32.155624657084516,
    "ttft": 6385.264132274406,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 755,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5406579614244444,
    "arrivals": 64833,
    "finished_requests": 64719,
    "scheduler_time": 37.67810332334538
}
#Debug simulation 
Total elapsed time: 4.622815639246255. Arrivals time: 0.15013068029657006 Scheduler time: 4.180218809749931 Scheduler overhead time: 0.11027595354244113 Adapter cache time: 0.022064794786274433 Engine time: 0.10774416849017143 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-16/adapters_32_slots_16_rate_1.6-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-16/adapters_32_slots_16_rate_1.6-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 270, 33, 33, 270, 33, 17280, 270, 33, 33, 33, 17280, 17280, 33, 33, 270, 270, 270, 17280, 17280, 33, 17280, 17280, 17280, 17280, 270, 33, 270, 270, 270, 270, 17280]
Prompts retrieved: 193380 . Total input tokens: 43129627 . Total output tokens: 38646207
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 4.631845600903034,
    "estimated_duration": 3599.9993182365697,
    "input_throughput": 4463.929456484405,
    "output_throughput": 3961.9413058629707,
    "total_throughput": 8425.870762347377,
    "itl": 32.15114154018609,
    "ttft": 6385.1728379369815,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 756,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2604780229460015,
    "arrivals": 64833,
    "finished_requests": 64719,
    "scheduler_time": 37.675517114807576
}
#Debug simulation 
Total elapsed time: 4.631921874824911. Arrivals time: 0.14910427294671535 Scheduler time: 4.189327573869377 Scheduler overhead time: 0.11124052433297038 Adapter cache time: 0.021922784857451916 Engine time: 0.10799620300531387 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-32/adapters_32_slots_16_rate_1.6-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-32/adapters_32_slots_16_rate_1.6-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 270, 33, 33, 270, 33, 17280, 270, 33, 33, 33, 17280, 17280, 33, 33, 270, 270, 270, 17280, 17280, 33, 17280, 17280, 17280, 17280, 270, 33, 270, 270, 270, 270, 17280]
Prompts retrieved: 193380 . Total input tokens: 43129627 . Total output tokens: 38646207
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.629832887090743,
    "estimated_duration": 3600.007914425954,
    "input_throughput": 4463.9187974014485,
    "output_throughput": 3961.9318454399377,
    "total_throughput": 8425.850642841386,
    "itl": 32.15584521938138,
    "ttft": 6385.296327239132,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 757,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.572947512753322,
    "arrivals": 64833,
    "finished_requests": 64719,
    "scheduler_time": 37.67853867670638
}
#Debug simulation 
Total elapsed time: 4.62990913586691. Arrivals time: 0.14951335871592164 Scheduler time: 4.188513830304146 Scheduler overhead time: 0.1100793918594718 Adapter cache time: 0.02191666094586253 Engine time: 0.10745139699429274 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-8/adapters_32_slots_16_rate_1.6-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-8/adapters_32_slots_16_rate_1.6-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 135, 66, 66, 135, 66, 17280, 135, 66, 66, 66, 17280, 17280, 66, 66, 135, 135, 135, 17280, 17280, 66, 17280, 17280, 17280, 17280, 135, 66, 135, 135, 135, 135, 17280]
Prompts retrieved: 192225 . Total input tokens: 42866645 . Total output tokens: 38418482
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 4.614993502851576,
    "estimated_duration": 3600.0255082089107,
    "input_throughput": 4438.318829565579,
    "output_throughput": 3924.0352513580656,
    "total_throughput": 8362.354080923644,
    "itl": 31.615801755032514,
    "ttft": 8545.684466588726,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 569,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7414175262977614,
    "arrivals": 64433,
    "finished_requests": 64281,
    "scheduler_time": 36.809794471885915
}
#Debug simulation 
Total elapsed time: 4.615069506689906. Arrivals time: 0.1488277753815055 Scheduler time: 4.168460065498948 Scheduler overhead time: 0.1129195629619062 Adapter cache time: 0.021140513941645622 Engine time: 0.11046798340976238 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-16/adapters_32_slots_16_rate_1.6-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-16/adapters_32_slots_16_rate_1.6-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 135, 66, 66, 135, 66, 17280, 135, 66, 66, 66, 17280, 17280, 66, 66, 135, 135, 135, 17280, 17280, 66, 17280, 17280, 17280, 17280, 135, 66, 135, 135, 135, 135, 17280]
Prompts retrieved: 192225 . Total input tokens: 42866645 . Total output tokens: 38418482
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.581081700976938,
    "estimated_duration": 3600.0145302126148,
    "input_throughput": 4438.332363913082,
    "output_throughput": 3924.047217433228,
    "total_throughput": 8362.379581346311,
    "itl": 31.617317789907297,
    "ttft": 8489.964494312244,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 570,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8595948891015794,
    "arrivals": 64433,
    "finished_requests": 64281,
    "scheduler_time": 36.81076831151547
}
#Debug simulation 
Total elapsed time: 4.581157822161913. Arrivals time: 0.149572282563895 Scheduler time: 4.137034479063004 Scheduler overhead time: 0.11164584523066878 Adapter cache time: 0.02116518374532461 Engine time: 0.10905203921720386 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-32/adapters_32_slots_16_rate_1.6-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-32/adapters_32_slots_16_rate_1.6-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 135, 66, 66, 135, 66, 17280, 135, 66, 66, 66, 17280, 17280, 66, 66, 135, 135, 135, 17280, 17280, 66, 17280, 17280, 17280, 17280, 135, 66, 135, 135, 135, 135, 17280]
Prompts retrieved: 192225 . Total input tokens: 42866645 . Total output tokens: 38418482
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.595609511248767,
    "estimated_duration": 3600.0230490425324,
    "input_throughput": 4438.321861369624,
    "output_throughput": 3924.037931856336,
    "total_throughput": 8362.35979322596,
    "itl": 31.617687867684346,
    "ttft": 8545.672569897763,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 570,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.862959791719925,
    "arrivals": 64433,
    "finished_requests": 64281,
    "scheduler_time": 36.81091411086845
}
#Debug simulation 
Total elapsed time: 4.595686112064868. Arrivals time: 0.1484241858124733 Scheduler time: 4.152054864913225 Scheduler overhead time: 0.11167102865874767 Adapter cache time: 0.020950499456375837 Engine time: 0.1097650621086359 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-16/adapters_32_slots_16_rate_1.6-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-16/adapters_32_slots_16_rate_1.6-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 135, 66, 66, 135, 66, 17280, 135, 66, 66, 66, 17280, 17280, 66, 66, 135, 135, 135, 17280, 17280, 66, 17280, 17280, 17280, 17280, 135, 66, 135, 135, 135, 135, 17280]
Prompts retrieved: 192225 . Total input tokens: 42866645 . Total output tokens: 38418482
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 4.594593079760671,
    "estimated_duration": 3600.0324421690048,
    "input_throughput": 4438.43722429707,
    "output_throughput": 3924.0874150258032,
    "total_throughput": 8362.524639322874,
    "itl": 31.616103978444055,
    "ttft": 8489.83858842203,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 570,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.76561796586028,
    "arrivals": 64433,
    "finished_requests": 64282,
    "scheduler_time": 36.810125219027526
}
#Debug simulation 
Total elapsed time: 4.59467864362523. Arrivals time: 0.1480834186077118 Scheduler time: 4.152032231446356 Scheduler overhead time: 0.11205743812024593 Adapter cache time: 0.021204238291829824 Engine time: 0.1081587322987616 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-32/adapters_32_slots_16_rate_1.6-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-32/adapters_32_slots_16_rate_1.6-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 135, 66, 66, 135, 66, 17280, 135, 66, 66, 66, 17280, 17280, 66, 66, 135, 135, 135, 17280, 17280, 66, 17280, 17280, 17280, 17280, 135, 66, 135, 135, 135, 135, 17280]
Prompts retrieved: 192225 . Total input tokens: 42866645 . Total output tokens: 38418482
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 4.5938218352384865,
    "estimated_duration": 3600.002904739959,
    "input_throughput": 4438.223918920455,
    "output_throughput": 3924.005167162609,
    "total_throughput": 8362.229086083064,
    "itl": 31.617672028070178,
    "ttft": 8601.730888463868,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 570,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.891883162595333,
    "arrivals": 64433,
    "finished_requests": 64279,
    "scheduler_time": 36.8110137493609
}
#Debug simulation 
Total elapsed time: 4.593934217002243. Arrivals time: 0.14832999417558312 Scheduler time: 4.150236936286092 Scheduler overhead time: 0.11193495150655508 Adapter cache time: 0.021200277842581272 Engine time: 0.10920550301671028 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-16/adapters_32_slots_16_rate_1.6-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-16/adapters_32_slots_16_rate_1.6-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 135, 66, 66, 135, 66, 17280, 135, 66, 66, 66, 17280, 17280, 66, 66, 135, 135, 135, 17280, 17280, 66, 17280, 17280, 17280, 17280, 135, 66, 135, 135, 135, 135, 17280]
Prompts retrieved: 192225 . Total input tokens: 42866645 . Total output tokens: 38418482
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 4.5912791271694005,
    "estimated_duration": 3600.0303422178868,
    "input_throughput": 4438.439813303363,
    "output_throughput": 3924.0897040042205,
    "total_throughput": 8362.529517307583,
    "itl": 31.61516484337292,
    "ttft": 8489.831183598659,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 570,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7043286680942165,
    "arrivals": 64433,
    "finished_requests": 64282,
    "scheduler_time": 36.80950482054741
}
#Debug simulation 
Total elapsed time: 4.5913564171642065. Arrivals time: 0.14925981312990189 Scheduler time: 4.146778512746096 Scheduler overhead time: 0.11151004862040281 Adapter cache time: 0.02108572656288743 Engine time: 0.1097895996645093 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-32/adapters_32_slots_16_rate_1.6-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-32/adapters_32_slots_16_rate_1.6-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 135, 66, 66, 135, 66, 17280, 135, 66, 66, 66, 17280, 17280, 66, 66, 135, 135, 135, 17280, 17280, 66, 17280, 17280, 17280, 17280, 135, 66, 135, 135, 135, 135, 17280]
Prompts retrieved: 192225 . Total input tokens: 42866645 . Total output tokens: 38418482
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.601267969701439,
    "estimated_duration": 3600.0004987479247,
    "input_throughput": 4438.226885123209,
    "output_throughput": 3924.007789697016,
    "total_throughput": 8362.234674820225,
    "itl": 31.618221081268544,
    "ttft": 8601.752174565638,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 570,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9107462305575558,
    "arrivals": 64433,
    "finished_requests": 64279,
    "scheduler_time": 36.81113793189784
}
#Debug simulation 
Total elapsed time: 4.6013442617841065. Arrivals time: 0.14866772014647722 Scheduler time: 4.156123514752835 Scheduler overhead time: 0.11213550949469209 Adapter cache time: 0.021141137462109327 Engine time: 0.11038904543966055 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-8/adapters_32_slots_16_rate_1.6-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-8/adapters_32_slots_16_rate_1.6-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 135, 33, 33, 135, 33, 17280, 135, 33, 33, 33, 17280, 17280, 33, 33, 135, 135, 135, 17280, 17280, 33, 17280, 17280, 17280, 17280, 135, 33, 135, 135, 135, 135, 17280]
Prompts retrieved: 191895 . Total input tokens: 42783320 . Total output tokens: 38357461
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 4.585468262899667,
    "estimated_duration": 3600.0187572810282,
    "input_throughput": 4398.0193069766365,
    "output_throughput": 3934.897553339104,
    "total_throughput": 8332.916860315741,
    "itl": 31.60055664266672,
    "ttft": 7829.814277746088,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 437,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3374331440986238,
    "arrivals": 64340,
    "finished_requests": 64200,
    "scheduler_time": 36.92230411968188
}
#Debug simulation 
Total elapsed time: 4.585550188552588. Arrivals time: 0.14884405536577106 Scheduler time: 4.141158998943865 Scheduler overhead time: 0.11187021667137742 Adapter cache time: 0.020549412816762924 Engine time: 0.1104408004321158 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-16/adapters_32_slots_16_rate_1.6-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-16/adapters_32_slots_16_rate_1.6-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 135, 33, 33, 135, 33, 17280, 135, 33, 33, 33, 17280, 17280, 33, 33, 135, 135, 135, 17280, 17280, 33, 17280, 17280, 17280, 17280, 135, 33, 135, 135, 135, 135, 17280]
Prompts retrieved: 191895 . Total input tokens: 42783320 . Total output tokens: 38357461
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.569724247325212,
    "estimated_duration": 3600.01311446706,
    "input_throughput": 4398.026200619517,
    "output_throughput": 3934.9037210652127,
    "total_throughput": 8332.92992168473,
    "itl": 31.601835570144036,
    "ttft": 7829.779845365511,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 437,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4374024807731691,
    "arrivals": 64340,
    "finished_requests": 64200,
    "scheduler_time": 36.923169769744156
}
#Debug simulation 
Total elapsed time: 4.5698067760095. Arrivals time: 0.14688222715631127 Scheduler time: 4.131469413638115 Scheduler overhead time: 0.11089223437011242 Adapter cache time: 0.02055267198011279 Engine time: 0.1072674342431128 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-32/adapters_32_slots_16_rate_1.6-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-32/adapters_32_slots_16_rate_1.6-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 135, 33, 33, 135, 33, 17280, 135, 33, 33, 33, 17280, 17280, 33, 33, 135, 135, 135, 17280, 17280, 33, 17280, 17280, 17280, 17280, 135, 33, 135, 135, 135, 135, 17280]
Prompts retrieved: 191895 . Total input tokens: 42783320 . Total output tokens: 38357461
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.614551009144634,
    "estimated_duration": 3600.01303357471,
    "input_throughput": 4398.026299443236,
    "output_throughput": 3934.903809482562,
    "total_throughput": 8332.930108925799,
    "itl": 31.601844807820765,
    "ttft": 7829.788138056079,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 437,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.437936935164043,
    "arrivals": 64340,
    "finished_requests": 64200,
    "scheduler_time": 36.92316563180453
}
#Debug simulation 
Total elapsed time: 4.614633973222226. Arrivals time: 0.15636410750448704 Scheduler time: 4.16266059782356 Scheduler overhead time: 0.11207479191944003 Adapter cache time: 0.020329381339251995 Engine time: 0.11017729761078954 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-16/adapters_32_slots_16_rate_1.6-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-16/adapters_32_slots_16_rate_1.6-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 135, 33, 33, 135, 33, 17280, 135, 33, 33, 33, 17280, 17280, 33, 33, 135, 135, 135, 17280, 17280, 33, 17280, 17280, 17280, 17280, 135, 33, 135, 135, 135, 135, 17280]
Prompts retrieved: 191895 . Total input tokens: 42783320 . Total output tokens: 38357461
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 4.5919812140055,
    "estimated_duration": 3600.0245261520245,
    "input_throughput": 4398.063370119215,
    "output_throughput": 3934.9095810581703,
    "total_throughput": 8332.972951177384,
    "itl": 31.600845602219962,
    "ttft": 7829.604436774225,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 437,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.360177965587933,
    "arrivals": 64340,
    "finished_requests": 64201,
    "scheduler_time": 36.92260683256203
}
#Debug simulation 
Total elapsed time: 4.592082079034299. Arrivals time: 0.1472338978201151 Scheduler time: 4.149611203465611 Scheduler overhead time: 0.11159406136721373 Adapter cache time: 0.020495709031820297 Engine time: 0.11033586598932743 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-32/adapters_32_slots_16_rate_1.6-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-32/adapters_32_slots_16_rate_1.6-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 135, 33, 33, 135, 33, 17280, 135, 33, 33, 33, 17280, 17280, 33, 33, 135, 135, 135, 17280, 17280, 33, 17280, 17280, 17280, 17280, 135, 33, 135, 135, 135, 135, 17280]
Prompts retrieved: 191895 . Total input tokens: 42783320 . Total output tokens: 38357461
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 4.575961024966091,
    "estimated_duration": 3600.018174168197,
    "input_throughput": 4398.020019345676,
    "output_throughput": 3934.898190694012,
    "total_throughput": 8332.918210039688,
    "itl": 31.602430745286917,
    "ttft": 7829.713960219315,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 437,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4617044007964475,
    "arrivals": 64340,
    "finished_requests": 64200,
    "scheduler_time": 36.92343975163352
}
#Debug simulation 
Total elapsed time: 4.576055688317865. Arrivals time: 0.1480020978488028 Scheduler time: 4.1349385674111545 Scheduler overhead time: 0.11192768346518278 Adapter cache time: 0.020312585402280092 Engine time: 0.10794872464612126 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-16/adapters_32_slots_16_rate_1.6-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-16/adapters_32_slots_16_rate_1.6-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 135, 33, 33, 135, 33, 17280, 135, 33, 33, 33, 17280, 17280, 33, 33, 135, 135, 135, 17280, 17280, 33, 17280, 17280, 17280, 17280, 135, 33, 135, 135, 135, 135, 17280]
Prompts retrieved: 191895 . Total input tokens: 42783320 . Total output tokens: 38357461
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 4.583103701937944,
    "estimated_duration": 3600.0008902088916,
    "input_throughput": 4397.976968022722,
    "output_throughput": 3934.809026999449,
    "total_throughput": 8332.78599502217,
    "itl": 31.599872758716938,
    "ttft": 7885.75200870053,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 437,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3066519788722413,
    "arrivals": 64340,
    "finished_requests": 64199,
    "scheduler_time": 36.92185616623845
}
#Debug simulation 
Total elapsed time: 4.583187886048108. Arrivals time: 0.14741028100252151 Scheduler time: 4.142866188660264 Scheduler overhead time: 0.1112565491348505 Adapter cache time: 0.02072932617738843 Engine time: 0.10797041514888406 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-32/adapters_32_slots_16_rate_1.6-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-32/adapters_32_slots_16_rate_1.6-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 135, 33, 33, 135, 33, 17280, 135, 33, 33, 33, 17280, 17280, 33, 33, 135, 135, 135, 17280, 17280, 33, 17280, 17280, 17280, 17280, 135, 33, 135, 135, 135, 135, 17280]
Prompts retrieved: 191895 . Total input tokens: 42783320 . Total output tokens: 38357461
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.583692014217377,
    "estimated_duration": 3600.0140381422043,
    "input_throughput": 4398.025072194061,
    "output_throughput": 3934.9027114656046,
    "total_throughput": 8332.927783659665,
    "itl": 31.602373380507842,
    "ttft": 7829.776548035805,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 437,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4781781468167903,
    "arrivals": 64340,
    "finished_requests": 64200,
    "scheduler_time": 36.92358057906077
}
#Debug simulation 
Total elapsed time: 4.583781369961798. Arrivals time: 0.1481738635338843 Scheduler time: 4.141514907591045 Scheduler overhead time: 0.11145849293097854 Adapter cache time: 0.02035639202222228 Engine time: 0.10929732723161578 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-8/adapters_32_slots_16_rate_1.6-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-8/adapters_32_slots_16_rate_1.6-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 66, 33, 33, 66, 33, 17280, 66, 33, 33, 33, 17280, 17280, 33, 33, 66, 66, 66, 17280, 17280, 33, 17280, 17280, 17280, 17280, 66, 33, 66, 66, 66, 66, 17280]
Prompts retrieved: 191136 . Total input tokens: 42607616 . Total output tokens: 38213099
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 4.563958708196878,
    "estimated_duration": 3600.001634497142,
    "input_throughput": 4397.343836820574,
    "output_throughput": 3892.2685105828455,
    "total_throughput": 8289.61234740342,
    "itl": 31.07058536170551,
    "ttft": 8029.944481302781,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 292,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8936624212283629,
    "arrivals": 64071,
    "finished_requests": 63929,
    "scheduler_time": 35.9904488703852
}
#Debug simulation 
Total elapsed time: 4.564036291092634. Arrivals time: 0.14987713424488902 Scheduler time: 4.116766274441034 Scheduler overhead time: 0.11291000107303262 Adapter cache time: 0.019968939013779163 Engine time: 0.11109163891524076 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-16/adapters_32_slots_16_rate_1.6-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-16/adapters_32_slots_16_rate_1.6-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 66, 33, 33, 66, 33, 17280, 66, 33, 33, 33, 17280, 17280, 33, 33, 66, 66, 66, 17280, 17280, 33, 17280, 17280, 17280, 17280, 66, 33, 66, 66, 66, 66, 17280]
Prompts retrieved: 191136 . Total input tokens: 42607616 . Total output tokens: 38213099
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.565818810835481,
    "estimated_duration": 3600.0039372563515,
    "input_throughput": 4397.341024039201,
    "output_throughput": 3892.2660208752463,
    "total_throughput": 8289.607044914448,
    "itl": 31.071607509821135,
    "ttft": 8030.070903623944,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 292,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9560395357548311,
    "arrivals": 64071,
    "finished_requests": 63929,
    "scheduler_time": 35.99103765125534
}
#Debug simulation 
Total elapsed time: 4.565897281747311. Arrivals time: 0.14791974890977144 Scheduler time: 4.120512462686747 Scheduler overhead time: 0.11379825696349144 Adapter cache time: 0.01987809408456087 Engine time: 0.1099544414319098 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-32/adapters_32_slots_16_rate_1.6-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-32/adapters_32_slots_16_rate_1.6-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 66, 33, 33, 66, 33, 17280, 66, 33, 33, 33, 17280, 17280, 33, 33, 66, 66, 66, 17280, 17280, 33, 17280, 17280, 17280, 17280, 66, 33, 66, 66, 66, 66, 17280]
Prompts retrieved: 191136 . Total input tokens: 42607616 . Total output tokens: 38213099
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.551491257734597,
    "estimated_duration": 3600.0060534006107,
    "input_throughput": 4397.338439208002,
    "output_throughput": 3892.2637329356508,
    "total_throughput": 8289.602172143652,
    "itl": 31.071562178995134,
    "ttft": 8030.032964542121,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 292,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9571687452308884,
    "arrivals": 64071,
    "finished_requests": 63929,
    "scheduler_time": 35.991078099335596
}
#Debug simulation 
Total elapsed time: 4.551570441108197. Arrivals time: 0.14688634779304266 Scheduler time: 4.1073228740133345 Scheduler overhead time: 0.11286642448976636 Adapter cache time: 0.020145678892731667 Engine time: 0.1110468115657568 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-16/adapters_32_slots_16_rate_1.6-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-16/adapters_32_slots_16_rate_1.6-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 66, 33, 33, 66, 33, 17280, 66, 33, 33, 33, 17280, 17280, 33, 33, 66, 66, 66, 17280, 17280, 33, 17280, 17280, 17280, 17280, 66, 33, 66, 66, 66, 66, 17280]
Prompts retrieved: 191136 . Total input tokens: 42607616 . Total output tokens: 38213099
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 4.549321130849421,
    "estimated_duration": 3599.995012684616,
    "input_throughput": 4397.351925272474,
    "output_throughput": 3892.2756700017576,
    "total_throughput": 8289.62759527423,
    "itl": 31.070962720748113,
    "ttft": 8029.970416775891,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 292,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9082338834973079,
    "arrivals": 64071,
    "finished_requests": 63929,
    "scheduler_time": 35.99052572173764
}
#Debug simulation 
Total elapsed time: 4.549402380827814. Arrivals time: 0.14729608036577702 Scheduler time: 4.106012103147805 Scheduler overhead time: 0.11248719692230225 Adapter cache time: 0.01958016073331237 Engine time: 0.11059238202869892 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-32/adapters_32_slots_16_rate_1.6-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-32/adapters_32_slots_16_rate_1.6-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 66, 33, 33, 66, 33, 17280, 66, 33, 33, 33, 17280, 17280, 33, 33, 66, 66, 66, 17280, 17280, 33, 17280, 17280, 17280, 17280, 66, 33, 66, 66, 66, 66, 17280]
Prompts retrieved: 191136 . Total input tokens: 42607616 . Total output tokens: 38213099
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 4.54461273085326,
    "estimated_duration": 3599.997420183678,
    "input_throughput": 4397.348984542412,
    "output_throughput": 3892.273067041552,
    "total_throughput": 8289.622051583965,
    "itl": 31.071929902946813,
    "ttft": 8029.921423037474,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 292,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9718819382414274,
    "arrivals": 64071,
    "finished_requests": 63929,
    "scheduler_time": 35.99114216854173
}
#Debug simulation 
Total elapsed time: 4.544732755050063. Arrivals time: 0.1470163445919752 Scheduler time: 4.099537682253867 Scheduler overhead time: 0.11289385287091136 Adapter cache time: 0.019980247598141432 Engine time: 0.11161951255053282 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-16/adapters_32_slots_16_rate_1.6-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-16/adapters_32_slots_16_rate_1.6-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 66, 33, 33, 66, 33, 17280, 66, 33, 33, 33, 17280, 17280, 33, 33, 66, 66, 66, 17280, 17280, 33, 17280, 17280, 17280, 17280, 66, 33, 66, 66, 66, 66, 17280]
Prompts retrieved: 191136 . Total input tokens: 42607616 . Total output tokens: 38213099
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 4.554888817947358,
    "estimated_duration": 3600.0027993250533,
    "input_throughput": 4397.342414002559,
    "output_throughput": 3892.267251188547,
    "total_throughput": 8289.609665191107,
    "itl": 31.07050194681179,
    "ttft": 8030.0270417328065,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 292,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8730946861114365,
    "arrivals": 64071,
    "finished_requests": 63929,
    "scheduler_time": 35.990255460453156
}
#Debug simulation 
Total elapsed time: 4.554963956121355. Arrivals time: 0.14696806948632002 Scheduler time: 4.109437640756369 Scheduler overhead time: 0.11455219751223922 Adapter cache time: 0.01980513706803322 Engine time: 0.11042269598692656 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-32/adapters_32_slots_16_rate_1.6-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-32/adapters_32_slots_16_rate_1.6-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 66, 33, 33, 66, 33, 17280, 66, 33, 33, 33, 17280, 17280, 33, 33, 66, 66, 66, 17280, 17280, 33, 17280, 17280, 17280, 17280, 66, 33, 66, 66, 66, 66, 17280]
Prompts retrieved: 191136 . Total input tokens: 42607616 . Total output tokens: 38213099
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.538778782822192,
    "estimated_duration": 3600.0146561719425,
    "input_throughput": 4397.328486666003,
    "output_throughput": 3892.3141537706965,
    "total_throughput": 8289.6426404367,
    "itl": 31.07197701701629,
    "ttft": 7973.831722598551,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 292,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9826967638731056,
    "arrivals": 64071,
    "finished_requests": 63930,
    "scheduler_time": 35.99138476389239
}
#Debug simulation 
Total elapsed time: 4.538855790160596. Arrivals time: 0.1507610478438437 Scheduler time: 4.089611889794469 Scheduler overhead time: 0.11490776389837265 Adapter cache time: 0.020071045495569706 Engine time: 0.109102972317487 
