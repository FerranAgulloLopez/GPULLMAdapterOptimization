INFO 06-01 00:47:16 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:47:16 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-16/adapters_320_slots_160_rate_0.8-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-16/adapters_320_slots_160_rate_0.8-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 66, 8640, 8640, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 8640, 8640, 1080, 66, 66, 1080, 8640, 8640, 1080, 1080, 66, 66, 1080, 8640, 8640, 66, 8640, 1080, 66, 1080, 8640, 66, 1080, 8640, 8640, 1080, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 8640, 66, 8640, 1080, 8640, 8640, 66, 8640, 66, 8640, 1080, 66, 66, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 66, 1080, 1080, 66, 8640, 1080, 8640, 8640, 1080, 66, 1080, 1080, 1080, 66, 8640, 1080, 8640, 66, 8640, 66, 66, 1080, 8640, 8640, 1080, 66, 1080, 66, 1080, 8640, 8640, 1080, 66, 1080, 66, 8640, 66, 66, 66, 66, 8640, 1080, 1080, 8640, 1080, 1080, 66, 1080, 8640, 1080, 66, 66, 1080, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 1080, 8640, 1080, 1080, 1080, 66, 8640, 66, 8640, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 66, 66, 8640, 1080, 8640, 1080, 8640, 1080, 66, 1080, 66, 66, 66, 8640, 8640, 1080, 1080, 66, 66, 1080, 66, 8640, 66, 66, 1080, 66, 8640, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 66, 1080, 8640, 1080, 1080, 8640, 1080, 66, 1080, 66, 8640, 1080, 1080, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 1080, 66, 1080, 66, 1080, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 1080, 1080, 8640, 66, 8640, 66, 66, 66, 8640, 1080, 8640, 8640, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 8640, 66, 66, 1080, 66, 1080, 1080, 66, 8640, 8640, 8640, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 1080, 8640, 1080, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1047036 . Total input tokens: 233445264 . Total output tokens: 209439237
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.868633391975891,
    "estimated_duration": 3600.0217548831215,
    "input_throughput": 4091.194165708083,
    "output_throughput": 3602.953505046557,
    "total_throughput": 7694.14767075464,
    "itl": 237.12173806138154,
    "ttft": 2104698.29367175,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1572,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.138373244954178,
    "arrivals": 349246,
    "finished_requests": 59622,
    "scheduler_time": 81.44815498454008
}
#Debug simulation 
Total elapsed time: 4.868750481982715. Arrivals time: 0.2178814184735529 Scheduler time: 4.555093739065342 Scheduler overhead time: 0.024931273073889315 Adapter cache time: 0.03460428840480745 Engine time: 0.024862621794454753 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-32/adapters_320_slots_160_rate_0.8-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-32/adapters_320_slots_160_rate_0.8-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 66, 8640, 8640, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 8640, 8640, 1080, 66, 66, 1080, 8640, 8640, 1080, 1080, 66, 66, 1080, 8640, 8640, 66, 8640, 1080, 66, 1080, 8640, 66, 1080, 8640, 8640, 1080, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 8640, 66, 8640, 1080, 8640, 8640, 66, 8640, 66, 8640, 1080, 66, 66, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 66, 1080, 1080, 66, 8640, 1080, 8640, 8640, 1080, 66, 1080, 1080, 1080, 66, 8640, 1080, 8640, 66, 8640, 66, 66, 1080, 8640, 8640, 1080, 66, 1080, 66, 1080, 8640, 8640, 1080, 66, 1080, 66, 8640, 66, 66, 66, 66, 8640, 1080, 1080, 8640, 1080, 1080, 66, 1080, 8640, 1080, 66, 66, 1080, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 1080, 8640, 1080, 1080, 1080, 66, 8640, 66, 8640, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 66, 66, 8640, 1080, 8640, 1080, 8640, 1080, 66, 1080, 66, 66, 66, 8640, 8640, 1080, 1080, 66, 66, 1080, 66, 8640, 66, 66, 1080, 66, 8640, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 66, 1080, 8640, 1080, 1080, 8640, 1080, 66, 1080, 66, 8640, 1080, 1080, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 1080, 66, 1080, 66, 1080, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 1080, 1080, 8640, 66, 8640, 66, 66, 66, 8640, 1080, 8640, 8640, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 8640, 66, 66, 1080, 66, 1080, 1080, 66, 8640, 8640, 8640, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 1080, 8640, 1080, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1047036 . Total input tokens: 233445264 . Total output tokens: 209439237
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.091585064015817,
    "estimated_duration": 3600.015965314057,
    "input_throughput": 3651.980470829126,
    "output_throughput": 3230.485117858482,
    "total_throughput": 6882.465588687608,
    "itl": 157.68204843809002,
    "ttft": 2181170.9704048983,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3920,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.826997727639089,
    "arrivals": 349246,
    "finished_requests": 53224,
    "scheduler_time": 90.24484133592003
}
#Debug simulation 
Total elapsed time: 4.09172403003322. Arrivals time: 0.19863046589307487 Scheduler time: 3.717613412067294 Scheduler overhead time: 0.034318766789510846 Adapter cache time: 0.09023883962072432 Engine time: 0.03483203344512731 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-16/adapters_320_slots_160_rate_0.8-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-16/adapters_320_slots_160_rate_0.8-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 66, 8640, 8640, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 8640, 8640, 1080, 66, 66, 1080, 8640, 8640, 1080, 1080, 66, 66, 1080, 8640, 8640, 66, 8640, 1080, 66, 1080, 8640, 66, 1080, 8640, 8640, 1080, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 8640, 66, 8640, 1080, 8640, 8640, 66, 8640, 66, 8640, 1080, 66, 66, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 66, 1080, 1080, 66, 8640, 1080, 8640, 8640, 1080, 66, 1080, 1080, 1080, 66, 8640, 1080, 8640, 66, 8640, 66, 66, 1080, 8640, 8640, 1080, 66, 1080, 66, 1080, 8640, 8640, 1080, 66, 1080, 66, 8640, 66, 66, 66, 66, 8640, 1080, 1080, 8640, 1080, 1080, 66, 1080, 8640, 1080, 66, 66, 1080, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 1080, 8640, 1080, 1080, 1080, 66, 8640, 66, 8640, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 66, 66, 8640, 1080, 8640, 1080, 8640, 1080, 66, 1080, 66, 66, 66, 8640, 8640, 1080, 1080, 66, 66, 1080, 66, 8640, 66, 66, 1080, 66, 8640, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 66, 1080, 8640, 1080, 1080, 8640, 1080, 66, 1080, 66, 8640, 1080, 1080, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 1080, 66, 1080, 66, 1080, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 1080, 1080, 8640, 66, 8640, 66, 66, 66, 8640, 1080, 8640, 8640, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 8640, 66, 66, 1080, 66, 1080, 1080, 66, 8640, 8640, 8640, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 1080, 8640, 1080, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1047036 . Total input tokens: 233445264 . Total output tokens: 209439237
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.858177665970288,
    "estimated_duration": 3600.1260378849456,
    "input_throughput": 4091.081213549084,
    "output_throughput": 3602.91885992424,
    "total_throughput": 7694.000073473325,
    "itl": 237.09514484551084,
    "ttft": 2104640.3023408437,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1558,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.866473376543625,
    "arrivals": 349246,
    "finished_requests": 59627,
    "scheduler_time": 81.45652064325493
}
#Debug simulation 
Total elapsed time: 4.85827338998206. Arrivals time: 0.2237964131636545 Scheduler time: 4.538959229364991 Scheduler overhead time: 0.024972335493657738 Adapter cache time: 0.03424414905020967 Engine time: 0.024880076991394162 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-32/adapters_320_slots_160_rate_0.8-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-32/adapters_320_slots_160_rate_0.8-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 66, 8640, 8640, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 8640, 8640, 1080, 66, 66, 1080, 8640, 8640, 1080, 1080, 66, 66, 1080, 8640, 8640, 66, 8640, 1080, 66, 1080, 8640, 66, 1080, 8640, 8640, 1080, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 8640, 66, 8640, 1080, 8640, 8640, 66, 8640, 66, 8640, 1080, 66, 66, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 66, 1080, 1080, 66, 8640, 1080, 8640, 8640, 1080, 66, 1080, 1080, 1080, 66, 8640, 1080, 8640, 66, 8640, 66, 66, 1080, 8640, 8640, 1080, 66, 1080, 66, 1080, 8640, 8640, 1080, 66, 1080, 66, 8640, 66, 66, 66, 66, 8640, 1080, 1080, 8640, 1080, 1080, 66, 1080, 8640, 1080, 66, 66, 1080, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 1080, 8640, 1080, 1080, 1080, 66, 8640, 66, 8640, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 66, 66, 8640, 1080, 8640, 1080, 8640, 1080, 66, 1080, 66, 66, 66, 8640, 8640, 1080, 1080, 66, 66, 1080, 66, 8640, 66, 66, 1080, 66, 8640, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 66, 1080, 8640, 1080, 1080, 8640, 1080, 66, 1080, 66, 8640, 1080, 1080, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 1080, 66, 1080, 66, 1080, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 1080, 1080, 8640, 66, 8640, 66, 66, 66, 8640, 1080, 8640, 8640, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 8640, 66, 66, 1080, 66, 1080, 1080, 66, 8640, 8640, 8640, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 1080, 8640, 1080, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1047036 . Total input tokens: 233445264 . Total output tokens: 209439237
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.038900228973944,
    "estimated_duration": 3600.029291775892,
    "input_throughput": 3650.440297811358,
    "output_throughput": 3229.0717818758408,
    "total_throughput": 6879.512079687199,
    "itl": 157.30757591017021,
    "ttft": 2181630.944240619,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3922,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.006836484297244,
    "arrivals": 349246,
    "finished_requests": 53197,
    "scheduler_time": 90.32554624105343
}
#Debug simulation 
Total elapsed time: 4.038997749972623. Arrivals time: 0.19892884331056848 Scheduler time: 3.6633714531199075 Scheduler overhead time: 0.0343826306052506 Adapter cache time: 0.09145014599198475 Engine time: 0.034800487104803324 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-16/adapters_320_slots_160_rate_0.8-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-16/adapters_320_slots_160_rate_0.8-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 66, 8640, 8640, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 8640, 8640, 1080, 66, 66, 1080, 8640, 8640, 1080, 1080, 66, 66, 1080, 8640, 8640, 66, 8640, 1080, 66, 1080, 8640, 66, 1080, 8640, 8640, 1080, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 8640, 66, 8640, 1080, 8640, 8640, 66, 8640, 66, 8640, 1080, 66, 66, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 66, 1080, 1080, 66, 8640, 1080, 8640, 8640, 1080, 66, 1080, 1080, 1080, 66, 8640, 1080, 8640, 66, 8640, 66, 66, 1080, 8640, 8640, 1080, 66, 1080, 66, 1080, 8640, 8640, 1080, 66, 1080, 66, 8640, 66, 66, 66, 66, 8640, 1080, 1080, 8640, 1080, 1080, 66, 1080, 8640, 1080, 66, 66, 1080, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 1080, 8640, 1080, 1080, 1080, 66, 8640, 66, 8640, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 66, 66, 8640, 1080, 8640, 1080, 8640, 1080, 66, 1080, 66, 66, 66, 8640, 8640, 1080, 1080, 66, 66, 1080, 66, 8640, 66, 66, 1080, 66, 8640, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 66, 1080, 8640, 1080, 1080, 8640, 1080, 66, 1080, 66, 8640, 1080, 1080, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 1080, 66, 1080, 66, 1080, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 1080, 1080, 8640, 66, 8640, 66, 66, 66, 8640, 1080, 8640, 8640, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 8640, 66, 66, 1080, 66, 1080, 1080, 66, 8640, 8640, 8640, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 1080, 8640, 1080, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1047036 . Total input tokens: 233445264 . Total output tokens: 209439237
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.8960542299901135,
    "estimated_duration": 3600.268765412343,
    "input_throughput": 4091.4198244066183,
    "output_throughput": 3603.2059952374816,
    "total_throughput": 7694.6258196440995,
    "itl": 237.08439380809787,
    "ttft": 2104581.0380432135,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1577,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.7153093150606,
    "arrivals": 349246,
    "finished_requests": 59631,
    "scheduler_time": 81.46339034103458
}
#Debug simulation 
Total elapsed time: 4.896153289009817. Arrivals time: 0.2145509494584985 Scheduler time: 4.585343201528303 Scheduler overhead time: 0.024961313290987164 Adapter cache time: 0.03486543241888285 Engine time: 0.025051012460608035 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-32/adapters_320_slots_160_rate_0.8-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-32/adapters_320_slots_160_rate_0.8-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 66, 8640, 8640, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 8640, 8640, 1080, 66, 66, 1080, 8640, 8640, 1080, 1080, 66, 66, 1080, 8640, 8640, 66, 8640, 1080, 66, 1080, 8640, 66, 1080, 8640, 8640, 1080, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 8640, 66, 8640, 1080, 8640, 8640, 66, 8640, 66, 8640, 1080, 66, 66, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 66, 1080, 1080, 66, 8640, 1080, 8640, 8640, 1080, 66, 1080, 1080, 1080, 66, 8640, 1080, 8640, 66, 8640, 66, 66, 1080, 8640, 8640, 1080, 66, 1080, 66, 1080, 8640, 8640, 1080, 66, 1080, 66, 8640, 66, 66, 66, 66, 8640, 1080, 1080, 8640, 1080, 1080, 66, 1080, 8640, 1080, 66, 66, 1080, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 1080, 8640, 1080, 1080, 1080, 66, 8640, 66, 8640, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 66, 66, 8640, 1080, 8640, 1080, 8640, 1080, 66, 1080, 66, 66, 66, 8640, 8640, 1080, 1080, 66, 66, 1080, 66, 8640, 66, 66, 1080, 66, 8640, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 66, 1080, 8640, 1080, 1080, 8640, 1080, 66, 1080, 66, 8640, 1080, 1080, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 1080, 66, 1080, 66, 1080, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 1080, 1080, 8640, 66, 8640, 66, 66, 66, 8640, 1080, 8640, 8640, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 8640, 66, 66, 1080, 66, 1080, 1080, 66, 8640, 8640, 8640, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 1080, 8640, 1080, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1047036 . Total input tokens: 233445264 . Total output tokens: 209439237
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.07041206600843,
    "estimated_duration": 3600.1275088557395,
    "input_throughput": 3650.3029316805773,
    "output_throughput": 3228.9831322376685,
    "total_throughput": 6879.286063918245,
    "itl": 157.31400549940255,
    "ttft": 2181664.7144853207,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3929,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.190494966692382,
    "arrivals": 349246,
    "finished_requests": 53196,
    "scheduler_time": 90.32610993843011
}
#Debug simulation 
Total elapsed time: 4.070505553972907. Arrivals time: 0.19225930358516052 Scheduler time: 3.7003169393283315 Scheduler overhead time: 0.03446676325984299 Adapter cache time: 0.09227184910560027 Engine time: 0.03509498160565272 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-8/adapters_320_slots_160_rate_0.8-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-8/adapters_320_slots_160_rate_0.8-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 33, 8640, 8640, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 8640, 8640, 1080, 33, 33, 1080, 8640, 8640, 1080, 1080, 33, 33, 1080, 8640, 8640, 33, 8640, 1080, 33, 1080, 8640, 33, 1080, 8640, 8640, 1080, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 8640, 33, 8640, 1080, 8640, 8640, 33, 8640, 33, 8640, 1080, 33, 33, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 33, 1080, 1080, 33, 8640, 1080, 8640, 8640, 1080, 33, 1080, 1080, 1080, 33, 8640, 1080, 8640, 33, 8640, 33, 33, 1080, 8640, 8640, 1080, 33, 1080, 33, 1080, 8640, 8640, 1080, 33, 1080, 33, 8640, 33, 33, 33, 33, 8640, 1080, 1080, 8640, 1080, 1080, 33, 1080, 8640, 1080, 33, 33, 1080, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 1080, 8640, 1080, 1080, 1080, 33, 8640, 33, 8640, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 33, 33, 8640, 1080, 8640, 1080, 8640, 1080, 33, 1080, 33, 33, 33, 8640, 8640, 1080, 1080, 33, 33, 1080, 33, 8640, 33, 33, 1080, 33, 8640, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 33, 1080, 8640, 1080, 1080, 8640, 1080, 33, 1080, 33, 8640, 1080, 1080, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 1080, 33, 1080, 33, 1080, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 1080, 1080, 8640, 33, 8640, 33, 33, 33, 8640, 1080, 8640, 8640, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 8640, 33, 33, 1080, 33, 1080, 1080, 33, 8640, 8640, 8640, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 1080, 8640, 1080, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1043538 . Total input tokens: 232659400 . Total output tokens: 208720485
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.979853804979939,
    "estimated_duration": 3600.115432751549,
    "input_throughput": 4064.1977384645024,
    "output_throughput": 3609.8817503935516,
    "total_throughput": 7674.079488858054,
    "itl": 238.0926411189836,
    "ttft": 2108710.9193696417,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1583,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.844752098645682,
    "arrivals": 348063,
    "finished_requests": 59470,
    "scheduler_time": 81.42504417539455
}
#Debug simulation 
Total elapsed time: 4.9799630849738605. Arrivals time: 0.47454082930926234 Scheduler time: 4.408870085666422 Scheduler overhead time: 0.024770944728516042 Adapter cache time: 0.035433906072285026 Engine time: 0.02496811078162864 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-16/adapters_320_slots_160_rate_0.8-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-16/adapters_320_slots_160_rate_0.8-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 33, 8640, 8640, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 8640, 8640, 1080, 33, 33, 1080, 8640, 8640, 1080, 1080, 33, 33, 1080, 8640, 8640, 33, 8640, 1080, 33, 1080, 8640, 33, 1080, 8640, 8640, 1080, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 8640, 33, 8640, 1080, 8640, 8640, 33, 8640, 33, 8640, 1080, 33, 33, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 33, 1080, 1080, 33, 8640, 1080, 8640, 8640, 1080, 33, 1080, 1080, 1080, 33, 8640, 1080, 8640, 33, 8640, 33, 33, 1080, 8640, 8640, 1080, 33, 1080, 33, 1080, 8640, 8640, 1080, 33, 1080, 33, 8640, 33, 33, 33, 33, 8640, 1080, 1080, 8640, 1080, 1080, 33, 1080, 8640, 1080, 33, 33, 1080, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 1080, 8640, 1080, 1080, 1080, 33, 8640, 33, 8640, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 33, 33, 8640, 1080, 8640, 1080, 8640, 1080, 33, 1080, 33, 33, 33, 8640, 8640, 1080, 1080, 33, 33, 1080, 33, 8640, 33, 33, 1080, 33, 8640, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 33, 1080, 8640, 1080, 1080, 8640, 1080, 33, 1080, 33, 8640, 1080, 1080, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 1080, 33, 1080, 33, 1080, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 1080, 1080, 8640, 33, 8640, 33, 33, 33, 8640, 1080, 8640, 8640, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 8640, 33, 33, 1080, 33, 1080, 1080, 33, 8640, 8640, 8640, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 1080, 8640, 1080, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1043538 . Total input tokens: 232659400 . Total output tokens: 208720485
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.710839250008576,
    "estimated_duration": 3600.266197412508,
    "input_throughput": 4063.4203688921857,
    "output_throughput": 3609.350333411225,
    "total_throughput": 7672.770702303411,
    "itl": 238.11614772823478,
    "ttft": 2108926.0636133496,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1595,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.218176475334808,
    "arrivals": 348063,
    "finished_requests": 59462,
    "scheduler_time": 81.4205716883149
}
#Debug simulation 
Total elapsed time: 4.710965842008591. Arrivals time: 0.21270219760481268 Scheduler time: 4.4004413319635205 Scheduler overhead time: 0.02481600211467594 Adapter cache time: 0.03677441948093474 Engine time: 0.024866889405529946 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-32/adapters_320_slots_160_rate_0.8-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-32/adapters_320_slots_160_rate_0.8-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 33, 8640, 8640, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 8640, 8640, 1080, 33, 33, 1080, 8640, 8640, 1080, 1080, 33, 33, 1080, 8640, 8640, 33, 8640, 1080, 33, 1080, 8640, 33, 1080, 8640, 8640, 1080, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 8640, 33, 8640, 1080, 8640, 8640, 33, 8640, 33, 8640, 1080, 33, 33, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 33, 1080, 1080, 33, 8640, 1080, 8640, 8640, 1080, 33, 1080, 1080, 1080, 33, 8640, 1080, 8640, 33, 8640, 33, 33, 1080, 8640, 8640, 1080, 33, 1080, 33, 1080, 8640, 8640, 1080, 33, 1080, 33, 8640, 33, 33, 33, 33, 8640, 1080, 1080, 8640, 1080, 1080, 33, 1080, 8640, 1080, 33, 33, 1080, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 1080, 8640, 1080, 1080, 1080, 33, 8640, 33, 8640, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 33, 33, 8640, 1080, 8640, 1080, 8640, 1080, 33, 1080, 33, 33, 33, 8640, 8640, 1080, 1080, 33, 33, 1080, 33, 8640, 33, 33, 1080, 33, 8640, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 33, 1080, 8640, 1080, 1080, 8640, 1080, 33, 1080, 33, 8640, 1080, 1080, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 1080, 33, 1080, 33, 1080, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 1080, 1080, 8640, 33, 8640, 33, 33, 33, 8640, 1080, 8640, 8640, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 8640, 33, 33, 1080, 33, 1080, 1080, 33, 8640, 8640, 8640, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 1080, 8640, 1080, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1043538 . Total input tokens: 232659400 . Total output tokens: 208720485
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.070146879996173,
    "estimated_duration": 3600.0644225007154,
    "input_throughput": 3650.2843998751773,
    "output_throughput": 3246.5555135486406,
    "total_throughput": 6896.839913423818,
    "itl": 155.7563028815433,
    "ttft": 2183983.259235915,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3643,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.922226715031291,
    "arrivals": 348063,
    "finished_requests": 53290,
    "scheduler_time": 91.08560554681809
}
#Debug simulation 
Total elapsed time: 4.070242652029265. Arrivals time: 0.1957732368609868 Scheduler time: 3.697908577392809 Scheduler overhead time: 0.03481779556022957 Adapter cache time: 0.09039896365720779 Engine time: 0.035260355565696955 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-16/adapters_320_slots_160_rate_0.8-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-16/adapters_320_slots_160_rate_0.8-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 33, 8640, 8640, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 8640, 8640, 1080, 33, 33, 1080, 8640, 8640, 1080, 1080, 33, 33, 1080, 8640, 8640, 33, 8640, 1080, 33, 1080, 8640, 33, 1080, 8640, 8640, 1080, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 8640, 33, 8640, 1080, 8640, 8640, 33, 8640, 33, 8640, 1080, 33, 33, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 33, 1080, 1080, 33, 8640, 1080, 8640, 8640, 1080, 33, 1080, 1080, 1080, 33, 8640, 1080, 8640, 33, 8640, 33, 33, 1080, 8640, 8640, 1080, 33, 1080, 33, 1080, 8640, 8640, 1080, 33, 1080, 33, 8640, 33, 33, 33, 33, 8640, 1080, 1080, 8640, 1080, 1080, 33, 1080, 8640, 1080, 33, 33, 1080, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 1080, 8640, 1080, 1080, 1080, 33, 8640, 33, 8640, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 33, 33, 8640, 1080, 8640, 1080, 8640, 1080, 33, 1080, 33, 33, 33, 8640, 8640, 1080, 1080, 33, 33, 1080, 33, 8640, 33, 33, 1080, 33, 8640, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 33, 1080, 8640, 1080, 1080, 8640, 1080, 33, 1080, 33, 8640, 1080, 1080, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 1080, 33, 1080, 33, 1080, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 1080, 1080, 8640, 33, 8640, 33, 33, 33, 8640, 1080, 8640, 8640, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 8640, 33, 33, 1080, 33, 1080, 1080, 33, 8640, 8640, 8640, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 1080, 8640, 1080, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1043538 . Total input tokens: 232659400 . Total output tokens: 208720485
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.9602324180305,
    "estimated_duration": 3600.0181321566697,
    "input_throughput": 4063.700365652309,
    "output_throughput": 3609.5990417179614,
    "total_throughput": 7673.29940737027,
    "itl": 238.10187751666916,
    "ttft": 2108821.014527762,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1595,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.982008381276278,
    "arrivals": 348063,
    "finished_requests": 59462,
    "scheduler_time": 81.41991700164382
}
#Debug simulation 
Total elapsed time: 4.960298474004958. Arrivals time: 0.4699548398493789 Scheduler time: 4.393180064973421 Scheduler overhead time: 0.02484838361851871 Adapter cache time: 0.036066827131435275 Engine time: 0.024902637698687613 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-32/adapters_320_slots_160_rate_0.8-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-32/adapters_320_slots_160_rate_0.8-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 33, 8640, 8640, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 8640, 8640, 1080, 33, 33, 1080, 8640, 8640, 1080, 1080, 33, 33, 1080, 8640, 8640, 33, 8640, 1080, 33, 1080, 8640, 33, 1080, 8640, 8640, 1080, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 8640, 33, 8640, 1080, 8640, 8640, 33, 8640, 33, 8640, 1080, 33, 33, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 33, 1080, 1080, 33, 8640, 1080, 8640, 8640, 1080, 33, 1080, 1080, 1080, 33, 8640, 1080, 8640, 33, 8640, 33, 33, 1080, 8640, 8640, 1080, 33, 1080, 33, 1080, 8640, 8640, 1080, 33, 1080, 33, 8640, 33, 33, 33, 33, 8640, 1080, 1080, 8640, 1080, 1080, 33, 1080, 8640, 1080, 33, 33, 1080, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 1080, 8640, 1080, 1080, 1080, 33, 8640, 33, 8640, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 33, 33, 8640, 1080, 8640, 1080, 8640, 1080, 33, 1080, 33, 33, 33, 8640, 8640, 1080, 1080, 33, 33, 1080, 33, 8640, 33, 33, 1080, 33, 8640, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 33, 1080, 8640, 1080, 1080, 8640, 1080, 33, 1080, 33, 8640, 1080, 1080, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 1080, 33, 1080, 33, 1080, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 1080, 1080, 8640, 33, 8640, 33, 33, 33, 8640, 1080, 8640, 8640, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 8640, 33, 33, 1080, 33, 1080, 1080, 33, 8640, 8640, 8640, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 1080, 8640, 1080, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1043538 . Total input tokens: 232659400 . Total output tokens: 208720485
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.063977737969253,
    "estimated_duration": 3600.0833398445748,
    "input_throughput": 3655.200382268959,
    "output_throughput": 3251.5075055194047,
    "total_throughput": 6906.707887788363,
    "itl": 155.98962268092143,
    "ttft": 2184510.046412729,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3646,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.093328148479758,
    "arrivals": 348063,
    "finished_requests": 53369,
    "scheduler_time": 91.08295696411719
}
#Debug simulation 
Total elapsed time: 4.064075557980686. Arrivals time: 0.20462522434536368 Scheduler time: 3.6828290418488905 Scheduler overhead time: 0.03437982592731714 Adapter cache time: 0.09102136257570237 Engine time: 0.035186794702894986 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-16/adapters_320_slots_160_rate_0.8-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-16/adapters_320_slots_160_rate_0.8-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 33, 8640, 8640, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 8640, 8640, 1080, 33, 33, 1080, 8640, 8640, 1080, 1080, 33, 33, 1080, 8640, 8640, 33, 8640, 1080, 33, 1080, 8640, 33, 1080, 8640, 8640, 1080, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 8640, 33, 8640, 1080, 8640, 8640, 33, 8640, 33, 8640, 1080, 33, 33, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 33, 1080, 1080, 33, 8640, 1080, 8640, 8640, 1080, 33, 1080, 1080, 1080, 33, 8640, 1080, 8640, 33, 8640, 33, 33, 1080, 8640, 8640, 1080, 33, 1080, 33, 1080, 8640, 8640, 1080, 33, 1080, 33, 8640, 33, 33, 33, 33, 8640, 1080, 1080, 8640, 1080, 1080, 33, 1080, 8640, 1080, 33, 33, 1080, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 1080, 8640, 1080, 1080, 1080, 33, 8640, 33, 8640, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 33, 33, 8640, 1080, 8640, 1080, 8640, 1080, 33, 1080, 33, 33, 33, 8640, 8640, 1080, 1080, 33, 33, 1080, 33, 8640, 33, 33, 1080, 33, 8640, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 33, 1080, 8640, 1080, 1080, 8640, 1080, 33, 1080, 33, 8640, 1080, 1080, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 1080, 33, 1080, 33, 1080, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 1080, 1080, 8640, 33, 8640, 33, 33, 33, 8640, 1080, 8640, 8640, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 8640, 33, 33, 1080, 33, 1080, 1080, 33, 8640, 8640, 8640, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 1080, 8640, 1080, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1043538 . Total input tokens: 232659400 . Total output tokens: 208720485
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.732539382996038,
    "estimated_duration": 3600.212354901927,
    "input_throughput": 4063.6955706460094,
    "output_throughput": 3609.5909682399842,
    "total_throughput": 7673.286538885994,
    "itl": 238.089097754505,
    "ttft": 2108702.6670259144,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1591,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.757170019189229,
    "arrivals": 348063,
    "finished_requests": 59461,
    "scheduler_time": 81.42857121108344
}
#Debug simulation 
Total elapsed time: 4.732671738020144. Arrivals time: 0.2182196329231374 Scheduler time: 4.417134188232012 Scheduler overhead time: 0.024888556101359427 Adapter cache time: 0.03592583886347711 Engine time: 0.02512593485880643 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-32/adapters_320_slots_160_rate_0.8-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-32/adapters_320_slots_160_rate_0.8-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [106 107 107]
Adapter prompts. [1080, 8640, 8640, 33, 8640, 8640, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 8640, 8640, 1080, 33, 33, 1080, 8640, 8640, 1080, 1080, 33, 33, 1080, 8640, 8640, 33, 8640, 1080, 33, 1080, 8640, 33, 1080, 8640, 8640, 1080, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 8640, 33, 8640, 1080, 8640, 8640, 33, 8640, 33, 8640, 1080, 33, 33, 1080, 1080, 8640, 1080, 8640, 8640, 8640, 33, 1080, 1080, 33, 8640, 1080, 8640, 8640, 1080, 33, 1080, 1080, 1080, 33, 8640, 1080, 8640, 33, 8640, 33, 33, 1080, 8640, 8640, 1080, 33, 1080, 33, 1080, 8640, 8640, 1080, 33, 1080, 33, 8640, 33, 33, 33, 33, 8640, 1080, 1080, 8640, 1080, 1080, 33, 1080, 8640, 1080, 33, 33, 1080, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 1080, 8640, 1080, 1080, 1080, 33, 8640, 33, 8640, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 33, 33, 8640, 1080, 8640, 1080, 8640, 1080, 33, 1080, 33, 33, 33, 8640, 8640, 1080, 1080, 33, 33, 1080, 33, 8640, 33, 33, 1080, 33, 8640, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 33, 1080, 8640, 1080, 1080, 8640, 1080, 33, 1080, 33, 8640, 1080, 1080, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 1080, 33, 1080, 33, 1080, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 1080, 1080, 8640, 33, 8640, 33, 33, 33, 8640, 1080, 8640, 8640, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 8640, 33, 33, 1080, 33, 1080, 1080, 33, 8640, 8640, 8640, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 1080, 1080, 1080, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 1080, 8640, 1080, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1043538 . Total input tokens: 232659400 . Total output tokens: 208720485
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.329368678969331,
    "estimated_duration": 3600.108635500098,
    "input_throughput": 3651.435923453439,
    "output_throughput": 3247.868379498428,
    "total_throughput": 6899.304302951867,
    "itl": 156.28010653209287,
    "ttft": 2183988.4251147616,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3638,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.21593473575935,
    "arrivals": 348063,
    "finished_requests": 53316,
    "scheduler_time": 90.95527190152234
}
#Debug simulation 
Total elapsed time: 4.329430088982917. Arrivals time: 0.4567098938859999 Scheduler time: 3.687768679985311 Scheduler overhead time: 0.03474001109134406 Adapter cache time: 0.09903830627445132 Engine time: 0.03509324829792604 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-8/adapters_320_slots_160_rate_0.8-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-8/adapters_320_slots_160_rate_0.8-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 270, 8640, 8640, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 8640, 8640, 540, 270, 270, 540, 8640, 8640, 540, 540, 270, 270, 540, 8640, 8640, 270, 8640, 540, 270, 540, 8640, 270, 540, 8640, 8640, 540, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 540, 540, 540, 270, 540, 270, 8640, 270, 8640, 540, 8640, 8640, 270, 8640, 270, 8640, 540, 270, 270, 540, 540, 8640, 540, 8640, 8640, 8640, 270, 540, 540, 270, 8640, 540, 8640, 8640, 540, 270, 540, 540, 540, 270, 8640, 540, 8640, 270, 8640, 270, 270, 540, 8640, 8640, 540, 270, 540, 270, 540, 8640, 8640, 540, 270, 540, 270, 8640, 270, 270, 270, 270, 8640, 540, 540, 8640, 540, 540, 270, 540, 8640, 540, 270, 270, 540, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 540, 8640, 540, 540, 540, 270, 8640, 270, 8640, 540, 270, 540, 270, 270, 540, 270, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 270, 270, 8640, 540, 8640, 540, 8640, 540, 270, 540, 270, 270, 270, 8640, 8640, 540, 540, 270, 270, 540, 270, 8640, 270, 270, 540, 270, 8640, 540, 270, 8640, 270, 270, 8640, 540, 8640, 540, 270, 540, 8640, 540, 540, 8640, 540, 270, 540, 270, 8640, 540, 540, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 540, 270, 540, 270, 540, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 540, 540, 8640, 270, 8640, 270, 270, 270, 8640, 540, 8640, 8640, 270, 540, 540, 540, 270, 540, 270, 540, 540, 8640, 270, 270, 540, 270, 540, 540, 270, 8640, 8640, 8640, 270, 540, 540, 540, 540, 270, 540, 270, 8640, 270, 270, 8640, 540, 8640, 540, 540, 540, 540, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 540, 8640, 540, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1010880 . Total input tokens: 225360144 . Total output tokens: 202148859
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.8052530940040015,
    "estimated_duration": 3600.2270853019363,
    "input_throughput": 4093.8348195233143,
    "output_throughput": 3600.974519892746,
    "total_throughput": 7694.8093394160605,
    "itl": 237.49177971877373,
    "ttft": 2101364.252845747,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2350,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.1921461982421855,
    "arrivals": 337149,
    "finished_requests": 59481,
    "scheduler_time": 81.35269989317818
}
#Debug simulation 
Total elapsed time: 4.80534765298944. Arrivals time: 0.22628039924893528 Scheduler time: 4.467340566974599 Scheduler overhead time: 0.025068354734685272 Adapter cache time: 0.04995697399135679 Engine time: 0.025221715215593576 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-16/adapters_320_slots_160_rate_0.8-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-16/adapters_320_slots_160_rate_0.8-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 270, 8640, 8640, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 8640, 8640, 540, 270, 270, 540, 8640, 8640, 540, 540, 270, 270, 540, 8640, 8640, 270, 8640, 540, 270, 540, 8640, 270, 540, 8640, 8640, 540, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 540, 540, 540, 270, 540, 270, 8640, 270, 8640, 540, 8640, 8640, 270, 8640, 270, 8640, 540, 270, 270, 540, 540, 8640, 540, 8640, 8640, 8640, 270, 540, 540, 270, 8640, 540, 8640, 8640, 540, 270, 540, 540, 540, 270, 8640, 540, 8640, 270, 8640, 270, 270, 540, 8640, 8640, 540, 270, 540, 270, 540, 8640, 8640, 540, 270, 540, 270, 8640, 270, 270, 270, 270, 8640, 540, 540, 8640, 540, 540, 270, 540, 8640, 540, 270, 270, 540, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 540, 8640, 540, 540, 540, 270, 8640, 270, 8640, 540, 270, 540, 270, 270, 540, 270, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 270, 270, 8640, 540, 8640, 540, 8640, 540, 270, 540, 270, 270, 270, 8640, 8640, 540, 540, 270, 270, 540, 270, 8640, 270, 270, 540, 270, 8640, 540, 270, 8640, 270, 270, 8640, 540, 8640, 540, 270, 540, 8640, 540, 540, 8640, 540, 270, 540, 270, 8640, 540, 540, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 540, 270, 540, 270, 540, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 540, 540, 8640, 270, 8640, 270, 270, 270, 8640, 540, 8640, 8640, 270, 540, 540, 540, 270, 540, 270, 540, 540, 8640, 270, 270, 540, 270, 540, 540, 270, 8640, 8640, 8640, 270, 540, 540, 540, 540, 270, 540, 270, 8640, 270, 270, 8640, 540, 8640, 540, 540, 540, 540, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 540, 8640, 540, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1010880 . Total input tokens: 225360144 . Total output tokens: 202148859
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.727421138959471,
    "estimated_duration": 3600.0933648580426,
    "input_throughput": 4092.8891299964985,
    "output_throughput": 3600.3824585563493,
    "total_throughput": 7693.271588552848,
    "itl": 237.52242642517686,
    "ttft": 2101466.272271363,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2352,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.676135920153133,
    "arrivals": 337149,
    "finished_requests": 59469,
    "scheduler_time": 81.339570300448
}
#Debug simulation 
Total elapsed time: 4.727541379979812. Arrivals time: 0.21941537177190185 Scheduler time: 4.397410337056499 Scheduler overhead time: 0.025066410191357136 Adapter cache time: 0.0491355592967011 Engine time: 0.02501357498113066 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-32/adapters_320_slots_160_rate_0.8-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-32/adapters_320_slots_160_rate_0.8-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 270, 8640, 8640, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 8640, 8640, 540, 270, 270, 540, 8640, 8640, 540, 540, 270, 270, 540, 8640, 8640, 270, 8640, 540, 270, 540, 8640, 270, 540, 8640, 8640, 540, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 540, 540, 540, 270, 540, 270, 8640, 270, 8640, 540, 8640, 8640, 270, 8640, 270, 8640, 540, 270, 270, 540, 540, 8640, 540, 8640, 8640, 8640, 270, 540, 540, 270, 8640, 540, 8640, 8640, 540, 270, 540, 540, 540, 270, 8640, 540, 8640, 270, 8640, 270, 270, 540, 8640, 8640, 540, 270, 540, 270, 540, 8640, 8640, 540, 270, 540, 270, 8640, 270, 270, 270, 270, 8640, 540, 540, 8640, 540, 540, 270, 540, 8640, 540, 270, 270, 540, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 540, 8640, 540, 540, 540, 270, 8640, 270, 8640, 540, 270, 540, 270, 270, 540, 270, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 270, 270, 8640, 540, 8640, 540, 8640, 540, 270, 540, 270, 270, 270, 8640, 8640, 540, 540, 270, 270, 540, 270, 8640, 270, 270, 540, 270, 8640, 540, 270, 8640, 270, 270, 8640, 540, 8640, 540, 270, 540, 8640, 540, 540, 8640, 540, 270, 540, 270, 8640, 540, 540, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 540, 270, 540, 270, 540, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 540, 540, 8640, 270, 8640, 270, 270, 270, 8640, 540, 8640, 8640, 270, 540, 540, 540, 270, 540, 270, 540, 540, 8640, 270, 270, 540, 270, 540, 540, 270, 8640, 8640, 8640, 270, 540, 540, 540, 540, 270, 540, 270, 8640, 270, 270, 8640, 540, 8640, 540, 540, 540, 540, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 540, 8640, 540, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1010880 . Total input tokens: 225360144 . Total output tokens: 202148859
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.177371168974787,
    "estimated_duration": 3600.0068893486878,
    "input_throughput": 3776.889161026004,
    "output_throughput": 3340.3694408417155,
    "total_throughput": 7117.258601867719,
    "itl": 152.13780897537774,
    "ttft": 2159357.0674273213,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3659,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.964178066718596,
    "arrivals": 337149,
    "finished_requests": 54921,
    "scheduler_time": 93.38539650848624
}
#Debug simulation 
Total elapsed time: 4.177516448020469. Arrivals time: 0.19805112044559792 Scheduler time: 3.8008505376637913 Scheduler overhead time: 0.03517202573129907 Adapter cache time: 0.09089974488597363 Engine time: 0.035963216330856085 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-16-16/adapters_320_slots_160_rate_0.8-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-16-16/adapters_320_slots_160_rate_0.8-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 270, 8640, 8640, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 8640, 8640, 540, 270, 270, 540, 8640, 8640, 540, 540, 270, 270, 540, 8640, 8640, 270, 8640, 540, 270, 540, 8640, 270, 540, 8640, 8640, 540, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 540, 540, 540, 270, 540, 270, 8640, 270, 8640, 540, 8640, 8640, 270, 8640, 270, 8640, 540, 270, 270, 540, 540, 8640, 540, 8640, 8640, 8640, 270, 540, 540, 270, 8640, 540, 8640, 8640, 540, 270, 540, 540, 540, 270, 8640, 540, 8640, 270, 8640, 270, 270, 540, 8640, 8640, 540, 270, 540, 270, 540, 8640, 8640, 540, 270, 540, 270, 8640, 270, 270, 270, 270, 8640, 540, 540, 8640, 540, 540, 270, 540, 8640, 540, 270, 270, 540, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 540, 8640, 540, 540, 540, 270, 8640, 270, 8640, 540, 270, 540, 270, 270, 540, 270, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 270, 270, 8640, 540, 8640, 540, 8640, 540, 270, 540, 270, 270, 270, 8640, 8640, 540, 540, 270, 270, 540, 270, 8640, 270, 270, 540, 270, 8640, 540, 270, 8640, 270, 270, 8640, 540, 8640, 540, 270, 540, 8640, 540, 540, 8640, 540, 270, 540, 270, 8640, 540, 540, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 540, 270, 540, 270, 540, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 540, 540, 8640, 270, 8640, 270, 270, 270, 8640, 540, 8640, 8640, 270, 540, 540, 540, 270, 540, 270, 540, 540, 8640, 270, 270, 540, 270, 540, 540, 270, 8640, 8640, 8640, 270, 540, 540, 540, 540, 270, 540, 270, 8640, 270, 270, 8640, 540, 8640, 540, 540, 540, 540, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 540, 8640, 540, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1010880 . Total input tokens: 225360144 . Total output tokens: 202148859
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.725702591007575,
    "estimated_duration": 3600.008211855021,
    "input_throughput": 4093.0042746784156,
    "output_throughput": 3600.8345640190573,
    "total_throughput": 7693.838838697473,
    "itl": 237.50135430811534,
    "ttft": 2101376.0926960837,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2352,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.347216688808725,
    "arrivals": 337149,
    "finished_requests": 59473,
    "scheduler_time": 81.34435976402483
}
#Debug simulation 
Total elapsed time: 4.725797909020912. Arrivals time: 0.2144135454436764 Scheduler time: 4.400575053237844 Scheduler overhead time: 0.025061723252292722 Adapter cache time: 0.04938476823735982 Engine time: 0.024978595436550677 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-16-32/adapters_320_slots_160_rate_0.8-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-16-32/adapters_320_slots_160_rate_0.8-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 270, 8640, 8640, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 8640, 8640, 540, 270, 270, 540, 8640, 8640, 540, 540, 270, 270, 540, 8640, 8640, 270, 8640, 540, 270, 540, 8640, 270, 540, 8640, 8640, 540, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 540, 540, 540, 270, 540, 270, 8640, 270, 8640, 540, 8640, 8640, 270, 8640, 270, 8640, 540, 270, 270, 540, 540, 8640, 540, 8640, 8640, 8640, 270, 540, 540, 270, 8640, 540, 8640, 8640, 540, 270, 540, 540, 540, 270, 8640, 540, 8640, 270, 8640, 270, 270, 540, 8640, 8640, 540, 270, 540, 270, 540, 8640, 8640, 540, 270, 540, 270, 8640, 270, 270, 270, 270, 8640, 540, 540, 8640, 540, 540, 270, 540, 8640, 540, 270, 270, 540, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 540, 8640, 540, 540, 540, 270, 8640, 270, 8640, 540, 270, 540, 270, 270, 540, 270, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 270, 270, 8640, 540, 8640, 540, 8640, 540, 270, 540, 270, 270, 270, 8640, 8640, 540, 540, 270, 270, 540, 270, 8640, 270, 270, 540, 270, 8640, 540, 270, 8640, 270, 270, 8640, 540, 8640, 540, 270, 540, 8640, 540, 540, 8640, 540, 270, 540, 270, 8640, 540, 540, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 540, 270, 540, 270, 540, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 540, 540, 8640, 270, 8640, 270, 270, 270, 8640, 540, 8640, 8640, 270, 540, 540, 540, 270, 540, 270, 540, 540, 8640, 270, 270, 540, 270, 540, 540, 270, 8640, 8640, 8640, 270, 540, 540, 540, 540, 270, 540, 270, 8640, 270, 270, 8640, 540, 8640, 540, 540, 540, 540, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 540, 8640, 540, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1010880 . Total input tokens: 225360144 . Total output tokens: 202148859
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.189566787972581,
    "estimated_duration": 3600.0197771589974,
    "input_throughput": 3775.798423731731,
    "output_throughput": 3339.5460981293995,
    "total_throughput": 7115.3445218611305,
    "itl": 152.0857914924527,
    "ttft": 2159237.189752384,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3666,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.146961984801308,
    "arrivals": 337149,
    "finished_requests": 54907,
    "scheduler_time": 93.39600253072956
}
#Debug simulation 
Total elapsed time: 4.189672845997848. Arrivals time: 0.2191233139601536 Scheduler time: 3.7905162561219186 Scheduler overhead time: 0.03545829019276425 Adapter cache time: 0.09156228293431923 Engine time: 0.036391997418832034 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_16-16-16/adapters_320_slots_160_rate_0.8-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_16-16-16/adapters_320_slots_160_rate_0.8-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 270, 8640, 8640, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 8640, 8640, 540, 270, 270, 540, 8640, 8640, 540, 540, 270, 270, 540, 8640, 8640, 270, 8640, 540, 270, 540, 8640, 270, 540, 8640, 8640, 540, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 540, 540, 540, 270, 540, 270, 8640, 270, 8640, 540, 8640, 8640, 270, 8640, 270, 8640, 540, 270, 270, 540, 540, 8640, 540, 8640, 8640, 8640, 270, 540, 540, 270, 8640, 540, 8640, 8640, 540, 270, 540, 540, 540, 270, 8640, 540, 8640, 270, 8640, 270, 270, 540, 8640, 8640, 540, 270, 540, 270, 540, 8640, 8640, 540, 270, 540, 270, 8640, 270, 270, 270, 270, 8640, 540, 540, 8640, 540, 540, 270, 540, 8640, 540, 270, 270, 540, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 540, 8640, 540, 540, 540, 270, 8640, 270, 8640, 540, 270, 540, 270, 270, 540, 270, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 270, 270, 8640, 540, 8640, 540, 8640, 540, 270, 540, 270, 270, 270, 8640, 8640, 540, 540, 270, 270, 540, 270, 8640, 270, 270, 540, 270, 8640, 540, 270, 8640, 270, 270, 8640, 540, 8640, 540, 270, 540, 8640, 540, 540, 8640, 540, 270, 540, 270, 8640, 540, 540, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 540, 270, 540, 270, 540, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 540, 540, 8640, 270, 8640, 270, 270, 270, 8640, 540, 8640, 8640, 270, 540, 540, 540, 270, 540, 270, 540, 540, 8640, 270, 270, 540, 270, 540, 540, 270, 8640, 8640, 8640, 270, 540, 540, 540, 540, 270, 540, 270, 8640, 270, 270, 8640, 540, 8640, 540, 540, 540, 540, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 540, 8640, 540, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1010880 . Total input tokens: 225360144 . Total output tokens: 202148859
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.724201753968373,
    "estimated_duration": 3600.0635395955965,
    "input_throughput": 4094.0207965483955,
    "output_throughput": 3601.1381069836098,
    "total_throughput": 7695.158903532005,
    "itl": 237.4817286671655,
    "ttft": 2101304.4048015047,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2350,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.0266181930199,
    "arrivals": 337149,
    "finished_requests": 59481,
    "scheduler_time": 81.3525422134291
}
#Debug simulation 
Total elapsed time: 4.724320536013693. Arrivals time: 0.21543280396144837 Scheduler time: 4.398777194088325 Scheduler overhead time: 0.024947927275206894 Adapter cache time: 0.048726656124927104 Engine time: 0.025015925813931972 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_16-16-32/adapters_320_slots_160_rate_0.8-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_16-16-32/adapters_320_slots_160_rate_0.8-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 270, 8640, 8640, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 8640, 8640, 540, 270, 270, 540, 8640, 8640, 540, 540, 270, 270, 540, 8640, 8640, 270, 8640, 540, 270, 540, 8640, 270, 540, 8640, 8640, 540, 270, 270, 8640, 270, 270, 8640, 8640, 270, 270, 540, 540, 540, 270, 540, 270, 8640, 270, 8640, 540, 8640, 8640, 270, 8640, 270, 8640, 540, 270, 270, 540, 540, 8640, 540, 8640, 8640, 8640, 270, 540, 540, 270, 8640, 540, 8640, 8640, 540, 270, 540, 540, 540, 270, 8640, 540, 8640, 270, 8640, 270, 270, 540, 8640, 8640, 540, 270, 540, 270, 540, 8640, 8640, 540, 270, 540, 270, 8640, 270, 270, 270, 270, 8640, 540, 540, 8640, 540, 540, 270, 540, 8640, 540, 270, 270, 540, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 540, 8640, 540, 540, 540, 270, 8640, 270, 8640, 540, 270, 540, 270, 270, 540, 270, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 270, 270, 8640, 540, 8640, 540, 8640, 540, 270, 540, 270, 270, 270, 8640, 8640, 540, 540, 270, 270, 540, 270, 8640, 270, 270, 540, 270, 8640, 540, 270, 8640, 270, 270, 8640, 540, 8640, 540, 270, 540, 8640, 540, 540, 8640, 540, 270, 540, 270, 8640, 540, 540, 8640, 8640, 270, 270, 270, 8640, 8640, 270, 270, 8640, 540, 270, 540, 270, 540, 8640, 8640, 8640, 270, 8640, 8640, 8640, 8640, 270, 540, 540, 8640, 270, 8640, 270, 270, 270, 8640, 540, 8640, 8640, 270, 540, 540, 540, 270, 540, 270, 540, 540, 8640, 270, 270, 540, 270, 540, 540, 270, 8640, 8640, 8640, 270, 540, 540, 540, 540, 270, 540, 270, 8640, 270, 270, 8640, 540, 8640, 540, 540, 540, 540, 270, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 8640, 540, 8640, 540, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1010880 . Total input tokens: 225360144 . Total output tokens: 202148859
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.15333272900898,
    "estimated_duration": 3600.0501967278587,
    "input_throughput": 3773.6812704300673,
    "output_throughput": 3337.502074532399,
    "total_throughput": 7111.183344962466,
    "itl": 151.52224732636557,
    "ttft": 2159556.2400314976,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3653,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.250938489026572,
    "arrivals": 337149,
    "finished_requests": 54872,
    "scheduler_time": 93.53293775303061
}
#Debug simulation 
Total elapsed time: 4.153426581993699. Arrivals time: 0.19549957767594606 Scheduler time: 3.7780673874076456 Scheduler overhead time: 0.03526349540334195 Adapter cache time: 0.09185146837262437 Engine time: 0.036145690886769444 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-8/adapters_320_slots_160_rate_0.8-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-8/adapters_320_slots_160_rate_0.8-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 135, 8640, 8640, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 8640, 8640, 540, 135, 135, 540, 8640, 8640, 540, 540, 135, 135, 540, 8640, 8640, 135, 8640, 540, 135, 540, 8640, 135, 540, 8640, 8640, 540, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 540, 540, 540, 135, 540, 135, 8640, 135, 8640, 540, 8640, 8640, 135, 8640, 135, 8640, 540, 135, 135, 540, 540, 8640, 540, 8640, 8640, 8640, 135, 540, 540, 135, 8640, 540, 8640, 8640, 540, 135, 540, 540, 540, 135, 8640, 540, 8640, 135, 8640, 135, 135, 540, 8640, 8640, 540, 135, 540, 135, 540, 8640, 8640, 540, 135, 540, 135, 8640, 135, 135, 135, 135, 8640, 540, 540, 8640, 540, 540, 135, 540, 8640, 540, 135, 135, 540, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 540, 8640, 540, 540, 540, 135, 8640, 135, 8640, 540, 135, 540, 135, 135, 540, 135, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 135, 135, 8640, 540, 8640, 540, 8640, 540, 135, 540, 135, 135, 135, 8640, 8640, 540, 540, 135, 135, 540, 135, 8640, 135, 135, 540, 135, 8640, 540, 135, 8640, 135, 135, 8640, 540, 8640, 540, 135, 540, 8640, 540, 540, 8640, 540, 135, 540, 135, 8640, 540, 540, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 540, 135, 540, 135, 540, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 540, 540, 8640, 135, 8640, 135, 135, 135, 8640, 540, 8640, 8640, 135, 540, 540, 540, 135, 540, 135, 540, 540, 8640, 135, 135, 540, 135, 540, 540, 135, 8640, 8640, 8640, 135, 540, 540, 540, 540, 135, 540, 135, 8640, 135, 135, 8640, 540, 8640, 540, 540, 540, 540, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 540, 8640, 540, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 996570 . Total input tokens: 222163490 . Total output tokens: 199302323
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.532248462026473,
    "estimated_duration": 3600.0243489518225,
    "input_throughput": 4102.701417644677,
    "output_throughput": 3602.8206319705573,
    "total_throughput": 7705.522049615235,
    "itl": 236.91470233830614,
    "ttft": 2100691.9091138504,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2513,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.691005700503242,
    "arrivals": 332464,
    "finished_requests": 59347,
    "scheduler_time": 81.34212876661162
}
#Debug simulation 
Total elapsed time: 4.532342313032132. Arrivals time: 0.21773550781654194 Scheduler time: 4.199743186647538 Scheduler overhead time: 0.024962674069684 Adapter cache time: 0.05301331065129489 Engine time: 0.02537187479902059 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-16/adapters_320_slots_160_rate_0.8-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-16/adapters_320_slots_160_rate_0.8-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 135, 8640, 8640, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 8640, 8640, 540, 135, 135, 540, 8640, 8640, 540, 540, 135, 135, 540, 8640, 8640, 135, 8640, 540, 135, 540, 8640, 135, 540, 8640, 8640, 540, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 540, 540, 540, 135, 540, 135, 8640, 135, 8640, 540, 8640, 8640, 135, 8640, 135, 8640, 540, 135, 135, 540, 540, 8640, 540, 8640, 8640, 8640, 135, 540, 540, 135, 8640, 540, 8640, 8640, 540, 135, 540, 540, 540, 135, 8640, 540, 8640, 135, 8640, 135, 135, 540, 8640, 8640, 540, 135, 540, 135, 540, 8640, 8640, 540, 135, 540, 135, 8640, 135, 135, 135, 135, 8640, 540, 540, 8640, 540, 540, 135, 540, 8640, 540, 135, 135, 540, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 540, 8640, 540, 540, 540, 135, 8640, 135, 8640, 540, 135, 540, 135, 135, 540, 135, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 135, 135, 8640, 540, 8640, 540, 8640, 540, 135, 540, 135, 135, 135, 8640, 8640, 540, 540, 135, 135, 540, 135, 8640, 135, 135, 540, 135, 8640, 540, 135, 8640, 135, 135, 8640, 540, 8640, 540, 135, 540, 8640, 540, 540, 8640, 540, 135, 540, 135, 8640, 540, 540, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 540, 135, 540, 135, 540, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 540, 540, 8640, 135, 8640, 135, 135, 135, 8640, 540, 8640, 8640, 135, 540, 540, 540, 135, 540, 135, 540, 540, 8640, 135, 135, 540, 135, 540, 540, 135, 8640, 8640, 8640, 135, 540, 540, 540, 540, 135, 540, 135, 8640, 135, 135, 8640, 540, 8640, 540, 540, 540, 540, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 540, 8640, 540, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 996570 . Total input tokens: 222163490 . Total output tokens: 199302323
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.528189214004669,
    "estimated_duration": 3600.079558023533,
    "input_throughput": 4102.403783573123,
    "output_throughput": 3602.415388597705,
    "total_throughput": 7704.819172170828,
    "itl": 236.94836849137656,
    "ttft": 2100737.6577904876,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2511,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.196907997389472,
    "arrivals": 332464,
    "finished_requests": 59340,
    "scheduler_time": 81.33238905193664
}
#Debug simulation 
Total elapsed time: 4.528314215014689. Arrivals time: 0.23174081707838923 Scheduler time: 4.182625933724921 Scheduler overhead time: 0.024896126124076545 Adapter cache time: 0.052522658195812255 Engine time: 0.02511722024064511 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-32/adapters_320_slots_160_rate_0.8-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-32/adapters_320_slots_160_rate_0.8-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 135, 8640, 8640, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 8640, 8640, 540, 135, 135, 540, 8640, 8640, 540, 540, 135, 135, 540, 8640, 8640, 135, 8640, 540, 135, 540, 8640, 135, 540, 8640, 8640, 540, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 540, 540, 540, 135, 540, 135, 8640, 135, 8640, 540, 8640, 8640, 135, 8640, 135, 8640, 540, 135, 135, 540, 540, 8640, 540, 8640, 8640, 8640, 135, 540, 540, 135, 8640, 540, 8640, 8640, 540, 135, 540, 540, 540, 135, 8640, 540, 8640, 135, 8640, 135, 135, 540, 8640, 8640, 540, 135, 540, 135, 540, 8640, 8640, 540, 135, 540, 135, 8640, 135, 135, 135, 135, 8640, 540, 540, 8640, 540, 540, 135, 540, 8640, 540, 135, 135, 540, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 540, 8640, 540, 540, 540, 135, 8640, 135, 8640, 540, 135, 540, 135, 135, 540, 135, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 135, 135, 8640, 540, 8640, 540, 8640, 540, 135, 540, 135, 135, 135, 8640, 8640, 540, 540, 135, 135, 540, 135, 8640, 135, 135, 540, 135, 8640, 540, 135, 8640, 135, 135, 8640, 540, 8640, 540, 135, 540, 8640, 540, 540, 8640, 540, 135, 540, 135, 8640, 540, 540, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 540, 135, 540, 135, 540, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 540, 540, 8640, 135, 8640, 135, 135, 135, 8640, 540, 8640, 8640, 135, 540, 540, 540, 135, 540, 135, 540, 540, 8640, 135, 135, 540, 135, 540, 540, 135, 8640, 8640, 8640, 135, 540, 540, 540, 540, 135, 540, 135, 8640, 135, 135, 8640, 540, 8640, 540, 540, 540, 540, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 540, 8640, 540, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 996570 . Total input tokens: 222163490 . Total output tokens: 199302323
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.207805952988565,
    "estimated_duration": 3600.1374160653086,
    "input_throughput": 3849.632221857552,
    "output_throughput": 3400.8040763569284,
    "total_throughput": 7250.43629821448,
    "itl": 149.15611001491473,
    "ttft": 2151141.431581028,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3020,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.865921912341953,
    "arrivals": 332464,
    "finished_requests": 55750,
    "scheduler_time": 95.0669822074368
}
#Debug simulation 
Total elapsed time: 4.20790122798644. Arrivals time: 0.20652320398949087 Scheduler time: 3.8307565239956602 Scheduler overhead time: 0.03584773075999692 Adapter cache time: 0.08124727255199105 Engine time: 0.0367972903768532 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-16/adapters_320_slots_160_rate_0.8-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-16/adapters_320_slots_160_rate_0.8-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 135, 8640, 8640, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 8640, 8640, 540, 135, 135, 540, 8640, 8640, 540, 540, 135, 135, 540, 8640, 8640, 135, 8640, 540, 135, 540, 8640, 135, 540, 8640, 8640, 540, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 540, 540, 540, 135, 540, 135, 8640, 135, 8640, 540, 8640, 8640, 135, 8640, 135, 8640, 540, 135, 135, 540, 540, 8640, 540, 8640, 8640, 8640, 135, 540, 540, 135, 8640, 540, 8640, 8640, 540, 135, 540, 540, 540, 135, 8640, 540, 8640, 135, 8640, 135, 135, 540, 8640, 8640, 540, 135, 540, 135, 540, 8640, 8640, 540, 135, 540, 135, 8640, 135, 135, 135, 135, 8640, 540, 540, 8640, 540, 540, 135, 540, 8640, 540, 135, 135, 540, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 540, 8640, 540, 540, 540, 135, 8640, 135, 8640, 540, 135, 540, 135, 135, 540, 135, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 135, 135, 8640, 540, 8640, 540, 8640, 540, 135, 540, 135, 135, 135, 8640, 8640, 540, 540, 135, 135, 540, 135, 8640, 135, 135, 540, 135, 8640, 540, 135, 8640, 135, 135, 8640, 540, 8640, 540, 135, 540, 8640, 540, 540, 8640, 540, 135, 540, 135, 8640, 540, 540, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 540, 135, 540, 135, 540, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 540, 540, 8640, 135, 8640, 135, 135, 135, 8640, 540, 8640, 8640, 135, 540, 540, 540, 135, 540, 135, 540, 540, 8640, 135, 135, 540, 135, 540, 540, 135, 8640, 8640, 8640, 135, 540, 540, 540, 540, 135, 540, 135, 8640, 135, 135, 8640, 540, 8640, 540, 540, 540, 540, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 540, 8640, 540, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 996570 . Total input tokens: 222163490 . Total output tokens: 199302323
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.5105289710336365,
    "estimated_duration": 3600.2243426098,
    "input_throughput": 4102.450179338943,
    "output_throughput": 3602.618272004096,
    "total_throughput": 7705.068451343039,
    "itl": 236.9255728697909,
    "ttft": 2100773.1700867084,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2514,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.854894769733946,
    "arrivals": 332464,
    "finished_requests": 59346,
    "scheduler_time": 81.34330835491974
}
#Debug simulation 
Total elapsed time: 4.510625057038851. Arrivals time: 0.21022830047877505 Scheduler time: 4.185990074533038 Scheduler overhead time: 0.024978420871775597 Adapter cache time: 0.05243173579219729 Engine time: 0.02546865027397871 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-32/adapters_320_slots_160_rate_0.8-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-32/adapters_320_slots_160_rate_0.8-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 135, 8640, 8640, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 8640, 8640, 540, 135, 135, 540, 8640, 8640, 540, 540, 135, 135, 540, 8640, 8640, 135, 8640, 540, 135, 540, 8640, 135, 540, 8640, 8640, 540, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 540, 540, 540, 135, 540, 135, 8640, 135, 8640, 540, 8640, 8640, 135, 8640, 135, 8640, 540, 135, 135, 540, 540, 8640, 540, 8640, 8640, 8640, 135, 540, 540, 135, 8640, 540, 8640, 8640, 540, 135, 540, 540, 540, 135, 8640, 540, 8640, 135, 8640, 135, 135, 540, 8640, 8640, 540, 135, 540, 135, 540, 8640, 8640, 540, 135, 540, 135, 8640, 135, 135, 135, 135, 8640, 540, 540, 8640, 540, 540, 135, 540, 8640, 540, 135, 135, 540, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 540, 8640, 540, 540, 540, 135, 8640, 135, 8640, 540, 135, 540, 135, 135, 540, 135, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 135, 135, 8640, 540, 8640, 540, 8640, 540, 135, 540, 135, 135, 135, 8640, 8640, 540, 540, 135, 135, 540, 135, 8640, 135, 135, 540, 135, 8640, 540, 135, 8640, 135, 135, 8640, 540, 8640, 540, 135, 540, 8640, 540, 540, 8640, 540, 135, 540, 135, 8640, 540, 540, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 540, 135, 540, 135, 540, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 540, 540, 8640, 135, 8640, 135, 135, 135, 8640, 540, 8640, 8640, 135, 540, 540, 540, 135, 540, 135, 540, 540, 8640, 135, 135, 540, 135, 540, 540, 135, 8640, 8640, 8640, 135, 540, 540, 540, 540, 135, 540, 135, 8640, 135, 135, 8640, 540, 8640, 540, 540, 540, 540, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 540, 8640, 540, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 996570 . Total input tokens: 222163490 . Total output tokens: 199302323
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.246737699955702,
    "estimated_duration": 3600.141957379589,
    "input_throughput": 3849.184605511069,
    "output_throughput": 3400.2253646992267,
    "total_throughput": 7249.409970210296,
    "itl": 149.09533949931617,
    "ttft": 2151283.3708613813,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3018,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.990161523427348,
    "arrivals": 332464,
    "finished_requests": 55739,
    "scheduler_time": 95.08096604892887
}
#Debug simulation 
Total elapsed time: 4.246876409975812. Arrivals time: 0.20118285034550354 Scheduler time: 3.8744101062766276 Scheduler overhead time: 0.0359479277394712 Adapter cache time: 0.08147704508155584 Engine time: 0.037002745375502855 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-16/adapters_320_slots_160_rate_0.8-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-16/adapters_320_slots_160_rate_0.8-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 135, 8640, 8640, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 8640, 8640, 540, 135, 135, 540, 8640, 8640, 540, 540, 135, 135, 540, 8640, 8640, 135, 8640, 540, 135, 540, 8640, 135, 540, 8640, 8640, 540, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 540, 540, 540, 135, 540, 135, 8640, 135, 8640, 540, 8640, 8640, 135, 8640, 135, 8640, 540, 135, 135, 540, 540, 8640, 540, 8640, 8640, 8640, 135, 540, 540, 135, 8640, 540, 8640, 8640, 540, 135, 540, 540, 540, 135, 8640, 540, 8640, 135, 8640, 135, 135, 540, 8640, 8640, 540, 135, 540, 135, 540, 8640, 8640, 540, 135, 540, 135, 8640, 135, 135, 135, 135, 8640, 540, 540, 8640, 540, 540, 135, 540, 8640, 540, 135, 135, 540, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 540, 8640, 540, 540, 540, 135, 8640, 135, 8640, 540, 135, 540, 135, 135, 540, 135, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 135, 135, 8640, 540, 8640, 540, 8640, 540, 135, 540, 135, 135, 135, 8640, 8640, 540, 540, 135, 135, 540, 135, 8640, 135, 135, 540, 135, 8640, 540, 135, 8640, 135, 135, 8640, 540, 8640, 540, 135, 540, 8640, 540, 540, 8640, 540, 135, 540, 135, 8640, 540, 540, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 540, 135, 540, 135, 540, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 540, 540, 8640, 135, 8640, 135, 135, 135, 8640, 540, 8640, 8640, 135, 540, 540, 540, 135, 540, 135, 540, 540, 8640, 135, 135, 540, 135, 540, 540, 135, 8640, 8640, 8640, 135, 540, 540, 540, 540, 135, 540, 135, 8640, 135, 135, 8640, 540, 8640, 540, 540, 540, 540, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 540, 8640, 540, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 996570 . Total input tokens: 222163490 . Total output tokens: 199302323
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.502765454992186,
    "estimated_duration": 3600.056922889683,
    "input_throughput": 4102.646240422402,
    "output_throughput": 3602.9683079534652,
    "total_throughput": 7705.614548375867,
    "itl": 236.90030284113595,
    "ttft": 2100773.3223006753,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2513,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.513996391088937,
    "arrivals": 332464,
    "finished_requests": 59349,
    "scheduler_time": 81.34667313980906
}
#Debug simulation 
Total elapsed time: 4.502888478979003. Arrivals time: 0.21422545582754537 Scheduler time: 4.1744470275589265 Scheduler overhead time: 0.025035445811226964 Adapter cache time: 0.052373430924490094 Engine time: 0.025207517202943563 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-32/adapters_320_slots_160_rate_0.8-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-32/adapters_320_slots_160_rate_0.8-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 135, 8640, 8640, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 8640, 8640, 540, 135, 135, 540, 8640, 8640, 540, 540, 135, 135, 540, 8640, 8640, 135, 8640, 540, 135, 540, 8640, 135, 540, 8640, 8640, 540, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 540, 540, 540, 135, 540, 135, 8640, 135, 8640, 540, 8640, 8640, 135, 8640, 135, 8640, 540, 135, 135, 540, 540, 8640, 540, 8640, 8640, 8640, 135, 540, 540, 135, 8640, 540, 8640, 8640, 540, 135, 540, 540, 540, 135, 8640, 540, 8640, 135, 8640, 135, 135, 540, 8640, 8640, 540, 135, 540, 135, 540, 8640, 8640, 540, 135, 540, 135, 8640, 135, 135, 135, 135, 8640, 540, 540, 8640, 540, 540, 135, 540, 8640, 540, 135, 135, 540, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 540, 8640, 540, 540, 540, 135, 8640, 135, 8640, 540, 135, 540, 135, 135, 540, 135, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 135, 135, 8640, 540, 8640, 540, 8640, 540, 135, 540, 135, 135, 135, 8640, 8640, 540, 540, 135, 135, 540, 135, 8640, 135, 135, 540, 135, 8640, 540, 135, 8640, 135, 135, 8640, 540, 8640, 540, 135, 540, 8640, 540, 540, 8640, 540, 135, 540, 135, 8640, 540, 540, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 540, 135, 540, 135, 540, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 540, 540, 8640, 135, 8640, 135, 135, 135, 8640, 540, 8640, 8640, 135, 540, 540, 540, 135, 540, 135, 540, 540, 8640, 135, 135, 540, 135, 540, 540, 135, 8640, 8640, 8640, 135, 540, 540, 540, 540, 135, 540, 135, 8640, 135, 135, 8640, 540, 8640, 540, 540, 540, 540, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 540, 8640, 540, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 996570 . Total input tokens: 222163490 . Total output tokens: 199302323
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.20327850501053,
    "estimated_duration": 3600.0319960627094,
    "input_throughput": 3848.386907436439,
    "output_throughput": 3399.863671596878,
    "total_throughput": 7248.250579033317,
    "itl": 148.93226873323243,
    "ttft": 2151254.266289174,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3012,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.092155331819708,
    "arrivals": 332464,
    "finished_requests": 55727,
    "scheduler_time": 95.1198950200158
}
#Debug simulation 
Total elapsed time: 4.203373252006713. Arrivals time: 0.19841808738419786 Scheduler time: 3.832681883708574 Scheduler overhead time: 0.03572185040684417 Adapter cache time: 0.08326830656733364 Engine time: 0.03655452450038865 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-8/adapters_320_slots_160_rate_0.8-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-8/adapters_320_slots_160_rate_0.8-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 66, 8640, 8640, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 8640, 8640, 540, 66, 66, 540, 8640, 8640, 540, 540, 66, 66, 540, 8640, 8640, 66, 8640, 540, 66, 540, 8640, 66, 540, 8640, 8640, 540, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 540, 540, 540, 66, 540, 66, 8640, 66, 8640, 540, 8640, 8640, 66, 8640, 66, 8640, 540, 66, 66, 540, 540, 8640, 540, 8640, 8640, 8640, 66, 540, 540, 66, 8640, 540, 8640, 8640, 540, 66, 540, 540, 540, 66, 8640, 540, 8640, 66, 8640, 66, 66, 540, 8640, 8640, 540, 66, 540, 66, 540, 8640, 8640, 540, 66, 540, 66, 8640, 66, 66, 66, 66, 8640, 540, 540, 8640, 540, 540, 66, 540, 8640, 540, 66, 66, 540, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 540, 8640, 540, 540, 540, 66, 8640, 66, 8640, 540, 66, 540, 66, 66, 540, 66, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 66, 66, 8640, 540, 8640, 540, 8640, 540, 66, 540, 66, 66, 66, 8640, 8640, 540, 540, 66, 66, 540, 66, 8640, 66, 66, 540, 66, 8640, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 66, 540, 8640, 540, 540, 8640, 540, 66, 540, 66, 8640, 540, 540, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 540, 66, 540, 66, 540, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 540, 540, 8640, 66, 8640, 66, 66, 66, 8640, 540, 8640, 8640, 66, 540, 540, 540, 66, 540, 66, 540, 540, 8640, 66, 66, 540, 66, 540, 540, 66, 8640, 8640, 8640, 66, 540, 540, 540, 540, 66, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 540, 540, 540, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 540, 8640, 540, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 989256 . Total input tokens: 220536779 . Total output tokens: 197807950
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.382982203038409,
    "estimated_duration": 3600.16022593648,
    "input_throughput": 4105.256730943276,
    "output_throughput": 3632.7097071347816,
    "total_throughput": 7737.966438078058,
    "itl": 236.24464221856203,
    "ttft": 2089618.7376011554,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2572,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.8715744773952805,
    "arrivals": 329992,
    "finished_requests": 59823,
    "scheduler_time": 81.88356063060864
}
#Debug simulation 
Total elapsed time: 4.383079364022706. Arrivals time: 0.21376705152215436 Scheduler time: 4.055021313659381 Scheduler overhead time: 0.02448098309105262 Adapter cache time: 0.05351694504497573 Engine time: 0.024922760960180312 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-16/adapters_320_slots_160_rate_0.8-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-16/adapters_320_slots_160_rate_0.8-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 66, 8640, 8640, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 8640, 8640, 540, 66, 66, 540, 8640, 8640, 540, 540, 66, 66, 540, 8640, 8640, 66, 8640, 540, 66, 540, 8640, 66, 540, 8640, 8640, 540, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 540, 540, 540, 66, 540, 66, 8640, 66, 8640, 540, 8640, 8640, 66, 8640, 66, 8640, 540, 66, 66, 540, 540, 8640, 540, 8640, 8640, 8640, 66, 540, 540, 66, 8640, 540, 8640, 8640, 540, 66, 540, 540, 540, 66, 8640, 540, 8640, 66, 8640, 66, 66, 540, 8640, 8640, 540, 66, 540, 66, 540, 8640, 8640, 540, 66, 540, 66, 8640, 66, 66, 66, 66, 8640, 540, 540, 8640, 540, 540, 66, 540, 8640, 540, 66, 66, 540, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 540, 8640, 540, 540, 540, 66, 8640, 66, 8640, 540, 66, 540, 66, 66, 540, 66, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 66, 66, 8640, 540, 8640, 540, 8640, 540, 66, 540, 66, 66, 66, 8640, 8640, 540, 540, 66, 66, 540, 66, 8640, 66, 66, 540, 66, 8640, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 66, 540, 8640, 540, 540, 8640, 540, 66, 540, 66, 8640, 540, 540, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 540, 66, 540, 66, 540, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 540, 540, 8640, 66, 8640, 66, 66, 66, 8640, 540, 8640, 8640, 66, 540, 540, 540, 66, 540, 66, 540, 540, 8640, 66, 66, 540, 66, 540, 540, 66, 8640, 8640, 8640, 66, 540, 540, 540, 540, 66, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 540, 540, 540, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 540, 8640, 540, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 989256 . Total input tokens: 220536779 . Total output tokens: 197807950
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.375267417985015,
    "estimated_duration": 3600.0255954047443,
    "input_throughput": 4104.746927039175,
    "output_throughput": 3632.1850090984963,
    "total_throughput": 7736.931936137671,
    "itl": 236.281419404522,
    "ttft": 2089677.5922928436,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2571,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.397149376324085,
    "arrivals": 329992,
    "finished_requests": 59815,
    "scheduler_time": 81.86843970715094
}
#Debug simulation 
Total elapsed time: 4.375364509993233. Arrivals time: 0.2144152473192662 Scheduler time: 4.04661872505676 Scheduler overhead time: 0.02451153815491125 Adapter cache time: 0.0537534196046181 Engine time: 0.024835804710164666 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-32/adapters_320_slots_160_rate_0.8-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-32/adapters_320_slots_160_rate_0.8-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 66, 8640, 8640, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 8640, 8640, 540, 66, 66, 540, 8640, 8640, 540, 540, 66, 66, 540, 8640, 8640, 66, 8640, 540, 66, 540, 8640, 66, 540, 8640, 8640, 540, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 540, 540, 540, 66, 540, 66, 8640, 66, 8640, 540, 8640, 8640, 66, 8640, 66, 8640, 540, 66, 66, 540, 540, 8640, 540, 8640, 8640, 8640, 66, 540, 540, 66, 8640, 540, 8640, 8640, 540, 66, 540, 540, 540, 66, 8640, 540, 8640, 66, 8640, 66, 66, 540, 8640, 8640, 540, 66, 540, 66, 540, 8640, 8640, 540, 66, 540, 66, 8640, 66, 66, 66, 66, 8640, 540, 540, 8640, 540, 540, 66, 540, 8640, 540, 66, 66, 540, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 540, 8640, 540, 540, 540, 66, 8640, 66, 8640, 540, 66, 540, 66, 66, 540, 66, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 66, 66, 8640, 540, 8640, 540, 8640, 540, 66, 540, 66, 66, 66, 8640, 8640, 540, 540, 66, 66, 540, 66, 8640, 66, 66, 540, 66, 8640, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 66, 540, 8640, 540, 540, 8640, 540, 66, 540, 66, 8640, 540, 540, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 540, 66, 540, 66, 540, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 540, 540, 8640, 66, 8640, 66, 66, 66, 8640, 540, 8640, 8640, 66, 540, 540, 540, 66, 540, 66, 540, 540, 8640, 66, 66, 540, 66, 540, 540, 66, 8640, 8640, 8640, 66, 540, 540, 540, 540, 66, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 540, 540, 540, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 540, 8640, 540, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 989256 . Total input tokens: 220536779 . Total output tokens: 197807950
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.288709559012204,
    "estimated_duration": 3600.114260982018,
    "input_throughput": 3883.816453143913,
    "output_throughput": 3456.0575298535355,
    "total_throughput": 7339.873982997448,
    "itl": 146.94611711693878,
    "ttft": 2132482.570899015,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2568,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.398857321683229,
    "arrivals": 329992,
    "finished_requests": 56644,
    "scheduler_time": 96.58227331370527
}
#Debug simulation 
Total elapsed time: 4.288832331018057. Arrivals time: 0.20902083249529824 Scheduler time: 3.913228597957641 Scheduler overhead time: 0.03651056403759867 Adapter cache time: 0.07581055670743808 Engine time: 0.037285552301909775 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-16/adapters_320_slots_160_rate_0.8-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-16/adapters_320_slots_160_rate_0.8-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 66, 8640, 8640, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 8640, 8640, 540, 66, 66, 540, 8640, 8640, 540, 540, 66, 66, 540, 8640, 8640, 66, 8640, 540, 66, 540, 8640, 66, 540, 8640, 8640, 540, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 540, 540, 540, 66, 540, 66, 8640, 66, 8640, 540, 8640, 8640, 66, 8640, 66, 8640, 540, 66, 66, 540, 540, 8640, 540, 8640, 8640, 8640, 66, 540, 540, 66, 8640, 540, 8640, 8640, 540, 66, 540, 540, 540, 66, 8640, 540, 8640, 66, 8640, 66, 66, 540, 8640, 8640, 540, 66, 540, 66, 540, 8640, 8640, 540, 66, 540, 66, 8640, 66, 66, 66, 66, 8640, 540, 540, 8640, 540, 540, 66, 540, 8640, 540, 66, 66, 540, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 540, 8640, 540, 540, 540, 66, 8640, 66, 8640, 540, 66, 540, 66, 66, 540, 66, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 66, 66, 8640, 540, 8640, 540, 8640, 540, 66, 540, 66, 66, 66, 8640, 8640, 540, 540, 66, 66, 540, 66, 8640, 66, 66, 540, 66, 8640, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 66, 540, 8640, 540, 540, 8640, 540, 66, 540, 66, 8640, 540, 540, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 540, 66, 540, 66, 540, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 540, 540, 8640, 66, 8640, 66, 66, 66, 8640, 540, 8640, 8640, 66, 540, 540, 540, 66, 540, 66, 540, 540, 8640, 66, 66, 540, 66, 540, 540, 66, 8640, 8640, 8640, 66, 540, 540, 540, 540, 66, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 540, 540, 540, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 540, 8640, 540, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 989256 . Total input tokens: 220536779 . Total output tokens: 197807950
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.38552376703592,
    "estimated_duration": 3600.0630903626907,
    "input_throughput": 4105.172500882781,
    "output_throughput": 3632.666614929369,
    "total_throughput": 7737.83911581215,
    "itl": 236.25523880881752,
    "ttft": 2089593.7794503674,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2572,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.018102803877248,
    "arrivals": 329992,
    "finished_requests": 59821,
    "scheduler_time": 81.87844020156831
}
#Debug simulation 
Total elapsed time: 4.385620394023135. Arrivals time: 0.21967014227993786 Scheduler time: 4.052299759292509 Scheduler overhead time: 0.024461434630211443 Adapter cache time: 0.053110026579815894 Engine time: 0.02479409729130566 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-32/adapters_320_slots_160_rate_0.8-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-32/adapters_320_slots_160_rate_0.8-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 66, 8640, 8640, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 8640, 8640, 540, 66, 66, 540, 8640, 8640, 540, 540, 66, 66, 540, 8640, 8640, 66, 8640, 540, 66, 540, 8640, 66, 540, 8640, 8640, 540, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 540, 540, 540, 66, 540, 66, 8640, 66, 8640, 540, 8640, 8640, 66, 8640, 66, 8640, 540, 66, 66, 540, 540, 8640, 540, 8640, 8640, 8640, 66, 540, 540, 66, 8640, 540, 8640, 8640, 540, 66, 540, 540, 540, 66, 8640, 540, 8640, 66, 8640, 66, 66, 540, 8640, 8640, 540, 66, 540, 66, 540, 8640, 8640, 540, 66, 540, 66, 8640, 66, 66, 66, 66, 8640, 540, 540, 8640, 540, 540, 66, 540, 8640, 540, 66, 66, 540, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 540, 8640, 540, 540, 540, 66, 8640, 66, 8640, 540, 66, 540, 66, 66, 540, 66, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 66, 66, 8640, 540, 8640, 540, 8640, 540, 66, 540, 66, 66, 66, 8640, 8640, 540, 540, 66, 66, 540, 66, 8640, 66, 66, 540, 66, 8640, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 66, 540, 8640, 540, 540, 8640, 540, 66, 540, 66, 8640, 540, 540, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 540, 66, 540, 66, 540, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 540, 540, 8640, 66, 8640, 66, 66, 66, 8640, 540, 8640, 8640, 66, 540, 540, 540, 66, 540, 66, 540, 540, 8640, 66, 66, 540, 66, 540, 540, 66, 8640, 8640, 8640, 66, 540, 540, 540, 540, 66, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 540, 540, 540, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 540, 8640, 540, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 989256 . Total input tokens: 220536779 . Total output tokens: 197807950
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.291280341974925,
    "estimated_duration": 3600.0751214385596,
    "input_throughput": 3884.536163348687,
    "output_throughput": 3456.6450921800238,
    "total_throughput": 7341.181255528711,
    "itl": 147.11109593107082,
    "ttft": 2132276.452086615,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2574,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.538105001691477,
    "arrivals": 329992,
    "finished_requests": 56651,
    "scheduler_time": 96.53600290013581
}
#Debug simulation 
Total elapsed time: 4.291375359985977. Arrivals time: 0.2113450975739397 Scheduler time: 3.9136131637496874 Scheduler overhead time: 0.036255360988434404 Adapter cache time: 0.07594308495754376 Engine time: 0.037169775168877095 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-16/adapters_320_slots_160_rate_0.8-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-16/adapters_320_slots_160_rate_0.8-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 66, 8640, 8640, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 8640, 8640, 540, 66, 66, 540, 8640, 8640, 540, 540, 66, 66, 540, 8640, 8640, 66, 8640, 540, 66, 540, 8640, 66, 540, 8640, 8640, 540, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 540, 540, 540, 66, 540, 66, 8640, 66, 8640, 540, 8640, 8640, 66, 8640, 66, 8640, 540, 66, 66, 540, 540, 8640, 540, 8640, 8640, 8640, 66, 540, 540, 66, 8640, 540, 8640, 8640, 540, 66, 540, 540, 540, 66, 8640, 540, 8640, 66, 8640, 66, 66, 540, 8640, 8640, 540, 66, 540, 66, 540, 8640, 8640, 540, 66, 540, 66, 8640, 66, 66, 66, 66, 8640, 540, 540, 8640, 540, 540, 66, 540, 8640, 540, 66, 66, 540, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 540, 8640, 540, 540, 540, 66, 8640, 66, 8640, 540, 66, 540, 66, 66, 540, 66, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 66, 66, 8640, 540, 8640, 540, 8640, 540, 66, 540, 66, 66, 66, 8640, 8640, 540, 540, 66, 66, 540, 66, 8640, 66, 66, 540, 66, 8640, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 66, 540, 8640, 540, 540, 8640, 540, 66, 540, 66, 8640, 540, 540, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 540, 66, 540, 66, 540, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 540, 540, 8640, 66, 8640, 66, 66, 66, 8640, 540, 8640, 8640, 66, 540, 540, 540, 66, 540, 66, 540, 540, 8640, 66, 66, 540, 66, 540, 540, 66, 8640, 8640, 8640, 66, 540, 540, 540, 540, 66, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 540, 540, 540, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 540, 8640, 540, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 989256 . Total input tokens: 220536779 . Total output tokens: 197807950
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.428822156041861,
    "estimated_duration": 3600.105692607575,
    "input_throughput": 4105.319193919297,
    "output_throughput": 3632.834454514893,
    "total_throughput": 7738.15364843419,
    "itl": 236.23298494946468,
    "ttft": 2089566.8162733528,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2573,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.693399408783061,
    "arrivals": 329992,
    "finished_requests": 59824,
    "scheduler_time": 81.8858082747736
}
#Debug simulation 
Total elapsed time: 4.428939041041303. Arrivals time: 0.2293249323265627 Scheduler time: 4.085996492533013 Scheduler overhead time: 0.02445170405553654 Adapter cache time: 0.053048814414069057 Engine time: 0.0247984888846986 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-32/adapters_320_slots_160_rate_0.8-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-32/adapters_320_slots_160_rate_0.8-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 66, 8640, 8640, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 8640, 8640, 540, 66, 66, 540, 8640, 8640, 540, 540, 66, 66, 540, 8640, 8640, 66, 8640, 540, 66, 540, 8640, 66, 540, 8640, 8640, 540, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 540, 540, 540, 66, 540, 66, 8640, 66, 8640, 540, 8640, 8640, 66, 8640, 66, 8640, 540, 66, 66, 540, 540, 8640, 540, 8640, 8640, 8640, 66, 540, 540, 66, 8640, 540, 8640, 8640, 540, 66, 540, 540, 540, 66, 8640, 540, 8640, 66, 8640, 66, 66, 540, 8640, 8640, 540, 66, 540, 66, 540, 8640, 8640, 540, 66, 540, 66, 8640, 66, 66, 66, 66, 8640, 540, 540, 8640, 540, 540, 66, 540, 8640, 540, 66, 66, 540, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 540, 8640, 540, 540, 540, 66, 8640, 66, 8640, 540, 66, 540, 66, 66, 540, 66, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 66, 66, 8640, 540, 8640, 540, 8640, 540, 66, 540, 66, 66, 66, 8640, 8640, 540, 540, 66, 66, 540, 66, 8640, 66, 66, 540, 66, 8640, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 66, 540, 8640, 540, 540, 8640, 540, 66, 540, 66, 8640, 540, 540, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 540, 66, 540, 66, 540, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 540, 540, 8640, 66, 8640, 66, 66, 66, 8640, 540, 8640, 8640, 66, 540, 540, 540, 66, 540, 66, 540, 540, 8640, 66, 66, 540, 66, 540, 540, 66, 8640, 8640, 8640, 66, 540, 540, 540, 540, 66, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 540, 540, 540, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 540, 8640, 540, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 989256 . Total input tokens: 220536779 . Total output tokens: 197807950
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.288357485027518,
    "estimated_duration": 3600.1396624930067,
    "input_throughput": 3885.028724223048,
    "output_throughput": 3457.0475500335333,
    "total_throughput": 7342.076274256581,
    "itl": 147.29189937000965,
    "ttft": 2132159.326311872,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2572,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.629385696351136,
    "arrivals": 329992,
    "finished_requests": 56659,
    "scheduler_time": 96.4917389654926
}
#Debug simulation 
Total elapsed time: 4.288527381024323. Arrivals time: 0.22022519318852574 Scheduler time: 3.9022990053053945 Scheduler overhead time: 0.0362401605816558 Adapter cache time: 0.07545847451547161 Engine time: 0.037003161443863064 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-8/adapters_320_slots_160_rate_0.8-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-8/adapters_320_slots_160_rate_0.8-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 33, 8640, 8640, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 8640, 8640, 540, 33, 33, 540, 8640, 8640, 540, 540, 33, 33, 540, 8640, 8640, 33, 8640, 540, 33, 540, 8640, 33, 540, 8640, 8640, 540, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 540, 540, 540, 33, 540, 33, 8640, 33, 8640, 540, 8640, 8640, 33, 8640, 33, 8640, 540, 33, 33, 540, 540, 8640, 540, 8640, 8640, 8640, 33, 540, 540, 33, 8640, 540, 8640, 8640, 540, 33, 540, 540, 540, 33, 8640, 540, 8640, 33, 8640, 33, 33, 540, 8640, 8640, 540, 33, 540, 33, 540, 8640, 8640, 540, 33, 540, 33, 8640, 33, 33, 33, 33, 8640, 540, 540, 8640, 540, 540, 33, 540, 8640, 540, 33, 33, 540, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 540, 8640, 540, 540, 540, 33, 8640, 33, 8640, 540, 33, 540, 33, 33, 540, 33, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 33, 33, 8640, 540, 8640, 540, 8640, 540, 33, 540, 33, 33, 33, 8640, 8640, 540, 540, 33, 33, 540, 33, 8640, 33, 33, 540, 33, 8640, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 33, 540, 8640, 540, 540, 8640, 540, 33, 540, 33, 8640, 540, 540, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 540, 33, 540, 33, 540, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 540, 540, 8640, 33, 8640, 33, 33, 33, 8640, 540, 8640, 8640, 33, 540, 540, 540, 33, 540, 33, 540, 540, 8640, 33, 33, 540, 33, 540, 540, 33, 8640, 8640, 8640, 33, 540, 540, 540, 540, 33, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 540, 540, 540, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 540, 8640, 540, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 985758 . Total input tokens: 219756182 . Total output tokens: 197094514
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.426276575948577,
    "estimated_duration": 3600.0376517135574,
    "input_throughput": 4166.943640953228,
    "output_throughput": 3687.089492989597,
    "total_throughput": 7854.033133942825,
    "itl": 232.40515459716107,
    "ttft": 2073117.9586376406,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2251,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.889157911592832,
    "arrivals": 328805,
    "finished_requests": 60821,
    "scheduler_time": 83.05284904670525
}
#Debug simulation 
Total elapsed time: 4.42637504497543. Arrivals time: 0.21764043206349015 Scheduler time: 4.0983355937642045 Scheduler overhead time: 0.024591913272161037 Adapter cache time: 0.049442175368312746 Engine time: 0.025038984138518572 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-16/adapters_320_slots_160_rate_0.8-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-16/adapters_320_slots_160_rate_0.8-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 33, 8640, 8640, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 8640, 8640, 540, 33, 33, 540, 8640, 8640, 540, 540, 33, 33, 540, 8640, 8640, 33, 8640, 540, 33, 540, 8640, 33, 540, 8640, 8640, 540, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 540, 540, 540, 33, 540, 33, 8640, 33, 8640, 540, 8640, 8640, 33, 8640, 33, 8640, 540, 33, 33, 540, 540, 8640, 540, 8640, 8640, 8640, 33, 540, 540, 33, 8640, 540, 8640, 8640, 540, 33, 540, 540, 540, 33, 8640, 540, 8640, 33, 8640, 33, 33, 540, 8640, 8640, 540, 33, 540, 33, 540, 8640, 8640, 540, 33, 540, 33, 8640, 33, 33, 33, 33, 8640, 540, 540, 8640, 540, 540, 33, 540, 8640, 540, 33, 33, 540, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 540, 8640, 540, 540, 540, 33, 8640, 33, 8640, 540, 33, 540, 33, 33, 540, 33, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 33, 33, 8640, 540, 8640, 540, 8640, 540, 33, 540, 33, 33, 33, 8640, 8640, 540, 540, 33, 33, 540, 33, 8640, 33, 33, 540, 33, 8640, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 33, 540, 8640, 540, 540, 8640, 540, 33, 540, 33, 8640, 540, 540, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 540, 33, 540, 33, 540, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 540, 540, 8640, 33, 8640, 33, 33, 33, 8640, 540, 8640, 8640, 33, 540, 540, 540, 33, 540, 33, 540, 540, 8640, 33, 33, 540, 33, 540, 540, 33, 8640, 8640, 8640, 33, 540, 540, 540, 540, 33, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 540, 540, 540, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 540, 8640, 540, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 985758 . Total input tokens: 219756182 . Total output tokens: 197094514
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.4233966509927996,
    "estimated_duration": 3600.1439496601683,
    "input_throughput": 4166.138690486469,
    "output_throughput": 3686.4739814786517,
    "total_throughput": 7852.612671965121,
    "itl": 232.43221031216927,
    "ttft": 2073254.4021790258,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2251,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.358614218267315,
    "arrivals": 328805,
    "finished_requests": 60812,
    "scheduler_time": 83.0455846667761
}
#Debug simulation 
Total elapsed time: 4.423491975001525. Arrivals time: 0.2195033131283708 Scheduler time: 4.093232392799109 Scheduler overhead time: 0.024546450411435217 Adapter cache time: 0.049743199022486806 Engine time: 0.025074310833588243 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-32/adapters_320_slots_160_rate_0.8-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-32/adapters_320_slots_160_rate_0.8-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 33, 8640, 8640, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 8640, 8640, 540, 33, 33, 540, 8640, 8640, 540, 540, 33, 33, 540, 8640, 8640, 33, 8640, 540, 33, 540, 8640, 33, 540, 8640, 8640, 540, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 540, 540, 540, 33, 540, 33, 8640, 33, 8640, 540, 8640, 8640, 33, 8640, 33, 8640, 540, 33, 33, 540, 540, 8640, 540, 8640, 8640, 8640, 33, 540, 540, 33, 8640, 540, 8640, 8640, 540, 33, 540, 540, 540, 33, 8640, 540, 8640, 33, 8640, 33, 33, 540, 8640, 8640, 540, 33, 540, 33, 540, 8640, 8640, 540, 33, 540, 33, 8640, 33, 33, 33, 33, 8640, 540, 540, 8640, 540, 540, 33, 540, 8640, 540, 33, 33, 540, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 540, 8640, 540, 540, 540, 33, 8640, 33, 8640, 540, 33, 540, 33, 33, 540, 33, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 33, 33, 8640, 540, 8640, 540, 8640, 540, 33, 540, 33, 33, 33, 8640, 8640, 540, 540, 33, 33, 540, 33, 8640, 33, 33, 540, 33, 8640, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 33, 540, 8640, 540, 540, 8640, 540, 33, 540, 33, 8640, 540, 540, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 540, 33, 540, 33, 540, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 540, 540, 8640, 33, 8640, 33, 33, 33, 8640, 540, 8640, 8640, 33, 540, 540, 540, 33, 540, 33, 540, 540, 8640, 33, 33, 540, 33, 540, 540, 33, 8640, 8640, 8640, 33, 540, 540, 540, 540, 33, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 540, 540, 540, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 540, 8640, 540, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 985758 . Total input tokens: 219756182 . Total output tokens: 197094514
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.308909122017212,
    "estimated_duration": 3600.0787010874815,
    "input_throughput": 3932.8540222532065,
    "output_throughput": 3496.2160677759434,
    "total_throughput": 7429.0700900291495,
    "itl": 145.33879955930516,
    "ttft": 2117291.793182235,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2136,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.99232586050402,
    "arrivals": 328805,
    "finished_requests": 57452,
    "scheduler_time": 97.59657214611126
}
#Debug simulation 
Total elapsed time: 4.309038244013209. Arrivals time: 0.20675542810931802 Scheduler time: 3.940668581519276 Scheduler overhead time: 0.03658869338687509 Adapter cache time: 0.07014998496742919 Engine time: 0.03765367926098406 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-16/adapters_320_slots_160_rate_0.8-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-16/adapters_320_slots_160_rate_0.8-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 33, 8640, 8640, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 8640, 8640, 540, 33, 33, 540, 8640, 8640, 540, 540, 33, 33, 540, 8640, 8640, 33, 8640, 540, 33, 540, 8640, 33, 540, 8640, 8640, 540, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 540, 540, 540, 33, 540, 33, 8640, 33, 8640, 540, 8640, 8640, 33, 8640, 33, 8640, 540, 33, 33, 540, 540, 8640, 540, 8640, 8640, 8640, 33, 540, 540, 33, 8640, 540, 8640, 8640, 540, 33, 540, 540, 540, 33, 8640, 540, 8640, 33, 8640, 33, 33, 540, 8640, 8640, 540, 33, 540, 33, 540, 8640, 8640, 540, 33, 540, 33, 8640, 33, 33, 33, 33, 8640, 540, 540, 8640, 540, 540, 33, 540, 8640, 540, 33, 33, 540, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 540, 8640, 540, 540, 540, 33, 8640, 33, 8640, 540, 33, 540, 33, 33, 540, 33, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 33, 33, 8640, 540, 8640, 540, 8640, 540, 33, 540, 33, 33, 33, 8640, 8640, 540, 540, 33, 33, 540, 33, 8640, 33, 33, 540, 33, 8640, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 33, 540, 8640, 540, 540, 8640, 540, 33, 540, 33, 8640, 540, 540, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 540, 33, 540, 33, 540, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 540, 540, 8640, 33, 8640, 33, 33, 33, 8640, 540, 8640, 8640, 33, 540, 540, 540, 33, 540, 33, 540, 540, 8640, 33, 33, 540, 33, 540, 540, 33, 8640, 8640, 8640, 33, 540, 540, 540, 540, 33, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 540, 540, 540, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 540, 8640, 540, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 985758 . Total input tokens: 219756182 . Total output tokens: 197094514
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.409936384006869,
    "estimated_duration": 3600.2401662462253,
    "input_throughput": 4166.709249189031,
    "output_throughput": 3686.8820931576142,
    "total_throughput": 7853.5913423466445,
    "itl": 232.41451096030084,
    "ttft": 2073171.418615843,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2250,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.019758816214508,
    "arrivals": 328805,
    "finished_requests": 60821,
    "scheduler_time": 83.055231875773
}
#Debug simulation 
Total elapsed time: 4.410031760984566. Arrivals time: 0.21777645498514175 Scheduler time: 4.081912975467276 Scheduler overhead time: 0.024519855272956192 Adapter cache time: 0.049382773286197335 Engine time: 0.025128257169853896 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-32/adapters_320_slots_160_rate_0.8-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-32/adapters_320_slots_160_rate_0.8-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 33, 8640, 8640, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 8640, 8640, 540, 33, 33, 540, 8640, 8640, 540, 540, 33, 33, 540, 8640, 8640, 33, 8640, 540, 33, 540, 8640, 33, 540, 8640, 8640, 540, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 540, 540, 540, 33, 540, 33, 8640, 33, 8640, 540, 8640, 8640, 33, 8640, 33, 8640, 540, 33, 33, 540, 540, 8640, 540, 8640, 8640, 8640, 33, 540, 540, 33, 8640, 540, 8640, 8640, 540, 33, 540, 540, 540, 33, 8640, 540, 8640, 33, 8640, 33, 33, 540, 8640, 8640, 540, 33, 540, 33, 540, 8640, 8640, 540, 33, 540, 33, 8640, 33, 33, 33, 33, 8640, 540, 540, 8640, 540, 540, 33, 540, 8640, 540, 33, 33, 540, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 540, 8640, 540, 540, 540, 33, 8640, 33, 8640, 540, 33, 540, 33, 33, 540, 33, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 33, 33, 8640, 540, 8640, 540, 8640, 540, 33, 540, 33, 33, 33, 8640, 8640, 540, 540, 33, 33, 540, 33, 8640, 33, 33, 540, 33, 8640, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 33, 540, 8640, 540, 540, 8640, 540, 33, 540, 33, 8640, 540, 540, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 540, 33, 540, 33, 540, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 540, 540, 8640, 33, 8640, 33, 33, 33, 8640, 540, 8640, 8640, 33, 540, 540, 540, 33, 540, 33, 540, 540, 8640, 33, 33, 540, 33, 540, 540, 33, 8640, 8640, 8640, 33, 540, 540, 540, 540, 33, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 540, 540, 540, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 540, 8640, 540, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 985758 . Total input tokens: 219756182 . Total output tokens: 197094514
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.574099134013522,
    "estimated_duration": 3600.1010952685724,
    "input_throughput": 3930.609620545766,
    "output_throughput": 3494.646029950288,
    "total_throughput": 7425.255650496054,
    "itl": 144.98598244243448,
    "ttft": 2117799.690339182,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2134,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.080885697919731,
    "arrivals": 328805,
    "finished_requests": 57424,
    "scheduler_time": 97.68809780592203
}
#Debug simulation 
Total elapsed time: 4.574165422003716. Arrivals time: 0.46384257526369765 Scheduler time: 3.9484855934861116 Scheduler overhead time: 0.03664898331044242 Adapter cache time: 0.07039607060141861 Engine time: 0.03761592006776482 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-16/adapters_320_slots_160_rate_0.8-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-16/adapters_320_slots_160_rate_0.8-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 33, 8640, 8640, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 8640, 8640, 540, 33, 33, 540, 8640, 8640, 540, 540, 33, 33, 540, 8640, 8640, 33, 8640, 540, 33, 540, 8640, 33, 540, 8640, 8640, 540, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 540, 540, 540, 33, 540, 33, 8640, 33, 8640, 540, 8640, 8640, 33, 8640, 33, 8640, 540, 33, 33, 540, 540, 8640, 540, 8640, 8640, 8640, 33, 540, 540, 33, 8640, 540, 8640, 8640, 540, 33, 540, 540, 540, 33, 8640, 540, 8640, 33, 8640, 33, 33, 540, 8640, 8640, 540, 33, 540, 33, 540, 8640, 8640, 540, 33, 540, 33, 8640, 33, 33, 33, 33, 8640, 540, 540, 8640, 540, 540, 33, 540, 8640, 540, 33, 33, 540, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 540, 8640, 540, 540, 540, 33, 8640, 33, 8640, 540, 33, 540, 33, 33, 540, 33, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 33, 33, 8640, 540, 8640, 540, 8640, 540, 33, 540, 33, 33, 33, 8640, 8640, 540, 540, 33, 33, 540, 33, 8640, 33, 33, 540, 33, 8640, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 33, 540, 8640, 540, 540, 8640, 540, 33, 540, 33, 8640, 540, 540, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 540, 33, 540, 33, 540, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 540, 540, 8640, 33, 8640, 33, 33, 33, 8640, 540, 8640, 8640, 33, 540, 540, 540, 33, 540, 33, 540, 540, 8640, 33, 33, 540, 33, 540, 540, 33, 8640, 8640, 8640, 33, 540, 540, 540, 540, 33, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 540, 540, 540, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 540, 8640, 540, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 985758 . Total input tokens: 219756182 . Total output tokens: 197094514
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.464487029996235,
    "estimated_duration": 3600.106213105739,
    "input_throughput": 4167.1573314660345,
    "output_throughput": 3687.0592738842993,
    "total_throughput": 7854.216605350333,
    "itl": 232.39409258194627,
    "ttft": 2073080.827009305,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2253,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.736583314414399,
    "arrivals": 328805,
    "finished_requests": 60823,
    "scheduler_time": 83.05802971979895
}
#Debug simulation 
Total elapsed time: 4.464593379991129. Arrivals time: 0.2230221286881715 Scheduler time: 4.129851219011471 Scheduler overhead time: 0.02460373449139297 Adapter cache time: 0.050631750375032425 Engine time: 0.025079044746235013 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-32/adapters_320_slots_160_rate_0.8-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-32/adapters_320_slots_160_rate_0.8-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [106 107 107]
Adapter prompts. [540, 8640, 8640, 33, 8640, 8640, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 8640, 8640, 540, 33, 33, 540, 8640, 8640, 540, 540, 33, 33, 540, 8640, 8640, 33, 8640, 540, 33, 540, 8640, 33, 540, 8640, 8640, 540, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 540, 540, 540, 33, 540, 33, 8640, 33, 8640, 540, 8640, 8640, 33, 8640, 33, 8640, 540, 33, 33, 540, 540, 8640, 540, 8640, 8640, 8640, 33, 540, 540, 33, 8640, 540, 8640, 8640, 540, 33, 540, 540, 540, 33, 8640, 540, 8640, 33, 8640, 33, 33, 540, 8640, 8640, 540, 33, 540, 33, 540, 8640, 8640, 540, 33, 540, 33, 8640, 33, 33, 33, 33, 8640, 540, 540, 8640, 540, 540, 33, 540, 8640, 540, 33, 33, 540, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 540, 8640, 540, 540, 540, 33, 8640, 33, 8640, 540, 33, 540, 33, 33, 540, 33, 540, 8640, 8640, 8640, 8640, 540, 540, 8640, 8640, 8640, 540, 8640, 33, 33, 8640, 540, 8640, 540, 8640, 540, 33, 540, 33, 33, 33, 8640, 8640, 540, 540, 33, 33, 540, 33, 8640, 33, 33, 540, 33, 8640, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 33, 540, 8640, 540, 540, 8640, 540, 33, 540, 33, 8640, 540, 540, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 540, 33, 540, 33, 540, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 540, 540, 8640, 33, 8640, 33, 33, 33, 8640, 540, 8640, 8640, 33, 540, 540, 540, 33, 540, 33, 540, 540, 8640, 33, 33, 540, 33, 540, 540, 33, 8640, 8640, 8640, 33, 540, 540, 540, 540, 33, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 540, 540, 540, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 540, 8640, 540, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 985758 . Total input tokens: 219756182 . Total output tokens: 197094514
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.345573617029004,
    "estimated_duration": 3600.0512918340505,
    "input_throughput": 3933.4184021544625,
    "output_throughput": 3496.5376822692915,
    "total_throughput": 7429.956084423754,
    "itl": 145.42393905642945,
    "ttft": 2117205.001994017,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2134,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.168999088331809,
    "arrivals": 328805,
    "finished_requests": 57458,
    "scheduler_time": 97.5739687984632
}
#Debug simulation 
Total elapsed time: 4.345668716006912. Arrivals time: 0.20721036661416292 Scheduler time: 3.9750923746614717 Scheduler overhead time: 0.036749140184838325 Adapter cache time: 0.07095344335539266 Engine time: 0.03850633429829031 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-8/adapters_320_slots_160_rate_0.8-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-8/adapters_320_slots_160_rate_0.8-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 135, 8640, 8640, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 8640, 270, 8640, 8640, 135, 8640, 270, 270, 8640, 8640, 270, 135, 135, 270, 8640, 8640, 270, 270, 135, 135, 270, 8640, 8640, 135, 8640, 270, 135, 270, 8640, 135, 270, 8640, 8640, 270, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 270, 270, 270, 135, 270, 135, 8640, 135, 8640, 270, 8640, 8640, 135, 8640, 135, 8640, 270, 135, 135, 270, 270, 8640, 270, 8640, 8640, 8640, 135, 270, 270, 135, 8640, 270, 8640, 8640, 270, 135, 270, 270, 270, 135, 8640, 270, 8640, 135, 8640, 135, 135, 270, 8640, 8640, 270, 135, 270, 135, 270, 8640, 8640, 270, 135, 270, 135, 8640, 135, 135, 135, 135, 8640, 270, 270, 8640, 270, 270, 135, 270, 8640, 270, 135, 135, 270, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 270, 8640, 270, 270, 270, 135, 8640, 135, 8640, 270, 135, 270, 135, 135, 270, 135, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 135, 135, 8640, 270, 8640, 270, 8640, 270, 135, 270, 135, 135, 135, 8640, 8640, 270, 270, 135, 135, 270, 135, 8640, 135, 135, 270, 135, 8640, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 135, 270, 8640, 270, 270, 8640, 270, 135, 270, 135, 8640, 270, 270, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 270, 135, 270, 135, 270, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 270, 270, 8640, 135, 8640, 135, 135, 135, 8640, 270, 8640, 8640, 135, 270, 270, 270, 135, 270, 135, 270, 270, 8640, 135, 135, 270, 135, 270, 270, 135, 8640, 8640, 8640, 135, 270, 270, 270, 270, 135, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 270, 270, 270, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 270, 8640, 270, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 967680 . Total input tokens: 215741050 . Total output tokens: 193491034
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.560384631971829,
    "estimated_duration": 3600.0788500530316,
    "input_throughput": 4328.724911058668,
    "output_throughput": 3808.9118519718,
    "total_throughput": 8137.636763030468,
    "itl": 224.51817339891812,
    "ttft": 2051348.3207256717,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2220,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.794282791530914,
    "arrivals": 322791,
    "finished_requests": 63049,
    "scheduler_time": 85.87481961323688
}
#Debug simulation 
Total elapsed time: 4.560479789972305. Arrivals time: 0.2228002286865376 Scheduler time: 4.22602285357425 Scheduler overhead time: 0.025338658248074353 Adapter cache time: 0.04882117419037968 Engine time: 0.025835971406195313 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-16/adapters_320_slots_160_rate_0.8-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-16/adapters_320_slots_160_rate_0.8-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 135, 8640, 8640, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 8640, 270, 8640, 8640, 135, 8640, 270, 270, 8640, 8640, 270, 135, 135, 270, 8640, 8640, 270, 270, 135, 135, 270, 8640, 8640, 135, 8640, 270, 135, 270, 8640, 135, 270, 8640, 8640, 270, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 270, 270, 270, 135, 270, 135, 8640, 135, 8640, 270, 8640, 8640, 135, 8640, 135, 8640, 270, 135, 135, 270, 270, 8640, 270, 8640, 8640, 8640, 135, 270, 270, 135, 8640, 270, 8640, 8640, 270, 135, 270, 270, 270, 135, 8640, 270, 8640, 135, 8640, 135, 135, 270, 8640, 8640, 270, 135, 270, 135, 270, 8640, 8640, 270, 135, 270, 135, 8640, 135, 135, 135, 135, 8640, 270, 270, 8640, 270, 270, 135, 270, 8640, 270, 135, 135, 270, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 270, 8640, 270, 270, 270, 135, 8640, 135, 8640, 270, 135, 270, 135, 135, 270, 135, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 135, 135, 8640, 270, 8640, 270, 8640, 270, 135, 270, 135, 135, 135, 8640, 8640, 270, 270, 135, 135, 270, 135, 8640, 135, 135, 270, 135, 8640, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 135, 270, 8640, 270, 270, 8640, 270, 135, 270, 135, 8640, 270, 270, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 270, 135, 270, 135, 270, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 270, 270, 8640, 135, 8640, 135, 135, 135, 8640, 270, 8640, 8640, 135, 270, 270, 270, 135, 270, 135, 270, 270, 8640, 135, 135, 270, 135, 270, 270, 135, 8640, 8640, 8640, 135, 270, 270, 270, 270, 135, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 270, 270, 270, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 270, 8640, 270, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 967680 . Total input tokens: 215741050 . Total output tokens: 193491034
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.553400438046083,
    "estimated_duration": 3600.137445246848,
    "input_throughput": 4328.326970008658,
    "output_throughput": 3808.574036000412,
    "total_throughput": 8136.9010060090695,
    "itl": 224.54297404215075,
    "ttft": 2051418.58583805,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2219,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.244545819500636,
    "arrivals": 322791,
    "finished_requests": 63044,
    "scheduler_time": 85.86679862061258
}
#Debug simulation 
Total elapsed time: 4.553540524037089. Arrivals time: 0.2297620950266719 Scheduler time: 4.2122920652036555 Scheduler overhead time: 0.025343699380755424 Adapter cache time: 0.0485701619181782 Engine time: 0.02586979081388563 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-32/adapters_320_slots_160_rate_0.8-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-32/adapters_320_slots_160_rate_0.8-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 135, 8640, 8640, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 8640, 270, 8640, 8640, 135, 8640, 270, 270, 8640, 8640, 270, 135, 135, 270, 8640, 8640, 270, 270, 135, 135, 270, 8640, 8640, 135, 8640, 270, 135, 270, 8640, 135, 270, 8640, 8640, 270, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 270, 270, 270, 135, 270, 135, 8640, 135, 8640, 270, 8640, 8640, 135, 8640, 135, 8640, 270, 135, 135, 270, 270, 8640, 270, 8640, 8640, 8640, 135, 270, 270, 135, 8640, 270, 8640, 8640, 270, 135, 270, 270, 270, 135, 8640, 270, 8640, 135, 8640, 135, 135, 270, 8640, 8640, 270, 135, 270, 135, 270, 8640, 8640, 270, 135, 270, 135, 8640, 135, 135, 135, 135, 8640, 270, 270, 8640, 270, 270, 135, 270, 8640, 270, 135, 135, 270, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 270, 8640, 270, 270, 270, 135, 8640, 135, 8640, 270, 135, 270, 135, 135, 270, 135, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 135, 135, 8640, 270, 8640, 270, 8640, 270, 135, 270, 135, 135, 135, 8640, 8640, 270, 270, 135, 135, 270, 135, 8640, 135, 135, 270, 135, 8640, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 135, 270, 8640, 270, 270, 8640, 270, 135, 270, 135, 8640, 270, 270, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 270, 135, 270, 135, 270, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 270, 270, 8640, 135, 8640, 135, 135, 135, 8640, 270, 8640, 8640, 135, 270, 270, 270, 135, 270, 135, 270, 270, 8640, 135, 135, 270, 135, 270, 270, 135, 8640, 8640, 8640, 135, 270, 270, 270, 270, 135, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 270, 270, 270, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 270, 8640, 270, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 967680 . Total input tokens: 215741050 . Total output tokens: 193491034
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.463885408011265,
    "estimated_duration": 3600.0710040008657,
    "input_throughput": 4072.056629913201,
    "output_throughput": 3600.114827067695,
    "total_throughput": 7672.171456980896,
    "itl": 141.6386192609408,
    "ttft": 2097094.539814466,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2062,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.743835388570983,
    "arrivals": 322791,
    "finished_requests": 59298,
    "scheduler_time": 100.26032830164476
}
#Debug simulation 
Total elapsed time: 4.464003559027333. Arrivals time: 0.21111023327102885 Scheduler time: 4.096896214934532 Scheduler overhead time: 0.03753978665918112 Adapter cache time: 0.0621217698790133 Engine time: 0.038621371902991086 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-16/adapters_320_slots_160_rate_0.8-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-16/adapters_320_slots_160_rate_0.8-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 135, 8640, 8640, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 8640, 270, 8640, 8640, 135, 8640, 270, 270, 8640, 8640, 270, 135, 135, 270, 8640, 8640, 270, 270, 135, 135, 270, 8640, 8640, 135, 8640, 270, 135, 270, 8640, 135, 270, 8640, 8640, 270, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 270, 270, 270, 135, 270, 135, 8640, 135, 8640, 270, 8640, 8640, 135, 8640, 135, 8640, 270, 135, 135, 270, 270, 8640, 270, 8640, 8640, 8640, 135, 270, 270, 135, 8640, 270, 8640, 8640, 270, 135, 270, 270, 270, 135, 8640, 270, 8640, 135, 8640, 135, 135, 270, 8640, 8640, 270, 135, 270, 135, 270, 8640, 8640, 270, 135, 270, 135, 8640, 135, 135, 135, 135, 8640, 270, 270, 8640, 270, 270, 135, 270, 8640, 270, 135, 135, 270, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 270, 8640, 270, 270, 270, 135, 8640, 135, 8640, 270, 135, 270, 135, 135, 270, 135, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 135, 135, 8640, 270, 8640, 270, 8640, 270, 135, 270, 135, 135, 135, 8640, 8640, 270, 270, 135, 135, 270, 135, 8640, 135, 135, 270, 135, 8640, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 135, 270, 8640, 270, 270, 8640, 270, 135, 270, 135, 8640, 270, 270, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 270, 135, 270, 135, 270, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 270, 270, 8640, 135, 8640, 135, 135, 135, 8640, 270, 8640, 8640, 135, 270, 270, 270, 135, 270, 135, 270, 270, 8640, 135, 135, 270, 135, 270, 270, 135, 8640, 8640, 8640, 135, 270, 270, 270, 270, 135, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 270, 270, 270, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 270, 8640, 270, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 967680 . Total input tokens: 215741050 . Total output tokens: 193491034
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.583874367992394,
    "estimated_duration": 3600.230930475961,
    "input_throughput": 4328.542057700666,
    "output_throughput": 3808.750956480223,
    "total_throughput": 8137.293014180889,
    "itl": 224.52262355547754,
    "ttft": 2051392.2475050322,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2220,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.93046590268588,
    "arrivals": 322791,
    "finished_requests": 63049,
    "scheduler_time": 85.87761749874902
}
#Debug simulation 
Total elapsed time: 4.583978345966898. Arrivals time: 0.2249314397922717 Scheduler time: 4.247648035408929 Scheduler overhead time: 0.02537507493980229 Adapter cache time: 0.04864781926153228 Engine time: 0.02570443192962557 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-32/adapters_320_slots_160_rate_0.8-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-32/adapters_320_slots_160_rate_0.8-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 135, 8640, 8640, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 8640, 270, 8640, 8640, 135, 8640, 270, 270, 8640, 8640, 270, 135, 135, 270, 8640, 8640, 270, 270, 135, 135, 270, 8640, 8640, 135, 8640, 270, 135, 270, 8640, 135, 270, 8640, 8640, 270, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 270, 270, 270, 135, 270, 135, 8640, 135, 8640, 270, 8640, 8640, 135, 8640, 135, 8640, 270, 135, 135, 270, 270, 8640, 270, 8640, 8640, 8640, 135, 270, 270, 135, 8640, 270, 8640, 8640, 270, 135, 270, 270, 270, 135, 8640, 270, 8640, 135, 8640, 135, 135, 270, 8640, 8640, 270, 135, 270, 135, 270, 8640, 8640, 270, 135, 270, 135, 8640, 135, 135, 135, 135, 8640, 270, 270, 8640, 270, 270, 135, 270, 8640, 270, 135, 135, 270, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 270, 8640, 270, 270, 270, 135, 8640, 135, 8640, 270, 135, 270, 135, 135, 270, 135, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 135, 135, 8640, 270, 8640, 270, 8640, 270, 135, 270, 135, 135, 135, 8640, 8640, 270, 270, 135, 135, 270, 135, 8640, 135, 135, 270, 135, 8640, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 135, 270, 8640, 270, 270, 8640, 270, 135, 270, 135, 8640, 270, 270, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 270, 135, 270, 135, 270, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 270, 270, 8640, 135, 8640, 135, 135, 135, 8640, 270, 8640, 8640, 135, 270, 270, 270, 135, 270, 135, 270, 270, 8640, 135, 135, 270, 135, 270, 270, 135, 8640, 8640, 8640, 135, 270, 270, 270, 270, 135, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 270, 270, 270, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 270, 8640, 270, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 967680 . Total input tokens: 215741050 . Total output tokens: 193491034
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.429393729020376,
    "estimated_duration": 3600.1224261961634,
    "input_throughput": 4072.369843125204,
    "output_throughput": 3600.4245038120625,
    "total_throughput": 7672.794346937267,
    "itl": 141.67279968732885,
    "ttft": 2096998.4194650748,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2062,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.8353841450809085,
    "arrivals": 322791,
    "finished_requests": 59304,
    "scheduler_time": 100.2563829364225
}
#Debug simulation 
Total elapsed time: 4.429486175999045. Arrivals time: 0.21061670512426645 Scheduler time: 4.063186751096509 Scheduler overhead time: 0.03759750793687999 Adapter cache time: 0.062000443460419774 Engine time: 0.03854903834871948 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-16/adapters_320_slots_160_rate_0.8-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-16/adapters_320_slots_160_rate_0.8-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 135, 8640, 8640, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 8640, 270, 8640, 8640, 135, 8640, 270, 270, 8640, 8640, 270, 135, 135, 270, 8640, 8640, 270, 270, 135, 135, 270, 8640, 8640, 135, 8640, 270, 135, 270, 8640, 135, 270, 8640, 8640, 270, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 270, 270, 270, 135, 270, 135, 8640, 135, 8640, 270, 8640, 8640, 135, 8640, 135, 8640, 270, 135, 135, 270, 270, 8640, 270, 8640, 8640, 8640, 135, 270, 270, 135, 8640, 270, 8640, 8640, 270, 135, 270, 270, 270, 135, 8640, 270, 8640, 135, 8640, 135, 135, 270, 8640, 8640, 270, 135, 270, 135, 270, 8640, 8640, 270, 135, 270, 135, 8640, 135, 135, 135, 135, 8640, 270, 270, 8640, 270, 270, 135, 270, 8640, 270, 135, 135, 270, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 270, 8640, 270, 270, 270, 135, 8640, 135, 8640, 270, 135, 270, 135, 135, 270, 135, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 135, 135, 8640, 270, 8640, 270, 8640, 270, 135, 270, 135, 135, 135, 8640, 8640, 270, 270, 135, 135, 270, 135, 8640, 135, 135, 270, 135, 8640, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 135, 270, 8640, 270, 270, 8640, 270, 135, 270, 135, 8640, 270, 270, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 270, 135, 270, 135, 270, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 270, 270, 8640, 135, 8640, 135, 135, 135, 8640, 270, 8640, 8640, 135, 270, 270, 270, 135, 270, 135, 270, 270, 8640, 135, 135, 270, 135, 270, 270, 135, 8640, 8640, 8640, 135, 270, 270, 270, 270, 135, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 270, 270, 270, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 270, 8640, 270, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 967680 . Total input tokens: 215741050 . Total output tokens: 193491034
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.627292751043569,
    "estimated_duration": 3600.089621024062,
    "input_throughput": 4328.944454323582,
    "output_throughput": 3808.972398886941,
    "total_throughput": 8137.916853210523,
    "itl": 224.50481420018394,
    "ttft": 2051386.205275277,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2219,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.634921604387729,
    "arrivals": 322791,
    "finished_requests": 63052,
    "scheduler_time": 85.87916135111998
}
#Debug simulation 
Total elapsed time: 4.627413730020635. Arrivals time: 0.2395339317736216 Scheduler time: 4.2750268678646535 Scheduler overhead time: 0.02539748325943947 Adapter cache time: 0.0497086868272163 Engine time: 0.025888401840347797 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-32/adapters_320_slots_160_rate_0.8-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-32/adapters_320_slots_160_rate_0.8-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 135, 8640, 8640, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 8640, 270, 8640, 8640, 135, 8640, 270, 270, 8640, 8640, 270, 135, 135, 270, 8640, 8640, 270, 270, 135, 135, 270, 8640, 8640, 135, 8640, 270, 135, 270, 8640, 135, 270, 8640, 8640, 270, 135, 135, 8640, 135, 135, 8640, 8640, 135, 135, 270, 270, 270, 135, 270, 135, 8640, 135, 8640, 270, 8640, 8640, 135, 8640, 135, 8640, 270, 135, 135, 270, 270, 8640, 270, 8640, 8640, 8640, 135, 270, 270, 135, 8640, 270, 8640, 8640, 270, 135, 270, 270, 270, 135, 8640, 270, 8640, 135, 8640, 135, 135, 270, 8640, 8640, 270, 135, 270, 135, 270, 8640, 8640, 270, 135, 270, 135, 8640, 135, 135, 135, 135, 8640, 270, 270, 8640, 270, 270, 135, 270, 8640, 270, 135, 135, 270, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 270, 8640, 270, 270, 270, 135, 8640, 135, 8640, 270, 135, 270, 135, 135, 270, 135, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 135, 135, 8640, 270, 8640, 270, 8640, 270, 135, 270, 135, 135, 135, 8640, 8640, 270, 270, 135, 135, 270, 135, 8640, 135, 135, 270, 135, 8640, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 135, 270, 8640, 270, 270, 8640, 270, 135, 270, 135, 8640, 270, 270, 8640, 8640, 135, 135, 135, 8640, 8640, 135, 135, 8640, 270, 135, 270, 135, 270, 8640, 8640, 8640, 135, 8640, 8640, 8640, 8640, 135, 270, 270, 8640, 135, 8640, 135, 135, 135, 8640, 270, 8640, 8640, 135, 270, 270, 270, 135, 270, 135, 270, 270, 8640, 135, 135, 270, 135, 270, 270, 135, 8640, 8640, 8640, 135, 270, 270, 270, 270, 135, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 270, 270, 270, 135, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 8640, 270, 8640, 270, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 967680 . Total input tokens: 215741050 . Total output tokens: 193491034
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.437728288990911,
    "estimated_duration": 3600.033618233825,
    "input_throughput": 4073.1791852527053,
    "output_throughput": 3601.1866484625566,
    "total_throughput": 7674.365833715262,
    "itl": 141.7742493026239,
    "ttft": 2097194.5111770728,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2065,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.9289012045038465,
    "arrivals": 322791,
    "finished_requests": 59314,
    "scheduler_time": 100.22346506847713
}
#Debug simulation 
Total elapsed time: 4.437849776004441. Arrivals time: 0.21416235354263335 Scheduler time: 4.066782848560251 Scheduler overhead time: 0.037762263731565326 Adapter cache time: 0.06278166943229735 Engine time: 0.03861052624415606 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-8/adapters_320_slots_160_rate_0.8-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-8/adapters_320_slots_160_rate_0.8-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 66, 8640, 8640, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 8640, 270, 8640, 8640, 66, 8640, 270, 270, 8640, 8640, 270, 66, 66, 270, 8640, 8640, 270, 270, 66, 66, 270, 8640, 8640, 66, 8640, 270, 66, 270, 8640, 66, 270, 8640, 8640, 270, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 270, 270, 270, 66, 270, 66, 8640, 66, 8640, 270, 8640, 8640, 66, 8640, 66, 8640, 270, 66, 66, 270, 270, 8640, 270, 8640, 8640, 8640, 66, 270, 270, 66, 8640, 270, 8640, 8640, 270, 66, 270, 270, 270, 66, 8640, 270, 8640, 66, 8640, 66, 66, 270, 8640, 8640, 270, 66, 270, 66, 270, 8640, 8640, 270, 66, 270, 66, 8640, 66, 66, 66, 66, 8640, 270, 270, 8640, 270, 270, 66, 270, 8640, 270, 66, 66, 270, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 270, 8640, 270, 270, 270, 66, 8640, 66, 8640, 270, 66, 270, 66, 66, 270, 66, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 66, 66, 8640, 270, 8640, 270, 8640, 270, 66, 270, 66, 66, 66, 8640, 8640, 270, 270, 66, 66, 270, 66, 8640, 66, 66, 270, 66, 8640, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 66, 270, 8640, 270, 270, 8640, 270, 66, 270, 66, 8640, 270, 270, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 270, 66, 270, 66, 270, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 270, 270, 8640, 66, 8640, 66, 66, 66, 8640, 270, 8640, 8640, 66, 270, 270, 270, 66, 270, 66, 270, 270, 8640, 66, 66, 270, 66, 270, 270, 66, 8640, 8640, 8640, 66, 270, 270, 270, 270, 66, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 270, 270, 270, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 270, 8640, 270, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 960366 . Total input tokens: 214114371 . Total output tokens: 192008310
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.620173191011418,
    "estimated_duration": 3600.1588379378345,
    "input_throughput": 4411.772012008727,
    "output_throughput": 3875.1276340882655,
    "total_throughput": 8286.899646096992,
    "itl": 220.0908471647002,
    "ttft": 2038141.8159267036,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1786,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.466031110664052,
    "arrivals": 320386,
    "finished_requests": 64140,
    "scheduler_time": 87.28099816698504
}
#Debug simulation 
Total elapsed time: 4.620266905985773. Arrivals time: 0.2281009426806122 Scheduler time: 4.285804094106425 Scheduler overhead time: 0.025681685365270823 Adapter cache time: 0.04259632737375796 Engine time: 0.026222108397632837 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-16/adapters_320_slots_160_rate_0.8-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-16/adapters_320_slots_160_rate_0.8-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 66, 8640, 8640, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 8640, 270, 8640, 8640, 66, 8640, 270, 270, 8640, 8640, 270, 66, 66, 270, 8640, 8640, 270, 270, 66, 66, 270, 8640, 8640, 66, 8640, 270, 66, 270, 8640, 66, 270, 8640, 8640, 270, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 270, 270, 270, 66, 270, 66, 8640, 66, 8640, 270, 8640, 8640, 66, 8640, 66, 8640, 270, 66, 66, 270, 270, 8640, 270, 8640, 8640, 8640, 66, 270, 270, 66, 8640, 270, 8640, 8640, 270, 66, 270, 270, 270, 66, 8640, 270, 8640, 66, 8640, 66, 66, 270, 8640, 8640, 270, 66, 270, 66, 270, 8640, 8640, 270, 66, 270, 66, 8640, 66, 66, 66, 66, 8640, 270, 270, 8640, 270, 270, 66, 270, 8640, 270, 66, 66, 270, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 270, 8640, 270, 270, 270, 66, 8640, 66, 8640, 270, 66, 270, 66, 66, 270, 66, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 66, 66, 8640, 270, 8640, 270, 8640, 270, 66, 270, 66, 66, 66, 8640, 8640, 270, 270, 66, 66, 270, 66, 8640, 66, 66, 270, 66, 8640, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 66, 270, 8640, 270, 270, 8640, 270, 66, 270, 66, 8640, 270, 270, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 270, 66, 270, 66, 270, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 270, 270, 8640, 66, 8640, 66, 66, 66, 8640, 270, 8640, 8640, 66, 270, 270, 270, 66, 270, 66, 270, 270, 8640, 66, 66, 270, 66, 270, 270, 66, 8640, 8640, 8640, 66, 270, 270, 270, 270, 66, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 270, 270, 270, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 270, 8640, 270, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 960366 . Total input tokens: 214114371 . Total output tokens: 192008310
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.851129751012195,
    "estimated_duration": 3600.0924233426513,
    "input_throughput": 4411.255915828602,
    "output_throughput": 3874.269979727261,
    "total_throughput": 8285.525895555864,
    "itl": 220.1069353962514,
    "ttft": 2038279.1954638588,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1787,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.829856901252487,
    "arrivals": 320386,
    "finished_requests": 64130,
    "scheduler_time": 87.27080385878389
}
#Debug simulation 
Total elapsed time: 4.851193821989. Arrivals time: 0.22613931790692732 Scheduler time: 4.518927956523839 Scheduler overhead time: 0.02567764016566798 Adapter cache time: 0.042533234402071685 Engine time: 0.026168756478000432 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-32/adapters_320_slots_160_rate_0.8-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-32/adapters_320_slots_160_rate_0.8-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 66, 8640, 8640, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 8640, 270, 8640, 8640, 66, 8640, 270, 270, 8640, 8640, 270, 66, 66, 270, 8640, 8640, 270, 270, 66, 66, 270, 8640, 8640, 66, 8640, 270, 66, 270, 8640, 66, 270, 8640, 8640, 270, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 270, 270, 270, 66, 270, 66, 8640, 66, 8640, 270, 8640, 8640, 66, 8640, 66, 8640, 270, 66, 66, 270, 270, 8640, 270, 8640, 8640, 8640, 66, 270, 270, 66, 8640, 270, 8640, 8640, 270, 66, 270, 270, 270, 66, 8640, 270, 8640, 66, 8640, 66, 66, 270, 8640, 8640, 270, 66, 270, 66, 270, 8640, 8640, 270, 66, 270, 66, 8640, 66, 66, 66, 66, 8640, 270, 270, 8640, 270, 270, 66, 270, 8640, 270, 66, 66, 270, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 270, 8640, 270, 270, 270, 66, 8640, 66, 8640, 270, 66, 270, 66, 66, 270, 66, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 66, 66, 8640, 270, 8640, 270, 8640, 270, 66, 270, 66, 66, 66, 8640, 8640, 270, 270, 66, 66, 270, 66, 8640, 66, 66, 270, 66, 8640, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 66, 270, 8640, 270, 270, 8640, 270, 66, 270, 66, 8640, 270, 270, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 270, 66, 270, 66, 270, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 270, 270, 8640, 66, 8640, 66, 66, 66, 8640, 270, 8640, 8640, 66, 270, 270, 270, 66, 270, 66, 270, 270, 8640, 66, 66, 270, 66, 270, 270, 66, 8640, 8640, 8640, 66, 270, 270, 270, 270, 66, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 270, 270, 270, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 270, 8640, 270, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 960366 . Total input tokens: 214114371 . Total output tokens: 192008310
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.425832909008022,
    "estimated_duration": 3600.0452865095945,
    "input_throughput": 4126.668921546748,
    "output_throughput": 3633.8156769920774,
    "total_throughput": 7760.484598538826,
    "itl": 139.609416480659,
    "ttft": 2090448.880585116,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1676,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.476294051948877,
    "arrivals": 320386,
    "finished_requests": 59969,
    "scheduler_time": 101.24403280609606
}
#Debug simulation 
Total elapsed time: 4.425931984034833. Arrivals time: 0.21423351840348914 Scheduler time: 4.061929569463246 Scheduler overhead time: 0.03784240724053234 Adapter cache time: 0.05549338925629854 Engine time: 0.03866165765793994 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-16/adapters_320_slots_160_rate_0.8-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-16/adapters_320_slots_160_rate_0.8-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 66, 8640, 8640, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 8640, 270, 8640, 8640, 66, 8640, 270, 270, 8640, 8640, 270, 66, 66, 270, 8640, 8640, 270, 270, 66, 66, 270, 8640, 8640, 66, 8640, 270, 66, 270, 8640, 66, 270, 8640, 8640, 270, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 270, 270, 270, 66, 270, 66, 8640, 66, 8640, 270, 8640, 8640, 66, 8640, 66, 8640, 270, 66, 66, 270, 270, 8640, 270, 8640, 8640, 8640, 66, 270, 270, 66, 8640, 270, 8640, 8640, 270, 66, 270, 270, 270, 66, 8640, 270, 8640, 66, 8640, 66, 66, 270, 8640, 8640, 270, 66, 270, 66, 270, 8640, 8640, 270, 66, 270, 66, 8640, 66, 66, 66, 66, 8640, 270, 270, 8640, 270, 270, 66, 270, 8640, 270, 66, 66, 270, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 270, 8640, 270, 270, 270, 66, 8640, 66, 8640, 270, 66, 270, 66, 66, 270, 66, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 66, 66, 8640, 270, 8640, 270, 8640, 270, 66, 270, 66, 66, 66, 8640, 8640, 270, 270, 66, 66, 270, 66, 8640, 66, 66, 270, 66, 8640, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 66, 270, 8640, 270, 270, 8640, 270, 66, 270, 66, 8640, 270, 270, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 270, 66, 270, 66, 270, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 270, 270, 8640, 66, 8640, 66, 66, 66, 8640, 270, 8640, 8640, 66, 270, 270, 270, 66, 270, 66, 270, 270, 8640, 66, 66, 270, 66, 270, 270, 66, 8640, 8640, 8640, 66, 270, 270, 270, 270, 66, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 270, 270, 270, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 270, 8640, 270, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 960366 . Total input tokens: 214114371 . Total output tokens: 192008310
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.605281107011251,
    "estimated_duration": 3600.029031576972,
    "input_throughput": 4411.643311954893,
    "output_throughput": 3874.6823644057486,
    "total_throughput": 8286.325676360642,
    "itl": 220.09496510258217,
    "ttft": 2038166.3186901077,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1786,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.57639792075366,
    "arrivals": 320386,
    "finished_requests": 64134,
    "scheduler_time": 87.27538230069746
}
#Debug simulation 
Total elapsed time: 4.605423181026708. Arrivals time: 0.225209605821874 Scheduler time: 4.27434038760839 Scheduler overhead time: 0.025786413927562535 Adapter cache time: 0.042118857498280704 Engine time: 0.02616222359938547 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-32/adapters_320_slots_160_rate_0.8-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-32/adapters_320_slots_160_rate_0.8-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 66, 8640, 8640, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 8640, 270, 8640, 8640, 66, 8640, 270, 270, 8640, 8640, 270, 66, 66, 270, 8640, 8640, 270, 270, 66, 66, 270, 8640, 8640, 66, 8640, 270, 66, 270, 8640, 66, 270, 8640, 8640, 270, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 270, 270, 270, 66, 270, 66, 8640, 66, 8640, 270, 8640, 8640, 66, 8640, 66, 8640, 270, 66, 66, 270, 270, 8640, 270, 8640, 8640, 8640, 66, 270, 270, 66, 8640, 270, 8640, 8640, 270, 66, 270, 270, 270, 66, 8640, 270, 8640, 66, 8640, 66, 66, 270, 8640, 8640, 270, 66, 270, 66, 270, 8640, 8640, 270, 66, 270, 66, 8640, 66, 66, 66, 66, 8640, 270, 270, 8640, 270, 270, 66, 270, 8640, 270, 66, 66, 270, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 270, 8640, 270, 270, 270, 66, 8640, 66, 8640, 270, 66, 270, 66, 66, 270, 66, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 66, 66, 8640, 270, 8640, 270, 8640, 270, 66, 270, 66, 66, 66, 8640, 8640, 270, 270, 66, 66, 270, 66, 8640, 66, 66, 270, 66, 8640, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 66, 270, 8640, 270, 270, 8640, 270, 66, 270, 66, 8640, 270, 270, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 270, 66, 270, 66, 270, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 270, 270, 8640, 66, 8640, 66, 66, 66, 8640, 270, 8640, 8640, 66, 270, 270, 270, 66, 270, 66, 270, 270, 8640, 66, 66, 270, 66, 270, 270, 66, 8640, 8640, 8640, 66, 270, 270, 270, 270, 66, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 270, 270, 270, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 270, 8640, 270, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 960366 . Total input tokens: 214114371 . Total output tokens: 192008310
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.487196150992531,
    "estimated_duration": 3600.0023911371063,
    "input_throughput": 4126.740870110216,
    "output_throughput": 3633.9167530018917,
    "total_throughput": 7760.657623112108,
    "itl": 139.61680961224621,
    "ttft": 2090379.3422598187,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1676,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.547470695059675,
    "arrivals": 320386,
    "finished_requests": 59969,
    "scheduler_time": 101.24024954528711
}
#Debug simulation 
Total elapsed time: 4.487288092030212. Arrivals time: 0.21891522977966815 Scheduler time: 4.119415724242572 Scheduler overhead time: 0.038061225903220475 Adapter cache time: 0.05435400520218536 Engine time: 0.03866985288914293 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-16/adapters_320_slots_160_rate_0.8-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-16/adapters_320_slots_160_rate_0.8-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 66, 8640, 8640, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 8640, 270, 8640, 8640, 66, 8640, 270, 270, 8640, 8640, 270, 66, 66, 270, 8640, 8640, 270, 270, 66, 66, 270, 8640, 8640, 66, 8640, 270, 66, 270, 8640, 66, 270, 8640, 8640, 270, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 270, 270, 270, 66, 270, 66, 8640, 66, 8640, 270, 8640, 8640, 66, 8640, 66, 8640, 270, 66, 66, 270, 270, 8640, 270, 8640, 8640, 8640, 66, 270, 270, 66, 8640, 270, 8640, 8640, 270, 66, 270, 270, 270, 66, 8640, 270, 8640, 66, 8640, 66, 66, 270, 8640, 8640, 270, 66, 270, 66, 270, 8640, 8640, 270, 66, 270, 66, 8640, 66, 66, 66, 66, 8640, 270, 270, 8640, 270, 270, 66, 270, 8640, 270, 66, 66, 270, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 270, 8640, 270, 270, 270, 66, 8640, 66, 8640, 270, 66, 270, 66, 66, 270, 66, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 66, 66, 8640, 270, 8640, 270, 8640, 270, 66, 270, 66, 66, 66, 8640, 8640, 270, 270, 66, 66, 270, 66, 8640, 66, 66, 270, 66, 8640, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 66, 270, 8640, 270, 270, 8640, 270, 66, 270, 66, 8640, 270, 270, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 270, 66, 270, 66, 270, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 270, 270, 8640, 66, 8640, 66, 66, 66, 8640, 270, 8640, 8640, 66, 270, 270, 270, 66, 270, 66, 270, 270, 8640, 66, 66, 270, 66, 270, 270, 66, 8640, 8640, 8640, 66, 270, 270, 270, 270, 66, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 270, 270, 270, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 270, 8640, 270, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 960366 . Total input tokens: 214114371 . Total output tokens: 192008310
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.592971638950985,
    "estimated_duration": 3600.1932435795284,
    "input_throughput": 4412.078998350333,
    "output_throughput": 3875.3244773406013,
    "total_throughput": 8287.403475690933,
    "itl": 220.08159041060856,
    "ttft": 2038129.99365488,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1787,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.343219876990035,
    "arrivals": 320386,
    "finished_requests": 64144,
    "scheduler_time": 87.28464468623277
}
#Debug simulation 
Total elapsed time: 4.593100444006268. Arrivals time: 0.22599226312013343 Scheduler time: 4.261113909014966 Scheduler overhead time: 0.025707737950142473 Adapter cache time: 0.042127793247345835 Engine time: 0.026307872321922332 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-32/adapters_320_slots_160_rate_0.8-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-32/adapters_320_slots_160_rate_0.8-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 66, 8640, 8640, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 8640, 270, 8640, 8640, 66, 8640, 270, 270, 8640, 8640, 270, 66, 66, 270, 8640, 8640, 270, 270, 66, 66, 270, 8640, 8640, 66, 8640, 270, 66, 270, 8640, 66, 270, 8640, 8640, 270, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 270, 270, 270, 66, 270, 66, 8640, 66, 8640, 270, 8640, 8640, 66, 8640, 66, 8640, 270, 66, 66, 270, 270, 8640, 270, 8640, 8640, 8640, 66, 270, 270, 66, 8640, 270, 8640, 8640, 270, 66, 270, 270, 270, 66, 8640, 270, 8640, 66, 8640, 66, 66, 270, 8640, 8640, 270, 66, 270, 66, 270, 8640, 8640, 270, 66, 270, 66, 8640, 66, 66, 66, 66, 8640, 270, 270, 8640, 270, 270, 66, 270, 8640, 270, 66, 66, 270, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 270, 8640, 270, 270, 270, 66, 8640, 66, 8640, 270, 66, 270, 66, 66, 270, 66, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 66, 66, 8640, 270, 8640, 270, 8640, 270, 66, 270, 66, 66, 66, 8640, 8640, 270, 270, 66, 66, 270, 66, 8640, 66, 66, 270, 66, 8640, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 66, 270, 8640, 270, 270, 8640, 270, 66, 270, 66, 8640, 270, 270, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 270, 66, 270, 66, 270, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 270, 270, 8640, 66, 8640, 66, 66, 66, 8640, 270, 8640, 8640, 66, 270, 270, 270, 66, 270, 66, 270, 270, 8640, 66, 66, 270, 66, 270, 270, 66, 8640, 8640, 8640, 66, 270, 270, 270, 270, 66, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 270, 270, 270, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 270, 8640, 270, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 960366 . Total input tokens: 214114371 . Total output tokens: 192008310
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.459323160001077,
    "estimated_duration": 3600.059292588311,
    "input_throughput": 4126.5848122515545,
    "output_throughput": 3633.736818427443,
    "total_throughput": 7760.321630678997,
    "itl": 139.621593796409,
    "ttft": 2090427.7646197833,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1676,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.616258016228576,
    "arrivals": 320386,
    "finished_requests": 59968,
    "scheduler_time": 101.2398166972913
}
#Debug simulation 
Total elapsed time: 4.459416561992839. Arrivals time: 0.21043253946118057 Scheduler time: 4.10056259582052 Scheduler overhead time: 0.03811411326751113 Adapter cache time: 0.053939271718263626 Engine time: 0.0386745358700864 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-8/adapters_320_slots_160_rate_0.8-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-8/adapters_320_slots_160_rate_0.8-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 33, 8640, 8640, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 8640, 270, 8640, 8640, 33, 8640, 270, 270, 8640, 8640, 270, 33, 33, 270, 8640, 8640, 270, 270, 33, 33, 270, 8640, 8640, 33, 8640, 270, 33, 270, 8640, 33, 270, 8640, 8640, 270, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 270, 270, 270, 33, 270, 33, 8640, 33, 8640, 270, 8640, 8640, 33, 8640, 33, 8640, 270, 33, 33, 270, 270, 8640, 270, 8640, 8640, 8640, 33, 270, 270, 33, 8640, 270, 8640, 8640, 270, 33, 270, 270, 270, 33, 8640, 270, 8640, 33, 8640, 33, 33, 270, 8640, 8640, 270, 33, 270, 33, 270, 8640, 8640, 270, 33, 270, 33, 8640, 33, 33, 33, 33, 8640, 270, 270, 8640, 270, 270, 33, 270, 8640, 270, 33, 33, 270, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 270, 8640, 270, 270, 270, 33, 8640, 33, 8640, 270, 33, 270, 33, 33, 270, 33, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 33, 33, 8640, 270, 8640, 270, 8640, 270, 33, 270, 33, 33, 33, 8640, 8640, 270, 270, 33, 33, 270, 33, 8640, 33, 33, 270, 33, 8640, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 33, 270, 8640, 270, 270, 8640, 270, 33, 270, 33, 8640, 270, 270, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 270, 33, 270, 33, 270, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 270, 270, 8640, 33, 8640, 33, 33, 33, 8640, 270, 8640, 8640, 33, 270, 270, 270, 33, 270, 33, 270, 270, 8640, 33, 33, 270, 33, 270, 270, 33, 8640, 8640, 8640, 33, 270, 270, 270, 270, 33, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 270, 270, 270, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 270, 8640, 270, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 956868 . Total input tokens: 213353240 . Total output tokens: 191310097
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.677912417973857,
    "estimated_duration": 3600.0835024136613,
    "input_throughput": 4476.000623095672,
    "output_throughput": 3947.6328786462177,
    "total_throughput": 8423.633501741891,
    "itl": 217.17293284791984,
    "ttft": 2031495.639579137,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1490,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.5601267384599256,
    "arrivals": 319202,
    "finished_requests": 64905,
    "scheduler_time": 88.84561936517483
}
#Debug simulation 
Total elapsed time: 4.6780098539893515. Arrivals time: 0.22637738328194246 Scheduler time: 4.349440218415111 Scheduler overhead time: 0.025936088524758816 Adapter cache time: 0.03770788089605048 Engine time: 0.026593616290483624 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-16/adapters_320_slots_160_rate_0.8-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-16/adapters_320_slots_160_rate_0.8-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 33, 8640, 8640, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 8640, 270, 8640, 8640, 33, 8640, 270, 270, 8640, 8640, 270, 33, 33, 270, 8640, 8640, 270, 270, 33, 33, 270, 8640, 8640, 33, 8640, 270, 33, 270, 8640, 33, 270, 8640, 8640, 270, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 270, 270, 270, 33, 270, 33, 8640, 33, 8640, 270, 8640, 8640, 33, 8640, 33, 8640, 270, 33, 33, 270, 270, 8640, 270, 8640, 8640, 8640, 33, 270, 270, 33, 8640, 270, 8640, 8640, 270, 33, 270, 270, 270, 33, 8640, 270, 8640, 33, 8640, 33, 33, 270, 8640, 8640, 270, 33, 270, 33, 270, 8640, 8640, 270, 33, 270, 33, 8640, 33, 33, 33, 33, 8640, 270, 270, 8640, 270, 270, 33, 270, 8640, 270, 33, 33, 270, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 270, 8640, 270, 270, 270, 33, 8640, 33, 8640, 270, 33, 270, 33, 33, 270, 33, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 33, 33, 8640, 270, 8640, 270, 8640, 270, 33, 270, 33, 33, 33, 8640, 8640, 270, 270, 33, 33, 270, 33, 8640, 33, 33, 270, 33, 8640, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 33, 270, 8640, 270, 270, 8640, 270, 33, 270, 33, 8640, 270, 270, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 270, 33, 270, 33, 270, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 270, 270, 8640, 33, 8640, 33, 33, 33, 8640, 270, 8640, 8640, 33, 270, 270, 270, 33, 270, 33, 270, 270, 8640, 33, 33, 270, 33, 270, 270, 33, 8640, 8640, 8640, 33, 270, 270, 270, 270, 33, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 270, 270, 270, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 270, 8640, 270, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 956868 . Total input tokens: 213353240 . Total output tokens: 191310097
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.721786941983737,
    "estimated_duration": 3600.2089050072723,
    "input_throughput": 4475.66611414941,
    "output_throughput": 3947.3914917088105,
    "total_throughput": 8423.057605858221,
    "itl": 217.18933023970922,
    "ttft": 2031577.9817234324,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1491,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.872480642597584,
    "arrivals": 319202,
    "finished_requests": 64903,
    "scheduler_time": 88.84259098668136
}
#Debug simulation 
Total elapsed time: 4.721894489019178. Arrivals time: 0.23204718524357304 Scheduler time: 4.387080981628969 Scheduler overhead time: 0.02618332178099081 Adapter cache time: 0.03774523769970983 Engine time: 0.026746192073915154 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-32/adapters_320_slots_160_rate_0.8-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-32/adapters_320_slots_160_rate_0.8-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 33, 8640, 8640, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 8640, 270, 8640, 8640, 33, 8640, 270, 270, 8640, 8640, 270, 33, 33, 270, 8640, 8640, 270, 270, 33, 33, 270, 8640, 8640, 33, 8640, 270, 33, 270, 8640, 33, 270, 8640, 8640, 270, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 270, 270, 270, 33, 270, 33, 8640, 33, 8640, 270, 8640, 8640, 33, 8640, 33, 8640, 270, 33, 33, 270, 270, 8640, 270, 8640, 8640, 8640, 33, 270, 270, 33, 8640, 270, 8640, 8640, 270, 33, 270, 270, 270, 33, 8640, 270, 8640, 33, 8640, 33, 33, 270, 8640, 8640, 270, 33, 270, 33, 270, 8640, 8640, 270, 33, 270, 33, 8640, 33, 33, 33, 33, 8640, 270, 270, 8640, 270, 270, 33, 270, 8640, 270, 33, 33, 270, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 270, 8640, 270, 270, 270, 33, 8640, 33, 8640, 270, 33, 270, 33, 33, 270, 33, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 33, 33, 8640, 270, 8640, 270, 8640, 270, 33, 270, 33, 33, 33, 8640, 8640, 270, 270, 33, 33, 270, 33, 8640, 33, 33, 270, 33, 8640, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 33, 270, 8640, 270, 270, 8640, 270, 33, 270, 33, 8640, 270, 270, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 270, 33, 270, 33, 270, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 270, 270, 8640, 33, 8640, 33, 33, 33, 8640, 270, 8640, 8640, 33, 270, 270, 270, 33, 270, 33, 270, 270, 8640, 33, 33, 270, 33, 270, 270, 33, 8640, 8640, 8640, 33, 270, 270, 270, 270, 33, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 270, 270, 270, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 270, 8640, 270, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 956868 . Total input tokens: 213353240 . Total output tokens: 191310097
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.46053501899587,
    "estimated_duration": 3600.0909588436302,
    "input_throughput": 4145.225543077227,
    "output_throughput": 3673.192747398685,
    "total_throughput": 7818.418290475911,
    "itl": 138.1457834817289,
    "ttft": 2087279.9656269944,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1403,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.5917910546063805,
    "arrivals": 319202,
    "finished_requests": 60124,
    "scheduler_time": 102.52710571976465
}
#Debug simulation 
Total elapsed time: 4.460651772969868. Arrivals time: 0.21168971934821457 Scheduler time: 4.101371031429153 Scheduler overhead time: 0.03843411593697965 Adapter cache time: 0.052235079172533005 Engine time: 0.039065216202288866 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-16-16/adapters_320_slots_160_rate_0.8-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-16-16/adapters_320_slots_160_rate_0.8-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 33, 8640, 8640, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 8640, 270, 8640, 8640, 33, 8640, 270, 270, 8640, 8640, 270, 33, 33, 270, 8640, 8640, 270, 270, 33, 33, 270, 8640, 8640, 33, 8640, 270, 33, 270, 8640, 33, 270, 8640, 8640, 270, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 270, 270, 270, 33, 270, 33, 8640, 33, 8640, 270, 8640, 8640, 33, 8640, 33, 8640, 270, 33, 33, 270, 270, 8640, 270, 8640, 8640, 8640, 33, 270, 270, 33, 8640, 270, 8640, 8640, 270, 33, 270, 270, 270, 33, 8640, 270, 8640, 33, 8640, 33, 33, 270, 8640, 8640, 270, 33, 270, 33, 270, 8640, 8640, 270, 33, 270, 33, 8640, 33, 33, 33, 33, 8640, 270, 270, 8640, 270, 270, 33, 270, 8640, 270, 33, 33, 270, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 270, 8640, 270, 270, 270, 33, 8640, 33, 8640, 270, 33, 270, 33, 33, 270, 33, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 33, 33, 8640, 270, 8640, 270, 8640, 270, 33, 270, 33, 33, 33, 8640, 8640, 270, 270, 33, 33, 270, 33, 8640, 33, 33, 270, 33, 8640, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 33, 270, 8640, 270, 270, 8640, 270, 33, 270, 33, 8640, 270, 270, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 270, 33, 270, 33, 270, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 270, 270, 8640, 33, 8640, 33, 33, 33, 8640, 270, 8640, 8640, 33, 270, 270, 270, 33, 270, 33, 270, 270, 8640, 33, 33, 270, 33, 270, 270, 33, 8640, 8640, 8640, 33, 270, 270, 270, 270, 33, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 270, 270, 270, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 270, 8640, 270, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 956868 . Total input tokens: 213353240 . Total output tokens: 191310097
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.652477829018608,
    "estimated_duration": 3600.172618531127,
    "input_throughput": 4475.889827353477,
    "output_throughput": 3947.5351617441133,
    "total_throughput": 8423.42498909759,
    "itl": 217.1761764435711,
    "ttft": 2031524.5795788132,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1490,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.656203836076805,
    "arrivals": 319202,
    "finished_requests": 64905,
    "scheduler_time": 88.84602065535785
}
#Debug simulation 
Total elapsed time: 4.652571904996876. Arrivals time: 0.2289942094939761 Scheduler time: 4.321129207964987 Scheduler overhead time: 0.026022398320492357 Adapter cache time: 0.0378658773843199 Engine time: 0.026534717355389148 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-16-32/adapters_320_slots_160_rate_0.8-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-16-32/adapters_320_slots_160_rate_0.8-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 33, 8640, 8640, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 8640, 270, 8640, 8640, 33, 8640, 270, 270, 8640, 8640, 270, 33, 33, 270, 8640, 8640, 270, 270, 33, 33, 270, 8640, 8640, 33, 8640, 270, 33, 270, 8640, 33, 270, 8640, 8640, 270, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 270, 270, 270, 33, 270, 33, 8640, 33, 8640, 270, 8640, 8640, 33, 8640, 33, 8640, 270, 33, 33, 270, 270, 8640, 270, 8640, 8640, 8640, 33, 270, 270, 33, 8640, 270, 8640, 8640, 270, 33, 270, 270, 270, 33, 8640, 270, 8640, 33, 8640, 33, 33, 270, 8640, 8640, 270, 33, 270, 33, 270, 8640, 8640, 270, 33, 270, 33, 8640, 33, 33, 33, 33, 8640, 270, 270, 8640, 270, 270, 33, 270, 8640, 270, 33, 33, 270, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 270, 8640, 270, 270, 270, 33, 8640, 33, 8640, 270, 33, 270, 33, 33, 270, 33, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 33, 33, 8640, 270, 8640, 270, 8640, 270, 33, 270, 33, 33, 33, 8640, 8640, 270, 270, 33, 33, 270, 33, 8640, 33, 33, 270, 33, 8640, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 33, 270, 8640, 270, 270, 8640, 270, 33, 270, 33, 8640, 270, 270, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 270, 33, 270, 33, 270, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 270, 270, 8640, 33, 8640, 33, 33, 33, 8640, 270, 8640, 8640, 33, 270, 270, 270, 33, 270, 33, 270, 270, 8640, 33, 33, 270, 33, 270, 270, 33, 8640, 8640, 8640, 33, 270, 270, 270, 270, 33, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 270, 270, 270, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 270, 8640, 270, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 956868 . Total input tokens: 213353240 . Total output tokens: 191310097
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.503489595954306,
    "estimated_duration": 3600.0731113921806,
    "input_throughput": 4146.402458539921,
    "output_throughput": 3674.483709272353,
    "total_throughput": 7820.886167812274,
    "itl": 138.2959366539599,
    "ttft": 2087019.3184851431,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1400,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.643519618492548,
    "arrivals": 319202,
    "finished_requests": 60138,
    "scheduler_time": 102.4847337650886
}
#Debug simulation 
Total elapsed time: 4.5035832559806295. Arrivals time: 0.22935156582389027 Scheduler time: 4.126340504328255 Scheduler overhead time: 0.03825778799364343 Adapter cache time: 0.05254650017013773 Engine time: 0.03921746980631724 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_16-16-16/adapters_320_slots_160_rate_0.8-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_16-16-16/adapters_320_slots_160_rate_0.8-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 33, 8640, 8640, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 8640, 270, 8640, 8640, 33, 8640, 270, 270, 8640, 8640, 270, 33, 33, 270, 8640, 8640, 270, 270, 33, 33, 270, 8640, 8640, 33, 8640, 270, 33, 270, 8640, 33, 270, 8640, 8640, 270, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 270, 270, 270, 33, 270, 33, 8640, 33, 8640, 270, 8640, 8640, 33, 8640, 33, 8640, 270, 33, 33, 270, 270, 8640, 270, 8640, 8640, 8640, 33, 270, 270, 33, 8640, 270, 8640, 8640, 270, 33, 270, 270, 270, 33, 8640, 270, 8640, 33, 8640, 33, 33, 270, 8640, 8640, 270, 33, 270, 33, 270, 8640, 8640, 270, 33, 270, 33, 8640, 33, 33, 33, 33, 8640, 270, 270, 8640, 270, 270, 33, 270, 8640, 270, 33, 33, 270, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 270, 8640, 270, 270, 270, 33, 8640, 33, 8640, 270, 33, 270, 33, 33, 270, 33, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 33, 33, 8640, 270, 8640, 270, 8640, 270, 33, 270, 33, 33, 33, 8640, 8640, 270, 270, 33, 33, 270, 33, 8640, 33, 33, 270, 33, 8640, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 33, 270, 8640, 270, 270, 8640, 270, 33, 270, 33, 8640, 270, 270, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 270, 33, 270, 33, 270, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 270, 270, 8640, 33, 8640, 33, 33, 33, 8640, 270, 8640, 8640, 33, 270, 270, 270, 33, 270, 33, 270, 270, 8640, 33, 33, 270, 33, 270, 270, 33, 8640, 8640, 8640, 33, 270, 270, 270, 270, 33, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 270, 270, 270, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 270, 8640, 270, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 956868 . Total input tokens: 213353240 . Total output tokens: 191310097
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.6720554630155675,
    "estimated_duration": 3600.0950224185704,
    "input_throughput": 4476.1851839049605,
    "output_throughput": 3947.7719092125617,
    "total_throughput": 8423.957093117522,
    "itl": 217.16503565784507,
    "ttft": 2031437.087683172,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1491,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.458164989699022,
    "arrivals": 319202,
    "finished_requests": 64909,
    "scheduler_time": 88.84875327244956
}
#Debug simulation 
Total elapsed time: 4.672221234010067. Arrivals time: 0.22990170994307846 Scheduler time: 4.339885564695578 Scheduler overhead time: 0.02601730066817254 Adapter cache time: 0.03804999322164804 Engine time: 0.026368261605966836 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_16-16-32/adapters_320_slots_160_rate_0.8-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_16-16-32/adapters_320_slots_160_rate_0.8-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [106 107 107]
Adapter prompts. [270, 8640, 8640, 33, 8640, 8640, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 8640, 270, 8640, 8640, 33, 8640, 270, 270, 8640, 8640, 270, 33, 33, 270, 8640, 8640, 270, 270, 33, 33, 270, 8640, 8640, 33, 8640, 270, 33, 270, 8640, 33, 270, 8640, 8640, 270, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 270, 270, 270, 33, 270, 33, 8640, 33, 8640, 270, 8640, 8640, 33, 8640, 33, 8640, 270, 33, 33, 270, 270, 8640, 270, 8640, 8640, 8640, 33, 270, 270, 33, 8640, 270, 8640, 8640, 270, 33, 270, 270, 270, 33, 8640, 270, 8640, 33, 8640, 33, 33, 270, 8640, 8640, 270, 33, 270, 33, 270, 8640, 8640, 270, 33, 270, 33, 8640, 33, 33, 33, 33, 8640, 270, 270, 8640, 270, 270, 33, 270, 8640, 270, 33, 33, 270, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 270, 8640, 270, 270, 270, 33, 8640, 33, 8640, 270, 33, 270, 33, 33, 270, 33, 270, 8640, 8640, 8640, 8640, 270, 270, 8640, 8640, 8640, 270, 8640, 33, 33, 8640, 270, 8640, 270, 8640, 270, 33, 270, 33, 33, 33, 8640, 8640, 270, 270, 33, 33, 270, 33, 8640, 33, 33, 270, 33, 8640, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 33, 270, 8640, 270, 270, 8640, 270, 33, 270, 33, 8640, 270, 270, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 270, 33, 270, 33, 270, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 270, 270, 8640, 33, 8640, 33, 33, 33, 8640, 270, 8640, 8640, 33, 270, 270, 270, 33, 270, 33, 270, 270, 8640, 33, 33, 270, 33, 270, 270, 33, 8640, 8640, 8640, 33, 270, 270, 270, 270, 33, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 270, 270, 270, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 270, 8640, 270, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 956868 . Total input tokens: 213353240 . Total output tokens: 191310097
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.7570229090051726,
    "estimated_duration": 3600.0599153148332,
    "input_throughput": 4145.302953574572,
    "output_throughput": 3673.3802522960227,
    "total_throughput": 7818.683205870594,
    "itl": 138.1473117298968,
    "ttft": 2087297.8592599537,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1404,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.71526668697595,
    "arrivals": 319202,
    "finished_requests": 60124,
    "scheduler_time": 102.52551068411236
}
#Debug simulation 
Total elapsed time: 4.757086323981639. Arrivals time: 0.4675633776350878 Scheduler time: 4.1420841658255085 Scheduler overhead time: 0.03841014381032437 Adapter cache time: 0.05161262035835534 Engine time: 0.03931152808945626 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-8/adapters_320_slots_160_rate_0.8-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-8/adapters_320_slots_160_rate_0.8-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [106 107 107]
Adapter prompts. [135, 8640, 8640, 66, 8640, 8640, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 8640, 135, 8640, 8640, 66, 8640, 135, 135, 8640, 8640, 135, 66, 66, 135, 8640, 8640, 135, 135, 66, 66, 135, 8640, 8640, 66, 8640, 135, 66, 135, 8640, 66, 135, 8640, 8640, 135, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 135, 135, 135, 66, 135, 66, 8640, 66, 8640, 135, 8640, 8640, 66, 8640, 66, 8640, 135, 66, 66, 135, 135, 8640, 135, 8640, 8640, 8640, 66, 135, 135, 66, 8640, 135, 8640, 8640, 135, 66, 135, 135, 135, 66, 8640, 135, 8640, 66, 8640, 66, 66, 135, 8640, 8640, 135, 66, 135, 66, 135, 8640, 8640, 135, 66, 135, 66, 8640, 66, 66, 66, 66, 8640, 135, 135, 8640, 135, 135, 66, 135, 8640, 135, 66, 66, 135, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 135, 8640, 135, 135, 135, 66, 8640, 66, 8640, 135, 66, 135, 66, 66, 135, 66, 135, 8640, 8640, 8640, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 66, 66, 8640, 135, 8640, 135, 8640, 135, 66, 135, 66, 66, 66, 8640, 8640, 135, 135, 66, 66, 135, 66, 8640, 66, 66, 135, 66, 8640, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 66, 135, 8640, 135, 135, 8640, 135, 66, 135, 66, 8640, 135, 135, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 135, 66, 135, 66, 135, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 135, 135, 8640, 66, 8640, 66, 66, 66, 8640, 135, 8640, 8640, 66, 135, 135, 135, 66, 135, 66, 135, 135, 8640, 66, 66, 135, 66, 135, 135, 66, 8640, 8640, 8640, 66, 135, 135, 135, 135, 66, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 135, 135, 135, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 135, 8640, 135, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 945921 . Total input tokens: 210892782 . Total output tokens: 189144371
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.825516122975387,
    "estimated_duration": 3600.126123285432,
    "input_throughput": 4629.0394917585845,
    "output_throughput": 4091.6363748271147,
    "total_throughput": 8720.6758665857,
    "itl": 209.882159721004,
    "ttft": 1997606.3328263932,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1266,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.874577483818965,
    "arrivals": 315552,
    "finished_requests": 67496,
    "scheduler_time": 91.96138526639474
}
#Debug simulation 
Total elapsed time: 4.82561415998498. Arrivals time: 0.23561325867194682 Scheduler time: 4.490636640170123 Scheduler overhead time: 0.02676056942436844 Adapter cache time: 0.032888806075789034 Engine time: 0.027326750627253205 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-16/adapters_320_slots_160_rate_0.8-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-16/adapters_320_slots_160_rate_0.8-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [106 107 107]
Adapter prompts. [135, 8640, 8640, 66, 8640, 8640, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 8640, 135, 8640, 8640, 66, 8640, 135, 135, 8640, 8640, 135, 66, 66, 135, 8640, 8640, 135, 135, 66, 66, 135, 8640, 8640, 66, 8640, 135, 66, 135, 8640, 66, 135, 8640, 8640, 135, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 135, 135, 135, 66, 135, 66, 8640, 66, 8640, 135, 8640, 8640, 66, 8640, 66, 8640, 135, 66, 66, 135, 135, 8640, 135, 8640, 8640, 8640, 66, 135, 135, 66, 8640, 135, 8640, 8640, 135, 66, 135, 135, 135, 66, 8640, 135, 8640, 66, 8640, 66, 66, 135, 8640, 8640, 135, 66, 135, 66, 135, 8640, 8640, 135, 66, 135, 66, 8640, 66, 66, 66, 66, 8640, 135, 135, 8640, 135, 135, 66, 135, 8640, 135, 66, 66, 135, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 135, 8640, 135, 135, 135, 66, 8640, 66, 8640, 135, 66, 135, 66, 66, 135, 66, 135, 8640, 8640, 8640, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 66, 66, 8640, 135, 8640, 135, 8640, 135, 66, 135, 66, 66, 66, 8640, 8640, 135, 135, 66, 66, 135, 66, 8640, 66, 66, 135, 66, 8640, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 66, 135, 8640, 135, 135, 8640, 135, 66, 135, 66, 8640, 135, 135, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 135, 66, 135, 66, 135, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 135, 135, 8640, 66, 8640, 66, 66, 66, 8640, 135, 8640, 8640, 66, 135, 135, 135, 66, 135, 66, 135, 135, 8640, 66, 66, 135, 66, 135, 135, 66, 8640, 8640, 8640, 66, 135, 135, 135, 135, 66, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 135, 135, 135, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 135, 8640, 135, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 945921 . Total input tokens: 210892782 . Total output tokens: 189144371
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.803156224021222,
    "estimated_duration": 3600.128348428855,
    "input_throughput": 4628.455818046591,
    "output_throughput": 4091.1369191678314,
    "total_throughput": 8719.592737214423,
    "itl": 209.89582323975452,
    "ttft": 1997737.5181767435,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1266,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.130258122109801,
    "arrivals": 315552,
    "finished_requests": 67488,
    "scheduler_time": 91.95558787343181
}
#Debug simulation 
Total elapsed time: 4.8032509940094315. Arrivals time: 0.24059741711243987 Scheduler time: 4.464259997475892 Scheduler overhead time: 0.026917504088487476 Adapter cache time: 0.031787047744728625 Engine time: 0.027345219801645726 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-32/adapters_320_slots_160_rate_0.8-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-32/adapters_320_slots_160_rate_0.8-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [106 107 107]
Adapter prompts. [135, 8640, 8640, 66, 8640, 8640, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 8640, 135, 8640, 8640, 66, 8640, 135, 135, 8640, 8640, 135, 66, 66, 135, 8640, 8640, 135, 135, 66, 66, 135, 8640, 8640, 66, 8640, 135, 66, 135, 8640, 66, 135, 8640, 8640, 135, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 135, 135, 135, 66, 135, 66, 8640, 66, 8640, 135, 8640, 8640, 66, 8640, 66, 8640, 135, 66, 66, 135, 135, 8640, 135, 8640, 8640, 8640, 66, 135, 135, 66, 8640, 135, 8640, 8640, 135, 66, 135, 135, 135, 66, 8640, 135, 8640, 66, 8640, 66, 66, 135, 8640, 8640, 135, 66, 135, 66, 135, 8640, 8640, 135, 66, 135, 66, 8640, 66, 66, 66, 66, 8640, 135, 135, 8640, 135, 135, 66, 135, 8640, 135, 66, 66, 135, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 135, 8640, 135, 135, 135, 66, 8640, 66, 8640, 135, 66, 135, 66, 66, 135, 66, 135, 8640, 8640, 8640, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 66, 66, 8640, 135, 8640, 135, 8640, 135, 66, 135, 66, 66, 66, 8640, 8640, 135, 135, 66, 66, 135, 66, 8640, 66, 66, 135, 66, 8640, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 66, 135, 8640, 135, 135, 8640, 135, 66, 135, 66, 8640, 135, 135, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 135, 66, 135, 66, 135, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 135, 135, 8640, 66, 8640, 66, 66, 66, 8640, 135, 8640, 8640, 66, 135, 135, 135, 66, 135, 66, 135, 135, 8640, 66, 66, 135, 66, 135, 135, 66, 8640, 8640, 8640, 66, 135, 135, 135, 135, 66, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 135, 135, 135, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 135, 8640, 135, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 945921 . Total input tokens: 210892782 . Total output tokens: 189144371
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.599062618974131,
    "estimated_duration": 3600.1134953523465,
    "input_throughput": 4248.411618062915,
    "output_throughput": 3772.022748041431,
    "total_throughput": 8020.434366104347,
    "itl": 135.1563683119535,
    "ttft": 2061835.8734368999,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1166,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.809098043441717,
    "arrivals": 315552,
    "finished_requests": 61975,
    "scheduler_time": 104.83655539935741
}
#Debug simulation 
Total elapsed time: 4.599156916025095. Arrivals time: 0.2175917510758154 Scheduler time: 4.241087592905387 Scheduler overhead time: 0.039125167299062014 Adapter cache time: 0.04250370297813788 Engine time: 0.040346932772081345 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-16-16/adapters_320_slots_160_rate_0.8-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-16-16/adapters_320_slots_160_rate_0.8-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [106 107 107]
Adapter prompts. [135, 8640, 8640, 66, 8640, 8640, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 8640, 135, 8640, 8640, 66, 8640, 135, 135, 8640, 8640, 135, 66, 66, 135, 8640, 8640, 135, 135, 66, 66, 135, 8640, 8640, 66, 8640, 135, 66, 135, 8640, 66, 135, 8640, 8640, 135, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 135, 135, 135, 66, 135, 66, 8640, 66, 8640, 135, 8640, 8640, 66, 8640, 66, 8640, 135, 66, 66, 135, 135, 8640, 135, 8640, 8640, 8640, 66, 135, 135, 66, 8640, 135, 8640, 8640, 135, 66, 135, 135, 135, 66, 8640, 135, 8640, 66, 8640, 66, 66, 135, 8640, 8640, 135, 66, 135, 66, 135, 8640, 8640, 135, 66, 135, 66, 8640, 66, 66, 66, 66, 8640, 135, 135, 8640, 135, 135, 66, 135, 8640, 135, 66, 66, 135, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 135, 8640, 135, 135, 135, 66, 8640, 66, 8640, 135, 66, 135, 66, 66, 135, 66, 135, 8640, 8640, 8640, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 66, 66, 8640, 135, 8640, 135, 8640, 135, 66, 135, 66, 66, 66, 8640, 8640, 135, 135, 66, 66, 135, 66, 8640, 66, 66, 135, 66, 8640, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 66, 135, 8640, 135, 135, 8640, 135, 66, 135, 66, 8640, 135, 135, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 135, 66, 135, 66, 135, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 135, 135, 8640, 66, 8640, 66, 66, 66, 8640, 135, 8640, 8640, 66, 135, 135, 135, 66, 135, 66, 135, 135, 8640, 66, 66, 135, 66, 135, 135, 66, 8640, 8640, 8640, 66, 135, 135, 135, 135, 66, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 135, 135, 135, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 135, 8640, 135, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 945921 . Total input tokens: 210892782 . Total output tokens: 189144371
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.885490118002053,
    "estimated_duration": 3600.0373943503414,
    "input_throughput": 4628.820252298283,
    "output_throughput": 4091.4322232083464,
    "total_throughput": 8720.25247550663,
    "itl": 209.88608193285904,
    "ttft": 1997641.5532783954,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1266,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9566051117726126,
    "arrivals": 315552,
    "finished_requests": 67492,
    "scheduler_time": 91.95781116340319
}
#Debug simulation 
Total elapsed time: 4.885592002014164. Arrivals time: 0.23785733856493607 Scheduler time: 4.548554524662904 Scheduler overhead time: 0.02708746981807053 Adapter cache time: 0.03191655268892646 Engine time: 0.027666730631608516 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-16-32/adapters_320_slots_160_rate_0.8-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-16-32/adapters_320_slots_160_rate_0.8-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [106 107 107]
Adapter prompts. [135, 8640, 8640, 66, 8640, 8640, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 8640, 135, 8640, 8640, 66, 8640, 135, 135, 8640, 8640, 135, 66, 66, 135, 8640, 8640, 135, 135, 66, 66, 135, 8640, 8640, 66, 8640, 135, 66, 135, 8640, 66, 135, 8640, 8640, 135, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 135, 135, 135, 66, 135, 66, 8640, 66, 8640, 135, 8640, 8640, 66, 8640, 66, 8640, 135, 66, 66, 135, 135, 8640, 135, 8640, 8640, 8640, 66, 135, 135, 66, 8640, 135, 8640, 8640, 135, 66, 135, 135, 135, 66, 8640, 135, 8640, 66, 8640, 66, 66, 135, 8640, 8640, 135, 66, 135, 66, 135, 8640, 8640, 135, 66, 135, 66, 8640, 66, 66, 66, 66, 8640, 135, 135, 8640, 135, 135, 66, 135, 8640, 135, 66, 66, 135, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 135, 8640, 135, 135, 135, 66, 8640, 66, 8640, 135, 66, 135, 66, 66, 135, 66, 135, 8640, 8640, 8640, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 66, 66, 8640, 135, 8640, 135, 8640, 135, 66, 135, 66, 66, 66, 8640, 8640, 135, 135, 66, 66, 135, 66, 8640, 66, 66, 135, 66, 8640, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 66, 135, 8640, 135, 135, 8640, 135, 66, 135, 66, 8640, 135, 135, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 135, 66, 135, 66, 135, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 135, 135, 8640, 66, 8640, 66, 66, 66, 8640, 135, 8640, 8640, 66, 135, 135, 135, 66, 135, 66, 135, 135, 8640, 66, 66, 135, 66, 135, 135, 66, 8640, 8640, 8640, 66, 135, 135, 135, 135, 66, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 135, 135, 135, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 135, 8640, 135, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 945921 . Total input tokens: 210892782 . Total output tokens: 189144371
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.551177659013774,
    "estimated_duration": 3600.112628726061,
    "input_throughput": 4248.324310179181,
    "output_throughput": 3771.5458932196575,
    "total_throughput": 8019.870203398838,
    "itl": 135.15774742022,
    "ttft": 2061863.125559945,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1166,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.858393527716399,
    "arrivals": 315552,
    "finished_requests": 61969,
    "scheduler_time": 104.83333490789855
}
#Debug simulation 
Total elapsed time: 4.55127628199989. Arrivals time: 0.21810681890929118 Scheduler time: 4.193830621486995 Scheduler overhead time: 0.039020090422127396 Adapter cache time: 0.041902438329998404 Engine time: 0.04015795583836734 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_16-16-16/adapters_320_slots_160_rate_0.8-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_16-16-16/adapters_320_slots_160_rate_0.8-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [106 107 107]
Adapter prompts. [135, 8640, 8640, 66, 8640, 8640, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 8640, 135, 8640, 8640, 66, 8640, 135, 135, 8640, 8640, 135, 66, 66, 135, 8640, 8640, 135, 135, 66, 66, 135, 8640, 8640, 66, 8640, 135, 66, 135, 8640, 66, 135, 8640, 8640, 135, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 135, 135, 135, 66, 135, 66, 8640, 66, 8640, 135, 8640, 8640, 66, 8640, 66, 8640, 135, 66, 66, 135, 135, 8640, 135, 8640, 8640, 8640, 66, 135, 135, 66, 8640, 135, 8640, 8640, 135, 66, 135, 135, 135, 66, 8640, 135, 8640, 66, 8640, 66, 66, 135, 8640, 8640, 135, 66, 135, 66, 135, 8640, 8640, 135, 66, 135, 66, 8640, 66, 66, 66, 66, 8640, 135, 135, 8640, 135, 135, 66, 135, 8640, 135, 66, 66, 135, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 135, 8640, 135, 135, 135, 66, 8640, 66, 8640, 135, 66, 135, 66, 66, 135, 66, 135, 8640, 8640, 8640, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 66, 66, 8640, 135, 8640, 135, 8640, 135, 66, 135, 66, 66, 66, 8640, 8640, 135, 135, 66, 66, 135, 66, 8640, 66, 66, 135, 66, 8640, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 66, 135, 8640, 135, 135, 8640, 135, 66, 135, 66, 8640, 135, 135, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 135, 66, 135, 66, 135, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 135, 135, 8640, 66, 8640, 66, 66, 66, 8640, 135, 8640, 8640, 66, 135, 135, 135, 66, 135, 66, 135, 135, 8640, 66, 66, 135, 66, 135, 135, 66, 8640, 8640, 8640, 66, 135, 135, 135, 135, 66, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 135, 135, 135, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 135, 8640, 135, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 945921 . Total input tokens: 210892782 . Total output tokens: 189144371
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.805563653004356,
    "estimated_duration": 3600.015827468823,
    "input_throughput": 4629.1465923129535,
    "output_throughput": 4091.5959001092933,
    "total_throughput": 8720.742492422247,
    "itl": 209.87639735295676,
    "ttft": 1997581.7716531558,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1267,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.788393723640959,
    "arrivals": 315552,
    "finished_requests": 67495,
    "scheduler_time": 91.96068532237777
}
#Debug simulation 
Total elapsed time: 4.805665221996605. Arrivals time: 0.23201161506585777 Scheduler time: 4.475386786973104 Scheduler overhead time: 0.026727285236120224 Adapter cache time: 0.03187239886028692 Engine time: 0.027436950360424817 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_16-16-32/adapters_320_slots_160_rate_0.8-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_16-16-32/adapters_320_slots_160_rate_0.8-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [106 107 107]
Adapter prompts. [135, 8640, 8640, 66, 8640, 8640, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 8640, 135, 8640, 8640, 66, 8640, 135, 135, 8640, 8640, 135, 66, 66, 135, 8640, 8640, 135, 135, 66, 66, 135, 8640, 8640, 66, 8640, 135, 66, 135, 8640, 66, 135, 8640, 8640, 135, 66, 66, 8640, 66, 66, 8640, 8640, 66, 66, 135, 135, 135, 66, 135, 66, 8640, 66, 8640, 135, 8640, 8640, 66, 8640, 66, 8640, 135, 66, 66, 135, 135, 8640, 135, 8640, 8640, 8640, 66, 135, 135, 66, 8640, 135, 8640, 8640, 135, 66, 135, 135, 135, 66, 8640, 135, 8640, 66, 8640, 66, 66, 135, 8640, 8640, 135, 66, 135, 66, 135, 8640, 8640, 135, 66, 135, 66, 8640, 66, 66, 66, 66, 8640, 135, 135, 8640, 135, 135, 66, 135, 8640, 135, 66, 66, 135, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 135, 8640, 135, 135, 135, 66, 8640, 66, 8640, 135, 66, 135, 66, 66, 135, 66, 135, 8640, 8640, 8640, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 66, 66, 8640, 135, 8640, 135, 8640, 135, 66, 135, 66, 66, 66, 8640, 8640, 135, 135, 66, 66, 135, 66, 8640, 66, 66, 135, 66, 8640, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 66, 135, 8640, 135, 135, 8640, 135, 66, 135, 66, 8640, 135, 135, 8640, 8640, 66, 66, 66, 8640, 8640, 66, 66, 8640, 135, 66, 135, 66, 135, 8640, 8640, 8640, 66, 8640, 8640, 8640, 8640, 66, 135, 135, 8640, 66, 8640, 66, 66, 66, 8640, 135, 8640, 8640, 66, 135, 135, 135, 66, 135, 66, 135, 135, 8640, 66, 66, 135, 66, 135, 135, 66, 8640, 8640, 8640, 66, 135, 135, 135, 135, 66, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 135, 135, 135, 66, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 8640, 135, 8640, 135, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 945921 . Total input tokens: 210892782 . Total output tokens: 189144371
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.595081400999334,
    "estimated_duration": 3600.1407576766683,
    "input_throughput": 4248.258618051955,
    "output_throughput": 3771.517258331445,
    "total_throughput": 8019.7758763834,
    "itl": 135.1590129873185,
    "ttft": 2061971.4144557493,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1166,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.906179966554103,
    "arrivals": 315552,
    "finished_requests": 61968,
    "scheduler_time": 104.83368108800147
}
#Debug simulation 
Total elapsed time: 4.595179574971553. Arrivals time: 0.21999030601000413 Scheduler time: 4.23638977057999 Scheduler overhead time: 0.03894062020117417 Adapter cache time: 0.04156075662467629 Engine time: 0.03993223822908476 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-8/adapters_320_slots_160_rate_0.8-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-8/adapters_320_slots_160_rate_0.8-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [106 107 107]
Adapter prompts. [135, 8640, 8640, 33, 8640, 8640, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 8640, 135, 8640, 8640, 33, 8640, 135, 135, 8640, 8640, 135, 33, 33, 135, 8640, 8640, 135, 135, 33, 33, 135, 8640, 8640, 33, 8640, 135, 33, 135, 8640, 33, 135, 8640, 8640, 135, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 135, 135, 135, 33, 135, 33, 8640, 33, 8640, 135, 8640, 8640, 33, 8640, 33, 8640, 135, 33, 33, 135, 135, 8640, 135, 8640, 8640, 8640, 33, 135, 135, 33, 8640, 135, 8640, 8640, 135, 33, 135, 135, 135, 33, 8640, 135, 8640, 33, 8640, 33, 33, 135, 8640, 8640, 135, 33, 135, 33, 135, 8640, 8640, 135, 33, 135, 33, 8640, 33, 33, 33, 33, 8640, 135, 135, 8640, 135, 135, 33, 135, 8640, 135, 33, 33, 135, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 135, 8640, 135, 135, 135, 33, 8640, 33, 8640, 135, 33, 135, 33, 33, 135, 33, 135, 8640, 8640, 8640, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 33, 33, 8640, 135, 8640, 135, 8640, 135, 33, 135, 33, 33, 33, 8640, 8640, 135, 135, 33, 33, 135, 33, 8640, 33, 33, 135, 33, 8640, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 33, 135, 8640, 135, 135, 8640, 135, 33, 135, 33, 8640, 135, 135, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 135, 33, 135, 33, 135, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 135, 135, 8640, 33, 8640, 33, 33, 33, 8640, 135, 8640, 8640, 33, 135, 135, 135, 33, 135, 33, 135, 135, 8640, 33, 33, 135, 33, 135, 135, 33, 8640, 8640, 8640, 33, 135, 135, 135, 135, 33, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 135, 135, 135, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 135, 8640, 135, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 942423 . Total input tokens: 210094551 . Total output tokens: 188466191
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.897409074008465,
    "estimated_duration": 3600.00435799956,
    "input_throughput": 4737.457042823415,
    "output_throughput": 4152.777472832667,
    "total_throughput": 8890.23451565608,
    "itl": 205.78192291330652,
    "ttft": 1982279.2832504606,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1014,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.103334572347884,
    "arrivals": 314288,
    "finished_requests": 68611,
    "scheduler_time": 93.4265896092296
}
#Debug simulation 
Total elapsed time: 4.897577855037525. Arrivals time: 0.23449869884643704 Scheduler time: 4.56723414955195 Scheduler overhead time: 0.02721762692090124 Adapter cache time: 0.028156135114841163 Engine time: 0.027751897869165987 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-16/adapters_320_slots_160_rate_0.8-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-16/adapters_320_slots_160_rate_0.8-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [106 107 107]
Adapter prompts. [135, 8640, 8640, 33, 8640, 8640, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 8640, 135, 8640, 8640, 33, 8640, 135, 135, 8640, 8640, 135, 33, 33, 135, 8640, 8640, 135, 135, 33, 33, 135, 8640, 8640, 33, 8640, 135, 33, 135, 8640, 33, 135, 8640, 8640, 135, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 135, 135, 135, 33, 135, 33, 8640, 33, 8640, 135, 8640, 8640, 33, 8640, 33, 8640, 135, 33, 33, 135, 135, 8640, 135, 8640, 8640, 8640, 33, 135, 135, 33, 8640, 135, 8640, 8640, 135, 33, 135, 135, 135, 33, 8640, 135, 8640, 33, 8640, 33, 33, 135, 8640, 8640, 135, 33, 135, 33, 135, 8640, 8640, 135, 33, 135, 33, 8640, 33, 33, 33, 33, 8640, 135, 135, 8640, 135, 135, 33, 135, 8640, 135, 33, 33, 135, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 135, 8640, 135, 135, 135, 33, 8640, 33, 8640, 135, 33, 135, 33, 33, 135, 33, 135, 8640, 8640, 8640, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 33, 33, 8640, 135, 8640, 135, 8640, 135, 33, 135, 33, 33, 33, 8640, 8640, 135, 135, 33, 33, 135, 33, 8640, 33, 33, 135, 33, 8640, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 33, 135, 8640, 135, 135, 8640, 135, 33, 135, 33, 8640, 135, 135, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 135, 33, 135, 33, 135, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 135, 135, 8640, 33, 8640, 33, 33, 33, 8640, 135, 8640, 8640, 33, 135, 135, 135, 33, 135, 33, 135, 135, 8640, 33, 33, 135, 33, 135, 135, 33, 8640, 8640, 8640, 33, 135, 135, 135, 135, 33, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 135, 135, 135, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 135, 8640, 135, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 942423 . Total input tokens: 210094551 . Total output tokens: 188466191
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.916625488025602,
    "estimated_duration": 3600.073966205472,
    "input_throughput": 4737.222945998392,
    "output_throughput": 4152.100523577647,
    "total_throughput": 8889.32346957604,
    "itl": 205.7923155884325,
    "ttft": 1982354.3632184314,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1014,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3105730062071297,
    "arrivals": 314288,
    "finished_requests": 68606,
    "scheduler_time": 93.42292596209658
}
#Debug simulation 
Total elapsed time: 4.9167256650398485. Arrivals time: 0.2348949903389439 Scheduler time: 4.5854470827034675 Scheduler overhead time: 0.02734335622517392 Adapter cache time: 0.02813352912198752 Engine time: 0.028084598889108747 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-32/adapters_320_slots_160_rate_0.8-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-32/adapters_320_slots_160_rate_0.8-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [106 107 107]
Adapter prompts. [135, 8640, 8640, 33, 8640, 8640, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 8640, 135, 8640, 8640, 33, 8640, 135, 135, 8640, 8640, 135, 33, 33, 135, 8640, 8640, 135, 135, 33, 33, 135, 8640, 8640, 33, 8640, 135, 33, 135, 8640, 33, 135, 8640, 8640, 135, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 135, 135, 135, 33, 135, 33, 8640, 33, 8640, 135, 8640, 8640, 33, 8640, 33, 8640, 135, 33, 33, 135, 135, 8640, 135, 8640, 8640, 8640, 33, 135, 135, 33, 8640, 135, 8640, 8640, 135, 33, 135, 135, 135, 33, 8640, 135, 8640, 33, 8640, 33, 33, 135, 8640, 8640, 135, 33, 135, 33, 135, 8640, 8640, 135, 33, 135, 33, 8640, 33, 33, 33, 33, 8640, 135, 135, 8640, 135, 135, 33, 135, 8640, 135, 33, 33, 135, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 135, 8640, 135, 135, 135, 33, 8640, 33, 8640, 135, 33, 135, 33, 33, 135, 33, 135, 8640, 8640, 8640, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 33, 33, 8640, 135, 8640, 135, 8640, 135, 33, 135, 33, 33, 33, 8640, 8640, 135, 135, 33, 33, 135, 33, 8640, 33, 33, 135, 33, 8640, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 33, 135, 8640, 135, 135, 8640, 135, 33, 135, 33, 8640, 135, 135, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 135, 33, 135, 33, 135, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 135, 135, 8640, 33, 8640, 33, 33, 33, 8640, 135, 8640, 8640, 33, 135, 135, 135, 33, 135, 33, 135, 135, 8640, 33, 33, 135, 33, 135, 135, 33, 8640, 8640, 8640, 33, 135, 135, 135, 135, 33, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 135, 135, 135, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 135, 8640, 135, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 942423 . Total input tokens: 210094551 . Total output tokens: 188466191
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.616212801018264,
    "estimated_duration": 3600.094958413837,
    "input_throughput": 4320.202988993531,
    "output_throughput": 3805.8823887347544,
    "total_throughput": 8126.0853777282855,
    "itl": 133.14722612041277,
    "ttft": 2052844.5207966997,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 911,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9787038903869445,
    "arrivals": 314288,
    "finished_requests": 62590,
    "scheduler_time": 106.10105571417486
}
#Debug simulation 
Total elapsed time: 4.616308527009096. Arrivals time: 0.21975632902467623 Scheduler time: 4.259014775278047 Scheduler overhead time: 0.039745850721374154 Adapter cache time: 0.03834377700695768 Engine time: 0.04071220592595637 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-16/adapters_320_slots_160_rate_0.8-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-16/adapters_320_slots_160_rate_0.8-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [106 107 107]
Adapter prompts. [135, 8640, 8640, 33, 8640, 8640, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 8640, 135, 8640, 8640, 33, 8640, 135, 135, 8640, 8640, 135, 33, 33, 135, 8640, 8640, 135, 135, 33, 33, 135, 8640, 8640, 33, 8640, 135, 33, 135, 8640, 33, 135, 8640, 8640, 135, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 135, 135, 135, 33, 135, 33, 8640, 33, 8640, 135, 8640, 8640, 33, 8640, 33, 8640, 135, 33, 33, 135, 135, 8640, 135, 8640, 8640, 8640, 33, 135, 135, 33, 8640, 135, 8640, 8640, 135, 33, 135, 135, 135, 33, 8640, 135, 8640, 33, 8640, 33, 33, 135, 8640, 8640, 135, 33, 135, 33, 135, 8640, 8640, 135, 33, 135, 33, 8640, 33, 33, 33, 33, 8640, 135, 135, 8640, 135, 135, 33, 135, 8640, 135, 33, 33, 135, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 135, 8640, 135, 135, 135, 33, 8640, 33, 8640, 135, 33, 135, 33, 33, 135, 33, 135, 8640, 8640, 8640, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 33, 33, 8640, 135, 8640, 135, 8640, 135, 33, 135, 33, 33, 33, 8640, 8640, 135, 135, 33, 33, 135, 33, 8640, 33, 33, 135, 33, 8640, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 33, 135, 8640, 135, 135, 8640, 135, 33, 135, 33, 8640, 135, 135, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 135, 33, 135, 33, 135, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 135, 135, 8640, 33, 8640, 33, 33, 33, 8640, 135, 8640, 8640, 33, 135, 135, 135, 33, 135, 33, 135, 135, 8640, 33, 33, 135, 33, 135, 135, 33, 8640, 8640, 8640, 33, 135, 135, 135, 135, 33, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 135, 135, 135, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 135, 8640, 135, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 942423 . Total input tokens: 210094551 . Total output tokens: 188466191
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.866158648044802,
    "estimated_duration": 3600.0955630470894,
    "input_throughput": 4737.337023788588,
    "output_throughput": 4152.672266106858,
    "total_throughput": 8890.009289895446,
    "itl": 205.78526911115446,
    "ttft": 1982303.7056906102,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1014,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.171650597937372,
    "arrivals": 314288,
    "finished_requests": 68611,
    "scheduler_time": 93.42746737704276
}
#Debug simulation 
Total elapsed time: 4.866255904024001. Arrivals time: 0.23695628711720929 Scheduler time: 4.533428292255849 Scheduler overhead time: 0.027141466038301587 Adapter cache time: 0.02820412680739537 Engine time: 0.027939128631260246 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-32/adapters_320_slots_160_rate_0.8-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-32/adapters_320_slots_160_rate_0.8-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [106 107 107]
Adapter prompts. [135, 8640, 8640, 33, 8640, 8640, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 8640, 135, 8640, 8640, 33, 8640, 135, 135, 8640, 8640, 135, 33, 33, 135, 8640, 8640, 135, 135, 33, 33, 135, 8640, 8640, 33, 8640, 135, 33, 135, 8640, 33, 135, 8640, 8640, 135, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 135, 135, 135, 33, 135, 33, 8640, 33, 8640, 135, 8640, 8640, 33, 8640, 33, 8640, 135, 33, 33, 135, 135, 8640, 135, 8640, 8640, 8640, 33, 135, 135, 33, 8640, 135, 8640, 8640, 135, 33, 135, 135, 135, 33, 8640, 135, 8640, 33, 8640, 33, 33, 135, 8640, 8640, 135, 33, 135, 33, 135, 8640, 8640, 135, 33, 135, 33, 8640, 33, 33, 33, 33, 8640, 135, 135, 8640, 135, 135, 33, 135, 8640, 135, 33, 33, 135, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 135, 8640, 135, 135, 135, 33, 8640, 33, 8640, 135, 33, 135, 33, 33, 135, 33, 135, 8640, 8640, 8640, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 33, 33, 8640, 135, 8640, 135, 8640, 135, 33, 135, 33, 33, 33, 8640, 8640, 135, 135, 33, 33, 135, 33, 8640, 33, 33, 135, 33, 8640, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 33, 135, 8640, 135, 135, 8640, 135, 33, 135, 33, 8640, 135, 135, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 135, 33, 135, 33, 135, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 135, 135, 8640, 33, 8640, 33, 33, 33, 8640, 135, 8640, 8640, 33, 135, 135, 135, 33, 135, 33, 135, 135, 8640, 33, 33, 135, 33, 135, 135, 33, 8640, 8640, 8640, 33, 135, 135, 135, 135, 33, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 135, 135, 135, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 135, 8640, 135, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 942423 . Total input tokens: 210094551 . Total output tokens: 188466191
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.619640003016684,
    "estimated_duration": 3600.125025403451,
    "input_throughput": 4322.32794422359,
    "output_throughput": 3807.5552663518506,
    "total_throughput": 8129.883210575441,
    "itl": 133.358808238355,
    "ttft": 2052668.9215795991,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 910,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0136780289001766,
    "arrivals": 314288,
    "finished_requests": 62624,
    "scheduler_time": 106.04305360634207
}
#Debug simulation 
Total elapsed time: 4.619733383005951. Arrivals time: 0.22242264699889347 Scheduler time: 4.2605207354645245 Scheduler overhead time: 0.039677654509432614 Adapter cache time: 0.038010140298865736 Engine time: 0.04062126314966008 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-16/adapters_320_slots_160_rate_0.8-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-16/adapters_320_slots_160_rate_0.8-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [106 107 107]
Adapter prompts. [135, 8640, 8640, 33, 8640, 8640, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 8640, 135, 8640, 8640, 33, 8640, 135, 135, 8640, 8640, 135, 33, 33, 135, 8640, 8640, 135, 135, 33, 33, 135, 8640, 8640, 33, 8640, 135, 33, 135, 8640, 33, 135, 8640, 8640, 135, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 135, 135, 135, 33, 135, 33, 8640, 33, 8640, 135, 8640, 8640, 33, 8640, 33, 8640, 135, 33, 33, 135, 135, 8640, 135, 8640, 8640, 8640, 33, 135, 135, 33, 8640, 135, 8640, 8640, 135, 33, 135, 135, 135, 33, 8640, 135, 8640, 33, 8640, 33, 33, 135, 8640, 8640, 135, 33, 135, 33, 135, 8640, 8640, 135, 33, 135, 33, 8640, 33, 33, 33, 33, 8640, 135, 135, 8640, 135, 135, 33, 135, 8640, 135, 33, 33, 135, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 135, 8640, 135, 135, 135, 33, 8640, 33, 8640, 135, 33, 135, 33, 33, 135, 33, 135, 8640, 8640, 8640, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 33, 33, 8640, 135, 8640, 135, 8640, 135, 33, 135, 33, 33, 33, 8640, 8640, 135, 135, 33, 33, 135, 33, 8640, 33, 33, 135, 33, 8640, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 33, 135, 8640, 135, 135, 8640, 135, 33, 135, 33, 8640, 135, 135, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 135, 33, 135, 33, 135, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 135, 135, 8640, 33, 8640, 33, 33, 33, 8640, 135, 8640, 8640, 33, 135, 135, 135, 33, 135, 33, 135, 135, 8640, 33, 33, 135, 33, 135, 135, 33, 8640, 8640, 8640, 33, 135, 135, 135, 135, 33, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 135, 135, 135, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 135, 8640, 135, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 942423 . Total input tokens: 210094551 . Total output tokens: 188466191
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.933253651019186,
    "estimated_duration": 3600.1036557577954,
    "input_throughput": 4737.326652448865,
    "output_throughput": 4152.789038751451,
    "total_throughput": 8890.115691200317,
    "itl": 205.7789274700848,
    "ttft": 1982285.874374713,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1014,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0319109990307354,
    "arrivals": 314288,
    "finished_requests": 68612,
    "scheduler_time": 93.43041626772968
}
#Debug simulation 
Total elapsed time: 4.933358353038784. Arrivals time: 0.23482977884123102 Scheduler time: 4.60186929279007 Scheduler overhead time: 0.027522621036041528 Adapter cache time: 0.02829329890664667 Engine time: 0.028147590870503336 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-32/adapters_320_slots_160_rate_0.8-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-32/adapters_320_slots_160_rate_0.8-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [106 107 107]
Adapter prompts. [135, 8640, 8640, 33, 8640, 8640, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 8640, 135, 8640, 8640, 33, 8640, 135, 135, 8640, 8640, 135, 33, 33, 135, 8640, 8640, 135, 135, 33, 33, 135, 8640, 8640, 33, 8640, 135, 33, 135, 8640, 33, 135, 8640, 8640, 135, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 135, 135, 135, 33, 135, 33, 8640, 33, 8640, 135, 8640, 8640, 33, 8640, 33, 8640, 135, 33, 33, 135, 135, 8640, 135, 8640, 8640, 8640, 33, 135, 135, 33, 8640, 135, 8640, 8640, 135, 33, 135, 135, 135, 33, 8640, 135, 8640, 33, 8640, 33, 33, 135, 8640, 8640, 135, 33, 135, 33, 135, 8640, 8640, 135, 33, 135, 33, 8640, 33, 33, 33, 33, 8640, 135, 135, 8640, 135, 135, 33, 135, 8640, 135, 33, 33, 135, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 135, 8640, 135, 135, 135, 33, 8640, 33, 8640, 135, 33, 135, 33, 33, 135, 33, 135, 8640, 8640, 8640, 8640, 135, 135, 8640, 8640, 8640, 135, 8640, 33, 33, 8640, 135, 8640, 135, 8640, 135, 33, 135, 33, 33, 33, 8640, 8640, 135, 135, 33, 33, 135, 33, 8640, 33, 33, 135, 33, 8640, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 33, 135, 8640, 135, 135, 8640, 135, 33, 135, 33, 8640, 135, 135, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 135, 33, 135, 33, 135, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 135, 135, 8640, 33, 8640, 33, 33, 33, 8640, 135, 8640, 8640, 33, 135, 135, 135, 33, 135, 33, 135, 135, 8640, 33, 33, 135, 33, 135, 135, 33, 8640, 8640, 8640, 33, 135, 135, 135, 135, 33, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 135, 135, 135, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 135, 8640, 135, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 942423 . Total input tokens: 210094551 . Total output tokens: 188466191
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.648242780007422,
    "estimated_duration": 3600.0925853480503,
    "input_throughput": 4320.397776241159,
    "output_throughput": 3806.033782510432,
    "total_throughput": 8126.43155875159,
    "itl": 133.1471316786323,
    "ttft": 2052788.4056654326,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 911,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0555394538864795,
    "arrivals": 314288,
    "finished_requests": 62593,
    "scheduler_time": 106.10196664937993
}
#Debug simulation 
Total elapsed time: 4.648338865023106. Arrivals time: 0.21758074458921328 Scheduler time: 4.293350426945835 Scheduler overhead time: 0.039751634758431464 Adapter cache time: 0.038370411028154194 Engine time: 0.04067455016775057 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-8/adapters_320_slots_160_rate_0.8-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-8/adapters_320_slots_160_rate_0.8-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [106 107 107]
Adapter prompts. [66, 8640, 8640, 33, 8640, 8640, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 8640, 66, 8640, 8640, 33, 8640, 66, 66, 8640, 8640, 66, 33, 33, 66, 8640, 8640, 66, 66, 33, 33, 66, 8640, 8640, 33, 8640, 66, 33, 66, 8640, 33, 66, 8640, 8640, 66, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 66, 66, 66, 33, 66, 33, 8640, 33, 8640, 66, 8640, 8640, 33, 8640, 33, 8640, 66, 33, 33, 66, 66, 8640, 66, 8640, 8640, 8640, 33, 66, 66, 33, 8640, 66, 8640, 8640, 66, 33, 66, 66, 66, 33, 8640, 66, 8640, 33, 8640, 33, 33, 66, 8640, 8640, 66, 33, 66, 33, 66, 8640, 8640, 66, 33, 66, 33, 8640, 33, 33, 33, 33, 8640, 66, 66, 8640, 66, 66, 33, 66, 8640, 66, 33, 33, 66, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 66, 8640, 66, 66, 66, 33, 8640, 33, 8640, 66, 33, 66, 33, 33, 66, 33, 66, 8640, 8640, 8640, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 33, 33, 8640, 66, 8640, 66, 8640, 66, 33, 66, 33, 33, 33, 8640, 8640, 66, 66, 33, 33, 66, 33, 8640, 33, 33, 66, 33, 8640, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 33, 66, 8640, 66, 66, 8640, 66, 33, 66, 33, 8640, 66, 66, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 66, 33, 66, 33, 66, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 66, 66, 8640, 33, 8640, 33, 33, 33, 8640, 66, 8640, 8640, 33, 66, 66, 66, 33, 66, 33, 66, 66, 8640, 33, 33, 66, 33, 66, 66, 33, 8640, 8640, 8640, 33, 66, 66, 66, 66, 33, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 66, 66, 66, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 66, 8640, 66, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 935040 . Total input tokens: 208436889 . Total output tokens: 187049243
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.999654256971553,
    "estimated_duration": 3600.0773052828617,
    "input_throughput": 4811.667231306568,
    "output_throughput": 4273.301014237873,
    "total_throughput": 9084.968245544442,
    "itl": 201.45301463707554,
    "ttft": 1961117.07727281,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 701,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1454019084968987,
    "arrivals": 311871,
    "finished_requests": 70409,
    "scheduler_time": 95.86682455130895
}
#Debug simulation 
Total elapsed time: 4.999750337970909. Arrivals time: 0.2400522500392981 Scheduler time: 4.670388086233288 Scheduler overhead time: 0.027803981793113053 Adapter cache time: 0.020344535121694207 Engine time: 0.028327539039310068 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-16/adapters_320_slots_160_rate_0.8-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-16/adapters_320_slots_160_rate_0.8-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [106 107 107]
Adapter prompts. [66, 8640, 8640, 33, 8640, 8640, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 8640, 66, 8640, 8640, 33, 8640, 66, 66, 8640, 8640, 66, 33, 33, 66, 8640, 8640, 66, 66, 33, 33, 66, 8640, 8640, 33, 8640, 66, 33, 66, 8640, 33, 66, 8640, 8640, 66, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 66, 66, 66, 33, 66, 33, 8640, 33, 8640, 66, 8640, 8640, 33, 8640, 33, 8640, 66, 33, 33, 66, 66, 8640, 66, 8640, 8640, 8640, 33, 66, 66, 33, 8640, 66, 8640, 8640, 66, 33, 66, 66, 66, 33, 8640, 66, 8640, 33, 8640, 33, 33, 66, 8640, 8640, 66, 33, 66, 33, 66, 8640, 8640, 66, 33, 66, 33, 8640, 33, 33, 33, 33, 8640, 66, 66, 8640, 66, 66, 33, 66, 8640, 66, 33, 33, 66, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 66, 8640, 66, 66, 66, 33, 8640, 33, 8640, 66, 33, 66, 33, 33, 66, 33, 66, 8640, 8640, 8640, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 33, 33, 8640, 66, 8640, 66, 8640, 66, 33, 66, 33, 33, 33, 8640, 8640, 66, 66, 33, 33, 66, 33, 8640, 33, 33, 66, 33, 8640, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 33, 66, 8640, 66, 66, 8640, 66, 33, 66, 33, 8640, 66, 66, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 66, 33, 66, 33, 66, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 66, 66, 8640, 33, 8640, 33, 33, 33, 8640, 66, 8640, 8640, 33, 66, 66, 66, 33, 66, 33, 66, 66, 8640, 33, 33, 66, 33, 66, 66, 33, 8640, 8640, 8640, 33, 66, 66, 66, 66, 33, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 66, 66, 66, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 66, 8640, 66, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 935040 . Total input tokens: 208436889 . Total output tokens: 187049243
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.279419869009871,
    "estimated_duration": 3600.1846288526244,
    "input_throughput": 4811.447407773789,
    "output_throughput": 4273.150292545665,
    "total_throughput": 9084.597700319455,
    "itl": 201.46173019216744,
    "ttft": 1961148.221377756,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 701,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2823447219352295,
    "arrivals": 311871,
    "finished_requests": 70408,
    "scheduler_time": 95.86661785835095
}
#Debug simulation 
Total elapsed time: 5.279509476036765. Arrivals time: 0.25012111954856664 Scheduler time: 4.939415359753184 Scheduler overhead time: 0.02800230518914759 Adapter cache time: 0.020519678306300193 Engine time: 0.028431386221200228 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-32/adapters_320_slots_160_rate_0.8-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-32/adapters_320_slots_160_rate_0.8-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [106 107 107]
Adapter prompts. [66, 8640, 8640, 33, 8640, 8640, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 8640, 66, 8640, 8640, 33, 8640, 66, 66, 8640, 8640, 66, 33, 33, 66, 8640, 8640, 66, 66, 33, 33, 66, 8640, 8640, 33, 8640, 66, 33, 66, 8640, 33, 66, 8640, 8640, 66, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 66, 66, 66, 33, 66, 33, 8640, 33, 8640, 66, 8640, 8640, 33, 8640, 33, 8640, 66, 33, 33, 66, 66, 8640, 66, 8640, 8640, 8640, 33, 66, 66, 33, 8640, 66, 8640, 8640, 66, 33, 66, 66, 66, 33, 8640, 66, 8640, 33, 8640, 33, 33, 66, 8640, 8640, 66, 33, 66, 33, 66, 8640, 8640, 66, 33, 66, 33, 8640, 33, 33, 33, 33, 8640, 66, 66, 8640, 66, 66, 33, 66, 8640, 66, 33, 33, 66, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 66, 8640, 66, 66, 66, 33, 8640, 33, 8640, 66, 33, 66, 33, 33, 66, 33, 66, 8640, 8640, 8640, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 33, 33, 8640, 66, 8640, 66, 8640, 66, 33, 66, 33, 33, 33, 8640, 8640, 66, 66, 33, 33, 66, 33, 8640, 33, 33, 66, 33, 8640, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 33, 66, 8640, 66, 66, 8640, 66, 33, 66, 33, 8640, 66, 66, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 66, 33, 66, 33, 66, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 66, 66, 8640, 33, 8640, 33, 33, 33, 8640, 66, 8640, 8640, 33, 66, 66, 66, 33, 66, 33, 66, 66, 8640, 33, 33, 66, 33, 66, 66, 33, 8640, 8640, 8640, 33, 66, 66, 66, 66, 33, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 66, 66, 66, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 66, 8640, 66, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 935040 . Total input tokens: 208436889 . Total output tokens: 187049243
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.69498825899791,
    "estimated_duration": 3600.056255164294,
    "input_throughput": 4345.748480334794,
    "output_throughput": 3879.3735458899496,
    "total_throughput": 8225.122026224744,
    "itl": 132.09746720107697,
    "ttft": 2036756.288572751,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 649,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1168876805529075,
    "arrivals": 311871,
    "finished_requests": 63641,
    "scheduler_time": 107.52437714755175
}
#Debug simulation 
Total elapsed time: 4.695132972032297. Arrivals time: 0.22402344027068466 Scheduler time: 4.34173296415247 Scheduler overhead time: 0.03987963043618947 Adapter cache time: 0.029910325189121068 Engine time: 0.04070199734997004 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-16/adapters_320_slots_160_rate_0.8-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-16/adapters_320_slots_160_rate_0.8-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [106 107 107]
Adapter prompts. [66, 8640, 8640, 33, 8640, 8640, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 8640, 66, 8640, 8640, 33, 8640, 66, 66, 8640, 8640, 66, 33, 33, 66, 8640, 8640, 66, 66, 33, 33, 66, 8640, 8640, 33, 8640, 66, 33, 66, 8640, 33, 66, 8640, 8640, 66, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 66, 66, 66, 33, 66, 33, 8640, 33, 8640, 66, 8640, 8640, 33, 8640, 33, 8640, 66, 33, 33, 66, 66, 8640, 66, 8640, 8640, 8640, 33, 66, 66, 33, 8640, 66, 8640, 8640, 66, 33, 66, 66, 66, 33, 8640, 66, 8640, 33, 8640, 33, 33, 66, 8640, 8640, 66, 33, 66, 33, 66, 8640, 8640, 66, 33, 66, 33, 8640, 33, 33, 33, 33, 8640, 66, 66, 8640, 66, 66, 33, 66, 8640, 66, 33, 33, 66, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 66, 8640, 66, 66, 66, 33, 8640, 33, 8640, 66, 33, 66, 33, 33, 66, 33, 66, 8640, 8640, 8640, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 33, 33, 8640, 66, 8640, 66, 8640, 66, 33, 66, 33, 33, 33, 8640, 8640, 66, 66, 33, 33, 66, 33, 8640, 33, 33, 66, 33, 8640, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 33, 66, 8640, 66, 66, 8640, 66, 33, 66, 33, 8640, 66, 66, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 66, 33, 66, 33, 66, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 66, 66, 8640, 33, 8640, 33, 33, 33, 8640, 66, 8640, 8640, 33, 66, 66, 66, 33, 66, 33, 66, 66, 8640, 33, 33, 66, 33, 66, 66, 33, 8640, 8640, 8640, 33, 66, 66, 66, 66, 33, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 66, 66, 66, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 66, 8640, 66, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 935040 . Total input tokens: 208436889 . Total output tokens: 187049243
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.989474135974888,
    "estimated_duration": 3600.0282850624576,
    "input_throughput": 4811.271086915779,
    "output_throughput": 4273.023371463071,
    "total_throughput": 9084.29445837885,
    "itl": 201.45750424782346,
    "ttft": 1961139.116249376,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 701,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1871420127386054,
    "arrivals": 311871,
    "finished_requests": 70403,
    "scheduler_time": 95.8641042638446
}
#Debug simulation 
Total elapsed time: 4.989569080004003. Arrivals time: 0.2405974321300164 Scheduler time: 4.659295463934541 Scheduler overhead time: 0.027892191661521792 Adapter cache time: 0.02037315967027098 Engine time: 0.02861160662723705 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-32/adapters_320_slots_160_rate_0.8-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-32/adapters_320_slots_160_rate_0.8-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [106 107 107]
Adapter prompts. [66, 8640, 8640, 33, 8640, 8640, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 8640, 66, 8640, 8640, 33, 8640, 66, 66, 8640, 8640, 66, 33, 33, 66, 8640, 8640, 66, 66, 33, 33, 66, 8640, 8640, 33, 8640, 66, 33, 66, 8640, 33, 66, 8640, 8640, 66, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 66, 66, 66, 33, 66, 33, 8640, 33, 8640, 66, 8640, 8640, 33, 8640, 33, 8640, 66, 33, 33, 66, 66, 8640, 66, 8640, 8640, 8640, 33, 66, 66, 33, 8640, 66, 8640, 8640, 66, 33, 66, 66, 66, 33, 8640, 66, 8640, 33, 8640, 33, 33, 66, 8640, 8640, 66, 33, 66, 33, 66, 8640, 8640, 66, 33, 66, 33, 8640, 33, 33, 33, 33, 8640, 66, 66, 8640, 66, 66, 33, 66, 8640, 66, 33, 33, 66, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 66, 8640, 66, 66, 66, 33, 8640, 33, 8640, 66, 33, 66, 33, 33, 66, 33, 66, 8640, 8640, 8640, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 33, 33, 8640, 66, 8640, 66, 8640, 66, 33, 66, 33, 33, 33, 8640, 8640, 66, 66, 33, 33, 66, 33, 8640, 33, 33, 66, 33, 8640, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 33, 66, 8640, 66, 66, 8640, 66, 33, 66, 33, 8640, 66, 66, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 66, 33, 66, 33, 66, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 66, 66, 8640, 33, 8640, 33, 33, 33, 8640, 66, 8640, 8640, 33, 66, 66, 66, 33, 66, 33, 66, 66, 8640, 33, 33, 66, 33, 66, 66, 33, 8640, 8640, 8640, 33, 66, 66, 66, 66, 33, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 66, 66, 66, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 66, 8640, 66, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 935040 . Total input tokens: 208436889 . Total output tokens: 187049243
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.6976383160217665,
    "estimated_duration": 3600.029542995588,
    "input_throughput": 4348.0568181601675,
    "output_throughput": 3880.8525966635716,
    "total_throughput": 8228.90941482374,
    "itl": 132.26329642988608,
    "ttft": 2036448.6909355563,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 649,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.143170221913607,
    "arrivals": 311871,
    "finished_requests": 63669,
    "scheduler_time": 107.47949532529886
}
#Debug simulation 
Total elapsed time: 4.6977337609860115. Arrivals time: 0.22416278277523816 Scheduler time: 4.344820242433343 Scheduler overhead time: 0.039682358503341675 Adapter cache time: 0.02956838591489941 Engine time: 0.040735547547228634 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-16/adapters_320_slots_160_rate_0.8-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-16/adapters_320_slots_160_rate_0.8-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [106 107 107]
Adapter prompts. [66, 8640, 8640, 33, 8640, 8640, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 8640, 66, 8640, 8640, 33, 8640, 66, 66, 8640, 8640, 66, 33, 33, 66, 8640, 8640, 66, 66, 33, 33, 66, 8640, 8640, 33, 8640, 66, 33, 66, 8640, 33, 66, 8640, 8640, 66, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 66, 66, 66, 33, 66, 33, 8640, 33, 8640, 66, 8640, 8640, 33, 8640, 33, 8640, 66, 33, 33, 66, 66, 8640, 66, 8640, 8640, 8640, 33, 66, 66, 33, 8640, 66, 8640, 8640, 66, 33, 66, 66, 66, 33, 8640, 66, 8640, 33, 8640, 33, 33, 66, 8640, 8640, 66, 33, 66, 33, 66, 8640, 8640, 66, 33, 66, 33, 8640, 33, 33, 33, 33, 8640, 66, 66, 8640, 66, 66, 33, 66, 8640, 66, 33, 33, 66, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 66, 8640, 66, 66, 66, 33, 8640, 33, 8640, 66, 33, 66, 33, 33, 66, 33, 66, 8640, 8640, 8640, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 33, 33, 8640, 66, 8640, 66, 8640, 66, 33, 66, 33, 33, 33, 8640, 8640, 66, 66, 33, 33, 66, 33, 8640, 33, 33, 66, 33, 8640, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 33, 66, 8640, 66, 66, 8640, 66, 33, 66, 33, 8640, 66, 66, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 66, 33, 66, 33, 66, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 66, 66, 8640, 33, 8640, 33, 33, 33, 8640, 66, 8640, 8640, 33, 66, 66, 66, 33, 66, 33, 66, 66, 8640, 33, 33, 66, 33, 66, 66, 33, 8640, 8640, 8640, 33, 66, 66, 66, 66, 33, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 66, 66, 66, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 66, 8640, 66, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 935040 . Total input tokens: 208436889 . Total output tokens: 187049243
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.9855519169941545,
    "estimated_duration": 3600.0276856794967,
    "input_throughput": 4811.657162778318,
    "output_throughput": 4273.336580492514,
    "total_throughput": 9084.993743270832,
    "itl": 201.45143329063345,
    "ttft": 1961089.9073282706,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 701,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0960252567263877,
    "arrivals": 311871,
    "finished_requests": 70408,
    "scheduler_time": 95.86651956926575
}
#Debug simulation 
Total elapsed time: 4.985677544027567. Arrivals time: 0.24101978936232626 Scheduler time: 4.655348136788234 Scheduler overhead time: 0.02774525881977752 Adapter cache time: 0.020170336589217186 Engine time: 0.028617704985663295 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-32/adapters_320_slots_160_rate_0.8-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-32/adapters_320_slots_160_rate_0.8-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [106 107 107]
Adapter prompts. [66, 8640, 8640, 33, 8640, 8640, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 8640, 66, 8640, 8640, 33, 8640, 66, 66, 8640, 8640, 66, 33, 33, 66, 8640, 8640, 66, 66, 33, 33, 66, 8640, 8640, 33, 8640, 66, 33, 66, 8640, 33, 66, 8640, 8640, 66, 33, 33, 8640, 33, 33, 8640, 8640, 33, 33, 66, 66, 66, 33, 66, 33, 8640, 33, 8640, 66, 8640, 8640, 33, 8640, 33, 8640, 66, 33, 33, 66, 66, 8640, 66, 8640, 8640, 8640, 33, 66, 66, 33, 8640, 66, 8640, 8640, 66, 33, 66, 66, 66, 33, 8640, 66, 8640, 33, 8640, 33, 33, 66, 8640, 8640, 66, 33, 66, 33, 66, 8640, 8640, 66, 33, 66, 33, 8640, 33, 33, 33, 33, 8640, 66, 66, 8640, 66, 66, 33, 66, 8640, 66, 33, 33, 66, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 66, 8640, 66, 66, 66, 33, 8640, 33, 8640, 66, 33, 66, 33, 33, 66, 33, 66, 8640, 8640, 8640, 8640, 66, 66, 8640, 8640, 8640, 66, 8640, 33, 33, 8640, 66, 8640, 66, 8640, 66, 33, 66, 33, 33, 33, 8640, 8640, 66, 66, 33, 33, 66, 33, 8640, 33, 33, 66, 33, 8640, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 33, 66, 8640, 66, 66, 8640, 66, 33, 66, 33, 8640, 66, 66, 8640, 8640, 33, 33, 33, 8640, 8640, 33, 33, 8640, 66, 33, 66, 33, 66, 8640, 8640, 8640, 33, 8640, 8640, 8640, 8640, 33, 66, 66, 8640, 33, 8640, 33, 33, 33, 8640, 66, 8640, 8640, 33, 66, 66, 66, 33, 66, 33, 66, 66, 8640, 33, 33, 66, 33, 66, 66, 33, 8640, 8640, 8640, 33, 66, 66, 66, 66, 33, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 66, 66, 66, 33, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 8640, 8640, 66, 8640, 66, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 935040 . Total input tokens: 208436889 . Total output tokens: 187049243
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.681399055989459,
    "estimated_duration": 3600.1052984309276,
    "input_throughput": 4345.430120285175,
    "output_throughput": 3879.2565334371843,
    "total_throughput": 8224.68665372236,
    "itl": 132.09873585156734,
    "ttft": 2036758.254276204,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 649,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.169704270847142,
    "arrivals": 311871,
    "finished_requests": 63638,
    "scheduler_time": 107.52424777787049
}
#Debug simulation 
Total elapsed time: 4.681505667977035. Arrivals time: 0.23035865428391844 Scheduler time: 4.322403416445013 Scheduler overhead time: 0.03988027368905023 Adapter cache time: 0.029335707426071167 Engine time: 0.0407278859638609 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-8/adapters_320_slots_160_rate_0.4-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-8/adapters_320_slots_160_rate_0.4-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 540, 4320, 4320, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 4320, 1080, 4320, 4320, 540, 4320, 1080, 1080, 4320, 4320, 1080, 540, 540, 1080, 4320, 4320, 1080, 1080, 540, 540, 1080, 4320, 4320, 540, 4320, 1080, 540, 1080, 4320, 540, 1080, 4320, 4320, 1080, 540, 540, 4320, 540, 540, 4320, 4320, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 4320, 540, 4320, 1080, 4320, 4320, 540, 4320, 540, 4320, 1080, 540, 540, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 540, 1080, 1080, 540, 4320, 1080, 4320, 4320, 1080, 540, 1080, 1080, 1080, 540, 4320, 1080, 4320, 540, 4320, 540, 540, 1080, 4320, 4320, 1080, 540, 1080, 540, 1080, 4320, 4320, 1080, 540, 1080, 540, 4320, 540, 540, 540, 540, 4320, 1080, 1080, 4320, 1080, 1080, 540, 1080, 4320, 1080, 540, 540, 1080, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 1080, 4320, 1080, 1080, 1080, 540, 4320, 540, 4320, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 540, 540, 4320, 1080, 4320, 1080, 4320, 1080, 540, 1080, 540, 540, 540, 4320, 4320, 1080, 1080, 540, 540, 1080, 540, 4320, 540, 540, 1080, 540, 4320, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 540, 1080, 4320, 1080, 1080, 4320, 1080, 540, 1080, 540, 4320, 1080, 1080, 4320, 4320, 540, 540, 540, 4320, 4320, 540, 540, 4320, 1080, 540, 1080, 540, 1080, 4320, 4320, 4320, 540, 4320, 4320, 4320, 4320, 540, 1080, 1080, 4320, 540, 4320, 540, 540, 540, 4320, 1080, 4320, 4320, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 4320, 540, 540, 1080, 540, 1080, 1080, 540, 4320, 4320, 4320, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 540, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 4320, 1080, 4320, 1080, 540, 4320, 540, 4320, 4320, 540, 540, 540]
Prompts retrieved: 635040 . Total input tokens: 141657226 . Total output tokens: 126959398
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 9.473359436029568,
    "estimated_duration": 3600.0617978045784,
    "input_throughput": 4088.0045473038526,
    "output_throughput": 3606.865584340411,
    "total_throughput": 7694.870131644263,
    "itl": 237.08222584045993,
    "ttft": 1964490.4251688293,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1116,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4155043222290358,
    "arrivals": 211085,
    "finished_requests": 59469,
    "scheduler_time": 80.0996932145409
}
#Debug simulation 
Total elapsed time: 9.473455881990958. Arrivals time: 0.2510594726772979 Scheduler time: 9.126516923832241 Scheduler overhead time: 0.027283368108328432 Adapter cache time: 0.02944712183671072 Engine time: 0.02709829423110932 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-16/adapters_320_slots_160_rate_0.4-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-16/adapters_320_slots_160_rate_0.4-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 540, 4320, 4320, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 4320, 1080, 4320, 4320, 540, 4320, 1080, 1080, 4320, 4320, 1080, 540, 540, 1080, 4320, 4320, 1080, 1080, 540, 540, 1080, 4320, 4320, 540, 4320, 1080, 540, 1080, 4320, 540, 1080, 4320, 4320, 1080, 540, 540, 4320, 540, 540, 4320, 4320, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 4320, 540, 4320, 1080, 4320, 4320, 540, 4320, 540, 4320, 1080, 540, 540, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 540, 1080, 1080, 540, 4320, 1080, 4320, 4320, 1080, 540, 1080, 1080, 1080, 540, 4320, 1080, 4320, 540, 4320, 540, 540, 1080, 4320, 4320, 1080, 540, 1080, 540, 1080, 4320, 4320, 1080, 540, 1080, 540, 4320, 540, 540, 540, 540, 4320, 1080, 1080, 4320, 1080, 1080, 540, 1080, 4320, 1080, 540, 540, 1080, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 1080, 4320, 1080, 1080, 1080, 540, 4320, 540, 4320, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 540, 540, 4320, 1080, 4320, 1080, 4320, 1080, 540, 1080, 540, 540, 540, 4320, 4320, 1080, 1080, 540, 540, 1080, 540, 4320, 540, 540, 1080, 540, 4320, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 540, 1080, 4320, 1080, 1080, 4320, 1080, 540, 1080, 540, 4320, 1080, 1080, 4320, 4320, 540, 540, 540, 4320, 4320, 540, 540, 4320, 1080, 540, 1080, 540, 1080, 4320, 4320, 4320, 540, 4320, 4320, 4320, 4320, 540, 1080, 1080, 4320, 540, 4320, 540, 540, 540, 4320, 1080, 4320, 4320, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 4320, 540, 540, 1080, 540, 1080, 1080, 540, 4320, 4320, 4320, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 540, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 4320, 1080, 4320, 1080, 540, 4320, 540, 4320, 4320, 540, 540, 540]
Prompts retrieved: 635040 . Total input tokens: 141657226 . Total output tokens: 126959398
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 9.414551533991471,
    "estimated_duration": 3600.126059071835,
    "input_throughput": 4087.1960477388375,
    "output_throughput": 3605.935399758447,
    "total_throughput": 7693.131447497285,
    "itl": 237.10847701755569,
    "ttft": 1964750.1993994392,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1118,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.6476883372571383,
    "arrivals": 211085,
    "finished_requests": 59462,
    "scheduler_time": 80.09623408445584
}
#Debug simulation 
Total elapsed time: 9.414677986002062. Arrivals time: 0.2523206841433421 Scheduler time: 9.06522515125107 Scheduler overhead time: 0.02775950380600989 Adapter cache time: 0.029752954025752842 Engine time: 0.027672535681631416 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-32/adapters_320_slots_160_rate_0.4-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-32/adapters_320_slots_160_rate_0.4-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 540, 4320, 4320, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 4320, 1080, 4320, 4320, 540, 4320, 1080, 1080, 4320, 4320, 1080, 540, 540, 1080, 4320, 4320, 1080, 1080, 540, 540, 1080, 4320, 4320, 540, 4320, 1080, 540, 1080, 4320, 540, 1080, 4320, 4320, 1080, 540, 540, 4320, 540, 540, 4320, 4320, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 4320, 540, 4320, 1080, 4320, 4320, 540, 4320, 540, 4320, 1080, 540, 540, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 540, 1080, 1080, 540, 4320, 1080, 4320, 4320, 1080, 540, 1080, 1080, 1080, 540, 4320, 1080, 4320, 540, 4320, 540, 540, 1080, 4320, 4320, 1080, 540, 1080, 540, 1080, 4320, 4320, 1080, 540, 1080, 540, 4320, 540, 540, 540, 540, 4320, 1080, 1080, 4320, 1080, 1080, 540, 1080, 4320, 1080, 540, 540, 1080, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 1080, 4320, 1080, 1080, 1080, 540, 4320, 540, 4320, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 540, 540, 4320, 1080, 4320, 1080, 4320, 1080, 540, 1080, 540, 540, 540, 4320, 4320, 1080, 1080, 540, 540, 1080, 540, 4320, 540, 540, 1080, 540, 4320, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 540, 1080, 4320, 1080, 1080, 4320, 1080, 540, 1080, 540, 4320, 1080, 1080, 4320, 4320, 540, 540, 540, 4320, 4320, 540, 540, 4320, 1080, 540, 1080, 540, 1080, 4320, 4320, 4320, 540, 4320, 4320, 4320, 4320, 540, 1080, 1080, 4320, 540, 4320, 540, 540, 540, 4320, 1080, 4320, 4320, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 4320, 540, 540, 1080, 540, 1080, 1080, 540, 4320, 4320, 4320, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 540, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 4320, 1080, 4320, 1080, 540, 4320, 540, 4320, 4320, 540, 540, 540]
Prompts retrieved: 635040 . Total input tokens: 141657226 . Total output tokens: 126959398
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.068773109989706,
    "estimated_duration": 3600.088644240217,
    "input_throughput": 3598.762775113355,
    "output_throughput": 3189.043697123458,
    "total_throughput": 6787.8064722368135,
    "itl": 157.55792561932265,
    "ttft": 2072337.9156594584,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3442,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.253821847345083,
    "arrivals": 211085,
    "finished_requests": 52423,
    "scheduler_time": 87.76368467583075
}
#Debug simulation 
Total elapsed time: 5.068867894995492. Arrivals time: 0.2110486698220484 Scheduler time: 4.690186320687644 Scheduler overhead time: 0.035558025527279824 Adapter cache time: 0.08049630676396191 Engine time: 0.035321103408932686 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-16-16/adapters_320_slots_160_rate_0.4-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-16-16/adapters_320_slots_160_rate_0.4-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 540, 4320, 4320, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 4320, 1080, 4320, 4320, 540, 4320, 1080, 1080, 4320, 4320, 1080, 540, 540, 1080, 4320, 4320, 1080, 1080, 540, 540, 1080, 4320, 4320, 540, 4320, 1080, 540, 1080, 4320, 540, 1080, 4320, 4320, 1080, 540, 540, 4320, 540, 540, 4320, 4320, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 4320, 540, 4320, 1080, 4320, 4320, 540, 4320, 540, 4320, 1080, 540, 540, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 540, 1080, 1080, 540, 4320, 1080, 4320, 4320, 1080, 540, 1080, 1080, 1080, 540, 4320, 1080, 4320, 540, 4320, 540, 540, 1080, 4320, 4320, 1080, 540, 1080, 540, 1080, 4320, 4320, 1080, 540, 1080, 540, 4320, 540, 540, 540, 540, 4320, 1080, 1080, 4320, 1080, 1080, 540, 1080, 4320, 1080, 540, 540, 1080, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 1080, 4320, 1080, 1080, 1080, 540, 4320, 540, 4320, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 540, 540, 4320, 1080, 4320, 1080, 4320, 1080, 540, 1080, 540, 540, 540, 4320, 4320, 1080, 1080, 540, 540, 1080, 540, 4320, 540, 540, 1080, 540, 4320, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 540, 1080, 4320, 1080, 1080, 4320, 1080, 540, 1080, 540, 4320, 1080, 1080, 4320, 4320, 540, 540, 540, 4320, 4320, 540, 540, 4320, 1080, 540, 1080, 540, 1080, 4320, 4320, 4320, 540, 4320, 4320, 4320, 4320, 540, 1080, 1080, 4320, 540, 4320, 540, 540, 540, 4320, 1080, 4320, 4320, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 4320, 540, 540, 1080, 540, 1080, 1080, 540, 4320, 4320, 4320, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 540, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 4320, 1080, 4320, 1080, 540, 4320, 540, 4320, 4320, 540, 540, 540]
Prompts retrieved: 635040 . Total input tokens: 141657226 . Total output tokens: 126959398
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 9.383647602982819,
    "estimated_duration": 3600.0620339873867,
    "input_throughput": 4087.5451203548782,
    "output_throughput": 3606.0617504474603,
    "total_throughput": 7693.606870802339,
    "itl": 237.09316823603106,
    "ttft": 1964607.3236441975,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1127,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5176981876301165,
    "arrivals": 211085,
    "finished_requests": 59452,
    "scheduler_time": 80.09656187930018
}
#Debug simulation 
Total elapsed time: 9.383741301018745. Arrivals time: 0.25740142981521785 Scheduler time: 9.029140227707103 Scheduler overhead time: 0.02729869051836431 Adapter cache time: 0.030309432302601635 Engine time: 0.027615774422883987 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-16-32/adapters_320_slots_160_rate_0.4-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-16-32/adapters_320_slots_160_rate_0.4-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 540, 4320, 4320, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 4320, 1080, 4320, 4320, 540, 4320, 1080, 1080, 4320, 4320, 1080, 540, 540, 1080, 4320, 4320, 1080, 1080, 540, 540, 1080, 4320, 4320, 540, 4320, 1080, 540, 1080, 4320, 540, 1080, 4320, 4320, 1080, 540, 540, 4320, 540, 540, 4320, 4320, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 4320, 540, 4320, 1080, 4320, 4320, 540, 4320, 540, 4320, 1080, 540, 540, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 540, 1080, 1080, 540, 4320, 1080, 4320, 4320, 1080, 540, 1080, 1080, 1080, 540, 4320, 1080, 4320, 540, 4320, 540, 540, 1080, 4320, 4320, 1080, 540, 1080, 540, 1080, 4320, 4320, 1080, 540, 1080, 540, 4320, 540, 540, 540, 540, 4320, 1080, 1080, 4320, 1080, 1080, 540, 1080, 4320, 1080, 540, 540, 1080, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 1080, 4320, 1080, 1080, 1080, 540, 4320, 540, 4320, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 540, 540, 4320, 1080, 4320, 1080, 4320, 1080, 540, 1080, 540, 540, 540, 4320, 4320, 1080, 1080, 540, 540, 1080, 540, 4320, 540, 540, 1080, 540, 4320, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 540, 1080, 4320, 1080, 1080, 4320, 1080, 540, 1080, 540, 4320, 1080, 1080, 4320, 4320, 540, 540, 540, 4320, 4320, 540, 540, 4320, 1080, 540, 1080, 540, 1080, 4320, 4320, 4320, 540, 4320, 4320, 4320, 4320, 540, 1080, 1080, 4320, 540, 4320, 540, 540, 540, 4320, 1080, 4320, 4320, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 4320, 540, 540, 1080, 540, 1080, 1080, 540, 4320, 4320, 4320, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 540, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 4320, 1080, 4320, 1080, 540, 4320, 540, 4320, 4320, 540, 540, 540]
Prompts retrieved: 635040 . Total input tokens: 141657226 . Total output tokens: 126959398
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 5.045255540986545,
    "estimated_duration": 3600.1360861692297,
    "input_throughput": 3599.5575416675647,
    "output_throughput": 3189.481932117231,
    "total_throughput": 6789.0394737847955,
    "itl": 157.55616632352118,
    "ttft": 2072548.974618924,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3463,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.474602124559958,
    "arrivals": 211085,
    "finished_requests": 52437,
    "scheduler_time": 87.76300538275817
}
#Debug simulation 
Total elapsed time: 5.045386579004116. Arrivals time: 0.2103255942929536 Scheduler time: 4.666189866897184 Scheduler overhead time: 0.035682562564034015 Adapter cache time: 0.08179022965487093 Engine time: 0.03509065165417269 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_16-16-16/adapters_320_slots_160_rate_0.4-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_16-16-16/adapters_320_slots_160_rate_0.4-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 540, 4320, 4320, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 4320, 1080, 4320, 4320, 540, 4320, 1080, 1080, 4320, 4320, 1080, 540, 540, 1080, 4320, 4320, 1080, 1080, 540, 540, 1080, 4320, 4320, 540, 4320, 1080, 540, 1080, 4320, 540, 1080, 4320, 4320, 1080, 540, 540, 4320, 540, 540, 4320, 4320, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 4320, 540, 4320, 1080, 4320, 4320, 540, 4320, 540, 4320, 1080, 540, 540, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 540, 1080, 1080, 540, 4320, 1080, 4320, 4320, 1080, 540, 1080, 1080, 1080, 540, 4320, 1080, 4320, 540, 4320, 540, 540, 1080, 4320, 4320, 1080, 540, 1080, 540, 1080, 4320, 4320, 1080, 540, 1080, 540, 4320, 540, 540, 540, 540, 4320, 1080, 1080, 4320, 1080, 1080, 540, 1080, 4320, 1080, 540, 540, 1080, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 1080, 4320, 1080, 1080, 1080, 540, 4320, 540, 4320, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 540, 540, 4320, 1080, 4320, 1080, 4320, 1080, 540, 1080, 540, 540, 540, 4320, 4320, 1080, 1080, 540, 540, 1080, 540, 4320, 540, 540, 1080, 540, 4320, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 540, 1080, 4320, 1080, 1080, 4320, 1080, 540, 1080, 540, 4320, 1080, 1080, 4320, 4320, 540, 540, 540, 4320, 4320, 540, 540, 4320, 1080, 540, 1080, 540, 1080, 4320, 4320, 4320, 540, 4320, 4320, 4320, 4320, 540, 1080, 1080, 4320, 540, 4320, 540, 540, 540, 4320, 1080, 4320, 4320, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 4320, 540, 540, 1080, 540, 1080, 1080, 540, 4320, 4320, 4320, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 540, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 4320, 1080, 4320, 1080, 540, 4320, 540, 4320, 4320, 540, 540, 540]
Prompts retrieved: 635040 . Total input tokens: 141657226 . Total output tokens: 126959398
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 9.369910566019826,
    "estimated_duration": 3600.219806079892,
    "input_throughput": 4087.7754116975766,
    "output_throughput": 3607.0200430734003,
    "total_throughput": 7694.795454770977,
    "itl": 237.07787088681027,
    "ttft": 1964644.9882778607,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1117,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3398861794056485,
    "arrivals": 211085,
    "finished_requests": 59466,
    "scheduler_time": 80.10465580068187
}
#Debug simulation 
Total elapsed time: 9.37000206799712. Arrivals time: 0.24720858945511281 Scheduler time: 9.026849097048398 Scheduler overhead time: 0.027112177456729114 Adapter cache time: 0.029519602481741458 Engine time: 0.02718869730597362 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_16-16-32/adapters_320_slots_160_rate_0.4-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_16-16-32/adapters_320_slots_160_rate_0.4-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 540, 4320, 4320, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 4320, 1080, 4320, 4320, 540, 4320, 1080, 1080, 4320, 4320, 1080, 540, 540, 1080, 4320, 4320, 1080, 1080, 540, 540, 1080, 4320, 4320, 540, 4320, 1080, 540, 1080, 4320, 540, 1080, 4320, 4320, 1080, 540, 540, 4320, 540, 540, 4320, 4320, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 4320, 540, 4320, 1080, 4320, 4320, 540, 4320, 540, 4320, 1080, 540, 540, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 540, 1080, 1080, 540, 4320, 1080, 4320, 4320, 1080, 540, 1080, 1080, 1080, 540, 4320, 1080, 4320, 540, 4320, 540, 540, 1080, 4320, 4320, 1080, 540, 1080, 540, 1080, 4320, 4320, 1080, 540, 1080, 540, 4320, 540, 540, 540, 540, 4320, 1080, 1080, 4320, 1080, 1080, 540, 1080, 4320, 1080, 540, 540, 1080, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 1080, 4320, 1080, 1080, 1080, 540, 4320, 540, 4320, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 540, 540, 4320, 1080, 4320, 1080, 4320, 1080, 540, 1080, 540, 540, 540, 4320, 4320, 1080, 1080, 540, 540, 1080, 540, 4320, 540, 540, 1080, 540, 4320, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 540, 1080, 4320, 1080, 1080, 4320, 1080, 540, 1080, 540, 4320, 1080, 1080, 4320, 4320, 540, 540, 540, 4320, 4320, 540, 540, 4320, 1080, 540, 1080, 540, 1080, 4320, 4320, 4320, 540, 4320, 4320, 4320, 4320, 540, 1080, 1080, 4320, 540, 4320, 540, 540, 540, 4320, 1080, 4320, 4320, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 4320, 540, 540, 1080, 540, 1080, 1080, 540, 4320, 4320, 4320, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 540, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 4320, 1080, 4320, 1080, 540, 4320, 540, 4320, 4320, 540, 540, 540]
Prompts retrieved: 635040 . Total input tokens: 141657226 . Total output tokens: 126959398
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.062003404018469,
    "estimated_duration": 3600.0810617015363,
    "input_throughput": 3596.323465527947,
    "output_throughput": 3186.4638055061228,
    "total_throughput": 6782.78727103407,
    "itl": 157.3371930575106,
    "ttft": 2072836.038892006,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3446,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.564443931057369,
    "arrivals": 211085,
    "finished_requests": 52377,
    "scheduler_time": 87.79177134015774
}
#Debug simulation 
Total elapsed time: 5.062113385007251. Arrivals time: 0.2095516620320268 Scheduler time: 4.684282303613145 Scheduler overhead time: 0.03547562996391207 Adapter cache time: 0.08129222254501656 Engine time: 0.03530271025374532 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-8/adapters_320_slots_160_rate_0.4-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-8/adapters_320_slots_160_rate_0.4-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 270, 4320, 4320, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 4320, 1080, 4320, 4320, 270, 4320, 1080, 1080, 4320, 4320, 1080, 270, 270, 1080, 4320, 4320, 1080, 1080, 270, 270, 1080, 4320, 4320, 270, 4320, 1080, 270, 1080, 4320, 270, 1080, 4320, 4320, 1080, 270, 270, 4320, 270, 270, 4320, 4320, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 4320, 270, 4320, 1080, 4320, 4320, 270, 4320, 270, 4320, 1080, 270, 270, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 270, 1080, 1080, 270, 4320, 1080, 4320, 4320, 1080, 270, 1080, 1080, 1080, 270, 4320, 1080, 4320, 270, 4320, 270, 270, 1080, 4320, 4320, 1080, 270, 1080, 270, 1080, 4320, 4320, 1080, 270, 1080, 270, 4320, 270, 270, 270, 270, 4320, 1080, 1080, 4320, 1080, 1080, 270, 1080, 4320, 1080, 270, 270, 1080, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 1080, 4320, 1080, 1080, 1080, 270, 4320, 270, 4320, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 270, 270, 4320, 1080, 4320, 1080, 4320, 1080, 270, 1080, 270, 270, 270, 4320, 4320, 1080, 1080, 270, 270, 1080, 270, 4320, 270, 270, 1080, 270, 4320, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 1080, 4320, 1080, 270, 1080, 270, 4320, 1080, 1080, 4320, 4320, 270, 270, 270, 4320, 4320, 270, 270, 4320, 1080, 270, 1080, 270, 1080, 4320, 4320, 4320, 270, 4320, 4320, 4320, 4320, 270, 1080, 1080, 4320, 270, 4320, 270, 270, 270, 4320, 1080, 4320, 4320, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 4320, 270, 270, 1080, 270, 1080, 1080, 270, 4320, 4320, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 606420 . Total input tokens: 135242520 . Total output tokens: 121269682
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 8.058495112985838,
    "estimated_duration": 3600.02455655738,
    "input_throughput": 4111.524176422401,
    "output_throughput": 3607.184283325602,
    "total_throughput": 7718.7084597480025,
    "itl": 236.37678222185912,
    "ttft": 1948154.9237177535,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1188,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.6358594397922017,
    "arrivals": 201527,
    "finished_requests": 59674,
    "scheduler_time": 79.93961408332729
}
#Debug simulation 
Total elapsed time: 8.05861730396282. Arrivals time: 0.2463545927312225 Scheduler time: 7.716857750783674 Scheduler overhead time: 0.02646616625133902 Adapter cache time: 0.030737471650354564 Engine time: 0.02640193118713796 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-16/adapters_320_slots_160_rate_0.4-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-16/adapters_320_slots_160_rate_0.4-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 270, 4320, 4320, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 4320, 1080, 4320, 4320, 270, 4320, 1080, 1080, 4320, 4320, 1080, 270, 270, 1080, 4320, 4320, 1080, 1080, 270, 270, 1080, 4320, 4320, 270, 4320, 1080, 270, 1080, 4320, 270, 1080, 4320, 4320, 1080, 270, 270, 4320, 270, 270, 4320, 4320, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 4320, 270, 4320, 1080, 4320, 4320, 270, 4320, 270, 4320, 1080, 270, 270, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 270, 1080, 1080, 270, 4320, 1080, 4320, 4320, 1080, 270, 1080, 1080, 1080, 270, 4320, 1080, 4320, 270, 4320, 270, 270, 1080, 4320, 4320, 1080, 270, 1080, 270, 1080, 4320, 4320, 1080, 270, 1080, 270, 4320, 270, 270, 270, 270, 4320, 1080, 1080, 4320, 1080, 1080, 270, 1080, 4320, 1080, 270, 270, 1080, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 1080, 4320, 1080, 1080, 1080, 270, 4320, 270, 4320, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 270, 270, 4320, 1080, 4320, 1080, 4320, 1080, 270, 1080, 270, 270, 270, 4320, 4320, 1080, 1080, 270, 270, 1080, 270, 4320, 270, 270, 1080, 270, 4320, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 1080, 4320, 1080, 270, 1080, 270, 4320, 1080, 1080, 4320, 4320, 270, 270, 270, 4320, 4320, 270, 270, 4320, 1080, 270, 1080, 270, 1080, 4320, 4320, 4320, 270, 4320, 4320, 4320, 4320, 270, 1080, 1080, 4320, 270, 4320, 270, 270, 270, 4320, 1080, 4320, 4320, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 4320, 270, 270, 1080, 270, 1080, 1080, 270, 4320, 4320, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 606420 . Total input tokens: 135242520 . Total output tokens: 121269682
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 8.094775303034112,
    "estimated_duration": 3600.2513627193157,
    "input_throughput": 4111.241829742753,
    "output_throughput": 3606.6684494474657,
    "total_throughput": 7717.910279190219,
    "itl": 236.40261218301865,
    "ttft": 1948497.2916690572,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1196,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9021592168184056,
    "arrivals": 201527,
    "finished_requests": 59675,
    "scheduler_time": 79.94079970116807
}
#Debug simulation 
Total elapsed time: 8.094872333982494. Arrivals time: 0.2440375160658732 Scheduler time: 7.754600130021572 Scheduler overhead time: 0.02683833212358877 Adapter cache time: 0.030535426863934845 Engine time: 0.02686087938491255 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-32/adapters_320_slots_160_rate_0.4-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-32/adapters_320_slots_160_rate_0.4-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 270, 4320, 4320, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 4320, 1080, 4320, 4320, 270, 4320, 1080, 1080, 4320, 4320, 1080, 270, 270, 1080, 4320, 4320, 1080, 1080, 270, 270, 1080, 4320, 4320, 270, 4320, 1080, 270, 1080, 4320, 270, 1080, 4320, 4320, 1080, 270, 270, 4320, 270, 270, 4320, 4320, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 4320, 270, 4320, 1080, 4320, 4320, 270, 4320, 270, 4320, 1080, 270, 270, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 270, 1080, 1080, 270, 4320, 1080, 4320, 4320, 1080, 270, 1080, 1080, 1080, 270, 4320, 1080, 4320, 270, 4320, 270, 270, 1080, 4320, 4320, 1080, 270, 1080, 270, 1080, 4320, 4320, 1080, 270, 1080, 270, 4320, 270, 270, 270, 270, 4320, 1080, 1080, 4320, 1080, 1080, 270, 1080, 4320, 1080, 270, 270, 1080, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 1080, 4320, 1080, 1080, 1080, 270, 4320, 270, 4320, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 270, 270, 4320, 1080, 4320, 1080, 4320, 1080, 270, 1080, 270, 270, 270, 4320, 4320, 1080, 1080, 270, 270, 1080, 270, 4320, 270, 270, 1080, 270, 4320, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 1080, 4320, 1080, 270, 1080, 270, 4320, 1080, 1080, 4320, 4320, 270, 270, 270, 4320, 4320, 270, 270, 4320, 1080, 270, 1080, 270, 1080, 4320, 4320, 4320, 270, 4320, 4320, 4320, 4320, 270, 1080, 1080, 4320, 270, 4320, 270, 270, 270, 4320, 1080, 4320, 4320, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 4320, 270, 270, 1080, 270, 1080, 1080, 270, 4320, 4320, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 606420 . Total input tokens: 135242520 . Total output tokens: 121269682
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.793127053009812,
    "estimated_duration": 3600.026830115591,
    "input_throughput": 3629.4296172177333,
    "output_throughput": 3195.8025711798914,
    "total_throughput": 6825.232188397625,
    "itl": 158.26032072182878,
    "ttft": 2057658.1920125054,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3434,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.23250892400682,
    "arrivals": 201527,
    "finished_requests": 52763,
    "scheduler_time": 87.4048206422429
}
#Debug simulation 
Total elapsed time: 4.793241010978818. Arrivals time: 0.21593231830047444 Scheduler time: 4.410549057647586 Scheduler overhead time: 0.03556949662743136 Adapter cache time: 0.07976214721566066 Engine time: 0.035125317226629704 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-16-16/adapters_320_slots_160_rate_0.4-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-16-16/adapters_320_slots_160_rate_0.4-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 270, 4320, 4320, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 4320, 1080, 4320, 4320, 270, 4320, 1080, 1080, 4320, 4320, 1080, 270, 270, 1080, 4320, 4320, 1080, 1080, 270, 270, 1080, 4320, 4320, 270, 4320, 1080, 270, 1080, 4320, 270, 1080, 4320, 4320, 1080, 270, 270, 4320, 270, 270, 4320, 4320, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 4320, 270, 4320, 1080, 4320, 4320, 270, 4320, 270, 4320, 1080, 270, 270, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 270, 1080, 1080, 270, 4320, 1080, 4320, 4320, 1080, 270, 1080, 1080, 1080, 270, 4320, 1080, 4320, 270, 4320, 270, 270, 1080, 4320, 4320, 1080, 270, 1080, 270, 1080, 4320, 4320, 1080, 270, 1080, 270, 4320, 270, 270, 270, 270, 4320, 1080, 1080, 4320, 1080, 1080, 270, 1080, 4320, 1080, 270, 270, 1080, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 1080, 4320, 1080, 1080, 1080, 270, 4320, 270, 4320, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 270, 270, 4320, 1080, 4320, 1080, 4320, 1080, 270, 1080, 270, 270, 270, 4320, 4320, 1080, 1080, 270, 270, 1080, 270, 4320, 270, 270, 1080, 270, 4320, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 1080, 4320, 1080, 270, 1080, 270, 4320, 1080, 1080, 4320, 4320, 270, 270, 270, 4320, 4320, 270, 270, 4320, 1080, 270, 1080, 270, 1080, 4320, 4320, 4320, 270, 4320, 4320, 4320, 4320, 270, 1080, 1080, 4320, 270, 4320, 270, 270, 270, 4320, 1080, 4320, 4320, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 4320, 270, 270, 1080, 270, 1080, 1080, 270, 4320, 4320, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 606420 . Total input tokens: 135242520 . Total output tokens: 121269682
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 8.021086186985485,
    "estimated_duration": 3600.175444370509,
    "input_throughput": 4111.631288176911,
    "output_throughput": 3606.0795371237787,
    "total_throughput": 7717.71082530069,
    "itl": 236.35855658208456,
    "ttft": 1948357.0155499794,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1219,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.809126627498727,
    "arrivals": 201527,
    "finished_requests": 59671,
    "scheduler_time": 79.94156008962257
}
#Debug simulation 
Total elapsed time: 8.021208463003859. Arrivals time: 0.24145232560113072 Scheduler time: 7.683800146332942 Scheduler overhead time: 0.026542940409854054 Adapter cache time: 0.03076108288951218 Engine time: 0.02678152039879933 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-16-32/adapters_320_slots_160_rate_0.4-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-16-32/adapters_320_slots_160_rate_0.4-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 270, 4320, 4320, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 4320, 1080, 4320, 4320, 270, 4320, 1080, 1080, 4320, 4320, 1080, 270, 270, 1080, 4320, 4320, 1080, 1080, 270, 270, 1080, 4320, 4320, 270, 4320, 1080, 270, 1080, 4320, 270, 1080, 4320, 4320, 1080, 270, 270, 4320, 270, 270, 4320, 4320, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 4320, 270, 4320, 1080, 4320, 4320, 270, 4320, 270, 4320, 1080, 270, 270, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 270, 1080, 1080, 270, 4320, 1080, 4320, 4320, 1080, 270, 1080, 1080, 1080, 270, 4320, 1080, 4320, 270, 4320, 270, 270, 1080, 4320, 4320, 1080, 270, 1080, 270, 1080, 4320, 4320, 1080, 270, 1080, 270, 4320, 270, 270, 270, 270, 4320, 1080, 1080, 4320, 1080, 1080, 270, 1080, 4320, 1080, 270, 270, 1080, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 1080, 4320, 1080, 1080, 1080, 270, 4320, 270, 4320, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 270, 270, 4320, 1080, 4320, 1080, 4320, 1080, 270, 1080, 270, 270, 270, 4320, 4320, 1080, 1080, 270, 270, 1080, 270, 4320, 270, 270, 1080, 270, 4320, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 1080, 4320, 1080, 270, 1080, 270, 4320, 1080, 1080, 4320, 4320, 270, 270, 270, 4320, 4320, 270, 270, 4320, 1080, 270, 1080, 270, 1080, 4320, 4320, 4320, 270, 4320, 4320, 4320, 4320, 270, 1080, 1080, 4320, 270, 4320, 270, 270, 270, 4320, 1080, 4320, 4320, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 4320, 270, 270, 1080, 270, 1080, 1080, 270, 4320, 4320, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 606420 . Total input tokens: 135242520 . Total output tokens: 121269682
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.983066437998787,
    "estimated_duration": 3600.0660164770525,
    "input_throughput": 3628.9148421740547,
    "output_throughput": 3195.807506679742,
    "total_throughput": 6824.722348853797,
    "itl": 158.26999673840314,
    "ttft": 2057508.8716772476,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3411,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.30503278506857,
    "arrivals": 201527,
    "finished_requests": 52758,
    "scheduler_time": 87.40338176174578
}
#Debug simulation 
Total elapsed time: 4.983131897053681. Arrivals time: 0.4334510667831637 Scheduler time: 4.384964005672373 Scheduler overhead time: 0.03529856982640922 Adapter cache time: 0.07834362320136279 Engine time: 0.03497538797091693 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_16-16-16/adapters_320_slots_160_rate_0.4-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_16-16-16/adapters_320_slots_160_rate_0.4-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 270, 4320, 4320, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 4320, 1080, 4320, 4320, 270, 4320, 1080, 1080, 4320, 4320, 1080, 270, 270, 1080, 4320, 4320, 1080, 1080, 270, 270, 1080, 4320, 4320, 270, 4320, 1080, 270, 1080, 4320, 270, 1080, 4320, 4320, 1080, 270, 270, 4320, 270, 270, 4320, 4320, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 4320, 270, 4320, 1080, 4320, 4320, 270, 4320, 270, 4320, 1080, 270, 270, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 270, 1080, 1080, 270, 4320, 1080, 4320, 4320, 1080, 270, 1080, 1080, 1080, 270, 4320, 1080, 4320, 270, 4320, 270, 270, 1080, 4320, 4320, 1080, 270, 1080, 270, 1080, 4320, 4320, 1080, 270, 1080, 270, 4320, 270, 270, 270, 270, 4320, 1080, 1080, 4320, 1080, 1080, 270, 1080, 4320, 1080, 270, 270, 1080, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 1080, 4320, 1080, 1080, 1080, 270, 4320, 270, 4320, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 270, 270, 4320, 1080, 4320, 1080, 4320, 1080, 270, 1080, 270, 270, 270, 4320, 4320, 1080, 1080, 270, 270, 1080, 270, 4320, 270, 270, 1080, 270, 4320, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 1080, 4320, 1080, 270, 1080, 270, 4320, 1080, 1080, 4320, 4320, 270, 270, 270, 4320, 4320, 270, 270, 4320, 1080, 270, 1080, 270, 1080, 4320, 4320, 4320, 270, 4320, 4320, 4320, 4320, 270, 1080, 1080, 4320, 270, 4320, 270, 270, 270, 4320, 1080, 4320, 4320, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 4320, 270, 270, 1080, 270, 1080, 1080, 270, 4320, 4320, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 606420 . Total input tokens: 135242520 . Total output tokens: 121269682
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 8.270621591014788,
    "estimated_duration": 3600.21827697486,
    "input_throughput": 4112.308993786985,
    "output_throughput": 3605.098636104344,
    "total_throughput": 7717.407629891329,
    "itl": 236.34375405343354,
    "ttft": 1948780.7777967365,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1178,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5222792473946747,
    "arrivals": 201527,
    "finished_requests": 59683,
    "scheduler_time": 79.94729778089334
}
#Debug simulation 
Total elapsed time: 8.270735692000017. Arrivals time: 0.246016496559605 Scheduler time: 7.926778255612589 Scheduler overhead time: 0.02717018435942009 Adapter cache time: 0.03197372588329017 Engine time: 0.026586989173665643 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_16-16-32/adapters_320_slots_160_rate_0.4-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_16-16-32/adapters_320_slots_160_rate_0.4-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 270, 4320, 4320, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 4320, 1080, 4320, 4320, 270, 4320, 1080, 1080, 4320, 4320, 1080, 270, 270, 1080, 4320, 4320, 1080, 1080, 270, 270, 1080, 4320, 4320, 270, 4320, 1080, 270, 1080, 4320, 270, 1080, 4320, 4320, 1080, 270, 270, 4320, 270, 270, 4320, 4320, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 4320, 270, 4320, 1080, 4320, 4320, 270, 4320, 270, 4320, 1080, 270, 270, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 270, 1080, 1080, 270, 4320, 1080, 4320, 4320, 1080, 270, 1080, 1080, 1080, 270, 4320, 1080, 4320, 270, 4320, 270, 270, 1080, 4320, 4320, 1080, 270, 1080, 270, 1080, 4320, 4320, 1080, 270, 1080, 270, 4320, 270, 270, 270, 270, 4320, 1080, 1080, 4320, 1080, 1080, 270, 1080, 4320, 1080, 270, 270, 1080, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 1080, 4320, 1080, 1080, 1080, 270, 4320, 270, 4320, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 270, 270, 4320, 1080, 4320, 1080, 4320, 1080, 270, 1080, 270, 270, 270, 4320, 4320, 1080, 1080, 270, 270, 1080, 270, 4320, 270, 270, 1080, 270, 4320, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 1080, 4320, 1080, 270, 1080, 270, 4320, 1080, 1080, 4320, 4320, 270, 270, 270, 4320, 4320, 270, 270, 4320, 1080, 270, 1080, 270, 1080, 4320, 4320, 4320, 270, 4320, 4320, 4320, 4320, 270, 1080, 1080, 4320, 270, 4320, 270, 270, 270, 4320, 1080, 4320, 4320, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 4320, 270, 270, 1080, 270, 1080, 1080, 270, 4320, 4320, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 606420 . Total input tokens: 135242520 . Total output tokens: 121269682
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.761647040955722,
    "estimated_duration": 3600.162777404855,
    "input_throughput": 3628.0881747839785,
    "output_throughput": 3194.8658188980944,
    "total_throughput": 6822.953993682073,
    "itl": 158.20517423877544,
    "ttft": 2058107.6128177934,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3456,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.59256411313942,
    "arrivals": 201527,
    "finished_requests": 52753,
    "scheduler_time": 87.41025381001913
}
#Debug simulation 
Total elapsed time: 4.761739949986804. Arrivals time: 0.210845883237198 Scheduler time: 4.384070506552234 Scheduler overhead time: 0.03537407278781757 Adapter cache time: 0.08038945466978475 Engine time: 0.03495032154023647 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-8/adapters_320_slots_160_rate_0.4-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-8/adapters_320_slots_160_rate_0.4-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 135, 4320, 4320, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 4320, 1080, 4320, 4320, 135, 4320, 1080, 1080, 4320, 4320, 1080, 135, 135, 1080, 4320, 4320, 1080, 1080, 135, 135, 1080, 4320, 4320, 135, 4320, 1080, 135, 1080, 4320, 135, 1080, 4320, 4320, 1080, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 4320, 135, 4320, 1080, 4320, 4320, 135, 4320, 135, 4320, 1080, 135, 135, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 135, 1080, 1080, 135, 4320, 1080, 4320, 4320, 1080, 135, 1080, 1080, 1080, 135, 4320, 1080, 4320, 135, 4320, 135, 135, 1080, 4320, 4320, 1080, 135, 1080, 135, 1080, 4320, 4320, 1080, 135, 1080, 135, 4320, 135, 135, 135, 135, 4320, 1080, 1080, 4320, 1080, 1080, 135, 1080, 4320, 1080, 135, 135, 1080, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 1080, 4320, 1080, 1080, 1080, 135, 4320, 135, 4320, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 135, 135, 4320, 1080, 4320, 1080, 4320, 1080, 135, 1080, 135, 135, 135, 4320, 4320, 1080, 1080, 135, 135, 1080, 135, 4320, 135, 135, 1080, 135, 4320, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 1080, 4320, 1080, 135, 1080, 135, 4320, 1080, 1080, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 1080, 135, 1080, 135, 1080, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 1080, 1080, 4320, 135, 4320, 135, 135, 135, 4320, 1080, 4320, 4320, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 4320, 135, 135, 1080, 135, 1080, 1080, 135, 4320, 4320, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 592110 . Total input tokens: 132043575 . Total output tokens: 118419472
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 7.030997305002529,
    "estimated_duration": 3600.0031430982217,
    "input_throughput": 4067.272837822771,
    "output_throughput": 3609.572404099832,
    "total_throughput": 7676.845241922603,
    "itl": 237.52221740791316,
    "ttft": 1943141.5864592143,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1166,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.568528709425679,
    "arrivals": 196873,
    "finished_requests": 59491,
    "scheduler_time": 79.78860647668041
}
#Debug simulation 
Total elapsed time: 7.031096708029509. Arrivals time: 0.23432308057090268 Scheduler time: 6.702854458882939 Scheduler overhead time: 0.026089220074936748 Adapter cache time: 0.029917568899691105 Engine time: 0.026164175593294203 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-16/adapters_320_slots_160_rate_0.4-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-16/adapters_320_slots_160_rate_0.4-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 135, 4320, 4320, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 4320, 1080, 4320, 4320, 135, 4320, 1080, 1080, 4320, 4320, 1080, 135, 135, 1080, 4320, 4320, 1080, 1080, 135, 135, 1080, 4320, 4320, 135, 4320, 1080, 135, 1080, 4320, 135, 1080, 4320, 4320, 1080, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 4320, 135, 4320, 1080, 4320, 4320, 135, 4320, 135, 4320, 1080, 135, 135, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 135, 1080, 1080, 135, 4320, 1080, 4320, 4320, 1080, 135, 1080, 1080, 1080, 135, 4320, 1080, 4320, 135, 4320, 135, 135, 1080, 4320, 4320, 1080, 135, 1080, 135, 1080, 4320, 4320, 1080, 135, 1080, 135, 4320, 135, 135, 135, 135, 4320, 1080, 1080, 4320, 1080, 1080, 135, 1080, 4320, 1080, 135, 135, 1080, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 1080, 4320, 1080, 1080, 1080, 135, 4320, 135, 4320, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 135, 135, 4320, 1080, 4320, 1080, 4320, 1080, 135, 1080, 135, 135, 135, 4320, 4320, 1080, 1080, 135, 135, 1080, 135, 4320, 135, 135, 1080, 135, 4320, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 1080, 4320, 1080, 135, 1080, 135, 4320, 1080, 1080, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 1080, 135, 1080, 135, 1080, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 1080, 1080, 4320, 135, 4320, 135, 135, 135, 4320, 1080, 4320, 4320, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 4320, 135, 135, 1080, 135, 1080, 1080, 135, 4320, 4320, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 592110 . Total input tokens: 132043575 . Total output tokens: 118419472
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 7.003222249972168,
    "estimated_duration": 3600.12270573293,
    "input_throughput": 4067.5046927376334,
    "output_throughput": 3609.056985560389,
    "total_throughput": 7676.561678298022,
    "itl": 237.5361950693535,
    "ttft": 1943190.3864075649,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1181,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.8540396998473514,
    "arrivals": 196873,
    "finished_requests": 59475,
    "scheduler_time": 79.78740365061117
}
#Debug simulation 
Total elapsed time: 7.003319686977193. Arrivals time: 0.2418027623789385 Scheduler time: 6.667924159846734 Scheduler overhead time: 0.025778360606636852 Adapter cache time: 0.030028612061869353 Engine time: 0.02603538567200303 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-32/adapters_320_slots_160_rate_0.4-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-32/adapters_320_slots_160_rate_0.4-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 135, 4320, 4320, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 4320, 1080, 4320, 4320, 135, 4320, 1080, 1080, 4320, 4320, 1080, 135, 135, 1080, 4320, 4320, 1080, 1080, 135, 135, 1080, 4320, 4320, 135, 4320, 1080, 135, 1080, 4320, 135, 1080, 4320, 4320, 1080, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 4320, 135, 4320, 1080, 4320, 4320, 135, 4320, 135, 4320, 1080, 135, 135, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 135, 1080, 1080, 135, 4320, 1080, 4320, 4320, 1080, 135, 1080, 1080, 1080, 135, 4320, 1080, 4320, 135, 4320, 135, 135, 1080, 4320, 4320, 1080, 135, 1080, 135, 1080, 4320, 4320, 1080, 135, 1080, 135, 4320, 135, 135, 135, 135, 4320, 1080, 1080, 4320, 1080, 1080, 135, 1080, 4320, 1080, 135, 135, 1080, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 1080, 4320, 1080, 1080, 1080, 135, 4320, 135, 4320, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 135, 135, 4320, 1080, 4320, 1080, 4320, 1080, 135, 1080, 135, 135, 135, 4320, 4320, 1080, 1080, 135, 135, 1080, 135, 4320, 135, 135, 1080, 135, 4320, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 1080, 4320, 1080, 135, 1080, 135, 4320, 1080, 1080, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 1080, 135, 1080, 135, 1080, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 1080, 1080, 4320, 135, 4320, 135, 135, 135, 4320, 1080, 4320, 4320, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 4320, 135, 135, 1080, 135, 1080, 1080, 135, 4320, 4320, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 592110 . Total input tokens: 132043575 . Total output tokens: 118419472
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.5140204089693725,
    "estimated_duration": 3600.0503445066456,
    "input_throughput": 3596.639702485721,
    "output_throughput": 3197.5938940869305,
    "total_throughput": 6794.233596572652,
    "itl": 158.48419496292655,
    "ttft": 2052030.5222765363,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3285,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.74159014364653,
    "arrivals": 196873,
    "finished_requests": 52511,
    "scheduler_time": 87.29089088037094
}
#Debug simulation 
Total elapsed time: 4.5141512749833055. Arrivals time: 0.20252300065476447 Scheduler time: 4.149011715315282 Scheduler overhead time: 0.035260578559245914 Adapter cache time: 0.07615548395551741 Engine time: 0.03503558289958164 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-16/adapters_320_slots_160_rate_0.4-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-16/adapters_320_slots_160_rate_0.4-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 135, 4320, 4320, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 4320, 1080, 4320, 4320, 135, 4320, 1080, 1080, 4320, 4320, 1080, 135, 135, 1080, 4320, 4320, 1080, 1080, 135, 135, 1080, 4320, 4320, 135, 4320, 1080, 135, 1080, 4320, 135, 1080, 4320, 4320, 1080, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 4320, 135, 4320, 1080, 4320, 4320, 135, 4320, 135, 4320, 1080, 135, 135, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 135, 1080, 1080, 135, 4320, 1080, 4320, 4320, 1080, 135, 1080, 1080, 1080, 135, 4320, 1080, 4320, 135, 4320, 135, 135, 1080, 4320, 4320, 1080, 135, 1080, 135, 1080, 4320, 4320, 1080, 135, 1080, 135, 4320, 135, 135, 135, 135, 4320, 1080, 1080, 4320, 1080, 1080, 135, 1080, 4320, 1080, 135, 135, 1080, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 1080, 4320, 1080, 1080, 1080, 135, 4320, 135, 4320, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 135, 135, 4320, 1080, 4320, 1080, 4320, 1080, 135, 1080, 135, 135, 135, 4320, 4320, 1080, 1080, 135, 135, 1080, 135, 4320, 135, 135, 1080, 135, 4320, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 1080, 4320, 1080, 135, 1080, 135, 4320, 1080, 1080, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 1080, 135, 1080, 135, 1080, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 1080, 1080, 4320, 135, 4320, 135, 135, 135, 4320, 1080, 4320, 4320, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 4320, 135, 135, 1080, 135, 1080, 1080, 135, 4320, 4320, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 592110 . Total input tokens: 132043575 . Total output tokens: 118419472
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 6.9486077319597825,
    "estimated_duration": 3600.193717715839,
    "input_throughput": 4067.8986044372455,
    "output_throughput": 3608.573876475337,
    "total_throughput": 7676.472480912583,
    "itl": 237.52054713069222,
    "ttft": 1943013.2983490233,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1183,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.694947291787205,
    "arrivals": 196873,
    "finished_requests": 59484,
    "scheduler_time": 79.79142375711862
}
#Debug simulation 
Total elapsed time: 6.948728257964831. Arrivals time: 0.2316527453949675 Scheduler time: 6.623343769519124 Scheduler overhead time: 0.02601942466571927 Adapter cache time: 0.029814729641657323 Engine time: 0.02622113679535687 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-32/adapters_320_slots_160_rate_0.4-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-32/adapters_320_slots_160_rate_0.4-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 135, 4320, 4320, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 4320, 1080, 4320, 4320, 135, 4320, 1080, 1080, 4320, 4320, 1080, 135, 135, 1080, 4320, 4320, 1080, 1080, 135, 135, 1080, 4320, 4320, 135, 4320, 1080, 135, 1080, 4320, 135, 1080, 4320, 4320, 1080, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 4320, 135, 4320, 1080, 4320, 4320, 135, 4320, 135, 4320, 1080, 135, 135, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 135, 1080, 1080, 135, 4320, 1080, 4320, 4320, 1080, 135, 1080, 1080, 1080, 135, 4320, 1080, 4320, 135, 4320, 135, 135, 1080, 4320, 4320, 1080, 135, 1080, 135, 1080, 4320, 4320, 1080, 135, 1080, 135, 4320, 135, 135, 135, 135, 4320, 1080, 1080, 4320, 1080, 1080, 135, 1080, 4320, 1080, 135, 135, 1080, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 1080, 4320, 1080, 1080, 1080, 135, 4320, 135, 4320, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 135, 135, 4320, 1080, 4320, 1080, 4320, 1080, 135, 1080, 135, 135, 135, 4320, 4320, 1080, 1080, 135, 135, 1080, 135, 4320, 135, 135, 1080, 135, 4320, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 1080, 4320, 1080, 135, 1080, 135, 4320, 1080, 1080, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 1080, 135, 1080, 135, 1080, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 1080, 1080, 4320, 135, 4320, 135, 135, 135, 4320, 1080, 4320, 4320, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 4320, 135, 135, 1080, 135, 1080, 1080, 135, 4320, 4320, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 592110 . Total input tokens: 132043575 . Total output tokens: 118419472
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.518269013031386,
    "estimated_duration": 3600.1294007344404,
    "input_throughput": 3597.318473429867,
    "output_throughput": 3197.552009561542,
    "total_throughput": 6794.8704829914095,
    "itl": 158.4752949338843,
    "ttft": 2052412.0690786317,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3302,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.938558422289207,
    "arrivals": 196873,
    "finished_requests": 52519,
    "scheduler_time": 87.28873599092849
}
#Debug simulation 
Total elapsed time: 4.518361477996223. Arrivals time: 0.1983135551563464 Scheduler time: 4.155812738579698 Scheduler overhead time: 0.035138162318617105 Adapter cache time: 0.07774182298453525 Engine time: 0.03504664055071771 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-16/adapters_320_slots_160_rate_0.4-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-16/adapters_320_slots_160_rate_0.4-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 135, 4320, 4320, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 4320, 1080, 4320, 4320, 135, 4320, 1080, 1080, 4320, 4320, 1080, 135, 135, 1080, 4320, 4320, 1080, 1080, 135, 135, 1080, 4320, 4320, 135, 4320, 1080, 135, 1080, 4320, 135, 1080, 4320, 4320, 1080, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 4320, 135, 4320, 1080, 4320, 4320, 135, 4320, 135, 4320, 1080, 135, 135, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 135, 1080, 1080, 135, 4320, 1080, 4320, 4320, 1080, 135, 1080, 1080, 1080, 135, 4320, 1080, 4320, 135, 4320, 135, 135, 1080, 4320, 4320, 1080, 135, 1080, 135, 1080, 4320, 4320, 1080, 135, 1080, 135, 4320, 135, 135, 135, 135, 4320, 1080, 1080, 4320, 1080, 1080, 135, 1080, 4320, 1080, 135, 135, 1080, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 1080, 4320, 1080, 1080, 1080, 135, 4320, 135, 4320, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 135, 135, 4320, 1080, 4320, 1080, 4320, 1080, 135, 1080, 135, 135, 135, 4320, 4320, 1080, 1080, 135, 135, 1080, 135, 4320, 135, 135, 1080, 135, 4320, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 1080, 4320, 1080, 135, 1080, 135, 4320, 1080, 1080, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 1080, 135, 1080, 135, 1080, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 1080, 1080, 4320, 135, 4320, 135, 135, 135, 4320, 1080, 4320, 4320, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 4320, 135, 135, 1080, 135, 1080, 1080, 135, 4320, 4320, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 592110 . Total input tokens: 132043575 . Total output tokens: 118419472
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 7.00386089499807,
    "estimated_duration": 3600.0483752290775,
    "input_throughput": 4067.5864526593223,
    "output_throughput": 3610.4075960293,
    "total_throughput": 7677.994048688622,
    "itl": 237.53502856052546,
    "ttft": 1942736.9381435441,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1170,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.498358845035458,
    "arrivals": 196873,
    "finished_requests": 59498,
    "scheduler_time": 79.7914691078956
}
#Debug simulation 
Total elapsed time: 7.003978257998824. Arrivals time: 0.2397735146805644 Scheduler time: 6.670821498613805 Scheduler overhead time: 0.025960789702367038 Adapter cache time: 0.029657097184099257 Engine time: 0.026005757390521467 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-32/adapters_320_slots_160_rate_0.4-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-32/adapters_320_slots_160_rate_0.4-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 135, 4320, 4320, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 4320, 1080, 4320, 4320, 135, 4320, 1080, 1080, 4320, 4320, 1080, 135, 135, 1080, 4320, 4320, 1080, 1080, 135, 135, 1080, 4320, 4320, 135, 4320, 1080, 135, 1080, 4320, 135, 1080, 4320, 4320, 1080, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 4320, 135, 4320, 1080, 4320, 4320, 135, 4320, 135, 4320, 1080, 135, 135, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 135, 1080, 1080, 135, 4320, 1080, 4320, 4320, 1080, 135, 1080, 1080, 1080, 135, 4320, 1080, 4320, 135, 4320, 135, 135, 1080, 4320, 4320, 1080, 135, 1080, 135, 1080, 4320, 4320, 1080, 135, 1080, 135, 4320, 135, 135, 135, 135, 4320, 1080, 1080, 4320, 1080, 1080, 135, 1080, 4320, 1080, 135, 135, 1080, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 1080, 4320, 1080, 1080, 1080, 135, 4320, 135, 4320, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 135, 135, 4320, 1080, 4320, 1080, 4320, 1080, 135, 1080, 135, 135, 135, 4320, 4320, 1080, 1080, 135, 135, 1080, 135, 4320, 135, 135, 1080, 135, 4320, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 1080, 4320, 1080, 135, 1080, 135, 4320, 1080, 1080, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 1080, 135, 1080, 135, 1080, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 1080, 1080, 4320, 135, 4320, 135, 135, 135, 4320, 1080, 4320, 4320, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 4320, 135, 135, 1080, 135, 1080, 1080, 135, 4320, 4320, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 592110 . Total input tokens: 132043575 . Total output tokens: 118419472
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.499289564031642,
    "estimated_duration": 3600.007603021988,
    "input_throughput": 3597.0574031926308,
    "output_throughput": 3197.737690980562,
    "total_throughput": 6794.795094173193,
    "itl": 158.50439915617085,
    "ttft": 2052260.997791936,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3285,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.015173232442999,
    "arrivals": 196873,
    "finished_requests": 52519,
    "scheduler_time": 87.28194244980529
}
#Debug simulation 
Total elapsed time: 4.499408928037155. Arrivals time: 0.19939118745969608 Scheduler time: 4.135325194394682 Scheduler overhead time: 0.035061479546129704 Adapter cache time: 0.07852404663572088 Engine time: 0.03502907004440203 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-8/adapters_320_slots_160_rate_0.4-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-8/adapters_320_slots_160_rate_0.4-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 66, 4320, 4320, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 4320, 4320, 1080, 66, 66, 1080, 4320, 4320, 1080, 1080, 66, 66, 1080, 4320, 4320, 66, 4320, 1080, 66, 1080, 4320, 66, 1080, 4320, 4320, 1080, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 4320, 66, 4320, 1080, 4320, 4320, 66, 4320, 66, 4320, 1080, 66, 66, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 66, 1080, 1080, 66, 4320, 1080, 4320, 4320, 1080, 66, 1080, 1080, 1080, 66, 4320, 1080, 4320, 66, 4320, 66, 66, 1080, 4320, 4320, 1080, 66, 1080, 66, 1080, 4320, 4320, 1080, 66, 1080, 66, 4320, 66, 66, 66, 66, 4320, 1080, 1080, 4320, 1080, 1080, 66, 1080, 4320, 1080, 66, 66, 1080, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 1080, 4320, 1080, 1080, 1080, 66, 4320, 66, 4320, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 66, 66, 4320, 1080, 4320, 1080, 4320, 1080, 66, 1080, 66, 66, 66, 4320, 4320, 1080, 1080, 66, 66, 1080, 66, 4320, 66, 66, 1080, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 1080, 1080, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 1080, 66, 1080, 66, 1080, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 1080, 1080, 4320, 66, 4320, 66, 66, 66, 4320, 1080, 4320, 4320, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 4320, 66, 66, 1080, 66, 1080, 1080, 66, 4320, 4320, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 584796 . Total input tokens: 130396952 . Total output tokens: 116962797
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 6.213920466019772,
    "estimated_duration": 3600.0066209908377,
    "input_throughput": 4080.9249945091674,
    "output_throughput": 3606.087256702587,
    "total_throughput": 7687.012251211754,
    "itl": 237.12394592245613,
    "ttft": 1938760.8113614414,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1157,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.540984319730283,
    "arrivals": 194481,
    "finished_requests": 59484,
    "scheduler_time": 79.74710474697648
}
#Debug simulation 
Total elapsed time: 6.214062797022052. Arrivals time: 0.22661438334034756 Scheduler time: 5.895131335710175 Scheduler overhead time: 0.02557609771611169 Adapter cache time: 0.02939869515830651 Engine time: 0.02567963016917929 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-16/adapters_320_slots_160_rate_0.4-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-16/adapters_320_slots_160_rate_0.4-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 66, 4320, 4320, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 4320, 4320, 1080, 66, 66, 1080, 4320, 4320, 1080, 1080, 66, 66, 1080, 4320, 4320, 66, 4320, 1080, 66, 1080, 4320, 66, 1080, 4320, 4320, 1080, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 4320, 66, 4320, 1080, 4320, 4320, 66, 4320, 66, 4320, 1080, 66, 66, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 66, 1080, 1080, 66, 4320, 1080, 4320, 4320, 1080, 66, 1080, 1080, 1080, 66, 4320, 1080, 4320, 66, 4320, 66, 66, 1080, 4320, 4320, 1080, 66, 1080, 66, 1080, 4320, 4320, 1080, 66, 1080, 66, 4320, 66, 66, 66, 66, 4320, 1080, 1080, 4320, 1080, 1080, 66, 1080, 4320, 1080, 66, 66, 1080, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 1080, 4320, 1080, 1080, 1080, 66, 4320, 66, 4320, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 66, 66, 4320, 1080, 4320, 1080, 4320, 1080, 66, 1080, 66, 66, 66, 4320, 4320, 1080, 1080, 66, 66, 1080, 66, 4320, 66, 66, 1080, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 1080, 1080, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 1080, 66, 1080, 66, 1080, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 1080, 1080, 4320, 66, 4320, 66, 66, 66, 4320, 1080, 4320, 4320, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 4320, 66, 66, 1080, 66, 1080, 1080, 66, 4320, 4320, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 584796 . Total input tokens: 130396952 . Total output tokens: 116962797
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 6.508703033032361,
    "estimated_duration": 3600.2002952210382,
    "input_throughput": 4080.705459499444,
    "output_throughput": 3605.893265780914,
    "total_throughput": 7686.598725280358,
    "itl": 237.13920126174344,
    "ttft": 1938839.8218838423,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1157,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.777783944266854,
    "arrivals": 194481,
    "finished_requests": 59484,
    "scheduler_time": 79.74707544172286
}
#Debug simulation 
Total elapsed time: 6.50876832701033. Arrivals time: 0.4690563338226639 Scheduler time: 5.9476635593455285 Scheduler overhead time: 0.025798347836825997 Adapter cache time: 0.028804276720620692 Engine time: 0.02579829579917714 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-32/adapters_320_slots_160_rate_0.4-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-32/adapters_320_slots_160_rate_0.4-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 66, 4320, 4320, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 4320, 4320, 1080, 66, 66, 1080, 4320, 4320, 1080, 1080, 66, 66, 1080, 4320, 4320, 66, 4320, 1080, 66, 1080, 4320, 66, 1080, 4320, 4320, 1080, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 4320, 66, 4320, 1080, 4320, 4320, 66, 4320, 66, 4320, 1080, 66, 66, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 66, 1080, 1080, 66, 4320, 1080, 4320, 4320, 1080, 66, 1080, 1080, 1080, 66, 4320, 1080, 4320, 66, 4320, 66, 66, 1080, 4320, 4320, 1080, 66, 1080, 66, 1080, 4320, 4320, 1080, 66, 1080, 66, 4320, 66, 66, 66, 66, 4320, 1080, 1080, 4320, 1080, 1080, 66, 1080, 4320, 1080, 66, 66, 1080, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 1080, 4320, 1080, 1080, 1080, 66, 4320, 66, 4320, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 66, 66, 4320, 1080, 4320, 1080, 4320, 1080, 66, 1080, 66, 66, 66, 4320, 4320, 1080, 1080, 66, 66, 1080, 66, 4320, 66, 66, 1080, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 1080, 1080, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 1080, 66, 1080, 66, 1080, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 1080, 1080, 4320, 66, 4320, 66, 66, 66, 4320, 1080, 4320, 4320, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 4320, 66, 66, 1080, 66, 1080, 1080, 66, 4320, 4320, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 584796 . Total input tokens: 130396952 . Total output tokens: 116962797
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.3633297710330226,
    "estimated_duration": 3600.0948953919715,
    "input_throughput": 3605.095803616839,
    "output_throughput": 3198.46763337784,
    "total_throughput": 6803.563436994678,
    "itl": 158.20930837895844,
    "ttft": 2047764.8480069835,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3136,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.254718333221545,
    "arrivals": 194481,
    "finished_requests": 52565,
    "scheduler_time": 87.22057692666522
}
#Debug simulation 
Total elapsed time: 4.363428898039274. Arrivals time: 0.19864458835218102 Scheduler time: 4.003320143034216 Scheduler overhead time: 0.034890747687313706 Adapter cache time: 0.07555039844010025 Engine time: 0.03495020105037838 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-16/adapters_320_slots_160_rate_0.4-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-16/adapters_320_slots_160_rate_0.4-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 66, 4320, 4320, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 4320, 4320, 1080, 66, 66, 1080, 4320, 4320, 1080, 1080, 66, 66, 1080, 4320, 4320, 66, 4320, 1080, 66, 1080, 4320, 66, 1080, 4320, 4320, 1080, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 4320, 66, 4320, 1080, 4320, 4320, 66, 4320, 66, 4320, 1080, 66, 66, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 66, 1080, 1080, 66, 4320, 1080, 4320, 4320, 1080, 66, 1080, 1080, 1080, 66, 4320, 1080, 4320, 66, 4320, 66, 66, 1080, 4320, 4320, 1080, 66, 1080, 66, 1080, 4320, 4320, 1080, 66, 1080, 66, 4320, 66, 66, 66, 66, 4320, 1080, 1080, 4320, 1080, 1080, 66, 1080, 4320, 1080, 66, 66, 1080, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 1080, 4320, 1080, 1080, 1080, 66, 4320, 66, 4320, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 66, 66, 4320, 1080, 4320, 1080, 4320, 1080, 66, 1080, 66, 66, 66, 4320, 4320, 1080, 1080, 66, 66, 1080, 66, 4320, 66, 66, 1080, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 1080, 1080, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 1080, 66, 1080, 66, 1080, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 1080, 1080, 4320, 66, 4320, 66, 66, 66, 4320, 1080, 4320, 4320, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 4320, 66, 66, 1080, 66, 1080, 1080, 66, 4320, 4320, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 584796 . Total input tokens: 130396952 . Total output tokens: 116962797
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 6.238540521997493,
    "estimated_duration": 3600.014152348415,
    "input_throughput": 4081.5758989210544,
    "output_throughput": 3606.499710988759,
    "total_throughput": 7688.0756099098135,
    "itl": 237.13619064036484,
    "ttft": 1938782.175300781,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1158,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.6173358671855693,
    "arrivals": 194481,
    "finished_requests": 59483,
    "scheduler_time": 79.74608876897636
}
#Debug simulation 
Total elapsed time: 6.238635796995368. Arrivals time: 0.2271405010833405 Scheduler time: 5.918983656680211 Scheduler overhead time: 0.025816228764597327 Adapter cache time: 0.029133923817425966 Engine time: 0.025887006195262074 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-32/adapters_320_slots_160_rate_0.4-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-32/adapters_320_slots_160_rate_0.4-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 66, 4320, 4320, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 4320, 4320, 1080, 66, 66, 1080, 4320, 4320, 1080, 1080, 66, 66, 1080, 4320, 4320, 66, 4320, 1080, 66, 1080, 4320, 66, 1080, 4320, 4320, 1080, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 4320, 66, 4320, 1080, 4320, 4320, 66, 4320, 66, 4320, 1080, 66, 66, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 66, 1080, 1080, 66, 4320, 1080, 4320, 4320, 1080, 66, 1080, 1080, 1080, 66, 4320, 1080, 4320, 66, 4320, 66, 66, 1080, 4320, 4320, 1080, 66, 1080, 66, 1080, 4320, 4320, 1080, 66, 1080, 66, 4320, 66, 66, 66, 66, 4320, 1080, 1080, 4320, 1080, 1080, 66, 1080, 4320, 1080, 66, 66, 1080, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 1080, 4320, 1080, 1080, 1080, 66, 4320, 66, 4320, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 66, 66, 4320, 1080, 4320, 1080, 4320, 1080, 66, 1080, 66, 66, 66, 4320, 4320, 1080, 1080, 66, 66, 1080, 66, 4320, 66, 66, 1080, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 1080, 1080, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 1080, 66, 1080, 66, 1080, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 1080, 1080, 4320, 66, 4320, 66, 66, 66, 4320, 1080, 4320, 4320, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 4320, 66, 66, 1080, 66, 1080, 1080, 66, 4320, 4320, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 584796 . Total input tokens: 130396952 . Total output tokens: 116962797
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.309357698017266,
    "estimated_duration": 3600.13933204339,
    "input_throughput": 3607.0017858529627,
    "output_throughput": 3200.484186110698,
    "total_throughput": 6807.485971963661,
    "itl": 158.50351303350266,
    "ttft": 2047701.0570422073,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3220,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.672258967942941,
    "arrivals": 194481,
    "finished_requests": 52591,
    "scheduler_time": 87.16719306014063
}
#Debug simulation 
Total elapsed time: 4.309453118010424. Arrivals time: 0.19787589507177472 Scheduler time: 3.9492459434550256 Scheduler overhead time: 0.03480448870686814 Adapter cache time: 0.07659970922395587 Engine time: 0.03492178628221154 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-16/adapters_320_slots_160_rate_0.4-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-16/adapters_320_slots_160_rate_0.4-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 66, 4320, 4320, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 4320, 4320, 1080, 66, 66, 1080, 4320, 4320, 1080, 1080, 66, 66, 1080, 4320, 4320, 66, 4320, 1080, 66, 1080, 4320, 66, 1080, 4320, 4320, 1080, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 4320, 66, 4320, 1080, 4320, 4320, 66, 4320, 66, 4320, 1080, 66, 66, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 66, 1080, 1080, 66, 4320, 1080, 4320, 4320, 1080, 66, 1080, 1080, 1080, 66, 4320, 1080, 4320, 66, 4320, 66, 66, 1080, 4320, 4320, 1080, 66, 1080, 66, 1080, 4320, 4320, 1080, 66, 1080, 66, 4320, 66, 66, 66, 66, 4320, 1080, 1080, 4320, 1080, 1080, 66, 1080, 4320, 1080, 66, 66, 1080, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 1080, 4320, 1080, 1080, 1080, 66, 4320, 66, 4320, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 66, 66, 4320, 1080, 4320, 1080, 4320, 1080, 66, 1080, 66, 66, 66, 4320, 4320, 1080, 1080, 66, 66, 1080, 66, 4320, 66, 66, 1080, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 1080, 1080, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 1080, 66, 1080, 66, 1080, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 1080, 1080, 4320, 66, 4320, 66, 66, 66, 4320, 1080, 4320, 4320, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 4320, 66, 66, 1080, 66, 1080, 1080, 66, 4320, 4320, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 584796 . Total input tokens: 130396952 . Total output tokens: 116962797
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 6.236653761006892,
    "estimated_duration": 3600.0033626284744,
    "input_throughput": 4081.330076667575,
    "output_throughput": 3605.7744097556383,
    "total_throughput": 7687.1044864232135,
    "itl": 237.12719318460378,
    "ttft": 1938699.5468232816,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1154,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.450518040317025,
    "arrivals": 194481,
    "finished_requests": 59482,
    "scheduler_time": 79.74872428908122
}
#Debug simulation 
Total elapsed time: 6.236778735008556. Arrivals time: 0.2297536430414766 Scheduler time: 5.914102288486902 Scheduler overhead time: 0.025838801986537874 Adapter cache time: 0.029150945716537535 Engine time: 0.02617340919096023 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-32/adapters_320_slots_160_rate_0.4-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-32/adapters_320_slots_160_rate_0.4-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 66, 4320, 4320, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 4320, 4320, 1080, 66, 66, 1080, 4320, 4320, 1080, 1080, 66, 66, 1080, 4320, 4320, 66, 4320, 1080, 66, 1080, 4320, 66, 1080, 4320, 4320, 1080, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 4320, 66, 4320, 1080, 4320, 4320, 66, 4320, 66, 4320, 1080, 66, 66, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 66, 1080, 1080, 66, 4320, 1080, 4320, 4320, 1080, 66, 1080, 1080, 1080, 66, 4320, 1080, 4320, 66, 4320, 66, 66, 1080, 4320, 4320, 1080, 66, 1080, 66, 1080, 4320, 4320, 1080, 66, 1080, 66, 4320, 66, 66, 66, 66, 4320, 1080, 1080, 4320, 1080, 1080, 66, 1080, 4320, 1080, 66, 66, 1080, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 1080, 4320, 1080, 1080, 1080, 66, 4320, 66, 4320, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 66, 66, 4320, 1080, 4320, 1080, 4320, 1080, 66, 1080, 66, 66, 66, 4320, 4320, 1080, 1080, 66, 66, 1080, 66, 4320, 66, 66, 1080, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 1080, 1080, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 1080, 66, 1080, 66, 1080, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 1080, 1080, 4320, 66, 4320, 66, 66, 66, 4320, 1080, 4320, 4320, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 4320, 66, 66, 1080, 66, 1080, 1080, 66, 4320, 4320, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 584796 . Total input tokens: 130396952 . Total output tokens: 116962797
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.526954703964293,
    "estimated_duration": 3600.1463621731154,
    "input_throughput": 3604.8831615185145,
    "output_throughput": 3198.326079456855,
    "total_throughput": 6803.2092409753695,
    "itl": 158.27467951322208,
    "ttft": 2048000.8247042275,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3209,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.767660755104712,
    "arrivals": 194481,
    "finished_requests": 52562,
    "scheduler_time": 87.20343497890669
}
#Debug simulation 
Total elapsed time: 4.527021341957152. Arrivals time: 0.1999454812030308 Scheduler time: 4.166237734258175 Scheduler overhead time: 0.03461806511040777 Adapter cache time: 0.0753232782590203 Engine time: 0.03478437993908301 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-8/adapters_320_slots_160_rate_0.4-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-8/adapters_320_slots_160_rate_0.4-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 33, 4320, 4320, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 4320, 4320, 1080, 33, 33, 1080, 4320, 4320, 1080, 1080, 33, 33, 1080, 4320, 4320, 33, 4320, 1080, 33, 1080, 4320, 33, 1080, 4320, 4320, 1080, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 4320, 33, 4320, 1080, 4320, 4320, 33, 4320, 33, 4320, 1080, 33, 33, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 33, 1080, 1080, 33, 4320, 1080, 4320, 4320, 1080, 33, 1080, 1080, 1080, 33, 4320, 1080, 4320, 33, 4320, 33, 33, 1080, 4320, 4320, 1080, 33, 1080, 33, 1080, 4320, 4320, 1080, 33, 1080, 33, 4320, 33, 33, 33, 33, 4320, 1080, 1080, 4320, 1080, 1080, 33, 1080, 4320, 1080, 33, 33, 1080, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 1080, 4320, 1080, 1080, 1080, 33, 4320, 33, 4320, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 33, 33, 4320, 1080, 4320, 1080, 4320, 1080, 33, 1080, 33, 33, 33, 4320, 4320, 1080, 1080, 33, 33, 1080, 33, 4320, 33, 33, 1080, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 1080, 1080, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 1080, 33, 1080, 33, 1080, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 1080, 1080, 4320, 33, 4320, 33, 33, 33, 4320, 1080, 4320, 4320, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 4320, 33, 33, 1080, 33, 1080, 1080, 33, 4320, 4320, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 581298 . Total input tokens: 129613956 . Total output tokens: 116260811
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 6.230374610982835,
    "estimated_duration": 3600.1797194161973,
    "input_throughput": 4109.697890970636,
    "output_throughput": 3604.1664614743518,
    "total_throughput": 7713.864352444987,
    "itl": 236.26616782386708,
    "ttft": 1934202.9079126215,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1062,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2502379840566613,
    "arrivals": 193337,
    "finished_requests": 59566,
    "scheduler_time": 79.7316587567108
}
#Debug simulation 
Total elapsed time: 6.230471851013135. Arrivals time: 0.23466626537265256 Scheduler time: 5.9045711980434135 Scheduler overhead time: 0.025679276848677546 Adapter cache time: 0.028171496407594532 Engine time: 0.025737234100233763 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-16/adapters_320_slots_160_rate_0.4-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-16/adapters_320_slots_160_rate_0.4-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 33, 4320, 4320, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 4320, 4320, 1080, 33, 33, 1080, 4320, 4320, 1080, 1080, 33, 33, 1080, 4320, 4320, 33, 4320, 1080, 33, 1080, 4320, 33, 1080, 4320, 4320, 1080, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 4320, 33, 4320, 1080, 4320, 4320, 33, 4320, 33, 4320, 1080, 33, 33, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 33, 1080, 1080, 33, 4320, 1080, 4320, 4320, 1080, 33, 1080, 1080, 1080, 33, 4320, 1080, 4320, 33, 4320, 33, 33, 1080, 4320, 4320, 1080, 33, 1080, 33, 1080, 4320, 4320, 1080, 33, 1080, 33, 4320, 33, 33, 33, 33, 4320, 1080, 1080, 4320, 1080, 1080, 33, 1080, 4320, 1080, 33, 33, 1080, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 1080, 4320, 1080, 1080, 1080, 33, 4320, 33, 4320, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 33, 33, 4320, 1080, 4320, 1080, 4320, 1080, 33, 1080, 33, 33, 33, 4320, 4320, 1080, 1080, 33, 33, 1080, 33, 4320, 33, 33, 1080, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 1080, 1080, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 1080, 33, 1080, 33, 1080, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 1080, 1080, 4320, 33, 4320, 33, 33, 33, 4320, 1080, 4320, 4320, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 4320, 33, 33, 1080, 33, 1080, 1080, 33, 4320, 4320, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 581298 . Total input tokens: 129613956 . Total output tokens: 116260811
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 6.118726729997434,
    "estimated_duration": 3600.173295174929,
    "input_throughput": 4108.49611595747,
    "output_throughput": 3602.9776725983224,
    "total_throughput": 7711.473788555792,
    "itl": 236.31005773701398,
    "ttft": 1934500.8216741406,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1065,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4728718588897083,
    "arrivals": 193337,
    "finished_requests": 59547,
    "scheduler_time": 79.72497277769125
}
#Debug simulation 
Total elapsed time: 6.118823875964154. Arrivals time: 0.227356314426288 Scheduler time: 5.801913712697569 Scheduler overhead time: 0.025514664012007415 Adapter cache time: 0.02671625738730654 Engine time: 0.025825456366874278 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-32/adapters_320_slots_160_rate_0.4-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-32/adapters_320_slots_160_rate_0.4-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 33, 4320, 4320, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 4320, 4320, 1080, 33, 33, 1080, 4320, 4320, 1080, 1080, 33, 33, 1080, 4320, 4320, 33, 4320, 1080, 33, 1080, 4320, 33, 1080, 4320, 4320, 1080, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 4320, 33, 4320, 1080, 4320, 4320, 33, 4320, 33, 4320, 1080, 33, 33, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 33, 1080, 1080, 33, 4320, 1080, 4320, 4320, 1080, 33, 1080, 1080, 1080, 33, 4320, 1080, 4320, 33, 4320, 33, 33, 1080, 4320, 4320, 1080, 33, 1080, 33, 1080, 4320, 4320, 1080, 33, 1080, 33, 4320, 33, 33, 33, 33, 4320, 1080, 1080, 4320, 1080, 1080, 33, 1080, 4320, 1080, 33, 33, 1080, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 1080, 4320, 1080, 1080, 1080, 33, 4320, 33, 4320, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 33, 33, 4320, 1080, 4320, 1080, 4320, 1080, 33, 1080, 33, 33, 33, 4320, 4320, 1080, 1080, 33, 33, 1080, 33, 4320, 33, 33, 1080, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 1080, 1080, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 1080, 33, 1080, 33, 1080, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 1080, 1080, 4320, 33, 4320, 33, 33, 33, 4320, 1080, 4320, 4320, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 4320, 33, 33, 1080, 33, 1080, 1080, 33, 4320, 4320, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 581298 . Total input tokens: 129613956 . Total output tokens: 116260811
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.31814269995084,
    "estimated_duration": 3600.111907270066,
    "input_throughput": 3625.638962400409,
    "output_throughput": 3190.39860311164,
    "total_throughput": 6816.03756551205,
    "itl": 157.45775943901222,
    "ttft": 2044305.8077975605,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2896,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.47368668533834,
    "arrivals": 193337,
    "finished_requests": 52529,
    "scheduler_time": 87.29226187330484
}
#Debug simulation 
Total elapsed time: 4.318294973985758. Arrivals time: 0.19787981151603162 Scheduler time: 3.9647728571435437 Scheduler overhead time: 0.035162780433893204 Adapter cache time: 0.06905736943008378 Engine time: 0.035199781064875424 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-16/adapters_320_slots_160_rate_0.4-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-16/adapters_320_slots_160_rate_0.4-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 33, 4320, 4320, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 4320, 4320, 1080, 33, 33, 1080, 4320, 4320, 1080, 1080, 33, 33, 1080, 4320, 4320, 33, 4320, 1080, 33, 1080, 4320, 33, 1080, 4320, 4320, 1080, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 4320, 33, 4320, 1080, 4320, 4320, 33, 4320, 33, 4320, 1080, 33, 33, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 33, 1080, 1080, 33, 4320, 1080, 4320, 4320, 1080, 33, 1080, 1080, 1080, 33, 4320, 1080, 4320, 33, 4320, 33, 33, 1080, 4320, 4320, 1080, 33, 1080, 33, 1080, 4320, 4320, 1080, 33, 1080, 33, 4320, 33, 33, 33, 33, 4320, 1080, 1080, 4320, 1080, 1080, 33, 1080, 4320, 1080, 33, 33, 1080, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 1080, 4320, 1080, 1080, 1080, 33, 4320, 33, 4320, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 33, 33, 4320, 1080, 4320, 1080, 4320, 1080, 33, 1080, 33, 33, 33, 4320, 4320, 1080, 1080, 33, 33, 1080, 33, 4320, 33, 33, 1080, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 1080, 1080, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 1080, 33, 1080, 33, 1080, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 1080, 1080, 4320, 33, 4320, 33, 33, 33, 4320, 1080, 4320, 4320, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 4320, 33, 33, 1080, 33, 1080, 1080, 33, 4320, 4320, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 581298 . Total input tokens: 129613956 . Total output tokens: 116260811
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 6.148981614969671,
    "estimated_duration": 3600.0176925118444,
    "input_throughput": 4109.16313849514,
    "output_throughput": 3603.601734231565,
    "total_throughput": 7712.764872726704,
    "itl": 236.3054021251301,
    "ttft": 1934201.4474302377,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1066,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3291761898644827,
    "arrivals": 193337,
    "finished_requests": 59551,
    "scheduler_time": 79.724060778194
}
#Debug simulation 
Total elapsed time: 6.149089854967315. Arrivals time: 0.23144474206492305 Scheduler time: 5.8280654975096695 Scheduler overhead time: 0.025459286698605865 Adapter cache time: 0.026908285159152 Engine time: 0.025674535427242517 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-32/adapters_320_slots_160_rate_0.4-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-32/adapters_320_slots_160_rate_0.4-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 33, 4320, 4320, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 4320, 4320, 1080, 33, 33, 1080, 4320, 4320, 1080, 1080, 33, 33, 1080, 4320, 4320, 33, 4320, 1080, 33, 1080, 4320, 33, 1080, 4320, 4320, 1080, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 4320, 33, 4320, 1080, 4320, 4320, 33, 4320, 33, 4320, 1080, 33, 33, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 33, 1080, 1080, 33, 4320, 1080, 4320, 4320, 1080, 33, 1080, 1080, 1080, 33, 4320, 1080, 4320, 33, 4320, 33, 33, 1080, 4320, 4320, 1080, 33, 1080, 33, 1080, 4320, 4320, 1080, 33, 1080, 33, 4320, 33, 33, 33, 33, 4320, 1080, 1080, 4320, 1080, 1080, 33, 1080, 4320, 1080, 33, 33, 1080, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 1080, 4320, 1080, 1080, 1080, 33, 4320, 33, 4320, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 33, 33, 4320, 1080, 4320, 1080, 4320, 1080, 33, 1080, 33, 33, 33, 4320, 4320, 1080, 1080, 33, 33, 1080, 33, 4320, 33, 33, 1080, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 1080, 1080, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 1080, 33, 1080, 33, 1080, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 1080, 1080, 4320, 33, 4320, 33, 33, 33, 4320, 1080, 4320, 4320, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 4320, 33, 33, 1080, 33, 1080, 1080, 33, 4320, 4320, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 581298 . Total input tokens: 129613956 . Total output tokens: 116260811
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.321987042960245,
    "estimated_duration": 3600.124914882947,
    "input_throughput": 3628.044667562507,
    "output_throughput": 3192.392284080976,
    "total_throughput": 6820.436951643483,
    "itl": 157.78794036489342,
    "ttft": 2043868.3513560188,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2950,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.78324796777176,
    "arrivals": 193337,
    "finished_requests": 52562,
    "scheduler_time": 87.23187734953054
}
#Debug simulation 
Total elapsed time: 4.322084540966898. Arrivals time: 0.19936198863433674 Scheduler time: 3.9653631181572564 Scheduler overhead time: 0.035048567806370556 Adapter cache time: 0.07088809582637623 Engine time: 0.035264082020148635 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-16/adapters_320_slots_160_rate_0.4-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-16/adapters_320_slots_160_rate_0.4-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 33, 4320, 4320, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 4320, 4320, 1080, 33, 33, 1080, 4320, 4320, 1080, 1080, 33, 33, 1080, 4320, 4320, 33, 4320, 1080, 33, 1080, 4320, 33, 1080, 4320, 4320, 1080, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 4320, 33, 4320, 1080, 4320, 4320, 33, 4320, 33, 4320, 1080, 33, 33, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 33, 1080, 1080, 33, 4320, 1080, 4320, 4320, 1080, 33, 1080, 1080, 1080, 33, 4320, 1080, 4320, 33, 4320, 33, 33, 1080, 4320, 4320, 1080, 33, 1080, 33, 1080, 4320, 4320, 1080, 33, 1080, 33, 4320, 33, 33, 33, 33, 4320, 1080, 1080, 4320, 1080, 1080, 33, 1080, 4320, 1080, 33, 33, 1080, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 1080, 4320, 1080, 1080, 1080, 33, 4320, 33, 4320, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 33, 33, 4320, 1080, 4320, 1080, 4320, 1080, 33, 1080, 33, 33, 33, 4320, 4320, 1080, 1080, 33, 33, 1080, 33, 4320, 33, 33, 1080, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 1080, 1080, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 1080, 33, 1080, 33, 1080, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 1080, 1080, 4320, 33, 4320, 33, 33, 33, 4320, 1080, 4320, 4320, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 4320, 33, 33, 1080, 33, 1080, 1080, 33, 4320, 4320, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 581298 . Total input tokens: 129613956 . Total output tokens: 116260811
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 6.106019650003873,
    "estimated_duration": 3600.078226946108,
    "input_throughput": 4108.97765756284,
    "output_throughput": 3604.03946305532,
    "total_throughput": 7713.01712061816,
    "itl": 236.28788546094626,
    "ttft": 1934444.8405986305,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1071,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2023438658401533,
    "arrivals": 193337,
    "finished_requests": 59560,
    "scheduler_time": 79.7282130822801
}
#Debug simulation 
Total elapsed time: 6.106116787996143. Arrivals time: 0.2252997625619173 Scheduler time: 5.791422177921049 Scheduler overhead time: 0.025470459077041596 Adapter cache time: 0.02683931024512276 Engine time: 0.025561756221577525 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-32/adapters_320_slots_160_rate_0.4-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-32/adapters_320_slots_160_rate_0.4-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 33, 4320, 4320, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 4320, 4320, 1080, 33, 33, 1080, 4320, 4320, 1080, 1080, 33, 33, 1080, 4320, 4320, 33, 4320, 1080, 33, 1080, 4320, 33, 1080, 4320, 4320, 1080, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 4320, 33, 4320, 1080, 4320, 4320, 33, 4320, 33, 4320, 1080, 33, 33, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 33, 1080, 1080, 33, 4320, 1080, 4320, 4320, 1080, 33, 1080, 1080, 1080, 33, 4320, 1080, 4320, 33, 4320, 33, 33, 1080, 4320, 4320, 1080, 33, 1080, 33, 1080, 4320, 4320, 1080, 33, 1080, 33, 4320, 33, 33, 33, 33, 4320, 1080, 1080, 4320, 1080, 1080, 33, 1080, 4320, 1080, 33, 33, 1080, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 1080, 4320, 1080, 1080, 1080, 33, 4320, 33, 4320, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 33, 33, 4320, 1080, 4320, 1080, 4320, 1080, 33, 1080, 33, 33, 33, 4320, 4320, 1080, 1080, 33, 33, 1080, 33, 4320, 33, 33, 1080, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 1080, 1080, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 1080, 33, 1080, 33, 1080, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 1080, 1080, 4320, 33, 4320, 33, 33, 33, 4320, 1080, 4320, 4320, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 4320, 33, 33, 1080, 33, 1080, 1080, 33, 4320, 4320, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 581298 . Total input tokens: 129613956 . Total output tokens: 116260811
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.315592030005064,
    "estimated_duration": 3600.0502611814377,
    "input_throughput": 3631.3190237821354,
    "output_throughput": 3194.4948446986136,
    "total_throughput": 6825.813868480749,
    "itl": 158.01820086689133,
    "ttft": 2043612.9992093432,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2951,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.903259673080822,
    "arrivals": 193337,
    "finished_requests": 52605,
    "scheduler_time": 87.18574065971644
}
#Debug simulation 
Total elapsed time: 4.3156893129926175. Arrivals time: 0.19875131925800815 Scheduler time: 3.959228021791205 Scheduler overhead time: 0.034976753348018974 Adapter cache time: 0.07136373326648027 Engine time: 0.03520830726483837 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-8/adapters_320_slots_160_rate_0.4-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-8/adapters_320_slots_160_rate_0.4-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 270, 4320, 4320, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 4320, 4320, 540, 270, 270, 540, 4320, 4320, 540, 540, 270, 270, 540, 4320, 4320, 270, 4320, 540, 270, 540, 4320, 270, 540, 4320, 4320, 540, 270, 270, 4320, 270, 270, 4320, 4320, 270, 270, 540, 540, 540, 270, 540, 270, 4320, 270, 4320, 540, 4320, 4320, 270, 4320, 270, 4320, 540, 270, 270, 540, 540, 4320, 540, 4320, 4320, 4320, 270, 540, 540, 270, 4320, 540, 4320, 4320, 540, 270, 540, 540, 540, 270, 4320, 540, 4320, 270, 4320, 270, 270, 540, 4320, 4320, 540, 270, 540, 270, 540, 4320, 4320, 540, 270, 540, 270, 4320, 270, 270, 270, 270, 4320, 540, 540, 4320, 540, 540, 270, 540, 4320, 540, 270, 270, 540, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 540, 4320, 540, 540, 540, 270, 4320, 270, 4320, 540, 270, 540, 270, 270, 540, 270, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 270, 270, 4320, 540, 4320, 540, 4320, 540, 270, 540, 270, 270, 270, 4320, 4320, 540, 540, 270, 270, 540, 270, 4320, 270, 270, 540, 270, 4320, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 270, 540, 4320, 540, 540, 4320, 540, 270, 540, 270, 4320, 540, 540, 4320, 4320, 270, 270, 270, 4320, 4320, 270, 270, 4320, 540, 270, 540, 270, 540, 4320, 4320, 4320, 270, 4320, 4320, 4320, 4320, 270, 540, 540, 4320, 270, 4320, 270, 270, 270, 4320, 540, 4320, 4320, 270, 540, 540, 540, 270, 540, 270, 540, 540, 4320, 270, 270, 540, 270, 540, 540, 270, 4320, 4320, 4320, 270, 540, 540, 540, 540, 270, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 540, 540, 540, 270, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 548640 . Total input tokens: 122301393 . Total output tokens: 109771629
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 6.319310363964178,
    "estimated_duration": 3600.068021215253,
    "input_throughput": 4054.901439076773,
    "output_throughput": 3606.1032523540134,
    "total_throughput": 7661.004691430786,
    "itl": 238.06490444970692,
    "ttft": 1913701.3746832847,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1463,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.477493569373738,
    "arrivals": 182454,
    "finished_requests": 59395,
    "scheduler_time": 79.38872726134964
}
#Debug simulation 
Total elapsed time: 6.319398273015395. Arrivals time: 0.2266133774537593 Scheduler time: 5.994572469207924 Scheduler overhead time: 0.025568310113158077 Adapter cache time: 0.035313183965627104 Engine time: 0.02580442017642781 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-16/adapters_320_slots_160_rate_0.4-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-16/adapters_320_slots_160_rate_0.4-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 270, 4320, 4320, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 4320, 4320, 540, 270, 270, 540, 4320, 4320, 540, 540, 270, 270, 540, 4320, 4320, 270, 4320, 540, 270, 540, 4320, 270, 540, 4320, 4320, 540, 270, 270, 4320, 270, 270, 4320, 4320, 270, 270, 540, 540, 540, 270, 540, 270, 4320, 270, 4320, 540, 4320, 4320, 270, 4320, 270, 4320, 540, 270, 270, 540, 540, 4320, 540, 4320, 4320, 4320, 270, 540, 540, 270, 4320, 540, 4320, 4320, 540, 270, 540, 540, 540, 270, 4320, 540, 4320, 270, 4320, 270, 270, 540, 4320, 4320, 540, 270, 540, 270, 540, 4320, 4320, 540, 270, 540, 270, 4320, 270, 270, 270, 270, 4320, 540, 540, 4320, 540, 540, 270, 540, 4320, 540, 270, 270, 540, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 540, 4320, 540, 540, 540, 270, 4320, 270, 4320, 540, 270, 540, 270, 270, 540, 270, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 270, 270, 4320, 540, 4320, 540, 4320, 540, 270, 540, 270, 270, 270, 4320, 4320, 540, 540, 270, 270, 540, 270, 4320, 270, 270, 540, 270, 4320, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 270, 540, 4320, 540, 540, 4320, 540, 270, 540, 270, 4320, 540, 540, 4320, 4320, 270, 270, 270, 4320, 4320, 270, 270, 4320, 540, 270, 540, 270, 540, 4320, 4320, 4320, 270, 4320, 4320, 4320, 4320, 270, 540, 540, 4320, 270, 4320, 270, 270, 270, 4320, 540, 4320, 4320, 270, 540, 540, 540, 270, 540, 270, 540, 540, 4320, 270, 270, 540, 270, 540, 540, 270, 4320, 4320, 4320, 270, 540, 540, 540, 540, 270, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 540, 540, 540, 270, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 548640 . Total input tokens: 122301393 . Total output tokens: 109771629
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 6.331808821996674,
    "estimated_duration": 3600.075345450377,
    "input_throughput": 4054.3195904068025,
    "output_throughput": 3605.974807278916,
    "total_throughput": 7660.294397685719,
    "itl": 238.09766986608736,
    "ttft": 1913847.1406073086,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1450,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.7343619584058745,
    "arrivals": 182454,
    "finished_requests": 59390,
    "scheduler_time": 79.38267599029278
}
#Debug simulation 
Total elapsed time: 6.331903536978643. Arrivals time: 0.22626575222238898 Scheduler time: 6.007633581466507 Scheduler overhead time: 0.0255313707748428 Adapter cache time: 0.034718484501354396 Engine time: 0.02613628638209775 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-32/adapters_320_slots_160_rate_0.4-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-32/adapters_320_slots_160_rate_0.4-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 270, 4320, 4320, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 4320, 4320, 540, 270, 270, 540, 4320, 4320, 540, 540, 270, 270, 540, 4320, 4320, 270, 4320, 540, 270, 540, 4320, 270, 540, 4320, 4320, 540, 270, 270, 4320, 270, 270, 4320, 4320, 270, 270, 540, 540, 540, 270, 540, 270, 4320, 270, 4320, 540, 4320, 4320, 270, 4320, 270, 4320, 540, 270, 270, 540, 540, 4320, 540, 4320, 4320, 4320, 270, 540, 540, 270, 4320, 540, 4320, 4320, 540, 270, 540, 540, 540, 270, 4320, 540, 4320, 270, 4320, 270, 270, 540, 4320, 4320, 540, 270, 540, 270, 540, 4320, 4320, 540, 270, 540, 270, 4320, 270, 270, 270, 270, 4320, 540, 540, 4320, 540, 540, 270, 540, 4320, 540, 270, 270, 540, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 540, 4320, 540, 540, 540, 270, 4320, 270, 4320, 540, 270, 540, 270, 270, 540, 270, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 270, 270, 4320, 540, 4320, 540, 4320, 540, 270, 540, 270, 270, 270, 4320, 4320, 540, 540, 270, 270, 540, 270, 4320, 270, 270, 540, 270, 4320, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 270, 540, 4320, 540, 540, 4320, 540, 270, 540, 270, 4320, 540, 540, 4320, 4320, 270, 270, 270, 4320, 4320, 270, 270, 4320, 540, 270, 540, 270, 540, 4320, 4320, 4320, 270, 4320, 4320, 4320, 4320, 270, 540, 540, 4320, 270, 4320, 270, 270, 270, 4320, 540, 4320, 4320, 270, 540, 540, 540, 270, 540, 270, 540, 540, 4320, 270, 270, 540, 270, 540, 540, 270, 4320, 4320, 4320, 270, 540, 540, 540, 540, 270, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 540, 540, 540, 270, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 548640 . Total input tokens: 122301393 . Total output tokens: 109771629
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.362800864968449,
    "estimated_duration": 3600.1716107793595,
    "input_throughput": 3582.027579293175,
    "output_throughput": 3199.871907635578,
    "total_throughput": 6781.899486928753,
    "itl": 159.02887282188695,
    "ttft": 2028296.0066636298,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3987,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.037321192900675,
    "arrivals": 182454,
    "finished_requests": 52461,
    "scheduler_time": 86.66852768298196
}
#Debug simulation 
Total elapsed time: 4.362895375001244. Arrivals time: 0.2036947372253053 Scheduler time: 3.9847059349995106 Scheduler overhead time: 0.03474805329460651 Adapter cache time: 0.08877574763027951 Engine time: 0.034848819428589195 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-16/adapters_320_slots_160_rate_0.4-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-16/adapters_320_slots_160_rate_0.4-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 270, 4320, 4320, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 4320, 4320, 540, 270, 270, 540, 4320, 4320, 540, 540, 270, 270, 540, 4320, 4320, 270, 4320, 540, 270, 540, 4320, 270, 540, 4320, 4320, 540, 270, 270, 4320, 270, 270, 4320, 4320, 270, 270, 540, 540, 540, 270, 540, 270, 4320, 270, 4320, 540, 4320, 4320, 270, 4320, 270, 4320, 540, 270, 270, 540, 540, 4320, 540, 4320, 4320, 4320, 270, 540, 540, 270, 4320, 540, 4320, 4320, 540, 270, 540, 540, 540, 270, 4320, 540, 4320, 270, 4320, 270, 270, 540, 4320, 4320, 540, 270, 540, 270, 540, 4320, 4320, 540, 270, 540, 270, 4320, 270, 270, 270, 270, 4320, 540, 540, 4320, 540, 540, 270, 540, 4320, 540, 270, 270, 540, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 540, 4320, 540, 540, 540, 270, 4320, 270, 4320, 540, 270, 540, 270, 270, 540, 270, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 270, 270, 4320, 540, 4320, 540, 4320, 540, 270, 540, 270, 270, 270, 4320, 4320, 540, 540, 270, 270, 540, 270, 4320, 270, 270, 540, 270, 4320, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 270, 540, 4320, 540, 540, 4320, 540, 270, 540, 270, 4320, 540, 540, 4320, 4320, 270, 270, 270, 4320, 4320, 270, 270, 4320, 540, 270, 540, 270, 540, 4320, 4320, 4320, 270, 4320, 4320, 4320, 4320, 270, 540, 540, 4320, 270, 4320, 270, 270, 270, 4320, 540, 4320, 4320, 270, 540, 540, 540, 270, 540, 270, 540, 540, 4320, 270, 270, 540, 270, 540, 540, 270, 4320, 4320, 4320, 270, 540, 540, 540, 540, 270, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 540, 540, 540, 270, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 548640 . Total input tokens: 122301393 . Total output tokens: 109771629
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 6.289608363993466,
    "estimated_duration": 3600.057449937614,
    "input_throughput": 4054.7611261739617,
    "output_throughput": 3605.626626937562,
    "total_throughput": 7660.387753111524,
    "itl": 238.06498523037075,
    "ttft": 1913763.541355887,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1458,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.554801892181775,
    "arrivals": 182454,
    "finished_requests": 59391,
    "scheduler_time": 79.38653405872965
}
#Debug simulation 
Total elapsed time: 6.289707106014248. Arrivals time: 0.22086953988764435 Scheduler time: 5.971072786138393 Scheduler overhead time: 0.02550452819559723 Adapter cache time: 0.03521362488390878 Engine time: 0.025603774120099843 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-32/adapters_320_slots_160_rate_0.4-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-32/adapters_320_slots_160_rate_0.4-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 270, 4320, 4320, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 4320, 4320, 540, 270, 270, 540, 4320, 4320, 540, 540, 270, 270, 540, 4320, 4320, 270, 4320, 540, 270, 540, 4320, 270, 540, 4320, 4320, 540, 270, 270, 4320, 270, 270, 4320, 4320, 270, 270, 540, 540, 540, 270, 540, 270, 4320, 270, 4320, 540, 4320, 4320, 270, 4320, 270, 4320, 540, 270, 270, 540, 540, 4320, 540, 4320, 4320, 4320, 270, 540, 540, 270, 4320, 540, 4320, 4320, 540, 270, 540, 540, 540, 270, 4320, 540, 4320, 270, 4320, 270, 270, 540, 4320, 4320, 540, 270, 540, 270, 540, 4320, 4320, 540, 270, 540, 270, 4320, 270, 270, 270, 270, 4320, 540, 540, 4320, 540, 540, 270, 540, 4320, 540, 270, 270, 540, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 540, 4320, 540, 540, 540, 270, 4320, 270, 4320, 540, 270, 540, 270, 270, 540, 270, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 270, 270, 4320, 540, 4320, 540, 4320, 540, 270, 540, 270, 270, 270, 4320, 4320, 540, 540, 270, 270, 540, 270, 4320, 270, 270, 540, 270, 4320, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 270, 540, 4320, 540, 540, 4320, 540, 270, 540, 270, 4320, 540, 540, 4320, 4320, 270, 270, 270, 4320, 4320, 270, 270, 4320, 540, 270, 540, 270, 540, 4320, 4320, 4320, 270, 4320, 4320, 4320, 4320, 270, 540, 540, 4320, 270, 4320, 270, 270, 270, 4320, 540, 4320, 4320, 270, 540, 540, 540, 270, 540, 270, 540, 540, 4320, 270, 270, 540, 270, 540, 540, 270, 4320, 4320, 4320, 270, 540, 540, 540, 540, 270, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 540, 540, 540, 270, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 548640 . Total input tokens: 122301393 . Total output tokens: 109771629
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.368599142995663,
    "estimated_duration": 3600.1325164757905,
    "input_throughput": 3578.8235408102487,
    "output_throughput": 3197.6997922480264,
    "total_throughput": 6776.523333058275,
    "itl": 158.7608368144448,
    "ttft": 2029010.8393201358,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3996,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.240070791243616,
    "arrivals": 182454,
    "finished_requests": 52416,
    "scheduler_time": 86.70734843830047
}
#Debug simulation 
Total elapsed time: 4.368738938996103. Arrivals time: 0.20145386032527313 Scheduler time: 3.9875959772616625 Scheduler overhead time: 0.034830561955459416 Adapter cache time: 0.09388364804908633 Engine time: 0.034865367342717946 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-16/adapters_320_slots_160_rate_0.4-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-16/adapters_320_slots_160_rate_0.4-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 270, 4320, 4320, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 4320, 4320, 540, 270, 270, 540, 4320, 4320, 540, 540, 270, 270, 540, 4320, 4320, 270, 4320, 540, 270, 540, 4320, 270, 540, 4320, 4320, 540, 270, 270, 4320, 270, 270, 4320, 4320, 270, 270, 540, 540, 540, 270, 540, 270, 4320, 270, 4320, 540, 4320, 4320, 270, 4320, 270, 4320, 540, 270, 270, 540, 540, 4320, 540, 4320, 4320, 4320, 270, 540, 540, 270, 4320, 540, 4320, 4320, 540, 270, 540, 540, 540, 270, 4320, 540, 4320, 270, 4320, 270, 270, 540, 4320, 4320, 540, 270, 540, 270, 540, 4320, 4320, 540, 270, 540, 270, 4320, 270, 270, 270, 270, 4320, 540, 540, 4320, 540, 540, 270, 540, 4320, 540, 270, 270, 540, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 540, 4320, 540, 540, 540, 270, 4320, 270, 4320, 540, 270, 540, 270, 270, 540, 270, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 270, 270, 4320, 540, 4320, 540, 4320, 540, 270, 540, 270, 270, 270, 4320, 4320, 540, 540, 270, 270, 540, 270, 4320, 270, 270, 540, 270, 4320, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 270, 540, 4320, 540, 540, 4320, 540, 270, 540, 270, 4320, 540, 540, 4320, 4320, 270, 270, 270, 4320, 4320, 270, 270, 4320, 540, 270, 540, 270, 540, 4320, 4320, 4320, 270, 4320, 4320, 4320, 4320, 270, 540, 540, 4320, 270, 4320, 270, 270, 270, 4320, 540, 4320, 4320, 270, 540, 540, 540, 270, 540, 270, 540, 540, 4320, 270, 270, 540, 270, 540, 540, 270, 4320, 4320, 4320, 270, 540, 540, 540, 540, 270, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 540, 540, 540, 270, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 548640 . Total input tokens: 122301393 . Total output tokens: 109771629
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 6.188074311998207,
    "estimated_duration": 3600.0016726018553,
    "input_throughput": 4054.5100606719307,
    "output_throughput": 3605.6561025480314,
    "total_throughput": 7660.166163219962,
    "itl": 238.05463519024093,
    "ttft": 1913802.7498442174,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1458,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.359493329967254,
    "arrivals": 182454,
    "finished_requests": 59390,
    "scheduler_time": 79.38904121748152
}
#Debug simulation 
Total elapsed time: 6.1881753749912605. Arrivals time: 0.21456930512795225 Scheduler time: 5.878724018635694 Scheduler overhead time: 0.02478650672128424 Adapter cache time: 0.03377086063846946 Engine time: 0.02494487987132743 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-32/adapters_320_slots_160_rate_0.4-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-32/adapters_320_slots_160_rate_0.4-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 270, 4320, 4320, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 4320, 4320, 540, 270, 270, 540, 4320, 4320, 540, 540, 270, 270, 540, 4320, 4320, 270, 4320, 540, 270, 540, 4320, 270, 540, 4320, 4320, 540, 270, 270, 4320, 270, 270, 4320, 4320, 270, 270, 540, 540, 540, 270, 540, 270, 4320, 270, 4320, 540, 4320, 4320, 270, 4320, 270, 4320, 540, 270, 270, 540, 540, 4320, 540, 4320, 4320, 4320, 270, 540, 540, 270, 4320, 540, 4320, 4320, 540, 270, 540, 540, 540, 270, 4320, 540, 4320, 270, 4320, 270, 270, 540, 4320, 4320, 540, 270, 540, 270, 540, 4320, 4320, 540, 270, 540, 270, 4320, 270, 270, 270, 270, 4320, 540, 540, 4320, 540, 540, 270, 540, 4320, 540, 270, 270, 540, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 540, 4320, 540, 540, 540, 270, 4320, 270, 4320, 540, 270, 540, 270, 270, 540, 270, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 270, 270, 4320, 540, 4320, 540, 4320, 540, 270, 540, 270, 270, 270, 4320, 4320, 540, 540, 270, 270, 540, 270, 4320, 270, 270, 540, 270, 4320, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 270, 540, 4320, 540, 540, 4320, 540, 270, 540, 270, 4320, 540, 540, 4320, 4320, 270, 270, 270, 4320, 4320, 270, 270, 4320, 540, 270, 540, 270, 540, 4320, 4320, 4320, 270, 4320, 4320, 4320, 4320, 270, 540, 540, 4320, 270, 4320, 270, 270, 270, 4320, 540, 4320, 4320, 270, 540, 540, 540, 270, 540, 270, 540, 540, 4320, 270, 270, 540, 270, 540, 540, 270, 4320, 4320, 4320, 270, 540, 540, 540, 540, 270, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 540, 540, 540, 270, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 548640 . Total input tokens: 122301393 . Total output tokens: 109771629
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.310906547005288,
    "estimated_duration": 3600.1707467727256,
    "input_throughput": 3581.5473506523645,
    "output_throughput": 3199.549635340442,
    "total_throughput": 6781.096985992806,
    "itl": 159.05018870254722,
    "ttft": 2028597.087136759,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3987,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.373038076571257,
    "arrivals": 182454,
    "finished_requests": 52455,
    "scheduler_time": 86.65834527006773
}
#Debug simulation 
Total elapsed time: 4.311003497976344. Arrivals time: 0.18235339527018368 Scheduler time: 3.9570694306166843 Scheduler overhead time: 0.034520132292527705 Adapter cache time: 0.08694712352007627 Engine time: 0.03424072009511292 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-8/adapters_320_slots_160_rate_0.4-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-8/adapters_320_slots_160_rate_0.4-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 135, 4320, 4320, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 4320, 4320, 540, 135, 135, 540, 4320, 4320, 540, 540, 135, 135, 540, 4320, 4320, 135, 4320, 540, 135, 540, 4320, 135, 540, 4320, 4320, 540, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 540, 540, 540, 135, 540, 135, 4320, 135, 4320, 540, 4320, 4320, 135, 4320, 135, 4320, 540, 135, 135, 540, 540, 4320, 540, 4320, 4320, 4320, 135, 540, 540, 135, 4320, 540, 4320, 4320, 540, 135, 540, 540, 540, 135, 4320, 540, 4320, 135, 4320, 135, 135, 540, 4320, 4320, 540, 135, 540, 135, 540, 4320, 4320, 540, 135, 540, 135, 4320, 135, 135, 135, 135, 4320, 540, 540, 4320, 540, 540, 135, 540, 4320, 540, 135, 135, 540, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 540, 4320, 540, 540, 540, 135, 4320, 135, 4320, 540, 135, 540, 135, 135, 540, 135, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 135, 135, 4320, 540, 4320, 540, 4320, 540, 135, 540, 135, 135, 135, 4320, 4320, 540, 540, 135, 135, 540, 135, 4320, 135, 135, 540, 135, 4320, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 135, 540, 4320, 540, 540, 4320, 540, 135, 540, 135, 4320, 540, 540, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 540, 135, 540, 135, 540, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 540, 540, 4320, 135, 4320, 135, 135, 135, 4320, 540, 4320, 4320, 135, 540, 540, 540, 135, 540, 135, 540, 540, 4320, 135, 135, 540, 135, 540, 540, 135, 4320, 4320, 4320, 135, 540, 540, 540, 540, 135, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 540, 540, 540, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 534330 . Total input tokens: 119088970 . Total output tokens: 106911388
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.52421357302228,
    "estimated_duration": 3600.0818415847293,
    "input_throughput": 4130.404155882864,
    "output_throughput": 3603.2497512028294,
    "total_throughput": 7733.653907085693,
    "itl": 235.57825905432114,
    "ttft": 1903809.280415999,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1580,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.835570635413883,
    "arrivals": 177727,
    "finished_requests": 59676,
    "scheduler_time": 79.36378890227235
}
#Debug simulation 
Total elapsed time: 5.524309217988048. Arrivals time: 0.20663085480919108 Scheduler time: 5.222007258853409 Scheduler overhead time: 0.024824458174407482 Adapter cache time: 0.034716758818831295 Engine time: 0.024815559445414692 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-16/adapters_320_slots_160_rate_0.4-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-16/adapters_320_slots_160_rate_0.4-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 135, 4320, 4320, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 4320, 4320, 540, 135, 135, 540, 4320, 4320, 540, 540, 135, 135, 540, 4320, 4320, 135, 4320, 540, 135, 540, 4320, 135, 540, 4320, 4320, 540, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 540, 540, 540, 135, 540, 135, 4320, 135, 4320, 540, 4320, 4320, 135, 4320, 135, 4320, 540, 135, 135, 540, 540, 4320, 540, 4320, 4320, 4320, 135, 540, 540, 135, 4320, 540, 4320, 4320, 540, 135, 540, 540, 540, 135, 4320, 540, 4320, 135, 4320, 135, 135, 540, 4320, 4320, 540, 135, 540, 135, 540, 4320, 4320, 540, 135, 540, 135, 4320, 135, 135, 135, 135, 4320, 540, 540, 4320, 540, 540, 135, 540, 4320, 540, 135, 135, 540, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 540, 4320, 540, 540, 540, 135, 4320, 135, 4320, 540, 135, 540, 135, 135, 540, 135, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 135, 135, 4320, 540, 4320, 540, 4320, 540, 135, 540, 135, 135, 135, 4320, 4320, 540, 540, 135, 135, 540, 135, 4320, 135, 135, 540, 135, 4320, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 135, 540, 4320, 540, 540, 4320, 540, 135, 540, 135, 4320, 540, 540, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 540, 135, 540, 135, 540, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 540, 540, 4320, 135, 4320, 135, 135, 135, 4320, 540, 4320, 4320, 135, 540, 540, 540, 135, 540, 135, 540, 540, 4320, 135, 135, 540, 135, 540, 540, 135, 4320, 4320, 4320, 135, 540, 540, 540, 540, 135, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 540, 540, 540, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 534330 . Total input tokens: 119088970 . Total output tokens: 106911388
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.521494710992556,
    "estimated_duration": 3600.2283727950908,
    "input_throughput": 4131.744839411784,
    "output_throughput": 3603.764999476172,
    "total_throughput": 7735.509838887956,
    "itl": 235.59576883219614,
    "ttft": 1903845.1437317114,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1576,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.143795921038739,
    "arrivals": 177727,
    "finished_requests": 59689,
    "scheduler_time": 79.3617663639401
}
#Debug simulation 
Total elapsed time: 5.521599105966743. Arrivals time: 0.20603021077113226 Scheduler time: 5.219660729169846 Scheduler overhead time: 0.02466447005281225 Adapter cache time: 0.035192857205402106 Engine time: 0.024763371679000556 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-32/adapters_320_slots_160_rate_0.4-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-32/adapters_320_slots_160_rate_0.4-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 135, 4320, 4320, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 4320, 4320, 540, 135, 135, 540, 4320, 4320, 540, 540, 135, 135, 540, 4320, 4320, 135, 4320, 540, 135, 540, 4320, 135, 540, 4320, 4320, 540, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 540, 540, 540, 135, 540, 135, 4320, 135, 4320, 540, 4320, 4320, 135, 4320, 135, 4320, 540, 135, 135, 540, 540, 4320, 540, 4320, 4320, 4320, 135, 540, 540, 135, 4320, 540, 4320, 4320, 540, 135, 540, 540, 540, 135, 4320, 540, 4320, 135, 4320, 135, 135, 540, 4320, 4320, 540, 135, 540, 135, 540, 4320, 4320, 540, 135, 540, 135, 4320, 135, 135, 135, 135, 4320, 540, 540, 4320, 540, 540, 135, 540, 4320, 540, 135, 135, 540, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 540, 4320, 540, 540, 540, 135, 4320, 135, 4320, 540, 135, 540, 135, 135, 540, 135, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 135, 135, 4320, 540, 4320, 540, 4320, 540, 135, 540, 135, 135, 135, 4320, 4320, 540, 540, 135, 135, 540, 135, 4320, 135, 135, 540, 135, 4320, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 135, 540, 4320, 540, 540, 4320, 540, 135, 540, 135, 4320, 540, 540, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 540, 135, 540, 135, 540, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 540, 540, 4320, 135, 4320, 135, 135, 135, 4320, 540, 4320, 4320, 135, 540, 540, 540, 135, 540, 135, 540, 540, 4320, 135, 135, 540, 135, 540, 540, 135, 4320, 4320, 4320, 135, 540, 540, 540, 540, 135, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 540, 540, 540, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 534330 . Total input tokens: 119088970 . Total output tokens: 106911388
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.1009791910182685,
    "estimated_duration": 3600.0045088908873,
    "input_throughput": 3634.0821150889633,
    "output_throughput": 3189.2665610958516,
    "total_throughput": 6823.348676184814,
    "itl": 157.4784176182436,
    "ttft": 2020834.2053611418,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4206,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.764219122304473,
    "arrivals": 177727,
    "finished_requests": 52548,
    "scheduler_time": 86.7065333074358
}
#Debug simulation 
Total elapsed time: 4.101091367017943. Arrivals time: 0.18095026968512684 Scheduler time: 3.7431705415365286 Scheduler overhead time: 0.03465451026568189 Adapter cache time: 0.09175405162386596 Engine time: 0.034453158907126635 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-16/adapters_320_slots_160_rate_0.4-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-16/adapters_320_slots_160_rate_0.4-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 135, 4320, 4320, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 4320, 4320, 540, 135, 135, 540, 4320, 4320, 540, 540, 135, 135, 540, 4320, 4320, 135, 4320, 540, 135, 540, 4320, 135, 540, 4320, 4320, 540, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 540, 540, 540, 135, 540, 135, 4320, 135, 4320, 540, 4320, 4320, 135, 4320, 135, 4320, 540, 135, 135, 540, 540, 4320, 540, 4320, 4320, 4320, 135, 540, 540, 135, 4320, 540, 4320, 4320, 540, 135, 540, 540, 540, 135, 4320, 540, 4320, 135, 4320, 135, 135, 540, 4320, 4320, 540, 135, 540, 135, 540, 4320, 4320, 540, 135, 540, 135, 4320, 135, 135, 135, 135, 4320, 540, 540, 4320, 540, 540, 135, 540, 4320, 540, 135, 135, 540, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 540, 4320, 540, 540, 540, 135, 4320, 135, 4320, 540, 135, 540, 135, 135, 540, 135, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 135, 135, 4320, 540, 4320, 540, 4320, 540, 135, 540, 135, 135, 135, 4320, 4320, 540, 540, 135, 135, 540, 135, 4320, 135, 135, 540, 135, 4320, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 135, 540, 4320, 540, 540, 4320, 540, 135, 540, 135, 4320, 540, 540, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 540, 135, 540, 135, 540, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 540, 540, 4320, 135, 4320, 135, 135, 135, 4320, 540, 4320, 4320, 135, 540, 540, 540, 135, 540, 135, 540, 540, 4320, 135, 135, 540, 135, 540, 540, 135, 4320, 4320, 4320, 135, 540, 540, 540, 540, 135, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 540, 540, 540, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 534330 . Total input tokens: 119088970 . Total output tokens: 106911388
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 5.574617993028369,
    "estimated_duration": 3600.174123889324,
    "input_throughput": 4132.276519983494,
    "output_throughput": 3604.576765853934,
    "total_throughput": 7736.853285837427,
    "itl": 235.57117929399732,
    "ttft": 1903873.653809605,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1579,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.932124599965649,
    "arrivals": 177727,
    "finished_requests": 59698,
    "scheduler_time": 79.36543902343139
}
#Debug simulation 
Total elapsed time: 5.574715710012242. Arrivals time: 0.20806138135958463 Scheduler time: 5.269533330225386 Scheduler overhead time: 0.02492466097464785 Adapter cache time: 0.03564966778503731 Engine time: 0.025094698299653828 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-32/adapters_320_slots_160_rate_0.4-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-32/adapters_320_slots_160_rate_0.4-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 135, 4320, 4320, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 4320, 4320, 540, 135, 135, 540, 4320, 4320, 540, 540, 135, 135, 540, 4320, 4320, 135, 4320, 540, 135, 540, 4320, 135, 540, 4320, 4320, 540, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 540, 540, 540, 135, 540, 135, 4320, 135, 4320, 540, 4320, 4320, 135, 4320, 135, 4320, 540, 135, 135, 540, 540, 4320, 540, 4320, 4320, 4320, 135, 540, 540, 135, 4320, 540, 4320, 4320, 540, 135, 540, 540, 540, 135, 4320, 540, 4320, 135, 4320, 135, 135, 540, 4320, 4320, 540, 135, 540, 135, 540, 4320, 4320, 540, 135, 540, 135, 4320, 135, 135, 135, 135, 4320, 540, 540, 4320, 540, 540, 135, 540, 4320, 540, 135, 135, 540, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 540, 4320, 540, 540, 540, 135, 4320, 135, 4320, 540, 135, 540, 135, 135, 540, 135, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 135, 135, 4320, 540, 4320, 540, 4320, 540, 135, 540, 135, 135, 135, 4320, 4320, 540, 540, 135, 135, 540, 135, 4320, 135, 135, 540, 135, 4320, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 135, 540, 4320, 540, 540, 4320, 540, 135, 540, 135, 4320, 540, 540, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 540, 135, 540, 135, 540, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 540, 540, 4320, 135, 4320, 135, 135, 135, 4320, 540, 4320, 4320, 135, 540, 540, 540, 135, 540, 135, 540, 540, 4320, 135, 135, 540, 135, 540, 540, 135, 4320, 4320, 4320, 135, 540, 540, 540, 540, 135, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 540, 540, 540, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 534330 . Total input tokens: 119088970 . Total output tokens: 106911388
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.090675260988064,
    "estimated_duration": 3600.0314157697326,
    "input_throughput": 3572.3063259019586,
    "output_throughput": 3137.461509508798,
    "total_throughput": 6709.767835410757,
    "itl": 151.1064204206705,
    "ttft": 2030704.2613685583,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3794,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.592875634840818,
    "arrivals": 177727,
    "finished_requests": 51644,
    "scheduler_time": 87.87676107781927
}
#Debug simulation 
Total elapsed time: 4.090771237039007. Arrivals time: 0.1810006121522747 Scheduler time: 3.7370787349063903 Scheduler overhead time: 0.03584207216044888 Adapter cache time: 0.08428717090282589 Engine time: 0.036048480949830264 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-16/adapters_320_slots_160_rate_0.4-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-16/adapters_320_slots_160_rate_0.4-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 135, 4320, 4320, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 4320, 4320, 540, 135, 135, 540, 4320, 4320, 540, 540, 135, 135, 540, 4320, 4320, 135, 4320, 540, 135, 540, 4320, 135, 540, 4320, 4320, 540, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 540, 540, 540, 135, 540, 135, 4320, 135, 4320, 540, 4320, 4320, 135, 4320, 135, 4320, 540, 135, 135, 540, 540, 4320, 540, 4320, 4320, 4320, 135, 540, 540, 135, 4320, 540, 4320, 4320, 540, 135, 540, 540, 540, 135, 4320, 540, 4320, 135, 4320, 135, 135, 540, 4320, 4320, 540, 135, 540, 135, 540, 4320, 4320, 540, 135, 540, 135, 4320, 135, 135, 135, 135, 4320, 540, 540, 4320, 540, 540, 135, 540, 4320, 540, 135, 135, 540, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 540, 4320, 540, 540, 540, 135, 4320, 135, 4320, 540, 135, 540, 135, 135, 540, 135, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 135, 135, 4320, 540, 4320, 540, 4320, 540, 135, 540, 135, 135, 135, 4320, 4320, 540, 540, 135, 135, 540, 135, 4320, 135, 135, 540, 135, 4320, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 135, 540, 4320, 540, 540, 4320, 540, 135, 540, 135, 4320, 540, 540, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 540, 135, 540, 135, 540, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 540, 540, 4320, 135, 4320, 135, 135, 135, 4320, 540, 4320, 4320, 135, 540, 540, 540, 135, 540, 135, 540, 540, 4320, 135, 135, 540, 135, 540, 540, 135, 4320, 4320, 4320, 135, 540, 540, 540, 540, 135, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 540, 540, 540, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 534330 . Total input tokens: 119088970 . Total output tokens: 106911388
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.533188896020874,
    "estimated_duration": 3600.020097217764,
    "input_throughput": 4131.597768438871,
    "output_throughput": 3603.6787711341626,
    "total_throughput": 7735.276539573033,
    "itl": 235.5571578068266,
    "ttft": 1903810.4477622672,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1578,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.718299365355502,
    "arrivals": 177727,
    "finished_requests": 59691,
    "scheduler_time": 79.36501836582116
}
#Debug simulation 
Total elapsed time: 5.533287425991148. Arrivals time: 0.20606387057341635 Scheduler time: 5.230869526509196 Scheduler overhead time: 0.024823090061545372 Adapter cache time: 0.03531969536561519 Engine time: 0.024851781025063246 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-32/adapters_320_slots_160_rate_0.4-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-32/adapters_320_slots_160_rate_0.4-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 135, 4320, 4320, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 4320, 4320, 540, 135, 135, 540, 4320, 4320, 540, 540, 135, 135, 540, 4320, 4320, 135, 4320, 540, 135, 540, 4320, 135, 540, 4320, 4320, 540, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 540, 540, 540, 135, 540, 135, 4320, 135, 4320, 540, 4320, 4320, 135, 4320, 135, 4320, 540, 135, 135, 540, 540, 4320, 540, 4320, 4320, 4320, 135, 540, 540, 135, 4320, 540, 4320, 4320, 540, 135, 540, 540, 540, 135, 4320, 540, 4320, 135, 4320, 135, 135, 540, 4320, 4320, 540, 135, 540, 135, 540, 4320, 4320, 540, 135, 540, 135, 4320, 135, 135, 135, 135, 4320, 540, 540, 4320, 540, 540, 135, 540, 4320, 540, 135, 135, 540, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 540, 4320, 540, 540, 540, 135, 4320, 135, 4320, 540, 135, 540, 135, 135, 540, 135, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 135, 135, 4320, 540, 4320, 540, 4320, 540, 135, 540, 135, 135, 135, 4320, 4320, 540, 540, 135, 135, 540, 135, 4320, 135, 135, 540, 135, 4320, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 135, 540, 4320, 540, 540, 4320, 540, 135, 540, 135, 4320, 540, 540, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 540, 135, 540, 135, 540, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 540, 540, 4320, 135, 4320, 135, 135, 135, 4320, 540, 4320, 4320, 135, 540, 540, 540, 135, 540, 135, 540, 540, 4320, 135, 135, 540, 135, 540, 540, 135, 4320, 4320, 4320, 135, 540, 540, 540, 540, 135, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 540, 540, 540, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 534330 . Total input tokens: 119088970 . Total output tokens: 106911388
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.11449090304086,
    "estimated_duration": 3600.059376310151,
    "input_throughput": 3634.91115899657,
    "output_throughput": 3189.916276261618,
    "total_throughput": 6824.827435258188,
    "itl": 157.56429781672256,
    "ttft": 2021003.9886169555,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4191,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.069848131797281,
    "arrivals": 177727,
    "finished_requests": 52560,
    "scheduler_time": 86.68951349767306
}
#Debug simulation 
Total elapsed time: 4.114607363007963. Arrivals time: 0.18181197572266683 Scheduler time: 3.7576277626794763 Scheduler overhead time: 0.03453918232116848 Adapter cache time: 0.0901155544561334 Engine time: 0.034359946788754314 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-8/adapters_320_slots_160_rate_0.4-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-8/adapters_320_slots_160_rate_0.4-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 66, 4320, 4320, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 4320, 4320, 540, 66, 66, 540, 4320, 4320, 540, 540, 66, 66, 540, 4320, 4320, 66, 4320, 540, 66, 540, 4320, 66, 540, 4320, 4320, 540, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 540, 540, 540, 66, 540, 66, 4320, 66, 4320, 540, 4320, 4320, 66, 4320, 66, 4320, 540, 66, 66, 540, 540, 4320, 540, 4320, 4320, 4320, 66, 540, 540, 66, 4320, 540, 4320, 4320, 540, 66, 540, 540, 540, 66, 4320, 540, 4320, 66, 4320, 66, 66, 540, 4320, 4320, 540, 66, 540, 66, 540, 4320, 4320, 540, 66, 540, 66, 4320, 66, 66, 66, 66, 4320, 540, 540, 4320, 540, 540, 66, 540, 4320, 540, 66, 66, 540, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 540, 4320, 540, 540, 540, 66, 4320, 66, 4320, 540, 66, 540, 66, 66, 540, 66, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 66, 66, 4320, 540, 4320, 540, 4320, 540, 66, 540, 66, 66, 66, 4320, 4320, 540, 540, 66, 66, 540, 66, 4320, 66, 66, 540, 66, 4320, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 66, 540, 4320, 540, 540, 4320, 540, 66, 540, 66, 4320, 540, 540, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 540, 66, 540, 66, 540, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 540, 540, 4320, 66, 4320, 66, 66, 66, 4320, 540, 4320, 4320, 66, 540, 540, 540, 66, 540, 66, 540, 540, 4320, 66, 66, 540, 66, 540, 540, 66, 4320, 4320, 4320, 66, 540, 540, 540, 540, 66, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 540, 540, 540, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 527016 . Total input tokens: 117464930 . Total output tokens: 105442026
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.04458634700859,
    "estimated_duration": 3600.0663867881285,
    "input_throughput": 4088.6187693700053,
    "output_throughput": 3604.0213168334526,
    "total_throughput": 7692.640086203458,
    "itl": 236.82571774913495,
    "ttft": 1894813.6758049335,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1630,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.988595022610526,
    "arrivals": 175481,
    "finished_requests": 59562,
    "scheduler_time": 79.16202707626663
}
#Debug simulation 
Total elapsed time: 5.044672279036604. Arrivals time: 0.20157778594875708 Scheduler time: 4.7467887962120585 Scheduler overhead time: 0.02455715514952317 Adapter cache time: 0.03598884044913575 Engine time: 0.024512933276128024 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-16/adapters_320_slots_160_rate_0.4-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-16/adapters_320_slots_160_rate_0.4-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 66, 4320, 4320, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 4320, 4320, 540, 66, 66, 540, 4320, 4320, 540, 540, 66, 66, 540, 4320, 4320, 66, 4320, 540, 66, 540, 4320, 66, 540, 4320, 4320, 540, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 540, 540, 540, 66, 540, 66, 4320, 66, 4320, 540, 4320, 4320, 66, 4320, 66, 4320, 540, 66, 66, 540, 540, 4320, 540, 4320, 4320, 4320, 66, 540, 540, 66, 4320, 540, 4320, 4320, 540, 66, 540, 540, 540, 66, 4320, 540, 4320, 66, 4320, 66, 66, 540, 4320, 4320, 540, 66, 540, 66, 540, 4320, 4320, 540, 66, 540, 66, 4320, 66, 66, 66, 66, 4320, 540, 540, 4320, 540, 540, 66, 540, 4320, 540, 66, 66, 540, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 540, 4320, 540, 540, 540, 66, 4320, 66, 4320, 540, 66, 540, 66, 66, 540, 66, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 66, 66, 4320, 540, 4320, 540, 4320, 540, 66, 540, 66, 66, 66, 4320, 4320, 540, 540, 66, 66, 540, 66, 4320, 66, 66, 540, 66, 4320, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 66, 540, 4320, 540, 540, 4320, 540, 66, 540, 66, 4320, 540, 540, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 540, 66, 540, 66, 540, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 540, 540, 4320, 66, 4320, 66, 66, 66, 4320, 540, 4320, 4320, 66, 540, 540, 540, 66, 540, 66, 540, 540, 4320, 66, 66, 540, 66, 540, 540, 66, 4320, 4320, 4320, 66, 540, 540, 540, 540, 66, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 540, 540, 540, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 527016 . Total input tokens: 117464930 . Total output tokens: 105442026
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.72941345901927,
    "estimated_duration": 3600.012492163504,
    "input_throughput": 4088.2994245264267,
    "output_throughput": 3603.4880512883556,
    "total_throughput": 7691.787475814782,
    "itl": 236.841442631054,
    "ttft": 1894956.8218335304,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1634,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.334379841517541,
    "arrivals": 175481,
    "finished_requests": 59556,
    "scheduler_time": 79.1544454019453
}
#Debug simulation 
Total elapsed time: 5.729518277046736. Arrivals time: 0.20570465159835294 Scheduler time: 5.426804356160574 Scheduler overhead time: 0.02474116295343265 Adapter cache time: 0.03657587303314358 Engine time: 0.024321284203324467 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-32/adapters_320_slots_160_rate_0.4-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-32/adapters_320_slots_160_rate_0.4-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 66, 4320, 4320, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 4320, 4320, 540, 66, 66, 540, 4320, 4320, 540, 540, 66, 66, 540, 4320, 4320, 66, 4320, 540, 66, 540, 4320, 66, 540, 4320, 4320, 540, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 540, 540, 540, 66, 540, 66, 4320, 66, 4320, 540, 4320, 4320, 66, 4320, 66, 4320, 540, 66, 66, 540, 540, 4320, 540, 4320, 4320, 4320, 66, 540, 540, 66, 4320, 540, 4320, 4320, 540, 66, 540, 540, 540, 66, 4320, 540, 4320, 66, 4320, 66, 66, 540, 4320, 4320, 540, 66, 540, 66, 540, 4320, 4320, 540, 66, 540, 66, 4320, 66, 66, 66, 66, 4320, 540, 540, 4320, 540, 540, 66, 540, 4320, 540, 66, 66, 540, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 540, 4320, 540, 540, 540, 66, 4320, 66, 4320, 540, 66, 540, 66, 66, 540, 66, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 66, 66, 4320, 540, 4320, 540, 4320, 540, 66, 540, 66, 66, 66, 4320, 4320, 540, 540, 66, 66, 540, 66, 4320, 66, 66, 540, 66, 4320, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 66, 540, 4320, 540, 540, 4320, 540, 66, 540, 66, 4320, 540, 540, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 540, 66, 540, 66, 540, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 540, 540, 4320, 66, 4320, 66, 66, 66, 4320, 540, 4320, 4320, 66, 540, 540, 540, 66, 540, 66, 540, 540, 4320, 66, 66, 540, 66, 540, 540, 66, 4320, 4320, 4320, 66, 540, 540, 540, 540, 66, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 540, 540, 540, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 527016 . Total input tokens: 117464930 . Total output tokens: 105442026
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.9938905049930327,
    "estimated_duration": 3600.0332916834413,
    "input_throughput": 3629.6183788594217,
    "output_throughput": 3207.195063077007,
    "total_throughput": 6836.813441936429,
    "itl": 157.49368686713433,
    "ttft": 2009891.6966558741,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4119,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.479872627778848,
    "arrivals": 175481,
    "finished_requests": 52829,
    "scheduler_time": 86.75048251282885
}
#Debug simulation 
Total elapsed time: 3.9939764050068334. Arrivals time: 0.1843117187381722 Scheduler time: 3.6344783094828017 Scheduler overhead time: 0.03413825324969366 Adapter cache time: 0.091007019742392 Engine time: 0.034209830628242344 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-16/adapters_320_slots_160_rate_0.4-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-16/adapters_320_slots_160_rate_0.4-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 66, 4320, 4320, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 4320, 4320, 540, 66, 66, 540, 4320, 4320, 540, 540, 66, 66, 540, 4320, 4320, 66, 4320, 540, 66, 540, 4320, 66, 540, 4320, 4320, 540, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 540, 540, 540, 66, 540, 66, 4320, 66, 4320, 540, 4320, 4320, 66, 4320, 66, 4320, 540, 66, 66, 540, 540, 4320, 540, 4320, 4320, 4320, 66, 540, 540, 66, 4320, 540, 4320, 4320, 540, 66, 540, 540, 540, 66, 4320, 540, 4320, 66, 4320, 66, 66, 540, 4320, 4320, 540, 66, 540, 66, 540, 4320, 4320, 540, 66, 540, 66, 4320, 66, 66, 66, 66, 4320, 540, 540, 4320, 540, 540, 66, 540, 4320, 540, 66, 66, 540, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 540, 4320, 540, 540, 540, 66, 4320, 66, 4320, 540, 66, 540, 66, 66, 540, 66, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 66, 66, 4320, 540, 4320, 540, 4320, 540, 66, 540, 66, 66, 66, 4320, 4320, 540, 540, 66, 66, 540, 66, 4320, 66, 66, 540, 66, 4320, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 66, 540, 4320, 540, 540, 4320, 540, 66, 540, 66, 4320, 540, 540, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 540, 66, 540, 66, 540, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 540, 540, 4320, 66, 4320, 66, 66, 66, 4320, 540, 4320, 4320, 66, 540, 540, 540, 66, 540, 66, 540, 540, 4320, 66, 66, 540, 66, 540, 540, 66, 4320, 4320, 4320, 66, 540, 540, 540, 540, 66, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 540, 540, 540, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 527016 . Total input tokens: 117464930 . Total output tokens: 105442026
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 5.748079671000596,
    "estimated_duration": 3600.0112798580285,
    "input_throughput": 4088.7580220527775,
    "output_throughput": 3604.2270402307454,
    "total_throughput": 7692.985062283523,
    "itl": 236.83656234610197,
    "ttft": 1894740.9592113707,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1632,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.095091814098293,
    "arrivals": 175481,
    "finished_requests": 59565,
    "scheduler_time": 79.1581583307874
}
#Debug simulation 
Total elapsed time: 5.7481704709935. Arrivals time: 0.20606517797568813 Scheduler time: 5.444645056501031 Scheduler overhead time: 0.024779384722933173 Adapter cache time: 0.03670461691217497 Engine time: 0.024551865935791284 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-32/adapters_320_slots_160_rate_0.4-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-32/adapters_320_slots_160_rate_0.4-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 66, 4320, 4320, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 4320, 4320, 540, 66, 66, 540, 4320, 4320, 540, 540, 66, 66, 540, 4320, 4320, 66, 4320, 540, 66, 540, 4320, 66, 540, 4320, 4320, 540, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 540, 540, 540, 66, 540, 66, 4320, 66, 4320, 540, 4320, 4320, 66, 4320, 66, 4320, 540, 66, 66, 540, 540, 4320, 540, 4320, 4320, 4320, 66, 540, 540, 66, 4320, 540, 4320, 4320, 540, 66, 540, 540, 540, 66, 4320, 540, 4320, 66, 4320, 66, 66, 540, 4320, 4320, 540, 66, 540, 66, 540, 4320, 4320, 540, 66, 540, 66, 4320, 66, 66, 66, 66, 4320, 540, 540, 4320, 540, 540, 66, 540, 4320, 540, 66, 66, 540, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 540, 4320, 540, 540, 540, 66, 4320, 66, 4320, 540, 66, 540, 66, 66, 540, 66, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 66, 66, 4320, 540, 4320, 540, 4320, 540, 66, 540, 66, 66, 66, 4320, 4320, 540, 540, 66, 66, 540, 66, 4320, 66, 66, 540, 66, 4320, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 66, 540, 4320, 540, 540, 4320, 540, 66, 540, 66, 4320, 540, 540, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 540, 66, 540, 66, 540, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 540, 540, 4320, 66, 4320, 66, 66, 66, 4320, 540, 4320, 4320, 66, 540, 540, 540, 66, 540, 66, 540, 540, 4320, 66, 66, 540, 66, 540, 540, 66, 4320, 4320, 4320, 66, 540, 540, 540, 540, 66, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 540, 540, 540, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 527016 . Total input tokens: 117464930 . Total output tokens: 105442026
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.074466073012445,
    "estimated_duration": 3600.15861178401,
    "input_throughput": 3629.7709098778987,
    "output_throughput": 3208.0336577939925,
    "total_throughput": 6837.804567671891,
    "itl": 157.66141305247783,
    "ttft": 2009549.4280515793,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4125,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.68147704927155,
    "arrivals": 175481,
    "finished_requests": 52842,
    "scheduler_time": 86.72337874129694
}
#Debug simulation 
Total elapsed time: 4.0745540669886395. Arrivals time: 0.18179532926296815 Scheduler time: 3.7169320224784315 Scheduler overhead time: 0.03444806404877454 Adapter cache time: 0.09102502587484196 Engine time: 0.034381851728539914 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-16/adapters_320_slots_160_rate_0.4-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-16/adapters_320_slots_160_rate_0.4-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 66, 4320, 4320, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 4320, 4320, 540, 66, 66, 540, 4320, 4320, 540, 540, 66, 66, 540, 4320, 4320, 66, 4320, 540, 66, 540, 4320, 66, 540, 4320, 4320, 540, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 540, 540, 540, 66, 540, 66, 4320, 66, 4320, 540, 4320, 4320, 66, 4320, 66, 4320, 540, 66, 66, 540, 540, 4320, 540, 4320, 4320, 4320, 66, 540, 540, 66, 4320, 540, 4320, 4320, 540, 66, 540, 540, 540, 66, 4320, 540, 4320, 66, 4320, 66, 66, 540, 4320, 4320, 540, 66, 540, 66, 540, 4320, 4320, 540, 66, 540, 66, 4320, 66, 66, 66, 66, 4320, 540, 540, 4320, 540, 540, 66, 540, 4320, 540, 66, 66, 540, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 540, 4320, 540, 540, 540, 66, 4320, 66, 4320, 540, 66, 540, 66, 66, 540, 66, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 66, 66, 4320, 540, 4320, 540, 4320, 540, 66, 540, 66, 66, 66, 4320, 4320, 540, 540, 66, 66, 540, 66, 4320, 66, 66, 540, 66, 4320, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 66, 540, 4320, 540, 540, 4320, 540, 66, 540, 66, 4320, 540, 540, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 540, 66, 540, 66, 540, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 540, 540, 4320, 66, 4320, 66, 66, 66, 4320, 540, 4320, 4320, 66, 540, 540, 540, 66, 540, 66, 540, 540, 4320, 66, 66, 540, 66, 540, 540, 66, 4320, 4320, 4320, 66, 540, 540, 540, 540, 66, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 540, 540, 540, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 527016 . Total input tokens: 117464930 . Total output tokens: 105442026
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.096638300048653,
    "estimated_duration": 3600.1000703102254,
    "input_throughput": 4088.6307915134157,
    "output_throughput": 3603.797046364328,
    "total_throughput": 7692.4278378777435,
    "itl": 236.8144449094532,
    "ttft": 1894775.28648275,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1634,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.885742181870018,
    "arrivals": 175481,
    "finished_requests": 59563,
    "scheduler_time": 79.16522994121435
}
#Debug simulation 
Total elapsed time: 5.096727469994221. Arrivals time: 0.20453664852539077 Scheduler time: 4.794863794639241 Scheduler overhead time: 0.024841797479894012 Adapter cache time: 0.036489875288680196 Engine time: 0.0246966183767654 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-32/adapters_320_slots_160_rate_0.4-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-32/adapters_320_slots_160_rate_0.4-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 66, 4320, 4320, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 4320, 4320, 540, 66, 66, 540, 4320, 4320, 540, 540, 66, 66, 540, 4320, 4320, 66, 4320, 540, 66, 540, 4320, 66, 540, 4320, 4320, 540, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 540, 540, 540, 66, 540, 66, 4320, 66, 4320, 540, 4320, 4320, 66, 4320, 66, 4320, 540, 66, 66, 540, 540, 4320, 540, 4320, 4320, 4320, 66, 540, 540, 66, 4320, 540, 4320, 4320, 540, 66, 540, 540, 540, 66, 4320, 540, 4320, 66, 4320, 66, 66, 540, 4320, 4320, 540, 66, 540, 66, 540, 4320, 4320, 540, 66, 540, 66, 4320, 66, 66, 66, 66, 4320, 540, 540, 4320, 540, 540, 66, 540, 4320, 540, 66, 66, 540, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 540, 4320, 540, 540, 540, 66, 4320, 66, 4320, 540, 66, 540, 66, 66, 540, 66, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 66, 66, 4320, 540, 4320, 540, 4320, 540, 66, 540, 66, 66, 66, 4320, 4320, 540, 540, 66, 66, 540, 66, 4320, 66, 66, 540, 66, 4320, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 66, 540, 4320, 540, 540, 4320, 540, 66, 540, 66, 4320, 540, 540, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 540, 66, 540, 66, 540, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 540, 540, 4320, 66, 4320, 66, 66, 66, 4320, 540, 4320, 4320, 66, 540, 540, 540, 66, 540, 66, 540, 540, 4320, 66, 66, 540, 66, 540, 540, 66, 4320, 4320, 4320, 66, 540, 540, 540, 540, 66, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 540, 540, 540, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 527016 . Total input tokens: 117464930 . Total output tokens: 105442026
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.015778782020789,
    "estimated_duration": 3600.1545749153247,
    "input_throughput": 3629.9419172320863,
    "output_throughput": 3208.0728090047755,
    "total_throughput": 6838.014726236862,
    "itl": 157.66886270882043,
    "ttft": 2009550.201527822,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4121,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.83550375346004,
    "arrivals": 175481,
    "finished_requests": 52844,
    "scheduler_time": 86.72017995114857
}
#Debug simulation 
Total elapsed time: 4.015883871004917. Arrivals time: 0.18293980974704027 Scheduler time: 3.657758390647359 Scheduler overhead time: 0.03408337413566187 Adapter cache time: 0.09137375024147332 Engine time: 0.03385509696090594 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-8/adapters_320_slots_160_rate_0.4-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-8/adapters_320_slots_160_rate_0.4-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 33, 4320, 4320, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 4320, 4320, 540, 33, 33, 540, 4320, 4320, 540, 540, 33, 33, 540, 4320, 4320, 33, 4320, 540, 33, 540, 4320, 33, 540, 4320, 4320, 540, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 540, 540, 540, 33, 540, 33, 4320, 33, 4320, 540, 4320, 4320, 33, 4320, 33, 4320, 540, 33, 33, 540, 540, 4320, 540, 4320, 4320, 4320, 33, 540, 540, 33, 4320, 540, 4320, 4320, 540, 33, 540, 540, 540, 33, 4320, 540, 4320, 33, 4320, 33, 33, 540, 4320, 4320, 540, 33, 540, 33, 540, 4320, 4320, 540, 33, 540, 33, 4320, 33, 33, 33, 33, 4320, 540, 540, 4320, 540, 540, 33, 540, 4320, 540, 33, 33, 540, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 540, 4320, 540, 540, 540, 33, 4320, 33, 4320, 540, 33, 540, 33, 33, 540, 33, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 33, 33, 4320, 540, 4320, 540, 4320, 540, 33, 540, 33, 33, 33, 4320, 4320, 540, 540, 33, 33, 540, 33, 4320, 33, 33, 540, 33, 4320, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 33, 540, 4320, 540, 540, 4320, 540, 33, 540, 33, 4320, 540, 540, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 540, 33, 540, 33, 540, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 540, 540, 4320, 33, 4320, 33, 33, 33, 4320, 540, 4320, 4320, 33, 540, 540, 540, 33, 540, 33, 540, 540, 4320, 33, 33, 540, 33, 540, 540, 33, 4320, 4320, 4320, 33, 540, 540, 540, 540, 33, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 540, 540, 540, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 523518 . Total input tokens: 116684838 . Total output tokens: 104734129
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.746561161009595,
    "estimated_duration": 3600.004326023508,
    "input_throughput": 4077.0070452143555,
    "output_throughput": 3605.062334559887,
    "total_throughput": 7682.069379774242,
    "itl": 237.30000518250876,
    "ttft": 1897175.9839424163,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1670,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.11101453236784,
    "arrivals": 174302,
    "finished_requests": 59572,
    "scheduler_time": 79.16168622648631
}
#Debug simulation 
Total elapsed time: 4.746645507984795. Arrivals time: 0.20147543877828866 Scheduler time: 4.448499771009665 Scheduler overhead time: 0.024524103908333927 Adapter cache time: 0.03637243859702721 Engine time: 0.024524652573745698 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-16/adapters_320_slots_160_rate_0.4-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-16/adapters_320_slots_160_rate_0.4-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 33, 4320, 4320, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 4320, 4320, 540, 33, 33, 540, 4320, 4320, 540, 540, 33, 33, 540, 4320, 4320, 33, 4320, 540, 33, 540, 4320, 33, 540, 4320, 4320, 540, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 540, 540, 540, 33, 540, 33, 4320, 33, 4320, 540, 4320, 4320, 33, 4320, 33, 4320, 540, 33, 33, 540, 540, 4320, 540, 4320, 4320, 4320, 33, 540, 540, 33, 4320, 540, 4320, 4320, 540, 33, 540, 540, 540, 33, 4320, 540, 4320, 33, 4320, 33, 33, 540, 4320, 4320, 540, 33, 540, 33, 540, 4320, 4320, 540, 33, 540, 33, 4320, 33, 33, 33, 33, 4320, 540, 540, 4320, 540, 540, 33, 540, 4320, 540, 33, 33, 540, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 540, 4320, 540, 540, 540, 33, 4320, 33, 4320, 540, 33, 540, 33, 33, 540, 33, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 33, 33, 4320, 540, 4320, 540, 4320, 540, 33, 540, 33, 33, 33, 4320, 4320, 540, 540, 33, 33, 540, 33, 4320, 33, 33, 540, 33, 4320, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 33, 540, 4320, 540, 540, 4320, 540, 33, 540, 33, 4320, 540, 540, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 540, 33, 540, 33, 540, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 540, 540, 4320, 33, 4320, 33, 33, 33, 4320, 540, 4320, 4320, 33, 540, 540, 540, 33, 540, 33, 540, 540, 4320, 33, 33, 540, 33, 540, 540, 33, 4320, 4320, 4320, 33, 540, 540, 540, 540, 33, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 540, 540, 540, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 523518 . Total input tokens: 116684838 . Total output tokens: 104734129
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.754059812054038,
    "estimated_duration": 3600.0581785328745,
    "input_throughput": 4076.500509772522,
    "output_throughput": 3604.460360495673,
    "total_throughput": 7680.960870268194,
    "itl": 237.32083966471095,
    "ttft": 1897313.1275365038,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1669,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.4557840098951615,
    "arrivals": 174302,
    "finished_requests": 59568,
    "scheduler_time": 79.15626013440924
}
#Debug simulation 
Total elapsed time: 4.75414890103275. Arrivals time: 0.19877039454877377 Scheduler time: 4.457642398076132 Scheduler overhead time: 0.02463543927296996 Adapter cache time: 0.03740607883082703 Engine time: 0.024418638611678034 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-32/adapters_320_slots_160_rate_0.4-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-32/adapters_320_slots_160_rate_0.4-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 33, 4320, 4320, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 4320, 4320, 540, 33, 33, 540, 4320, 4320, 540, 540, 33, 33, 540, 4320, 4320, 33, 4320, 540, 33, 540, 4320, 33, 540, 4320, 4320, 540, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 540, 540, 540, 33, 540, 33, 4320, 33, 4320, 540, 4320, 4320, 33, 4320, 33, 4320, 540, 33, 33, 540, 540, 4320, 540, 4320, 4320, 4320, 33, 540, 540, 33, 4320, 540, 4320, 4320, 540, 33, 540, 540, 540, 33, 4320, 540, 4320, 33, 4320, 33, 33, 540, 4320, 4320, 540, 33, 540, 33, 540, 4320, 4320, 540, 33, 540, 33, 4320, 33, 33, 33, 33, 4320, 540, 540, 4320, 540, 540, 33, 540, 4320, 540, 33, 33, 540, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 540, 4320, 540, 540, 540, 33, 4320, 33, 4320, 540, 33, 540, 33, 33, 540, 33, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 33, 33, 4320, 540, 4320, 540, 4320, 540, 33, 540, 33, 33, 33, 4320, 4320, 540, 540, 33, 33, 540, 33, 4320, 33, 33, 540, 33, 4320, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 33, 540, 4320, 540, 540, 4320, 540, 33, 540, 33, 4320, 540, 540, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 540, 33, 540, 33, 540, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 540, 540, 4320, 33, 4320, 33, 33, 33, 4320, 540, 4320, 4320, 33, 540, 540, 540, 33, 540, 33, 540, 540, 4320, 33, 33, 540, 33, 540, 540, 33, 4320, 4320, 4320, 33, 540, 540, 540, 540, 33, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 540, 540, 540, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 523518 . Total input tokens: 116684838 . Total output tokens: 104734129
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.015931228001136,
    "estimated_duration": 3600.0462637565606,
    "input_throughput": 3653.7472122023446,
    "output_throughput": 3242.8405483373076,
    "total_throughput": 6896.587760539652,
    "itl": 155.44074718397175,
    "ttft": 2000996.6817388104,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3853,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.613301787431451,
    "arrivals": 174302,
    "finished_requests": 53351,
    "scheduler_time": 87.84819929846269
}
#Debug simulation 
Total elapsed time: 4.01601506996667. Arrivals time: 0.18520630348939449 Scheduler time: 3.6533095558406785 Scheduler overhead time: 0.03419558174209669 Adapter cache time: 0.09286124759819359 Engine time: 0.034480656730011106 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-16/adapters_320_slots_160_rate_0.4-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-16/adapters_320_slots_160_rate_0.4-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 33, 4320, 4320, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 4320, 4320, 540, 33, 33, 540, 4320, 4320, 540, 540, 33, 33, 540, 4320, 4320, 33, 4320, 540, 33, 540, 4320, 33, 540, 4320, 4320, 540, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 540, 540, 540, 33, 540, 33, 4320, 33, 4320, 540, 4320, 4320, 33, 4320, 33, 4320, 540, 33, 33, 540, 540, 4320, 540, 4320, 4320, 4320, 33, 540, 540, 33, 4320, 540, 4320, 4320, 540, 33, 540, 540, 540, 33, 4320, 540, 4320, 33, 4320, 33, 33, 540, 4320, 4320, 540, 33, 540, 33, 540, 4320, 4320, 540, 33, 540, 33, 4320, 33, 33, 33, 33, 4320, 540, 540, 4320, 540, 540, 33, 540, 4320, 540, 33, 33, 540, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 540, 4320, 540, 540, 540, 33, 4320, 33, 4320, 540, 33, 540, 33, 33, 540, 33, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 33, 33, 4320, 540, 4320, 540, 4320, 540, 33, 540, 33, 33, 33, 4320, 4320, 540, 540, 33, 33, 540, 33, 4320, 33, 33, 540, 33, 4320, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 33, 540, 4320, 540, 540, 4320, 540, 33, 540, 33, 4320, 540, 540, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 540, 33, 540, 33, 540, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 540, 540, 4320, 33, 4320, 33, 33, 33, 4320, 540, 4320, 4320, 33, 540, 540, 540, 33, 540, 33, 540, 540, 4320, 33, 33, 540, 33, 540, 540, 33, 4320, 4320, 4320, 33, 540, 540, 540, 540, 33, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 540, 540, 540, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 523518 . Total input tokens: 116684838 . Total output tokens: 104734129
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.738983157032635,
    "estimated_duration": 3600.157296838847,
    "input_throughput": 4077.518505341325,
    "output_throughput": 3605.247196114664,
    "total_throughput": 7682.765701455989,
    "itl": 237.30554457726723,
    "ttft": 1897257.2802046854,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1673,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.22381280596588,
    "arrivals": 174302,
    "finished_requests": 59580,
    "scheduler_time": 79.16306463962138
}
#Debug simulation 
Total elapsed time: 4.7390687330043875. Arrivals time: 0.20489420217927545 Scheduler time: 4.436878458946012 Scheduler overhead time: 0.02452094911132008 Adapter cache time: 0.036976790346670896 Engine time: 0.024569213157519698 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-32/adapters_320_slots_160_rate_0.4-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-32/adapters_320_slots_160_rate_0.4-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 33, 4320, 4320, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 4320, 4320, 540, 33, 33, 540, 4320, 4320, 540, 540, 33, 33, 540, 4320, 4320, 33, 4320, 540, 33, 540, 4320, 33, 540, 4320, 4320, 540, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 540, 540, 540, 33, 540, 33, 4320, 33, 4320, 540, 4320, 4320, 33, 4320, 33, 4320, 540, 33, 33, 540, 540, 4320, 540, 4320, 4320, 4320, 33, 540, 540, 33, 4320, 540, 4320, 4320, 540, 33, 540, 540, 540, 33, 4320, 540, 4320, 33, 4320, 33, 33, 540, 4320, 4320, 540, 33, 540, 33, 540, 4320, 4320, 540, 33, 540, 33, 4320, 33, 33, 33, 33, 4320, 540, 540, 4320, 540, 540, 33, 540, 4320, 540, 33, 33, 540, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 540, 4320, 540, 540, 540, 33, 4320, 33, 4320, 540, 33, 540, 33, 33, 540, 33, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 33, 33, 4320, 540, 4320, 540, 4320, 540, 33, 540, 33, 33, 33, 4320, 4320, 540, 540, 33, 33, 540, 33, 4320, 33, 33, 540, 33, 4320, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 33, 540, 4320, 540, 540, 4320, 540, 33, 540, 33, 4320, 540, 540, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 540, 33, 540, 33, 540, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 540, 540, 4320, 33, 4320, 33, 33, 33, 4320, 540, 4320, 4320, 33, 540, 540, 540, 33, 540, 33, 540, 540, 4320, 33, 33, 540, 33, 540, 540, 33, 4320, 4320, 4320, 33, 540, 540, 540, 540, 33, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 540, 540, 540, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 523518 . Total input tokens: 116684838 . Total output tokens: 104734129
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.045577971963212,
    "estimated_duration": 3600.0805700678434,
    "input_throughput": 3654.5343205338495,
    "output_throughput": 3243.4515763573463,
    "total_throughput": 6897.985896891196,
    "itl": 155.57754613514396,
    "ttft": 2000902.306017904,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3849,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.773747646919558,
    "arrivals": 174302,
    "finished_requests": 53359,
    "scheduler_time": 87.8141728088651
}
#Debug simulation 
Total elapsed time: 4.045660859963391. Arrivals time: 0.19178385159466416 Scheduler time: 3.67727585620014 Scheduler overhead time: 0.03427207574713975 Adapter cache time: 0.09164044877979904 Engine time: 0.034673214657232165 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-16/adapters_320_slots_160_rate_0.4-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-16/adapters_320_slots_160_rate_0.4-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 33, 4320, 4320, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 4320, 4320, 540, 33, 33, 540, 4320, 4320, 540, 540, 33, 33, 540, 4320, 4320, 33, 4320, 540, 33, 540, 4320, 33, 540, 4320, 4320, 540, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 540, 540, 540, 33, 540, 33, 4320, 33, 4320, 540, 4320, 4320, 33, 4320, 33, 4320, 540, 33, 33, 540, 540, 4320, 540, 4320, 4320, 4320, 33, 540, 540, 33, 4320, 540, 4320, 4320, 540, 33, 540, 540, 540, 33, 4320, 540, 4320, 33, 4320, 33, 33, 540, 4320, 4320, 540, 33, 540, 33, 540, 4320, 4320, 540, 33, 540, 33, 4320, 33, 33, 33, 33, 4320, 540, 540, 4320, 540, 540, 33, 540, 4320, 540, 33, 33, 540, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 540, 4320, 540, 540, 540, 33, 4320, 33, 4320, 540, 33, 540, 33, 33, 540, 33, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 33, 33, 4320, 540, 4320, 540, 4320, 540, 33, 540, 33, 33, 33, 4320, 4320, 540, 540, 33, 33, 540, 33, 4320, 33, 33, 540, 33, 4320, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 33, 540, 4320, 540, 540, 4320, 540, 33, 540, 33, 4320, 540, 540, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 540, 33, 540, 33, 540, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 540, 540, 4320, 33, 4320, 33, 33, 33, 4320, 540, 4320, 4320, 33, 540, 540, 540, 33, 540, 33, 540, 540, 4320, 33, 33, 540, 33, 540, 540, 33, 4320, 4320, 4320, 33, 540, 540, 540, 540, 33, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 540, 540, 540, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 523518 . Total input tokens: 116684838 . Total output tokens: 104734129
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.93145775294397,
    "estimated_duration": 3600.1503048658524,
    "input_throughput": 4077.349765136255,
    "output_throughput": 3605.224754771352,
    "total_throughput": 7682.574519907606,
    "itl": 237.2971786685193,
    "ttft": 1897141.685704587,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1675,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.008334243961003,
    "arrivals": 174302,
    "finished_requests": 59579,
    "scheduler_time": 79.16687150840858
}
#Debug simulation 
Total elapsed time: 4.931519841949921. Arrivals time: 0.3976905752788298 Scheduler time: 4.436566806631163 Scheduler overhead time: 0.024566360167227685 Adapter cache time: 0.0370311004226096 Engine time: 0.02446138404775411 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-32/adapters_320_slots_160_rate_0.4-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-32/adapters_320_slots_160_rate_0.4-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 33, 4320, 4320, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 4320, 4320, 540, 33, 33, 540, 4320, 4320, 540, 540, 33, 33, 540, 4320, 4320, 33, 4320, 540, 33, 540, 4320, 33, 540, 4320, 4320, 540, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 540, 540, 540, 33, 540, 33, 4320, 33, 4320, 540, 4320, 4320, 33, 4320, 33, 4320, 540, 33, 33, 540, 540, 4320, 540, 4320, 4320, 4320, 33, 540, 540, 33, 4320, 540, 4320, 4320, 540, 33, 540, 540, 540, 33, 4320, 540, 4320, 33, 4320, 33, 33, 540, 4320, 4320, 540, 33, 540, 33, 540, 4320, 4320, 540, 33, 540, 33, 4320, 33, 33, 33, 33, 4320, 540, 540, 4320, 540, 540, 33, 540, 4320, 540, 33, 33, 540, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 540, 4320, 540, 540, 540, 33, 4320, 33, 4320, 540, 33, 540, 33, 33, 540, 33, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 33, 33, 4320, 540, 4320, 540, 4320, 540, 33, 540, 33, 33, 33, 4320, 4320, 540, 540, 33, 33, 540, 33, 4320, 33, 33, 540, 33, 4320, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 33, 540, 4320, 540, 540, 4320, 540, 33, 540, 33, 4320, 540, 540, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 540, 33, 540, 33, 540, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 540, 540, 4320, 33, 4320, 33, 33, 33, 4320, 540, 4320, 4320, 33, 540, 540, 540, 33, 540, 33, 540, 540, 4320, 33, 33, 540, 33, 540, 540, 33, 4320, 4320, 4320, 33, 540, 540, 540, 540, 33, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 540, 540, 540, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 523518 . Total input tokens: 116684838 . Total output tokens: 104734129
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.03850148798665,
    "estimated_duration": 3600.0663710476015,
    "input_throughput": 3654.1781856571374,
    "output_throughput": 3243.381870374303,
    "total_throughput": 6897.560056031441,
    "itl": 155.60487997173473,
    "ttft": 2000850.7167352852,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3851,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.939210458061778,
    "arrivals": 174302,
    "finished_requests": 53356,
    "scheduler_time": 87.80625599183082
}
#Debug simulation 
Total elapsed time: 4.038583127956372. Arrivals time: 0.1928606708534062 Scheduler time: 3.6684039356769063 Scheduler overhead time: 0.03414073842577636 Adapter cache time: 0.09263793518766761 Engine time: 0.034587599511723965 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-8/adapters_320_slots_160_rate_0.4-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-8/adapters_320_slots_160_rate_0.4-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 135, 4320, 4320, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 4320, 4320, 270, 135, 135, 270, 4320, 4320, 270, 270, 135, 135, 270, 4320, 4320, 135, 4320, 270, 135, 270, 4320, 135, 270, 4320, 4320, 270, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 270, 270, 270, 135, 270, 135, 4320, 135, 4320, 270, 4320, 4320, 135, 4320, 135, 4320, 270, 135, 135, 270, 270, 4320, 270, 4320, 4320, 4320, 135, 270, 270, 135, 4320, 270, 4320, 4320, 270, 135, 270, 270, 270, 135, 4320, 270, 4320, 135, 4320, 135, 135, 270, 4320, 4320, 270, 135, 270, 135, 270, 4320, 4320, 270, 135, 270, 135, 4320, 135, 135, 135, 135, 4320, 270, 270, 4320, 270, 270, 135, 270, 4320, 270, 135, 135, 270, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 270, 4320, 270, 270, 270, 135, 4320, 135, 4320, 270, 135, 270, 135, 135, 270, 135, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 135, 135, 4320, 270, 4320, 270, 4320, 270, 135, 270, 135, 135, 135, 4320, 4320, 270, 270, 135, 135, 270, 135, 4320, 135, 135, 270, 135, 4320, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 135, 270, 4320, 270, 270, 4320, 270, 135, 270, 135, 4320, 270, 270, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 270, 135, 270, 135, 270, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 270, 270, 4320, 135, 4320, 135, 135, 135, 4320, 270, 4320, 4320, 135, 270, 270, 270, 135, 270, 135, 270, 270, 4320, 135, 135, 270, 135, 270, 270, 135, 4320, 4320, 4320, 135, 270, 270, 270, 270, 135, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 270, 270, 270, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 505440 . Total input tokens: 112700817 . Total output tokens: 101087654
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.791479517996777,
    "estimated_duration": 3600.2333053760917,
    "input_throughput": 4124.031900329577,
    "output_throughput": 3604.583897555035,
    "total_throughput": 7728.615797884613,
    "itl": 235.68531144722857,
    "ttft": 1878827.2003158345,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2225,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.809585230250578,
    "arrivals": 168141,
    "finished_requests": 59470,
    "scheduler_time": 78.96777745109493
}
#Debug simulation 
Total elapsed time: 4.791563513979781. Arrivals time: 0.2016152857686393 Scheduler time: 4.482962553447578 Scheduler overhead time: 0.024738414853345603 Adapter cache time: 0.04602220834931359 Engine time: 0.024796167912427336 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-16/adapters_320_slots_160_rate_0.4-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-16/adapters_320_slots_160_rate_0.4-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 135, 4320, 4320, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 4320, 4320, 270, 135, 135, 270, 4320, 4320, 270, 270, 135, 135, 270, 4320, 4320, 135, 4320, 270, 135, 270, 4320, 135, 270, 4320, 4320, 270, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 270, 270, 270, 135, 270, 135, 4320, 135, 4320, 270, 4320, 4320, 135, 4320, 135, 4320, 270, 135, 135, 270, 270, 4320, 270, 4320, 4320, 4320, 135, 270, 270, 135, 4320, 270, 4320, 4320, 270, 135, 270, 270, 270, 135, 4320, 270, 4320, 135, 4320, 135, 135, 270, 4320, 4320, 270, 135, 270, 135, 270, 4320, 4320, 270, 135, 270, 135, 4320, 135, 135, 135, 135, 4320, 270, 270, 4320, 270, 270, 135, 270, 4320, 270, 135, 135, 270, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 270, 4320, 270, 270, 270, 135, 4320, 135, 4320, 270, 135, 270, 135, 135, 270, 135, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 135, 135, 4320, 270, 4320, 270, 4320, 270, 135, 270, 135, 135, 135, 4320, 4320, 270, 270, 135, 135, 270, 135, 4320, 135, 135, 270, 135, 4320, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 135, 270, 4320, 270, 270, 4320, 270, 135, 270, 135, 4320, 270, 270, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 270, 135, 270, 135, 270, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 270, 270, 4320, 135, 4320, 135, 135, 135, 4320, 270, 4320, 4320, 135, 270, 270, 270, 135, 270, 135, 270, 270, 4320, 135, 135, 270, 135, 270, 270, 135, 4320, 4320, 4320, 135, 270, 270, 270, 270, 135, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 270, 270, 270, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 505440 . Total input tokens: 112700817 . Total output tokens: 101087654
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.7529769809916615,
    "estimated_duration": 3600.0889639603274,
    "input_throughput": 4123.562819866913,
    "output_throughput": 3604.404816075816,
    "total_throughput": 7727.967635942729,
    "itl": 235.71141038921854,
    "ttft": 1878946.9758241135,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2223,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.2524200674958434,
    "arrivals": 168141,
    "finished_requests": 59464,
    "scheduler_time": 78.95572826867308
}
#Debug simulation 
Total elapsed time: 4.7530833480414. Arrivals time: 0.20130692346720025 Scheduler time: 4.445048202178441 Scheduler overhead time: 0.024702184135094285 Adapter cache time: 0.04619239823659882 Engine time: 0.024521000625099987 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-32/adapters_320_slots_160_rate_0.4-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-32/adapters_320_slots_160_rate_0.4-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 135, 4320, 4320, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 4320, 4320, 270, 135, 135, 270, 4320, 4320, 270, 270, 135, 135, 270, 4320, 4320, 135, 4320, 270, 135, 270, 4320, 135, 270, 4320, 4320, 270, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 270, 270, 270, 135, 270, 135, 4320, 135, 4320, 270, 4320, 4320, 135, 4320, 135, 4320, 270, 135, 135, 270, 270, 4320, 270, 4320, 4320, 4320, 135, 270, 270, 135, 4320, 270, 4320, 4320, 270, 135, 270, 270, 270, 135, 4320, 270, 4320, 135, 4320, 135, 135, 270, 4320, 4320, 270, 135, 270, 135, 270, 4320, 4320, 270, 135, 270, 135, 4320, 135, 135, 135, 135, 4320, 270, 270, 4320, 270, 270, 135, 270, 4320, 270, 135, 135, 270, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 270, 4320, 270, 270, 270, 135, 4320, 135, 4320, 270, 135, 270, 135, 135, 270, 135, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 135, 135, 4320, 270, 4320, 270, 4320, 270, 135, 270, 135, 135, 135, 4320, 4320, 270, 270, 135, 135, 270, 135, 4320, 135, 135, 270, 135, 4320, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 135, 270, 4320, 270, 270, 4320, 270, 135, 270, 135, 4320, 270, 270, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 270, 135, 270, 135, 270, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 270, 270, 4320, 135, 4320, 135, 135, 135, 4320, 270, 4320, 4320, 135, 270, 270, 270, 135, 270, 135, 270, 270, 4320, 135, 135, 270, 135, 270, 270, 135, 4320, 4320, 4320, 135, 270, 270, 270, 270, 135, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 270, 270, 270, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 505440 . Total input tokens: 112700817 . Total output tokens: 101087654
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.091453647997696,
    "estimated_duration": 3600.091529359217,
    "input_throughput": 3767.7292061555713,
    "output_throughput": 3316.9689999869133,
    "total_throughput": 7084.698206142485,
    "itl": 151.87933095193137,
    "ttft": 1964062.8357423756,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3692,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.07877858349979,
    "arrivals": 168141,
    "finished_requests": 54411,
    "scheduler_time": 89.34024302541879
}
#Debug simulation 
Total elapsed time: 4.0915381429949775. Arrivals time: 0.18601216952083632 Scheduler time: 3.7267275259364396 Scheduler overhead time: 0.03478199028177187 Adapter cache time: 0.09259566495893523 Engine time: 0.03502735716756433 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-16/adapters_320_slots_160_rate_0.4-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-16/adapters_320_slots_160_rate_0.4-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 135, 4320, 4320, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 4320, 4320, 270, 135, 135, 270, 4320, 4320, 270, 270, 135, 135, 270, 4320, 4320, 135, 4320, 270, 135, 270, 4320, 135, 270, 4320, 4320, 270, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 270, 270, 270, 135, 270, 135, 4320, 135, 4320, 270, 4320, 4320, 135, 4320, 135, 4320, 270, 135, 135, 270, 270, 4320, 270, 4320, 4320, 4320, 135, 270, 270, 135, 4320, 270, 4320, 4320, 270, 135, 270, 270, 270, 135, 4320, 270, 4320, 135, 4320, 135, 135, 270, 4320, 4320, 270, 135, 270, 135, 270, 4320, 4320, 270, 135, 270, 135, 4320, 135, 135, 135, 135, 4320, 270, 270, 4320, 270, 270, 135, 270, 4320, 270, 135, 135, 270, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 270, 4320, 270, 270, 270, 135, 4320, 135, 4320, 270, 135, 270, 135, 135, 270, 135, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 135, 135, 4320, 270, 4320, 270, 4320, 270, 135, 270, 135, 135, 135, 4320, 4320, 270, 270, 135, 135, 270, 135, 4320, 135, 135, 270, 135, 4320, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 135, 270, 4320, 270, 270, 4320, 270, 135, 270, 135, 4320, 270, 270, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 270, 135, 270, 135, 270, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 270, 270, 4320, 135, 4320, 135, 135, 135, 4320, 270, 4320, 4320, 135, 270, 270, 270, 135, 270, 135, 270, 270, 4320, 135, 135, 270, 135, 270, 270, 135, 4320, 4320, 4320, 135, 270, 270, 270, 270, 135, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 270, 270, 270, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 505440 . Total input tokens: 112700817 . Total output tokens: 101087654
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.800468211004045,
    "estimated_duration": 3600.1720282422853,
    "input_throughput": 4123.632949631068,
    "output_throughput": 3604.3708184509883,
    "total_throughput": 7728.003768082056,
    "itl": 235.69189386127937,
    "ttft": 1878909.0508707713,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2224,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.939157341317967,
    "arrivals": 168141,
    "finished_requests": 59466,
    "scheduler_time": 78.96384447940946
}
#Debug simulation 
Total elapsed time: 4.800551955995616. Arrivals time: 0.2044265739968978 Scheduler time: 4.488209103117697 Scheduler overhead time: 0.024862749967724085 Adapter cache time: 0.046852026716805995 Engine time: 0.02481262374203652 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-32/adapters_320_slots_160_rate_0.4-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-32/adapters_320_slots_160_rate_0.4-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 135, 4320, 4320, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 4320, 4320, 270, 135, 135, 270, 4320, 4320, 270, 270, 135, 135, 270, 4320, 4320, 135, 4320, 270, 135, 270, 4320, 135, 270, 4320, 4320, 270, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 270, 270, 270, 135, 270, 135, 4320, 135, 4320, 270, 4320, 4320, 135, 4320, 135, 4320, 270, 135, 135, 270, 270, 4320, 270, 4320, 4320, 4320, 135, 270, 270, 135, 4320, 270, 4320, 4320, 270, 135, 270, 270, 270, 135, 4320, 270, 4320, 135, 4320, 135, 135, 270, 4320, 4320, 270, 135, 270, 135, 270, 4320, 4320, 270, 135, 270, 135, 4320, 135, 135, 135, 135, 4320, 270, 270, 4320, 270, 270, 135, 270, 4320, 270, 135, 135, 270, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 270, 4320, 270, 270, 270, 135, 4320, 135, 4320, 270, 135, 270, 135, 135, 270, 135, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 135, 135, 4320, 270, 4320, 270, 4320, 270, 135, 270, 135, 135, 135, 4320, 4320, 270, 270, 135, 135, 270, 135, 4320, 135, 135, 270, 135, 4320, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 135, 270, 4320, 270, 270, 4320, 270, 135, 270, 135, 4320, 270, 270, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 270, 135, 270, 135, 270, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 270, 270, 4320, 135, 4320, 135, 135, 135, 4320, 270, 4320, 4320, 135, 270, 270, 270, 135, 270, 135, 270, 270, 4320, 135, 135, 270, 135, 270, 270, 135, 4320, 4320, 4320, 135, 270, 270, 270, 270, 135, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 270, 270, 270, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 505440 . Total input tokens: 112700817 . Total output tokens: 101087654
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.105075269995723,
    "estimated_duration": 3600.043554229115,
    "input_throughput": 3767.2316447582816,
    "output_throughput": 3316.6862623018415,
    "total_throughput": 7083.917907060123,
    "itl": 151.8835763001077,
    "ttft": 1964025.6772525904,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3687,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.224600151403974,
    "arrivals": 168141,
    "finished_requests": 54405,
    "scheduler_time": 89.33592722873526
}
#Debug simulation 
Total elapsed time: 4.1051605170359835. Arrivals time: 0.1866755266673863 Scheduler time: 3.7408573965076357 Scheduler overhead time: 0.035267365048639476 Adapter cache time: 0.09084990923292935 Engine time: 0.03511109156534076 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-16/adapters_320_slots_160_rate_0.4-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-16/adapters_320_slots_160_rate_0.4-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 135, 4320, 4320, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 4320, 4320, 270, 135, 135, 270, 4320, 4320, 270, 270, 135, 135, 270, 4320, 4320, 135, 4320, 270, 135, 270, 4320, 135, 270, 4320, 4320, 270, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 270, 270, 270, 135, 270, 135, 4320, 135, 4320, 270, 4320, 4320, 135, 4320, 135, 4320, 270, 135, 135, 270, 270, 4320, 270, 4320, 4320, 4320, 135, 270, 270, 135, 4320, 270, 4320, 4320, 270, 135, 270, 270, 270, 135, 4320, 270, 4320, 135, 4320, 135, 135, 270, 4320, 4320, 270, 135, 270, 135, 270, 4320, 4320, 270, 135, 270, 135, 4320, 135, 135, 135, 135, 4320, 270, 270, 4320, 270, 270, 135, 270, 4320, 270, 135, 135, 270, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 270, 4320, 270, 270, 270, 135, 4320, 135, 4320, 270, 135, 270, 135, 135, 270, 135, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 135, 135, 4320, 270, 4320, 270, 4320, 270, 135, 270, 135, 135, 135, 4320, 4320, 270, 270, 135, 135, 270, 135, 4320, 135, 135, 270, 135, 4320, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 135, 270, 4320, 270, 270, 4320, 270, 135, 270, 135, 4320, 270, 270, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 270, 135, 270, 135, 270, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 270, 270, 4320, 135, 4320, 135, 135, 135, 4320, 270, 4320, 4320, 135, 270, 270, 270, 135, 270, 135, 270, 270, 4320, 135, 135, 270, 135, 270, 270, 135, 4320, 4320, 4320, 135, 270, 270, 270, 270, 135, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 270, 270, 270, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 505440 . Total input tokens: 112700817 . Total output tokens: 101087654
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.776869522989728,
    "estimated_duration": 3600.0230171789876,
    "input_throughput": 4124.273630793235,
    "output_throughput": 3604.735563654536,
    "total_throughput": 7729.009194447771,
    "itl": 235.67410026807943,
    "ttft": 1878765.2718040482,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2223,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.646881805567337,
    "arrivals": 168141,
    "finished_requests": 59470,
    "scheduler_time": 78.96622558672634
}
#Debug simulation 
Total elapsed time: 4.776958213013131. Arrivals time: 0.2100779679021798 Scheduler time: 4.459055665589403 Scheduler overhead time: 0.024734942766372114 Adapter cache time: 0.047119028109591454 Engine time: 0.024614992027636617 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-32/adapters_320_slots_160_rate_0.4-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-32/adapters_320_slots_160_rate_0.4-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 135, 4320, 4320, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 4320, 4320, 270, 135, 135, 270, 4320, 4320, 270, 270, 135, 135, 270, 4320, 4320, 135, 4320, 270, 135, 270, 4320, 135, 270, 4320, 4320, 270, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 270, 270, 270, 135, 270, 135, 4320, 135, 4320, 270, 4320, 4320, 135, 4320, 135, 4320, 270, 135, 135, 270, 270, 4320, 270, 4320, 4320, 4320, 135, 270, 270, 135, 4320, 270, 4320, 4320, 270, 135, 270, 270, 270, 135, 4320, 270, 4320, 135, 4320, 135, 135, 270, 4320, 4320, 270, 135, 270, 135, 270, 4320, 4320, 270, 135, 270, 135, 4320, 135, 135, 135, 135, 4320, 270, 270, 4320, 270, 270, 135, 270, 4320, 270, 135, 135, 270, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 270, 4320, 270, 270, 270, 135, 4320, 135, 4320, 270, 135, 270, 135, 135, 270, 135, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 135, 135, 4320, 270, 4320, 270, 4320, 270, 135, 270, 135, 135, 135, 4320, 4320, 270, 270, 135, 135, 270, 135, 4320, 135, 135, 270, 135, 4320, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 135, 270, 4320, 270, 270, 4320, 270, 135, 270, 135, 4320, 270, 270, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 270, 135, 270, 135, 270, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 270, 270, 4320, 135, 4320, 135, 135, 135, 4320, 270, 4320, 4320, 135, 270, 270, 270, 135, 270, 135, 270, 270, 4320, 135, 135, 270, 135, 270, 270, 135, 4320, 4320, 4320, 135, 270, 270, 270, 270, 135, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 270, 270, 270, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 505440 . Total input tokens: 112700817 . Total output tokens: 101087654
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.326350853021722,
    "estimated_duration": 3600.072130692677,
    "input_throughput": 3767.503957591632,
    "output_throughput": 3316.7457668973334,
    "total_throughput": 7084.2497244889655,
    "itl": 151.89301954208221,
    "ttft": 1963998.7082745496,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3693,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.394903304464352,
    "arrivals": 168141,
    "finished_requests": 54407,
    "scheduler_time": 89.33245946818847
}
#Debug simulation 
Total elapsed time: 4.32641539798351. Arrivals time: 0.19213077845051885 Scheduler time: 3.9556325259036385 Scheduler overhead time: 0.03505486430367455 Adapter cache time: 0.09176658641081303 Engine time: 0.035386364615987986 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_320_slots_160_rate_0.4-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_320_slots_160_rate_0.4-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 66, 4320, 4320, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 4320, 4320, 270, 66, 66, 270, 4320, 4320, 270, 270, 66, 66, 270, 4320, 4320, 66, 4320, 270, 66, 270, 4320, 66, 270, 4320, 4320, 270, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 270, 270, 270, 66, 270, 66, 4320, 66, 4320, 270, 4320, 4320, 66, 4320, 66, 4320, 270, 66, 66, 270, 270, 4320, 270, 4320, 4320, 4320, 66, 270, 270, 66, 4320, 270, 4320, 4320, 270, 66, 270, 270, 270, 66, 4320, 270, 4320, 66, 4320, 66, 66, 270, 4320, 4320, 270, 66, 270, 66, 270, 4320, 4320, 270, 66, 270, 66, 4320, 66, 66, 66, 66, 4320, 270, 270, 4320, 270, 270, 66, 270, 4320, 270, 66, 66, 270, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 270, 4320, 270, 270, 270, 66, 4320, 66, 4320, 270, 66, 270, 66, 66, 270, 66, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 66, 66, 4320, 270, 4320, 270, 4320, 270, 66, 270, 66, 66, 66, 4320, 4320, 270, 270, 66, 66, 270, 66, 4320, 66, 66, 270, 66, 4320, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 66, 270, 4320, 270, 270, 4320, 270, 66, 270, 66, 4320, 270, 270, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 270, 66, 270, 66, 270, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 270, 270, 4320, 66, 4320, 66, 66, 66, 4320, 270, 4320, 4320, 66, 270, 270, 270, 66, 270, 66, 270, 270, 4320, 66, 66, 270, 66, 270, 270, 66, 4320, 4320, 4320, 66, 270, 270, 270, 270, 66, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 270, 270, 270, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 498126 . Total input tokens: 111065075 . Total output tokens: 99648594
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.408714498975314,
    "estimated_duration": 3600.2561611593387,
    "input_throughput": 4134.517193689544,
    "output_throughput": 3600.5593545948495,
    "total_throughput": 7735.0765482843935,
    "itl": 235.2412177124063,
    "ttft": 1867764.7725156373,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2606,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.975631060688998,
    "arrivals": 165887,
    "finished_requests": 59782,
    "scheduler_time": 78.89815730273077
}
#Debug simulation 
Total elapsed time: 4.408800668956246. Arrivals time: 0.1991564807249233 Scheduler time: 4.095764420519117 Scheduler overhead time: 0.024575467396061867 Adapter cache time: 0.05349381442647427 Engine time: 0.02455132087925449 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_320_slots_160_rate_0.4-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_320_slots_160_rate_0.4-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 66, 4320, 4320, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 4320, 4320, 270, 66, 66, 270, 4320, 4320, 270, 270, 66, 66, 270, 4320, 4320, 66, 4320, 270, 66, 270, 4320, 66, 270, 4320, 4320, 270, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 270, 270, 270, 66, 270, 66, 4320, 66, 4320, 270, 4320, 4320, 66, 4320, 66, 4320, 270, 66, 66, 270, 270, 4320, 270, 4320, 4320, 4320, 66, 270, 270, 66, 4320, 270, 4320, 4320, 270, 66, 270, 270, 270, 66, 4320, 270, 4320, 66, 4320, 66, 66, 270, 4320, 4320, 270, 66, 270, 66, 270, 4320, 4320, 270, 66, 270, 66, 4320, 66, 66, 66, 66, 4320, 270, 270, 4320, 270, 270, 66, 270, 4320, 270, 66, 66, 270, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 270, 4320, 270, 270, 270, 66, 4320, 66, 4320, 270, 66, 270, 66, 66, 270, 66, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 66, 66, 4320, 270, 4320, 270, 4320, 270, 66, 270, 66, 66, 66, 4320, 4320, 270, 270, 66, 66, 270, 66, 4320, 66, 66, 270, 66, 4320, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 66, 270, 4320, 270, 270, 4320, 270, 66, 270, 66, 4320, 270, 270, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 270, 66, 270, 66, 270, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 270, 270, 4320, 66, 4320, 66, 66, 66, 4320, 270, 4320, 4320, 66, 270, 270, 270, 66, 270, 66, 270, 270, 4320, 66, 66, 270, 66, 270, 270, 66, 4320, 4320, 4320, 66, 270, 270, 270, 270, 66, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 270, 270, 270, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 498126 . Total input tokens: 111065075 . Total output tokens: 99648594
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.565177429001778,
    "estimated_duration": 3600.154427172475,
    "input_throughput": 4134.1390490544545,
    "output_throughput": 3600.159177110505,
    "total_throughput": 7734.2982261649595,
    "itl": 235.27755871700361,
    "ttft": 1867887.4979981305,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2604,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.497455417329641,
    "arrivals": 165887,
    "finished_requests": 59774,
    "scheduler_time": 78.88569113881972
}
#Debug simulation 
Total elapsed time: 4.5652431800263. Arrivals time: 0.2015642267651856 Scheduler time: 4.2498533700127155 Scheduler overhead time: 0.024574693641625345 Adapter cache time: 0.05336400860687718 Engine time: 0.024634491535834968 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-32/adapters_320_slots_160_rate_0.4-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-32/adapters_320_slots_160_rate_0.4-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 66, 4320, 4320, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 4320, 4320, 270, 66, 66, 270, 4320, 4320, 270, 270, 66, 66, 270, 4320, 4320, 66, 4320, 270, 66, 270, 4320, 66, 270, 4320, 4320, 270, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 270, 270, 270, 66, 270, 66, 4320, 66, 4320, 270, 4320, 4320, 66, 4320, 66, 4320, 270, 66, 66, 270, 270, 4320, 270, 4320, 4320, 4320, 66, 270, 270, 66, 4320, 270, 4320, 4320, 270, 66, 270, 270, 270, 66, 4320, 270, 4320, 66, 4320, 66, 66, 270, 4320, 4320, 270, 66, 270, 66, 270, 4320, 4320, 270, 66, 270, 66, 4320, 66, 66, 66, 66, 4320, 270, 270, 4320, 270, 270, 66, 270, 4320, 270, 66, 66, 270, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 270, 4320, 270, 270, 270, 66, 4320, 66, 4320, 270, 66, 270, 66, 66, 270, 66, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 66, 66, 4320, 270, 4320, 270, 4320, 270, 66, 270, 66, 66, 66, 4320, 4320, 270, 270, 66, 66, 270, 66, 4320, 66, 66, 270, 66, 4320, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 66, 270, 4320, 270, 270, 4320, 270, 66, 270, 66, 4320, 270, 270, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 270, 66, 270, 66, 270, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 270, 270, 4320, 66, 4320, 66, 66, 66, 4320, 270, 4320, 4320, 66, 270, 270, 270, 66, 270, 66, 270, 270, 4320, 66, 66, 270, 66, 270, 270, 66, 4320, 4320, 4320, 66, 270, 270, 270, 270, 66, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 270, 270, 270, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 498126 . Total input tokens: 111065075 . Total output tokens: 99648594
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.21627814299427,
    "estimated_duration": 3600.106310090118,
    "input_throughput": 3905.9960425579766,
    "output_throughput": 3416.1852291778964,
    "total_throughput": 7322.1812717358725,
    "itl": 148.00164891471763,
    "ttft": 1925228.4249605597,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2897,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.47133424427332,
    "arrivals": 165887,
    "finished_requests": 56486,
    "scheduler_time": 91.59922838061016
}
#Debug simulation 
Total elapsed time: 4.21637285099132. Arrivals time: 0.1970586003153585 Scheduler time: 3.8509280963335186 Scheduler overhead time: 0.03555899177445099 Adapter cache time: 0.08004581101704389 Engine time: 0.03595863952068612 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_320_slots_160_rate_0.4-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_320_slots_160_rate_0.4-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 66, 4320, 4320, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 4320, 4320, 270, 66, 66, 270, 4320, 4320, 270, 270, 66, 66, 270, 4320, 4320, 66, 4320, 270, 66, 270, 4320, 66, 270, 4320, 4320, 270, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 270, 270, 270, 66, 270, 66, 4320, 66, 4320, 270, 4320, 4320, 66, 4320, 66, 4320, 270, 66, 66, 270, 270, 4320, 270, 4320, 4320, 4320, 66, 270, 270, 66, 4320, 270, 4320, 4320, 270, 66, 270, 270, 270, 66, 4320, 270, 4320, 66, 4320, 66, 66, 270, 4320, 4320, 270, 66, 270, 66, 270, 4320, 4320, 270, 66, 270, 66, 4320, 66, 66, 66, 66, 4320, 270, 270, 4320, 270, 270, 66, 270, 4320, 270, 66, 66, 270, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 270, 4320, 270, 270, 270, 66, 4320, 66, 4320, 270, 66, 270, 66, 66, 270, 66, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 66, 66, 4320, 270, 4320, 270, 4320, 270, 66, 270, 66, 66, 66, 4320, 4320, 270, 270, 66, 66, 270, 66, 4320, 66, 66, 270, 66, 4320, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 66, 270, 4320, 270, 270, 4320, 270, 66, 270, 66, 4320, 270, 270, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 270, 66, 270, 66, 270, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 270, 270, 4320, 66, 4320, 66, 66, 66, 4320, 270, 4320, 4320, 66, 270, 270, 270, 66, 270, 66, 270, 270, 4320, 66, 66, 270, 66, 270, 270, 66, 4320, 4320, 4320, 66, 270, 270, 270, 270, 66, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 270, 270, 270, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 498126 . Total input tokens: 111065075 . Total output tokens: 99648594
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.563983594998717,
    "estimated_duration": 3600.163449823893,
    "input_throughput": 4134.445340454779,
    "output_throughput": 3600.3776441411433,
    "total_throughput": 7734.822984595923,
    "itl": 235.25278614111554,
    "ttft": 1867810.381828766,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2607,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.1252061361095,
    "arrivals": 165887,
    "finished_requests": 59778,
    "scheduler_time": 78.89338419960076
}
#Debug simulation 
Total elapsed time: 4.564066972001456. Arrivals time: 0.38048914313549176 Scheduler time: 4.070149720064364 Scheduler overhead time: 0.024588877509813756 Adapter cache time: 0.052883455995470285 Engine time: 0.024676614673808217 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-32/adapters_320_slots_160_rate_0.4-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-32/adapters_320_slots_160_rate_0.4-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 66, 4320, 4320, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 4320, 4320, 270, 66, 66, 270, 4320, 4320, 270, 270, 66, 66, 270, 4320, 4320, 66, 4320, 270, 66, 270, 4320, 66, 270, 4320, 4320, 270, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 270, 270, 270, 66, 270, 66, 4320, 66, 4320, 270, 4320, 4320, 66, 4320, 66, 4320, 270, 66, 66, 270, 270, 4320, 270, 4320, 4320, 4320, 66, 270, 270, 66, 4320, 270, 4320, 4320, 270, 66, 270, 270, 270, 66, 4320, 270, 4320, 66, 4320, 66, 66, 270, 4320, 4320, 270, 66, 270, 66, 270, 4320, 4320, 270, 66, 270, 66, 4320, 66, 66, 66, 66, 4320, 270, 270, 4320, 270, 270, 66, 270, 4320, 270, 66, 66, 270, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 270, 4320, 270, 270, 270, 66, 4320, 66, 4320, 270, 66, 270, 66, 66, 270, 66, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 66, 66, 4320, 270, 4320, 270, 4320, 270, 66, 270, 66, 66, 66, 4320, 4320, 270, 270, 66, 66, 270, 66, 4320, 66, 66, 270, 66, 4320, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 66, 270, 4320, 270, 270, 4320, 270, 66, 270, 66, 4320, 270, 270, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 270, 66, 270, 66, 270, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 270, 270, 4320, 66, 4320, 66, 66, 66, 4320, 270, 4320, 4320, 66, 270, 270, 270, 66, 270, 66, 270, 270, 4320, 66, 66, 270, 66, 270, 270, 66, 4320, 4320, 4320, 66, 270, 270, 270, 270, 66, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 270, 270, 270, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 498126 . Total input tokens: 111065075 . Total output tokens: 99648594
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.189909501990769,
    "estimated_duration": 3600.154040654882,
    "input_throughput": 3905.7470433798985,
    "output_throughput": 3415.8607829355587,
    "total_throughput": 7321.607826315457,
    "itl": 148.01103142053938,
    "ttft": 1925329.0600656145,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2890,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.57689804624726,
    "arrivals": 165887,
    "finished_requests": 56483,
    "scheduler_time": 91.596259756481
}
#Debug simulation 
Total elapsed time: 4.189996607019566. Arrivals time: 0.2007456999272108 Scheduler time: 3.8213150845258497 Scheduler overhead time: 0.035515652038156986 Adapter cache time: 0.07967890426516533 Engine time: 0.036115081049501896 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_320_slots_160_rate_0.4-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_320_slots_160_rate_0.4-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 66, 4320, 4320, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 4320, 4320, 270, 66, 66, 270, 4320, 4320, 270, 270, 66, 66, 270, 4320, 4320, 66, 4320, 270, 66, 270, 4320, 66, 270, 4320, 4320, 270, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 270, 270, 270, 66, 270, 66, 4320, 66, 4320, 270, 4320, 4320, 66, 4320, 66, 4320, 270, 66, 66, 270, 270, 4320, 270, 4320, 4320, 4320, 66, 270, 270, 66, 4320, 270, 4320, 4320, 270, 66, 270, 270, 270, 66, 4320, 270, 4320, 66, 4320, 66, 66, 270, 4320, 4320, 270, 66, 270, 66, 270, 4320, 4320, 270, 66, 270, 66, 4320, 66, 66, 66, 66, 4320, 270, 270, 4320, 270, 270, 66, 270, 4320, 270, 66, 66, 270, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 270, 4320, 270, 270, 270, 66, 4320, 66, 4320, 270, 66, 270, 66, 66, 270, 66, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 66, 66, 4320, 270, 4320, 270, 4320, 270, 66, 270, 66, 66, 66, 4320, 4320, 270, 270, 66, 66, 270, 66, 4320, 66, 66, 270, 66, 4320, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 66, 270, 4320, 270, 270, 4320, 270, 66, 270, 66, 4320, 270, 270, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 270, 66, 270, 66, 270, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 270, 270, 4320, 66, 4320, 66, 66, 66, 4320, 270, 4320, 4320, 66, 270, 270, 270, 66, 270, 66, 270, 270, 4320, 66, 66, 270, 66, 270, 270, 66, 4320, 4320, 4320, 66, 270, 270, 270, 270, 66, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 270, 270, 270, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 498126 . Total input tokens: 111065075 . Total output tokens: 99648594
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.547100289026275,
    "estimated_duration": 3600.2101289980565,
    "input_throughput": 4134.728937097559,
    "output_throughput": 3600.8925966795973,
    "total_throughput": 7735.621533777156,
    "itl": 235.23124391596113,
    "ttft": 1867653.2274727544,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2606,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.792071068514829,
    "arrivals": 165887,
    "finished_requests": 59786,
    "scheduler_time": 78.90099277613115
}
#Debug simulation 
Total elapsed time: 4.547185586008709. Arrivals time: 0.38232496206182986 Scheduler time: 4.0504187164478935 Scheduler overhead time: 0.02470715279923752 Adapter cache time: 0.053867020877078176 Engine time: 0.02453373634489253 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-32/adapters_320_slots_160_rate_0.4-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-32/adapters_320_slots_160_rate_0.4-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 66, 4320, 4320, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 4320, 4320, 270, 66, 66, 270, 4320, 4320, 270, 270, 66, 66, 270, 4320, 4320, 66, 4320, 270, 66, 270, 4320, 66, 270, 4320, 4320, 270, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 270, 270, 270, 66, 270, 66, 4320, 66, 4320, 270, 4320, 4320, 66, 4320, 66, 4320, 270, 66, 66, 270, 270, 4320, 270, 4320, 4320, 4320, 66, 270, 270, 66, 4320, 270, 4320, 4320, 270, 66, 270, 270, 270, 66, 4320, 270, 4320, 66, 4320, 66, 66, 270, 4320, 4320, 270, 66, 270, 66, 270, 4320, 4320, 270, 66, 270, 66, 4320, 66, 66, 66, 66, 4320, 270, 270, 4320, 270, 270, 66, 270, 4320, 270, 66, 66, 270, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 270, 4320, 270, 270, 270, 66, 4320, 66, 4320, 270, 66, 270, 66, 66, 270, 66, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 66, 66, 4320, 270, 4320, 270, 4320, 270, 66, 270, 66, 66, 66, 4320, 4320, 270, 270, 66, 66, 270, 66, 4320, 66, 66, 270, 66, 4320, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 66, 270, 4320, 270, 270, 4320, 270, 66, 270, 66, 4320, 270, 270, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 270, 66, 270, 66, 270, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 270, 270, 4320, 66, 4320, 66, 66, 66, 4320, 270, 4320, 4320, 66, 270, 270, 270, 66, 270, 66, 270, 270, 4320, 66, 66, 270, 66, 270, 270, 66, 4320, 4320, 4320, 66, 270, 270, 270, 270, 66, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 270, 270, 270, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 498126 . Total input tokens: 111065075 . Total output tokens: 99648594
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.214523771952372,
    "estimated_duration": 3600.136677784236,
    "input_throughput": 3905.583387087918,
    "output_throughput": 3415.84086956629,
    "total_throughput": 7321.424256654208,
    "itl": 148.0135463766909,
    "ttft": 1925399.4451711238,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2894,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.702925024404621,
    "arrivals": 165887,
    "finished_requests": 56480,
    "scheduler_time": 91.59249299609331
}
#Debug simulation 
Total elapsed time: 4.214633194962516. Arrivals time: 0.20734478038502857 Scheduler time: 3.839093137299642 Scheduler overhead time: 0.03554357565008104 Adapter cache time: 0.07991942897206172 Engine time: 0.03608127904590219 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_320_slots_160_rate_0.4-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_320_slots_160_rate_0.4-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 33, 4320, 4320, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 4320, 4320, 270, 33, 33, 270, 4320, 4320, 270, 270, 33, 33, 270, 4320, 4320, 33, 4320, 270, 33, 270, 4320, 33, 270, 4320, 4320, 270, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 270, 270, 270, 33, 270, 33, 4320, 33, 4320, 270, 4320, 4320, 33, 4320, 33, 4320, 270, 33, 33, 270, 270, 4320, 270, 4320, 4320, 4320, 33, 270, 270, 33, 4320, 270, 4320, 4320, 270, 33, 270, 270, 270, 33, 4320, 270, 4320, 33, 4320, 33, 33, 270, 4320, 4320, 270, 33, 270, 33, 270, 4320, 4320, 270, 33, 270, 33, 4320, 33, 33, 33, 33, 4320, 270, 270, 4320, 270, 270, 33, 270, 4320, 270, 33, 33, 270, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 270, 4320, 270, 270, 270, 33, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 33, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 33, 33, 4320, 270, 4320, 270, 4320, 270, 33, 270, 33, 33, 33, 4320, 4320, 270, 270, 33, 33, 270, 33, 4320, 33, 33, 270, 33, 4320, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 33, 270, 4320, 270, 270, 4320, 270, 33, 270, 33, 4320, 270, 270, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 270, 33, 270, 33, 270, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 270, 270, 4320, 33, 4320, 33, 33, 33, 4320, 270, 4320, 4320, 33, 270, 270, 270, 33, 270, 33, 270, 270, 4320, 33, 33, 270, 33, 270, 270, 33, 4320, 4320, 4320, 33, 270, 270, 270, 270, 33, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 270, 270, 270, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 494628 . Total input tokens: 110245784 . Total output tokens: 98947582
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.32451366900932,
    "estimated_duration": 3600.2504436128556,
    "input_throughput": 4118.655141423966,
    "output_throughput": 3643.531805758614,
    "total_throughput": 7762.186947182579,
    "itl": 234.99016082239734,
    "ttft": 1849926.3575443567,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2475,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.574707166233793,
    "arrivals": 164660,
    "finished_requests": 60336,
    "scheduler_time": 79.42577892372539
}
#Debug simulation 
Total elapsed time: 4.3246105090365745. Arrivals time: 0.19513620983343571 Scheduler time: 4.019026263675187 Scheduler overhead time: 0.024175863480195403 Adapter cache time: 0.05063670320669189 Engine time: 0.02448549575638026 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_320_slots_160_rate_0.4-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_320_slots_160_rate_0.4-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 33, 4320, 4320, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 4320, 4320, 270, 33, 33, 270, 4320, 4320, 270, 270, 33, 33, 270, 4320, 4320, 33, 4320, 270, 33, 270, 4320, 33, 270, 4320, 4320, 270, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 270, 270, 270, 33, 270, 33, 4320, 33, 4320, 270, 4320, 4320, 33, 4320, 33, 4320, 270, 33, 33, 270, 270, 4320, 270, 4320, 4320, 4320, 33, 270, 270, 33, 4320, 270, 4320, 4320, 270, 33, 270, 270, 270, 33, 4320, 270, 4320, 33, 4320, 33, 33, 270, 4320, 4320, 270, 33, 270, 33, 270, 4320, 4320, 270, 33, 270, 33, 4320, 33, 33, 33, 33, 4320, 270, 270, 4320, 270, 270, 33, 270, 4320, 270, 33, 33, 270, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 270, 4320, 270, 270, 270, 33, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 33, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 33, 33, 4320, 270, 4320, 270, 4320, 270, 33, 270, 33, 33, 33, 4320, 4320, 270, 270, 33, 33, 270, 33, 4320, 33, 33, 270, 33, 4320, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 33, 270, 4320, 270, 270, 4320, 270, 33, 270, 33, 4320, 270, 270, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 270, 33, 270, 33, 270, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 270, 270, 4320, 33, 4320, 33, 33, 33, 4320, 270, 4320, 4320, 33, 270, 270, 270, 33, 270, 33, 270, 270, 4320, 33, 33, 270, 33, 270, 270, 33, 4320, 4320, 4320, 33, 270, 270, 270, 270, 33, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 270, 270, 270, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 494628 . Total input tokens: 110245784 . Total output tokens: 98947582
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.04055671999231,
    "estimated_duration": 3600.185168386582,
    "input_throughput": 4118.125125948523,
    "output_throughput": 3642.947344810488,
    "total_throughput": 7761.072470759012,
    "itl": 235.02160621190572,
    "ttft": 1850192.6545188804,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2475,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.087223210180763,
    "arrivals": 164660,
    "finished_requests": 60325,
    "scheduler_time": 79.41401602207779
}
#Debug simulation 
Total elapsed time: 5.040643893997185. Arrivals time: 0.21164003311423585 Scheduler time: 4.718531196471304 Scheduler overhead time: 0.024323144694790244 Adapter cache time: 0.05091389984590933 Engine time: 0.024153953709173948 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-32/adapters_320_slots_160_rate_0.4-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-32/adapters_320_slots_160_rate_0.4-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 33, 4320, 4320, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 4320, 4320, 270, 33, 33, 270, 4320, 4320, 270, 270, 33, 33, 270, 4320, 4320, 33, 4320, 270, 33, 270, 4320, 33, 270, 4320, 4320, 270, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 270, 270, 270, 33, 270, 33, 4320, 33, 4320, 270, 4320, 4320, 33, 4320, 33, 4320, 270, 33, 33, 270, 270, 4320, 270, 4320, 4320, 4320, 33, 270, 270, 33, 4320, 270, 4320, 4320, 270, 33, 270, 270, 270, 33, 4320, 270, 4320, 33, 4320, 33, 33, 270, 4320, 4320, 270, 33, 270, 33, 270, 4320, 4320, 270, 33, 270, 33, 4320, 33, 33, 33, 33, 4320, 270, 270, 4320, 270, 270, 33, 270, 4320, 270, 33, 33, 270, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 270, 4320, 270, 270, 270, 33, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 33, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 33, 33, 4320, 270, 4320, 270, 4320, 270, 33, 270, 33, 33, 33, 4320, 4320, 270, 270, 33, 33, 270, 33, 4320, 33, 33, 270, 33, 4320, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 33, 270, 4320, 270, 270, 4320, 270, 33, 270, 33, 4320, 270, 270, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 270, 33, 270, 33, 270, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 270, 270, 4320, 33, 4320, 33, 33, 33, 4320, 270, 4320, 4320, 33, 270, 270, 270, 33, 270, 33, 270, 270, 4320, 33, 33, 270, 33, 270, 270, 33, 4320, 4320, 4320, 33, 270, 270, 270, 270, 33, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 270, 270, 270, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 494628 . Total input tokens: 110245784 . Total output tokens: 98947582
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.25738771999022,
    "estimated_duration": 3600.143714006193,
    "input_throughput": 3903.6080546799594,
    "output_throughput": 3470.889217945955,
    "total_throughput": 7374.497272625914,
    "itl": 147.02060855461835,
    "ttft": 1904758.9306251314,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2429,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.94478143220765,
    "arrivals": 164660,
    "finished_requests": 57206,
    "scheduler_time": 92.71654562051062
}
#Debug simulation 
Total elapsed time: 4.257470495998859. Arrivals time: 0.18515543785179034 Scheduler time: 3.9104386250837706 Scheduler overhead time: 0.03603139118058607 Adapter cache time: 0.07235574373044074 Engine time: 0.036610217997804284 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_320_slots_160_rate_0.4-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_320_slots_160_rate_0.4-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 33, 4320, 4320, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 4320, 4320, 270, 33, 33, 270, 4320, 4320, 270, 270, 33, 33, 270, 4320, 4320, 33, 4320, 270, 33, 270, 4320, 33, 270, 4320, 4320, 270, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 270, 270, 270, 33, 270, 33, 4320, 33, 4320, 270, 4320, 4320, 33, 4320, 33, 4320, 270, 33, 33, 270, 270, 4320, 270, 4320, 4320, 4320, 33, 270, 270, 33, 4320, 270, 4320, 4320, 270, 33, 270, 270, 270, 33, 4320, 270, 4320, 33, 4320, 33, 33, 270, 4320, 4320, 270, 33, 270, 33, 270, 4320, 4320, 270, 33, 270, 33, 4320, 33, 33, 33, 33, 4320, 270, 270, 4320, 270, 270, 33, 270, 4320, 270, 33, 33, 270, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 270, 4320, 270, 270, 270, 33, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 33, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 33, 33, 4320, 270, 4320, 270, 4320, 270, 33, 270, 33, 33, 33, 4320, 4320, 270, 270, 33, 33, 270, 33, 4320, 33, 33, 270, 33, 4320, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 33, 270, 4320, 270, 270, 4320, 270, 33, 270, 33, 4320, 270, 270, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 270, 33, 270, 33, 270, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 270, 270, 4320, 33, 4320, 33, 33, 33, 4320, 270, 4320, 4320, 33, 270, 270, 270, 33, 270, 33, 270, 270, 4320, 33, 33, 270, 33, 270, 270, 33, 4320, 4320, 4320, 33, 270, 270, 270, 270, 33, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 270, 270, 270, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 494628 . Total input tokens: 110245784 . Total output tokens: 98947582
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.336142671993002,
    "estimated_duration": 3600.0233293212277,
    "input_throughput": 4118.609421010502,
    "output_throughput": 3643.3177788525563,
    "total_throughput": 7761.9271998630575,
    "itl": 235.00182877653373,
    "ttft": 1850050.9281901938,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2475,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.728476520590195,
    "arrivals": 164660,
    "finished_requests": 60328,
    "scheduler_time": 79.41658388427638
}
#Debug simulation 
Total elapsed time: 4.336227731953841. Arrivals time: 0.20095435623079538 Scheduler time: 4.024720421817619 Scheduler overhead time: 0.024243342457339168 Adapter cache time: 0.05079203937202692 Engine time: 0.02431438711937517 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-32/adapters_320_slots_160_rate_0.4-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-32/adapters_320_slots_160_rate_0.4-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 33, 4320, 4320, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 4320, 4320, 270, 33, 33, 270, 4320, 4320, 270, 270, 33, 33, 270, 4320, 4320, 33, 4320, 270, 33, 270, 4320, 33, 270, 4320, 4320, 270, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 270, 270, 270, 33, 270, 33, 4320, 33, 4320, 270, 4320, 4320, 33, 4320, 33, 4320, 270, 33, 33, 270, 270, 4320, 270, 4320, 4320, 4320, 33, 270, 270, 33, 4320, 270, 4320, 4320, 270, 33, 270, 270, 270, 33, 4320, 270, 4320, 33, 4320, 33, 33, 270, 4320, 4320, 270, 33, 270, 33, 270, 4320, 4320, 270, 33, 270, 33, 4320, 33, 33, 33, 33, 4320, 270, 270, 4320, 270, 270, 33, 270, 4320, 270, 33, 33, 270, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 270, 4320, 270, 270, 270, 33, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 33, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 33, 33, 4320, 270, 4320, 270, 4320, 270, 33, 270, 33, 33, 33, 4320, 4320, 270, 270, 33, 33, 270, 33, 4320, 33, 33, 270, 33, 4320, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 33, 270, 4320, 270, 270, 4320, 270, 33, 270, 33, 4320, 270, 270, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 270, 33, 270, 33, 270, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 270, 270, 4320, 33, 4320, 33, 33, 33, 4320, 270, 4320, 4320, 33, 270, 270, 270, 33, 270, 33, 270, 270, 4320, 33, 33, 270, 33, 270, 270, 33, 4320, 4320, 4320, 33, 270, 270, 270, 270, 33, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 270, 270, 270, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 494628 . Total input tokens: 110245784 . Total output tokens: 98947582
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.256696273980197,
    "estimated_duration": 3600.0274148549083,
    "input_throughput": 3903.6288840501466,
    "output_throughput": 3470.974956590326,
    "total_throughput": 7374.603840640473,
    "itl": 147.02383000284107,
    "ttft": 1904723.2505501425,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2427,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.046796924769689,
    "arrivals": 164660,
    "finished_requests": 57204,
    "scheduler_time": 92.71271998481754
}
#Debug simulation 
Total elapsed time: 4.256779988994822. Arrivals time: 0.19398423313396052 Scheduler time: 3.901493430719711 Scheduler overhead time: 0.036058774043340236 Adapter cache time: 0.07198392366990447 Engine time: 0.036439380899537355 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_320_slots_160_rate_0.4-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_320_slots_160_rate_0.4-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 33, 4320, 4320, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 4320, 4320, 270, 33, 33, 270, 4320, 4320, 270, 270, 33, 33, 270, 4320, 4320, 33, 4320, 270, 33, 270, 4320, 33, 270, 4320, 4320, 270, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 270, 270, 270, 33, 270, 33, 4320, 33, 4320, 270, 4320, 4320, 33, 4320, 33, 4320, 270, 33, 33, 270, 270, 4320, 270, 4320, 4320, 4320, 33, 270, 270, 33, 4320, 270, 4320, 4320, 270, 33, 270, 270, 270, 33, 4320, 270, 4320, 33, 4320, 33, 33, 270, 4320, 4320, 270, 33, 270, 33, 270, 4320, 4320, 270, 33, 270, 33, 4320, 33, 33, 33, 33, 4320, 270, 270, 4320, 270, 270, 33, 270, 4320, 270, 33, 33, 270, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 270, 4320, 270, 270, 270, 33, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 33, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 33, 33, 4320, 270, 4320, 270, 4320, 270, 33, 270, 33, 33, 33, 4320, 4320, 270, 270, 33, 33, 270, 33, 4320, 33, 33, 270, 33, 4320, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 33, 270, 4320, 270, 270, 4320, 270, 33, 270, 33, 4320, 270, 270, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 270, 33, 270, 33, 270, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 270, 270, 4320, 33, 4320, 33, 33, 33, 4320, 270, 4320, 4320, 33, 270, 270, 270, 33, 270, 33, 270, 270, 4320, 33, 33, 270, 33, 270, 270, 33, 4320, 4320, 4320, 33, 270, 270, 270, 270, 33, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 270, 270, 270, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 494628 . Total input tokens: 110245784 . Total output tokens: 98947582
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.342956000007689,
    "estimated_duration": 3600.053041172177,
    "input_throughput": 4118.880702705409,
    "output_throughput": 3643.6677043316495,
    "total_throughput": 7762.5484070370585,
    "itl": 234.97991285183357,
    "ttft": 1849880.1421233637,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2476,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.40336453017756,
    "arrivals": 164660,
    "finished_requests": 60335,
    "scheduler_time": 79.42460920602988
}
#Debug simulation 
Total elapsed time: 4.3430747060338035. Arrivals time: 0.20012738782679662 Scheduler time: 4.0322835556580685 Scheduler overhead time: 0.02426588477101177 Adapter cache time: 0.050843887438531965 Engine time: 0.024389595550019294 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-32/adapters_320_slots_160_rate_0.4-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-32/adapters_320_slots_160_rate_0.4-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 33, 4320, 4320, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 4320, 4320, 270, 33, 33, 270, 4320, 4320, 270, 270, 33, 33, 270, 4320, 4320, 33, 4320, 270, 33, 270, 4320, 33, 270, 4320, 4320, 270, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 270, 270, 270, 33, 270, 33, 4320, 33, 4320, 270, 4320, 4320, 33, 4320, 33, 4320, 270, 33, 33, 270, 270, 4320, 270, 4320, 4320, 4320, 33, 270, 270, 33, 4320, 270, 4320, 4320, 270, 33, 270, 270, 270, 33, 4320, 270, 4320, 33, 4320, 33, 33, 270, 4320, 4320, 270, 33, 270, 33, 270, 4320, 4320, 270, 33, 270, 33, 4320, 33, 33, 33, 33, 4320, 270, 270, 4320, 270, 270, 33, 270, 4320, 270, 33, 33, 270, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 270, 4320, 270, 270, 270, 33, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 33, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 33, 33, 4320, 270, 4320, 270, 4320, 270, 33, 270, 33, 33, 33, 4320, 4320, 270, 270, 33, 33, 270, 33, 4320, 33, 33, 270, 33, 4320, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 33, 270, 4320, 270, 270, 4320, 270, 33, 270, 33, 4320, 270, 270, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 270, 33, 270, 33, 270, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 270, 270, 4320, 33, 4320, 33, 33, 33, 4320, 270, 4320, 4320, 33, 270, 270, 270, 33, 270, 33, 270, 270, 4320, 33, 33, 270, 33, 270, 270, 33, 4320, 4320, 4320, 33, 270, 270, 270, 270, 33, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 270, 270, 270, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 494628 . Total input tokens: 110245784 . Total output tokens: 98947582
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.248485503019765,
    "estimated_duration": 3600.0929709068987,
    "input_throughput": 3903.606132832682,
    "output_throughput": 3470.9375843847197,
    "total_throughput": 7374.5437172174015,
    "itl": 147.02919053539307,
    "ttft": 1904781.13462948,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2429,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.15110338184948,
    "arrivals": 164660,
    "finished_requests": 57205,
    "scheduler_time": 92.71041032113001
}
#Debug simulation 
Total elapsed time: 4.248568654991686. Arrivals time: 0.19365660572657362 Scheduler time: 3.8933014791691676 Scheduler overhead time: 0.03592010238207877 Adapter cache time: 0.0723606250830926 Engine time: 0.036447857797611505 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_320_slots_160_rate_0.4-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_320_slots_160_rate_0.4-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [106 107 107]
Adapter prompts. [135, 4320, 4320, 66, 4320, 4320, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 4320, 4320, 135, 66, 66, 135, 4320, 4320, 135, 135, 66, 66, 135, 4320, 4320, 66, 4320, 135, 66, 135, 4320, 66, 135, 4320, 4320, 135, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 135, 135, 135, 66, 135, 66, 4320, 66, 4320, 135, 4320, 4320, 66, 4320, 66, 4320, 135, 66, 66, 135, 135, 4320, 135, 4320, 4320, 4320, 66, 135, 135, 66, 4320, 135, 4320, 4320, 135, 66, 135, 135, 135, 66, 4320, 135, 4320, 66, 4320, 66, 66, 135, 4320, 4320, 135, 66, 135, 66, 135, 4320, 4320, 135, 66, 135, 66, 4320, 66, 66, 66, 66, 4320, 135, 135, 4320, 135, 135, 66, 135, 4320, 135, 66, 66, 135, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 135, 4320, 135, 135, 135, 66, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 66, 135, 4320, 4320, 4320, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 66, 66, 4320, 135, 4320, 135, 4320, 135, 66, 135, 66, 66, 66, 4320, 4320, 135, 135, 66, 66, 135, 66, 4320, 66, 66, 135, 66, 4320, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 66, 135, 4320, 135, 135, 4320, 135, 66, 135, 66, 4320, 135, 135, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 135, 66, 135, 66, 135, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 135, 135, 4320, 66, 4320, 66, 66, 66, 4320, 135, 4320, 4320, 66, 135, 135, 135, 66, 135, 66, 135, 135, 4320, 66, 66, 135, 66, 135, 135, 66, 4320, 4320, 4320, 66, 135, 135, 135, 135, 66, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 135, 135, 135, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 483681 . Total input tokens: 107784951 . Total output tokens: 96806238
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.491022359987255,
    "estimated_duration": 3600.028046327833,
    "input_throughput": 4346.27308416673,
    "output_throughput": 3812.3519659797075,
    "total_throughput": 8158.625050146437,
    "itl": 223.3534158705029,
    "ttft": 1798903.3167530708,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2154,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.592290600431345,
    "arrivals": 161177,
    "finished_requests": 62957,
    "scheduler_time": 82.86315100646073
}
#Debug simulation 
Total elapsed time: 4.491110040980857. Arrivals time: 0.21490083524258807 Scheduler time: 4.1675413168850355 Scheduler overhead time: 0.025081830041017383 Adapter cache time: 0.04663122148485854 Engine time: 0.02533886954188347 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_320_slots_160_rate_0.4-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_320_slots_160_rate_0.4-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [106 107 107]
Adapter prompts. [135, 4320, 4320, 66, 4320, 4320, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 4320, 4320, 135, 66, 66, 135, 4320, 4320, 135, 135, 66, 66, 135, 4320, 4320, 66, 4320, 135, 66, 135, 4320, 66, 135, 4320, 4320, 135, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 135, 135, 135, 66, 135, 66, 4320, 66, 4320, 135, 4320, 4320, 66, 4320, 66, 4320, 135, 66, 66, 135, 135, 4320, 135, 4320, 4320, 4320, 66, 135, 135, 66, 4320, 135, 4320, 4320, 135, 66, 135, 135, 135, 66, 4320, 135, 4320, 66, 4320, 66, 66, 135, 4320, 4320, 135, 66, 135, 66, 135, 4320, 4320, 135, 66, 135, 66, 4320, 66, 66, 66, 66, 4320, 135, 135, 4320, 135, 135, 66, 135, 4320, 135, 66, 66, 135, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 135, 4320, 135, 135, 135, 66, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 66, 135, 4320, 4320, 4320, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 66, 66, 4320, 135, 4320, 135, 4320, 135, 66, 135, 66, 66, 66, 4320, 4320, 135, 135, 66, 66, 135, 66, 4320, 66, 66, 135, 66, 4320, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 66, 135, 4320, 135, 135, 4320, 135, 66, 135, 66, 4320, 135, 135, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 135, 66, 135, 66, 135, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 135, 135, 4320, 66, 4320, 66, 66, 66, 4320, 135, 4320, 4320, 66, 135, 135, 135, 66, 135, 66, 135, 135, 4320, 66, 66, 135, 66, 135, 135, 66, 4320, 4320, 4320, 66, 135, 135, 135, 135, 66, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 135, 135, 135, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 483681 . Total input tokens: 107784951 . Total output tokens: 96806238
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.684756460017525,
    "estimated_duration": 3600.1714864889645,
    "input_throughput": 4345.73215712511,
    "output_throughput": 3811.826478683508,
    "total_throughput": 8157.5586358086175,
    "itl": 223.38371499119137,
    "ttft": 1799070.563463603,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2153,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.032084473254819,
    "arrivals": 161177,
    "finished_requests": 62950,
    "scheduler_time": 82.85648592148048
}
#Debug simulation 
Total elapsed time: 4.684818978013936. Arrivals time: 0.20593399595236406 Scheduler time: 4.370385618065484 Scheduler overhead time: 0.02506817621178925 Adapter cache time: 0.04647190071409568 Engine time: 0.025374083139467984 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-32/adapters_320_slots_160_rate_0.4-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-32/adapters_320_slots_160_rate_0.4-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [106 107 107]
Adapter prompts. [135, 4320, 4320, 66, 4320, 4320, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 4320, 4320, 135, 66, 66, 135, 4320, 4320, 135, 135, 66, 66, 135, 4320, 4320, 66, 4320, 135, 66, 135, 4320, 66, 135, 4320, 4320, 135, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 135, 135, 135, 66, 135, 66, 4320, 66, 4320, 135, 4320, 4320, 66, 4320, 66, 4320, 135, 66, 66, 135, 135, 4320, 135, 4320, 4320, 4320, 66, 135, 135, 66, 4320, 135, 4320, 4320, 135, 66, 135, 135, 135, 66, 4320, 135, 4320, 66, 4320, 66, 66, 135, 4320, 4320, 135, 66, 135, 66, 135, 4320, 4320, 135, 66, 135, 66, 4320, 66, 66, 66, 66, 4320, 135, 135, 4320, 135, 135, 66, 135, 4320, 135, 66, 66, 135, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 135, 4320, 135, 135, 135, 66, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 66, 135, 4320, 4320, 4320, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 66, 66, 4320, 135, 4320, 135, 4320, 135, 66, 135, 66, 66, 66, 4320, 4320, 135, 135, 66, 66, 135, 66, 4320, 66, 66, 135, 66, 4320, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 66, 135, 4320, 135, 135, 4320, 135, 66, 135, 66, 4320, 135, 135, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 135, 66, 135, 66, 135, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 135, 135, 4320, 66, 4320, 66, 66, 66, 4320, 135, 4320, 4320, 66, 135, 135, 135, 66, 135, 66, 135, 135, 4320, 66, 66, 135, 66, 135, 135, 66, 4320, 4320, 4320, 66, 135, 135, 135, 135, 66, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 135, 135, 135, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 483681 . Total input tokens: 107784951 . Total output tokens: 96806238
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.386277483019512,
    "estimated_duration": 3600.0099374632027,
    "input_throughput": 4086.450941956704,
    "output_throughput": 3593.802301867185,
    "total_throughput": 7680.2532438238895,
    "itl": 139.89690761439087,
    "ttft": 1865164.6615230495,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1995,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.524743488449558,
    "arrivals": 161177,
    "finished_requests": 59126,
    "scheduler_time": 96.1451036933787
}
#Debug simulation 
Total elapsed time: 4.3863623210345395. Arrivals time: 0.19691451598191634 Scheduler time: 4.036764388089068 Scheduler overhead time: 0.03740656434092671 Adapter cache time: 0.05967459373641759 Engine time: 0.037901935866102576 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_320_slots_160_rate_0.4-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_320_slots_160_rate_0.4-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [106 107 107]
Adapter prompts. [135, 4320, 4320, 66, 4320, 4320, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 4320, 4320, 135, 66, 66, 135, 4320, 4320, 135, 135, 66, 66, 135, 4320, 4320, 66, 4320, 135, 66, 135, 4320, 66, 135, 4320, 4320, 135, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 135, 135, 135, 66, 135, 66, 4320, 66, 4320, 135, 4320, 4320, 66, 4320, 66, 4320, 135, 66, 66, 135, 135, 4320, 135, 4320, 4320, 4320, 66, 135, 135, 66, 4320, 135, 4320, 4320, 135, 66, 135, 135, 135, 66, 4320, 135, 4320, 66, 4320, 66, 66, 135, 4320, 4320, 135, 66, 135, 66, 135, 4320, 4320, 135, 66, 135, 66, 4320, 66, 66, 66, 66, 4320, 135, 135, 4320, 135, 135, 66, 135, 4320, 135, 66, 66, 135, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 135, 4320, 135, 135, 135, 66, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 66, 135, 4320, 4320, 4320, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 66, 66, 4320, 135, 4320, 135, 4320, 135, 66, 135, 66, 66, 66, 4320, 4320, 135, 135, 66, 66, 135, 66, 4320, 66, 66, 135, 66, 4320, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 66, 135, 4320, 135, 135, 4320, 135, 66, 135, 66, 4320, 135, 135, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 135, 66, 135, 66, 135, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 135, 135, 4320, 66, 4320, 66, 66, 66, 4320, 135, 4320, 4320, 66, 135, 135, 135, 66, 135, 66, 135, 135, 4320, 66, 66, 135, 66, 135, 135, 66, 4320, 4320, 4320, 66, 135, 135, 135, 135, 66, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 135, 135, 135, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 483681 . Total input tokens: 107784951 . Total output tokens: 96806238
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.471546750981361,
    "estimated_duration": 3600.044241212049,
    "input_throughput": 4346.171866691346,
    "output_throughput": 3812.307871910845,
    "total_throughput": 8158.47973860219,
    "itl": 223.3643438700245,
    "ttft": 1798963.4169138102,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2154,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.713510007937215,
    "arrivals": 161177,
    "finished_requests": 62955,
    "scheduler_time": 82.86015729494636
}
#Debug simulation 
Total elapsed time: 4.471631010004785. Arrivals time: 0.20375637017423287 Scheduler time: 4.159341904858593 Scheduler overhead time: 0.025077140948269516 Adapter cache time: 0.0465028426842764 Engine time: 0.02540885249618441 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-32/adapters_320_slots_160_rate_0.4-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-32/adapters_320_slots_160_rate_0.4-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [106 107 107]
Adapter prompts. [135, 4320, 4320, 66, 4320, 4320, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 4320, 4320, 135, 66, 66, 135, 4320, 4320, 135, 135, 66, 66, 135, 4320, 4320, 66, 4320, 135, 66, 135, 4320, 66, 135, 4320, 4320, 135, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 135, 135, 135, 66, 135, 66, 4320, 66, 4320, 135, 4320, 4320, 66, 4320, 66, 4320, 135, 66, 66, 135, 135, 4320, 135, 4320, 4320, 4320, 66, 135, 135, 66, 4320, 135, 4320, 4320, 135, 66, 135, 135, 135, 66, 4320, 135, 4320, 66, 4320, 66, 66, 135, 4320, 4320, 135, 66, 135, 66, 135, 4320, 4320, 135, 66, 135, 66, 4320, 66, 66, 66, 66, 4320, 135, 135, 4320, 135, 135, 66, 135, 4320, 135, 66, 66, 135, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 135, 4320, 135, 135, 135, 66, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 66, 135, 4320, 4320, 4320, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 66, 66, 4320, 135, 4320, 135, 4320, 135, 66, 135, 66, 66, 66, 4320, 4320, 135, 135, 66, 66, 135, 66, 4320, 66, 66, 135, 66, 4320, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 66, 135, 4320, 135, 135, 4320, 135, 66, 135, 66, 4320, 135, 135, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 135, 66, 135, 66, 135, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 135, 135, 4320, 66, 4320, 66, 66, 66, 4320, 135, 4320, 4320, 66, 135, 135, 135, 66, 135, 66, 135, 135, 4320, 66, 66, 135, 66, 135, 135, 66, 4320, 4320, 4320, 66, 135, 135, 135, 135, 66, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 135, 135, 135, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 483681 . Total input tokens: 107784951 . Total output tokens: 96806238
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.394032061973121,
    "estimated_duration": 3600.0469932986543,
    "input_throughput": 4086.2066599083523,
    "output_throughput": 3593.6164233639356,
    "total_throughput": 7679.8230832722875,
    "itl": 139.90167747328732,
    "ttft": 1865238.052806568,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1996,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.618792734797918,
    "arrivals": 161177,
    "finished_requests": 59123,
    "scheduler_time": 96.14131931395845
}
#Debug simulation 
Total elapsed time: 4.394114670983981. Arrivals time: 0.19700278580421582 Scheduler time: 4.0435523363994434 Scheduler overhead time: 0.03750481555471197 Adapter cache time: 0.06010683311615139 Engine time: 0.03825196489924565 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_320_slots_160_rate_0.4-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_320_slots_160_rate_0.4-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [106 107 107]
Adapter prompts. [135, 4320, 4320, 66, 4320, 4320, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 4320, 4320, 135, 66, 66, 135, 4320, 4320, 135, 135, 66, 66, 135, 4320, 4320, 66, 4320, 135, 66, 135, 4320, 66, 135, 4320, 4320, 135, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 135, 135, 135, 66, 135, 66, 4320, 66, 4320, 135, 4320, 4320, 66, 4320, 66, 4320, 135, 66, 66, 135, 135, 4320, 135, 4320, 4320, 4320, 66, 135, 135, 66, 4320, 135, 4320, 4320, 135, 66, 135, 135, 135, 66, 4320, 135, 4320, 66, 4320, 66, 66, 135, 4320, 4320, 135, 66, 135, 66, 135, 4320, 4320, 135, 66, 135, 66, 4320, 66, 66, 66, 66, 4320, 135, 135, 4320, 135, 135, 66, 135, 4320, 135, 66, 66, 135, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 135, 4320, 135, 135, 135, 66, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 66, 135, 4320, 4320, 4320, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 66, 66, 4320, 135, 4320, 135, 4320, 135, 66, 135, 66, 66, 66, 4320, 4320, 135, 135, 66, 66, 135, 66, 4320, 66, 66, 135, 66, 4320, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 66, 135, 4320, 135, 135, 4320, 135, 66, 135, 66, 4320, 135, 135, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 135, 66, 135, 66, 135, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 135, 135, 4320, 66, 4320, 66, 66, 66, 4320, 135, 4320, 4320, 66, 135, 135, 135, 66, 135, 66, 135, 135, 4320, 66, 66, 135, 66, 135, 135, 66, 4320, 4320, 4320, 66, 135, 135, 135, 135, 66, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 135, 135, 135, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 483681 . Total input tokens: 107784951 . Total output tokens: 96806238
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.483438469003886,
    "estimated_duration": 3600.09452254085,
    "input_throughput": 4346.516154513675,
    "output_throughput": 3812.425177745944,
    "total_throughput": 8158.941332259619,
    "itl": 223.34360440573164,
    "ttft": 1798851.7946642959,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2154,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.440568335219094,
    "arrivals": 161177,
    "finished_requests": 62961,
    "scheduler_time": 82.86721027417998
}
#Debug simulation 
Total elapsed time: 4.483520157984458. Arrivals time: 0.19464124378282577 Scheduler time: 4.180818811117206 Scheduler overhead time: 0.025019311113283038 Adapter cache time: 0.04613738274201751 Engine time: 0.025370892544742674 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-32/adapters_320_slots_160_rate_0.4-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-32/adapters_320_slots_160_rate_0.4-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [106 107 107]
Adapter prompts. [135, 4320, 4320, 66, 4320, 4320, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 4320, 4320, 135, 66, 66, 135, 4320, 4320, 135, 135, 66, 66, 135, 4320, 4320, 66, 4320, 135, 66, 135, 4320, 66, 135, 4320, 4320, 135, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 135, 135, 135, 66, 135, 66, 4320, 66, 4320, 135, 4320, 4320, 66, 4320, 66, 4320, 135, 66, 66, 135, 135, 4320, 135, 4320, 4320, 4320, 66, 135, 135, 66, 4320, 135, 4320, 4320, 135, 66, 135, 135, 135, 66, 4320, 135, 4320, 66, 4320, 66, 66, 135, 4320, 4320, 135, 66, 135, 66, 135, 4320, 4320, 135, 66, 135, 66, 4320, 66, 66, 66, 66, 4320, 135, 135, 4320, 135, 135, 66, 135, 4320, 135, 66, 66, 135, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 135, 4320, 135, 135, 135, 66, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 66, 135, 4320, 4320, 4320, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 66, 66, 4320, 135, 4320, 135, 4320, 135, 66, 135, 66, 66, 66, 4320, 4320, 135, 135, 66, 66, 135, 66, 4320, 66, 66, 135, 66, 4320, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 66, 135, 4320, 135, 135, 4320, 135, 66, 135, 66, 4320, 135, 135, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 135, 66, 135, 66, 135, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 135, 135, 4320, 66, 4320, 66, 66, 66, 4320, 135, 4320, 4320, 66, 135, 135, 135, 66, 135, 66, 135, 135, 4320, 66, 66, 135, 66, 135, 135, 66, 4320, 4320, 4320, 66, 135, 135, 135, 135, 66, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 135, 135, 135, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 483681 . Total input tokens: 107784951 . Total output tokens: 96806238
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.113448037009221,
    "estimated_duration": 3600.023817643252,
    "input_throughput": 4086.233243209547,
    "output_throughput": 3593.727057191946,
    "total_throughput": 7679.9603004014925,
    "itl": 139.9081513374938,
    "ttft": 1865203.185060461,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1995,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.693167822323535,
    "arrivals": 161177,
    "finished_requests": 59124,
    "scheduler_time": 96.1393062600191
}
#Debug simulation 
Total elapsed time: 5.1135290680103935. Arrivals time: 0.18897453870158643 Scheduler time: 4.77036345389206 Scheduler overhead time: 0.037739697203505784 Adapter cache time: 0.0604501903289929 Engine time: 0.03813548828475177 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_320_slots_160_rate_0.4-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_320_slots_160_rate_0.4-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [106 107 107]
Adapter prompts. [135, 4320, 4320, 33, 4320, 4320, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 4320, 4320, 135, 33, 33, 135, 4320, 4320, 135, 135, 33, 33, 135, 4320, 4320, 33, 4320, 135, 33, 135, 4320, 33, 135, 4320, 4320, 135, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 135, 135, 135, 33, 135, 33, 4320, 33, 4320, 135, 4320, 4320, 33, 4320, 33, 4320, 135, 33, 33, 135, 135, 4320, 135, 4320, 4320, 4320, 33, 135, 135, 33, 4320, 135, 4320, 4320, 135, 33, 135, 135, 135, 33, 4320, 135, 4320, 33, 4320, 33, 33, 135, 4320, 4320, 135, 33, 135, 33, 135, 4320, 4320, 135, 33, 135, 33, 4320, 33, 33, 33, 33, 4320, 135, 135, 4320, 135, 135, 33, 135, 4320, 135, 33, 33, 135, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 135, 4320, 135, 135, 135, 33, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 33, 135, 4320, 4320, 4320, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 33, 33, 4320, 135, 4320, 135, 4320, 135, 33, 135, 33, 33, 33, 4320, 4320, 135, 135, 33, 33, 135, 33, 4320, 33, 33, 135, 33, 4320, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 33, 135, 4320, 135, 135, 4320, 135, 33, 135, 33, 4320, 135, 135, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 135, 33, 135, 33, 135, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 135, 135, 4320, 33, 4320, 33, 33, 33, 4320, 135, 4320, 4320, 33, 135, 135, 135, 33, 135, 33, 135, 135, 4320, 33, 33, 135, 33, 135, 135, 33, 4320, 4320, 4320, 33, 135, 135, 135, 135, 33, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 135, 135, 135, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 480183 . Total input tokens: 107014508 . Total output tokens: 96108185
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.78648027201416,
    "estimated_duration": 3600.2323124157747,
    "input_throughput": 4458.999755276364,
    "output_throughput": 3930.7582877906493,
    "total_throughput": 8389.758043067013,
    "itl": 217.57243207253796,
    "ttft": 1765354.2792905893,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1671,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.114075020111773,
    "arrivals": 159905,
    "finished_requests": 64798,
    "scheduler_time": 85.3000275710948
}
#Debug simulation 
Total elapsed time: 4.786582997010555. Arrivals time: 0.3753965578507632 Scheduler time: 4.30795583629515 Scheduler overhead time: 0.0257344581768848 Adapter cache time: 0.039556262257974595 Engine time: 0.026007106294855475 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_320_slots_160_rate_0.4-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_320_slots_160_rate_0.4-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [106 107 107]
Adapter prompts. [135, 4320, 4320, 33, 4320, 4320, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 4320, 4320, 135, 33, 33, 135, 4320, 4320, 135, 135, 33, 33, 135, 4320, 4320, 33, 4320, 135, 33, 135, 4320, 33, 135, 4320, 4320, 135, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 135, 135, 135, 33, 135, 33, 4320, 33, 4320, 135, 4320, 4320, 33, 4320, 33, 4320, 135, 33, 33, 135, 135, 4320, 135, 4320, 4320, 4320, 33, 135, 135, 33, 4320, 135, 4320, 4320, 135, 33, 135, 135, 135, 33, 4320, 135, 4320, 33, 4320, 33, 33, 135, 4320, 4320, 135, 33, 135, 33, 135, 4320, 4320, 135, 33, 135, 33, 4320, 33, 33, 33, 33, 4320, 135, 135, 4320, 135, 135, 33, 135, 4320, 135, 33, 33, 135, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 135, 4320, 135, 135, 135, 33, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 33, 135, 4320, 4320, 4320, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 33, 33, 4320, 135, 4320, 135, 4320, 135, 33, 135, 33, 33, 33, 4320, 4320, 135, 135, 33, 33, 135, 33, 4320, 33, 33, 135, 33, 4320, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 33, 135, 4320, 135, 135, 4320, 135, 33, 135, 33, 4320, 135, 135, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 135, 33, 135, 33, 135, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 135, 135, 4320, 33, 4320, 33, 33, 33, 4320, 135, 4320, 4320, 33, 135, 135, 135, 33, 135, 33, 135, 135, 4320, 33, 33, 135, 33, 135, 135, 33, 4320, 4320, 4320, 33, 135, 135, 135, 135, 33, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 135, 135, 135, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 480183 . Total input tokens: 107014508 . Total output tokens: 96108185
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.6166006160201505,
    "estimated_duration": 3600.228027319133,
    "input_throughput": 4458.789520605288,
    "output_throughput": 3930.6868600036005,
    "total_throughput": 8389.476380608889,
    "itl": 217.5950440420054,
    "ttft": 1765398.454003711,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1671,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.4544093947530365,
    "arrivals": 159905,
    "finished_requests": 64794,
    "scheduler_time": 85.2922493011429
}
#Debug simulation 
Total elapsed time: 4.616707633016631. Arrivals time: 0.19932912557851523 Scheduler time: 4.31413708726177 Scheduler overhead time: 0.02561449131462723 Adapter cache time: 0.039736541046295315 Engine time: 0.025984859035816044 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-32/adapters_320_slots_160_rate_0.4-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-32/adapters_320_slots_160_rate_0.4-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [106 107 107]
Adapter prompts. [135, 4320, 4320, 33, 4320, 4320, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 4320, 4320, 135, 33, 33, 135, 4320, 4320, 135, 135, 33, 33, 135, 4320, 4320, 33, 4320, 135, 33, 135, 4320, 33, 135, 4320, 4320, 135, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 135, 135, 135, 33, 135, 33, 4320, 33, 4320, 135, 4320, 4320, 33, 4320, 33, 4320, 135, 33, 33, 135, 135, 4320, 135, 4320, 4320, 4320, 33, 135, 135, 33, 4320, 135, 4320, 4320, 135, 33, 135, 135, 135, 33, 4320, 135, 4320, 33, 4320, 33, 33, 135, 4320, 4320, 135, 33, 135, 33, 135, 4320, 4320, 135, 33, 135, 33, 4320, 33, 33, 33, 33, 4320, 135, 135, 4320, 135, 135, 33, 135, 4320, 135, 33, 33, 135, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 135, 4320, 135, 135, 135, 33, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 33, 135, 4320, 4320, 4320, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 33, 33, 4320, 135, 4320, 135, 4320, 135, 33, 135, 33, 33, 33, 4320, 4320, 135, 135, 33, 33, 135, 33, 4320, 33, 33, 135, 33, 4320, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 33, 135, 4320, 135, 135, 4320, 135, 33, 135, 33, 4320, 135, 135, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 135, 33, 135, 33, 135, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 135, 135, 4320, 33, 4320, 33, 33, 33, 4320, 135, 4320, 4320, 33, 135, 135, 135, 33, 135, 33, 135, 135, 4320, 33, 33, 135, 33, 135, 135, 33, 4320, 4320, 4320, 33, 135, 135, 135, 135, 33, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 135, 135, 135, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 480183 . Total input tokens: 107014508 . Total output tokens: 96108185
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.418602208956145,
    "estimated_duration": 3600.0092715735577,
    "input_throughput": 4154.730688641335,
    "output_throughput": 3668.8002734578877,
    "total_throughput": 7823.530962099223,
    "itl": 136.95552849628515,
    "ttft": 1847103.9216328026,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1548,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.060081087239029,
    "arrivals": 159905,
    "finished_requests": 60296,
    "scheduler_time": 98.13145671092873
}
#Debug simulation 
Total elapsed time: 4.4186877309693955. Arrivals time: 0.19295932439854369 Scheduler time: 4.07950310286833 Scheduler overhead time: 0.03807196632260457 Adapter cache time: 0.05165852338541299 Engine time: 0.03859524731524289 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_320_slots_160_rate_0.4-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_320_slots_160_rate_0.4-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [106 107 107]
Adapter prompts. [135, 4320, 4320, 33, 4320, 4320, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 4320, 4320, 135, 33, 33, 135, 4320, 4320, 135, 135, 33, 33, 135, 4320, 4320, 33, 4320, 135, 33, 135, 4320, 33, 135, 4320, 4320, 135, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 135, 135, 135, 33, 135, 33, 4320, 33, 4320, 135, 4320, 4320, 33, 4320, 33, 4320, 135, 33, 33, 135, 135, 4320, 135, 4320, 4320, 4320, 33, 135, 135, 33, 4320, 135, 4320, 4320, 135, 33, 135, 135, 135, 33, 4320, 135, 4320, 33, 4320, 33, 33, 135, 4320, 4320, 135, 33, 135, 33, 135, 4320, 4320, 135, 33, 135, 33, 4320, 33, 33, 33, 33, 4320, 135, 135, 4320, 135, 135, 33, 135, 4320, 135, 33, 33, 135, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 135, 4320, 135, 135, 135, 33, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 33, 135, 4320, 4320, 4320, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 33, 33, 4320, 135, 4320, 135, 4320, 135, 33, 135, 33, 33, 33, 4320, 4320, 135, 135, 33, 33, 135, 33, 4320, 33, 33, 135, 33, 4320, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 33, 135, 4320, 135, 135, 4320, 135, 33, 135, 33, 4320, 135, 135, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 135, 33, 135, 33, 135, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 135, 135, 4320, 33, 4320, 33, 33, 33, 4320, 135, 4320, 4320, 33, 135, 135, 135, 33, 135, 33, 135, 135, 4320, 33, 33, 135, 33, 135, 135, 33, 4320, 4320, 4320, 33, 135, 135, 135, 135, 33, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 135, 135, 135, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 480183 . Total input tokens: 107014508 . Total output tokens: 96108185
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.595002323039807,
    "estimated_duration": 3600.156865171159,
    "input_throughput": 4459.093200994947,
    "output_throughput": 3930.840663335152,
    "total_throughput": 8389.9338643301,
    "itl": 217.57776741524327,
    "ttft": 1765319.5013389078,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1669,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.205723675009667,
    "arrivals": 159905,
    "finished_requests": 64798,
    "scheduler_time": 85.29680718858344
}
#Debug simulation 
Total elapsed time: 4.5950902590411715. Arrivals time: 0.20126875571440905 Scheduler time: 4.291117301443592 Scheduler overhead time: 0.02565071458229795 Adapter cache time: 0.03927421191474423 Engine time: 0.025923871668055654 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-32/adapters_320_slots_160_rate_0.4-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-32/adapters_320_slots_160_rate_0.4-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [106 107 107]
Adapter prompts. [135, 4320, 4320, 33, 4320, 4320, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 4320, 4320, 135, 33, 33, 135, 4320, 4320, 135, 135, 33, 33, 135, 4320, 4320, 33, 4320, 135, 33, 135, 4320, 33, 135, 4320, 4320, 135, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 135, 135, 135, 33, 135, 33, 4320, 33, 4320, 135, 4320, 4320, 33, 4320, 33, 4320, 135, 33, 33, 135, 135, 4320, 135, 4320, 4320, 4320, 33, 135, 135, 33, 4320, 135, 4320, 4320, 135, 33, 135, 135, 135, 33, 4320, 135, 4320, 33, 4320, 33, 33, 135, 4320, 4320, 135, 33, 135, 33, 135, 4320, 4320, 135, 33, 135, 33, 4320, 33, 33, 33, 33, 4320, 135, 135, 4320, 135, 135, 33, 135, 4320, 135, 33, 33, 135, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 135, 4320, 135, 135, 135, 33, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 33, 135, 4320, 4320, 4320, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 33, 33, 4320, 135, 4320, 135, 4320, 135, 33, 135, 33, 33, 33, 4320, 4320, 135, 135, 33, 33, 135, 33, 4320, 33, 33, 135, 33, 4320, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 33, 135, 4320, 135, 135, 4320, 135, 33, 135, 33, 4320, 135, 135, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 135, 33, 135, 33, 135, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 135, 135, 4320, 33, 4320, 33, 33, 33, 4320, 135, 4320, 4320, 33, 135, 135, 135, 33, 135, 33, 135, 135, 4320, 33, 33, 135, 33, 135, 135, 33, 4320, 4320, 4320, 33, 135, 135, 135, 135, 33, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 135, 135, 135, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 480183 . Total input tokens: 107014508 . Total output tokens: 96108185
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.4219268129672855,
    "estimated_duration": 3600.0658152258115,
    "input_throughput": 4158.497307655739,
    "output_throughput": 3672.9134073263085,
    "total_throughput": 7831.4107149820475,
    "itl": 137.7137963517952,
    "ttft": 1845415.9191828873,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1546,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.122444123215919,
    "arrivals": 159905,
    "finished_requests": 60365,
    "scheduler_time": 97.92826687025286
}
#Debug simulation 
Total elapsed time: 4.422027199005242. Arrivals time: 0.19040852517355233 Scheduler time: 4.0848680241033435 Scheduler overhead time: 0.037962971488013864 Adapter cache time: 0.05252803076291457 Engine time: 0.03841502120485529 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_320_slots_160_rate_0.4-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_320_slots_160_rate_0.4-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [106 107 107]
Adapter prompts. [135, 4320, 4320, 33, 4320, 4320, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 4320, 4320, 135, 33, 33, 135, 4320, 4320, 135, 135, 33, 33, 135, 4320, 4320, 33, 4320, 135, 33, 135, 4320, 33, 135, 4320, 4320, 135, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 135, 135, 135, 33, 135, 33, 4320, 33, 4320, 135, 4320, 4320, 33, 4320, 33, 4320, 135, 33, 33, 135, 135, 4320, 135, 4320, 4320, 4320, 33, 135, 135, 33, 4320, 135, 4320, 4320, 135, 33, 135, 135, 135, 33, 4320, 135, 4320, 33, 4320, 33, 33, 135, 4320, 4320, 135, 33, 135, 33, 135, 4320, 4320, 135, 33, 135, 33, 4320, 33, 33, 33, 33, 4320, 135, 135, 4320, 135, 135, 33, 135, 4320, 135, 33, 33, 135, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 135, 4320, 135, 135, 135, 33, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 33, 135, 4320, 4320, 4320, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 33, 33, 4320, 135, 4320, 135, 4320, 135, 33, 135, 33, 33, 33, 4320, 4320, 135, 135, 33, 33, 135, 33, 4320, 33, 33, 135, 33, 4320, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 33, 135, 4320, 135, 135, 4320, 135, 33, 135, 33, 4320, 135, 135, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 135, 33, 135, 33, 135, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 135, 135, 4320, 33, 4320, 33, 33, 33, 4320, 135, 4320, 4320, 33, 135, 135, 135, 33, 135, 33, 135, 135, 4320, 33, 33, 135, 33, 135, 135, 33, 4320, 4320, 4320, 33, 135, 135, 135, 135, 33, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 135, 135, 135, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 480183 . Total input tokens: 107014508 . Total output tokens: 96108185
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.646368367015384,
    "estimated_duration": 3600.0814067835595,
    "input_throughput": 4459.186664432322,
    "output_throughput": 3930.9230544993648,
    "total_throughput": 8390.109718931686,
    "itl": 217.5667228138615,
    "ttft": 1765298.3336101738,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1671,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.996374042781395,
    "arrivals": 159905,
    "finished_requests": 64798,
    "scheduler_time": 85.29851226000854
}
#Debug simulation 
Total elapsed time: 4.646473257045727. Arrivals time: 0.20671210816362873 Scheduler time: 4.33563383546425 Scheduler overhead time: 0.025746432424057275 Adapter cache time: 0.04025690729031339 Engine time: 0.026076965441461653 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-32/adapters_320_slots_160_rate_0.4-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-32/adapters_320_slots_160_rate_0.4-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [106 107 107]
Adapter prompts. [135, 4320, 4320, 33, 4320, 4320, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 4320, 4320, 135, 33, 33, 135, 4320, 4320, 135, 135, 33, 33, 135, 4320, 4320, 33, 4320, 135, 33, 135, 4320, 33, 135, 4320, 4320, 135, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 135, 135, 135, 33, 135, 33, 4320, 33, 4320, 135, 4320, 4320, 33, 4320, 33, 4320, 135, 33, 33, 135, 135, 4320, 135, 4320, 4320, 4320, 33, 135, 135, 33, 4320, 135, 4320, 4320, 135, 33, 135, 135, 135, 33, 4320, 135, 4320, 33, 4320, 33, 33, 135, 4320, 4320, 135, 33, 135, 33, 135, 4320, 4320, 135, 33, 135, 33, 4320, 33, 33, 33, 33, 4320, 135, 135, 4320, 135, 135, 33, 135, 4320, 135, 33, 33, 135, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 135, 4320, 135, 135, 135, 33, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 33, 135, 4320, 4320, 4320, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 33, 33, 4320, 135, 4320, 135, 4320, 135, 33, 135, 33, 33, 33, 4320, 4320, 135, 135, 33, 33, 135, 33, 4320, 33, 33, 135, 33, 4320, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 33, 135, 4320, 135, 135, 4320, 135, 33, 135, 33, 4320, 135, 135, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 135, 33, 135, 33, 135, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 135, 135, 4320, 33, 4320, 33, 33, 33, 4320, 135, 4320, 4320, 33, 135, 135, 135, 33, 135, 33, 135, 135, 4320, 33, 33, 135, 33, 135, 135, 33, 4320, 4320, 4320, 33, 135, 135, 135, 135, 33, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 135, 135, 135, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 480183 . Total input tokens: 107014508 . Total output tokens: 96108185
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.425271948974114,
    "estimated_duration": 3600.005703824241,
    "input_throughput": 4158.511744605529,
    "output_throughput": 3672.840569656368,
    "total_throughput": 7831.352314261897,
    "itl": 137.7145394688433,
    "ttft": 1845422.1453881816,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1547,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.186140980981235,
    "arrivals": 159905,
    "finished_requests": 60363,
    "scheduler_time": 97.92447514432439
}
#Debug simulation 
Total elapsed time: 4.425375377992168. Arrivals time: 0.19176401547156274 Scheduler time: 4.086558981449343 Scheduler overhead time: 0.03789027640596032 Adapter cache time: 0.052472869283519685 Engine time: 0.03876532631693408 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_320_slots_160_rate_0.4-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_320_slots_160_rate_0.4-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [106 107 107]
Adapter prompts. [66, 4320, 4320, 33, 4320, 4320, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 4320, 4320, 66, 33, 33, 66, 4320, 4320, 66, 66, 33, 33, 66, 4320, 4320, 33, 4320, 66, 33, 66, 4320, 33, 66, 4320, 4320, 66, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 66, 66, 66, 33, 66, 33, 4320, 33, 4320, 66, 4320, 4320, 33, 4320, 33, 4320, 66, 33, 33, 66, 66, 4320, 66, 4320, 4320, 4320, 33, 66, 66, 33, 4320, 66, 4320, 4320, 66, 33, 66, 66, 66, 33, 4320, 66, 4320, 33, 4320, 33, 33, 66, 4320, 4320, 66, 33, 66, 33, 66, 4320, 4320, 66, 33, 66, 33, 4320, 33, 33, 33, 33, 4320, 66, 66, 4320, 66, 66, 33, 66, 4320, 66, 33, 33, 66, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 66, 4320, 66, 66, 66, 33, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 33, 66, 4320, 4320, 4320, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 33, 33, 4320, 66, 4320, 66, 4320, 66, 33, 66, 33, 33, 33, 4320, 4320, 66, 66, 33, 33, 66, 33, 4320, 33, 33, 66, 33, 4320, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 33, 66, 4320, 66, 66, 4320, 66, 33, 66, 33, 4320, 66, 66, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 66, 33, 66, 33, 66, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 66, 66, 4320, 33, 4320, 33, 33, 33, 4320, 66, 4320, 4320, 33, 66, 66, 66, 33, 66, 33, 66, 66, 4320, 33, 33, 66, 33, 66, 66, 33, 4320, 4320, 4320, 33, 66, 66, 66, 66, 33, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 66, 66, 66, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 472800 . Total input tokens: 105331521 . Total output tokens: 94640994
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.799069559958298,
    "estimated_duration": 3600.049359098135,
    "input_throughput": 4647.415168827391,
    "output_throughput": 4104.686776767381,
    "total_throughput": 8752.101945594772,
    "itl": 208.49931533458113,
    "ttft": 1713927.930300606,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1238,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7888838269888447,
    "arrivals": 157567,
    "finished_requests": 67622,
    "scheduler_time": 88.63698076591066
}
#Debug simulation 
Total elapsed time: 4.799151109007653. Arrivals time: 0.21558797580655664 Scheduler time: 4.485847924777772 Scheduler overhead time: 0.026586373161990196 Adapter cache time: 0.03152652631979436 Engine time: 0.02718477015150711 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_320_slots_160_rate_0.4-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_320_slots_160_rate_0.4-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [106 107 107]
Adapter prompts. [66, 4320, 4320, 33, 4320, 4320, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 4320, 4320, 66, 33, 33, 66, 4320, 4320, 66, 66, 33, 33, 66, 4320, 4320, 33, 4320, 66, 33, 66, 4320, 33, 66, 4320, 4320, 66, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 66, 66, 66, 33, 66, 33, 4320, 33, 4320, 66, 4320, 4320, 33, 4320, 33, 4320, 66, 33, 33, 66, 66, 4320, 66, 4320, 4320, 4320, 33, 66, 66, 33, 4320, 66, 4320, 4320, 66, 33, 66, 66, 66, 33, 4320, 66, 4320, 33, 4320, 33, 33, 66, 4320, 4320, 66, 33, 66, 33, 66, 4320, 4320, 66, 33, 66, 33, 4320, 33, 33, 33, 33, 4320, 66, 66, 4320, 66, 66, 33, 66, 4320, 66, 33, 33, 66, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 66, 4320, 66, 66, 66, 33, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 33, 66, 4320, 4320, 4320, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 33, 33, 4320, 66, 4320, 66, 4320, 66, 33, 66, 33, 33, 33, 4320, 4320, 66, 66, 33, 33, 66, 33, 4320, 33, 33, 66, 33, 4320, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 33, 66, 4320, 66, 66, 4320, 66, 33, 66, 33, 4320, 66, 66, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 66, 33, 66, 33, 66, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 66, 66, 4320, 33, 4320, 33, 33, 33, 4320, 66, 4320, 4320, 33, 66, 66, 66, 33, 66, 33, 66, 66, 4320, 33, 33, 66, 33, 66, 66, 33, 4320, 4320, 4320, 33, 66, 66, 66, 66, 33, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 66, 66, 66, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 472800 . Total input tokens: 105331521 . Total output tokens: 94640994
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.944830033986364,
    "estimated_duration": 3600.04484659781,
    "input_throughput": 4647.197385835526,
    "output_throughput": 4104.474702298279,
    "total_throughput": 8751.672088133804,
    "itl": 208.5140044212829,
    "ttft": 1713999.622430553,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1238,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.038773402802182,
    "arrivals": 157567,
    "finished_requests": 67619,
    "scheduler_time": 88.63124626380396
}
#Debug simulation 
Total elapsed time: 4.9448931670049205. Arrivals time: 0.37989151634974405 Scheduler time: 4.467554348986596 Scheduler overhead time: 0.02668026409810409 Adapter cache time: 0.03135904419468716 Engine time: 0.027111320989206433 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-32/adapters_320_slots_160_rate_0.4-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-32/adapters_320_slots_160_rate_0.4-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [106 107 107]
Adapter prompts. [66, 4320, 4320, 33, 4320, 4320, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 4320, 4320, 66, 33, 33, 66, 4320, 4320, 66, 66, 33, 33, 66, 4320, 4320, 33, 4320, 66, 33, 66, 4320, 33, 66, 4320, 4320, 66, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 66, 66, 66, 33, 66, 33, 4320, 33, 4320, 66, 4320, 4320, 33, 4320, 33, 4320, 66, 33, 33, 66, 66, 4320, 66, 4320, 4320, 4320, 33, 66, 66, 33, 4320, 66, 4320, 4320, 66, 33, 66, 66, 66, 33, 4320, 66, 4320, 33, 4320, 33, 33, 66, 4320, 4320, 66, 33, 66, 33, 66, 4320, 4320, 66, 33, 66, 33, 4320, 33, 33, 33, 33, 4320, 66, 66, 4320, 66, 66, 33, 66, 4320, 66, 33, 33, 66, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 66, 4320, 66, 66, 66, 33, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 33, 66, 4320, 4320, 4320, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 33, 33, 4320, 66, 4320, 66, 4320, 66, 33, 66, 33, 33, 33, 4320, 4320, 66, 66, 33, 33, 66, 33, 4320, 33, 33, 66, 33, 4320, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 33, 66, 4320, 66, 66, 4320, 66, 33, 66, 33, 4320, 66, 66, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 66, 33, 66, 33, 66, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 66, 66, 4320, 33, 4320, 33, 33, 33, 4320, 66, 4320, 4320, 33, 66, 66, 66, 33, 66, 33, 66, 66, 4320, 33, 33, 66, 33, 66, 66, 33, 4320, 4320, 4320, 33, 66, 66, 66, 66, 33, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 66, 66, 66, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 472800 . Total input tokens: 105331521 . Total output tokens: 94640994
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.564479699998628,
    "estimated_duration": 3600.0635846899763,
    "input_throughput": 4262.4447149372945,
    "output_throughput": 3781.0282179147143,
    "total_throughput": 8043.472932852009,
    "itl": 133.80874931500162,
    "ttft": 1806206.406616846,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1145,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7407999301887522,
    "arrivals": 157567,
    "finished_requests": 62093,
    "scheduler_time": 100.37048128045018
}
#Debug simulation 
Total elapsed time: 4.564588134991936. Arrivals time: 0.1944837380433455 Scheduler time: 4.230898830050137 Scheduler overhead time: 0.03903375822119415 Adapter cache time: 0.042114183597732335 Engine time: 0.03961381787667051 
