INFO 06-01 00:47:02 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:47:03 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-16/adapters_64_slots_64_rate_0.8-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-16/adapters_64_slots_64_rate_0.8-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 8640, 8640, 33, 8640, 33, 135, 33, 8640, 135, 8640, 33, 135, 8640, 8640, 8640, 33, 8640, 135, 135, 33, 33, 33, 8640, 33, 33, 33, 8640, 135, 33, 8640, 8640, 8640, 8640, 135, 135, 135, 8640, 33, 135, 135, 8640, 8640, 135, 8640, 33, 8640, 135, 135, 135, 8640, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 8640, 135]
Prompts retrieved: 193608 . Total input tokens: 43331592 . Total output tokens: 38638110
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 4.713327159173787,
    "estimated_duration": 3600.0019731591083,
    "input_throughput": 4473.263103761156,
    "output_throughput": 3978.4883749470628,
    "total_throughput": 8451.75147870822,
    "itl": 37.73995571180386,
    "ttft": 9271.707823248687,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20035231587942698,
    "arrivals": 64890,
    "finished_requests": 64724,
    "scheduler_time": 40.915150134027
}
#Debug simulation 
Total elapsed time: 4.713447709102184. Arrivals time: 0.17222184827551246 Scheduler time: 4.272725161164999 Scheduler overhead time: 0.09883719310164452 Adapter cache time: 0.02259427634999156 Engine time: 0.09984958963468671 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-32/adapters_64_slots_64_rate_0.8-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-32/adapters_64_slots_64_rate_0.8-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 8640, 8640, 33, 8640, 33, 135, 33, 8640, 135, 8640, 33, 135, 8640, 8640, 8640, 33, 8640, 135, 135, 33, 33, 33, 8640, 33, 33, 33, 8640, 135, 33, 8640, 8640, 8640, 8640, 135, 135, 135, 8640, 33, 135, 135, 8640, 8640, 135, 8640, 33, 8640, 135, 135, 135, 8640, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 8640, 135]
Prompts retrieved: 193608 . Total input tokens: 43331592 . Total output tokens: 38638110
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 4.750923766288906,
    "estimated_duration": 3599.9849729536013,
    "input_throughput": 4473.284227847124,
    "output_throughput": 3978.507162558814,
    "total_throughput": 8451.791390405937,
    "itl": 37.74013489366993,
    "ttft": 9271.754105641994,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21192767810076457,
    "arrivals": 64890,
    "finished_requests": 64724,
    "scheduler_time": 40.9150924678541
}
#Debug simulation 
Total elapsed time: 4.751032518222928. Arrivals time: 0.17347355978563428 Scheduler time: 4.314913877751678 Scheduler overhead time: 0.09768580598756671 Adapter cache time: 0.022339120041579008 Engine time: 0.09608487458899617 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-16/adapters_64_slots_64_rate_0.8-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-16/adapters_64_slots_64_rate_0.8-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 8640, 8640, 33, 8640, 33, 135, 33, 8640, 135, 8640, 33, 135, 8640, 8640, 8640, 33, 8640, 135, 135, 33, 33, 33, 8640, 33, 33, 33, 8640, 135, 33, 8640, 8640, 8640, 8640, 135, 135, 135, 8640, 33, 135, 135, 8640, 8640, 135, 8640, 33, 8640, 135, 135, 135, 8640, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 8640, 135]
Prompts retrieved: 193608 . Total input tokens: 43331592 . Total output tokens: 38638110
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 4.667208191007376,
    "estimated_duration": 3599.9816274462814,
    "input_throughput": 4473.288384925319,
    "output_throughput": 3978.510859834581,
    "total_throughput": 8451.7992447599,
    "itl": 37.73989403332631,
    "ttft": 9271.751136110299,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19136321887373942,
    "arrivals": 64890,
    "finished_requests": 64724,
    "scheduler_time": 40.91488713955461
}
#Debug simulation 
Total elapsed time: 4.667314181104302. Arrivals time: 0.16921826032921672 Scheduler time: 4.2347568003460765 Scheduler overhead time: 0.09718459378927946 Adapter cache time: 0.022376087959855795 Engine time: 0.09747333033010364 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-32/adapters_64_slots_64_rate_0.8-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-32/adapters_64_slots_64_rate_0.8-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 8640, 8640, 33, 8640, 33, 135, 33, 8640, 135, 8640, 33, 135, 8640, 8640, 8640, 33, 8640, 135, 135, 33, 33, 33, 8640, 33, 33, 33, 8640, 135, 33, 8640, 8640, 8640, 8640, 135, 135, 135, 8640, 33, 135, 135, 8640, 8640, 135, 8640, 33, 8640, 135, 135, 135, 8640, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 8640, 135]
Prompts retrieved: 193608 . Total input tokens: 43331592 . Total output tokens: 38638110
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 4.703614356927574,
    "estimated_duration": 3599.985659660063,
    "input_throughput": 4473.2833745567295,
    "output_throughput": 3978.506403648408,
    "total_throughput": 8451.789778205137,
    "itl": 37.740207170637625,
    "ttft": 9271.746708521297,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21469426140189143,
    "arrivals": 64890,
    "finished_requests": 64724,
    "scheduler_time": 40.915088504995964
}
#Debug simulation 
Total elapsed time: 4.703740217257291. Arrivals time: 0.17511040437966585 Scheduler time: 4.263991358689964 Scheduler overhead time: 0.09775162767618895 Adapter cache time: 0.02260390529409051 Engine time: 0.09786126250401139 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-8/adapters_64_slots_64_rate_0.8-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-8/adapters_64_slots_64_rate_0.8-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 8640, 8640, 33, 8640, 33, 66, 33, 8640, 66, 8640, 33, 66, 8640, 8640, 8640, 33, 8640, 66, 66, 33, 33, 33, 8640, 33, 33, 33, 8640, 66, 33, 8640, 8640, 8640, 8640, 66, 66, 66, 8640, 33, 66, 66, 8640, 8640, 66, 8640, 33, 8640, 66, 66, 66, 8640, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 8640, 66]
Prompts retrieved: 192159 . Total input tokens: 43010186 . Total output tokens: 38352570
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 4.653712471015751,
    "estimated_duration": 3600.0260374528443,
    "input_throughput": 4452.717795158439,
    "output_throughput": 3907.6170154461743,
    "total_throughput": 8360.334810604612,
    "itl": 36.72899460092793,
    "ttft": 9058.09350197216,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19587121561169607,
    "arrivals": 64419,
    "finished_requests": 64258,
    "scheduler_time": 39.43299012059785
}
#Debug simulation 
Total elapsed time: 4.653816182166338. Arrivals time: 0.1708431076258421 Scheduler time: 4.212579879909754 Scheduler overhead time: 0.10036431672051549 Adapter cache time: 0.020907771307975054 Engine time: 0.10068483836948872 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-16/adapters_64_slots_64_rate_0.8-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-16/adapters_64_slots_64_rate_0.8-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 8640, 8640, 33, 8640, 33, 66, 33, 8640, 66, 8640, 33, 66, 8640, 8640, 8640, 33, 8640, 66, 66, 33, 33, 33, 8640, 33, 33, 33, 8640, 66, 33, 8640, 8640, 8640, 8640, 66, 66, 66, 8640, 33, 66, 66, 8640, 8640, 66, 8640, 33, 8640, 66, 66, 66, 8640, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 8640, 66]
Prompts retrieved: 192159 . Total input tokens: 43010186 . Total output tokens: 38352570
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 4.638664503116161,
    "estimated_duration": 3600.0005299322265,
    "input_throughput": 4452.749344540174,
    "output_throughput": 3907.644702559206,
    "total_throughput": 8360.39404709938,
    "itl": 36.72897487410777,
    "ttft": 9057.986871531863,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20893281756667417,
    "arrivals": 64419,
    "finished_requests": 64258,
    "scheduler_time": 39.43275877352809
}
#Debug simulation 
Total elapsed time: 4.638801791705191. Arrivals time: 0.16981357289478183 Scheduler time: 4.2035416713915765 Scheduler overhead time: 0.09907102026045322 Adapter cache time: 0.0208507152274251 Engine time: 0.09814048046246171 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-32/adapters_64_slots_64_rate_0.8-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-32/adapters_64_slots_64_rate_0.8-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 8640, 8640, 33, 8640, 33, 66, 33, 8640, 66, 8640, 33, 66, 8640, 8640, 8640, 33, 8640, 66, 66, 33, 33, 33, 8640, 33, 33, 33, 8640, 66, 33, 8640, 8640, 8640, 8640, 66, 66, 66, 8640, 33, 66, 66, 8640, 8640, 66, 8640, 33, 8640, 66, 66, 66, 8640, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 8640, 66]
Prompts retrieved: 192159 . Total input tokens: 43010186 . Total output tokens: 38352570
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 4.615718406159431,
    "estimated_duration": 3600.002762084403,
    "input_throughput": 4452.746583649475,
    "output_throughput": 3907.6422796561687,
    "total_throughput": 8360.388863305643,
    "itl": 36.72899696834049,
    "ttft": 9058.005085983146,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20928684858605254,
    "arrivals": 64419,
    "finished_requests": 64258,
    "scheduler_time": 39.43281135603252
}
#Debug simulation 
Total elapsed time: 4.6158153638243675. Arrivals time: 0.16876763431355357 Scheduler time: 4.182532479986548 Scheduler overhead time: 0.09876013081520796 Adapter cache time: 0.020796163007616997 Engine time: 0.09809428593143821 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-16/adapters_64_slots_64_rate_0.8-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-16/adapters_64_slots_64_rate_0.8-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 8640, 8640, 33, 8640, 33, 66, 33, 8640, 66, 8640, 33, 66, 8640, 8640, 8640, 33, 8640, 66, 66, 33, 33, 33, 8640, 33, 33, 33, 8640, 66, 33, 8640, 8640, 8640, 8640, 66, 66, 66, 8640, 33, 66, 66, 8640, 8640, 66, 8640, 33, 8640, 66, 66, 66, 8640, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 8640, 66]
Prompts retrieved: 192159 . Total input tokens: 43010186 . Total output tokens: 38352570
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 4.626537365373224,
    "estimated_duration": 3600.0248929292143,
    "input_throughput": 4452.719210771076,
    "output_throughput": 3907.6182577598092,
    "total_throughput": 8360.337468530886,
    "itl": 36.72899078356957,
    "ttft": 9058.091587119652,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.200352315879427,
    "arrivals": 64419,
    "finished_requests": 64258,
    "scheduler_time": 39.432965933699535
}
#Debug simulation 
Total elapsed time: 4.626676618121564. Arrivals time: 0.17262628534808755 Scheduler time: 4.188220931217074 Scheduler overhead time: 0.09913594555109739 Adapter cache time: 0.020912958774715662 Engine time: 0.0986415739171207 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-32/adapters_64_slots_64_rate_0.8-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-32/adapters_64_slots_64_rate_0.8-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 8640, 8640, 33, 8640, 33, 66, 33, 8640, 66, 8640, 33, 66, 8640, 8640, 8640, 33, 8640, 66, 66, 33, 33, 33, 8640, 33, 33, 33, 8640, 66, 33, 8640, 8640, 8640, 8640, 66, 66, 66, 8640, 33, 66, 66, 8640, 8640, 66, 8640, 33, 8640, 66, 66, 66, 8640, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 8640, 66]
Prompts retrieved: 192159 . Total input tokens: 43010186 . Total output tokens: 38352570
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 4.715386656112969,
    "estimated_duration": 3600.008956218671,
    "input_throughput": 4452.738922304591,
    "output_throughput": 3907.63555621152,
    "total_throughput": 8360.37447851611,
    "itl": 36.729111993794945,
    "ttft": 9058.068125021822,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21192767810076454,
    "arrivals": 64419,
    "finished_requests": 64258,
    "scheduler_time": 39.43292469260785
}
#Debug simulation 
Total elapsed time: 4.715486447326839. Arrivals time: 0.17182714492082596 Scheduler time: 4.276243090163916 Scheduler overhead time: 0.09962683590129018 Adapter cache time: 0.020867251325398684 Engine time: 0.09952614083886147 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-16/adapters_64_slots_64_rate_0.8-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-16/adapters_64_slots_64_rate_0.8-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 8640, 8640, 33, 8640, 33, 66, 33, 8640, 66, 8640, 33, 66, 8640, 8640, 8640, 33, 8640, 66, 66, 33, 33, 33, 8640, 33, 33, 33, 8640, 66, 33, 8640, 8640, 8640, 8640, 66, 66, 66, 8640, 33, 66, 66, 8640, 8640, 66, 8640, 33, 8640, 66, 66, 66, 8640, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 8640, 66]
Prompts retrieved: 192159 . Total input tokens: 43010186 . Total output tokens: 38352570
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 4.7300980826839805,
    "estimated_duration": 3600.0197864008005,
    "input_throughput": 4452.72552683002,
    "output_throughput": 3907.62380060814,
    "total_throughput": 8360.34932743816,
    "itl": 36.72897055561372,
    "ttft": 9058.050835017137,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19136321887373942,
    "arrivals": 64419,
    "finished_requests": 64258,
    "scheduler_time": 39.43288912332146
}
#Debug simulation 
Total elapsed time: 4.73028285196051. Arrivals time: 0.17427108902484179 Scheduler time: 4.288954503368586 Scheduler overhead time: 0.09898945223540068 Adapter cache time: 0.020831019151955843 Engine time: 0.09981546876952052 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-32/adapters_64_slots_64_rate_0.8-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-32/adapters_64_slots_64_rate_0.8-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 8640, 8640, 33, 8640, 33, 66, 33, 8640, 66, 8640, 33, 66, 8640, 8640, 8640, 33, 8640, 66, 66, 33, 33, 33, 8640, 33, 33, 33, 8640, 66, 33, 8640, 8640, 8640, 8640, 66, 66, 66, 8640, 33, 66, 66, 8640, 8640, 66, 8640, 33, 8640, 66, 66, 66, 8640, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 8640, 66]
Prompts retrieved: 192159 . Total input tokens: 43010186 . Total output tokens: 38352570
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 4.73344456916675,
    "estimated_duration": 3600.0122860047913,
    "input_throughput": 4452.734803799685,
    "output_throughput": 3907.631941893122,
    "total_throughput": 8360.366745692807,
    "itl": 36.72916381326737,
    "ttft": 9058.099553003394,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2146942614018914,
    "arrivals": 64419,
    "finished_requests": 64258,
    "scheduler_time": 39.43293666313207
}
#Debug simulation 
Total elapsed time: 4.733544860966504. Arrivals time: 0.17173402570188046 Scheduler time: 4.294660358689725 Scheduler overhead time: 0.09915651753544807 Adapter cache time: 0.020945673808455467 Engine time: 0.09978315560147166 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-8/adapters_64_slots_64_rate_0.4-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-8/adapters_64_slots_64_rate_0.4-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [21 21 22]
Adapter prompts. [540, 1080, 4320, 4320, 540, 4320, 540, 1080, 540, 4320, 1080, 4320, 540, 1080, 4320, 4320, 4320, 540, 4320, 1080, 1080, 540, 540, 540, 4320, 540, 540, 540, 4320, 1080, 540, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 540, 1080, 1080, 4320, 4320, 1080, 4320, 540, 4320, 1080, 1080, 1080, 4320, 1080, 540, 540, 1080, 1080, 540, 1080, 540, 540, 540, 4320, 1080]
Prompts retrieved: 129060 . Total input tokens: 28842701 . Total output tokens: 25798776
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 3.3871570848859847,
    "estimated_duration": 3600.0342678869292,
    "input_throughput": 2992.6201247866506,
    "output_throughput": 2625.101400922782,
    "total_throughput": 5617.721525709432,
    "itl": 34.944433570218166,
    "ttft": 8381.260414836403,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19587121561169607,
    "arrivals": 43251,
    "finished_requests": 43151,
    "scheduler_time": 19.785872287710266
}
#Debug simulation 
Total elapsed time: 3.3872926901094615. Arrivals time: 0.12702797632664442 Scheduler time: 2.9503974728286266 Scheduler overhead time: 0.09977658838033676 Adapter cache time: 0.062216379679739475 Engine time: 0.09952788054943085 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-16/adapters_64_slots_64_rate_0.4-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-16/adapters_64_slots_64_rate_0.4-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [21 21 22]
Adapter prompts. [540, 1080, 4320, 4320, 540, 4320, 540, 1080, 540, 4320, 1080, 4320, 540, 1080, 4320, 4320, 4320, 540, 4320, 1080, 1080, 540, 540, 540, 4320, 540, 540, 540, 4320, 1080, 540, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 540, 1080, 1080, 4320, 4320, 1080, 4320, 540, 4320, 1080, 1080, 1080, 4320, 1080, 540, 540, 1080, 1080, 540, 1080, 540, 540, 540, 4320, 1080]
Prompts retrieved: 129060 . Total input tokens: 28842701 . Total output tokens: 25798776
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.4094901639036834,
    "estimated_duration": 3600.0340519304723,
    "input_throughput": 2992.620304305963,
    "output_throughput": 2625.101558395625,
    "total_throughput": 5617.721862701588,
    "itl": 34.944608199658035,
    "ttft": 8381.198454617459,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2089328175666742,
    "arrivals": 43251,
    "finished_requests": 43151,
    "scheduler_time": 19.785993631951513
}
#Debug simulation 
Total elapsed time: 3.409586099907756. Arrivals time: 0.12675571674481034 Scheduler time: 2.972559979185462 Scheduler overhead time: 0.09973233146592975 Adapter cache time: 0.06211930140852928 Engine time: 0.10038533387705684 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-32/adapters_64_slots_64_rate_0.4-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-32/adapters_64_slots_64_rate_0.4-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [21 21 22]
Adapter prompts. [540, 1080, 4320, 4320, 540, 4320, 540, 1080, 540, 4320, 1080, 4320, 540, 1080, 4320, 4320, 4320, 540, 4320, 1080, 1080, 540, 540, 540, 4320, 540, 540, 540, 4320, 1080, 540, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 540, 1080, 1080, 4320, 4320, 1080, 4320, 540, 4320, 1080, 1080, 1080, 4320, 1080, 540, 540, 1080, 1080, 540, 1080, 540, 540, 540, 4320, 1080]
Prompts retrieved: 129060 . Total input tokens: 28842701 . Total output tokens: 25798776
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.40199566911906,
    "estimated_duration": 3600.0286665733215,
    "input_throughput": 2992.624781028414,
    "output_throughput": 2625.105485339202,
    "total_throughput": 5617.730266367616,
    "itl": 34.94449716372654,
    "ttft": 8381.167158005994,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20928684858605257,
    "arrivals": 43251,
    "finished_requests": 43151,
    "scheduler_time": 19.78594509425504
}
#Debug simulation 
Total elapsed time: 3.40210379101336. Arrivals time: 0.1261523263528943 Scheduler time: 2.9672247073613107 Scheduler overhead time: 0.0996961584314704 Adapter cache time: 0.062090386636555195 Engine time: 0.09907169919461012 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-16-16/adapters_64_slots_64_rate_0.4-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-16-16/adapters_64_slots_64_rate_0.4-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [21 21 22]
Adapter prompts. [540, 1080, 4320, 4320, 540, 4320, 540, 1080, 540, 4320, 1080, 4320, 540, 1080, 4320, 4320, 4320, 540, 4320, 1080, 1080, 540, 540, 540, 4320, 540, 540, 540, 4320, 1080, 540, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 540, 1080, 1080, 4320, 4320, 1080, 4320, 540, 4320, 1080, 1080, 1080, 4320, 1080, 540, 540, 1080, 1080, 540, 1080, 540, 540, 540, 4320, 1080]
Prompts retrieved: 129060 . Total input tokens: 28842701 . Total output tokens: 25798776
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 3.411609008908272,
    "estimated_duration": 3600.034268271042,
    "input_throughput": 2992.620124467347,
    "output_throughput": 2625.1014006426917,
    "total_throughput": 5617.721525110039,
    "itl": 34.94449255668361,
    "ttft": 8381.269705910061,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.200352315879427,
    "arrivals": 43251,
    "finished_requests": 43151,
    "scheduler_time": 19.785827794821785
}
#Debug simulation 
Total elapsed time: 3.4117122860625386. Arrivals time: 0.12713505188003182 Scheduler time: 2.9754920015111566 Scheduler overhead time: 0.09913908876478672 Adapter cache time: 0.061886999290436506 Engine time: 0.10049604531377554 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-16-32/adapters_64_slots_64_rate_0.4-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-16-32/adapters_64_slots_64_rate_0.4-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [21 21 22]
Adapter prompts. [540, 1080, 4320, 4320, 540, 4320, 540, 1080, 540, 4320, 1080, 4320, 540, 1080, 4320, 4320, 4320, 540, 4320, 1080, 1080, 540, 540, 540, 4320, 540, 540, 540, 4320, 1080, 540, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 540, 1080, 1080, 4320, 4320, 1080, 4320, 540, 4320, 1080, 1080, 1080, 4320, 1080, 540, 540, 1080, 1080, 540, 1080, 540, 540, 540, 4320, 1080]
Prompts retrieved: 129060 . Total input tokens: 28842701 . Total output tokens: 25798776
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 3.416552791837603,
    "estimated_duration": 3600.032337667592,
    "input_throughput": 2992.621729331469,
    "output_throughput": 2625.1028084161076,
    "total_throughput": 5617.7245377475765,
    "itl": 34.944563021903015,
    "ttft": 8381.227736309524,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21192767810076457,
    "arrivals": 43251,
    "finished_requests": 43151,
    "scheduler_time": 19.785973407911282
}
#Debug simulation 
Total elapsed time: 3.4166593439877033. Arrivals time: 0.12850312376394868 Scheduler time: 2.9800716182217 Scheduler overhead time: 0.0996103584766388 Adapter cache time: 0.0620236536487937 Engine time: 0.09852392273023725 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_16-16-16/adapters_64_slots_64_rate_0.4-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_16-16-16/adapters_64_slots_64_rate_0.4-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [21 21 22]
Adapter prompts. [540, 1080, 4320, 4320, 540, 4320, 540, 1080, 540, 4320, 1080, 4320, 540, 1080, 4320, 4320, 4320, 540, 4320, 1080, 1080, 540, 540, 540, 4320, 540, 540, 540, 4320, 1080, 540, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 540, 1080, 1080, 4320, 4320, 1080, 4320, 540, 4320, 1080, 1080, 1080, 4320, 1080, 540, 540, 1080, 1080, 540, 1080, 540, 540, 540, 4320, 1080]
Prompts retrieved: 129060 . Total input tokens: 28842701 . Total output tokens: 25798776
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 3.390651605091989,
    "estimated_duration": 3600.034045060987,
    "input_throughput": 2992.6203100163984,
    "output_throughput": 2625.1015634047712,
    "total_throughput": 5617.72187342117,
    "itl": 34.94453567220383,
    "ttft": 8381.201675080416,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19136321887373942,
    "arrivals": 43251,
    "finished_requests": 43151,
    "scheduler_time": 19.785904646174608
}
#Debug simulation 
Total elapsed time: 3.390770775731653. Arrivals time: 0.12768993712961674 Scheduler time: 2.955403578467667 Scheduler overhead time: 0.09984082588925958 Adapter cache time: 0.06194545514881611 Engine time: 0.09790185652673244 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_16-16-32/adapters_64_slots_64_rate_0.4-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_16-16-32/adapters_64_slots_64_rate_0.4-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [21 21 22]
Adapter prompts. [540, 1080, 4320, 4320, 540, 4320, 540, 1080, 540, 4320, 1080, 4320, 540, 1080, 4320, 4320, 4320, 540, 4320, 1080, 1080, 540, 540, 540, 4320, 540, 540, 540, 4320, 1080, 540, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 540, 1080, 1080, 4320, 4320, 1080, 4320, 540, 4320, 1080, 1080, 1080, 4320, 1080, 540, 540, 1080, 1080, 540, 1080, 540, 540, 540, 4320, 1080]
Prompts retrieved: 129060 . Total input tokens: 28842701 . Total output tokens: 25798776
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.4096335768699646,
    "estimated_duration": 3600.0343295572256,
    "input_throughput": 2992.6200735216476,
    "output_throughput": 2625.1013559535495,
    "total_throughput": 5617.721429475197,
    "itl": 34.94453005899905,
    "ttft": 8381.234493238535,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21469426140189146,
    "arrivals": 43251,
    "finished_requests": 43151,
    "scheduler_time": 19.78597745271926
}
#Debug simulation 
Total elapsed time: 3.409733235836029. Arrivals time: 0.12932459404692054 Scheduler time: 2.96992693701759 Scheduler overhead time: 0.09941629599779844 Adapter cache time: 0.062264940701425076 Engine time: 0.10079323640093207 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-8/adapters_64_slots_64_rate_0.4-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-8/adapters_64_slots_64_rate_0.4-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [21 21 22]
Adapter prompts. [270, 1080, 4320, 4320, 270, 4320, 270, 1080, 270, 4320, 1080, 4320, 270, 1080, 4320, 4320, 4320, 270, 4320, 1080, 1080, 270, 270, 270, 4320, 270, 270, 270, 4320, 1080, 270, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 270, 1080, 1080, 4320, 4320, 1080, 4320, 270, 4320, 1080, 1080, 1080, 4320, 1080, 270, 270, 1080, 1080, 270, 1080, 270, 270, 270, 4320, 1080]
Prompts retrieved: 123390 . Total input tokens: 27563012 . Total output tokens: 24672264
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 3.2705300678499043,
    "estimated_duration": 3599.978268248179,
    "input_throughput": 2860.950325961793,
    "output_throughput": 2514.8957369694476,
    "total_throughput": 5375.846062931241,
    "itl": 32.990061000577086,
    "ttft": 7108.091445773084,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19587121561169607,
    "arrivals": 41341,
    "finished_requests": 41260,
    "scheduler_time": 17.065765344754794
}
#Debug simulation 
Total elapsed time: 3.2706375108100474. Arrivals time: 0.11916919657960534 Scheduler time: 2.836646028328687 Scheduler overhead time: 0.10394265782088041 Adapter cache time: 0.05692639900371432 Engine time: 0.10380790429189801 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-16/adapters_64_slots_64_rate_0.4-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-16/adapters_64_slots_64_rate_0.4-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [21 21 22]
Adapter prompts. [270, 1080, 4320, 4320, 270, 4320, 270, 1080, 270, 4320, 1080, 4320, 270, 1080, 4320, 4320, 4320, 270, 4320, 1080, 1080, 270, 270, 270, 4320, 270, 270, 270, 4320, 1080, 270, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 270, 1080, 1080, 4320, 4320, 1080, 4320, 270, 4320, 1080, 1080, 1080, 4320, 1080, 270, 270, 1080, 1080, 270, 1080, 270, 270, 270, 4320, 1080]
Prompts retrieved: 123390 . Total input tokens: 27563012 . Total output tokens: 24672264
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.2450668830424547,
    "estimated_duration": 3599.9643172804945,
    "input_throughput": 2860.961413023227,
    "output_throughput": 2514.9054829630363,
    "total_throughput": 5375.866895986263,
    "itl": 32.98999782348237,
    "ttft": 7108.084035216103,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20893281756667417,
    "arrivals": 41341,
    "finished_requests": 41260,
    "scheduler_time": 17.065800914041155
}
#Debug simulation 
Total elapsed time: 3.245233476161957. Arrivals time: 0.12132999999448657 Scheduler time: 2.8076161248609424 Scheduler overhead time: 0.10425700293853879 Adapter cache time: 0.05703286686912179 Engine time: 0.10483872331678867 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-32/adapters_64_slots_64_rate_0.4-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-32/adapters_64_slots_64_rate_0.4-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [21 21 22]
Adapter prompts. [270, 1080, 4320, 4320, 270, 4320, 270, 1080, 270, 4320, 1080, 4320, 270, 1080, 4320, 4320, 4320, 270, 4320, 1080, 1080, 270, 270, 270, 4320, 270, 270, 270, 4320, 1080, 270, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 270, 1080, 1080, 4320, 4320, 1080, 4320, 270, 4320, 1080, 1080, 1080, 4320, 1080, 270, 270, 1080, 1080, 270, 1080, 270, 270, 270, 4320, 1080]
Prompts retrieved: 123390 . Total input tokens: 27563012 . Total output tokens: 24672264
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.2874276940710843,
    "estimated_duration": 3599.9642892595875,
    "input_throughput": 2860.961435291985,
    "output_throughput": 2514.9055025382117,
    "total_throughput": 5375.866937830197,
    "itl": 32.990009909819555,
    "ttft": 7108.069008807076,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20928684858605254,
    "arrivals": 41341,
    "finished_requests": 41260,
    "scheduler_time": 17.065800914041144
}
#Debug simulation 
Total elapsed time: 3.2875363817438483. Arrivals time: 0.12304854858666658 Scheduler time: 2.8498305617831647 Scheduler overhead time: 0.10422068601474166 Adapter cache time: 0.05713939620181918 Engine time: 0.10328970290720463 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-16-16/adapters_64_slots_64_rate_0.4-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-16-16/adapters_64_slots_64_rate_0.4-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [21 21 22]
Adapter prompts. [270, 1080, 4320, 4320, 270, 4320, 270, 1080, 270, 4320, 1080, 4320, 270, 1080, 4320, 4320, 4320, 270, 4320, 1080, 1080, 270, 270, 270, 4320, 270, 270, 270, 4320, 1080, 270, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 270, 1080, 1080, 4320, 4320, 1080, 4320, 270, 4320, 1080, 1080, 1080, 4320, 1080, 270, 270, 1080, 1080, 270, 1080, 270, 270, 270, 4320, 1080]
Prompts retrieved: 123390 . Total input tokens: 27563012 . Total output tokens: 24672264
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 3.3070007897913456,
    "estimated_duration": 3599.982035579501,
    "input_throughput": 2860.9473320169163,
    "output_throughput": 2514.8931051659033,
    "total_throughput": 5375.840437182819,
    "itl": 32.99009066218384,
    "ttft": 7107.968397075262,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20035231587942698,
    "arrivals": 41341,
    "finished_requests": 41260,
    "scheduler_time": 17.065789613603098
}
#Debug simulation 
Total elapsed time: 3.307101754937321. Arrivals time: 0.12295581540092826 Scheduler time: 2.866760364267975 Scheduler overhead time: 0.10489148180931807 Adapter cache time: 0.057215724140405655 Engine time: 0.10497991414740682 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-16-32/adapters_64_slots_64_rate_0.4-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-16-32/adapters_64_slots_64_rate_0.4-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [21 21 22]
Adapter prompts. [270, 1080, 4320, 4320, 270, 4320, 270, 1080, 270, 4320, 1080, 4320, 270, 1080, 4320, 4320, 4320, 270, 4320, 1080, 1080, 270, 270, 270, 4320, 270, 270, 270, 4320, 1080, 270, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 270, 1080, 1080, 4320, 4320, 1080, 4320, 270, 4320, 1080, 1080, 1080, 4320, 1080, 270, 270, 1080, 1080, 270, 1080, 270, 270, 270, 4320, 1080]
Prompts retrieved: 123390 . Total input tokens: 27563012 . Total output tokens: 24672264
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 3.2666186350397766,
    "estimated_duration": 3599.9639900358407,
    "input_throughput": 2860.9616730909192,
    "output_throughput": 2514.9057115734827,
    "total_throughput": 5375.867384664402,
    "itl": 32.989938566724774,
    "ttft": 7108.09453804143,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21192767810076454,
    "arrivals": 41341,
    "finished_requests": 41260,
    "scheduler_time": 17.065792824425053
}
#Debug simulation 
Total elapsed time: 3.2667155787348747. Arrivals time: 0.11512107308954 Scheduler time: 2.83961614780128 Scheduler overhead time: 0.10382972983643413 Adapter cache time: 0.056930729188025 Engine time: 0.10129579622298479 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_16-16-16/adapters_64_slots_64_rate_0.4-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_16-16-16/adapters_64_slots_64_rate_0.4-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [21 21 22]
Adapter prompts. [270, 1080, 4320, 4320, 270, 4320, 270, 1080, 270, 4320, 1080, 4320, 270, 1080, 4320, 4320, 4320, 270, 4320, 1080, 1080, 270, 270, 270, 4320, 270, 270, 270, 4320, 1080, 270, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 270, 1080, 1080, 4320, 4320, 1080, 4320, 270, 4320, 1080, 1080, 1080, 4320, 1080, 270, 270, 1080, 1080, 270, 1080, 270, 270, 270, 4320, 1080]
Prompts retrieved: 123390 . Total input tokens: 27563012 . Total output tokens: 24672264
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 3.297904253937304,
    "estimated_duration": 3599.964323366309,
    "input_throughput": 2860.961408186712,
    "output_throughput": 2514.9054787115365,
    "total_throughput": 5375.866886898249,
    "itl": 32.989834636138,
    "ttft": 7108.06492173669,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19136321887373942,
    "arrivals": 41341,
    "finished_requests": 41260,
    "scheduler_time": 17.065668269361804
}
#Debug simulation 
Total elapsed time: 3.2980265598744154. Arrivals time: 0.12157216714695096 Scheduler time: 2.8581215222366154 Scheduler overhead time: 0.10465807560831308 Adapter cache time: 0.05681016715243459 Engine time: 0.10676173446699977 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_16-16-32/adapters_64_slots_64_rate_0.4-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_16-16-32/adapters_64_slots_64_rate_0.4-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [21 21 22]
Adapter prompts. [270, 1080, 4320, 4320, 270, 4320, 270, 1080, 270, 4320, 1080, 4320, 270, 1080, 4320, 4320, 4320, 270, 4320, 1080, 1080, 270, 270, 270, 4320, 270, 270, 270, 4320, 1080, 270, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 270, 1080, 1080, 4320, 4320, 1080, 4320, 270, 4320, 1080, 1080, 1080, 4320, 1080, 270, 270, 1080, 1080, 270, 1080, 270, 270, 270, 4320, 1080]
Prompts retrieved: 123390 . Total input tokens: 27563012 . Total output tokens: 24672264
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.3204648327082396,
    "estimated_duration": 3599.9778895380477,
    "input_throughput": 2860.950626927773,
    "output_throughput": 2514.89600153121,
    "total_throughput": 5375.846628458983,
    "itl": 32.99018744187488,
    "ttft": 7108.082896188853,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2146942614018914,
    "arrivals": 41341,
    "finished_requests": 41260,
    "scheduler_time": 17.065906913036255
}
#Debug simulation 
Total elapsed time: 3.3205644926056266. Arrivals time: 0.1194061478599906 Scheduler time: 2.883270970545709 Scheduler overhead time: 0.10500201117247343 Adapter cache time: 0.05696942703798413 Engine time: 0.10544687416404486 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-8/adapters_64_slots_64_rate_0.4-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-8/adapters_64_slots_64_rate_0.4-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 1080, 4320, 4320, 135, 4320, 135, 1080, 135, 4320, 1080, 4320, 135, 1080, 4320, 4320, 4320, 135, 4320, 1080, 1080, 135, 135, 135, 4320, 135, 135, 135, 4320, 1080, 135, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 135, 1080, 1080, 4320, 4320, 1080, 4320, 135, 4320, 1080, 1080, 1080, 4320, 1080, 135, 135, 1080, 1080, 135, 1080, 135, 135, 135, 4320, 1080]
Prompts retrieved: 120555 . Total input tokens: 26904447 . Total output tokens: 24124616
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 3.2215685239061713,
    "estimated_duration": 3600.005395590338,
    "input_throughput": 2783.5474947550088,
    "output_throughput": 2459.367147295106,
    "total_throughput": 5242.914642050115,
    "itl": 31.903172066657458,
    "ttft": 6292.747921731952,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19587121561169607,
    "arrivals": 40385,
    "finished_requests": 40315,
    "scheduler_time": 15.59848609947927
}
#Debug simulation 
Total elapsed time: 3.2216809750534594. Arrivals time: 0.12118742382153869 Scheduler time: 2.7831900706514716 Scheduler overhead time: 0.10614784015342593 Adapter cache time: 0.054860207717865705 Engine time: 0.10513677448034286 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-16/adapters_64_slots_64_rate_0.4-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-16/adapters_64_slots_64_rate_0.4-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 1080, 4320, 4320, 135, 4320, 135, 1080, 135, 4320, 1080, 4320, 135, 1080, 4320, 4320, 4320, 135, 4320, 1080, 1080, 135, 135, 135, 4320, 135, 135, 135, 4320, 1080, 135, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 135, 1080, 1080, 4320, 4320, 1080, 4320, 135, 4320, 1080, 1080, 1080, 4320, 1080, 135, 135, 1080, 1080, 135, 1080, 135, 135, 135, 4320, 1080]
Prompts retrieved: 120555 . Total input tokens: 26904447 . Total output tokens: 24124616
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.2071164059452713,
    "estimated_duration": 3600.0301014177453,
    "input_throughput": 2783.5283921802948,
    "output_throughput": 2459.3502694639324,
    "total_throughput": 5242.878661644228,
    "itl": 31.928803722079618,
    "ttft": 6292.83684719316,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2089328175666742,
    "arrivals": 40385,
    "finished_requests": 40315,
    "scheduler_time": 15.615729324946377
}
#Debug simulation 
Total elapsed time: 3.2072182027623057. Arrivals time: 0.11902950471267104 Scheduler time: 2.7690571355633438 Scheduler overhead time: 0.10705766594037414 Adapter cache time: 0.054249817971140146 Engine time: 0.10641860589385033 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-32/adapters_64_slots_64_rate_0.4-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-32/adapters_64_slots_64_rate_0.4-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 1080, 4320, 4320, 135, 4320, 135, 1080, 135, 4320, 1080, 4320, 135, 1080, 4320, 4320, 4320, 135, 4320, 1080, 1080, 135, 135, 135, 4320, 135, 135, 135, 4320, 1080, 135, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 135, 1080, 1080, 4320, 4320, 1080, 4320, 135, 4320, 1080, 1080, 1080, 4320, 1080, 135, 135, 1080, 1080, 135, 1080, 135, 135, 135, 4320, 1080]
Prompts retrieved: 120555 . Total input tokens: 26904447 . Total output tokens: 24124616
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.2300885068252683,
    "estimated_duration": 3600.0301039885903,
    "input_throughput": 2783.528390192528,
    "output_throughput": 2459.350267707667,
    "total_throughput": 5242.878657900195,
    "itl": 31.92880757150978,
    "ttft": 6292.826190074618,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20928684858605257,
    "arrivals": 40385,
    "finished_requests": 40315,
    "scheduler_time": 15.615726114124346
}
#Debug simulation 
Total elapsed time: 3.230189324822277. Arrivals time: 0.1194447698071599 Scheduler time: 2.789981364272535 Scheduler overhead time: 0.1071661189198494 Adapter cache time: 0.054516205564141273 Engine time: 0.10754620376974344 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-16/adapters_64_slots_64_rate_0.4-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-16/adapters_64_slots_64_rate_0.4-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 1080, 4320, 4320, 135, 4320, 135, 1080, 135, 4320, 1080, 4320, 135, 1080, 4320, 4320, 4320, 135, 4320, 1080, 1080, 135, 135, 135, 4320, 135, 135, 135, 4320, 1080, 135, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 135, 1080, 1080, 4320, 4320, 1080, 4320, 135, 4320, 1080, 1080, 1080, 4320, 1080, 135, 135, 1080, 1080, 135, 1080, 135, 135, 135, 4320, 1080]
Prompts retrieved: 120555 . Total input tokens: 26904447 . Total output tokens: 24124616
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 3.229569453280419,
    "estimated_duration": 3599.999951466598,
    "input_throughput": 2783.5517041931207,
    "output_throughput": 2459.370866489343,
    "total_throughput": 5242.922570682464,
    "itl": 31.903545758006615,
    "ttft": 6292.78465384326,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20035231587942698,
    "arrivals": 40385,
    "finished_requests": 40315,
    "scheduler_time": 15.598625958813786
}
#Debug simulation 
Total elapsed time: 3.229685647878796. Arrivals time: 0.12100635282695293 Scheduler time: 2.7876418055966496 Scheduler overhead time: 0.10706882691010833 Adapter cache time: 0.0549408788792789 Engine time: 0.10711422003805637 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-32/adapters_64_slots_64_rate_0.4-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-32/adapters_64_slots_64_rate_0.4-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 1080, 4320, 4320, 135, 4320, 135, 1080, 135, 4320, 1080, 4320, 135, 1080, 4320, 4320, 4320, 135, 4320, 1080, 1080, 135, 135, 135, 4320, 135, 135, 135, 4320, 1080, 135, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 135, 1080, 1080, 4320, 4320, 1080, 4320, 135, 4320, 1080, 1080, 1080, 4320, 1080, 135, 135, 1080, 1080, 135, 1080, 135, 135, 135, 4320, 1080]
Prompts retrieved: 120555 . Total input tokens: 26904447 . Total output tokens: 24124616
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 3.215424159076065,
    "estimated_duration": 3600.0245899226065,
    "input_throughput": 2783.532653652076,
    "output_throughput": 2459.3540346318405,
    "total_throughput": 5242.886688283917,
    "itl": 31.929108335045747,
    "ttft": 6292.797807512744,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21192767810076457,
    "arrivals": 40385,
    "finished_requests": 40315,
    "scheduler_time": 15.615858799778536
}
#Debug simulation 
Total elapsed time: 3.2155205248855054. Arrivals time: 0.11898821592330933 Scheduler time: 2.777641387656331 Scheduler overhead time: 0.10685676848515868 Adapter cache time: 0.054299409966915846 Engine time: 0.1061161127872765 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-16/adapters_64_slots_64_rate_0.4-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-16/adapters_64_slots_64_rate_0.4-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 1080, 4320, 4320, 135, 4320, 135, 1080, 135, 4320, 1080, 4320, 135, 1080, 4320, 4320, 4320, 135, 4320, 1080, 1080, 135, 135, 135, 4320, 135, 135, 135, 4320, 1080, 135, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 135, 1080, 1080, 4320, 4320, 1080, 4320, 135, 4320, 1080, 1080, 1080, 4320, 1080, 135, 135, 1080, 1080, 135, 1080, 135, 135, 135, 4320, 1080]
Prompts retrieved: 120555 . Total input tokens: 26904447 . Total output tokens: 24124616
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 3.17950179008767,
    "estimated_duration": 3600.0035651905914,
    "input_throughput": 2783.548910032671,
    "output_throughput": 2459.3683977452574,
    "total_throughput": 5242.917307777929,
    "itl": 31.90332704536217,
    "ttft": 6292.651843512157,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19136321887373942,
    "arrivals": 40385,
    "finished_requests": 40315,
    "scheduler_time": 15.598494148120452
}
#Debug simulation 
Total elapsed time: 3.179607131984085. Arrivals time: 0.11878623440861702 Scheduler time: 2.7380292555317283 Scheduler overhead time: 0.10763710271567106 Adapter cache time: 0.054621847812086344 Engine time: 0.10895378701388836 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-32/adapters_64_slots_64_rate_0.4-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-32/adapters_64_slots_64_rate_0.4-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 1080, 4320, 4320, 135, 4320, 135, 1080, 135, 4320, 1080, 4320, 135, 1080, 4320, 4320, 4320, 135, 4320, 1080, 1080, 135, 135, 135, 4320, 135, 135, 135, 4320, 1080, 135, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 135, 1080, 1080, 4320, 4320, 1080, 4320, 135, 4320, 1080, 1080, 1080, 4320, 1080, 135, 135, 1080, 1080, 135, 1080, 135, 135, 135, 4320, 1080]
Prompts retrieved: 120555 . Total input tokens: 26904447 . Total output tokens: 24124616
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.2237603343091905,
    "estimated_duration": 3600.024402113336,
    "input_throughput": 2783.53279886588,
    "output_throughput": 2459.3541629336064,
    "total_throughput": 5242.886961799487,
    "itl": 31.929039171470524,
    "ttft": 6292.623700430283,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21469426140189146,
    "arrivals": 40385,
    "finished_requests": 40315,
    "scheduler_time": 15.615842620546388
}
#Debug simulation 
Total elapsed time: 3.223873865325004. Arrivals time: 0.11571656074374914 Scheduler time: 2.7907305164262652 Scheduler overhead time: 0.10646707657724619 Adapter cache time: 0.05458900751546025 Engine time: 0.10503336740657687 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-8/adapters_64_slots_64_rate_0.4-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-8/adapters_64_slots_64_rate_0.4-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 1080, 4320, 4320, 66, 4320, 66, 1080, 66, 4320, 1080, 4320, 66, 1080, 4320, 4320, 4320, 66, 4320, 1080, 1080, 66, 66, 66, 4320, 66, 66, 66, 4320, 1080, 66, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 66, 1080, 1080, 4320, 4320, 1080, 4320, 66, 4320, 1080, 1080, 1080, 4320, 1080, 66, 66, 1080, 1080, 66, 1080, 66, 66, 66, 4320, 1080]
Prompts retrieved: 119106 . Total input tokens: 26581357 . Total output tokens: 23854509
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 3.135785636957735,
    "estimated_duration": 3600.0309443903293,
    "input_throughput": 2739.9578371320003,
    "output_throughput": 2468.8412786699478,
    "total_throughput": 5208.799115801949,
    "itl": 31.735125137162612,
    "ttft": 8976.254822407984,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19587121561169607,
    "arrivals": 39938,
    "finished_requests": 39838,
    "scheduler_time": 15.58475143717459
}
#Debug simulation 
Total elapsed time: 3.135947464965284. Arrivals time: 0.1169260423630476 Scheduler time: 2.7044271104969084 Scheduler overhead time: 0.10732286516577005 Adapter cache time: 0.05036204680800438 Engine time: 0.10539145953953266 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-16/adapters_64_slots_64_rate_0.4-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-16/adapters_64_slots_64_rate_0.4-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 1080, 4320, 4320, 66, 4320, 66, 1080, 66, 4320, 1080, 4320, 66, 1080, 4320, 4320, 4320, 66, 4320, 1080, 1080, 66, 66, 66, 4320, 66, 66, 66, 4320, 1080, 66, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 66, 1080, 1080, 4320, 4320, 1080, 4320, 66, 4320, 1080, 1080, 1080, 4320, 1080, 66, 66, 1080, 1080, 66, 1080, 66, 66, 66, 4320, 1080]
Prompts retrieved: 119106 . Total input tokens: 26581357 . Total output tokens: 23854509
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.1918740309774876,
    "estimated_duration": 3600.0309494347066,
    "input_throughput": 2739.957833292761,
    "output_throughput": 2468.841275210598,
    "total_throughput": 5208.799108503359,
    "itl": 31.735001452063067,
    "ttft": 8976.2991531631,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20893281756667417,
    "arrivals": 39938,
    "finished_requests": 39838,
    "scheduler_time": 15.584687554231941
}
#Debug simulation 
Total elapsed time: 3.1919791349209845. Arrivals time: 0.11581562319770455 Scheduler time: 2.7569357734173536 Scheduler overhead time: 0.10756290052086115 Adapter cache time: 0.0508747766725719 Engine time: 0.10895235696807504 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-32/adapters_64_slots_64_rate_0.4-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-32/adapters_64_slots_64_rate_0.4-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 1080, 4320, 4320, 66, 4320, 66, 1080, 66, 4320, 1080, 4320, 66, 1080, 4320, 4320, 4320, 66, 4320, 1080, 1080, 66, 66, 66, 4320, 66, 66, 66, 4320, 1080, 66, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 66, 1080, 1080, 4320, 4320, 1080, 4320, 66, 4320, 1080, 1080, 1080, 4320, 1080, 66, 66, 1080, 1080, 66, 1080, 66, 66, 66, 4320, 1080]
Prompts retrieved: 119106 . Total input tokens: 26581357 . Total output tokens: 23854509
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.1933414549566805,
    "estimated_duration": 3600.0309303969907,
    "input_throughput": 2739.9578477822306,
    "output_throughput": 2468.8412882663465,
    "total_throughput": 5208.799136048577,
    "itl": 31.73501024084832,
    "ttft": 8976.3277716508,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20928684858605257,
    "arrivals": 39938,
    "finished_requests": 39838,
    "scheduler_time": 15.584687554231921
}
#Debug simulation 
Total elapsed time: 3.193455193657428. Arrivals time: 0.11794331204146147 Scheduler time: 2.7599817565642297 Scheduler overhead time: 0.10757820820435882 Adapter cache time: 0.05072044814005494 Engine time: 0.10534017346799374 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-16/adapters_64_slots_64_rate_0.4-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-16/adapters_64_slots_64_rate_0.4-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 1080, 4320, 4320, 66, 4320, 66, 1080, 66, 4320, 1080, 4320, 66, 1080, 4320, 4320, 4320, 66, 4320, 1080, 1080, 66, 66, 66, 4320, 66, 66, 66, 4320, 1080, 66, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 66, 1080, 1080, 4320, 4320, 1080, 4320, 66, 4320, 1080, 1080, 1080, 4320, 1080, 66, 66, 1080, 1080, 66, 1080, 66, 66, 66, 4320, 1080]
Prompts retrieved: 119106 . Total input tokens: 26581357 . Total output tokens: 23854509
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 3.221043032128364,
    "estimated_duration": 3600.0309640369032,
    "input_throughput": 2739.9578221791335,
    "output_throughput": 2468.8412651966546,
    "total_throughput": 5208.799087375788,
    "itl": 31.735034636627272,
    "ttft": 8976.279468219871,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20035231587942695,
    "arrivals": 39938,
    "finished_requests": 39838,
    "scheduler_time": 15.584735257942443
}
#Debug simulation 
Total elapsed time: 3.2211418971419334. Arrivals time: 0.11523545766249299 Scheduler time: 2.7860751543194056 Scheduler overhead time: 0.10789932776242495 Adapter cache time: 0.051570131443440914 Engine time: 0.10872937506064773 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-32/adapters_64_slots_64_rate_0.4-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-32/adapters_64_slots_64_rate_0.4-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 1080, 4320, 4320, 66, 4320, 66, 1080, 66, 4320, 1080, 4320, 66, 1080, 4320, 4320, 4320, 66, 4320, 1080, 1080, 66, 66, 66, 4320, 66, 66, 66, 4320, 1080, 66, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 66, 1080, 1080, 4320, 4320, 1080, 4320, 66, 4320, 1080, 1080, 1080, 4320, 1080, 66, 66, 1080, 1080, 66, 1080, 66, 66, 66, 4320, 1080]
Prompts retrieved: 119106 . Total input tokens: 26581357 . Total output tokens: 23854509
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 3.1391043649055064,
    "estimated_duration": 3600.0298534275703,
    "input_throughput": 2739.9586674562156,
    "output_throughput": 2468.8420268342693,
    "total_throughput": 5208.800694290485,
    "itl": 31.73528265773591,
    "ttft": 8976.317666099389,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21192767810076457,
    "arrivals": 39938,
    "finished_requests": 39838,
    "scheduler_time": 15.584864691799803
}
#Debug simulation 
Total elapsed time: 3.1392021477222443. Arrivals time: 0.11388234188780189 Scheduler time: 2.709675674792379 Scheduler overhead time: 0.10779073880985379 Adapter cache time: 0.0509343771263957 Engine time: 0.10506309242919087 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-16/adapters_64_slots_64_rate_0.4-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-16/adapters_64_slots_64_rate_0.4-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 1080, 4320, 4320, 66, 4320, 66, 1080, 66, 4320, 1080, 4320, 66, 1080, 4320, 4320, 4320, 66, 4320, 1080, 1080, 66, 66, 66, 4320, 66, 66, 66, 4320, 1080, 66, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 66, 1080, 1080, 4320, 4320, 1080, 4320, 66, 4320, 1080, 1080, 1080, 4320, 1080, 66, 66, 1080, 1080, 66, 1080, 66, 66, 66, 4320, 1080]
Prompts retrieved: 119106 . Total input tokens: 26581357 . Total output tokens: 23854509
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 3.177008217200637,
    "estimated_duration": 3600.029819703252,
    "input_throughput": 2739.958693123569,
    "output_throughput": 2468.8420499618596,
    "total_throughput": 5208.800743085429,
    "itl": 31.735170140276907,
    "ttft": 8976.322424187652,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19136321887373942,
    "arrivals": 39938,
    "finished_requests": 39838,
    "scheduler_time": 15.584771661214933
}
#Debug simulation 
Total elapsed time: 3.177107912953943. Arrivals time: 0.11672284733504057 Scheduler time: 2.743494303897023 Scheduler overhead time: 0.10668883053585887 Adapter cache time: 0.050662482157349586 Engine time: 0.10793872876092792 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-32/adapters_64_slots_64_rate_0.4-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-32/adapters_64_slots_64_rate_0.4-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 1080, 4320, 4320, 66, 4320, 66, 1080, 66, 4320, 1080, 4320, 66, 1080, 4320, 4320, 4320, 66, 4320, 1080, 1080, 66, 66, 66, 4320, 66, 66, 66, 4320, 1080, 66, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 66, 1080, 1080, 4320, 4320, 1080, 4320, 66, 4320, 1080, 1080, 1080, 4320, 1080, 66, 66, 1080, 1080, 66, 1080, 66, 66, 66, 4320, 1080]
Prompts retrieved: 119106 . Total input tokens: 26581357 . Total output tokens: 23854509
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.1504103769548237,
    "estimated_duration": 3600.0309500030676,
    "input_throughput": 2739.9578328601856,
    "output_throughput": 2468.841274820825,
    "total_throughput": 5208.79910768101,
    "itl": 31.735275661426087,
    "ttft": 8976.269561721432,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21469426140189143,
    "arrivals": 39938,
    "finished_requests": 39838,
    "scheduler_time": 15.584868736607808
}
#Debug simulation 
Total elapsed time: 3.150544796139002. Arrivals time: 0.11541211139410734 Scheduler time: 2.7205604957416654 Scheduler overhead time: 0.1073449095711112 Adapter cache time: 0.050780193880200386 Engine time: 0.10486508999019861 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-8/adapters_64_slots_64_rate_0.4-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-8/adapters_64_slots_64_rate_0.4-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 1080, 4320, 4320, 33, 4320, 33, 1080, 33, 4320, 1080, 4320, 33, 1080, 4320, 4320, 4320, 33, 4320, 1080, 1080, 33, 33, 33, 4320, 33, 33, 33, 4320, 1080, 33, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 33, 1080, 1080, 4320, 4320, 1080, 4320, 33, 4320, 1080, 1080, 1080, 4320, 1080, 33, 33, 1080, 1080, 33, 1080, 33, 33, 33, 4320, 1080]
Prompts retrieved: 118413 . Total input tokens: 26410766 . Total output tokens: 23719308
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 3.1413104068487883,
    "estimated_duration": 3599.777189020946,
    "input_throughput": 2743.3514580067354,
    "output_throughput": 2414.6166675288146,
    "total_throughput": 5157.96812553555,
    "itl": 31.087779443854192,
    "ttft": 8299.348027478101,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19587121561169607,
    "arrivals": 39719,
    "finished_requests": 39628,
    "scheduler_time": 14.450029838718235
}
#Debug simulation 
Total elapsed time: 3.1414063246920705. Arrivals time: 0.11743596801534295 Scheduler time: 2.7036964832805097 Scheduler overhead time: 0.10887623392045498 Adapter cache time: 0.051017293240875006 Engine time: 0.10774727817624807 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-16/adapters_64_slots_64_rate_0.4-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-16/adapters_64_slots_64_rate_0.4-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 1080, 4320, 4320, 33, 4320, 33, 1080, 33, 4320, 1080, 4320, 33, 1080, 4320, 4320, 4320, 33, 4320, 1080, 1080, 33, 33, 33, 4320, 33, 33, 33, 4320, 1080, 33, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 33, 1080, 1080, 4320, 4320, 1080, 4320, 33, 4320, 1080, 1080, 1080, 4320, 1080, 33, 33, 1080, 1080, 33, 1080, 33, 33, 33, 4320, 1080]
Prompts retrieved: 118413 . Total input tokens: 26410766 . Total output tokens: 23719308
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.0881360438652337,
    "estimated_duration": 3599.7764089880707,
    "input_throughput": 2743.3520524615246,
    "output_throughput": 2414.6171907503062,
    "total_throughput": 5157.969243211831,
    "itl": 31.087729492933157,
    "ttft": 8299.30744185721,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2089328175666742,
    "arrivals": 39719,
    "finished_requests": 39628,
    "scheduler_time": 14.449957032173476
}
#Debug simulation 
Total elapsed time: 3.088234568014741. Arrivals time: 0.1165160764940083 Scheduler time: 2.6511219325475395 Scheduler overhead time: 0.1085802256129682 Adapter cache time: 0.05064671393483877 Engine time: 0.10903806053102016 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-32/adapters_64_slots_64_rate_0.4-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-32/adapters_64_slots_64_rate_0.4-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 1080, 4320, 4320, 33, 4320, 33, 1080, 33, 4320, 1080, 4320, 33, 1080, 4320, 4320, 4320, 33, 4320, 1080, 1080, 33, 33, 33, 4320, 33, 33, 33, 4320, 1080, 33, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 33, 1080, 1080, 4320, 4320, 1080, 4320, 33, 4320, 1080, 1080, 1080, 4320, 1080, 33, 33, 1080, 1080, 33, 1080, 33, 33, 33, 4320, 1080]
Prompts retrieved: 118413 . Total input tokens: 26410766 . Total output tokens: 23719308
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.165260646957904,
    "estimated_duration": 3599.777092867188,
    "input_throughput": 2743.3515312844816,
    "output_throughput": 2414.6167320257155,
    "total_throughput": 5157.9682633101975,
    "itl": 31.087717482709778,
    "ttft": 8299.315379805472,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20928684858605257,
    "arrivals": 39719,
    "finished_requests": 39628,
    "scheduler_time": 14.449965121789548
}
#Debug simulation 
Total elapsed time: 3.165360889863223. Arrivals time: 0.11343500856310129 Scheduler time: 2.7316841795109212 Scheduler overhead time: 0.10875113774091005 Adapter cache time: 0.05086730886250734 Engine time: 0.1084184660576284 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-16/adapters_64_slots_64_rate_0.4-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-16/adapters_64_slots_64_rate_0.4-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 1080, 4320, 4320, 33, 4320, 33, 1080, 33, 4320, 1080, 4320, 33, 1080, 4320, 4320, 4320, 33, 4320, 1080, 1080, 33, 33, 33, 4320, 33, 33, 33, 4320, 1080, 33, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 33, 1080, 1080, 4320, 4320, 1080, 4320, 33, 4320, 1080, 1080, 1080, 4320, 1080, 33, 33, 1080, 1080, 33, 1080, 33, 33, 33, 4320, 1080]
Prompts retrieved: 118413 . Total input tokens: 26410766 . Total output tokens: 23719308
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 3.0841637393459678,
    "estimated_duration": 3599.7772766359903,
    "input_throughput": 2743.3513912362546,
    "output_throughput": 2414.6166087594156,
    "total_throughput": 5157.967999995671,
    "itl": 31.087750544983308,
    "ttft": 8299.283825994871,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20035231587942698,
    "arrivals": 39719,
    "finished_requests": 39628,
    "scheduler_time": 14.450001525061916
}
#Debug simulation 
Total elapsed time: 3.0842884462326765. Arrivals time: 0.11624355567619205 Scheduler time: 2.6480141412466764 Scheduler overhead time: 0.10816545179113746 Adapter cache time: 0.050887385848909616 Engine time: 0.10875003738328815 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-32/adapters_64_slots_64_rate_0.4-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-32/adapters_64_slots_64_rate_0.4-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 1080, 4320, 4320, 33, 4320, 33, 1080, 33, 4320, 1080, 4320, 33, 1080, 4320, 4320, 4320, 33, 4320, 1080, 1080, 33, 33, 33, 4320, 33, 33, 33, 4320, 1080, 33, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 33, 1080, 1080, 4320, 4320, 1080, 4320, 33, 4320, 1080, 1080, 1080, 4320, 1080, 33, 33, 1080, 1080, 33, 1080, 33, 33, 33, 4320, 1080]
Prompts retrieved: 118413 . Total input tokens: 26410766 . Total output tokens: 23719308
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 3.1163467462174594,
    "estimated_duration": 3599.7994213503816,
    "input_throughput": 2743.371183802069,
    "output_throughput": 2414.602310464111,
    "total_throughput": 5157.97349426618,
    "itl": 31.087570283100817,
    "ttft": 8208.697704854796,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21192767810076457,
    "arrivals": 39719,
    "finished_requests": 39629,
    "scheduler_time": 14.450156102728673
}
#Debug simulation 
Total elapsed time: 3.1164453560486436. Arrivals time: 0.1159514538012445 Scheduler time: 2.68083383096382 Scheduler overhead time: 0.1086486978456378 Adapter cache time: 0.05088292621076107 Engine time: 0.10767700430005789 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-16/adapters_64_slots_64_rate_0.4-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-16/adapters_64_slots_64_rate_0.4-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 1080, 4320, 4320, 33, 4320, 33, 1080, 33, 4320, 1080, 4320, 33, 1080, 4320, 4320, 4320, 33, 4320, 1080, 1080, 33, 33, 33, 4320, 33, 33, 33, 4320, 1080, 33, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 33, 1080, 1080, 4320, 4320, 1080, 4320, 33, 4320, 1080, 1080, 1080, 4320, 1080, 33, 33, 1080, 1080, 33, 1080, 33, 33, 33, 4320, 1080]
Prompts retrieved: 118413 . Total input tokens: 26410766 . Total output tokens: 23719308
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 3.0816582147963345,
    "estimated_duration": 3599.8006365679507,
    "input_throughput": 2743.37025769721,
    "output_throughput": 2414.601495344762,
    "total_throughput": 5157.971753041972,
    "itl": 31.087223682326126,
    "ttft": 8208.709252618833,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19136321887373942,
    "arrivals": 39719,
    "finished_requests": 39629,
    "scheduler_time": 14.450067116951688
}
#Debug simulation 
Total elapsed time: 3.081757980864495. Arrivals time: 0.1131796445697546 Scheduler time: 2.65017944900319 Scheduler overhead time: 0.10858461959287524 Adapter cache time: 0.05070777516812086 Engine time: 0.10686996066942811 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-32/adapters_64_slots_64_rate_0.4-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-32/adapters_64_slots_64_rate_0.4-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 1080, 4320, 4320, 33, 4320, 33, 1080, 33, 4320, 1080, 4320, 33, 1080, 4320, 4320, 4320, 33, 4320, 1080, 1080, 33, 33, 33, 4320, 33, 33, 33, 4320, 1080, 33, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 33, 1080, 1080, 4320, 4320, 1080, 4320, 33, 4320, 1080, 1080, 1080, 4320, 1080, 33, 33, 1080, 1080, 33, 1080, 33, 33, 33, 4320, 1080]
Prompts retrieved: 118413 . Total input tokens: 26410766 . Total output tokens: 23719308
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 3.115134781692177,
    "estimated_duration": 3599.7993615694036,
    "input_throughput": 2743.3712293605563,
    "output_throughput": 2414.602350562814,
    "total_throughput": 5157.97357992337,
    "itl": 31.08753391485725,
    "ttft": 8208.717271838621,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21469426140189143,
    "arrivals": 39719,
    "finished_requests": 39629,
    "scheduler_time": 14.450152057920635
}
#Debug simulation 
Total elapsed time: 3.1153136868961155. Arrivals time: 0.11684985272586346 Scheduler time: 2.6768017117865384 Scheduler overhead time: 0.11023105029016733 Adapter cache time: 0.05099721485748887 Engine time: 0.10775357764214277 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-8/adapters_64_slots_64_rate_0.4-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-8/adapters_64_slots_64_rate_0.4-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 4320, 4320, 270, 4320, 270, 540, 270, 4320, 540, 4320, 270, 540, 4320, 4320, 4320, 270, 4320, 540, 540, 270, 270, 270, 4320, 270, 270, 270, 4320, 540, 270, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 270, 540, 540, 4320, 4320, 540, 4320, 270, 4320, 540, 540, 540, 4320, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 4320, 540]
Prompts retrieved: 112050 . Total input tokens: 24972799 . Total output tokens: 22423910
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 2.981202006340027,
    "estimated_duration": 3600.015490466064,
    "input_throughput": 2585.938595168319,
    "output_throughput": 2293.264021186529,
    "total_throughput": 4879.202616354848,
    "itl": 30.003364454264574,
    "ttft": 9336.55061687691,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19587121561169607,
    "arrivals": 37601,
    "finished_requests": 37504,
    "scheduler_time": 11.908884250494248
}
#Debug simulation 
Total elapsed time: 2.9813299900852144. Arrivals time: 0.11028915690258145 Scheduler time: 2.5261566736735404 Scheduler overhead time: 0.12148859305307269 Adapter cache time: 0.055387831293046474 Engine time: 0.11293061869218946 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-16/adapters_64_slots_64_rate_0.4-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-16/adapters_64_slots_64_rate_0.4-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 4320, 4320, 270, 4320, 270, 540, 270, 4320, 540, 4320, 270, 540, 4320, 4320, 4320, 270, 4320, 540, 540, 270, 270, 270, 4320, 270, 270, 270, 4320, 540, 270, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 270, 540, 540, 4320, 4320, 540, 4320, 270, 4320, 540, 540, 540, 4320, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 4320, 540]
Prompts retrieved: 112050 . Total input tokens: 24972799 . Total output tokens: 22423910
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 2.954768572933972,
    "estimated_duration": 3600.0080215028115,
    "input_throughput": 2585.943960234237,
    "output_throughput": 2293.2687790383447,
    "total_throughput": 4879.2127392725815,
    "itl": 30.003472917005112,
    "ttft": 9241.123977739719,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2089328175666742,
    "arrivals": 37601,
    "finished_requests": 37504,
    "scheduler_time": 11.908941711792947
}
#Debug simulation 
Total elapsed time: 2.9548684181645513. Arrivals time: 0.11067505134269595 Scheduler time: 2.5160776218399405 Scheduler overhead time: 0.11252187751233578 Adapter cache time: 0.05380622111260891 Engine time: 0.1079969722777605 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-32/adapters_64_slots_64_rate_0.4-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-32/adapters_64_slots_64_rate_0.4-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 4320, 4320, 270, 4320, 270, 540, 270, 4320, 540, 4320, 270, 540, 4320, 4320, 4320, 270, 4320, 540, 540, 270, 270, 270, 4320, 270, 270, 270, 4320, 540, 270, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 270, 540, 540, 4320, 4320, 540, 4320, 270, 4320, 540, 540, 540, 4320, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 4320, 540]
Prompts retrieved: 112050 . Total input tokens: 24972799 . Total output tokens: 22423910
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 2.9673706968314946,
    "estimated_duration": 3600.0080163157722,
    "input_throughput": 2585.943963960171,
    "output_throughput": 2293.2687823425804,
    "total_throughput": 4879.212746302752,
    "itl": 30.003473577165202,
    "ttft": 9241.123791051852,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20928684858605254,
    "arrivals": 37601,
    "finished_requests": 37504,
    "scheduler_time": 11.908937666984903
}
#Debug simulation 
Total elapsed time: 2.9674697150476277. Arrivals time: 0.11039065383374691 Scheduler time: 2.529544312041253 Scheduler overhead time: 0.1116414531134069 Adapter cache time: 0.05428869230672717 Engine time: 0.10801427159458399 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-16/adapters_64_slots_64_rate_0.4-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-16/adapters_64_slots_64_rate_0.4-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 4320, 4320, 270, 4320, 270, 540, 270, 4320, 540, 4320, 270, 540, 4320, 4320, 4320, 270, 4320, 540, 540, 270, 270, 270, 4320, 270, 270, 270, 4320, 540, 270, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 270, 540, 540, 4320, 4320, 540, 4320, 270, 4320, 540, 540, 540, 4320, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 4320, 540]
Prompts retrieved: 112050 . Total input tokens: 24972799 . Total output tokens: 22423910
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 2.981949524022639,
    "estimated_duration": 3600.001743138937,
    "input_throughput": 2585.9484700923704,
    "output_throughput": 2293.2727784741464,
    "total_throughput": 4879.221248566517,
    "itl": 30.0034836532436,
    "ttft": 9241.017599285029,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20035231587942698,
    "arrivals": 37601,
    "finished_requests": 37504,
    "scheduler_time": 11.90889721890434
}
#Debug simulation 
Total elapsed time: 2.982050728984177. Arrivals time: 0.11237142514437437 Scheduler time: 2.5378886605612934 Scheduler overhead time: 0.11197520606219769 Adapter cache time: 0.0540246581658721 Engine time: 0.11196227697655559 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-32/adapters_64_slots_64_rate_0.4-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-32/adapters_64_slots_64_rate_0.4-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 4320, 4320, 270, 4320, 270, 540, 270, 4320, 540, 4320, 270, 540, 4320, 4320, 4320, 270, 4320, 540, 540, 270, 270, 270, 4320, 270, 270, 270, 4320, 540, 270, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 270, 540, 540, 4320, 4320, 540, 4320, 270, 4320, 540, 540, 540, 4320, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 4320, 540]
Prompts retrieved: 112050 . Total input tokens: 24972799 . Total output tokens: 22423910
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 2.988252412993461,
    "estimated_duration": 3600.0170852871006,
    "input_throughput": 2585.937449587847,
    "output_throughput": 2293.2630052619884,
    "total_throughput": 4879.200454849835,
    "itl": 30.00351375934962,
    "ttft": 9336.510341545762,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21192767810076454,
    "arrivals": 37601,
    "finished_requests": 37504,
    "scheduler_time": 11.909053298445947
}
#Debug simulation 
Total elapsed time: 2.9883533120155334. Arrivals time: 0.11299212602898479 Scheduler time: 2.5439483602531254 Scheduler overhead time: 0.11134151089936495 Adapter cache time: 0.05384659906849265 Engine time: 0.11235060961917043 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-16/adapters_64_slots_64_rate_0.4-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-16/adapters_64_slots_64_rate_0.4-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 4320, 4320, 270, 4320, 270, 540, 270, 4320, 540, 4320, 270, 540, 4320, 4320, 4320, 270, 4320, 540, 540, 270, 270, 270, 4320, 270, 270, 270, 4320, 540, 270, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 270, 540, 540, 4320, 4320, 540, 4320, 270, 4320, 540, 540, 540, 4320, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 4320, 540]
Prompts retrieved: 112050 . Total input tokens: 24972799 . Total output tokens: 22423910
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 2.978705076035112,
    "estimated_duration": 3600.015408885662,
    "input_throughput": 2585.9386537685987,
    "output_throughput": 2293.2640731544734,
    "total_throughput": 4879.202726923072,
    "itl": 30.00340707818761,
    "ttft": 9336.546345654466,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19136321887373942,
    "arrivals": 37601,
    "finished_requests": 37504,
    "scheduler_time": 11.908893174096344
}
#Debug simulation 
Total elapsed time: 2.978836033027619. Arrivals time: 0.11181376362219453 Scheduler time: 2.539545970503241 Scheduler overhead time: 0.11186554236337543 Adapter cache time: 0.05414420645684004 Engine time: 0.1078516524285078 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-32/adapters_64_slots_64_rate_0.4-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-32/adapters_64_slots_64_rate_0.4-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 4320, 4320, 270, 4320, 270, 540, 270, 4320, 540, 4320, 270, 540, 4320, 4320, 4320, 270, 4320, 540, 540, 270, 270, 270, 4320, 270, 270, 270, 4320, 540, 270, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 270, 540, 540, 4320, 4320, 540, 4320, 270, 4320, 540, 540, 540, 4320, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 4320, 540]
Prompts retrieved: 112050 . Total input tokens: 24972799 . Total output tokens: 22423910
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 2.977699853014201,
    "estimated_duration": 3600.0170876871452,
    "input_throughput": 2585.937447863865,
    "output_throughput": 2293.263003733125,
    "total_throughput": 4879.20045159699,
    "itl": 30.00354898494285,
    "ttft": 9336.51471109738,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21469426140189143,
    "arrivals": 37601,
    "finished_requests": 37504,
    "scheduler_time": 11.909037119213778
}
#Debug simulation 
Total elapsed time: 2.9777973531745374. Arrivals time: 0.11048560217022896 Scheduler time: 2.5375858857296407 Scheduler overhead time: 0.11160420160740614 Adapter cache time: 0.05413736775517464 Engine time: 0.11015366669744253 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-8/adapters_64_slots_64_rate_0.4-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-8/adapters_64_slots_64_rate_0.4-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 4320, 4320, 135, 4320, 135, 540, 135, 4320, 540, 4320, 135, 540, 4320, 4320, 4320, 135, 4320, 540, 540, 135, 135, 135, 4320, 135, 135, 135, 4320, 540, 135, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 135, 540, 540, 4320, 4320, 540, 4320, 135, 4320, 540, 540, 540, 4320, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 4320, 540]
Prompts retrieved: 109215 . Total input tokens: 24374214 . Total output tokens: 21824796
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 2.929653662722558,
    "estimated_duration": 3599.8394130739325,
    "input_throughput": 2523.977032698096,
    "output_throughput": 2253.777479777088,
    "total_throughput": 4777.754512475184,
    "itl": 29.231367591693704,
    "ttft": 7813.199614812769,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19587121561169607,
    "arrivals": 36626,
    "finished_requests": 36547,
    "scheduler_time": 10.766029003204814
}
#Debug simulation 
Total elapsed time: 2.929784331936389. Arrivals time: 0.10999854700639844 Scheduler time: 2.485775562468916 Scheduler overhead time: 0.11417758325114846 Adapter cache time: 0.05098053580150008 Engine time: 0.11382865812629461 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-16/adapters_64_slots_64_rate_0.4-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-16/adapters_64_slots_64_rate_0.4-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 4320, 4320, 135, 4320, 135, 540, 135, 4320, 540, 4320, 135, 540, 4320, 4320, 4320, 135, 4320, 540, 540, 135, 135, 135, 4320, 135, 135, 135, 4320, 540, 135, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 135, 540, 540, 4320, 4320, 540, 4320, 135, 4320, 540, 540, 540, 4320, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 4320, 540]
Prompts retrieved: 109215 . Total input tokens: 24374214 . Total output tokens: 21824796
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 2.9157812879420817,
    "estimated_duration": 3599.863058980704,
    "input_throughput": 2524.155461228256,
    "output_throughput": 2253.8346228918285,
    "total_throughput": 4777.990084120085,
    "itl": 29.231518357468083,
    "ttft": 7714.91801007622,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2089328175666742,
    "arrivals": 36626,
    "finished_requests": 36548,
    "scheduler_time": 10.766212687538633
}
#Debug simulation 
Total elapsed time: 2.9158848272636533. Arrivals time: 0.10988876409828663 Scheduler time: 2.476145809981972 Scheduler overhead time: 0.11312206787988544 Adapter cache time: 0.05108166392892599 Engine time: 0.11100950976833701 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-32/adapters_64_slots_64_rate_0.4-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-32/adapters_64_slots_64_rate_0.4-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 4320, 4320, 135, 4320, 135, 540, 135, 4320, 540, 4320, 135, 540, 4320, 4320, 4320, 135, 4320, 540, 540, 135, 135, 135, 4320, 135, 135, 135, 4320, 540, 135, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 135, 540, 540, 4320, 4320, 540, 4320, 135, 4320, 540, 540, 540, 4320, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 4320, 540]
Prompts retrieved: 109215 . Total input tokens: 24374214 . Total output tokens: 21824796
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 2.944533891044557,
    "estimated_duration": 3599.839210905558,
    "input_throughput": 2523.977174445631,
    "output_throughput": 2253.7776063501105,
    "total_throughput": 4777.754780795742,
    "itl": 29.231533229380442,
    "ttft": 7813.166094024263,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20928684858605257,
    "arrivals": 36626,
    "finished_requests": 36547,
    "scheduler_time": 10.766180329074361
}
#Debug simulation 
Total elapsed time: 2.9446855853311718. Arrivals time: 0.10898956516757607 Scheduler time: 2.497411537449807 Scheduler overhead time: 0.11387252248823643 Adapter cache time: 0.05252123577520251 Engine time: 0.11345352046191692 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-16/adapters_64_slots_64_rate_0.4-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-16/adapters_64_slots_64_rate_0.4-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 4320, 4320, 135, 4320, 135, 540, 135, 4320, 540, 4320, 135, 540, 4320, 4320, 4320, 135, 4320, 540, 540, 135, 135, 135, 4320, 135, 135, 135, 4320, 540, 135, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 135, 540, 540, 4320, 4320, 540, 4320, 135, 4320, 540, 540, 540, 4320, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 4320, 540]
Prompts retrieved: 109215 . Total input tokens: 24374214 . Total output tokens: 21824796
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 2.93779840413481,
    "estimated_duration": 3599.8630892068313,
    "input_throughput": 2524.155440034271,
    "output_throughput": 2253.8346039675835,
    "total_throughput": 4777.990044001855,
    "itl": 29.23143468900907,
    "ttft": 7714.94209980304,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20035231587942698,
    "arrivals": 36626,
    "finished_requests": 36548,
    "scheduler_time": 10.766208642730597
}
#Debug simulation 
Total elapsed time: 2.9379148702137172. Arrivals time: 0.10860518971458077 Scheduler time: 2.493444158695638 Scheduler overhead time: 0.11443793727084994 Adapter cache time: 0.05131354555487633 Engine time: 0.11466150218620896 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-32/adapters_64_slots_64_rate_0.4-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-32/adapters_64_slots_64_rate_0.4-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 4320, 4320, 135, 4320, 135, 540, 135, 4320, 540, 4320, 135, 540, 4320, 4320, 4320, 135, 4320, 540, 540, 135, 135, 135, 4320, 135, 135, 135, 4320, 540, 135, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 135, 540, 540, 4320, 4320, 540, 4320, 135, 4320, 540, 540, 540, 4320, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 4320, 540]
Prompts retrieved: 109215 . Total input tokens: 24374214 . Total output tokens: 21824796
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 2.9337017610669136,
    "estimated_duration": 3599.839285816072,
    "input_throughput": 2523.9771219231675,
    "output_throughput": 2253.7775594503396,
    "total_throughput": 4777.754681373507,
    "itl": 29.231566659824434,
    "ttft": 7813.217506286159,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21192767810076457,
    "arrivals": 36626,
    "finished_requests": 36547,
    "scheduler_time": 10.766170571486256
}
#Debug simulation 
Total elapsed time: 2.9338039881549776. Arrivals time: 0.10945087065920234 Scheduler time: 2.4797974727116525 Scheduler overhead time: 0.1227303915657103 Adapter cache time: 0.05180452857166529 Engine time: 0.11172257782891393 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-16/adapters_64_slots_64_rate_0.4-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-16/adapters_64_slots_64_rate_0.4-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 4320, 4320, 135, 4320, 135, 540, 135, 4320, 540, 4320, 135, 540, 4320, 4320, 4320, 135, 4320, 540, 540, 135, 135, 135, 4320, 135, 135, 135, 4320, 540, 135, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 135, 540, 540, 4320, 4320, 540, 4320, 135, 4320, 540, 540, 540, 4320, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 4320, 540]
Prompts retrieved: 109215 . Total input tokens: 24374214 . Total output tokens: 21824796
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 2.9253756259568036,
    "estimated_duration": 3599.839269584584,
    "input_throughput": 2523.9771333036488,
    "output_throughput": 2253.7775696125054,
    "total_throughput": 4777.754702916154,
    "itl": 29.231385227461285,
    "ttft": 7813.24030871938,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19136321887373942,
    "arrivals": 36626,
    "finished_requests": 36547,
    "scheduler_time": 10.766021747574731
}
#Debug simulation 
Total elapsed time: 2.925476159900427. Arrivals time: 0.10893790191039443 Scheduler time: 2.4822863745503128 Scheduler overhead time: 0.11507890513166785 Adapter cache time: 0.051307125482708216 Engine time: 0.11270077340304852 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-32/adapters_64_slots_64_rate_0.4-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-32/adapters_64_slots_64_rate_0.4-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 4320, 4320, 135, 4320, 135, 540, 135, 4320, 540, 4320, 135, 540, 4320, 4320, 4320, 135, 4320, 540, 540, 135, 135, 135, 4320, 135, 135, 135, 4320, 540, 135, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 135, 540, 540, 4320, 4320, 540, 4320, 135, 4320, 540, 540, 540, 4320, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 4320, 540]
Prompts retrieved: 109215 . Total input tokens: 24374214 . Total output tokens: 21824796
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 2.939325180836022,
    "estimated_duration": 3599.839202234539,
    "input_throughput": 2523.9771805251953,
    "output_throughput": 2253.777611778839,
    "total_throughput": 4777.754792304035,
    "itl": 29.231593287309483,
    "ttft": 7813.23220482868,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21469426140189146,
    "arrivals": 36626,
    "finished_requests": 36547,
    "scheduler_time": 10.76618103793837
}
#Debug simulation 
Total elapsed time: 2.9394220248796046. Arrivals time: 0.10957930609583855 Scheduler time: 2.495864267461002 Scheduler overhead time: 0.11349470820277929 Adapter cache time: 0.0511166425421834 Engine time: 0.11414170218631625 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-8/adapters_64_slots_64_rate_0.4-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-8/adapters_64_slots_64_rate_0.4-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 4320, 4320, 66, 4320, 66, 540, 66, 4320, 540, 4320, 66, 540, 4320, 4320, 4320, 66, 4320, 540, 540, 66, 66, 66, 4320, 66, 66, 66, 4320, 540, 66, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 66, 540, 540, 4320, 4320, 540, 4320, 66, 4320, 540, 540, 540, 4320, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 4320, 540]
Prompts retrieved: 107766 . Total input tokens: 24055828 . Total output tokens: 21538374
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 2.909573275130242,
    "estimated_duration": 3599.9228444789505,
    "input_throughput": 2477.1119785737237,
    "output_throughput": 2191.1575166388607,
    "total_throughput": 4668.269495212584,
    "itl": 28.745541772026144,
    "ttft": 6619.994778243779,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19587121561169607,
    "arrivals": 36150,
    "finished_requests": 36084,
    "scheduler_time": 9.417613897067717
}
#Debug simulation 
Total elapsed time: 2.909671534784138. Arrivals time: 0.10555400419980288 Scheduler time: 2.4666432794183493 Scheduler overhead time: 0.11675977008417249 Adapter cache time: 0.04971532570198178 Engine time: 0.11491996515542269 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-16/adapters_64_slots_64_rate_0.4-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-16/adapters_64_slots_64_rate_0.4-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 4320, 4320, 66, 4320, 66, 540, 66, 4320, 540, 4320, 66, 540, 4320, 4320, 4320, 66, 4320, 540, 540, 66, 66, 66, 4320, 66, 66, 66, 4320, 540, 66, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 66, 540, 540, 4320, 4320, 540, 4320, 66, 4320, 540, 540, 540, 4320, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 4320, 540]
Prompts retrieved: 107766 . Total input tokens: 24055828 . Total output tokens: 21538374
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 2.903483791742474,
    "estimated_duration": 3599.917659435449,
    "input_throughput": 2477.1155464145972,
    "output_throughput": 2191.160672613001,
    "total_throughput": 4668.276219027599,
    "itl": 28.751523720646478,
    "ttft": 6620.05330975921,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2089328175666742,
    "arrivals": 36150,
    "finished_requests": 36084,
    "scheduler_time": 9.422919392611739
}
#Debug simulation 
Total elapsed time: 2.9035909208469093. Arrivals time: 0.10862798755988479 Scheduler time: 2.457567324396223 Scheduler overhead time: 0.11673155287280679 Adapter cache time: 0.04948900267481804 Engine time: 0.11504784319549799 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-32/adapters_64_slots_64_rate_0.4-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-32/adapters_64_slots_64_rate_0.4-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 4320, 4320, 66, 4320, 66, 540, 66, 4320, 540, 4320, 66, 540, 4320, 4320, 4320, 66, 4320, 540, 540, 66, 66, 66, 4320, 66, 66, 66, 4320, 540, 66, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 66, 540, 540, 4320, 4320, 540, 4320, 66, 4320, 540, 540, 540, 4320, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 4320, 540]
Prompts retrieved: 107766 . Total input tokens: 24055828 . Total output tokens: 21538374
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 2.868404865730554,
    "estimated_duration": 3599.916882164126,
    "input_throughput": 2477.116081257745,
    "output_throughput": 2191.1611457145787,
    "total_throughput": 4668.277226972324,
    "itl": 28.75154202487714,
    "ttft": 6620.0426554816795,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2092868485860526,
    "arrivals": 36150,
    "finished_requests": 36084,
    "scheduler_time": 9.422883823325385
}
#Debug simulation 
Total elapsed time: 2.868533733766526. Arrivals time: 0.10995585937052965 Scheduler time: 2.4188004569150507 Scheduler overhead time: 0.11773119308054447 Adapter cache time: 0.0501222163438797 Engine time: 0.11587655125185847 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-16/adapters_64_slots_64_rate_0.4-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-16/adapters_64_slots_64_rate_0.4-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 4320, 4320, 66, 4320, 66, 540, 66, 4320, 540, 4320, 66, 540, 4320, 4320, 4320, 66, 4320, 540, 540, 66, 66, 66, 4320, 66, 66, 66, 4320, 540, 66, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 66, 540, 540, 4320, 4320, 540, 4320, 66, 4320, 540, 540, 540, 4320, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 4320, 540]
Prompts retrieved: 107766 . Total input tokens: 24055828 . Total output tokens: 21538374
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 2.883414078038186,
    "estimated_duration": 3599.92318841993,
    "input_throughput": 2477.111741907474,
    "output_throughput": 2191.1573072930432,
    "total_throughput": 4668.269049200517,
    "itl": 28.74558701018651,
    "ttft": 6619.968459153273,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.200352315879427,
    "arrivals": 36150,
    "finished_requests": 36084,
    "scheduler_time": 9.41760092865755
}
#Debug simulation 
Total elapsed time: 2.8835235838778317. Arrivals time: 0.11079887114465237 Scheduler time: 2.437527507543564 Scheduler overhead time: 0.11639828933402896 Adapter cache time: 0.04982261126860976 Engine time: 0.1133033037185669 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-32/adapters_64_slots_64_rate_0.4-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-32/adapters_64_slots_64_rate_0.4-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 4320, 4320, 66, 4320, 66, 540, 66, 4320, 540, 4320, 66, 540, 4320, 4320, 4320, 66, 4320, 540, 540, 66, 66, 66, 4320, 66, 66, 66, 4320, 540, 66, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 66, 540, 540, 4320, 4320, 540, 4320, 66, 4320, 540, 540, 540, 4320, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 4320, 540]
Prompts retrieved: 107766 . Total input tokens: 24055828 . Total output tokens: 21538374
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 2.856494782026857,
    "estimated_duration": 3599.9175875729334,
    "input_throughput": 2477.115595863439,
    "output_throughput": 2191.1607163535355,
    "total_throughput": 4668.2763122169745,
    "itl": 28.75150779639681,
    "ttft": 6619.965984850831,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2119276781007646,
    "arrivals": 36150,
    "finished_requests": 36084,
    "scheduler_time": 9.422932361021898
}
#Debug simulation 
Total elapsed time: 2.856592718977481. Arrivals time: 0.10595536371693015 Scheduler time: 2.415554211009294 Scheduler overhead time: 0.11502131074666977 Adapter cache time: 0.04949747631326318 Engine time: 0.1149668749421835 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-16/adapters_64_slots_64_rate_0.4-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-16/adapters_64_slots_64_rate_0.4-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 4320, 4320, 66, 4320, 66, 540, 66, 4320, 540, 4320, 66, 540, 4320, 4320, 4320, 66, 4320, 540, 540, 66, 66, 66, 4320, 66, 66, 66, 4320, 540, 66, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 66, 540, 540, 4320, 4320, 540, 4320, 66, 4320, 540, 540, 540, 4320, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 4320, 540]
Prompts retrieved: 107766 . Total input tokens: 24055828 . Total output tokens: 21538374
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 2.891937504056841,
    "estimated_duration": 3599.922021349388,
    "input_throughput": 2477.112544970464,
    "output_throughput": 2191.158017651526,
    "total_throughput": 4668.27056262199,
    "itl": 28.745500338922014,
    "ttft": 6620.042605200897,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19136321887373942,
    "arrivals": 36150,
    "finished_requests": 36084,
    "scheduler_time": 9.417641501859949
}
#Debug simulation 
Total elapsed time: 2.89203718630597. Arrivals time: 0.1069945590570569 Scheduler time: 2.446341454051435 Scheduler overhead time: 0.11598163889721036 Adapter cache time: 0.04999986523762345 Engine time: 0.11692231893539429 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-32/adapters_64_slots_64_rate_0.4-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-32/adapters_64_slots_64_rate_0.4-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 4320, 4320, 66, 4320, 66, 540, 66, 4320, 540, 4320, 66, 540, 4320, 4320, 4320, 66, 4320, 540, 540, 66, 66, 66, 4320, 66, 66, 66, 4320, 540, 66, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 66, 540, 540, 4320, 4320, 540, 4320, 66, 4320, 540, 540, 540, 4320, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 4320, 540]
Prompts retrieved: 107766 . Total input tokens: 24055828 . Total output tokens: 21538374
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 2.8760694921948016,
    "estimated_duration": 3599.928045902653,
    "input_throughput": 2477.1083994719206,
    "output_throughput": 2191.154350703737,
    "total_throughput": 4668.262750175658,
    "itl": 28.751551775554866,
    "ttft": 6620.079240603498,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21469426140189146,
    "arrivals": 36150,
    "finished_requests": 36084,
    "scheduler_time": 9.423005042444668
}
#Debug simulation 
Total elapsed time: 2.8761705681681633. Arrivals time: 0.10727640753611922 Scheduler time: 2.4337983042933047 Scheduler overhead time: 0.11621394846588373 Adapter cache time: 0.049784481059759855 Engine time: 0.11354536889120936 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-8/adapters_64_slots_64_rate_0.4-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-8/adapters_64_slots_64_rate_0.4-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 4320, 4320, 33, 4320, 33, 540, 33, 4320, 540, 4320, 33, 540, 4320, 4320, 4320, 33, 4320, 540, 540, 33, 33, 33, 4320, 33, 33, 33, 4320, 540, 33, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 33, 540, 540, 4320, 4320, 540, 4320, 33, 4320, 540, 540, 540, 4320, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 4320, 540]
Prompts retrieved: 107073 . Total input tokens: 23891210 . Total output tokens: 21397833
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 2.8853617580607533,
    "estimated_duration": 3599.9479339899813,
    "input_throughput": 2476.006365492287,
    "output_throughput": 2174.835898618802,
    "total_throughput": 4650.842264111088,
    "itl": 28.48294417480395,
    "ttft": 7762.348088949276,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19587121561169607,
    "arrivals": 35929,
    "finished_requests": 35852,
    "scheduler_time": 9.064992954146108
}
#Debug simulation 
Total elapsed time: 2.885459490120411. Arrivals time: 0.10403446946293116 Scheduler time: 2.442199590150267 Scheduler overhead time: 0.11694536823779345 Adapter cache time: 0.049592725932598114 Engine time: 0.11641946667805314 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-16/adapters_64_slots_64_rate_0.4-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-16/adapters_64_slots_64_rate_0.4-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 4320, 4320, 33, 4320, 33, 540, 33, 4320, 540, 4320, 33, 540, 4320, 4320, 4320, 33, 4320, 540, 540, 33, 33, 33, 4320, 33, 33, 33, 4320, 540, 33, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 33, 540, 540, 4320, 4320, 540, 4320, 33, 4320, 540, 540, 540, 4320, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 4320, 540]
Prompts retrieved: 107073 . Total input tokens: 23891210 . Total output tokens: 21397833
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 2.846957270987332,
    "estimated_duration": 3599.947876259206,
    "input_throughput": 2476.006405198908,
    "output_throughput": 2174.8359334956854,
    "total_throughput": 4650.842338694593,
    "itl": 28.483188286583015,
    "ttft": 7762.2724073162935,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20893281756667417,
    "arrivals": 35929,
    "finished_requests": 35852,
    "scheduler_time": 9.0651504514157
}
#Debug simulation 
Total elapsed time: 2.847109089139849. Arrivals time: 0.10238884389400482 Scheduler time: 2.408782407641411 Scheduler overhead time: 0.11581116123124957 Adapter cache time: 0.04796058777719736 Engine time: 0.11605890979990363 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-32/adapters_64_slots_64_rate_0.4-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-32/adapters_64_slots_64_rate_0.4-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 4320, 4320, 33, 4320, 33, 540, 33, 4320, 540, 4320, 33, 540, 4320, 4320, 4320, 33, 4320, 540, 540, 33, 33, 33, 4320, 33, 33, 33, 4320, 540, 33, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 33, 540, 540, 4320, 4320, 540, 4320, 33, 4320, 540, 540, 540, 4320, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 4320, 540]
Prompts retrieved: 107073 . Total input tokens: 23891210 . Total output tokens: 21397833
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 2.8577209669165313,
    "estimated_duration": 3599.9477845008932,
    "input_throughput": 2476.006468309315,
    "output_throughput": 2174.8359889296216,
    "total_throughput": 4650.842457238937,
    "itl": 28.48320450558617,
    "ttft": 7762.273626421903,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20928684858605254,
    "arrivals": 35929,
    "finished_requests": 35852,
    "scheduler_time": 9.065154496223741
}
#Debug simulation 
Total elapsed time: 2.857850768137723. Arrivals time: 0.10678322287276387 Scheduler time: 2.415216735098511 Scheduler overhead time: 0.11679810239002109 Adapter cache time: 0.048207392916083336 Engine time: 0.11492012348026037 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-16/adapters_64_slots_64_rate_0.4-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-16/adapters_64_slots_64_rate_0.4-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 4320, 4320, 33, 4320, 33, 540, 33, 4320, 540, 4320, 33, 540, 4320, 4320, 4320, 33, 4320, 540, 540, 33, 33, 33, 4320, 33, 33, 33, 4320, 540, 33, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 33, 540, 540, 4320, 4320, 540, 4320, 33, 4320, 540, 540, 540, 4320, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 4320, 540]
Prompts retrieved: 107073 . Total input tokens: 23891210 . Total output tokens: 21397833
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 2.871033084113151,
    "estimated_duration": 3599.9355405146043,
    "input_throughput": 2476.0148896237824,
    "output_throughput": 2174.843385912631,
    "total_throughput": 4650.858275536414,
    "itl": 28.48317313482293,
    "ttft": 7762.305941915551,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20035231587942698,
    "arrivals": 35929,
    "finished_requests": 35852,
    "scheduler_time": 9.065122971745442
}
#Debug simulation 
Total elapsed time: 2.8711324743926525. Arrivals time: 0.10786929214373231 Scheduler time: 2.4261517045088112 Scheduler overhead time: 0.11614330671727657 Adapter cache time: 0.04843690153211355 Engine time: 0.11648130929097533 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-32/adapters_64_slots_64_rate_0.4-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-32/adapters_64_slots_64_rate_0.4-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 4320, 4320, 33, 4320, 33, 540, 33, 4320, 540, 4320, 33, 540, 4320, 4320, 4320, 33, 4320, 540, 540, 33, 33, 33, 4320, 33, 33, 33, 4320, 540, 33, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 33, 540, 540, 4320, 4320, 540, 4320, 33, 4320, 540, 540, 540, 4320, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 4320, 540]
Prompts retrieved: 107073 . Total input tokens: 23891210 . Total output tokens: 21397833
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 2.919833404943347,
    "estimated_duration": 3599.9478589426144,
    "input_throughput": 2476.006417109078,
    "output_throughput": 2174.835943957155,
    "total_throughput": 4650.842361066233,
    "itl": 28.48329447216396,
    "ttft": 7762.289880645742,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21192767810076457,
    "arrivals": 35929,
    "finished_requests": 35852,
    "scheduler_time": 9.065182101016036
}
#Debug simulation 
Total elapsed time: 2.9199369652196765. Arrivals time: 0.10589071083813906 Scheduler time: 2.4752173107117414 Scheduler overhead time: 0.11645672982558608 Adapter cache time: 0.04856146778911352 Engine time: 0.11723125167191029 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-16/adapters_64_slots_64_rate_0.4-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-16/adapters_64_slots_64_rate_0.4-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 4320, 4320, 33, 4320, 33, 540, 33, 4320, 540, 4320, 33, 540, 4320, 4320, 4320, 33, 4320, 540, 540, 33, 33, 33, 4320, 33, 33, 33, 4320, 540, 33, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 33, 540, 540, 4320, 4320, 540, 4320, 33, 4320, 540, 540, 540, 4320, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 4320, 540]
Prompts retrieved: 107073 . Total input tokens: 23891210 . Total output tokens: 21397833
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 2.8512860569171607,
    "estimated_duration": 3599.94810097157,
    "input_throughput": 2476.0062506441095,
    "output_throughput": 2174.8357977402493,
    "total_throughput": 4650.842048384359,
    "itl": 28.48291202272493,
    "ttft": 7762.288945624294,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19136321887373942,
    "arrivals": 35929,
    "finished_requests": 35852,
    "scheduler_time": 9.065027564324451
}
#Debug simulation 
Total elapsed time: 2.85138969309628. Arrivals time: 0.1067265491001308 Scheduler time: 2.4097338947467506 Scheduler overhead time: 0.11664963001385331 Adapter cache time: 0.04823026852682233 Engine time: 0.11392559437081218 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-32/adapters_64_slots_64_rate_0.4-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-32/adapters_64_slots_64_rate_0.4-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 4320, 4320, 33, 4320, 33, 540, 33, 4320, 540, 4320, 33, 540, 4320, 4320, 4320, 33, 4320, 540, 540, 33, 33, 33, 4320, 33, 33, 33, 4320, 540, 33, 4320, 4320, 4320, 4320, 540, 540, 540, 4320, 33, 540, 540, 4320, 4320, 540, 4320, 33, 4320, 540, 540, 540, 4320, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 4320, 540]
Prompts retrieved: 107073 . Total input tokens: 23891210 . Total output tokens: 21397833
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 2.894415096845478,
    "estimated_duration": 3599.947872652927,
    "input_throughput": 2476.006407679269,
    "output_throughput": 2174.8359356743463,
    "total_throughput": 4650.842343353615,
    "itl": 28.483253908978416,
    "ttft": 7762.29248901707,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21469426140189143,
    "arrivals": 35929,
    "finished_requests": 35852,
    "scheduler_time": 9.065163419825826
}
#Debug simulation 
Total elapsed time: 2.8945114840753376. Arrivals time: 0.10482598980888724 Scheduler time: 2.4547397401183844 Scheduler overhead time: 0.11780274659395218 Adapter cache time: 0.04828142747282982 Engine time: 0.11241371277719736 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-8/adapters_64_slots_64_rate_0.4-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-8/adapters_64_slots_64_rate_0.4-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 4320, 4320, 135, 4320, 135, 270, 135, 4320, 270, 4320, 135, 270, 4320, 4320, 4320, 135, 4320, 270, 270, 135, 135, 135, 4320, 135, 135, 135, 4320, 270, 135, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 135, 270, 270, 4320, 4320, 270, 4320, 135, 4320, 270, 270, 270, 4320, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 4320, 270]
Prompts retrieved: 103545 . Total input tokens: 23082393 . Total output tokens: 20692227
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 2.7959911739453673,
    "estimated_duration": 3599.8910740355927,
    "input_throughput": 2374.342118751422,
    "output_throughput": 2113.051157259763,
    "total_throughput": 4487.393276011185,
    "itl": 27.72312998115744,
    "ttft": 4713.659690227713,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19587121561169607,
    "arrivals": 34705,
    "finished_requests": 34660,
    "scheduler_time": 7.52950909981936
}
#Debug simulation 
Total elapsed time: 2.79609482223168. Arrivals time: 0.1029614876024425 Scheduler time: 2.3497256245464087 Scheduler overhead time: 0.12045464105904102 Adapter cache time: 0.04640856385231018 Engine time: 0.11908671585842967 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-16/adapters_64_slots_64_rate_0.4-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-16/adapters_64_slots_64_rate_0.4-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 4320, 4320, 135, 4320, 135, 270, 135, 4320, 270, 4320, 135, 270, 4320, 4320, 4320, 135, 4320, 270, 270, 135, 135, 135, 4320, 135, 135, 135, 4320, 270, 135, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 135, 270, 270, 4320, 4320, 270, 4320, 135, 4320, 270, 270, 270, 4320, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 4320, 270]
Prompts retrieved: 103545 . Total input tokens: 23082393 . Total output tokens: 20692227
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 2.766321954317391,
    "estimated_duration": 3599.8852327674467,
    "input_throughput": 2374.3459714211845,
    "output_throughput": 2113.054585951962,
    "total_throughput": 4487.4005573731465,
    "itl": 27.723142638466975,
    "ttft": 4713.722011755088,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20893281756667417,
    "arrivals": 34705,
    "finished_requests": 34660,
    "scheduler_time": 7.529607592940359
}
#Debug simulation 
Total elapsed time: 2.7664264291524887. Arrivals time: 0.10423010122030973 Scheduler time: 2.324486542493105 Scheduler overhead time: 0.11892853071913123 Adapter cache time: 0.04610611591488123 Engine time: 0.1156611223705113 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-32/adapters_64_slots_64_rate_0.4-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-32/adapters_64_slots_64_rate_0.4-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 4320, 4320, 135, 4320, 135, 270, 135, 4320, 270, 4320, 135, 270, 4320, 4320, 4320, 135, 4320, 270, 270, 135, 135, 135, 4320, 135, 135, 135, 4320, 270, 135, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 135, 270, 270, 4320, 4320, 270, 4320, 135, 4320, 270, 270, 270, 4320, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 4320, 270]
Prompts retrieved: 103545 . Total input tokens: 23082393 . Total output tokens: 20692227
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 2.873854731209576,
    "estimated_duration": 3599.885297851035,
    "input_throughput": 2374.345928494551,
    "output_throughput": 2113.0545477493074,
    "total_throughput": 4487.400476243859,
    "itl": 27.72313223755483,
    "ttft": 4713.710873902848,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2092868485860526,
    "arrivals": 34705,
    "finished_requests": 34660,
    "scheduler_time": 7.5295995033242695
}
#Debug simulation 
Total elapsed time: 2.8739536409266293. Arrivals time: 0.10303849540650845 Scheduler time: 2.4281977736391127 Scheduler overhead time: 0.11873864941298962 Adapter cache time: 0.04681553691625595 Engine time: 0.1191092268563807 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-16/adapters_64_slots_64_rate_0.4-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-16/adapters_64_slots_64_rate_0.4-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 4320, 4320, 135, 4320, 135, 270, 135, 4320, 270, 4320, 135, 270, 4320, 4320, 4320, 135, 4320, 270, 270, 135, 135, 135, 4320, 135, 135, 135, 4320, 270, 135, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 135, 270, 270, 4320, 4320, 270, 4320, 135, 4320, 270, 270, 270, 4320, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 4320, 270]
Prompts retrieved: 103545 . Total input tokens: 23082393 . Total output tokens: 20692227
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 2.8085317821241915,
    "estimated_duration": 3599.88229163843,
    "input_throughput": 2374.347911278454,
    "output_throughput": 2113.0563123323413,
    "total_throughput": 4487.404223610795,
    "itl": 27.723397997938502,
    "ttft": 4713.680736191879,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20035231587942698,
    "arrivals": 34705,
    "finished_requests": 34660,
    "scheduler_time": 7.529702291497327
}
#Debug simulation 
Total elapsed time: 2.8086361601017416. Arrivals time: 0.10461706388741732 Scheduler time: 2.362128520384431 Scheduler overhead time: 0.11884001176804304 Adapter cache time: 0.04605958005413413 Engine time: 0.11929353419691324 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-32/adapters_64_slots_64_rate_0.4-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-32/adapters_64_slots_64_rate_0.4-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 4320, 4320, 135, 4320, 135, 270, 135, 4320, 270, 4320, 135, 270, 4320, 4320, 4320, 135, 4320, 270, 270, 135, 135, 135, 4320, 135, 135, 135, 4320, 270, 135, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 135, 270, 270, 4320, 4320, 270, 4320, 135, 4320, 270, 270, 270, 4320, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 4320, 270]
Prompts retrieved: 103545 . Total input tokens: 23082393 . Total output tokens: 20692227
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 2.7790675908327103,
    "estimated_duration": 3599.8910351846553,
    "input_throughput": 2374.3421443759244,
    "output_throughput": 2113.051180064347,
    "total_throughput": 4487.3933244402715,
    "itl": 27.723305935169495,
    "ttft": 4713.69872020765,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2119276781007646,
    "arrivals": 34705,
    "finished_requests": 34660,
    "scheduler_time": 7.529601880160302
}
#Debug simulation 
Total elapsed time: 2.77916307374835. Arrivals time: 0.10251481831073761 Scheduler time: 2.3365234616212547 Scheduler overhead time: 0.11938065523281693 Adapter cache time: 0.04630914470180869 Engine time: 0.11717894161120057 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-16/adapters_64_slots_64_rate_0.4-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-16/adapters_64_slots_64_rate_0.4-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 4320, 4320, 135, 4320, 135, 270, 135, 4320, 270, 4320, 135, 270, 4320, 4320, 4320, 135, 4320, 270, 270, 135, 135, 135, 4320, 135, 135, 135, 4320, 270, 135, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 135, 270, 270, 4320, 4320, 270, 4320, 135, 4320, 270, 270, 270, 4320, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 4320, 270]
Prompts retrieved: 103545 . Total input tokens: 23082393 . Total output tokens: 20692227
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 2.798731575720012,
    "estimated_duration": 3599.885228228774,
    "input_throughput": 2374.3459744147185,
    "output_throughput": 2113.054588616065,
    "total_throughput": 4487.400563030783,
    "itl": 27.72298167879133,
    "ttft": 4713.739681507283,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19136321887373942,
    "arrivals": 34705,
    "finished_requests": 34660,
    "scheduler_time": 7.529462813836882
}
#Debug simulation 
Total elapsed time: 2.798831682652235. Arrivals time: 0.10394909093156457 Scheduler time: 2.354256776627153 Scheduler overhead time: 0.11998997163027525 Adapter cache time: 0.04616405535489321 Engine time: 0.1168217146769166 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-32/adapters_64_slots_64_rate_0.4-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-32/adapters_64_slots_64_rate_0.4-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 4320, 4320, 135, 4320, 135, 270, 135, 4320, 270, 4320, 135, 270, 4320, 4320, 4320, 135, 4320, 270, 270, 135, 135, 135, 4320, 135, 135, 135, 4320, 270, 135, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 135, 270, 270, 4320, 4320, 270, 4320, 135, 4320, 270, 270, 270, 4320, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 4320, 270]
Prompts retrieved: 103545 . Total input tokens: 23082393 . Total output tokens: 20692227
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 2.8005083790048957,
    "estimated_duration": 3599.89574126302,
    "input_throughput": 2374.3390404415327,
    "output_throughput": 2113.048417710891,
    "total_throughput": 4487.387458152424,
    "itl": 27.723443497198854,
    "ttft": 4713.711435891032,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21469426140189146,
    "arrivals": 34705,
    "finished_requests": 34660,
    "scheduler_time": 7.5297679675340135
}
#Debug simulation 
Total elapsed time: 2.800637294072658. Arrivals time: 0.10234783729538321 Scheduler time: 2.3576916344463825 Scheduler overhead time: 0.11879945266991854 Adapter cache time: 0.046135398093611 Engine time: 0.11783991754055023 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_64_slots_64_rate_0.4-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_64_slots_64_rate_0.4-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 4320, 4320, 66, 4320, 66, 270, 66, 4320, 270, 4320, 66, 270, 4320, 4320, 4320, 66, 4320, 270, 270, 66, 66, 66, 4320, 66, 66, 66, 4320, 270, 66, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 66, 270, 270, 4320, 4320, 270, 4320, 66, 4320, 270, 270, 270, 4320, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 4320, 270]
Prompts retrieved: 102096 . Total input tokens: 22764722 . Total output tokens: 20398109
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 2.7966631059534848,
    "estimated_duration": 3599.7431595792937,
    "input_throughput": 2369.4240455190784,
    "output_throughput": 2109.876917131954,
    "total_throughput": 4479.300962651033,
    "itl": 27.445370417011226,
    "ttft": 8458.443855121743,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19587121561169607,
    "arrivals": 34232,
    "finished_requests": 34152,
    "scheduler_time": 7.255643943416025
}
#Debug simulation 
Total elapsed time: 2.7968260417692363. Arrivals time: 0.10219766991212964 Scheduler time: 2.3557837144471705 Scheduler overhead time: 0.12020442308858037 Adapter cache time: 0.044402866158634424 Engine time: 0.11622684402391315 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_64_slots_64_rate_0.4-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_64_slots_64_rate_0.4-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 4320, 4320, 66, 4320, 66, 270, 66, 4320, 270, 4320, 66, 270, 4320, 4320, 4320, 66, 4320, 270, 270, 66, 66, 66, 4320, 66, 66, 66, 4320, 270, 66, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 66, 270, 270, 4320, 4320, 270, 4320, 66, 4320, 270, 270, 270, 4320, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 4320, 270]
Prompts retrieved: 102096 . Total input tokens: 22764722 . Total output tokens: 20398109
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 2.813190266955644,
    "estimated_duration": 3599.7337768203233,
    "input_throughput": 2369.4302214576605,
    "output_throughput": 2109.882416557133,
    "total_throughput": 4479.312638014794,
    "itl": 27.445501344539135,
    "ttft": 8458.441647430145,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20893281756667417,
    "arrivals": 34232,
    "finished_requests": 34152,
    "scheduler_time": 7.25581682910393
}
#Debug simulation 
Total elapsed time: 2.8132879552431405. Arrivals time: 0.10165140824392438 Scheduler time: 2.371410508174449 Scheduler overhead time: 0.12056185072287917 Adapter cache time: 0.04485688265413046 Engine time: 0.1168457018211484 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-32/adapters_64_slots_64_rate_0.4-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-32/adapters_64_slots_64_rate_0.4-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 4320, 4320, 66, 4320, 66, 270, 66, 4320, 270, 4320, 66, 270, 4320, 4320, 4320, 66, 4320, 270, 270, 66, 66, 66, 4320, 66, 66, 66, 4320, 270, 66, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 66, 270, 270, 4320, 4320, 270, 4320, 66, 4320, 270, 270, 270, 4320, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 4320, 270]
Prompts retrieved: 102096 . Total input tokens: 22764722 . Total output tokens: 20398109
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 2.799094293732196,
    "estimated_duration": 3599.7356806273,
    "input_throughput": 2369.428968327379,
    "output_throughput": 2109.881300694964,
    "total_throughput": 4479.310269022343,
    "itl": 27.445476867840675,
    "ttft": 8458.46761966124,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20928684858605257,
    "arrivals": 34232,
    "finished_requests": 34152,
    "scheduler_time": 7.255854316606323
}
#Debug simulation 
Total elapsed time: 2.7991968169808388. Arrivals time: 0.10265245893970132 Scheduler time: 2.3552162828855217 Scheduler overhead time: 0.11969973845407367 Adapter cache time: 0.04497070983052254 Engine time: 0.11890514194965363 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_64_slots_64_rate_0.4-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_64_slots_64_rate_0.4-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 4320, 4320, 66, 4320, 66, 270, 66, 4320, 270, 4320, 66, 270, 4320, 4320, 4320, 66, 4320, 270, 270, 66, 66, 66, 4320, 66, 66, 66, 4320, 270, 66, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 66, 270, 270, 4320, 4320, 270, 4320, 66, 4320, 270, 270, 270, 4320, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 4320, 270]
Prompts retrieved: 102096 . Total input tokens: 22764722 . Total output tokens: 20398109
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 2.7801983626559377,
    "estimated_duration": 3599.7431663265224,
    "input_throughput": 2369.4240410779157,
    "output_throughput": 2109.876913177277,
    "total_throughput": 4479.300954255193,
    "itl": 27.445371840593396,
    "ttft": 8458.456962853841,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20035231587942698,
    "arrivals": 34232,
    "finished_requests": 34152,
    "scheduler_time": 7.255687602318468
}
#Debug simulation 
Total elapsed time: 2.7803169987164438. Arrivals time: 0.09891168773174286 Scheduler time: 2.342651216313243 Scheduler overhead time: 0.12019191728904843 Adapter cache time: 0.044489406514912844 Engine time: 0.11635489715263247 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-32/adapters_64_slots_64_rate_0.4-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-32/adapters_64_slots_64_rate_0.4-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 4320, 4320, 66, 4320, 66, 270, 66, 4320, 270, 4320, 66, 270, 4320, 4320, 4320, 66, 4320, 270, 270, 66, 66, 66, 4320, 66, 66, 66, 4320, 270, 66, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 66, 270, 270, 4320, 4320, 270, 4320, 66, 4320, 270, 270, 270, 4320, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 4320, 270]
Prompts retrieved: 102096 . Total input tokens: 22764722 . Total output tokens: 20398109
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 2.8144311239011586,
    "estimated_duration": 3599.73508726679,
    "input_throughput": 2369.429358891003,
    "output_throughput": 2109.88164847618,
    "total_throughput": 4479.311007367183,
    "itl": 27.445466127919982,
    "ttft": 8458.42514721716,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21192767810076454,
    "arrivals": 34232,
    "finished_requests": 34152,
    "scheduler_time": 7.255851105784305
}
#Debug simulation 
Total elapsed time: 2.814540301915258. Arrivals time: 0.10281551815569401 Scheduler time: 2.3692578468471766 Scheduler overhead time: 0.12033428251743317 Adapter cache time: 0.04486984806135297 Engine time: 0.11944724433124065 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_64_slots_64_rate_0.4-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_64_slots_64_rate_0.4-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 4320, 4320, 66, 4320, 66, 270, 66, 4320, 270, 4320, 66, 270, 4320, 4320, 4320, 66, 4320, 270, 270, 66, 66, 66, 4320, 66, 66, 66, 4320, 270, 66, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 66, 270, 270, 4320, 4320, 270, 4320, 66, 4320, 270, 270, 270, 4320, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 4320, 270]
Prompts retrieved: 102096 . Total input tokens: 22764722 . Total output tokens: 20398109
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 2.791155290789902,
    "estimated_duration": 3599.7350853625667,
    "input_throughput": 2369.4293601444074,
    "output_throughput": 2109.8816495922856,
    "total_throughput": 4479.311009736693,
    "itl": 27.445293590691783,
    "ttft": 8458.425146270245,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19136321887373942,
    "arrivals": 34232,
    "finished_requests": 34152,
    "scheduler_time": 7.255652910190283
}
#Debug simulation 
Total elapsed time: 2.7912626317702234. Arrivals time: 0.10177306365221739 Scheduler time: 2.347889657597989 Scheduler overhead time: 0.12044090358540416 Adapter cache time: 0.04452510876581073 Engine time: 0.11847835453227162 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-32/adapters_64_slots_64_rate_0.4-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-32/adapters_64_slots_64_rate_0.4-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 4320, 4320, 66, 4320, 66, 270, 66, 4320, 270, 4320, 66, 270, 4320, 4320, 4320, 66, 4320, 270, 270, 66, 66, 66, 4320, 66, 66, 66, 4320, 270, 66, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 66, 270, 270, 4320, 4320, 270, 4320, 66, 4320, 270, 270, 270, 4320, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 4320, 270]
Prompts retrieved: 102096 . Total input tokens: 22764722 . Total output tokens: 20398109
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 2.8308236147277057,
    "estimated_duration": 3599.738698178921,
    "input_throughput": 2369.4269821070384,
    "output_throughput": 2109.87953204555,
    "total_throughput": 4479.3065141525885,
    "itl": 27.445448893384167,
    "ttft": 8458.431087802599,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21469426140189143,
    "arrivals": 34232,
    "finished_requests": 34152,
    "scheduler_time": 7.255786513977633
}
#Debug simulation 
Total elapsed time: 2.8309237328357995. Arrivals time: 0.10284348018467426 Scheduler time: 2.3849566313438118 Scheduler overhead time: 0.12088937731459737 Adapter cache time: 0.044544799253344536 Engine time: 0.11975470837205648 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_64_slots_64_rate_0.4-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_64_slots_64_rate_0.4-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 4320, 4320, 33, 4320, 33, 270, 33, 4320, 270, 4320, 33, 270, 4320, 4320, 4320, 33, 4320, 270, 270, 33, 33, 33, 4320, 33, 33, 33, 4320, 270, 33, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 33, 270, 270, 4320, 4320, 270, 4320, 33, 4320, 270, 270, 270, 4320, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 4320, 270]
Prompts retrieved: 101403 . Total input tokens: 22599607 . Total output tokens: 20263556
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 2.7505739382468164,
    "estimated_duration": 3600.023431307242,
    "input_throughput": 2330.3734434177386,
    "output_throughput": 2073.2106727677083,
    "total_throughput": 4403.584116185447,
    "itl": 27.1765750065157,
    "ttft": 8516.25420096776,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19587121561169607,
    "arrivals": 33997,
    "finished_requests": 33917,
    "scheduler_time": 6.5851283948659205
}
#Debug simulation 
Total elapsed time: 2.750670748297125. Arrivals time: 0.09796865284442902 Scheduler time: 2.309659907594323 Scheduler overhead time: 0.12204207293689251 Adapter cache time: 0.04328868305310607 Engine time: 0.11949731037020683 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_64_slots_64_rate_0.4-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_64_slots_64_rate_0.4-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 4320, 4320, 33, 4320, 33, 270, 33, 4320, 270, 4320, 33, 270, 4320, 4320, 4320, 33, 4320, 270, 270, 33, 33, 33, 4320, 33, 33, 33, 4320, 270, 33, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 33, 270, 270, 4320, 4320, 270, 4320, 33, 4320, 270, 270, 270, 4320, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 4320, 270]
Prompts retrieved: 101403 . Total input tokens: 22599607 . Total output tokens: 20263556
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 2.752947609871626,
    "estimated_duration": 3600.0175945691494,
    "input_throughput": 2330.3772216713414,
    "output_throughput": 2073.214034081199,
    "total_throughput": 4403.59125575254,
    "itl": 27.17677134364964,
    "ttft": 8516.25594889512,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20893281756667417,
    "arrivals": 33997,
    "finished_requests": 33917,
    "scheduler_time": 6.585290896051585
}
#Debug simulation 
Total elapsed time: 2.753042448312044. Arrivals time: 0.09785838890820742 Scheduler time: 2.3114236970432103 Scheduler overhead time: 0.12071869010105729 Adapter cache time: 0.04350394103676081 Engine time: 0.12113809585571289 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-32/adapters_64_slots_64_rate_0.4-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-32/adapters_64_slots_64_rate_0.4-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 4320, 4320, 33, 4320, 33, 270, 33, 4320, 270, 4320, 33, 270, 4320, 4320, 4320, 33, 4320, 270, 270, 33, 33, 33, 4320, 33, 33, 33, 4320, 270, 33, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 33, 270, 270, 4320, 4320, 270, 4320, 33, 4320, 270, 270, 270, 4320, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 4320, 270]
Prompts retrieved: 101403 . Total input tokens: 22599607 . Total output tokens: 20263556
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 2.769349887035787,
    "estimated_duration": 3600.017560895048,
    "input_throughput": 2330.37724346939,
    "output_throughput": 2073.2140534737764,
    "total_throughput": 4403.5912969431665,
    "itl": 27.17677111382365,
    "ttft": 8516.224086531924,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20928684858605257,
    "arrivals": 33997,
    "finished_requests": 33917,
    "scheduler_time": 6.585276259669432
}
#Debug simulation 
Total elapsed time: 2.7694547032006085. Arrivals time: 0.10004733921959996 Scheduler time: 2.3303963667713106 Scheduler overhead time: 0.12087177624925971 Adapter cache time: 0.04317333176732063 Engine time: 0.11649828776717186 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_64_slots_64_rate_0.4-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_64_slots_64_rate_0.4-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 4320, 4320, 33, 4320, 33, 270, 33, 4320, 270, 4320, 33, 270, 4320, 4320, 4320, 33, 4320, 270, 270, 33, 33, 33, 4320, 33, 33, 33, 4320, 270, 33, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 33, 270, 270, 4320, 4320, 270, 4320, 33, 4320, 270, 270, 270, 4320, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 4320, 270]
Prompts retrieved: 101403 . Total input tokens: 22599607 . Total output tokens: 20263556
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 2.7632632311433554,
    "estimated_duration": 3600.0176217668504,
    "input_throughput": 2330.3772040656213,
    "output_throughput": 2073.214018418316,
    "total_throughput": 4403.591222483937,
    "itl": 27.196349252276637,
    "ttft": 8516.21548954035,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20035231587942698,
    "arrivals": 33997,
    "finished_requests": 33917,
    "scheduler_time": 6.600954352871311
}
#Debug simulation 
Total elapsed time: 2.7633874961175025. Arrivals time: 0.09591968497261405 Scheduler time: 2.324169995263219 Scheduler overhead time: 0.12363427691161633 Adapter cache time: 0.04328624717891216 Engine time: 0.11792682437226176 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-32/adapters_64_slots_64_rate_0.4-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-32/adapters_64_slots_64_rate_0.4-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 4320, 4320, 33, 4320, 33, 270, 33, 4320, 270, 4320, 33, 270, 4320, 4320, 4320, 33, 4320, 270, 270, 33, 33, 33, 4320, 33, 33, 33, 4320, 270, 33, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 33, 270, 270, 4320, 4320, 270, 4320, 33, 4320, 270, 270, 270, 4320, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 4320, 270]
Prompts retrieved: 101403 . Total input tokens: 22599607 . Total output tokens: 20263556
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 2.765782688744366,
    "estimated_duration": 3600.0232561151324,
    "input_throughput": 2330.373556823406,
    "output_throughput": 2073.210773658765,
    "total_throughput": 4403.584330482171,
    "itl": 27.176795028278967,
    "ttft": 8516.262516432316,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21192767810076457,
    "arrivals": 33997,
    "finished_requests": 33917,
    "scheduler_time": 6.58531349692781
}
#Debug simulation 
Total elapsed time: 2.7658834336325526. Arrivals time: 0.10031561320647597 Scheduler time: 2.3180369464680552 Scheduler overhead time: 0.12374115735292435 Adapter cache time: 0.043668973725289106 Engine time: 0.12114234315231442 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_64_slots_64_rate_0.4-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_64_slots_64_rate_0.4-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 4320, 4320, 33, 4320, 33, 270, 33, 4320, 270, 4320, 33, 270, 4320, 4320, 4320, 33, 4320, 270, 270, 33, 33, 33, 4320, 33, 33, 33, 4320, 270, 33, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 33, 270, 270, 4320, 4320, 270, 4320, 33, 4320, 270, 270, 270, 4320, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 4320, 270]
Prompts retrieved: 101403 . Total input tokens: 22599607 . Total output tokens: 20263556
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 2.745291959028691,
    "estimated_duration": 3600.022748309662,
    "input_throughput": 2330.3738855370066,
    "output_throughput": 2073.211066097965,
    "total_throughput": 4403.584951634972,
    "itl": 27.17656055937858,
    "ttft": 8516.249550168792,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19136321887373942,
    "arrivals": 33997,
    "finished_requests": 33917,
    "scheduler_time": 6.585192277808583
}
#Debug simulation 
Total elapsed time: 2.7453894168138504. Arrivals time: 0.09846256021410227 Scheduler time: 2.304597095120698 Scheduler overhead time: 0.12044135248288512 Adapter cache time: 0.043207937851548195 Engine time: 0.12042392510920763 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-32/adapters_64_slots_64_rate_0.4-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-32/adapters_64_slots_64_rate_0.4-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 4320, 4320, 33, 4320, 33, 270, 33, 4320, 270, 4320, 33, 270, 4320, 4320, 4320, 33, 4320, 270, 270, 33, 33, 33, 4320, 33, 33, 33, 4320, 270, 33, 4320, 4320, 4320, 4320, 270, 270, 270, 4320, 33, 270, 270, 4320, 4320, 270, 4320, 33, 4320, 270, 270, 270, 4320, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 4320, 270]
Prompts retrieved: 101403 . Total input tokens: 22599607 . Total output tokens: 20263556
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 2.726838561706245,
    "estimated_duration": 3600.024996337097,
    "input_throughput": 2330.372430340325,
    "output_throughput": 2073.209771486022,
    "total_throughput": 4403.582201826347,
    "itl": 27.17666003739401,
    "ttft": 8516.234875453,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21469426140189146,
    "arrivals": 33997,
    "finished_requests": 33917,
    "scheduler_time": 6.585281263585496
}
#Debug simulation 
Total elapsed time: 2.7270532697439194. Arrivals time: 0.09773173648864031 Scheduler time: 2.292145400773734 Scheduler overhead time: 0.1203581290319562 Adapter cache time: 0.043010751251131296 Engine time: 0.11575393285602331 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_64_slots_64_rate_0.4-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_64_slots_64_rate_0.4-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 4320, 4320, 66, 4320, 66, 135, 66, 4320, 135, 4320, 66, 135, 4320, 4320, 4320, 66, 4320, 135, 135, 66, 66, 66, 4320, 66, 66, 66, 4320, 135, 66, 4320, 4320, 4320, 4320, 135, 135, 135, 4320, 66, 135, 135, 4320, 4320, 135, 4320, 66, 4320, 135, 135, 135, 4320, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 4320, 135]
Prompts retrieved: 99261 . Total input tokens: 22115311 . Total output tokens: 19830516
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 2.679423603694886,
    "estimated_duration": 3599.9117252772526,
    "input_throughput": 2261.359339130193,
    "output_throughput": 2024.6960359670063,
    "total_throughput": 4286.055375097199,
    "itl": 26.646619617119935,
    "ttft": 5774.6883915793815,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19587121561169607,
    "arrivals": 33294,
    "finished_requests": 33241,
    "scheduler_time": 5.44760919113722
}
#Debug simulation 
Total elapsed time: 2.679518929682672. Arrivals time: 0.09749636519700289 Scheduler time: 2.2393131400458515 Scheduler overhead time: 0.12229613354429603 Adapter cache time: 0.040533301420509815 Engine time: 0.12095568142831326 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_64_slots_64_rate_0.4-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_64_slots_64_rate_0.4-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 4320, 4320, 66, 4320, 66, 135, 66, 4320, 135, 4320, 66, 135, 4320, 4320, 4320, 66, 4320, 135, 135, 66, 66, 66, 4320, 66, 66, 66, 4320, 135, 66, 4320, 4320, 4320, 4320, 135, 135, 135, 4320, 66, 135, 135, 4320, 4320, 135, 4320, 66, 4320, 135, 135, 135, 4320, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 4320, 135]
Prompts retrieved: 99261 . Total input tokens: 22115311 . Total output tokens: 19830516
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 2.689074640162289,
    "estimated_duration": 3599.921504431292,
    "input_throughput": 2261.3531961681065,
    "output_throughput": 2024.6905358986314,
    "total_throughput": 4286.043732066738,
    "itl": 26.6058574370914,
    "ttft": 5774.748093051189,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20893281756667417,
    "arrivals": 33294,
    "finished_requests": 33241,
    "scheduler_time": 5.414578662580213
}
#Debug simulation 
Total elapsed time: 2.689173642080277. Arrivals time: 0.0945100411772728 Scheduler time: 2.2504399796016514 Scheduler overhead time: 0.1229249550960958 Adapter cache time: 0.04120798176154494 Engine time: 0.12094381917268038 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-32/adapters_64_slots_64_rate_0.4-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-32/adapters_64_slots_64_rate_0.4-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 4320, 4320, 66, 4320, 66, 135, 66, 4320, 135, 4320, 66, 135, 4320, 4320, 4320, 66, 4320, 135, 135, 66, 66, 66, 4320, 66, 66, 66, 4320, 135, 66, 4320, 4320, 4320, 4320, 135, 135, 135, 4320, 66, 135, 135, 4320, 4320, 135, 4320, 66, 4320, 135, 135, 135, 4320, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 4320, 135]
Prompts retrieved: 99261 . Total input tokens: 22115311 . Total output tokens: 19830516
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 2.684308784082532,
    "estimated_duration": 3599.9215751794563,
    "input_throughput": 2261.3531517264196,
    "output_throughput": 2024.6904961080038,
    "total_throughput": 4286.043647834424,
    "itl": 26.60586072006799,
    "ttft": 5774.743880220969,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2092868485860526,
    "arrivals": 33294,
    "finished_requests": 33241,
    "scheduler_time": 5.414568071006101
}
#Debug simulation 
Total elapsed time: 2.6844084900803864. Arrivals time: 0.09784267656505108 Scheduler time: 2.2424478316679597 Scheduler overhead time: 0.12206694018095732 Adapter cache time: 0.04149209801107645 Engine time: 0.12142266379669309 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_64_slots_64_rate_0.4-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_64_slots_64_rate_0.4-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 4320, 4320, 66, 4320, 66, 135, 66, 4320, 135, 4320, 66, 135, 4320, 4320, 4320, 66, 4320, 135, 135, 66, 66, 66, 4320, 66, 66, 66, 4320, 135, 66, 4320, 4320, 4320, 4320, 135, 135, 135, 4320, 66, 135, 135, 4320, 4320, 135, 4320, 66, 4320, 135, 135, 135, 4320, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 4320, 135]
Prompts retrieved: 99261 . Total input tokens: 22115311 . Total output tokens: 19830516
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 2.7138167871162295,
    "estimated_duration": 3599.9127369122057,
    "input_throughput": 2261.358703650859,
    "output_throughput": 2024.6954669939703,
    "total_throughput": 4286.054170644829,
    "itl": 26.60589086815369,
    "ttft": 5774.655338792078,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20035231587942698,
    "arrivals": 33294,
    "finished_requests": 33241,
    "scheduler_time": 5.4145926733523275
}
#Debug simulation 
Total elapsed time: 2.713916316162795. Arrivals time: 0.0956061533652246 Scheduler time: 2.2741892896592617 Scheduler overhead time: 0.12259407807141542 Adapter cache time: 0.04150080354884267 Engine time: 0.12067250534892082 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-32/adapters_64_slots_64_rate_0.4-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-32/adapters_64_slots_64_rate_0.4-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 4320, 4320, 66, 4320, 66, 135, 66, 4320, 135, 4320, 66, 135, 4320, 4320, 4320, 66, 4320, 135, 135, 66, 66, 66, 4320, 66, 66, 66, 4320, 135, 66, 4320, 4320, 4320, 4320, 135, 135, 135, 4320, 66, 135, 135, 4320, 4320, 135, 4320, 66, 4320, 135, 135, 135, 4320, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 4320, 135]
Prompts retrieved: 99261 . Total input tokens: 22115311 . Total output tokens: 19830516
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 2.700656448956579,
    "estimated_duration": 3599.92488672105,
    "input_throughput": 2261.3510715260663,
    "output_throughput": 2024.6886336117009,
    "total_throughput": 4286.039705137768,
    "itl": 26.605739151297694,
    "ttft": 5774.732258952411,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2119276781007646,
    "arrivals": 33294,
    "finished_requests": 33241,
    "scheduler_time": 5.414618610172621
}
#Debug simulation 
Total elapsed time: 2.700759343802929. Arrivals time: 0.09688145574182272 Scheduler time: 2.258152598515153 Scheduler overhead time: 0.12306479690596461 Adapter cache time: 0.04137052036821842 Engine time: 0.12205915991216898 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_64_slots_64_rate_0.4-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_64_slots_64_rate_0.4-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 4320, 4320, 66, 4320, 66, 135, 66, 4320, 135, 4320, 66, 135, 4320, 4320, 4320, 66, 4320, 135, 135, 66, 66, 66, 4320, 66, 66, 66, 4320, 135, 66, 4320, 4320, 4320, 4320, 135, 135, 135, 4320, 66, 135, 135, 4320, 4320, 135, 4320, 66, 4320, 135, 135, 135, 4320, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 4320, 135]
Prompts retrieved: 99261 . Total input tokens: 22115311 . Total output tokens: 19830516
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 2.6895569879561663,
    "estimated_duration": 3599.9272198288268,
    "input_throughput": 2261.349605947612,
    "output_throughput": 2024.6873214138402,
    "total_throughput": 4286.036927361452,
    "itl": 26.646602671065597,
    "ttft": 5774.738902197182,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19136321887373942,
    "arrivals": 33294,
    "finished_requests": 33241,
    "scheduler_time": 5.447443937749525
}
#Debug simulation 
Total elapsed time: 2.6896688318811357. Arrivals time: 0.09201033879071474 Scheduler time: 2.2584146023727953 Scheduler overhead time: 0.1223437818698585 Adapter cache time: 0.03995922161266208 Engine time: 0.11805546283721924 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-32/adapters_64_slots_64_rate_0.4-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-32/adapters_64_slots_64_rate_0.4-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 4320, 4320, 66, 4320, 66, 135, 66, 4320, 135, 4320, 66, 135, 4320, 4320, 4320, 66, 4320, 135, 135, 66, 66, 66, 4320, 66, 66, 66, 4320, 135, 66, 4320, 4320, 4320, 4320, 135, 135, 135, 4320, 66, 135, 135, 4320, 4320, 135, 4320, 66, 4320, 135, 135, 135, 4320, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 4320, 135]
Prompts retrieved: 99261 . Total input tokens: 22115311 . Total output tokens: 19830516
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 2.6931349239312112,
    "estimated_duration": 3599.924373863194,
    "input_throughput": 2261.3513936860736,
    "output_throughput": 2024.688922055947,
    "total_throughput": 4286.0403157420205,
    "itl": 26.60578508071491,
    "ttft": 5774.638790846243,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21469426140189146,
    "arrivals": 33294,
    "finished_requests": 33241,
    "scheduler_time": 5.414700673817463
}
#Debug simulation 
Total elapsed time: 2.693259181920439. Arrivals time: 0.09541035583242774 Scheduler time: 2.2521653664298356 Scheduler overhead time: 0.12260829703882337 Adapter cache time: 0.041597054339945316 Engine time: 0.12228636723011732 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_64_slots_64_rate_0.4-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_64_slots_64_rate_0.4-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 4320, 4320, 33, 4320, 33, 135, 33, 4320, 135, 4320, 33, 135, 4320, 4320, 4320, 33, 4320, 135, 135, 33, 33, 33, 4320, 33, 33, 33, 4320, 135, 33, 4320, 4320, 4320, 4320, 135, 135, 135, 4320, 33, 135, 135, 4320, 4320, 135, 4320, 33, 4320, 135, 135, 135, 4320, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 4320, 135]
Prompts retrieved: 98568 . Total input tokens: 21979772 . Total output tokens: 19688007
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 2.676825241651386,
    "estimated_duration": 3599.688814295369,
    "input_throughput": 2285.6595179354545,
    "output_throughput": 2007.0765482027502,
    "total_throughput": 4292.7360661382045,
    "itl": 26.406605145157737,
    "ttft": 6471.272978326616,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19587121561169607,
    "arrivals": 33045,
    "finished_requests": 32986,
    "scheduler_time": 5.085902302286684
}
#Debug simulation 
Total elapsed time: 2.6769222910515964. Arrivals time: 0.0966565404087305 Scheduler time: 2.239107700996101 Scheduler overhead time: 0.1227566059678793 Adapter cache time: 0.03994791302829981 Engine time: 0.11913292435929179 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_64_slots_64_rate_0.4-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_64_slots_64_rate_0.4-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 4320, 4320, 33, 4320, 33, 135, 33, 4320, 135, 4320, 33, 135, 4320, 4320, 4320, 33, 4320, 135, 135, 33, 33, 33, 4320, 33, 33, 33, 4320, 135, 33, 4320, 4320, 4320, 4320, 135, 135, 135, 4320, 33, 135, 135, 4320, 4320, 135, 4320, 33, 4320, 135, 135, 135, 4320, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 4320, 135]
Prompts retrieved: 98568 . Total input tokens: 21979772 . Total output tokens: 19688007
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 2.677100250031799,
    "estimated_duration": 3599.6748620056374,
    "input_throughput": 2285.6683771199764,
    "output_throughput": 2007.084327603554,
    "total_throughput": 4292.75270472353,
    "itl": 26.406711275332892,
    "ttft": 6471.157371871464,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20893281756667417,
    "arrivals": 33045,
    "finished_requests": 32986,
    "scheduler_time": 5.085886206308504
}
#Debug simulation 
Total elapsed time: 2.6772034489549696. Arrivals time: 0.09600234404206276 Scheduler time: 2.240409360267222 Scheduler overhead time: 0.12256216397508979 Adapter cache time: 0.03968610009178519 Engine time: 0.11913324147462845 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-32/adapters_64_slots_64_rate_0.4-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-32/adapters_64_slots_64_rate_0.4-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 4320, 4320, 33, 4320, 33, 135, 33, 4320, 135, 4320, 33, 135, 4320, 4320, 4320, 33, 4320, 135, 135, 33, 33, 33, 4320, 33, 33, 33, 4320, 135, 33, 4320, 4320, 4320, 4320, 135, 135, 135, 4320, 33, 135, 135, 4320, 4320, 135, 4320, 33, 4320, 135, 135, 135, 4320, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 4320, 135]
Prompts retrieved: 98568 . Total input tokens: 21979772 . Total output tokens: 19688007
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 2.668581247795373,
    "estimated_duration": 3599.6764932662313,
    "input_throughput": 2285.667341326687,
    "output_throughput": 2007.0834180558268,
    "total_throughput": 4292.750759382514,
    "itl": 26.40674094739187,
    "ttft": 6471.164414863889,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20928684858605257,
    "arrivals": 33045,
    "finished_requests": 32986,
    "scheduler_time": 5.085903219526667
}
#Debug simulation 
Total elapsed time: 2.6686773910187185. Arrivals time: 0.09517023013904691 Scheduler time: 2.225263249129057 Scheduler overhead time: 0.12288783024996519 Adapter cache time: 0.039569034706801176 Engine time: 0.12615071330219507 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_64_slots_64_rate_0.4-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_64_slots_64_rate_0.4-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 4320, 4320, 33, 4320, 33, 135, 33, 4320, 135, 4320, 33, 135, 4320, 4320, 4320, 33, 4320, 135, 135, 33, 33, 33, 4320, 33, 33, 33, 4320, 135, 33, 4320, 4320, 4320, 4320, 135, 135, 135, 4320, 33, 135, 135, 4320, 4320, 135, 4320, 33, 4320, 135, 135, 135, 4320, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 4320, 135]
Prompts retrieved: 98568 . Total input tokens: 21979772 . Total output tokens: 19688007
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 2.6824824260547757,
    "estimated_duration": 3599.6907105391874,
    "input_throughput": 2285.6583138965298,
    "output_throughput": 2007.0754909156653,
    "total_throughput": 4292.733804812195,
    "itl": 26.406556427347237,
    "ttft": 6471.361347862928,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.200352315879427,
    "arrivals": 33045,
    "finished_requests": 32986,
    "scheduler_time": 5.085832706563949
}
#Debug simulation 
Total elapsed time: 2.682581026107073. Arrivals time: 0.09609815152361989 Scheduler time: 2.241776525042951 Scheduler overhead time: 0.12315242784097791 Adapter cache time: 0.040240009780973196 Engine time: 0.12180562596768141 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-32/adapters_64_slots_64_rate_0.4-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-32/adapters_64_slots_64_rate_0.4-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 4320, 4320, 33, 4320, 33, 135, 33, 4320, 135, 4320, 33, 135, 4320, 4320, 4320, 33, 4320, 135, 135, 33, 33, 33, 4320, 33, 33, 33, 4320, 135, 33, 4320, 4320, 4320, 4320, 135, 135, 135, 4320, 33, 135, 135, 4320, 4320, 135, 4320, 33, 4320, 135, 135, 135, 4320, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 4320, 135]
Prompts retrieved: 98568 . Total input tokens: 21979772 . Total output tokens: 19688007
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 2.7088668746873736,
    "estimated_duration": 3599.6828598263655,
    "input_throughput": 2285.6632987931803,
    "output_throughput": 2007.0798682383088,
    "total_throughput": 4292.743167031489,
    "itl": 26.406757838253338,
    "ttft": 6471.228307663016,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21192767810076457,
    "arrivals": 33045,
    "finished_requests": 32986,
    "scheduler_time": 5.085980321123476
}
#Debug simulation 
Total elapsed time: 2.708966186735779. Arrivals time: 0.09486338961869478 Scheduler time: 2.263956226874143 Scheduler overhead time: 0.12375731160864234 Adapter cache time: 0.04018546640872955 Engine time: 0.12341610807925463 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_64_slots_64_rate_0.4-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_64_slots_64_rate_0.4-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 4320, 4320, 33, 4320, 33, 135, 33, 4320, 135, 4320, 33, 135, 4320, 4320, 4320, 33, 4320, 135, 135, 33, 33, 33, 4320, 33, 33, 33, 4320, 135, 33, 4320, 4320, 4320, 4320, 135, 135, 135, 4320, 33, 135, 135, 4320, 4320, 135, 4320, 33, 4320, 135, 135, 135, 4320, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 4320, 135]
Prompts retrieved: 98568 . Total input tokens: 21979772 . Total output tokens: 19688007
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 2.684879600070417,
    "estimated_duration": 3599.6748574301087,
    "input_throughput": 2285.668380025278,
    "output_throughput": 2007.0843301547486,
    "total_throughput": 4292.752710180027,
    "itl": 26.406481707034008,
    "ttft": 6471.22482662122,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19136321887373942,
    "arrivals": 33045,
    "finished_requests": 32986,
    "scheduler_time": 5.0859102249127375
}
#Debug simulation 
Total elapsed time: 2.6850366489961743. Arrivals time: 0.09617870301008224 Scheduler time: 2.2439637007191777 Scheduler overhead time: 0.12358295219019055 Adapter cache time: 0.040093373972922564 Engine time: 0.12170151714235544 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-32/adapters_64_slots_64_rate_0.4-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-32/adapters_64_slots_64_rate_0.4-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 4320, 4320, 33, 4320, 33, 135, 33, 4320, 135, 4320, 33, 135, 4320, 4320, 4320, 33, 4320, 135, 135, 33, 33, 33, 4320, 33, 33, 33, 4320, 135, 33, 4320, 4320, 4320, 4320, 135, 135, 135, 4320, 33, 135, 135, 4320, 4320, 135, 4320, 33, 4320, 135, 135, 135, 4320, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 4320, 135]
Prompts retrieved: 98568 . Total input tokens: 21979772 . Total output tokens: 19688007
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 2.6860653469339013,
    "estimated_duration": 3599.6866267922765,
    "input_throughput": 2285.6609069139354,
    "output_throughput": 2007.0777678884094,
    "total_throughput": 4292.738674802345,
    "itl": 26.406797181419837,
    "ttft": 6471.231708160072,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21469426140189143,
    "arrivals": 33045,
    "finished_requests": 32986,
    "scheduler_time": 5.086062051270296
}
#Debug simulation 
Total elapsed time: 2.6861669891513884. Arrivals time: 0.0978813711553812 Scheduler time: 2.2418441022746265 Scheduler overhead time: 0.12380112614482641 Adapter cache time: 0.04005564656108618 Engine time: 0.12305146921426058 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_64_slots_64_rate_0.4-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_64_slots_64_rate_0.4-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 4320, 4320, 33, 4320, 33, 66, 33, 4320, 66, 4320, 33, 66, 4320, 4320, 4320, 33, 4320, 66, 66, 33, 33, 33, 4320, 33, 33, 33, 4320, 66, 33, 4320, 4320, 4320, 4320, 66, 66, 66, 4320, 33, 66, 66, 4320, 4320, 66, 4320, 33, 4320, 66, 66, 66, 4320, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 4320, 66]
Prompts retrieved: 97119 . Total input tokens: 21643986 . Total output tokens: 19399276
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 2.631147976964712,
    "estimated_duration": 3599.9473433771236,
    "input_throughput": 2209.9023238870172,
    "output_throughput": 1970.729381098281,
    "total_throughput": 4180.631704985299,
    "itl": 26.058830669511618,
    "ttft": 5130.866825808984,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19587121561169607,
    "arrivals": 32548,
    "finished_requests": 32502,
    "scheduler_time": 4.3478672095491255
}
#Debug simulation 
Total elapsed time: 2.6312466710805893. Arrivals time: 0.09411109937354922 Scheduler time: 2.1880477350205183 Scheduler overhead time: 0.12528018886223435 Adapter cache time: 0.03798114601522684 Engine time: 0.12539114570245147 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_64_slots_64_rate_0.4-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_64_slots_64_rate_0.4-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 4320, 4320, 33, 4320, 33, 66, 33, 4320, 66, 4320, 33, 66, 4320, 4320, 4320, 33, 4320, 66, 66, 33, 33, 33, 4320, 33, 33, 33, 4320, 66, 33, 4320, 4320, 4320, 4320, 66, 66, 66, 4320, 33, 66, 66, 4320, 4320, 66, 4320, 33, 4320, 66, 66, 66, 4320, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 4320, 66]
Prompts retrieved: 97119 . Total input tokens: 21643986 . Total output tokens: 19399276
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 2.65984551794827,
    "estimated_duration": 3599.9364353092164,
    "input_throughput": 2209.9090200509777,
    "output_throughput": 1970.735352550917,
    "total_throughput": 4180.644372601894,
    "itl": 26.05872103953445,
    "ttft": 5130.875601492563,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20893281756667417,
    "arrivals": 32548,
    "finished_requests": 32502,
    "scheduler_time": 4.348231575770846
}
#Debug simulation 
Total elapsed time: 2.6599630918353796. Arrivals time: 0.09550190949812531 Scheduler time: 2.2086985944770277 Scheduler overhead time: 0.12765251426026225 Adapter cache time: 0.038029957097023726 Engine time: 0.12891209172084928 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-32/adapters_64_slots_64_rate_0.4-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-32/adapters_64_slots_64_rate_0.4-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 4320, 4320, 33, 4320, 33, 66, 33, 4320, 66, 4320, 33, 66, 4320, 4320, 4320, 33, 4320, 66, 66, 33, 33, 33, 4320, 33, 33, 33, 4320, 66, 33, 4320, 4320, 4320, 4320, 66, 66, 66, 4320, 33, 66, 66, 4320, 4320, 66, 4320, 33, 4320, 66, 66, 66, 4320, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 4320, 66]
Prompts retrieved: 97119 . Total input tokens: 21643986 . Total output tokens: 19399276
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 2.617207869887352,
    "estimated_duration": 3599.9370643880716,
    "input_throughput": 2209.908633875605,
    "output_throughput": 1970.735008170469,
    "total_throughput": 4180.643642046074,
    "itl": 26.0587226050355,
    "ttft": 5130.888611902882,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20928684858605254,
    "arrivals": 32548,
    "finished_requests": 32502,
    "scheduler_time": 4.348259180563131
}
#Debug simulation 
Total elapsed time: 2.617333179805428. Arrivals time: 0.0944501687772572 Scheduler time: 2.1787383491173387 Scheduler overhead time: 0.12486555567011237 Adapter cache time: 0.03780119260773063 Engine time: 0.12099577160552144 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_64_slots_64_rate_0.4-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_64_slots_64_rate_0.4-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 4320, 4320, 33, 4320, 33, 66, 33, 4320, 66, 4320, 33, 66, 4320, 4320, 4320, 33, 4320, 66, 66, 33, 33, 33, 4320, 33, 33, 33, 4320, 66, 33, 4320, 4320, 4320, 4320, 66, 66, 66, 4320, 33, 66, 66, 4320, 4320, 66, 4320, 33, 4320, 66, 66, 66, 4320, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 4320, 66]
Prompts retrieved: 97119 . Total input tokens: 21643986 . Total output tokens: 19399276
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 2.6201335857622325,
    "estimated_duration": 3599.9365226949044,
    "input_throughput": 2209.908966407137,
    "output_throughput": 1970.7353047128333,
    "total_throughput": 4180.644271119971,
    "itl": 26.058880283583033,
    "ttft": 5130.928107991375,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.200352315879427,
    "arrivals": 32548,
    "finished_requests": 32502,
    "scheduler_time": 4.348206097570575
}
#Debug simulation 
Total elapsed time: 2.6202324028126895. Arrivals time: 0.09324539406225085 Scheduler time: 2.185051920823753 Scheduler overhead time: 0.12362376414239407 Adapter cache time: 0.03778485767543316 Engine time: 0.12033506715670228 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-32/adapters_64_slots_64_rate_0.4-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-32/adapters_64_slots_64_rate_0.4-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 4320, 4320, 33, 4320, 33, 66, 33, 4320, 66, 4320, 33, 66, 4320, 4320, 4320, 33, 4320, 66, 66, 33, 33, 33, 4320, 33, 33, 33, 4320, 66, 33, 4320, 4320, 4320, 4320, 66, 66, 66, 4320, 33, 66, 66, 4320, 4320, 66, 4320, 33, 4320, 66, 66, 66, 4320, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 4320, 66]
Prompts retrieved: 97119 . Total input tokens: 21643986 . Total output tokens: 19399276
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 2.644635616336018,
    "estimated_duration": 3599.9474325694036,
    "input_throughput": 2209.902269134488,
    "output_throughput": 1970.7293322714995,
    "total_throughput": 4180.631601405988,
    "itl": 26.05905721644669,
    "ttft": 5130.890415451163,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21192767810076454,
    "arrivals": 32548,
    "finished_requests": 32502,
    "scheduler_time": 4.34810109955152
}
#Debug simulation 
Total elapsed time: 2.6447472842410207. Arrivals time: 0.09518349869176745 Scheduler time: 2.2025112346746027 Scheduler overhead time: 0.12475069332867861 Adapter cache time: 0.0378345875069499 Engine time: 0.12438410799950361 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_64_slots_64_rate_0.4-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_64_slots_64_rate_0.4-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 4320, 4320, 33, 4320, 33, 66, 33, 4320, 66, 4320, 33, 66, 4320, 4320, 4320, 33, 4320, 66, 66, 33, 33, 33, 4320, 33, 33, 33, 4320, 66, 33, 4320, 4320, 4320, 4320, 66, 66, 66, 4320, 33, 66, 66, 4320, 4320, 66, 4320, 33, 4320, 66, 66, 66, 4320, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 4320, 66]
Prompts retrieved: 97119 . Total input tokens: 21643986 . Total output tokens: 19399276
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 2.6388941910117865,
    "estimated_duration": 3599.944223124115,
    "input_throughput": 2209.9042393206873,
    "output_throughput": 1970.731089228713,
    "total_throughput": 4180.635328549401,
    "itl": 26.05878705224672,
    "ttft": 5130.872189513868,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19136321887373942,
    "arrivals": 32548,
    "finished_requests": 32502,
    "scheduler_time": 4.348119405375697
}
#Debug simulation 
Total elapsed time: 2.638992658816278. Arrivals time: 0.0945054143667221 Scheduler time: 2.198364943265915 Scheduler overhead time: 0.12426500068977475 Adapter cache time: 0.03792950697243214 Engine time: 0.12396905990317464 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-32/adapters_64_slots_64_rate_0.4-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-32/adapters_64_slots_64_rate_0.4-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 4320, 4320, 33, 4320, 33, 66, 33, 4320, 66, 4320, 33, 66, 4320, 4320, 4320, 33, 4320, 66, 66, 33, 33, 33, 4320, 33, 33, 33, 4320, 66, 33, 4320, 4320, 4320, 4320, 66, 66, 66, 4320, 33, 66, 66, 4320, 4320, 66, 4320, 33, 4320, 66, 66, 66, 4320, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 4320, 66]
Prompts retrieved: 97119 . Total input tokens: 21643986 . Total output tokens: 19399276
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 2.6474768221378326,
    "estimated_duration": 3599.947448272403,
    "input_throughput": 2209.902259494877,
    "output_throughput": 1970.7293236751625,
    "total_throughput": 4180.631583170039,
    "itl": 26.058977735473384,
    "ttft": 5130.87428301026,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2146942614018914,
    "arrivals": 32548,
    "finished_requests": 32502,
    "scheduler_time": 4.348001522200502
}
#Debug simulation 
Total elapsed time: 2.647574888076633. Arrivals time: 0.09378488827496767 Scheduler time: 2.2046153340488672 Scheduler overhead time: 0.1260394868440926 Adapter cache time: 0.03780301893129945 Engine time: 0.12458948651328683 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_64_slots_64_rate_0.1-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_64_slots_64_rate_0.1-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 1080, 1080, 270, 1080, 270, 540, 270, 1080, 540, 1080, 270, 540, 1080, 1080, 1080, 270, 1080, 540, 540, 270, 270, 270, 1080, 270, 270, 270, 1080, 540, 270, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 270, 540, 540, 1080, 1080, 540, 1080, 270, 1080, 540, 540, 540, 1080, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 1080, 540]
Prompts retrieved: 40770 . Total input tokens: 9017193 . Total output tokens: 8172157
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.473296546842903,
    "estimated_duration": 3599.6136680842515,
    "input_throughput": 945.9178995206286,
    "output_throughput": 849.4225441774366,
    "total_throughput": 1795.3404436980652,
    "itl": 21.92871964616088,
    "ttft": 4993.986741314697,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19587121561169607,
    "arrivals": 13796,
    "finished_requests": 13777,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4733895887620747. Arrivals time: 0.0477166511118412 Scheduler time: 1.011557032354176 Scheduler overhead time: 0.13792620040476322 Adapter cache time: 0.07160111144185066 Engine time: 0.13686892623081803 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_64_slots_64_rate_0.1-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_64_slots_64_rate_0.1-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 1080, 1080, 270, 1080, 270, 540, 270, 1080, 540, 1080, 270, 540, 1080, 1080, 1080, 270, 1080, 540, 540, 270, 270, 270, 1080, 270, 270, 270, 1080, 540, 270, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 270, 540, 540, 1080, 1080, 540, 1080, 270, 1080, 540, 540, 540, 1080, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 1080, 540]
Prompts retrieved: 40770 . Total input tokens: 9017193 . Total output tokens: 8172157
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.4727803571149707,
    "estimated_duration": 3599.61999123796,
    "input_throughput": 945.9162379051554,
    "output_throughput": 849.4210520673463,
    "total_throughput": 1795.3372899725018,
    "itl": 21.928850750581947,
    "ttft": 4994.127735226683,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2089328175666742,
    "arrivals": 13796,
    "finished_requests": 13777,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4728763308376074. Arrivals time: 0.04883406311273575 Scheduler time: 1.0088328677229583 Scheduler overhead time: 0.13892097165808082 Adapter cache time: 0.0713513046503067 Engine time: 0.13692495599389076 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-32/adapters_64_slots_64_rate_0.1-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-32/adapters_64_slots_64_rate_0.1-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 1080, 1080, 270, 1080, 270, 540, 270, 1080, 540, 1080, 270, 540, 1080, 1080, 1080, 270, 1080, 540, 540, 270, 270, 270, 1080, 270, 270, 270, 1080, 540, 270, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 270, 540, 540, 1080, 1080, 540, 1080, 270, 1080, 540, 540, 540, 1080, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 1080, 540]
Prompts retrieved: 40770 . Total input tokens: 9017193 . Total output tokens: 8172157
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.4681055219843984,
    "estimated_duration": 3599.6199746502,
    "input_throughput": 945.9162422641243,
    "output_throughput": 849.4210559816463,
    "total_throughput": 1795.3372982457706,
    "itl": 21.928899926695337,
    "ttft": 4994.089842182215,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2092868485860526,
    "arrivals": 13796,
    "finished_requests": 13777,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4682243140414357. Arrivals time: 0.04875344131141901 Scheduler time: 1.0059866635128856 Scheduler overhead time: 0.1387694552540779 Adapter cache time: 0.0712170209735632 Engine time: 0.13550435192883015 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_64_slots_64_rate_0.1-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_64_slots_64_rate_0.1-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 1080, 1080, 270, 1080, 270, 540, 270, 1080, 540, 1080, 270, 540, 1080, 1080, 1080, 270, 1080, 540, 540, 270, 270, 270, 1080, 270, 270, 270, 1080, 540, 270, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 270, 540, 540, 1080, 1080, 540, 1080, 270, 1080, 540, 540, 540, 1080, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 1080, 540]
Prompts retrieved: 40770 . Total input tokens: 9017193 . Total output tokens: 8172157
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 1.482728166040033,
    "estimated_duration": 3599.6134196069147,
    "input_throughput": 945.9179648162959,
    "output_throughput": 849.4226028121363,
    "total_throughput": 1795.3405676284322,
    "itl": 21.929011006398323,
    "ttft": 4994.200306537082,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20035231587942698,
    "arrivals": 13796,
    "finished_requests": 13777,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.482823601923883. Arrivals time: 0.0492801102809608 Scheduler time: 1.0202931347303092 Scheduler overhead time: 0.13712305389344692 Adapter cache time: 0.07153439661487937 Engine time: 0.13697711750864983 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-32/adapters_64_slots_64_rate_0.1-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-32/adapters_64_slots_64_rate_0.1-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 1080, 1080, 270, 1080, 270, 540, 270, 1080, 540, 1080, 270, 540, 1080, 1080, 1080, 270, 1080, 540, 540, 270, 270, 270, 1080, 270, 270, 270, 1080, 540, 270, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 270, 540, 540, 1080, 1080, 540, 1080, 270, 1080, 540, 540, 540, 1080, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 1080, 540]
Prompts retrieved: 40770 . Total input tokens: 9017193 . Total output tokens: 8172157
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 1.458970399107784,
    "estimated_duration": 3599.599465705508,
    "input_throughput": 945.9216316814973,
    "output_throughput": 849.4258956116172,
    "total_throughput": 1795.3475272931146,
    "itl": 21.928741507559565,
    "ttft": 4994.139949452372,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2119276781007646,
    "arrivals": 13796,
    "finished_requests": 13777,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4591085757128894. Arrivals time: 0.04854901507496834 Scheduler time: 0.9979934860020876 Scheduler overhead time: 0.13825801061466336 Adapter cache time: 0.0714595764875412 Engine time: 0.13496188027784228 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_64_slots_64_rate_0.1-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_64_slots_64_rate_0.1-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 1080, 1080, 270, 1080, 270, 540, 270, 1080, 540, 1080, 270, 540, 1080, 1080, 1080, 270, 1080, 540, 540, 270, 270, 270, 1080, 270, 270, 270, 1080, 540, 270, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 270, 540, 540, 1080, 1080, 540, 1080, 270, 1080, 540, 540, 540, 1080, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 1080, 540]
Prompts retrieved: 40770 . Total input tokens: 9017193 . Total output tokens: 8172157
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.4769785711541772,
    "estimated_duration": 3599.5997217543236,
    "input_throughput": 945.9215643956511,
    "output_throughput": 849.4258351897616,
    "total_throughput": 1795.3473995854126,
    "itl": 21.92855496746779,
    "ttft": 4994.131145155781,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19136321887373942,
    "arrivals": 13796,
    "finished_requests": 13777,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4770746659487486. Arrivals time: 0.04870374733582139 Scheduler time: 1.0147466813214123 Scheduler overhead time: 0.13827467383816838 Adapter cache time: 0.07145315315574408 Engine time: 0.1362543269060552 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-32/adapters_64_slots_64_rate_0.1-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-32/adapters_64_slots_64_rate_0.1-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 1080, 1080, 270, 1080, 270, 540, 270, 1080, 540, 1080, 270, 540, 1080, 1080, 1080, 270, 1080, 540, 540, 270, 270, 270, 1080, 270, 270, 270, 1080, 540, 270, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 270, 540, 540, 1080, 1080, 540, 1080, 270, 1080, 540, 540, 540, 1080, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 1080, 540]
Prompts retrieved: 40770 . Total input tokens: 9017193 . Total output tokens: 8172157
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.4623675728216767,
    "estimated_duration": 3599.5997080477564,
    "input_throughput": 945.9215679975342,
    "output_throughput": 849.425838424208,
    "total_throughput": 1795.3474064217423,
    "itl": 21.92857147480274,
    "ttft": 4994.031142781525,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2146942614018915,
    "arrivals": 13796,
    "finished_requests": 13777,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.46246306784451. Arrivals time: 0.04693574784323573 Scheduler time: 1.0023989700712264 Scheduler overhead time: 0.13829019712284207 Adapter cache time: 0.07160609075799584 Engine time: 0.13541498593986034 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_64_slots_64_rate_0.1-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_64_slots_64_rate_0.1-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 1080, 1080, 135, 1080, 135, 540, 135, 1080, 540, 1080, 135, 540, 1080, 1080, 1080, 135, 1080, 540, 540, 135, 135, 135, 1080, 135, 135, 135, 1080, 540, 135, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 135, 540, 540, 1080, 1080, 540, 1080, 135, 1080, 540, 540, 540, 1080, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 1080, 540]
Prompts retrieved: 37935 . Total input tokens: 8385449 . Total output tokens: 7584892
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.4011382018215954,
    "estimated_duration": 3599.5242699498303,
    "input_throughput": 868.568390023267,
    "output_throughput": 784.265027344668,
    "total_throughput": 1652.8334173679352,
    "itl": 21.46022561674858,
    "ttft": 3694.31490181023,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19587121561169607,
    "arrivals": 12790,
    "finished_requests": 12777,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4012384419329464. Arrivals time: 0.04644266935065389 Scheduler time: 0.9414430037140846 Scheduler overhead time: 0.1388041926547885 Adapter cache time: 0.06695209071040154 Engine time: 0.13839568756520748 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_64_slots_64_rate_0.1-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_64_slots_64_rate_0.1-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 1080, 1080, 135, 1080, 135, 540, 135, 1080, 540, 1080, 135, 540, 1080, 1080, 1080, 135, 1080, 540, 540, 135, 135, 135, 1080, 135, 135, 135, 1080, 540, 135, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 135, 540, 540, 1080, 1080, 540, 1080, 135, 1080, 540, 540, 540, 1080, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 1080, 540]
Prompts retrieved: 37935 . Total input tokens: 8385449 . Total output tokens: 7584892
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.4004339431412518,
    "estimated_duration": 3599.5206748363566,
    "input_throughput": 868.5692575281945,
    "output_throughput": 784.2658106494526,
    "total_throughput": 1652.8350681776471,
    "itl": 21.460303033544783,
    "ttft": 3694.500587551777,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20893281756667417,
    "arrivals": 12790,
    "finished_requests": 12777,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4005283480510116. Arrivals time: 0.045909748412668705 Scheduler time: 0.9399800952523947 Scheduler overhead time: 0.14026577165350318 Adapter cache time: 0.06715398281812668 Engine time: 0.13828965462744236 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-32/adapters_64_slots_64_rate_0.1-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-32/adapters_64_slots_64_rate_0.1-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 1080, 1080, 135, 1080, 135, 540, 135, 1080, 540, 1080, 135, 540, 1080, 1080, 1080, 135, 1080, 540, 540, 135, 135, 135, 1080, 135, 135, 135, 1080, 540, 135, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 135, 540, 540, 1080, 1080, 540, 1080, 135, 1080, 540, 540, 540, 1080, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 1080, 540]
Prompts retrieved: 37935 . Total input tokens: 8385449 . Total output tokens: 7584892
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.4117828393355012,
    "estimated_duration": 3599.5206496959645,
    "input_throughput": 868.5692635946056,
    "output_throughput": 784.265816127057,
    "total_throughput": 1652.8350797216626,
    "itl": 21.460298184980903,
    "ttft": 3694.4987173902146,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20928684858605257,
    "arrivals": 12790,
    "finished_requests": 12777,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4118814012035728. Arrivals time: 0.04457722511142492 Scheduler time: 0.953376040328294 Scheduler overhead time: 0.13902764907106757 Adapter cache time: 0.066392891574651 Engine time: 0.1390743046067655 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_64_slots_64_rate_0.1-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_64_slots_64_rate_0.1-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 1080, 1080, 135, 1080, 135, 540, 135, 1080, 540, 1080, 135, 540, 1080, 1080, 1080, 135, 1080, 540, 540, 135, 135, 135, 1080, 135, 135, 135, 1080, 540, 135, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 135, 540, 540, 1080, 1080, 540, 1080, 135, 1080, 540, 540, 540, 1080, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 1080, 540]
Prompts retrieved: 37935 . Total input tokens: 8385449 . Total output tokens: 7584892
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 1.4219820708967745,
    "estimated_duration": 3599.538720347976,
    "input_throughput": 868.5649031434118,
    "output_throughput": 784.2618789018321,
    "total_throughput": 1652.8267820452438,
    "itl": 21.46021665425762,
    "ttft": 3694.5050223378585,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20035231587942695,
    "arrivals": 12790,
    "finished_requests": 12777,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4220783929340541. Arrivals time: 0.04573366744443774 Scheduler time: 0.9565750071778893 Scheduler overhead time: 0.141773228533566 Adapter cache time: 0.06653024861589074 Engine time: 0.14210115605965257 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-32/adapters_64_slots_64_rate_0.1-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-32/adapters_64_slots_64_rate_0.1-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 1080, 1080, 135, 1080, 135, 540, 135, 1080, 540, 1080, 135, 540, 1080, 1080, 1080, 135, 1080, 540, 540, 135, 135, 135, 1080, 135, 135, 135, 1080, 540, 135, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 135, 540, 540, 1080, 1080, 540, 1080, 135, 1080, 540, 540, 540, 1080, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 1080, 540]
Prompts retrieved: 37935 . Total input tokens: 8385449 . Total output tokens: 7584892
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 1.4077218370512128,
    "estimated_duration": 3599.52122265179,
    "input_throughput": 868.569125339602,
    "output_throughput": 784.2656912911023,
    "total_throughput": 1652.8348166307044,
    "itl": 21.460336053206785,
    "ttft": 3694.3605540974636,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2119276781007646,
    "arrivals": 12790,
    "finished_requests": 12777,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4078467697836459. Arrivals time: 0.046338226180523634 Scheduler time: 0.945974602829665 Scheduler overhead time: 0.1407887083478272 Adapter cache time: 0.06680244114249945 Engine time: 0.1387779638171196 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_64_slots_64_rate_0.1-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_64_slots_64_rate_0.1-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 1080, 1080, 135, 1080, 135, 540, 135, 1080, 540, 1080, 135, 540, 1080, 1080, 1080, 135, 1080, 540, 540, 135, 135, 135, 1080, 135, 135, 135, 1080, 540, 135, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 135, 540, 540, 1080, 1080, 540, 1080, 135, 1080, 540, 540, 540, 1080, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 1080, 540]
Prompts retrieved: 37935 . Total input tokens: 8385449 . Total output tokens: 7584892
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.3902901159599423,
    "estimated_duration": 3599.5206668711958,
    "input_throughput": 868.5692594501987,
    "output_throughput": 784.2658123849069,
    "total_throughput": 1652.8350718351055,
    "itl": 21.46023127467873,
    "ttft": 3694.4391691126857,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19136321887373942,
    "arrivals": 12790,
    "finished_requests": 12777,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3903907192870975. Arrivals time: 0.04459954472258687 Scheduler time: 0.9307869262993336 Scheduler overhead time: 0.13994265720248222 Adapter cache time: 0.06665983097627759 Engine time: 0.13937663799151778 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-32/adapters_64_slots_64_rate_0.1-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-32/adapters_64_slots_64_rate_0.1-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 1080, 1080, 135, 1080, 135, 540, 135, 1080, 540, 1080, 135, 540, 1080, 1080, 1080, 135, 1080, 540, 540, 135, 135, 135, 1080, 135, 135, 135, 1080, 540, 135, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 135, 540, 540, 1080, 1080, 540, 1080, 135, 1080, 540, 540, 540, 1080, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 1080, 540]
Prompts retrieved: 37935 . Total input tokens: 8385449 . Total output tokens: 7584892
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.4126269607804716,
    "estimated_duration": 3599.521464106501,
    "input_throughput": 868.569067076272,
    "output_throughput": 784.2656386828188,
    "total_throughput": 1652.8347057590909,
    "itl": 21.46034288580792,
    "ttft": 3694.2846866058335,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21469426140189146,
    "arrivals": 12790,
    "finished_requests": 12777,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4127287110313773. Arrivals time: 0.04666823614388704 Scheduler time: 0.9506361028179526 Scheduler overhead time: 0.14044247521087527 Adapter cache time: 0.06633550580590963 Engine time: 0.1393950474448502 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_64_slots_64_rate_0.1-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_64_slots_64_rate_0.1-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 1080, 1080, 66, 1080, 66, 540, 66, 1080, 540, 1080, 66, 540, 1080, 1080, 1080, 66, 1080, 540, 540, 66, 66, 66, 1080, 66, 66, 66, 1080, 540, 66, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 66, 540, 540, 1080, 1080, 540, 1080, 66, 1080, 540, 540, 540, 1080, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 1080, 540]
Prompts retrieved: 36486 . Total input tokens: 8062787 . Total output tokens: 7286246
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.390080421231687,
    "estimated_duration": 3599.5449912574168,
    "input_throughput": 838.9496470622223,
    "output_throughput": 745.1147315880834,
    "total_throughput": 1584.0643786503058,
    "itl": 21.159319439509424,
    "ttft": 4123.691357779455,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19587121561169607,
    "arrivals": 12326,
    "finished_requests": 12312,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3902247180230916. Arrivals time: 0.04337804578244686 Scheduler time: 0.9263071892783046 Scheduler overhead time: 0.14306635223329067 Adapter cache time: 0.06430262327194214 Engine time: 0.14293507812544703 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_64_slots_64_rate_0.1-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_64_slots_64_rate_0.1-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 1080, 1080, 66, 1080, 66, 540, 66, 1080, 540, 1080, 66, 540, 1080, 1080, 1080, 66, 1080, 540, 540, 66, 66, 66, 1080, 66, 66, 66, 1080, 540, 66, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 66, 540, 540, 1080, 1080, 540, 1080, 66, 1080, 540, 540, 540, 1080, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 1080, 540]
Prompts retrieved: 36486 . Total input tokens: 8062787 . Total output tokens: 7286246
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.3795236428268254,
    "estimated_duration": 3599.545012220875,
    "input_throughput": 838.9496421762476,
    "output_throughput": 745.1147272485956,
    "total_throughput": 1584.0643694248433,
    "itl": 21.15943984359819,
    "ttft": 4123.751587861227,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20893281756667417,
    "arrivals": 12326,
    "finished_requests": 12312,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3796206419356167. Arrivals time: 0.045150994788855314 Scheduler time: 0.91667172126472 Scheduler overhead time: 0.14153165509924293 Adapter cache time: 0.06429082760587335 Engine time: 0.1421436807140708 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-32/adapters_64_slots_64_rate_0.1-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-32/adapters_64_slots_64_rate_0.1-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 1080, 1080, 66, 1080, 66, 540, 66, 1080, 540, 1080, 66, 540, 1080, 1080, 1080, 66, 1080, 540, 540, 66, 66, 66, 1080, 66, 66, 66, 1080, 540, 66, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 66, 540, 540, 1080, 1080, 540, 1080, 66, 1080, 540, 540, 540, 1080, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 1080, 540]
Prompts retrieved: 36486 . Total input tokens: 8062787 . Total output tokens: 7286246
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.357398048043251,
    "estimated_duration": 3599.5449914789647,
    "input_throughput": 838.949647010586,
    "output_throughput": 745.1147315422224,
    "total_throughput": 1584.0643785528084,
    "itl": 21.159456100534634,
    "ttft": 4123.784145988617,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20928684858605257,
    "arrivals": 12326,
    "finished_requests": 12312,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3574959291145205. Arrivals time: 0.04448794247582555 Scheduler time: 0.8974158139899373 Scheduler overhead time: 0.14086194289848208 Adapter cache time: 0.06388439983129501 Engine time: 0.14059443771839142 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_64_slots_64_rate_0.1-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_64_slots_64_rate_0.1-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 1080, 1080, 66, 1080, 66, 540, 66, 1080, 540, 1080, 66, 540, 1080, 1080, 1080, 66, 1080, 540, 540, 66, 66, 66, 1080, 66, 66, 66, 1080, 540, 66, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 66, 540, 540, 1080, 1080, 540, 1080, 66, 1080, 540, 540, 540, 1080, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 1080, 540]
Prompts retrieved: 36486 . Total input tokens: 8062787 . Total output tokens: 7286246
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 1.3702915674075484,
    "estimated_duration": 3599.5506934427067,
    "input_throughput": 838.9483180501472,
    "output_throughput": 745.1135512234703,
    "total_throughput": 1584.0618692736175,
    "itl": 21.159375477820056,
    "ttft": 4123.7890613430345,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20035231587942698,
    "arrivals": 12326,
    "finished_requests": 12312,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3703894303180277. Arrivals time: 0.045454696752130985 Scheduler time: 0.9091007015667856 Scheduler overhead time: 0.14152795542031527 Adapter cache time: 0.06390179833397269 Engine time: 0.1407307838089764 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-32/adapters_64_slots_64_rate_0.1-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-32/adapters_64_slots_64_rate_0.1-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 1080, 1080, 66, 1080, 66, 540, 66, 1080, 540, 1080, 66, 540, 1080, 1080, 1080, 66, 1080, 540, 540, 66, 66, 66, 1080, 66, 66, 66, 1080, 540, 66, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 66, 540, 540, 1080, 1080, 540, 1080, 66, 1080, 540, 540, 540, 1080, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 1080, 540]
Prompts retrieved: 36486 . Total input tokens: 8062787 . Total output tokens: 7286246
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 1.3874891698360443,
    "estimated_duration": 3599.545063293264,
    "input_throughput": 838.9496302727538,
    "output_throughput": 745.1147166764848,
    "total_throughput": 1584.0643469492386,
    "itl": 21.159529553073806,
    "ttft": 4123.795257973226,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2119276781007646,
    "arrivals": 12326,
    "finished_requests": 12312,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3875850327312946. Arrivals time: 0.043333581648766994 Scheduler time: 0.9283251077868044 Scheduler overhead time: 0.140778002794832 Adapter cache time: 0.06396538205444813 Engine time: 0.14127972768619657 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_64_slots_64_rate_0.1-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_64_slots_64_rate_0.1-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 1080, 1080, 66, 1080, 66, 540, 66, 1080, 540, 1080, 66, 540, 1080, 1080, 1080, 66, 1080, 540, 540, 66, 66, 66, 1080, 66, 66, 66, 1080, 540, 66, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 66, 540, 540, 1080, 1080, 540, 1080, 66, 1080, 540, 540, 540, 1080, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 1080, 540]
Prompts retrieved: 36486 . Total input tokens: 8062787 . Total output tokens: 7286246
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.3717843247577548,
    "estimated_duration": 3599.544989555959,
    "input_throughput": 838.9496474587828,
    "output_throughput": 745.1147319402893,
    "total_throughput": 1584.064379399072,
    "itl": 21.15927253409359,
    "ttft": 4123.778847187809,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19136321887373942,
    "arrivals": 12326,
    "finished_requests": 12312,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3718874137848616. Arrivals time: 0.04474452370777726 Scheduler time: 0.9103913833387196 Scheduler overhead time: 0.14140687510371208 Adapter cache time: 0.06367235817015171 Engine time: 0.1415865821763873 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-32/adapters_64_slots_64_rate_0.1-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-32/adapters_64_slots_64_rate_0.1-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 1080, 1080, 66, 1080, 66, 540, 66, 1080, 540, 1080, 66, 540, 1080, 1080, 1080, 66, 1080, 540, 540, 66, 66, 66, 1080, 66, 66, 66, 1080, 540, 66, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 66, 540, 540, 1080, 1080, 540, 1080, 66, 1080, 540, 540, 540, 1080, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 1080, 540]
Prompts retrieved: 36486 . Total input tokens: 8062787 . Total output tokens: 7286246
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.373828490730375,
    "estimated_duration": 3599.5449734703066,
    "input_throughput": 838.9496512078824,
    "output_throughput": 745.1147352700593,
    "total_throughput": 1584.0643864779418,
    "itl": 21.159427362364255,
    "ttft": 4123.722199986053,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21469426140189146,
    "arrivals": 12326,
    "finished_requests": 12312,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3739288807846606. Arrivals time: 0.04565710760653019 Scheduler time: 0.9123530243523419 Scheduler overhead time: 0.14159446768462658 Adapter cache time: 0.06415997771546245 Engine time: 0.14038564590737224 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_64_slots_64_rate_0.1-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_64_slots_64_rate_0.1-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 1080, 1080, 33, 1080, 33, 540, 33, 1080, 540, 1080, 33, 540, 1080, 1080, 1080, 33, 1080, 540, 540, 33, 33, 33, 1080, 33, 33, 33, 1080, 540, 33, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 33, 540, 540, 1080, 1080, 540, 1080, 33, 1080, 540, 540, 540, 1080, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 1080, 540]
Prompts retrieved: 35793 . Total input tokens: 7921893 . Total output tokens: 7141485
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.3512995070777833,
    "estimated_duration": 3599.626737988787,
    "input_throughput": 810.644328536791,
    "output_throughput": 728.9466911411117,
    "total_throughput": 1539.5910196779028,
    "itl": 21.00313078010692,
    "ttft": 6302.772409890783,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19587121561169607,
    "arrivals": 12061,
    "finished_requests": 12040,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3513935250230134. Arrivals time: 0.04437928460538387 Scheduler time: 0.8915132465772331 Scheduler overhead time: 0.141713363584131 Adapter cache time: 0.06258918810635805 Engine time: 0.14080623537302017 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_64_slots_64_rate_0.1-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_64_slots_64_rate_0.1-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 1080, 1080, 33, 1080, 33, 540, 33, 1080, 540, 1080, 33, 540, 1080, 1080, 1080, 33, 1080, 540, 540, 33, 33, 33, 1080, 33, 33, 33, 1080, 540, 33, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 33, 540, 540, 1080, 1080, 540, 1080, 33, 1080, 540, 540, 540, 1080, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 1080, 540]
Prompts retrieved: 35793 . Total input tokens: 7921893 . Total output tokens: 7141485
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.368000506889075,
    "estimated_duration": 3599.6114946335156,
    "input_throughput": 810.6477613904524,
    "output_throughput": 728.9497780279615,
    "total_throughput": 1539.597539418414,
    "itl": 21.00326870448244,
    "ttft": 6302.820071204005,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2089328175666742,
    "arrivals": 12061,
    "finished_requests": 12040,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.368099451996386. Arrivals time: 0.043985395692288876 Scheduler time: 0.9082594807259738 Scheduler overhead time: 0.14125137403607368 Adapter cache time: 0.06287924060598016 Engine time: 0.1415098332799971 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-32/adapters_64_slots_64_rate_0.1-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-32/adapters_64_slots_64_rate_0.1-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 1080, 1080, 33, 1080, 33, 540, 33, 1080, 540, 1080, 33, 540, 1080, 1080, 1080, 33, 1080, 540, 540, 33, 33, 33, 1080, 33, 33, 33, 1080, 540, 33, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 33, 540, 540, 1080, 1080, 540, 1080, 33, 1080, 540, 540, 540, 1080, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 1080, 540]
Prompts retrieved: 35793 . Total input tokens: 7921893 . Total output tokens: 7141485
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.364736306015402,
    "estimated_duration": 3599.617415641933,
    "input_throughput": 810.6464279564609,
    "output_throughput": 728.9485789789313,
    "total_throughput": 1539.5950069353921,
    "itl": 21.00331702268205,
    "ttft": 6302.786274873003,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20928684858605257,
    "arrivals": 12061,
    "finished_requests": 12040,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3648359891958535. Arrivals time: 0.044123008381575346 Scheduler time: 0.9053068091161549 Scheduler overhead time: 0.14132421975955367 Adapter cache time: 0.06334272399544716 Engine time: 0.14073276659473777 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_64_slots_64_rate_0.1-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_64_slots_64_rate_0.1-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 1080, 1080, 33, 1080, 33, 540, 33, 1080, 540, 1080, 33, 540, 1080, 1080, 1080, 33, 1080, 540, 540, 33, 33, 33, 1080, 33, 33, 33, 1080, 540, 33, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 33, 540, 540, 1080, 1080, 540, 1080, 33, 1080, 540, 540, 540, 1080, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 1080, 540]
Prompts retrieved: 35793 . Total input tokens: 7921893 . Total output tokens: 7141485
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 1.3456633342429996,
    "estimated_duration": 3599.6284610880653,
    "input_throughput": 810.6439404910046,
    "output_throughput": 728.9463422030113,
    "total_throughput": 1539.590282694016,
    "itl": 21.003123318165066,
    "ttft": 6302.8131956356765,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20035231587942695,
    "arrivals": 12061,
    "finished_requests": 12040,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3458049991168082. Arrivals time: 0.043718580622226 Scheduler time: 0.8851773175410926 Scheduler overhead time: 0.1417921781539917 Adapter cache time: 0.0631630546413362 Engine time: 0.14169896999374032 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-32/adapters_64_slots_64_rate_0.1-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-32/adapters_64_slots_64_rate_0.1-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 1080, 1080, 33, 1080, 33, 540, 33, 1080, 540, 1080, 33, 540, 1080, 1080, 1080, 33, 1080, 540, 540, 33, 33, 33, 1080, 33, 33, 33, 1080, 540, 33, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 33, 540, 540, 1080, 1080, 540, 1080, 33, 1080, 540, 540, 540, 1080, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 1080, 540]
Prompts retrieved: 35793 . Total input tokens: 7921893 . Total output tokens: 7141485
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 1.3555237469263375,
    "estimated_duration": 3599.6264607097205,
    "input_throughput": 810.6443909806877,
    "output_throughput": 728.946747291843,
    "total_throughput": 1539.5911382725308,
    "itl": 21.00312573853671,
    "ttft": 6302.725884125086,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21192767810076457,
    "arrivals": 12061,
    "finished_requests": 12040,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3556469180621207. Arrivals time: 0.04467858420684934 Scheduler time: 0.8945332849398255 Scheduler overhead time: 0.14169666543602943 Adapter cache time: 0.0625579827465117 Engine time: 0.14226410072296858 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_64_slots_64_rate_0.1-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_64_slots_64_rate_0.1-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 1080, 1080, 33, 1080, 33, 540, 33, 1080, 540, 1080, 33, 540, 1080, 1080, 1080, 33, 1080, 540, 540, 33, 33, 33, 1080, 33, 33, 33, 1080, 540, 33, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 33, 540, 540, 1080, 1080, 540, 1080, 33, 1080, 540, 540, 540, 1080, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 1080, 540]
Prompts retrieved: 35793 . Total input tokens: 7921893 . Total output tokens: 7141485
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.3691739570349455,
    "estimated_duration": 3599.6268424522427,
    "input_throughput": 810.6443050113782,
    "output_throughput": 728.9466699866161,
    "total_throughput": 1539.5909749979944,
    "itl": 21.003166653218322,
    "ttft": 6302.822016416988,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19136321887373942,
    "arrivals": 12061,
    "finished_requests": 12040,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.36927820276469. Arrivals time: 0.044167852494865656 Scheduler time: 0.9078840226866305 Scheduler overhead time: 0.1419177777133882 Adapter cache time: 0.06304921489208937 Engine time: 0.14160562260076404 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-32/adapters_64_slots_64_rate_0.1-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-32/adapters_64_slots_64_rate_0.1-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 1080, 1080, 33, 1080, 33, 540, 33, 1080, 540, 1080, 33, 540, 1080, 1080, 1080, 33, 1080, 540, 540, 33, 33, 33, 1080, 33, 33, 33, 1080, 540, 33, 1080, 1080, 1080, 1080, 540, 540, 540, 1080, 33, 540, 540, 1080, 1080, 540, 1080, 33, 1080, 540, 540, 540, 1080, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 1080, 540]
Prompts retrieved: 35793 . Total input tokens: 7921893 . Total output tokens: 7141485
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.3724877522327006,
    "estimated_duration": 3599.6266867189015,
    "input_throughput": 810.644340082889,
    "output_throughput": 728.946701523581,
    "total_throughput": 1539.59104160647,
    "itl": 21.003152949696407,
    "ttft": 6302.779986939504,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21469426140189143,
    "arrivals": 12061,
    "finished_requests": 12040,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3726102523505688. Arrivals time: 0.044495505746454 Scheduler time: 0.910887926351279 Scheduler overhead time: 0.14206435671076179 Adapter cache time: 0.0629259580746293 Engine time: 0.14210357470437884 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_64_slots_64_rate_0.1-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_64_slots_64_rate_0.1-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 1080, 1080, 135, 1080, 135, 270, 135, 1080, 270, 1080, 135, 270, 1080, 1080, 1080, 135, 1080, 270, 270, 135, 135, 135, 1080, 135, 135, 135, 1080, 270, 135, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 135, 270, 270, 1080, 1080, 270, 1080, 135, 1080, 270, 270, 270, 1080, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 1080, 270]
Prompts retrieved: 32265 . Total input tokens: 7128362 . Total output tokens: 6458112
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.2720207017846406,
    "estimated_duration": 3599.346056807383,
    "input_throughput": 744.6547116332008,
    "output_throughput": 664.8832766368449,
    "total_throughput": 1409.5379882700456,
    "itl": 20.691395466479797,
    "ttft": 5648.718518042076,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19587121561169607,
    "arrivals": 10900,
    "finished_requests": 10883,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.272104324772954. Arrivals time: 0.04057529242709279 Scheduler time: 0.8155122408643365 Scheduler overhead time: 0.14388009160757065 Adapter cache time: 0.05993626033887267 Engine time: 0.14130979450419545 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_64_slots_64_rate_0.1-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_64_slots_64_rate_0.1-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 1080, 1080, 135, 1080, 135, 270, 135, 1080, 270, 1080, 135, 270, 1080, 1080, 1080, 135, 1080, 270, 270, 135, 135, 135, 1080, 135, 135, 135, 1080, 270, 135, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 135, 270, 270, 1080, 1080, 270, 1080, 135, 1080, 270, 270, 270, 1080, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 1080, 270]
Prompts retrieved: 32265 . Total input tokens: 7128362 . Total output tokens: 6458112
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.283394768834114,
    "estimated_duration": 3599.341520371016,
    "input_throughput": 744.6556501600662,
    "output_throughput": 664.884114623643,
    "total_throughput": 1409.5397647837092,
    "itl": 20.691376909097308,
    "ttft": 5648.717176605633,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2089328175666742,
    "arrivals": 10900,
    "finished_requests": 10883,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2834953619167209. Arrivals time: 0.041121752467006445 Scheduler time: 0.8222918887622654 Scheduler overhead time: 0.1432141992263496 Adapter cache time: 0.05992500297725201 Engine time: 0.14580546086654067 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-32/adapters_64_slots_64_rate_0.1-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-32/adapters_64_slots_64_rate_0.1-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 1080, 1080, 135, 1080, 135, 270, 135, 1080, 270, 1080, 135, 270, 1080, 1080, 1080, 135, 1080, 270, 270, 135, 135, 135, 1080, 135, 135, 135, 1080, 270, 135, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 135, 270, 270, 1080, 1080, 270, 1080, 135, 1080, 270, 270, 270, 1080, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 1080, 270]
Prompts retrieved: 32265 . Total input tokens: 7128362 . Total output tokens: 6458112
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.3068472109735012,
    "estimated_duration": 3599.3415339994226,
    "input_throughput": 744.655647340531,
    "output_throughput": 664.8841121061516,
    "total_throughput": 1409.5397594466826,
    "itl": 20.691385614307954,
    "ttft": 5648.719578818944,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20928684858605254,
    "arrivals": 10900,
    "finished_requests": 10883,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3069485248997808. Arrivals time: 0.04110709438100457 Scheduler time: 0.8411045465618372 Scheduler overhead time: 0.1472968147136271 Adapter cache time: 0.06008771900087595 Engine time: 0.14564503589645028 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_64_slots_64_rate_0.1-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_64_slots_64_rate_0.1-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 1080, 1080, 135, 1080, 135, 270, 135, 1080, 270, 1080, 135, 270, 1080, 1080, 1080, 135, 1080, 270, 270, 135, 135, 135, 1080, 135, 135, 135, 1080, 270, 135, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 135, 270, 270, 1080, 1080, 270, 1080, 135, 1080, 270, 270, 270, 1080, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 1080, 270]
Prompts retrieved: 32265 . Total input tokens: 7128362 . Total output tokens: 6458112
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 1.2789747552014887,
    "estimated_duration": 3599.3532188014847,
    "input_throughput": 744.6532299190349,
    "output_throughput": 664.8819536519039,
    "total_throughput": 1409.5351835709387,
    "itl": 20.69133657212977,
    "ttft": 5648.688313497983,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.200352315879427,
    "arrivals": 10900,
    "finished_requests": 10883,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2790710753761232. Arrivals time: 0.04081273591145873 Scheduler time: 0.8226932985708117 Scheduler overhead time: 0.14278993662446737 Adapter cache time: 0.06005878699943423 Engine time: 0.14165604952722788 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-32/adapters_64_slots_64_rate_0.1-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-32/adapters_64_slots_64_rate_0.1-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 1080, 1080, 135, 1080, 135, 270, 135, 1080, 270, 1080, 135, 270, 1080, 1080, 1080, 135, 1080, 270, 270, 135, 135, 135, 1080, 135, 135, 135, 1080, 270, 135, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 135, 270, 270, 1080, 1080, 270, 1080, 135, 1080, 270, 270, 270, 1080, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 1080, 270]
Prompts retrieved: 32265 . Total input tokens: 7128362 . Total output tokens: 6458112
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 1.2680853847414255,
    "estimated_duration": 3599.3415274150198,
    "input_throughput": 744.6556487027559,
    "output_throughput": 664.8841133224477,
    "total_throughput": 1409.5397620252036,
    "itl": 20.691425360909943,
    "ttft": 5648.7390256777435,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21192767810076457,
    "arrivals": 10900,
    "finished_requests": 10883,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2681777155958116. Arrivals time: 0.040681726299226284 Scheduler time: 0.811975282151252 Scheduler overhead time: 0.1435463484376669 Adapter cache time: 0.0597326853312552 Engine time: 0.1415106006897986 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_64_slots_64_rate_0.1-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_64_slots_64_rate_0.1-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 1080, 1080, 135, 1080, 135, 270, 135, 1080, 270, 1080, 135, 270, 1080, 1080, 1080, 135, 1080, 270, 270, 135, 135, 135, 1080, 135, 135, 135, 1080, 270, 135, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 135, 270, 270, 1080, 1080, 270, 1080, 135, 1080, 270, 270, 270, 1080, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 1080, 270]
Prompts retrieved: 32265 . Total input tokens: 7128362 . Total output tokens: 6458112
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.282136749010533,
    "estimated_duration": 3599.3419900062095,
    "input_throughput": 744.6555529988347,
    "output_throughput": 664.8840278708474,
    "total_throughput": 1409.5395808696821,
    "itl": 20.691310259093505,
    "ttft": 5648.745690132221,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19136321887373942,
    "arrivals": 10900,
    "finished_requests": 10883,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2822215002961457. Arrivals time: 0.040424416307359934 Scheduler time: 0.82653638580814 Scheduler overhead time: 0.14285555109381676 Adapter cache time: 0.05916789220646024 Engine time: 0.14184035640209913 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-32/adapters_64_slots_64_rate_0.1-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-32/adapters_64_slots_64_rate_0.1-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 1080, 1080, 135, 1080, 135, 270, 135, 1080, 270, 1080, 135, 270, 1080, 1080, 1080, 135, 1080, 270, 270, 135, 135, 135, 1080, 135, 135, 135, 1080, 270, 135, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 135, 270, 270, 1080, 1080, 270, 1080, 135, 1080, 270, 270, 270, 1080, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 1080, 270]
Prompts retrieved: 32265 . Total input tokens: 7128362 . Total output tokens: 6458112
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.2934462898410857,
    "estimated_duration": 3599.345786745326,
    "input_throughput": 744.6547675052939,
    "output_throughput": 664.8833265236176,
    "total_throughput": 1409.5380940289115,
    "itl": 20.691545159757613,
    "ttft": 5648.736559371677,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21469426140189146,
    "arrivals": 10900,
    "finished_requests": 10883,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.293597200885415. Arrivals time: 0.04093241086229682 Scheduler time: 0.8387436266057193 Scheduler overhead time: 0.14167861873283982 Adapter cache time: 0.05957452580332756 Engine time: 0.1414076485671103 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_64_slots_64_rate_0.1-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_64_slots_64_rate_0.1-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 1080, 1080, 66, 1080, 66, 270, 66, 1080, 270, 1080, 66, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 1080, 66, 66, 66, 1080, 270, 66, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 66, 270, 270, 1080, 1080, 270, 1080, 66, 1080, 270, 270, 270, 1080, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 1080, 270]
Prompts retrieved: 30816 . Total input tokens: 6815025 . Total output tokens: 6168815
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.232073421124369,
    "estimated_duration": 3599.8716417208652,
    "input_throughput": 705.0326379933741,
    "output_throughput": 628.3246251854519,
    "total_throughput": 1333.3572631788259,
    "itl": 20.3217796089459,
    "ttft": 5925.628733560275,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19587121561169607,
    "arrivals": 10387,
    "finished_requests": 10370,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2321531479246914. Arrivals time: 0.0388903166167438 Scheduler time: 0.780941542237997 Scheduler overhead time: 0.1414902745746076 Adapter cache time: 0.05644880561158061 Engine time: 0.1428893725387752 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_64_slots_64_rate_0.1-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_64_slots_64_rate_0.1-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 1080, 1080, 66, 1080, 66, 270, 66, 1080, 270, 1080, 66, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 1080, 66, 66, 66, 1080, 270, 66, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 66, 270, 270, 1080, 1080, 270, 1080, 66, 1080, 270, 270, 270, 1080, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 1080, 270]
Prompts retrieved: 30816 . Total input tokens: 6815025 . Total output tokens: 6168815
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.2154294769279659,
    "estimated_duration": 3599.8824080195777,
    "input_throughput": 705.0305294267259,
    "output_throughput": 628.3227460322362,
    "total_throughput": 1333.3532754589621,
    "itl": 20.32192465677518,
    "ttft": 5925.605718428898,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20893281756667417,
    "arrivals": 10387,
    "finished_requests": 10370,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2155248378403485. Arrivals time: 0.03829249041154981 Scheduler time: 0.7652232497930527 Scheduler overhead time: 0.14329334255307913 Adapter cache time: 0.05707874149084091 Engine time: 0.13976617297157645 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_64_slots_64_rate_0.1-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_64_slots_64_rate_0.1-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 1080, 1080, 66, 1080, 66, 270, 66, 1080, 270, 1080, 66, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 1080, 66, 66, 66, 1080, 270, 66, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 66, 270, 270, 1080, 1080, 270, 1080, 66, 1080, 270, 270, 270, 1080, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 1080, 270]
Prompts retrieved: 30816 . Total input tokens: 6815025 . Total output tokens: 6168815
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.2268288400955498,
    "estimated_duration": 3599.883322878689,
    "input_throughput": 705.0303502532513,
    "output_throughput": 628.3225863529528,
    "total_throughput": 1333.3529366062041,
    "itl": 20.321869060031258,
    "ttft": 5925.596110510402,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20928684858605254,
    "arrivals": 10387,
    "finished_requests": 10370,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.226918974891305. Arrivals time: 0.03794068796560168 Scheduler time: 0.7759763649664819 Scheduler overhead time: 0.14302082359790802 Adapter cache time: 0.056860094889998436 Engine time: 0.14138993993401527 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_64_slots_64_rate_0.1-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_64_slots_64_rate_0.1-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 1080, 1080, 66, 1080, 66, 270, 66, 1080, 270, 1080, 66, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 1080, 66, 66, 66, 1080, 270, 66, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 66, 270, 270, 1080, 1080, 270, 1080, 66, 1080, 270, 270, 270, 1080, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 1080, 270]
Prompts retrieved: 30816 . Total input tokens: 6815025 . Total output tokens: 6168815
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 1.2474033902399242,
    "estimated_duration": 3599.872391317078,
    "input_throughput": 705.0324911854493,
    "output_throughput": 628.3244943503255,
    "total_throughput": 1333.3569855357748,
    "itl": 20.321447629901236,
    "ttft": 5925.571459394731,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20035231587942695,
    "arrivals": 10387,
    "finished_requests": 10370,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2474991818889976. Arrivals time: 0.039271585177630186 Scheduler time: 0.7945747128687799 Scheduler overhead time: 0.14353349059820175 Adapter cache time: 0.05690336925908923 Engine time: 0.1418966897763312 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_64_slots_64_rate_0.1-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_64_slots_64_rate_0.1-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 1080, 1080, 66, 1080, 66, 270, 66, 1080, 270, 1080, 66, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 1080, 66, 66, 66, 1080, 270, 66, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 66, 270, 270, 1080, 1080, 270, 1080, 66, 1080, 270, 270, 270, 1080, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 1080, 270]
Prompts retrieved: 30816 . Total input tokens: 6815025 . Total output tokens: 6168815
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 1.2422424051910639,
    "estimated_duration": 3599.8621470798826,
    "input_throughput": 705.0344975178517,
    "output_throughput": 628.3262823924484,
    "total_throughput": 1333.3607799103002,
    "itl": 20.32189598602123,
    "ttft": 5925.551543103679,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21192767810076457,
    "arrivals": 10387,
    "finished_requests": 10370,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.242339420132339. Arrivals time: 0.03829969419166446 Scheduler time: 0.7920689820311964 Scheduler overhead time: 0.14231239492073655 Adapter cache time: 0.05671529704704881 Engine time: 0.141418247949332 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_64_slots_64_rate_0.1-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_64_slots_64_rate_0.1-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 1080, 1080, 66, 1080, 66, 270, 66, 1080, 270, 1080, 66, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 1080, 66, 66, 66, 1080, 270, 66, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 66, 270, 270, 1080, 1080, 270, 1080, 66, 1080, 270, 270, 270, 1080, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 1080, 270]
Prompts retrieved: 30816 . Total input tokens: 6815025 . Total output tokens: 6168815
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.2163917892612517,
    "estimated_duration": 3599.883549476808,
    "input_throughput": 705.0303058744403,
    "output_throughput": 628.3225468025856,
    "total_throughput": 1333.352852677026,
    "itl": 20.321550221337972,
    "ttft": 5925.612589619874,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19136321887373942,
    "arrivals": 10387,
    "finished_requests": 10370,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.216472146101296. Arrivals time: 0.03810061188414693 Scheduler time: 0.7650403827428818 Scheduler overhead time: 0.14351036492735147 Adapter cache time: 0.056913635693490505 Engine time: 0.14153002807870507 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_64_slots_64_rate_0.1-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_64_slots_64_rate_0.1-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 1080, 1080, 66, 1080, 66, 270, 66, 1080, 270, 1080, 66, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 1080, 66, 66, 66, 1080, 270, 66, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 66, 270, 270, 1080, 1080, 270, 1080, 66, 1080, 270, 270, 270, 1080, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 1080, 270]
Prompts retrieved: 30816 . Total input tokens: 6815025 . Total output tokens: 6168815
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.2343831220641732,
    "estimated_duration": 3599.8701250546965,
    "input_throughput": 705.0329350316318,
    "output_throughput": 628.3248899057526,
    "total_throughput": 1333.3578249373843,
    "itl": 20.322014806760084,
    "ttft": 5925.590874739452,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21469426140189143,
    "arrivals": 10387,
    "finished_requests": 10370,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2344652712345123. Arrivals time: 0.038701978512108326 Scheduler time: 0.782105365768075 Scheduler overhead time: 0.14358427375555038 Adapter cache time: 0.05682119447737932 Engine time: 0.1413528430275619 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_64_slots_64_rate_0.1-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_64_slots_64_rate_0.1-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 1080, 1080, 33, 1080, 33, 270, 33, 1080, 270, 1080, 33, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 1080, 33, 33, 33, 1080, 270, 33, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 33, 270, 270, 1080, 1080, 270, 1080, 33, 1080, 270, 270, 270, 1080, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 1080, 270]
Prompts retrieved: 30123 . Total input tokens: 6646577 . Total output tokens: 6036268
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.2159131690859795,
    "estimated_duration": 3599.772464305831,
    "input_throughput": 696.3401228425636,
    "output_throughput": 611.9258986066999,
    "total_throughput": 1308.2660214492635,
    "itl": 20.374574486627278,
    "ttft": 5006.794312295059,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19587121561169607,
    "arrivals": 10134,
    "finished_requests": 10120,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.216010362841189. Arrivals time: 0.03860290627926588 Scheduler time: 0.7642961335368454 Scheduler overhead time: 0.14324451331049204 Adapter cache time: 0.05535829532891512 Engine time: 0.14295345358550549 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_64_slots_64_rate_0.1-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_64_slots_64_rate_0.1-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 1080, 1080, 33, 1080, 33, 270, 33, 1080, 270, 1080, 33, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 1080, 33, 33, 33, 1080, 270, 33, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 33, 270, 270, 1080, 1080, 270, 1080, 33, 1080, 270, 270, 270, 1080, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 1080, 270]
Prompts retrieved: 30123 . Total input tokens: 6646577 . Total output tokens: 6036268
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.203364484012127,
    "estimated_duration": 3599.772419866155,
    "input_throughput": 696.3401314389763,
    "output_throughput": 611.9259061610076,
    "total_throughput": 1308.266037599984,
    "itl": 20.37446630694156,
    "ttft": 5006.797885729571,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20893281756667417,
    "arrivals": 10134,
    "finished_requests": 10120,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2034555599093437. Arrivals time: 0.03753693029284477 Scheduler time: 0.7546683973632753 Scheduler overhead time: 0.14377921866253018 Adapter cache time: 0.054721185471862555 Engine time: 0.14111560070887208 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_64_slots_64_rate_0.1-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_64_slots_64_rate_0.1-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 1080, 1080, 33, 1080, 33, 270, 33, 1080, 270, 1080, 33, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 1080, 33, 33, 33, 1080, 270, 33, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 33, 270, 270, 1080, 1080, 270, 1080, 33, 1080, 270, 270, 270, 1080, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 1080, 270]
Prompts retrieved: 30123 . Total input tokens: 6646577 . Total output tokens: 6036268
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.1979037690907717,
    "estimated_duration": 3599.7718599389013,
    "input_throughput": 696.340239751345,
    "output_throughput": 611.9260013431484,
    "total_throughput": 1308.2662410944936,
    "itl": 20.3744331701088,
    "ttft": 5006.823184508975,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20928684858605254,
    "arrivals": 10134,
    "finished_requests": 10120,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1980348778888583. Arrivals time: 0.03804262261837721 Scheduler time: 0.7495758128352463 Scheduler overhead time: 0.14283248269930482 Adapter cache time: 0.05510029150173068 Engine time: 0.14078400935977697 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_64_slots_64_rate_0.1-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_64_slots_64_rate_0.1-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 1080, 1080, 33, 1080, 33, 270, 33, 1080, 270, 1080, 33, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 1080, 33, 33, 33, 1080, 270, 33, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 33, 270, 270, 1080, 1080, 270, 1080, 33, 1080, 270, 270, 270, 1080, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 1080, 270]
Prompts retrieved: 30123 . Total input tokens: 6646577 . Total output tokens: 6036268
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 1.1920921639539301,
    "estimated_duration": 3599.7612176696375,
    "input_throughput": 696.342298399095,
    "output_throughput": 611.9278104301634,
    "total_throughput": 1308.2701088292583,
    "itl": 20.374361711904303,
    "ttft": 5006.900796246073,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20035231587942698,
    "arrivals": 10134,
    "finished_requests": 10120,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.192167205736041. Arrivals time: 0.03723686281591654 Scheduler time: 0.7450694986619055 Scheduler overhead time: 0.14291368890553713 Adapter cache time: 0.05458607478067279 Engine time: 0.14096973044797778 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_64_slots_64_rate_0.1-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_64_slots_64_rate_0.1-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 1080, 1080, 33, 1080, 33, 270, 33, 1080, 270, 1080, 33, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 1080, 33, 33, 33, 1080, 270, 33, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 33, 270, 270, 1080, 1080, 270, 1080, 33, 1080, 270, 270, 270, 1080, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 1080, 270]
Prompts retrieved: 30123 . Total input tokens: 6646577 . Total output tokens: 6036268
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 1.2137501668184996,
    "estimated_duration": 3599.7717799265884,
    "input_throughput": 696.3402552289355,
    "output_throughput": 611.9260149444592,
    "total_throughput": 1308.2662701733948,
    "itl": 20.374663456001066,
    "ttft": 5006.775636054836,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21192767810076454,
    "arrivals": 10134,
    "finished_requests": 10120,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2138283466920257. Arrivals time: 0.037297303788363934 Scheduler time: 0.7653903113678098 Scheduler overhead time: 0.14257442206144333 Adapter cache time: 0.05447930144146085 Engine time: 0.1424557864665985 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_64_slots_64_rate_0.1-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_64_slots_64_rate_0.1-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 1080, 1080, 33, 1080, 33, 270, 33, 1080, 270, 1080, 33, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 1080, 33, 33, 33, 1080, 270, 33, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 33, 270, 270, 1080, 1080, 270, 1080, 33, 1080, 270, 270, 270, 1080, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 1080, 270]
Prompts retrieved: 30123 . Total input tokens: 6646577 . Total output tokens: 6036268
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.2149436553008854,
    "estimated_duration": 3599.7724315006712,
    "input_throughput": 696.3401291883949,
    "output_throughput": 611.9259041832543,
    "total_throughput": 1308.2660333716492,
    "itl": 20.374439308685226,
    "ttft": 5006.7432704320645,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19136321887373942,
    "arrivals": 10134,
    "finished_requests": 10120,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.215038530062884. Arrivals time: 0.038002395536750555 Scheduler time: 0.7666398407891393 Scheduler overhead time: 0.1432955884374678 Adapter cache time: 0.05451176827773452 Engine time: 0.14106059866026044 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_64_slots_64_rate_0.1-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_64_slots_64_rate_0.1-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 1080, 1080, 33, 1080, 33, 270, 33, 1080, 270, 1080, 33, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 1080, 33, 33, 33, 1080, 270, 33, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 33, 270, 270, 1080, 1080, 270, 1080, 33, 1080, 270, 270, 270, 1080, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 1080, 270]
Prompts retrieved: 30123 . Total input tokens: 6646577 . Total output tokens: 6036268
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.1869555828161538,
    "estimated_duration": 3599.7581396043583,
    "input_throughput": 696.3428938243896,
    "output_throughput": 611.9283336746907,
    "total_throughput": 1308.2712274990804,
    "itl": 20.37462858497674,
    "ttft": 5006.842911361898,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21469426140189143,
    "arrivals": 10134,
    "finished_requests": 10120,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1870490428991616. Arrivals time: 0.03684529522433877 Scheduler time: 0.7426280044019222 Scheduler overhead time: 0.1421790225431323 Adapter cache time: 0.05471481382846832 Engine time: 0.1397209200076759 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_64_slots_64_rate_0.1-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_64_slots_64_rate_0.1-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 1080, 1080, 66, 1080, 66, 135, 66, 1080, 135, 1080, 66, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 1080, 66, 66, 66, 1080, 135, 66, 1080, 1080, 1080, 1080, 135, 135, 135, 1080, 66, 135, 135, 1080, 1080, 135, 1080, 66, 1080, 135, 135, 135, 1080, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 1080, 135]
Prompts retrieved: 27981 . Total input tokens: 6178389 . Total output tokens: 5605039
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.1561579052358866,
    "estimated_duration": 3600.000623205674,
    "input_throughput": 640.5515557790656,
    "output_throughput": 574.2521228118941,
    "total_throughput": 1214.8036785909596,
    "itl": 20.099643974764646,
    "ttft": 4978.243816998745,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19587121561169607,
    "arrivals": 9465,
    "finished_requests": 9451,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1562359100207686. Arrivals time: 0.036472554318606853 Scheduler time: 0.7126177912577987 Scheduler overhead time: 0.14272540947422385 Adapter cache time: 0.05157760623842478 Engine time: 0.14141599740833044 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_64_slots_64_rate_0.1-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_64_slots_64_rate_0.1-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 1080, 1080, 66, 1080, 66, 135, 66, 1080, 135, 1080, 66, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 1080, 66, 66, 66, 1080, 135, 66, 1080, 1080, 1080, 1080, 135, 135, 135, 1080, 66, 135, 135, 1080, 1080, 135, 1080, 66, 1080, 135, 135, 135, 1080, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 1080, 135]
Prompts retrieved: 27981 . Total input tokens: 6178389 . Total output tokens: 5605039
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.1695828740485013,
    "estimated_duration": 3600.0107612329743,
    "input_throughput": 640.5497519152467,
    "output_throughput": 574.2505056545897,
    "total_throughput": 1214.8002575698363,
    "itl": 20.09972256750593,
    "ttft": 4978.481635419656,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2089328175666742,
    "arrivals": 9465,
    "finished_requests": 9451,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.169646808411926. Arrivals time: 0.036027316469699144 Scheduler time: 0.7268377668224275 Scheduler overhead time: 0.14252610970288515 Adapter cache time: 0.05106245120987296 Engine time: 0.1416780292056501 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_64_slots_64_rate_0.1-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_64_slots_64_rate_0.1-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 1080, 1080, 66, 1080, 66, 135, 66, 1080, 135, 1080, 66, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 1080, 66, 66, 66, 1080, 135, 66, 1080, 1080, 1080, 1080, 135, 135, 135, 1080, 66, 135, 135, 1080, 1080, 135, 1080, 66, 1080, 135, 135, 135, 1080, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 1080, 135]
Prompts retrieved: 27981 . Total input tokens: 6178389 . Total output tokens: 5605039
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.1684241890907288,
    "estimated_duration": 3600.0107577116637,
    "input_throughput": 640.5497525417933,
    "output_throughput": 574.2505062162865,
    "total_throughput": 1214.8002587580797,
    "itl": 20.099726133592394,
    "ttft": 4978.438043540043,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2092868485860526,
    "arrivals": 9465,
    "finished_requests": 9451,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1684991898946464. Arrivals time: 0.035841458942741156 Scheduler time: 0.7237597233615816 Scheduler overhead time: 0.1436207494698465 Adapter cache time: 0.05183576978743076 Engine time: 0.14217470213770866 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_64_slots_64_rate_0.1-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_64_slots_64_rate_0.1-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 1080, 1080, 66, 1080, 66, 135, 66, 1080, 135, 1080, 66, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 1080, 66, 66, 66, 1080, 135, 66, 1080, 1080, 1080, 1080, 135, 135, 135, 1080, 66, 135, 135, 1080, 1080, 135, 1080, 66, 1080, 135, 135, 135, 1080, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 1080, 135]
Prompts retrieved: 27981 . Total input tokens: 6178389 . Total output tokens: 5605039
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 1.1585331810638309,
    "estimated_duration": 3600.0046407247337,
    "input_throughput": 640.5508409388526,
    "output_throughput": 574.2514819602623,
    "total_throughput": 1214.8023228991149,
    "itl": 20.099733482739417,
    "ttft": 4978.384701903464,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20035231587942698,
    "arrivals": 9465,
    "finished_requests": 9451,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.158635945059359. Arrivals time: 0.03594233747571707 Scheduler time: 0.716497493442148 Scheduler overhead time: 0.1419604392722249 Adapter cache time: 0.0520210568793118 Engine time: 0.1407208670862019 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_64_slots_64_rate_0.1-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_64_slots_64_rate_0.1-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 1080, 1080, 66, 1080, 66, 135, 66, 1080, 135, 1080, 66, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 1080, 66, 66, 66, 1080, 135, 66, 1080, 1080, 1080, 1080, 135, 135, 135, 1080, 66, 135, 135, 1080, 1080, 135, 1080, 66, 1080, 135, 135, 135, 1080, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 1080, 135]
Prompts retrieved: 27981 . Total input tokens: 6178389 . Total output tokens: 5605039
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 1.1521010310389102,
    "estimated_duration": 3600.0121360817698,
    "input_throughput": 640.5495072885561,
    "output_throughput": 574.250286347658,
    "total_throughput": 1214.799793636214,
    "itl": 20.099756910465047,
    "ttft": 4978.407694828421,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2119276781007646,
    "arrivals": 9465,
    "finished_requests": 9451,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1521954010240734. Arrivals time: 0.03553774766623974 Scheduler time: 0.7096378952264786 Scheduler overhead time: 0.14340137830004096 Adapter cache time: 0.05168088199570775 Engine time: 0.14056022791191936 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_64_slots_64_rate_0.1-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_64_slots_64_rate_0.1-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 1080, 1080, 66, 1080, 66, 135, 66, 1080, 135, 1080, 66, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 1080, 66, 66, 66, 1080, 135, 66, 1080, 1080, 1080, 1080, 135, 135, 135, 1080, 66, 135, 135, 1080, 1080, 135, 1080, 66, 1080, 135, 135, 135, 1080, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 1080, 135]
Prompts retrieved: 27981 . Total input tokens: 6178389 . Total output tokens: 5605039
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.1660777097567916,
    "estimated_duration": 3600.012091743979,
    "input_throughput": 640.5495151775713,
    "output_throughput": 574.2502934201311,
    "total_throughput": 1214.7998085977024,
    "itl": 20.099589527224605,
    "ttft": 4978.395490376769,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19136321887373942,
    "arrivals": 9465,
    "finished_requests": 9451,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.166155797895044. Arrivals time: 0.03611599653959274 Scheduler time: 0.7213718956336379 Scheduler overhead time: 0.14274144358932972 Adapter cache time: 0.05201004119589925 Engine time: 0.14211137033998966 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_64_slots_64_rate_0.1-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_64_slots_64_rate_0.1-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 1080, 1080, 66, 1080, 66, 135, 66, 1080, 135, 1080, 66, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 1080, 66, 66, 66, 1080, 135, 66, 1080, 1080, 1080, 1080, 135, 135, 135, 1080, 66, 135, 135, 1080, 1080, 135, 1080, 66, 1080, 135, 135, 135, 1080, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 1080, 135]
Prompts retrieved: 27981 . Total input tokens: 6178389 . Total output tokens: 5605039
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.1650754720903933,
    "estimated_duration": 3600.011163462202,
    "input_throughput": 640.5496803466264,
    "output_throughput": 574.2504414935838,
    "total_throughput": 1214.8001218402103,
    "itl": 19.998453909090934,
    "ttft": 4978.260693842234,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21469426140189146,
    "arrivals": 9465,
    "finished_requests": 9451,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1651577418670058. Arrivals time: 0.035868104081600904 Scheduler time: 0.7182810176163912 Scheduler overhead time: 0.1438361038453877 Adapter cache time: 0.05307237431406975 Engine time: 0.1421453533694148 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_64_slots_64_rate_0.1-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_64_slots_64_rate_0.1-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 1080, 1080, 33, 1080, 33, 135, 33, 1080, 135, 1080, 33, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 1080, 33, 33, 33, 1080, 135, 33, 1080, 1080, 1080, 1080, 135, 135, 135, 1080, 33, 135, 135, 1080, 1080, 135, 1080, 33, 1080, 135, 135, 135, 1080, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 1080, 135]
Prompts retrieved: 27288 . Total input tokens: 6016089 . Total output tokens: 5465738
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.138379284646362,
    "estimated_duration": 3598.9998757246813,
    "input_throughput": 628.6785435202074,
    "output_throughput": 558.4501443183023,
    "total_throughput": 1187.1286878385097,
    "itl": 19.864490558795417,
    "ttft": 7075.729644071935,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19587121561169607,
    "arrivals": 9201,
    "finished_requests": 9183,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.138492798898369. Arrivals time: 0.035944691859185696 Scheduler time: 0.6960984538309276 Scheduler overhead time: 0.1433630520477891 Adapter cache time: 0.051301801577210426 Engine time: 0.139622223097831 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_64_slots_64_rate_0.1-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_64_slots_64_rate_0.1-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 1080, 1080, 33, 1080, 33, 135, 33, 1080, 135, 1080, 33, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 1080, 33, 33, 33, 1080, 135, 33, 1080, 1080, 1080, 1080, 135, 135, 135, 1080, 33, 135, 135, 1080, 1080, 135, 1080, 33, 1080, 135, 135, 135, 1080, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 1080, 135]
Prompts retrieved: 27288 . Total input tokens: 6016089 . Total output tokens: 5465738
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.1519276490435004,
    "estimated_duration": 3598.9916213232655,
    "input_throughput": 628.6799854143837,
    "output_throughput": 558.451425141418,
    "total_throughput": 1187.1314105558017,
    "itl": 19.864801209573276,
    "ttft": 7075.575254498058,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2089328175666742,
    "arrivals": 9201,
    "finished_requests": 9183,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1520600412040949. Arrivals time: 0.0359461666084826 Scheduler time: 0.7050335989333689 Scheduler overhead time: 0.1438671862706542 Adapter cache time: 0.0515617779456079 Engine time: 0.14343118341639638 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_64_slots_64_rate_0.1-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_64_slots_64_rate_0.1-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 1080, 1080, 33, 1080, 33, 135, 33, 1080, 135, 1080, 33, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 1080, 33, 33, 33, 1080, 135, 33, 1080, 1080, 1080, 1080, 135, 135, 135, 1080, 33, 135, 135, 1080, 1080, 135, 1080, 33, 1080, 135, 135, 135, 1080, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 1080, 135]
Prompts retrieved: 27288 . Total input tokens: 6016089 . Total output tokens: 5465738
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.1498153801076114,
    "estimated_duration": 3598.991507466675,
    "input_throughput": 628.6800053031108,
    "output_throughput": 558.4514428084158,
    "total_throughput": 1187.1314481115267,
    "itl": 19.86480306702799,
    "ttft": 7075.5608829390585,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20928684858605254,
    "arrivals": 9201,
    "finished_requests": 9183,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1498976983129978. Arrivals time: 0.0357583099976182 Scheduler time: 0.7013051612302661 Scheduler overhead time: 0.14379123970866203 Adapter cache time: 0.051547333132475615 Engine time: 0.14529713010415435 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_64_slots_64_rate_0.1-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_64_slots_64_rate_0.1-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 1080, 1080, 33, 1080, 33, 135, 33, 1080, 135, 1080, 33, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 1080, 33, 33, 33, 1080, 135, 33, 1080, 1080, 1080, 1080, 135, 135, 135, 1080, 33, 135, 135, 1080, 1080, 135, 1080, 33, 1080, 135, 135, 135, 1080, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 1080, 135]
Prompts retrieved: 27288 . Total input tokens: 6016089 . Total output tokens: 5465738
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 1.154369316995144,
    "estimated_duration": 3599.00299983831,
    "input_throughput": 628.6779977959593,
    "output_throughput": 558.449659555798,
    "total_throughput": 1187.1276573517573,
    "itl": 19.864282288650234,
    "ttft": 7075.683871451038,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20035231587942698,
    "arrivals": 9201,
    "finished_requests": 9183,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1544648986309767. Arrivals time: 0.03581708623096347 Scheduler time: 0.7079970040358603 Scheduler overhead time: 0.14460518723353744 Adapter cache time: 0.05176802724599838 Engine time: 0.1420069895684719 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_64_slots_64_rate_0.1-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_64_slots_64_rate_0.1-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 1080, 1080, 33, 1080, 33, 135, 33, 1080, 135, 1080, 33, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 1080, 33, 33, 33, 1080, 135, 33, 1080, 1080, 1080, 1080, 135, 135, 135, 1080, 33, 135, 135, 1080, 1080, 135, 1080, 33, 1080, 135, 135, 135, 1080, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 1080, 135]
Prompts retrieved: 27288 . Total input tokens: 6016089 . Total output tokens: 5465738
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 1.1374661927111447,
    "estimated_duration": 3598.9951455502232,
    "input_throughput": 628.6793697950615,
    "output_throughput": 558.4508782916758,
    "total_throughput": 1187.1302480867373,
    "itl": 19.86460068944445,
    "ttft": 7075.631922653069,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21192767810076454,
    "arrivals": 9201,
    "finished_requests": 9183,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1375255519524217. Arrivals time: 0.03439949685707688 Scheduler time: 0.6958288638852537 Scheduler overhead time: 0.14326926926150918 Adapter cache time: 0.05114257521927357 Engine time: 0.14056914485991 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_64_slots_64_rate_0.1-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_64_slots_64_rate_0.1-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 1080, 1080, 33, 1080, 33, 135, 33, 1080, 135, 1080, 33, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 1080, 33, 33, 33, 1080, 135, 33, 1080, 1080, 1080, 1080, 135, 135, 135, 1080, 33, 135, 135, 1080, 1080, 135, 1080, 33, 1080, 135, 135, 135, 1080, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 1080, 135]
Prompts retrieved: 27288 . Total input tokens: 6016089 . Total output tokens: 5465738
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.1523798881098628,
    "estimated_duration": 3598.9952519033236,
    "input_throughput": 628.6793512170987,
    "output_throughput": 558.4508617890194,
    "total_throughput": 1187.130213006118,
    "itl": 19.864679660846075,
    "ttft": 7075.671917589327,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19136321887373942,
    "arrivals": 9201,
    "finished_requests": 9183,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1525019728578627. Arrivals time: 0.035439576487988234 Scheduler time: 0.7060204562731087 Scheduler overhead time: 0.14464621990919113 Adapter cache time: 0.05301609728485346 Engine time: 0.14117557043209672 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_64_slots_64_rate_0.1-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_64_slots_64_rate_0.1-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 1080, 1080, 33, 1080, 33, 135, 33, 1080, 135, 1080, 33, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 1080, 33, 33, 33, 1080, 135, 33, 1080, 1080, 1080, 1080, 135, 135, 135, 1080, 33, 135, 135, 1080, 1080, 135, 1080, 33, 1080, 135, 135, 135, 1080, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 1080, 135]
Prompts retrieved: 27288 . Total input tokens: 6016089 . Total output tokens: 5465738
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.1443161820061505,
    "estimated_duration": 3598.9955790001177,
    "input_throughput": 628.6792940792124,
    "output_throughput": 558.45081103389,
    "total_throughput": 1187.1301051131022,
    "itl": 19.86440558882875,
    "ttft": 7075.702539189116,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2146942614018914,
    "arrivals": 9201,
    "finished_requests": 9183,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.144394809845835. Arrivals time: 0.034983934834599495 Scheduler time: 0.6994563364423811 Scheduler overhead time: 0.14366843085736036 Adapter cache time: 0.051940474193543196 Engine time: 0.14236738113686442 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_64_slots_64_rate_0.1-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_64_slots_64_rate_0.1-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 1080, 1080, 33, 1080, 33, 66, 33, 1080, 66, 1080, 33, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 1080, 33, 33, 33, 1080, 66, 33, 1080, 1080, 1080, 1080, 66, 66, 66, 1080, 33, 66, 66, 1080, 1080, 66, 1080, 33, 1080, 66, 66, 66, 1080, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 1080, 66]
Prompts retrieved: 25839 . Total input tokens: 5688973 . Total output tokens: 5166475
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.1211149129085243,
    "estimated_duration": 3599.8027672397516,
    "input_throughput": 596.7218591942749,
    "output_throughput": 526.5082901898244,
    "total_throughput": 1123.2301493840991,
    "itl": 19.67503990368385,
    "ttft": 5790.702410197589,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19587121561169607,
    "arrivals": 8753,
    "finished_requests": 8739,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.12118287011981. Arrivals time: 0.034367434214800596 Scheduler time: 0.6739665814675391 Scheduler overhead time: 0.14606298366561532 Adapter cache time: 0.049365146551281214 Engine time: 0.1447467473335564 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_64_slots_64_rate_0.1-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_64_slots_64_rate_0.1-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 1080, 1080, 33, 1080, 33, 66, 33, 1080, 66, 1080, 33, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 1080, 33, 33, 33, 1080, 66, 33, 1080, 1080, 1080, 1080, 66, 66, 66, 1080, 33, 66, 66, 1080, 1080, 66, 1080, 33, 1080, 66, 66, 66, 1080, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 1080, 66]
Prompts retrieved: 25839 . Total input tokens: 5688973 . Total output tokens: 5166475
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.1158481799066067,
    "estimated_duration": 3599.8156118840025,
    "input_throughput": 596.719730007443,
    "output_throughput": 526.506411534801,
    "total_throughput": 1123.226141542244,
    "itl": 19.675045385087824,
    "ttft": 5790.6774630006985,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20893281756667417,
    "arrivals": 8753,
    "finished_requests": 8739,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1159401969052851. Arrivals time: 0.03401983669027686 Scheduler time: 0.6685188869014382 Scheduler overhead time: 0.14776081824675202 Adapter cache time: 0.048815055284649134 Engine time: 0.14376254053786397 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_64_slots_64_rate_0.1-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_64_slots_64_rate_0.1-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 1080, 1080, 33, 1080, 33, 66, 33, 1080, 66, 1080, 33, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 1080, 33, 33, 33, 1080, 66, 33, 1080, 1080, 1080, 1080, 66, 66, 66, 1080, 33, 66, 66, 1080, 1080, 66, 1080, 33, 1080, 66, 66, 66, 1080, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 1080, 66]
Prompts retrieved: 25839 . Total input tokens: 5688973 . Total output tokens: 5166475
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.095515111926943,
    "estimated_duration": 3599.8156018294667,
    "input_throughput": 596.7197316741227,
    "output_throughput": 526.5064130053701,
    "total_throughput": 1123.2261446794928,
    "itl": 19.675045394318786,
    "ttft": 5790.679464259448,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20928684858605254,
    "arrivals": 8753,
    "finished_requests": 8739,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0955854700878263. Arrivals time: 0.032812963239848614 Scheduler time: 0.6582831921987236 Scheduler overhead time: 0.1444248273037374 Adapter cache time: 0.048571811988949776 Engine time: 0.13938957219943404 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_64_slots_64_rate_0.1-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_64_slots_64_rate_0.1-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 1080, 1080, 33, 1080, 33, 66, 33, 1080, 66, 1080, 33, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 1080, 33, 33, 33, 1080, 66, 33, 1080, 1080, 1080, 1080, 66, 66, 66, 1080, 33, 66, 66, 1080, 1080, 66, 1080, 33, 1080, 66, 66, 66, 1080, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 1080, 66]
Prompts retrieved: 25839 . Total input tokens: 5688973 . Total output tokens: 5166475
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 1.1291629690676928,
    "estimated_duration": 3599.8124785202817,
    "input_throughput": 596.7202494067074,
    "output_throughput": 526.5068698186973,
    "total_throughput": 1123.2271192254047,
    "itl": 19.675077930524882,
    "ttft": 5790.638361360954,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20035231587942698,
    "arrivals": 8753,
    "finished_requests": 8739,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1292418981902301. Arrivals time: 0.03403338370844722 Scheduler time: 0.6817538584582508 Scheduler overhead time: 0.14575025346130133 Adapter cache time: 0.04910768195986748 Engine time: 0.14520874060690403 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_64_slots_64_rate_0.1-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_64_slots_64_rate_0.1-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 1080, 1080, 33, 1080, 33, 66, 33, 1080, 66, 1080, 33, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 1080, 33, 33, 33, 1080, 66, 33, 1080, 1080, 1080, 1080, 66, 66, 66, 1080, 33, 66, 66, 1080, 1080, 66, 1080, 33, 1080, 66, 66, 66, 1080, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 1080, 66]
Prompts retrieved: 25839 . Total input tokens: 5688973 . Total output tokens: 5166475
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 1.117877097800374,
    "estimated_duration": 3599.820344968147,
    "input_throughput": 596.7189454336526,
    "output_throughput": 526.5057192782689,
    "total_throughput": 1123.2246647119214,
    "itl": 19.67517566402857,
    "ttft": 5790.7196746000345,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21192767810076454,
    "arrivals": 8753,
    "finished_requests": 8739,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1179723786190152. Arrivals time: 0.03369097225368023 Scheduler time: 0.672429047524929 Scheduler overhead time: 0.14488018583506346 Adapter cache time: 0.04924833960831165 Engine time: 0.14507305342704058 
