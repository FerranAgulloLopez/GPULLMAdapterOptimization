INFO 06-01 00:47:20 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:47:20 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-8/adapters_384_slots_96_rate_0.8-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-8/adapters_384_slots_96_rate_0.8-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 8640, 1080, 135, 8640, 8640, 135, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 135, 8640, 135, 8640, 1080, 1080, 1080, 135, 135, 1080, 135, 8640, 135, 8640, 1080, 8640, 1080, 135, 1080, 8640, 1080, 8640, 135, 8640, 8640, 8640, 8640, 135, 1080, 1080, 1080, 8640, 1080, 135, 1080, 135, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 135, 135, 8640, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 8640, 135, 1080, 8640, 135, 8640, 1080, 135, 8640, 8640, 8640, 8640, 1080, 135, 1080, 8640, 8640, 1080, 135, 135, 8640, 1080, 1080, 135, 135, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 135, 1080, 1080, 1080, 1080, 135, 135, 8640, 135, 8640, 135, 135, 135, 1080, 1080, 8640, 135, 135, 8640, 135, 8640, 1080, 135, 8640, 1080, 1080, 135, 8640, 8640, 8640, 135, 1080, 8640, 135, 8640, 1080, 1080, 8640, 8640, 135, 1080, 8640, 135, 1080, 1080, 135, 1080, 135, 1080, 8640, 8640, 1080, 135, 8640, 135, 8640, 1080, 1080, 1080, 1080, 1080, 135, 135, 8640, 135, 8640, 135, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 8640, 8640, 135, 135, 8640, 135, 135, 135, 1080, 135, 1080, 8640, 8640, 1080, 1080, 135, 8640, 1080, 8640, 135, 1080, 1080, 135, 135, 1080, 135, 8640, 8640, 135, 8640, 8640, 135, 1080, 8640, 135, 135, 1080, 1080, 135, 135, 8640, 8640, 8640, 8640, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 8640, 1080, 1080, 1080, 8640, 135, 1080, 1080, 8640, 8640, 135, 8640, 8640, 135, 8640, 135, 135, 1080, 135, 8640, 8640, 8640, 1080, 135, 8640, 8640, 1080, 1080, 8640, 8640, 135, 8640, 8640, 1080, 135, 8640, 1080, 1080, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 135, 8640, 135, 1080, 8640, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 8640, 135, 135, 135, 1080, 135, 1080, 1080, 135, 8640, 1080, 8640, 135, 8640, 135, 1080, 1080, 1080, 1080, 135, 1080, 8640, 8640, 135, 8640, 8640, 135, 8640, 1080, 8640, 1080, 1080, 1080, 135, 1080, 135, 135, 8640, 135, 1080, 135, 135, 1080, 8640, 1080, 8640, 135, 8640, 8640, 1080, 8640, 1080, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1261440 . Total input tokens: 281190256 . Total output tokens: 252079041
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 76.18576868716627,
    "estimated_duration": 3600.073629851529,
    "input_throughput": 5287.151585503819,
    "output_throughput": 4684.659185899911,
    "total_throughput": 9971.81077140373,
    "itl": 182.61721358175643,
    "ttft": 1978183.1003503606,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 590,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8056877689203514,
    "arrivals": 420933,
    "finished_requests": 77151,
    "scheduler_time": 135.24516519878355
}
#Debug simulation 
Total elapsed time: 76.18597946502268. Arrivals time: 0.4025334739126265 Scheduler time: 75.62866267049685 Scheduler overhead time: 0.06037530303001404 Adapter cache time: 0.02060374617576599 Engine time: 0.05332428915426135 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-16/adapters_384_slots_96_rate_0.8-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-16/adapters_384_slots_96_rate_0.8-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 8640, 1080, 135, 8640, 8640, 135, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 135, 8640, 135, 8640, 1080, 1080, 1080, 135, 135, 1080, 135, 8640, 135, 8640, 1080, 8640, 1080, 135, 1080, 8640, 1080, 8640, 135, 8640, 8640, 8640, 8640, 135, 1080, 1080, 1080, 8640, 1080, 135, 1080, 135, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 135, 135, 8640, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 8640, 135, 1080, 8640, 135, 8640, 1080, 135, 8640, 8640, 8640, 8640, 1080, 135, 1080, 8640, 8640, 1080, 135, 135, 8640, 1080, 1080, 135, 135, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 135, 1080, 1080, 1080, 1080, 135, 135, 8640, 135, 8640, 135, 135, 135, 1080, 1080, 8640, 135, 135, 8640, 135, 8640, 1080, 135, 8640, 1080, 1080, 135, 8640, 8640, 8640, 135, 1080, 8640, 135, 8640, 1080, 1080, 8640, 8640, 135, 1080, 8640, 135, 1080, 1080, 135, 1080, 135, 1080, 8640, 8640, 1080, 135, 8640, 135, 8640, 1080, 1080, 1080, 1080, 1080, 135, 135, 8640, 135, 8640, 135, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 8640, 8640, 135, 135, 8640, 135, 135, 135, 1080, 135, 1080, 8640, 8640, 1080, 1080, 135, 8640, 1080, 8640, 135, 1080, 1080, 135, 135, 1080, 135, 8640, 8640, 135, 8640, 8640, 135, 1080, 8640, 135, 135, 1080, 1080, 135, 135, 8640, 8640, 8640, 8640, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 8640, 1080, 1080, 1080, 8640, 135, 1080, 1080, 8640, 8640, 135, 8640, 8640, 135, 8640, 135, 135, 1080, 135, 8640, 8640, 8640, 1080, 135, 8640, 8640, 1080, 1080, 8640, 8640, 135, 8640, 8640, 1080, 135, 8640, 1080, 1080, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 135, 8640, 135, 1080, 8640, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 8640, 135, 135, 135, 1080, 135, 1080, 1080, 135, 8640, 1080, 8640, 135, 8640, 135, 1080, 1080, 1080, 1080, 135, 1080, 8640, 8640, 135, 8640, 8640, 135, 8640, 1080, 8640, 1080, 1080, 1080, 135, 1080, 135, 135, 8640, 135, 1080, 135, 135, 1080, 8640, 1080, 8640, 135, 8640, 8640, 1080, 8640, 1080, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1261440 . Total input tokens: 281190256 . Total output tokens: 252079041
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 75.92222454585135,
    "estimated_duration": 3600.1393038852843,
    "input_throughput": 5288.500358709084,
    "output_throughput": 4684.949268990131,
    "total_throughput": 9973.449627699216,
    "itl": 182.62949293384722,
    "ttft": 1978102.566654455,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 585,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9081230013910726,
    "arrivals": 420933,
    "finished_requests": 77162,
    "scheduler_time": 135.24409384969456
}
#Debug simulation 
Total elapsed time: 75.92246842617169. Arrivals time: 0.406024812720716 Scheduler time: 75.36090528406203 Scheduler overhead time: 0.06058767857030034 Adapter cache time: 0.020988148171454668 Engine time: 0.05349293211475015 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-32/adapters_384_slots_96_rate_0.8-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-32/adapters_384_slots_96_rate_0.8-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 8640, 1080, 135, 8640, 8640, 135, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 135, 8640, 135, 8640, 1080, 1080, 1080, 135, 135, 1080, 135, 8640, 135, 8640, 1080, 8640, 1080, 135, 1080, 8640, 1080, 8640, 135, 8640, 8640, 8640, 8640, 135, 1080, 1080, 1080, 8640, 1080, 135, 1080, 135, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 135, 135, 8640, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 8640, 135, 1080, 8640, 135, 8640, 1080, 135, 8640, 8640, 8640, 8640, 1080, 135, 1080, 8640, 8640, 1080, 135, 135, 8640, 1080, 1080, 135, 135, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 135, 1080, 1080, 1080, 1080, 135, 135, 8640, 135, 8640, 135, 135, 135, 1080, 1080, 8640, 135, 135, 8640, 135, 8640, 1080, 135, 8640, 1080, 1080, 135, 8640, 8640, 8640, 135, 1080, 8640, 135, 8640, 1080, 1080, 8640, 8640, 135, 1080, 8640, 135, 1080, 1080, 135, 1080, 135, 1080, 8640, 8640, 1080, 135, 8640, 135, 8640, 1080, 1080, 1080, 1080, 1080, 135, 135, 8640, 135, 8640, 135, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 8640, 8640, 135, 135, 8640, 135, 135, 135, 1080, 135, 1080, 8640, 8640, 1080, 1080, 135, 8640, 1080, 8640, 135, 1080, 1080, 135, 135, 1080, 135, 8640, 8640, 135, 8640, 8640, 135, 1080, 8640, 135, 135, 1080, 1080, 135, 135, 8640, 8640, 8640, 8640, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 8640, 1080, 1080, 1080, 8640, 135, 1080, 1080, 8640, 8640, 135, 8640, 8640, 135, 8640, 135, 135, 1080, 135, 8640, 8640, 8640, 1080, 135, 8640, 8640, 1080, 1080, 8640, 8640, 135, 8640, 8640, 1080, 135, 8640, 1080, 1080, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 135, 8640, 135, 1080, 8640, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 8640, 135, 135, 135, 1080, 135, 1080, 1080, 135, 8640, 1080, 8640, 135, 8640, 135, 1080, 1080, 1080, 1080, 135, 1080, 8640, 8640, 135, 8640, 8640, 135, 8640, 1080, 8640, 1080, 1080, 1080, 135, 1080, 135, 135, 8640, 135, 1080, 135, 135, 1080, 8640, 1080, 8640, 135, 8640, 8640, 1080, 8640, 1080, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1261440 . Total input tokens: 281190256 . Total output tokens: 252079041
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 75.30059302598238,
    "estimated_duration": 3600.140466192891,
    "input_throughput": 5272.769542815647,
    "output_throughput": 4675.155638523967,
    "total_throughput": 9947.925181339615,
    "itl": 180.71756727107342,
    "ttft": 1979952.4652973695,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 595,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9427574853785456,
    "arrivals": 420933,
    "finished_requests": 76962,
    "scheduler_time": 135.75549153872961
}
#Debug simulation 
Total elapsed time: 75.30078591965139. Arrivals time: 0.4253703155554831 Scheduler time: 74.72245217021555 Scheduler overhead time: 0.05974497739225626 Adapter cache time: 0.020452197641134262 Engine time: 0.052728279028087854 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-16/adapters_384_slots_96_rate_0.8-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-16/adapters_384_slots_96_rate_0.8-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 8640, 1080, 135, 8640, 8640, 135, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 135, 8640, 135, 8640, 1080, 1080, 1080, 135, 135, 1080, 135, 8640, 135, 8640, 1080, 8640, 1080, 135, 1080, 8640, 1080, 8640, 135, 8640, 8640, 8640, 8640, 135, 1080, 1080, 1080, 8640, 1080, 135, 1080, 135, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 135, 135, 8640, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 8640, 135, 1080, 8640, 135, 8640, 1080, 135, 8640, 8640, 8640, 8640, 1080, 135, 1080, 8640, 8640, 1080, 135, 135, 8640, 1080, 1080, 135, 135, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 135, 1080, 1080, 1080, 1080, 135, 135, 8640, 135, 8640, 135, 135, 135, 1080, 1080, 8640, 135, 135, 8640, 135, 8640, 1080, 135, 8640, 1080, 1080, 135, 8640, 8640, 8640, 135, 1080, 8640, 135, 8640, 1080, 1080, 8640, 8640, 135, 1080, 8640, 135, 1080, 1080, 135, 1080, 135, 1080, 8640, 8640, 1080, 135, 8640, 135, 8640, 1080, 1080, 1080, 1080, 1080, 135, 135, 8640, 135, 8640, 135, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 8640, 8640, 135, 135, 8640, 135, 135, 135, 1080, 135, 1080, 8640, 8640, 1080, 1080, 135, 8640, 1080, 8640, 135, 1080, 1080, 135, 135, 1080, 135, 8640, 8640, 135, 8640, 8640, 135, 1080, 8640, 135, 135, 1080, 1080, 135, 135, 8640, 8640, 8640, 8640, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 8640, 1080, 1080, 1080, 8640, 135, 1080, 1080, 8640, 8640, 135, 8640, 8640, 135, 8640, 135, 135, 1080, 135, 8640, 8640, 8640, 1080, 135, 8640, 8640, 1080, 1080, 8640, 8640, 135, 8640, 8640, 1080, 135, 8640, 1080, 1080, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 135, 8640, 135, 1080, 8640, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 8640, 135, 135, 135, 1080, 135, 1080, 1080, 135, 8640, 1080, 8640, 135, 8640, 135, 1080, 1080, 1080, 1080, 135, 1080, 8640, 8640, 135, 8640, 8640, 135, 8640, 1080, 8640, 1080, 1080, 1080, 135, 1080, 135, 135, 8640, 135, 1080, 135, 135, 1080, 8640, 1080, 8640, 135, 8640, 8640, 1080, 8640, 1080, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1261440 . Total input tokens: 281190256 . Total output tokens: 252079041
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 76.53559975931421,
    "estimated_duration": 3600.049772440818,
    "input_throughput": 5287.249677966199,
    "output_throughput": 4685.133002637473,
    "total_throughput": 9972.38268060367,
    "itl": 182.64172581245157,
    "ttft": 1977923.006829219,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 580,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8126794721837973,
    "arrivals": 420933,
    "finished_requests": 77138,
    "scheduler_time": 135.24576386111636
}
#Debug simulation 
Total elapsed time: 76.53576100012287. Arrivals time: 0.39948521507903934 Scheduler time: 75.98016849718988 Scheduler overhead time: 0.060713949147611856 Adapter cache time: 0.020284350495785475 Engine time: 0.05403455859050155 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-32/adapters_384_slots_96_rate_0.8-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-32/adapters_384_slots_96_rate_0.8-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 8640, 1080, 135, 8640, 8640, 135, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 135, 8640, 135, 8640, 1080, 1080, 1080, 135, 135, 1080, 135, 8640, 135, 8640, 1080, 8640, 1080, 135, 1080, 8640, 1080, 8640, 135, 8640, 8640, 8640, 8640, 135, 1080, 1080, 1080, 8640, 1080, 135, 1080, 135, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 135, 135, 8640, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 8640, 135, 1080, 8640, 135, 8640, 1080, 135, 8640, 8640, 8640, 8640, 1080, 135, 1080, 8640, 8640, 1080, 135, 135, 8640, 1080, 1080, 135, 135, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 135, 1080, 1080, 1080, 1080, 135, 135, 8640, 135, 8640, 135, 135, 135, 1080, 1080, 8640, 135, 135, 8640, 135, 8640, 1080, 135, 8640, 1080, 1080, 135, 8640, 8640, 8640, 135, 1080, 8640, 135, 8640, 1080, 1080, 8640, 8640, 135, 1080, 8640, 135, 1080, 1080, 135, 1080, 135, 1080, 8640, 8640, 1080, 135, 8640, 135, 8640, 1080, 1080, 1080, 1080, 1080, 135, 135, 8640, 135, 8640, 135, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 8640, 8640, 135, 135, 8640, 135, 135, 135, 1080, 135, 1080, 8640, 8640, 1080, 1080, 135, 8640, 1080, 8640, 135, 1080, 1080, 135, 135, 1080, 135, 8640, 8640, 135, 8640, 8640, 135, 1080, 8640, 135, 135, 1080, 1080, 135, 135, 8640, 8640, 8640, 8640, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 8640, 1080, 1080, 1080, 8640, 135, 1080, 1080, 8640, 8640, 135, 8640, 8640, 135, 8640, 135, 135, 1080, 135, 8640, 8640, 8640, 1080, 135, 8640, 8640, 1080, 1080, 8640, 8640, 135, 8640, 8640, 1080, 135, 8640, 1080, 1080, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 135, 8640, 135, 1080, 8640, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 8640, 135, 135, 135, 1080, 135, 1080, 1080, 135, 8640, 1080, 8640, 135, 8640, 135, 1080, 1080, 1080, 1080, 135, 1080, 8640, 8640, 135, 8640, 8640, 135, 8640, 1080, 8640, 1080, 1080, 1080, 135, 1080, 135, 135, 8640, 135, 1080, 135, 135, 1080, 8640, 1080, 8640, 135, 8640, 8640, 1080, 8640, 1080, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1261440 . Total input tokens: 281190256 . Total output tokens: 252079041
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 74.78205367084593,
    "estimated_duration": 3600.0372654172324,
    "input_throughput": 5270.881827330422,
    "output_throughput": 4672.969405512608,
    "total_throughput": 9943.851232843032,
    "itl": 180.7385516813055,
    "ttft": 1979965.4335552845,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 610,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0200887693837313,
    "arrivals": 420933,
    "finished_requests": 76928,
    "scheduler_time": 135.74306678627295
}
#Debug simulation 
Total elapsed time: 74.78221553284675. Arrivals time: 0.39716012217104435 Scheduler time: 74.22962768329307 Scheduler overhead time: 0.060545241460204124 Adapter cache time: 0.02144406922161579 Engine time: 0.05336380749940872 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-16/adapters_384_slots_96_rate_0.8-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-16/adapters_384_slots_96_rate_0.8-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 8640, 1080, 135, 8640, 8640, 135, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 135, 8640, 135, 8640, 1080, 1080, 1080, 135, 135, 1080, 135, 8640, 135, 8640, 1080, 8640, 1080, 135, 1080, 8640, 1080, 8640, 135, 8640, 8640, 8640, 8640, 135, 1080, 1080, 1080, 8640, 1080, 135, 1080, 135, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 135, 135, 8640, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 8640, 135, 1080, 8640, 135, 8640, 1080, 135, 8640, 8640, 8640, 8640, 1080, 135, 1080, 8640, 8640, 1080, 135, 135, 8640, 1080, 1080, 135, 135, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 135, 1080, 1080, 1080, 1080, 135, 135, 8640, 135, 8640, 135, 135, 135, 1080, 1080, 8640, 135, 135, 8640, 135, 8640, 1080, 135, 8640, 1080, 1080, 135, 8640, 8640, 8640, 135, 1080, 8640, 135, 8640, 1080, 1080, 8640, 8640, 135, 1080, 8640, 135, 1080, 1080, 135, 1080, 135, 1080, 8640, 8640, 1080, 135, 8640, 135, 8640, 1080, 1080, 1080, 1080, 1080, 135, 135, 8640, 135, 8640, 135, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 8640, 8640, 135, 135, 8640, 135, 135, 135, 1080, 135, 1080, 8640, 8640, 1080, 1080, 135, 8640, 1080, 8640, 135, 1080, 1080, 135, 135, 1080, 135, 8640, 8640, 135, 8640, 8640, 135, 1080, 8640, 135, 135, 1080, 1080, 135, 135, 8640, 8640, 8640, 8640, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 8640, 1080, 1080, 1080, 8640, 135, 1080, 1080, 8640, 8640, 135, 8640, 8640, 135, 8640, 135, 135, 1080, 135, 8640, 8640, 8640, 1080, 135, 8640, 8640, 1080, 1080, 8640, 8640, 135, 8640, 8640, 1080, 135, 8640, 1080, 1080, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 135, 8640, 135, 1080, 8640, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 8640, 135, 135, 135, 1080, 135, 1080, 1080, 135, 8640, 1080, 8640, 135, 8640, 135, 1080, 1080, 1080, 1080, 135, 1080, 8640, 8640, 135, 8640, 8640, 135, 8640, 1080, 8640, 1080, 1080, 1080, 135, 1080, 135, 135, 8640, 135, 1080, 135, 135, 1080, 8640, 1080, 8640, 135, 8640, 8640, 1080, 8640, 1080, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1261440 . Total input tokens: 281190256 . Total output tokens: 252079041
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 76.48347234213725,
    "estimated_duration": 3600.0266482996917,
    "input_throughput": 5287.220584600368,
    "output_throughput": 4684.720322269133,
    "total_throughput": 9971.940906869502,
    "itl": 182.6158679311152,
    "ttft": 1978167.9830442495,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 590,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7641296739922578,
    "arrivals": 420933,
    "finished_requests": 77151,
    "scheduler_time": 135.24466582865688
}
#Debug simulation 
Total elapsed time: 76.48363911313936. Arrivals time: 0.41443372052162886 Scheduler time: 75.91415301384404 Scheduler overhead time: 0.06054034177213907 Adapter cache time: 0.020710671320557594 Engine time: 0.053262395318597555 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-32/adapters_384_slots_96_rate_0.8-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-32/adapters_384_slots_96_rate_0.8-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 8640, 1080, 135, 8640, 8640, 135, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 135, 8640, 135, 8640, 1080, 1080, 1080, 135, 135, 1080, 135, 8640, 135, 8640, 1080, 8640, 1080, 135, 1080, 8640, 1080, 8640, 135, 8640, 8640, 8640, 8640, 135, 1080, 1080, 1080, 8640, 1080, 135, 1080, 135, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 135, 135, 8640, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 8640, 135, 1080, 8640, 135, 8640, 1080, 135, 8640, 8640, 8640, 8640, 1080, 135, 1080, 8640, 8640, 1080, 135, 135, 8640, 1080, 1080, 135, 135, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 135, 1080, 1080, 1080, 1080, 135, 135, 8640, 135, 8640, 135, 135, 135, 1080, 1080, 8640, 135, 135, 8640, 135, 8640, 1080, 135, 8640, 1080, 1080, 135, 8640, 8640, 8640, 135, 1080, 8640, 135, 8640, 1080, 1080, 8640, 8640, 135, 1080, 8640, 135, 1080, 1080, 135, 1080, 135, 1080, 8640, 8640, 1080, 135, 8640, 135, 8640, 1080, 1080, 1080, 1080, 1080, 135, 135, 8640, 135, 8640, 135, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 8640, 8640, 135, 135, 8640, 135, 135, 135, 1080, 135, 1080, 8640, 8640, 1080, 1080, 135, 8640, 1080, 8640, 135, 1080, 1080, 135, 135, 1080, 135, 8640, 8640, 135, 8640, 8640, 135, 1080, 8640, 135, 135, 1080, 1080, 135, 135, 8640, 8640, 8640, 8640, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 8640, 1080, 1080, 1080, 8640, 135, 1080, 1080, 8640, 8640, 135, 8640, 8640, 135, 8640, 135, 135, 1080, 135, 8640, 8640, 8640, 1080, 135, 8640, 8640, 1080, 1080, 8640, 8640, 135, 8640, 8640, 1080, 135, 8640, 1080, 1080, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 135, 8640, 135, 1080, 8640, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 8640, 135, 135, 135, 1080, 135, 1080, 1080, 135, 8640, 1080, 8640, 135, 8640, 135, 1080, 1080, 1080, 1080, 135, 1080, 8640, 8640, 135, 8640, 8640, 135, 8640, 1080, 8640, 1080, 1080, 1080, 135, 1080, 135, 135, 8640, 135, 1080, 135, 135, 1080, 8640, 1080, 8640, 135, 8640, 8640, 1080, 8640, 1080, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1261440 . Total input tokens: 281190256 . Total output tokens: 252079041
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 74.86842531012371,
    "estimated_duration": 3600.104482963766,
    "input_throughput": 5271.229235096341,
    "output_throughput": 4673.3182549605835,
    "total_throughput": 9944.547490056924,
    "itl": 180.73620913312837,
    "ttft": 1980054.2730091107,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 615,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.059742612056431,
    "arrivals": 420933,
    "finished_requests": 76939,
    "scheduler_time": 135.74674352541547
}
#Debug simulation 
Total elapsed time: 74.86858254484832. Arrivals time: 0.4355251109227538 Scheduler time: 74.2763749640435 Scheduler overhead time: 0.06040315702557564 Adapter cache time: 0.02150716120377183 Engine time: 0.053762131836265326 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-8/adapters_384_slots_96_rate_0.8-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-8/adapters_384_slots_96_rate_0.8-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 8640, 1080, 66, 8640, 8640, 66, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 66, 8640, 66, 8640, 1080, 1080, 1080, 66, 66, 1080, 66, 8640, 66, 8640, 1080, 8640, 1080, 66, 1080, 8640, 1080, 8640, 66, 8640, 8640, 8640, 8640, 66, 1080, 1080, 1080, 8640, 1080, 66, 1080, 66, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 66, 66, 8640, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 8640, 66, 1080, 8640, 66, 8640, 1080, 66, 8640, 8640, 8640, 8640, 1080, 66, 1080, 8640, 8640, 1080, 66, 66, 8640, 1080, 1080, 66, 66, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 66, 1080, 1080, 1080, 1080, 66, 66, 8640, 66, 8640, 66, 66, 66, 1080, 1080, 8640, 66, 66, 8640, 66, 8640, 1080, 66, 8640, 1080, 1080, 66, 8640, 8640, 8640, 66, 1080, 8640, 66, 8640, 1080, 1080, 8640, 8640, 66, 1080, 8640, 66, 1080, 1080, 66, 1080, 66, 1080, 8640, 8640, 1080, 66, 8640, 66, 8640, 1080, 1080, 1080, 1080, 1080, 66, 66, 8640, 66, 8640, 66, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 8640, 8640, 66, 66, 8640, 66, 66, 66, 1080, 66, 1080, 8640, 8640, 1080, 1080, 66, 8640, 1080, 8640, 66, 1080, 1080, 66, 66, 1080, 66, 8640, 8640, 66, 8640, 8640, 66, 1080, 8640, 66, 66, 1080, 1080, 66, 66, 8640, 8640, 8640, 8640, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 8640, 1080, 1080, 1080, 8640, 66, 1080, 1080, 8640, 8640, 66, 8640, 8640, 66, 8640, 66, 66, 1080, 66, 8640, 8640, 8640, 1080, 66, 8640, 8640, 1080, 1080, 8640, 8640, 66, 8640, 8640, 1080, 66, 8640, 1080, 1080, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 66, 8640, 66, 1080, 8640, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 8640, 66, 66, 66, 1080, 66, 1080, 1080, 66, 8640, 1080, 8640, 66, 8640, 66, 1080, 1080, 1080, 1080, 66, 1080, 8640, 8640, 66, 8640, 8640, 66, 8640, 1080, 8640, 1080, 1080, 1080, 66, 1080, 66, 66, 8640, 66, 1080, 66, 66, 1080, 8640, 1080, 8640, 66, 8640, 8640, 1080, 8640, 1080, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1252608 . Total input tokens: 279232614 . Total output tokens: 250315201
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 75.75347262201831,
    "estimated_duration": 3600.1439101900714,
    "input_throughput": 5289.680489187606,
    "output_throughput": 4683.901371906471,
    "total_throughput": 9973.581861094077,
    "itl": 182.95475169460488,
    "ttft": 1983400.7045021493,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 564,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.726115087578097,
    "arrivals": 418062,
    "finished_requests": 77224,
    "scheduler_time": 135.23309011969343
}
#Debug simulation 
Total elapsed time: 75.75362384086475. Arrivals time: 0.41392560862004757 Scheduler time: 75.18734165187925 Scheduler overhead time: 0.059526517521589994 Adapter cache time: 0.019573919009417295 Engine time: 0.05301171122118831 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-16/adapters_384_slots_96_rate_0.8-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-16/adapters_384_slots_96_rate_0.8-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 8640, 1080, 66, 8640, 8640, 66, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 66, 8640, 66, 8640, 1080, 1080, 1080, 66, 66, 1080, 66, 8640, 66, 8640, 1080, 8640, 1080, 66, 1080, 8640, 1080, 8640, 66, 8640, 8640, 8640, 8640, 66, 1080, 1080, 1080, 8640, 1080, 66, 1080, 66, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 66, 66, 8640, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 8640, 66, 1080, 8640, 66, 8640, 1080, 66, 8640, 8640, 8640, 8640, 1080, 66, 1080, 8640, 8640, 1080, 66, 66, 8640, 1080, 1080, 66, 66, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 66, 1080, 1080, 1080, 1080, 66, 66, 8640, 66, 8640, 66, 66, 66, 1080, 1080, 8640, 66, 66, 8640, 66, 8640, 1080, 66, 8640, 1080, 1080, 66, 8640, 8640, 8640, 66, 1080, 8640, 66, 8640, 1080, 1080, 8640, 8640, 66, 1080, 8640, 66, 1080, 1080, 66, 1080, 66, 1080, 8640, 8640, 1080, 66, 8640, 66, 8640, 1080, 1080, 1080, 1080, 1080, 66, 66, 8640, 66, 8640, 66, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 8640, 8640, 66, 66, 8640, 66, 66, 66, 1080, 66, 1080, 8640, 8640, 1080, 1080, 66, 8640, 1080, 8640, 66, 1080, 1080, 66, 66, 1080, 66, 8640, 8640, 66, 8640, 8640, 66, 1080, 8640, 66, 66, 1080, 1080, 66, 66, 8640, 8640, 8640, 8640, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 8640, 1080, 1080, 1080, 8640, 66, 1080, 1080, 8640, 8640, 66, 8640, 8640, 66, 8640, 66, 66, 1080, 66, 8640, 8640, 8640, 1080, 66, 8640, 8640, 1080, 1080, 8640, 8640, 66, 8640, 8640, 1080, 66, 8640, 1080, 1080, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 66, 8640, 66, 1080, 8640, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 8640, 66, 66, 66, 1080, 66, 1080, 1080, 66, 8640, 1080, 8640, 66, 8640, 66, 1080, 1080, 1080, 1080, 66, 1080, 8640, 8640, 66, 8640, 8640, 66, 8640, 1080, 8640, 1080, 1080, 1080, 66, 1080, 66, 66, 8640, 66, 1080, 66, 66, 1080, 8640, 1080, 8640, 66, 8640, 8640, 1080, 8640, 1080, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1252608 . Total input tokens: 279232614 . Total output tokens: 250315201
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 75.8902522707358,
    "estimated_duration": 3600.062314634158,
    "input_throughput": 5290.038431441795,
    "output_throughput": 4684.367526486479,
    "total_throughput": 9974.405957928275,
    "itl": 182.97504967253525,
    "ttft": 1983443.462101222,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 561,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8285984832630544,
    "arrivals": 418062,
    "finished_requests": 77229,
    "scheduler_time": 135.2220993648966
}
#Debug simulation 
Total elapsed time: 75.89041697792709. Arrivals time: 0.40332402708008885 Scheduler time: 75.33437928976491 Scheduler overhead time: 0.06026831269264221 Adapter cache time: 0.019793958868831396 Engine time: 0.05229230597615242 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-32/adapters_384_slots_96_rate_0.8-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-32/adapters_384_slots_96_rate_0.8-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 8640, 1080, 66, 8640, 8640, 66, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 66, 8640, 66, 8640, 1080, 1080, 1080, 66, 66, 1080, 66, 8640, 66, 8640, 1080, 8640, 1080, 66, 1080, 8640, 1080, 8640, 66, 8640, 8640, 8640, 8640, 66, 1080, 1080, 1080, 8640, 1080, 66, 1080, 66, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 66, 66, 8640, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 8640, 66, 1080, 8640, 66, 8640, 1080, 66, 8640, 8640, 8640, 8640, 1080, 66, 1080, 8640, 8640, 1080, 66, 66, 8640, 1080, 1080, 66, 66, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 66, 1080, 1080, 1080, 1080, 66, 66, 8640, 66, 8640, 66, 66, 66, 1080, 1080, 8640, 66, 66, 8640, 66, 8640, 1080, 66, 8640, 1080, 1080, 66, 8640, 8640, 8640, 66, 1080, 8640, 66, 8640, 1080, 1080, 8640, 8640, 66, 1080, 8640, 66, 1080, 1080, 66, 1080, 66, 1080, 8640, 8640, 1080, 66, 8640, 66, 8640, 1080, 1080, 1080, 1080, 1080, 66, 66, 8640, 66, 8640, 66, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 8640, 8640, 66, 66, 8640, 66, 66, 66, 1080, 66, 1080, 8640, 8640, 1080, 1080, 66, 8640, 1080, 8640, 66, 1080, 1080, 66, 66, 1080, 66, 8640, 8640, 66, 8640, 8640, 66, 1080, 8640, 66, 66, 1080, 1080, 66, 66, 8640, 8640, 8640, 8640, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 8640, 1080, 1080, 1080, 8640, 66, 1080, 1080, 8640, 8640, 66, 8640, 8640, 66, 8640, 66, 66, 1080, 66, 8640, 8640, 8640, 1080, 66, 8640, 8640, 1080, 1080, 8640, 8640, 66, 8640, 8640, 1080, 66, 8640, 1080, 1080, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 66, 8640, 66, 1080, 8640, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 8640, 66, 66, 66, 1080, 66, 1080, 1080, 66, 8640, 1080, 8640, 66, 8640, 66, 1080, 1080, 1080, 1080, 66, 1080, 8640, 8640, 66, 8640, 8640, 66, 8640, 1080, 8640, 1080, 1080, 1080, 66, 1080, 66, 66, 8640, 66, 1080, 66, 66, 1080, 8640, 1080, 8640, 66, 8640, 8640, 1080, 8640, 1080, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1252608 . Total input tokens: 279232614 . Total output tokens: 250315201
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 74.99694898212329,
    "estimated_duration": 3600.055919671344,
    "input_throughput": 5274.080854203331,
    "output_throughput": 4672.0679831927455,
    "total_throughput": 9946.148837396076,
    "itl": 181.11948307699302,
    "ttft": 1985366.023785425,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 560,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8288148807920628,
    "arrivals": 418062,
    "finished_requests": 77008,
    "scheduler_time": 135.74292031729797
}
#Debug simulation 
Total elapsed time: 74.99711968190968. Arrivals time: 0.4267357448115945 Scheduler time: 74.41922293789685 Scheduler overhead time: 0.058237249962985516 Adapter cache time: 0.019949793815612793 Engine time: 0.05273701902478933 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-16/adapters_384_slots_96_rate_0.8-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-16/adapters_384_slots_96_rate_0.8-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 8640, 1080, 66, 8640, 8640, 66, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 66, 8640, 66, 8640, 1080, 1080, 1080, 66, 66, 1080, 66, 8640, 66, 8640, 1080, 8640, 1080, 66, 1080, 8640, 1080, 8640, 66, 8640, 8640, 8640, 8640, 66, 1080, 1080, 1080, 8640, 1080, 66, 1080, 66, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 66, 66, 8640, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 8640, 66, 1080, 8640, 66, 8640, 1080, 66, 8640, 8640, 8640, 8640, 1080, 66, 1080, 8640, 8640, 1080, 66, 66, 8640, 1080, 1080, 66, 66, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 66, 1080, 1080, 1080, 1080, 66, 66, 8640, 66, 8640, 66, 66, 66, 1080, 1080, 8640, 66, 66, 8640, 66, 8640, 1080, 66, 8640, 1080, 1080, 66, 8640, 8640, 8640, 66, 1080, 8640, 66, 8640, 1080, 1080, 8640, 8640, 66, 1080, 8640, 66, 1080, 1080, 66, 1080, 66, 1080, 8640, 8640, 1080, 66, 8640, 66, 8640, 1080, 1080, 1080, 1080, 1080, 66, 66, 8640, 66, 8640, 66, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 8640, 8640, 66, 66, 8640, 66, 66, 66, 1080, 66, 1080, 8640, 8640, 1080, 1080, 66, 8640, 1080, 8640, 66, 1080, 1080, 66, 66, 1080, 66, 8640, 8640, 66, 8640, 8640, 66, 1080, 8640, 66, 66, 1080, 1080, 66, 66, 8640, 8640, 8640, 8640, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 8640, 1080, 1080, 1080, 8640, 66, 1080, 1080, 8640, 8640, 66, 8640, 8640, 66, 8640, 66, 66, 1080, 66, 8640, 8640, 8640, 1080, 66, 8640, 8640, 1080, 1080, 8640, 8640, 66, 8640, 8640, 1080, 66, 8640, 1080, 1080, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 66, 8640, 66, 1080, 8640, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 8640, 66, 66, 66, 1080, 66, 1080, 1080, 66, 8640, 1080, 8640, 66, 8640, 66, 1080, 1080, 1080, 1080, 66, 1080, 8640, 8640, 66, 8640, 8640, 66, 8640, 1080, 8640, 1080, 1080, 1080, 66, 1080, 66, 66, 8640, 66, 1080, 66, 66, 1080, 8640, 1080, 8640, 66, 8640, 8640, 1080, 8640, 1080, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1252608 . Total input tokens: 279232614 . Total output tokens: 250315201
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 75.61467781988904,
    "estimated_duration": 3600.0559962557923,
    "input_throughput": 5289.630222364728,
    "output_throughput": 4683.449928983274,
    "total_throughput": 9973.080151348002,
    "itl": 182.9616886045747,
    "ttft": 1983170.2116210556,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 557,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7414567434904074,
    "arrivals": 418062,
    "finished_requests": 77210,
    "scheduler_time": 135.23166854480854
}
#Debug simulation 
Total elapsed time: 75.6148299719207. Arrivals time: 0.4282446950674057 Scheduler time: 75.03402092028409 Scheduler overhead time: 0.059693449176847935 Adapter cache time: 0.019881208892911673 Engine time: 0.05275663128122687 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-32/adapters_384_slots_96_rate_0.8-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-32/adapters_384_slots_96_rate_0.8-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 8640, 1080, 66, 8640, 8640, 66, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 66, 8640, 66, 8640, 1080, 1080, 1080, 66, 66, 1080, 66, 8640, 66, 8640, 1080, 8640, 1080, 66, 1080, 8640, 1080, 8640, 66, 8640, 8640, 8640, 8640, 66, 1080, 1080, 1080, 8640, 1080, 66, 1080, 66, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 66, 66, 8640, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 8640, 66, 1080, 8640, 66, 8640, 1080, 66, 8640, 8640, 8640, 8640, 1080, 66, 1080, 8640, 8640, 1080, 66, 66, 8640, 1080, 1080, 66, 66, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 66, 1080, 1080, 1080, 1080, 66, 66, 8640, 66, 8640, 66, 66, 66, 1080, 1080, 8640, 66, 66, 8640, 66, 8640, 1080, 66, 8640, 1080, 1080, 66, 8640, 8640, 8640, 66, 1080, 8640, 66, 8640, 1080, 1080, 8640, 8640, 66, 1080, 8640, 66, 1080, 1080, 66, 1080, 66, 1080, 8640, 8640, 1080, 66, 8640, 66, 8640, 1080, 1080, 1080, 1080, 1080, 66, 66, 8640, 66, 8640, 66, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 8640, 8640, 66, 66, 8640, 66, 66, 66, 1080, 66, 1080, 8640, 8640, 1080, 1080, 66, 8640, 1080, 8640, 66, 1080, 1080, 66, 66, 1080, 66, 8640, 8640, 66, 8640, 8640, 66, 1080, 8640, 66, 66, 1080, 1080, 66, 66, 8640, 8640, 8640, 8640, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 8640, 1080, 1080, 1080, 8640, 66, 1080, 1080, 8640, 8640, 66, 8640, 8640, 66, 8640, 66, 66, 1080, 66, 8640, 8640, 8640, 1080, 66, 8640, 8640, 1080, 1080, 8640, 8640, 66, 8640, 8640, 1080, 66, 8640, 1080, 1080, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 66, 8640, 66, 1080, 8640, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 8640, 66, 66, 66, 1080, 66, 1080, 1080, 66, 8640, 1080, 8640, 66, 8640, 66, 1080, 1080, 1080, 1080, 66, 1080, 8640, 8640, 66, 8640, 8640, 66, 8640, 1080, 8640, 1080, 1080, 1080, 66, 1080, 66, 66, 8640, 66, 1080, 66, 66, 1080, 8640, 1080, 8640, 66, 8640, 8640, 1080, 8640, 1080, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1252608 . Total input tokens: 279232614 . Total output tokens: 250315201
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 74.81936723506078,
    "estimated_duration": 3600.196104560356,
    "input_throughput": 5276.503403783273,
    "output_throughput": 4671.515526250424,
    "total_throughput": 9948.018930033697,
    "itl": 180.99610244643443,
    "ttft": 1985755.111348876,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 561,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8549570824764712,
    "arrivals": 418062,
    "finished_requests": 77027,
    "scheduler_time": 135.77834278434304
}
#Debug simulation 
Total elapsed time: 74.81952333077788. Arrivals time: 0.4063610299490392 Scheduler time: 74.25996590405703 Scheduler overhead time: 0.06039615627378225 Adapter cache time: 0.019137054216116667 Engine time: 0.053653760347515345 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-16/adapters_384_slots_96_rate_0.8-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-16/adapters_384_slots_96_rate_0.8-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 8640, 1080, 66, 8640, 8640, 66, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 66, 8640, 66, 8640, 1080, 1080, 1080, 66, 66, 1080, 66, 8640, 66, 8640, 1080, 8640, 1080, 66, 1080, 8640, 1080, 8640, 66, 8640, 8640, 8640, 8640, 66, 1080, 1080, 1080, 8640, 1080, 66, 1080, 66, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 66, 66, 8640, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 8640, 66, 1080, 8640, 66, 8640, 1080, 66, 8640, 8640, 8640, 8640, 1080, 66, 1080, 8640, 8640, 1080, 66, 66, 8640, 1080, 1080, 66, 66, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 66, 1080, 1080, 1080, 1080, 66, 66, 8640, 66, 8640, 66, 66, 66, 1080, 1080, 8640, 66, 66, 8640, 66, 8640, 1080, 66, 8640, 1080, 1080, 66, 8640, 8640, 8640, 66, 1080, 8640, 66, 8640, 1080, 1080, 8640, 8640, 66, 1080, 8640, 66, 1080, 1080, 66, 1080, 66, 1080, 8640, 8640, 1080, 66, 8640, 66, 8640, 1080, 1080, 1080, 1080, 1080, 66, 66, 8640, 66, 8640, 66, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 8640, 8640, 66, 66, 8640, 66, 66, 66, 1080, 66, 1080, 8640, 8640, 1080, 1080, 66, 8640, 1080, 8640, 66, 1080, 1080, 66, 66, 1080, 66, 8640, 8640, 66, 8640, 8640, 66, 1080, 8640, 66, 66, 1080, 1080, 66, 66, 8640, 8640, 8640, 8640, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 8640, 1080, 1080, 1080, 8640, 66, 1080, 1080, 8640, 8640, 66, 8640, 8640, 66, 8640, 66, 66, 1080, 66, 8640, 8640, 8640, 1080, 66, 8640, 8640, 1080, 1080, 8640, 8640, 66, 8640, 8640, 1080, 66, 8640, 1080, 1080, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 66, 8640, 66, 1080, 8640, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 8640, 66, 66, 66, 1080, 66, 1080, 1080, 66, 8640, 1080, 8640, 66, 8640, 66, 1080, 1080, 1080, 1080, 66, 1080, 8640, 8640, 66, 8640, 8640, 66, 8640, 1080, 8640, 1080, 1080, 1080, 66, 1080, 66, 66, 8640, 66, 1080, 66, 66, 1080, 8640, 1080, 8640, 66, 8640, 8640, 1080, 8640, 1080, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1252608 . Total input tokens: 279232614 . Total output tokens: 250315201
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 76.14151949808002,
    "estimated_duration": 3600.0375375771437,
    "input_throughput": 5289.365125013494,
    "output_throughput": 4684.218657161333,
    "total_throughput": 9973.583782174826,
    "itl": 182.974507095834,
    "ttft": 1983444.8180311862,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 562,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.680408265735,
    "arrivals": 418062,
    "finished_requests": 77226,
    "scheduler_time": 135.22457521663392
}
#Debug simulation 
Total elapsed time: 76.14168111700565. Arrivals time: 0.4089691690169275 Scheduler time: 75.58014058507979 Scheduler overhead time: 0.059307627845555544 Adapter cache time: 0.019662485923618078 Engine time: 0.05311937537044287 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-32/adapters_384_slots_96_rate_0.8-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-32/adapters_384_slots_96_rate_0.8-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 8640, 1080, 66, 8640, 8640, 66, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 66, 8640, 66, 8640, 1080, 1080, 1080, 66, 66, 1080, 66, 8640, 66, 8640, 1080, 8640, 1080, 66, 1080, 8640, 1080, 8640, 66, 8640, 8640, 8640, 8640, 66, 1080, 1080, 1080, 8640, 1080, 66, 1080, 66, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 66, 66, 8640, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 8640, 66, 1080, 8640, 66, 8640, 1080, 66, 8640, 8640, 8640, 8640, 1080, 66, 1080, 8640, 8640, 1080, 66, 66, 8640, 1080, 1080, 66, 66, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 66, 1080, 1080, 1080, 1080, 66, 66, 8640, 66, 8640, 66, 66, 66, 1080, 1080, 8640, 66, 66, 8640, 66, 8640, 1080, 66, 8640, 1080, 1080, 66, 8640, 8640, 8640, 66, 1080, 8640, 66, 8640, 1080, 1080, 8640, 8640, 66, 1080, 8640, 66, 1080, 1080, 66, 1080, 66, 1080, 8640, 8640, 1080, 66, 8640, 66, 8640, 1080, 1080, 1080, 1080, 1080, 66, 66, 8640, 66, 8640, 66, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 8640, 8640, 66, 66, 8640, 66, 66, 66, 1080, 66, 1080, 8640, 8640, 1080, 1080, 66, 8640, 1080, 8640, 66, 1080, 1080, 66, 66, 1080, 66, 8640, 8640, 66, 8640, 8640, 66, 1080, 8640, 66, 66, 1080, 1080, 66, 66, 8640, 8640, 8640, 8640, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 8640, 1080, 1080, 1080, 8640, 66, 1080, 1080, 8640, 8640, 66, 8640, 8640, 66, 8640, 66, 66, 1080, 66, 8640, 8640, 8640, 1080, 66, 8640, 8640, 1080, 1080, 8640, 8640, 66, 8640, 8640, 1080, 66, 8640, 1080, 1080, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 66, 8640, 66, 1080, 8640, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 8640, 66, 66, 66, 1080, 66, 1080, 1080, 66, 8640, 1080, 8640, 66, 8640, 66, 1080, 1080, 1080, 1080, 66, 1080, 8640, 8640, 66, 8640, 8640, 66, 8640, 1080, 8640, 1080, 1080, 1080, 66, 1080, 66, 66, 8640, 66, 1080, 66, 66, 1080, 8640, 1080, 8640, 66, 8640, 8640, 1080, 8640, 1080, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1252608 . Total input tokens: 279232614 . Total output tokens: 250315201
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 75.22646322706714,
    "estimated_duration": 3600.0365706285515,
    "input_throughput": 5274.072812178398,
    "output_throughput": 4672.32253617446,
    "total_throughput": 9946.395348352858,
    "itl": 181.1249820238413,
    "ttft": 1985433.9962137647,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 560,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8752180279791317,
    "arrivals": 418062,
    "finished_requests": 77009,
    "scheduler_time": 135.74004042046627
}
#Debug simulation 
Total elapsed time: 75.2266251379624. Arrivals time: 0.4201478767208755 Scheduler time: 74.65405956702307 Scheduler overhead time: 0.05929514346644282 Adapter cache time: 0.019868129398673773 Engine time: 0.05264263227581978 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-8/adapters_384_slots_96_rate_0.8-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-8/adapters_384_slots_96_rate_0.8-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 1080, 33, 8640, 8640, 33, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 33, 8640, 33, 8640, 1080, 1080, 1080, 33, 33, 1080, 33, 8640, 33, 8640, 1080, 8640, 1080, 33, 1080, 8640, 1080, 8640, 33, 8640, 8640, 8640, 8640, 33, 1080, 1080, 1080, 8640, 1080, 33, 1080, 33, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 33, 33, 8640, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 8640, 33, 1080, 8640, 33, 8640, 1080, 33, 8640, 8640, 8640, 8640, 1080, 33, 1080, 8640, 8640, 1080, 33, 33, 8640, 1080, 1080, 33, 33, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 33, 1080, 1080, 1080, 1080, 33, 33, 8640, 33, 8640, 33, 33, 33, 1080, 1080, 8640, 33, 33, 8640, 33, 8640, 1080, 33, 8640, 1080, 1080, 33, 8640, 8640, 8640, 33, 1080, 8640, 33, 8640, 1080, 1080, 8640, 8640, 33, 1080, 8640, 33, 1080, 1080, 33, 1080, 33, 1080, 8640, 8640, 1080, 33, 8640, 33, 8640, 1080, 1080, 1080, 1080, 1080, 33, 33, 8640, 33, 8640, 33, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 8640, 8640, 33, 33, 8640, 33, 33, 33, 1080, 33, 1080, 8640, 8640, 1080, 1080, 33, 8640, 1080, 8640, 33, 1080, 1080, 33, 33, 1080, 33, 8640, 8640, 33, 8640, 8640, 33, 1080, 8640, 33, 33, 1080, 1080, 33, 33, 8640, 8640, 8640, 8640, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 8640, 1080, 1080, 1080, 8640, 33, 1080, 1080, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 1080, 33, 8640, 8640, 8640, 1080, 33, 8640, 8640, 1080, 1080, 8640, 8640, 33, 8640, 8640, 1080, 33, 8640, 1080, 1080, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 1080, 8640, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 8640, 33, 33, 33, 1080, 33, 1080, 1080, 33, 8640, 1080, 8640, 33, 8640, 33, 1080, 1080, 1080, 1080, 33, 1080, 8640, 8640, 33, 8640, 8640, 33, 8640, 1080, 8640, 1080, 1080, 1080, 33, 1080, 33, 33, 8640, 33, 1080, 33, 33, 1080, 8640, 1080, 8640, 33, 8640, 8640, 1080, 8640, 1080, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1248384 . Total input tokens: 278293930 . Total output tokens: 249477165
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 79.98391100903973,
    "estimated_duration": 3600.1110063816013,
    "input_throughput": 5309.562390191994,
    "output_throughput": 4683.588081065058,
    "total_throughput": 9993.150471257053,
    "itl": 182.1215328524805,
    "ttft": 1975964.3733570038,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 489,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4965785067831325,
    "arrivals": 416618,
    "finished_requests": 77209,
    "scheduler_time": 135.40944704963195
}
#Debug simulation 
Total elapsed time: 79.98408496333286. Arrivals time: 0.412860871758312 Scheduler time: 79.42000039760023 Scheduler overhead time: 0.05970524623990059 Adapter cache time: 0.018432918936014175 Engine time: 0.0527213029563427 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-16/adapters_384_slots_96_rate_0.8-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-16/adapters_384_slots_96_rate_0.8-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 1080, 33, 8640, 8640, 33, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 33, 8640, 33, 8640, 1080, 1080, 1080, 33, 33, 1080, 33, 8640, 33, 8640, 1080, 8640, 1080, 33, 1080, 8640, 1080, 8640, 33, 8640, 8640, 8640, 8640, 33, 1080, 1080, 1080, 8640, 1080, 33, 1080, 33, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 33, 33, 8640, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 8640, 33, 1080, 8640, 33, 8640, 1080, 33, 8640, 8640, 8640, 8640, 1080, 33, 1080, 8640, 8640, 1080, 33, 33, 8640, 1080, 1080, 33, 33, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 33, 1080, 1080, 1080, 1080, 33, 33, 8640, 33, 8640, 33, 33, 33, 1080, 1080, 8640, 33, 33, 8640, 33, 8640, 1080, 33, 8640, 1080, 1080, 33, 8640, 8640, 8640, 33, 1080, 8640, 33, 8640, 1080, 1080, 8640, 8640, 33, 1080, 8640, 33, 1080, 1080, 33, 1080, 33, 1080, 8640, 8640, 1080, 33, 8640, 33, 8640, 1080, 1080, 1080, 1080, 1080, 33, 33, 8640, 33, 8640, 33, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 8640, 8640, 33, 33, 8640, 33, 33, 33, 1080, 33, 1080, 8640, 8640, 1080, 1080, 33, 8640, 1080, 8640, 33, 1080, 1080, 33, 33, 1080, 33, 8640, 8640, 33, 8640, 8640, 33, 1080, 8640, 33, 33, 1080, 1080, 33, 33, 8640, 8640, 8640, 8640, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 8640, 1080, 1080, 1080, 8640, 33, 1080, 1080, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 1080, 33, 8640, 8640, 8640, 1080, 33, 8640, 8640, 1080, 1080, 8640, 8640, 33, 8640, 8640, 1080, 33, 8640, 1080, 1080, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 1080, 8640, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 8640, 33, 33, 33, 1080, 33, 1080, 1080, 33, 8640, 1080, 8640, 33, 8640, 33, 1080, 1080, 1080, 1080, 33, 1080, 8640, 8640, 33, 8640, 8640, 33, 8640, 1080, 8640, 1080, 1080, 1080, 33, 1080, 33, 33, 8640, 33, 1080, 33, 33, 1080, 8640, 1080, 8640, 33, 8640, 8640, 1080, 8640, 1080, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1248384 . Total input tokens: 278293930 . Total output tokens: 249477165
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 80.32263268111274,
    "estimated_duration": 3600.1511414057627,
    "input_throughput": 5308.3654683835575,
    "output_throughput": 4682.110927547909,
    "total_throughput": 9990.476395931466,
    "itl": 182.11604272614207,
    "ttft": 1976224.7388887948,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 487,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5897651627473584,
    "arrivals": 416618,
    "finished_requests": 77214,
    "scheduler_time": 135.40482599304028
}
#Debug simulation 
Total elapsed time: 80.32278569927439. Arrivals time: 0.4138218821026385 Scheduler time: 79.75607721460983 Scheduler overhead time: 0.060315417125821114 Adapter cache time: 0.01851648837327957 Engine time: 0.053903873078525066 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-32/adapters_384_slots_96_rate_0.8-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-32/adapters_384_slots_96_rate_0.8-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 1080, 33, 8640, 8640, 33, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 33, 8640, 33, 8640, 1080, 1080, 1080, 33, 33, 1080, 33, 8640, 33, 8640, 1080, 8640, 1080, 33, 1080, 8640, 1080, 8640, 33, 8640, 8640, 8640, 8640, 33, 1080, 1080, 1080, 8640, 1080, 33, 1080, 33, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 33, 33, 8640, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 8640, 33, 1080, 8640, 33, 8640, 1080, 33, 8640, 8640, 8640, 8640, 1080, 33, 1080, 8640, 8640, 1080, 33, 33, 8640, 1080, 1080, 33, 33, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 33, 1080, 1080, 1080, 1080, 33, 33, 8640, 33, 8640, 33, 33, 33, 1080, 1080, 8640, 33, 33, 8640, 33, 8640, 1080, 33, 8640, 1080, 1080, 33, 8640, 8640, 8640, 33, 1080, 8640, 33, 8640, 1080, 1080, 8640, 8640, 33, 1080, 8640, 33, 1080, 1080, 33, 1080, 33, 1080, 8640, 8640, 1080, 33, 8640, 33, 8640, 1080, 1080, 1080, 1080, 1080, 33, 33, 8640, 33, 8640, 33, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 8640, 8640, 33, 33, 8640, 33, 33, 33, 1080, 33, 1080, 8640, 8640, 1080, 1080, 33, 8640, 1080, 8640, 33, 1080, 1080, 33, 33, 1080, 33, 8640, 8640, 33, 8640, 8640, 33, 1080, 8640, 33, 33, 1080, 1080, 33, 33, 8640, 8640, 8640, 8640, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 8640, 1080, 1080, 1080, 8640, 33, 1080, 1080, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 1080, 33, 8640, 8640, 8640, 1080, 33, 8640, 8640, 1080, 1080, 8640, 8640, 33, 8640, 8640, 1080, 33, 8640, 1080, 1080, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 1080, 8640, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 8640, 33, 33, 33, 1080, 33, 1080, 1080, 33, 8640, 1080, 8640, 33, 8640, 33, 1080, 1080, 1080, 1080, 33, 1080, 8640, 8640, 33, 8640, 8640, 33, 8640, 1080, 8640, 1080, 1080, 1080, 33, 1080, 33, 33, 8640, 33, 1080, 33, 33, 1080, 8640, 1080, 8640, 33, 8640, 8640, 1080, 8640, 1080, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1248384 . Total input tokens: 278293930 . Total output tokens: 249477165
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 79.58309085899964,
    "estimated_duration": 3600.0642313916387,
    "input_throughput": 5295.293021100033,
    "output_throughput": 4673.05495643804,
    "total_throughput": 9968.347977538073,
    "itl": 180.3962600281057,
    "ttft": 1977422.09172103,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 495,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6191824933141568,
    "arrivals": 416618,
    "finished_requests": 77025,
    "scheduler_time": 135.88936629350846
}
#Debug simulation 
Total elapsed time: 79.58325118664652. Arrivals time: 0.43795851757749915 Scheduler time: 78.9918392454274 Scheduler overhead time: 0.06016439711675048 Adapter cache time: 0.018665821757167578 Engine time: 0.053803032729774714 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-16/adapters_384_slots_96_rate_0.8-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-16/adapters_384_slots_96_rate_0.8-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 1080, 33, 8640, 8640, 33, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 33, 8640, 33, 8640, 1080, 1080, 1080, 33, 33, 1080, 33, 8640, 33, 8640, 1080, 8640, 1080, 33, 1080, 8640, 1080, 8640, 33, 8640, 8640, 8640, 8640, 33, 1080, 1080, 1080, 8640, 1080, 33, 1080, 33, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 33, 33, 8640, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 8640, 33, 1080, 8640, 33, 8640, 1080, 33, 8640, 8640, 8640, 8640, 1080, 33, 1080, 8640, 8640, 1080, 33, 33, 8640, 1080, 1080, 33, 33, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 33, 1080, 1080, 1080, 1080, 33, 33, 8640, 33, 8640, 33, 33, 33, 1080, 1080, 8640, 33, 33, 8640, 33, 8640, 1080, 33, 8640, 1080, 1080, 33, 8640, 8640, 8640, 33, 1080, 8640, 33, 8640, 1080, 1080, 8640, 8640, 33, 1080, 8640, 33, 1080, 1080, 33, 1080, 33, 1080, 8640, 8640, 1080, 33, 8640, 33, 8640, 1080, 1080, 1080, 1080, 1080, 33, 33, 8640, 33, 8640, 33, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 8640, 8640, 33, 33, 8640, 33, 33, 33, 1080, 33, 1080, 8640, 8640, 1080, 1080, 33, 8640, 1080, 8640, 33, 1080, 1080, 33, 33, 1080, 33, 8640, 8640, 33, 8640, 8640, 33, 1080, 8640, 33, 33, 1080, 1080, 33, 33, 8640, 8640, 8640, 8640, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 8640, 1080, 1080, 1080, 8640, 33, 1080, 1080, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 1080, 33, 8640, 8640, 8640, 1080, 33, 8640, 8640, 1080, 1080, 8640, 8640, 33, 8640, 8640, 1080, 33, 8640, 1080, 1080, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 1080, 8640, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 8640, 33, 33, 33, 1080, 33, 1080, 1080, 33, 8640, 1080, 8640, 33, 8640, 33, 1080, 1080, 1080, 1080, 33, 1080, 8640, 8640, 33, 8640, 8640, 33, 8640, 1080, 8640, 1080, 1080, 1080, 33, 1080, 33, 33, 8640, 33, 1080, 33, 33, 1080, 8640, 1080, 8640, 33, 8640, 8640, 1080, 8640, 1080, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1248384 . Total input tokens: 278293930 . Total output tokens: 249477165
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 80.82377920579165,
    "estimated_duration": 3600.0954755145767,
    "input_throughput": 5306.038167576552,
    "output_throughput": 4682.037494461375,
    "total_throughput": 9988.075662037927,
    "itl": 182.17338267083457,
    "ttft": 1975957.1628568943,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 493,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5443731901585072,
    "arrivals": 416618,
    "finished_requests": 77196,
    "scheduler_time": 135.38811445842543
}
#Debug simulation 
Total elapsed time: 80.82394200377166. Arrivals time: 0.4254200868308544 Scheduler time: 80.24489217158407 Scheduler overhead time: 0.06057873461395502 Adapter cache time: 0.01817259658128023 Engine time: 0.05422540055587888 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-32/adapters_384_slots_96_rate_0.8-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-32/adapters_384_slots_96_rate_0.8-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 1080, 33, 8640, 8640, 33, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 33, 8640, 33, 8640, 1080, 1080, 1080, 33, 33, 1080, 33, 8640, 33, 8640, 1080, 8640, 1080, 33, 1080, 8640, 1080, 8640, 33, 8640, 8640, 8640, 8640, 33, 1080, 1080, 1080, 8640, 1080, 33, 1080, 33, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 33, 33, 8640, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 8640, 33, 1080, 8640, 33, 8640, 1080, 33, 8640, 8640, 8640, 8640, 1080, 33, 1080, 8640, 8640, 1080, 33, 33, 8640, 1080, 1080, 33, 33, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 33, 1080, 1080, 1080, 1080, 33, 33, 8640, 33, 8640, 33, 33, 33, 1080, 1080, 8640, 33, 33, 8640, 33, 8640, 1080, 33, 8640, 1080, 1080, 33, 8640, 8640, 8640, 33, 1080, 8640, 33, 8640, 1080, 1080, 8640, 8640, 33, 1080, 8640, 33, 1080, 1080, 33, 1080, 33, 1080, 8640, 8640, 1080, 33, 8640, 33, 8640, 1080, 1080, 1080, 1080, 1080, 33, 33, 8640, 33, 8640, 33, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 8640, 8640, 33, 33, 8640, 33, 33, 33, 1080, 33, 1080, 8640, 8640, 1080, 1080, 33, 8640, 1080, 8640, 33, 1080, 1080, 33, 33, 1080, 33, 8640, 8640, 33, 8640, 8640, 33, 1080, 8640, 33, 33, 1080, 1080, 33, 33, 8640, 8640, 8640, 8640, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 8640, 1080, 1080, 1080, 8640, 33, 1080, 1080, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 1080, 33, 8640, 8640, 8640, 1080, 33, 8640, 8640, 1080, 1080, 8640, 8640, 33, 8640, 8640, 1080, 33, 8640, 1080, 1080, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 1080, 8640, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 8640, 33, 33, 33, 1080, 33, 1080, 1080, 33, 8640, 1080, 8640, 33, 8640, 33, 1080, 1080, 1080, 1080, 33, 1080, 8640, 8640, 33, 8640, 8640, 33, 8640, 1080, 8640, 1080, 1080, 1080, 33, 1080, 33, 33, 8640, 33, 1080, 33, 33, 1080, 8640, 1080, 8640, 33, 8640, 8640, 1080, 8640, 1080, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1248384 . Total input tokens: 278293930 . Total output tokens: 249477165
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 74.64216278214008,
    "estimated_duration": 3600.0307249789917,
    "input_throughput": 5298.355335595451,
    "output_throughput": 4678.586736255783,
    "total_throughput": 9976.942071851234,
    "itl": 180.9922263934843,
    "ttft": 1977339.0903538137,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 516,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7098704927414694,
    "arrivals": 416618,
    "finished_requests": 77116,
    "scheduler_time": 135.54641096309825
}
#Debug simulation 
Total elapsed time: 74.64232630794868. Arrivals time: 0.41042427252978086 Scheduler time: 74.07870380906388 Scheduler overhead time: 0.059596958104521036 Adapter cache time: 0.019113207701593637 Engine time: 0.05343065224587917 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-16/adapters_384_slots_96_rate_0.8-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-16/adapters_384_slots_96_rate_0.8-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 1080, 33, 8640, 8640, 33, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 33, 8640, 33, 8640, 1080, 1080, 1080, 33, 33, 1080, 33, 8640, 33, 8640, 1080, 8640, 1080, 33, 1080, 8640, 1080, 8640, 33, 8640, 8640, 8640, 8640, 33, 1080, 1080, 1080, 8640, 1080, 33, 1080, 33, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 33, 33, 8640, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 8640, 33, 1080, 8640, 33, 8640, 1080, 33, 8640, 8640, 8640, 8640, 1080, 33, 1080, 8640, 8640, 1080, 33, 33, 8640, 1080, 1080, 33, 33, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 33, 1080, 1080, 1080, 1080, 33, 33, 8640, 33, 8640, 33, 33, 33, 1080, 1080, 8640, 33, 33, 8640, 33, 8640, 1080, 33, 8640, 1080, 1080, 33, 8640, 8640, 8640, 33, 1080, 8640, 33, 8640, 1080, 1080, 8640, 8640, 33, 1080, 8640, 33, 1080, 1080, 33, 1080, 33, 1080, 8640, 8640, 1080, 33, 8640, 33, 8640, 1080, 1080, 1080, 1080, 1080, 33, 33, 8640, 33, 8640, 33, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 8640, 8640, 33, 33, 8640, 33, 33, 33, 1080, 33, 1080, 8640, 8640, 1080, 1080, 33, 8640, 1080, 8640, 33, 1080, 1080, 33, 33, 1080, 33, 8640, 8640, 33, 8640, 8640, 33, 1080, 8640, 33, 33, 1080, 1080, 33, 33, 8640, 8640, 8640, 8640, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 8640, 1080, 1080, 1080, 8640, 33, 1080, 1080, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 1080, 33, 8640, 8640, 8640, 1080, 33, 8640, 8640, 1080, 1080, 8640, 8640, 33, 8640, 8640, 1080, 33, 8640, 1080, 1080, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 1080, 8640, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 8640, 33, 33, 33, 1080, 33, 1080, 1080, 33, 8640, 1080, 8640, 33, 8640, 33, 1080, 1080, 1080, 1080, 33, 1080, 8640, 8640, 33, 8640, 8640, 33, 8640, 1080, 8640, 1080, 1080, 1080, 33, 1080, 33, 33, 8640, 33, 1080, 33, 33, 1080, 8640, 1080, 8640, 33, 8640, 8640, 1080, 8640, 1080, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1248384 . Total input tokens: 278293930 . Total output tokens: 249477165
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 80.47634766809642,
    "estimated_duration": 3600.119028469293,
    "input_throughput": 5307.9233905565825,
    "output_throughput": 4681.594099172368,
    "total_throughput": 9989.51748972895,
    "itl": 182.1028330745073,
    "ttft": 1976054.5059278198,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 485,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4501743930275406,
    "arrivals": 416618,
    "finished_requests": 77204,
    "scheduler_time": 135.40647487225283
}
#Debug simulation 
Total elapsed time: 80.47650696709752. Arrivals time: 0.40647879196330905 Scheduler time: 79.91654071537778 Scheduler overhead time: 0.06063049053773284 Adapter cache time: 0.018431310076266527 Engine time: 0.05370254395529628 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-32/adapters_384_slots_96_rate_0.8-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-32/adapters_384_slots_96_rate_0.8-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 1080, 33, 8640, 8640, 33, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 33, 8640, 33, 8640, 1080, 1080, 1080, 33, 33, 1080, 33, 8640, 33, 8640, 1080, 8640, 1080, 33, 1080, 8640, 1080, 8640, 33, 8640, 8640, 8640, 8640, 33, 1080, 1080, 1080, 8640, 1080, 33, 1080, 33, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 33, 33, 8640, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 8640, 33, 1080, 8640, 33, 8640, 1080, 33, 8640, 8640, 8640, 8640, 1080, 33, 1080, 8640, 8640, 1080, 33, 33, 8640, 1080, 1080, 33, 33, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 8640, 8640, 33, 1080, 1080, 1080, 1080, 33, 33, 8640, 33, 8640, 33, 33, 33, 1080, 1080, 8640, 33, 33, 8640, 33, 8640, 1080, 33, 8640, 1080, 1080, 33, 8640, 8640, 8640, 33, 1080, 8640, 33, 8640, 1080, 1080, 8640, 8640, 33, 1080, 8640, 33, 1080, 1080, 33, 1080, 33, 1080, 8640, 8640, 1080, 33, 8640, 33, 8640, 1080, 1080, 1080, 1080, 1080, 33, 33, 8640, 33, 8640, 33, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 8640, 8640, 33, 33, 8640, 33, 33, 33, 1080, 33, 1080, 8640, 8640, 1080, 1080, 33, 8640, 1080, 8640, 33, 1080, 1080, 33, 33, 1080, 33, 8640, 8640, 33, 8640, 8640, 33, 1080, 8640, 33, 33, 1080, 1080, 33, 33, 8640, 8640, 8640, 8640, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 8640, 1080, 1080, 1080, 8640, 33, 1080, 1080, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 1080, 33, 8640, 8640, 8640, 1080, 33, 8640, 8640, 1080, 1080, 8640, 8640, 33, 8640, 8640, 1080, 33, 8640, 1080, 1080, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 1080, 8640, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 8640, 33, 33, 33, 1080, 33, 1080, 1080, 33, 8640, 1080, 8640, 33, 8640, 33, 1080, 1080, 1080, 1080, 33, 1080, 8640, 8640, 33, 8640, 8640, 33, 8640, 1080, 8640, 1080, 1080, 1080, 33, 1080, 33, 33, 8640, 33, 1080, 33, 33, 1080, 8640, 1080, 8640, 33, 8640, 8640, 1080, 8640, 1080, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1248384 . Total input tokens: 278293930 . Total output tokens: 249477165
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 74.84308568108827,
    "estimated_duration": 3600.0557093672155,
    "input_throughput": 5298.318565007066,
    "output_throughput": 4678.554266861753,
    "total_throughput": 9976.872831868819,
    "itl": 180.99323646990788,
    "ttft": 1977347.7413310509,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 516,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7325061742961385,
    "arrivals": 416618,
    "finished_requests": 77116,
    "scheduler_time": 135.54667130485572
}
#Debug simulation 
Total elapsed time: 74.84324651071802. Arrivals time: 0.41053210478276014 Scheduler time: 74.27797519927844 Scheduler overhead time: 0.061003688257187605 Adapter cache time: 0.019027306232601404 Engine time: 0.05400765920057893 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-8/adapters_384_slots_96_rate_0.8-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-8/adapters_384_slots_96_rate_0.8-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 8640, 540, 270, 8640, 8640, 270, 540, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 270, 8640, 270, 8640, 540, 540, 540, 270, 270, 540, 270, 8640, 270, 8640, 540, 8640, 540, 270, 540, 8640, 540, 8640, 270, 8640, 8640, 8640, 8640, 270, 540, 540, 540, 8640, 540, 270, 540, 270, 8640, 540, 8640, 8640, 540, 8640, 8640, 270, 270, 8640, 540, 540, 270, 270, 270, 540, 270, 540, 270, 8640, 270, 540, 8640, 270, 8640, 540, 270, 8640, 8640, 8640, 8640, 540, 270, 540, 8640, 8640, 540, 270, 270, 8640, 540, 540, 270, 270, 8640, 540, 8640, 540, 8640, 8640, 540, 8640, 8640, 270, 540, 540, 540, 540, 270, 270, 8640, 270, 8640, 270, 270, 270, 540, 540, 8640, 270, 270, 8640, 270, 8640, 540, 270, 8640, 540, 540, 270, 8640, 8640, 8640, 270, 540, 8640, 270, 8640, 540, 540, 8640, 8640, 270, 540, 8640, 270, 540, 540, 270, 540, 270, 540, 8640, 8640, 540, 270, 8640, 270, 8640, 540, 540, 540, 540, 540, 270, 270, 8640, 270, 8640, 270, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 270, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 270, 270, 270, 270, 270, 540, 270, 270, 540, 8640, 8640, 270, 270, 8640, 270, 270, 270, 540, 270, 540, 8640, 8640, 540, 540, 270, 8640, 540, 8640, 270, 540, 540, 270, 270, 540, 270, 8640, 8640, 270, 8640, 8640, 270, 540, 8640, 270, 270, 540, 540, 270, 270, 8640, 8640, 8640, 8640, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 8640, 540, 540, 540, 8640, 270, 540, 540, 8640, 8640, 270, 8640, 8640, 270, 8640, 270, 270, 540, 270, 8640, 8640, 8640, 540, 270, 8640, 8640, 540, 540, 8640, 8640, 270, 8640, 8640, 540, 270, 8640, 540, 540, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 270, 8640, 270, 540, 8640, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 8640, 270, 270, 270, 540, 270, 540, 540, 270, 8640, 540, 8640, 270, 8640, 270, 540, 540, 540, 540, 270, 540, 8640, 8640, 270, 8640, 8640, 270, 8640, 540, 8640, 540, 540, 540, 270, 540, 270, 270, 8640, 270, 540, 270, 270, 540, 8640, 540, 8640, 270, 8640, 8640, 540, 8640, 540, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1209600 . Total input tokens: 269633474 . Total output tokens: 241711905
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 81.81565588479862,
    "estimated_duration": 3600.06869799985,
    "input_throughput": 5379.073185675305,
    "output_throughput": 4678.844603537258,
    "total_throughput": 10057.917789212563,
    "itl": 181.4342570687311,
    "ttft": 1967863.0185179026,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 674,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0627687394107115,
    "arrivals": 403575,
    "finished_requests": 77620,
    "scheduler_time": 135.43359555436075
}
#Debug simulation 
Total elapsed time: 81.81580624170601. Arrivals time: 0.4135649660602212 Scheduler time: 81.2453944273293 Scheduler overhead time: 0.060524262953549623 Adapter cache time: 0.021482294891029596 Engine time: 0.05445984052494168 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-16/adapters_384_slots_96_rate_0.8-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-16/adapters_384_slots_96_rate_0.8-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 8640, 540, 270, 8640, 8640, 270, 540, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 270, 8640, 270, 8640, 540, 540, 540, 270, 270, 540, 270, 8640, 270, 8640, 540, 8640, 540, 270, 540, 8640, 540, 8640, 270, 8640, 8640, 8640, 8640, 270, 540, 540, 540, 8640, 540, 270, 540, 270, 8640, 540, 8640, 8640, 540, 8640, 8640, 270, 270, 8640, 540, 540, 270, 270, 270, 540, 270, 540, 270, 8640, 270, 540, 8640, 270, 8640, 540, 270, 8640, 8640, 8640, 8640, 540, 270, 540, 8640, 8640, 540, 270, 270, 8640, 540, 540, 270, 270, 8640, 540, 8640, 540, 8640, 8640, 540, 8640, 8640, 270, 540, 540, 540, 540, 270, 270, 8640, 270, 8640, 270, 270, 270, 540, 540, 8640, 270, 270, 8640, 270, 8640, 540, 270, 8640, 540, 540, 270, 8640, 8640, 8640, 270, 540, 8640, 270, 8640, 540, 540, 8640, 8640, 270, 540, 8640, 270, 540, 540, 270, 540, 270, 540, 8640, 8640, 540, 270, 8640, 270, 8640, 540, 540, 540, 540, 540, 270, 270, 8640, 270, 8640, 270, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 270, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 270, 270, 270, 270, 270, 540, 270, 270, 540, 8640, 8640, 270, 270, 8640, 270, 270, 270, 540, 270, 540, 8640, 8640, 540, 540, 270, 8640, 540, 8640, 270, 540, 540, 270, 270, 540, 270, 8640, 8640, 270, 8640, 8640, 270, 540, 8640, 270, 270, 540, 540, 270, 270, 8640, 8640, 8640, 8640, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 8640, 540, 540, 540, 8640, 270, 540, 540, 8640, 8640, 270, 8640, 8640, 270, 8640, 270, 270, 540, 270, 8640, 8640, 8640, 540, 270, 8640, 8640, 540, 540, 8640, 8640, 270, 8640, 8640, 540, 270, 8640, 540, 540, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 270, 8640, 270, 540, 8640, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 8640, 270, 270, 270, 540, 270, 540, 540, 270, 8640, 540, 8640, 270, 8640, 270, 540, 540, 540, 540, 270, 540, 8640, 8640, 270, 8640, 8640, 270, 8640, 540, 8640, 540, 540, 540, 270, 540, 270, 270, 8640, 270, 540, 270, 270, 540, 8640, 540, 8640, 270, 8640, 8640, 540, 8640, 540, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1209600 . Total input tokens: 269633474 . Total output tokens: 241711905
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 81.0342799979262,
    "estimated_duration": 3600.1737132994595,
    "input_throughput": 5378.788231374787,
    "output_throughput": 4678.707568408635,
    "total_throughput": 10057.495799783423,
    "itl": 181.44157814207108,
    "ttft": 1967854.8318237492,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 674,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1958930295147043,
    "arrivals": 403575,
    "finished_requests": 77619,
    "scheduler_time": 135.4333973323966
}
#Debug simulation 
Total elapsed time: 81.03443989017978. Arrivals time: 0.4096577954478562 Scheduler time: 80.46928836591542 Scheduler overhead time: 0.06001413846388459 Adapter cache time: 0.021309361327439547 Engine time: 0.05390473594889045 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-32/adapters_384_slots_96_rate_0.8-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-32/adapters_384_slots_96_rate_0.8-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 8640, 540, 270, 8640, 8640, 270, 540, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 270, 8640, 270, 8640, 540, 540, 540, 270, 270, 540, 270, 8640, 270, 8640, 540, 8640, 540, 270, 540, 8640, 540, 8640, 270, 8640, 8640, 8640, 8640, 270, 540, 540, 540, 8640, 540, 270, 540, 270, 8640, 540, 8640, 8640, 540, 8640, 8640, 270, 270, 8640, 540, 540, 270, 270, 270, 540, 270, 540, 270, 8640, 270, 540, 8640, 270, 8640, 540, 270, 8640, 8640, 8640, 8640, 540, 270, 540, 8640, 8640, 540, 270, 270, 8640, 540, 540, 270, 270, 8640, 540, 8640, 540, 8640, 8640, 540, 8640, 8640, 270, 540, 540, 540, 540, 270, 270, 8640, 270, 8640, 270, 270, 270, 540, 540, 8640, 270, 270, 8640, 270, 8640, 540, 270, 8640, 540, 540, 270, 8640, 8640, 8640, 270, 540, 8640, 270, 8640, 540, 540, 8640, 8640, 270, 540, 8640, 270, 540, 540, 270, 540, 270, 540, 8640, 8640, 540, 270, 8640, 270, 8640, 540, 540, 540, 540, 540, 270, 270, 8640, 270, 8640, 270, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 270, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 270, 270, 270, 270, 270, 540, 270, 270, 540, 8640, 8640, 270, 270, 8640, 270, 270, 270, 540, 270, 540, 8640, 8640, 540, 540, 270, 8640, 540, 8640, 270, 540, 540, 270, 270, 540, 270, 8640, 8640, 270, 8640, 8640, 270, 540, 8640, 270, 270, 540, 540, 270, 270, 8640, 8640, 8640, 8640, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 8640, 540, 540, 540, 8640, 270, 540, 540, 8640, 8640, 270, 8640, 8640, 270, 8640, 270, 270, 540, 270, 8640, 8640, 8640, 540, 270, 8640, 8640, 540, 540, 8640, 8640, 270, 8640, 8640, 540, 270, 8640, 540, 540, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 270, 8640, 270, 540, 8640, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 8640, 270, 270, 270, 540, 270, 540, 540, 270, 8640, 540, 8640, 270, 8640, 270, 540, 540, 540, 540, 270, 540, 8640, 8640, 270, 8640, 8640, 270, 8640, 540, 8640, 540, 540, 540, 270, 540, 270, 270, 8640, 270, 540, 270, 270, 540, 8640, 540, 8640, 270, 8640, 8640, 540, 8640, 540, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1209600 . Total input tokens: 269633474 . Total output tokens: 241711905
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 81.38298565940931,
    "estimated_duration": 3600.1704334641636,
    "input_throughput": 5369.126644762889,
    "output_throughput": 4670.993029576913,
    "total_throughput": 10040.119674339801,
    "itl": 180.0843461491524,
    "ttft": 1969394.339219091,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 674,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.200732344146823,
    "arrivals": 403575,
    "finished_requests": 77482,
    "scheduler_time": 135.82183903346882
}
#Debug simulation 
Total elapsed time: 81.38314090622589. Arrivals time: 0.42398666171357036 Scheduler time: 80.80330274952576 Scheduler overhead time: 0.060172831173986197 Adapter cache time: 0.02174956165254116 Engine time: 0.05358027992770076 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-16-16/adapters_384_slots_96_rate_0.8-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-16-16/adapters_384_slots_96_rate_0.8-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 8640, 540, 270, 8640, 8640, 270, 540, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 270, 8640, 270, 8640, 540, 540, 540, 270, 270, 540, 270, 8640, 270, 8640, 540, 8640, 540, 270, 540, 8640, 540, 8640, 270, 8640, 8640, 8640, 8640, 270, 540, 540, 540, 8640, 540, 270, 540, 270, 8640, 540, 8640, 8640, 540, 8640, 8640, 270, 270, 8640, 540, 540, 270, 270, 270, 540, 270, 540, 270, 8640, 270, 540, 8640, 270, 8640, 540, 270, 8640, 8640, 8640, 8640, 540, 270, 540, 8640, 8640, 540, 270, 270, 8640, 540, 540, 270, 270, 8640, 540, 8640, 540, 8640, 8640, 540, 8640, 8640, 270, 540, 540, 540, 540, 270, 270, 8640, 270, 8640, 270, 270, 270, 540, 540, 8640, 270, 270, 8640, 270, 8640, 540, 270, 8640, 540, 540, 270, 8640, 8640, 8640, 270, 540, 8640, 270, 8640, 540, 540, 8640, 8640, 270, 540, 8640, 270, 540, 540, 270, 540, 270, 540, 8640, 8640, 540, 270, 8640, 270, 8640, 540, 540, 540, 540, 540, 270, 270, 8640, 270, 8640, 270, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 270, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 270, 270, 270, 270, 270, 540, 270, 270, 540, 8640, 8640, 270, 270, 8640, 270, 270, 270, 540, 270, 540, 8640, 8640, 540, 540, 270, 8640, 540, 8640, 270, 540, 540, 270, 270, 540, 270, 8640, 8640, 270, 8640, 8640, 270, 540, 8640, 270, 270, 540, 540, 270, 270, 8640, 8640, 8640, 8640, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 8640, 540, 540, 540, 8640, 270, 540, 540, 8640, 8640, 270, 8640, 8640, 270, 8640, 270, 270, 540, 270, 8640, 8640, 8640, 540, 270, 8640, 8640, 540, 540, 8640, 8640, 270, 8640, 8640, 540, 270, 8640, 540, 540, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 270, 8640, 270, 540, 8640, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 8640, 270, 270, 270, 540, 270, 540, 540, 270, 8640, 540, 8640, 270, 8640, 270, 540, 540, 540, 540, 270, 540, 8640, 8640, 270, 8640, 8640, 270, 8640, 540, 8640, 540, 540, 540, 270, 540, 270, 270, 8640, 270, 540, 270, 270, 540, 8640, 540, 8640, 270, 8640, 8640, 540, 8640, 540, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1209600 . Total input tokens: 269633474 . Total output tokens: 241711905
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 81.32929830113426,
    "estimated_duration": 3600.1745554964405,
    "input_throughput": 5380.487168442006,
    "output_throughput": 4678.899520103187,
    "total_throughput": 10059.386688545193,
    "itl": 181.43686912752318,
    "ttft": 1967822.0417591648,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 656,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0464608196914034,
    "arrivals": 403575,
    "finished_requests": 77638,
    "scheduler_time": 135.4378341777985
}
#Debug simulation 
Total elapsed time: 81.32944446802139. Arrivals time: 0.43800776870921254 Scheduler time: 80.73480853857473 Scheduler overhead time: 0.06124113220721483 Adapter cache time: 0.02110012387856841 Engine time: 0.05397537164390087 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-16-32/adapters_384_slots_96_rate_0.8-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-16-32/adapters_384_slots_96_rate_0.8-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 8640, 540, 270, 8640, 8640, 270, 540, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 270, 8640, 270, 8640, 540, 540, 540, 270, 270, 540, 270, 8640, 270, 8640, 540, 8640, 540, 270, 540, 8640, 540, 8640, 270, 8640, 8640, 8640, 8640, 270, 540, 540, 540, 8640, 540, 270, 540, 270, 8640, 540, 8640, 8640, 540, 8640, 8640, 270, 270, 8640, 540, 540, 270, 270, 270, 540, 270, 540, 270, 8640, 270, 540, 8640, 270, 8640, 540, 270, 8640, 8640, 8640, 8640, 540, 270, 540, 8640, 8640, 540, 270, 270, 8640, 540, 540, 270, 270, 8640, 540, 8640, 540, 8640, 8640, 540, 8640, 8640, 270, 540, 540, 540, 540, 270, 270, 8640, 270, 8640, 270, 270, 270, 540, 540, 8640, 270, 270, 8640, 270, 8640, 540, 270, 8640, 540, 540, 270, 8640, 8640, 8640, 270, 540, 8640, 270, 8640, 540, 540, 8640, 8640, 270, 540, 8640, 270, 540, 540, 270, 540, 270, 540, 8640, 8640, 540, 270, 8640, 270, 8640, 540, 540, 540, 540, 540, 270, 270, 8640, 270, 8640, 270, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 270, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 270, 270, 270, 270, 270, 540, 270, 270, 540, 8640, 8640, 270, 270, 8640, 270, 270, 270, 540, 270, 540, 8640, 8640, 540, 540, 270, 8640, 540, 8640, 270, 540, 540, 270, 270, 540, 270, 8640, 8640, 270, 8640, 8640, 270, 540, 8640, 270, 270, 540, 540, 270, 270, 8640, 8640, 8640, 8640, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 8640, 540, 540, 540, 8640, 270, 540, 540, 8640, 8640, 270, 8640, 8640, 270, 8640, 270, 270, 540, 270, 8640, 8640, 8640, 540, 270, 8640, 8640, 540, 540, 8640, 8640, 270, 8640, 8640, 540, 270, 8640, 540, 540, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 270, 8640, 270, 540, 8640, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 8640, 270, 270, 270, 540, 270, 540, 540, 270, 8640, 540, 8640, 270, 8640, 270, 540, 540, 540, 540, 270, 540, 8640, 8640, 270, 8640, 8640, 270, 8640, 540, 8640, 540, 540, 540, 270, 540, 270, 270, 8640, 270, 540, 270, 270, 540, 8640, 540, 8640, 270, 8640, 8640, 540, 8640, 540, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1209600 . Total input tokens: 269633474 . Total output tokens: 241711905
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 81.03751884168014,
    "estimated_duration": 3600.201200076316,
    "input_throughput": 5369.080761261413,
    "output_throughput": 4670.9531121881555,
    "total_throughput": 10040.033873449569,
    "itl": 180.08537287130224,
    "ttft": 1969403.2641192074,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 674,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.229278453662995,
    "arrivals": 403575,
    "finished_requests": 77482,
    "scheduler_time": 135.82209836624955
}
#Debug simulation 
Total elapsed time: 81.03766900999472. Arrivals time: 0.4215687862597406 Scheduler time: 80.45874548703432 Scheduler overhead time: 0.060936347115784883 Adapter cache time: 0.02161009283736348 Engine time: 0.05416293581947684 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_16-16-16/adapters_384_slots_96_rate_0.8-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_16-16-16/adapters_384_slots_96_rate_0.8-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 8640, 540, 270, 8640, 8640, 270, 540, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 270, 8640, 270, 8640, 540, 540, 540, 270, 270, 540, 270, 8640, 270, 8640, 540, 8640, 540, 270, 540, 8640, 540, 8640, 270, 8640, 8640, 8640, 8640, 270, 540, 540, 540, 8640, 540, 270, 540, 270, 8640, 540, 8640, 8640, 540, 8640, 8640, 270, 270, 8640, 540, 540, 270, 270, 270, 540, 270, 540, 270, 8640, 270, 540, 8640, 270, 8640, 540, 270, 8640, 8640, 8640, 8640, 540, 270, 540, 8640, 8640, 540, 270, 270, 8640, 540, 540, 270, 270, 8640, 540, 8640, 540, 8640, 8640, 540, 8640, 8640, 270, 540, 540, 540, 540, 270, 270, 8640, 270, 8640, 270, 270, 270, 540, 540, 8640, 270, 270, 8640, 270, 8640, 540, 270, 8640, 540, 540, 270, 8640, 8640, 8640, 270, 540, 8640, 270, 8640, 540, 540, 8640, 8640, 270, 540, 8640, 270, 540, 540, 270, 540, 270, 540, 8640, 8640, 540, 270, 8640, 270, 8640, 540, 540, 540, 540, 540, 270, 270, 8640, 270, 8640, 270, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 270, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 270, 270, 270, 270, 270, 540, 270, 270, 540, 8640, 8640, 270, 270, 8640, 270, 270, 270, 540, 270, 540, 8640, 8640, 540, 540, 270, 8640, 540, 8640, 270, 540, 540, 270, 270, 540, 270, 8640, 8640, 270, 8640, 8640, 270, 540, 8640, 270, 270, 540, 540, 270, 270, 8640, 8640, 8640, 8640, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 8640, 540, 540, 540, 8640, 270, 540, 540, 8640, 8640, 270, 8640, 8640, 270, 8640, 270, 270, 540, 270, 8640, 8640, 8640, 540, 270, 8640, 8640, 540, 540, 8640, 8640, 270, 8640, 8640, 540, 270, 8640, 540, 540, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 270, 8640, 270, 540, 8640, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 8640, 270, 270, 270, 540, 270, 540, 540, 270, 8640, 540, 8640, 270, 8640, 270, 540, 540, 540, 540, 270, 540, 8640, 8640, 270, 8640, 8640, 270, 8640, 540, 8640, 540, 540, 540, 270, 540, 270, 270, 8640, 270, 540, 270, 270, 540, 8640, 540, 8640, 270, 8640, 8640, 540, 8640, 540, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1209600 . Total input tokens: 269633474 . Total output tokens: 241711905
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 81.86699111806229,
    "estimated_duration": 3600.0157202655973,
    "input_throughput": 5379.024288974868,
    "output_throughput": 4678.912901735132,
    "total_throughput": 10057.93719071,
    "itl": 181.4328819966907,
    "ttft": 1967827.8125581485,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 674,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.015293898764032,
    "arrivals": 403575,
    "finished_requests": 77619,
    "scheduler_time": 135.432778407673
}
#Debug simulation 
Total elapsed time: 81.86715998500586. Arrivals time: 0.6884454083628953 Scheduler time: 81.02276615658775 Scheduler overhead time: 0.060259184800088406 Adapter cache time: 0.02161376317963004 Engine time: 0.053324886597692966 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_16-16-32/adapters_384_slots_96_rate_0.8-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_16-16-32/adapters_384_slots_96_rate_0.8-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 8640, 540, 270, 8640, 8640, 270, 540, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 270, 8640, 270, 8640, 540, 540, 540, 270, 270, 540, 270, 8640, 270, 8640, 540, 8640, 540, 270, 540, 8640, 540, 8640, 270, 8640, 8640, 8640, 8640, 270, 540, 540, 540, 8640, 540, 270, 540, 270, 8640, 540, 8640, 8640, 540, 8640, 8640, 270, 270, 8640, 540, 540, 270, 270, 270, 540, 270, 540, 270, 8640, 270, 540, 8640, 270, 8640, 540, 270, 8640, 8640, 8640, 8640, 540, 270, 540, 8640, 8640, 540, 270, 270, 8640, 540, 540, 270, 270, 8640, 540, 8640, 540, 8640, 8640, 540, 8640, 8640, 270, 540, 540, 540, 540, 270, 270, 8640, 270, 8640, 270, 270, 270, 540, 540, 8640, 270, 270, 8640, 270, 8640, 540, 270, 8640, 540, 540, 270, 8640, 8640, 8640, 270, 540, 8640, 270, 8640, 540, 540, 8640, 8640, 270, 540, 8640, 270, 540, 540, 270, 540, 270, 540, 8640, 8640, 540, 270, 8640, 270, 8640, 540, 540, 540, 540, 540, 270, 270, 8640, 270, 8640, 270, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 270, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 270, 270, 270, 270, 270, 540, 270, 270, 540, 8640, 8640, 270, 270, 8640, 270, 270, 270, 540, 270, 540, 8640, 8640, 540, 540, 270, 8640, 540, 8640, 270, 540, 540, 270, 270, 540, 270, 8640, 8640, 270, 8640, 8640, 270, 540, 8640, 270, 270, 540, 540, 270, 270, 8640, 8640, 8640, 8640, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 8640, 540, 540, 540, 8640, 270, 540, 540, 8640, 8640, 270, 8640, 8640, 270, 8640, 270, 270, 540, 270, 8640, 8640, 8640, 540, 270, 8640, 8640, 540, 540, 8640, 8640, 270, 8640, 8640, 540, 270, 8640, 540, 540, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 270, 8640, 270, 540, 8640, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 8640, 270, 270, 270, 540, 270, 540, 540, 270, 8640, 540, 8640, 270, 8640, 270, 540, 540, 540, 540, 270, 540, 8640, 8640, 270, 8640, 8640, 270, 8640, 540, 8640, 540, 540, 540, 270, 540, 270, 270, 8640, 270, 540, 270, 270, 540, 8640, 540, 8640, 270, 8640, 8640, 540, 8640, 540, 270, 8640, 270, 8640, 8640, 270, 270, 270]
Prompts retrieved: 1209600 . Total input tokens: 269633474 . Total output tokens: 241711905
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 80.51304550515488,
    "estimated_duration": 3600.178171330094,
    "input_throughput": 5370.315601035094,
    "output_throughput": 4671.31075176391,
    "total_throughput": 10041.626352799005,
    "itl": 180.06455162532504,
    "ttft": 1969080.4102788821,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 668,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2367911545932326,
    "arrivals": 403575,
    "finished_requests": 77497,
    "scheduler_time": 135.82486989109893
}
#Debug simulation 
Total elapsed time: 80.51319964276627. Arrivals time: 0.4109960990026593 Scheduler time: 79.9474958810024 Scheduler overhead time: 0.059316596016287804 Adapter cache time: 0.021285891998559237 Engine time: 0.05359441740438342 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-8/adapters_384_slots_96_rate_0.8-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-8/adapters_384_slots_96_rate_0.8-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 8640, 540, 135, 8640, 8640, 135, 540, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 135, 8640, 135, 8640, 540, 540, 540, 135, 135, 540, 135, 8640, 135, 8640, 540, 8640, 540, 135, 540, 8640, 540, 8640, 135, 8640, 8640, 8640, 8640, 135, 540, 540, 540, 8640, 540, 135, 540, 135, 8640, 540, 8640, 8640, 540, 8640, 8640, 135, 135, 8640, 540, 540, 135, 135, 135, 540, 135, 540, 135, 8640, 135, 540, 8640, 135, 8640, 540, 135, 8640, 8640, 8640, 8640, 540, 135, 540, 8640, 8640, 540, 135, 135, 8640, 540, 540, 135, 135, 8640, 540, 8640, 540, 8640, 8640, 540, 8640, 8640, 135, 540, 540, 540, 540, 135, 135, 8640, 135, 8640, 135, 135, 135, 540, 540, 8640, 135, 135, 8640, 135, 8640, 540, 135, 8640, 540, 540, 135, 8640, 8640, 8640, 135, 540, 8640, 135, 8640, 540, 540, 8640, 8640, 135, 540, 8640, 135, 540, 540, 135, 540, 135, 540, 8640, 8640, 540, 135, 8640, 135, 8640, 540, 540, 540, 540, 540, 135, 135, 8640, 135, 8640, 135, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 135, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 135, 135, 135, 135, 135, 540, 135, 135, 540, 8640, 8640, 135, 135, 8640, 135, 135, 135, 540, 135, 540, 8640, 8640, 540, 540, 135, 8640, 540, 8640, 135, 540, 540, 135, 135, 540, 135, 8640, 8640, 135, 8640, 8640, 135, 540, 8640, 135, 135, 540, 540, 135, 135, 8640, 8640, 8640, 8640, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 8640, 540, 540, 540, 8640, 135, 540, 540, 8640, 8640, 135, 8640, 8640, 135, 8640, 135, 135, 540, 135, 8640, 8640, 8640, 540, 135, 8640, 8640, 540, 540, 8640, 8640, 135, 8640, 8640, 540, 135, 8640, 540, 540, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 135, 8640, 135, 540, 8640, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 8640, 135, 135, 135, 540, 135, 540, 540, 135, 8640, 540, 8640, 135, 8640, 135, 540, 540, 540, 540, 135, 540, 8640, 8640, 135, 8640, 8640, 135, 8640, 540, 8640, 540, 540, 540, 135, 540, 135, 135, 8640, 135, 540, 135, 135, 540, 8640, 540, 8640, 135, 8640, 8640, 540, 8640, 540, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1192320 . Total input tokens: 265725538 . Total output tokens: 238232918
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 89.81358449812979,
    "estimated_duration": 3600.2017994698763,
    "input_throughput": 5312.307216449973,
    "output_throughput": 4675.814006447849,
    "total_throughput": 9988.121222897822,
    "itl": 182.00133087881144,
    "ttft": 1956144.7003057734,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 566,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7322360630659628,
    "arrivals": 397780,
    "finished_requests": 77213,
    "scheduler_time": 135.27825216750477
}
#Debug simulation 
Total elapsed time: 89.81374617479742. Arrivals time: 0.4168616342358291 Scheduler time: 89.23896217765287 Scheduler overhead time: 0.0623755706474185 Adapter cache time: 0.019614496733993292 Engine time: 0.05523438658565283 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-16/adapters_384_slots_96_rate_0.8-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-16/adapters_384_slots_96_rate_0.8-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 8640, 540, 135, 8640, 8640, 135, 540, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 135, 8640, 135, 8640, 540, 540, 540, 135, 135, 540, 135, 8640, 135, 8640, 540, 8640, 540, 135, 540, 8640, 540, 8640, 135, 8640, 8640, 8640, 8640, 135, 540, 540, 540, 8640, 540, 135, 540, 135, 8640, 540, 8640, 8640, 540, 8640, 8640, 135, 135, 8640, 540, 540, 135, 135, 135, 540, 135, 540, 135, 8640, 135, 540, 8640, 135, 8640, 540, 135, 8640, 8640, 8640, 8640, 540, 135, 540, 8640, 8640, 540, 135, 135, 8640, 540, 540, 135, 135, 8640, 540, 8640, 540, 8640, 8640, 540, 8640, 8640, 135, 540, 540, 540, 540, 135, 135, 8640, 135, 8640, 135, 135, 135, 540, 540, 8640, 135, 135, 8640, 135, 8640, 540, 135, 8640, 540, 540, 135, 8640, 8640, 8640, 135, 540, 8640, 135, 8640, 540, 540, 8640, 8640, 135, 540, 8640, 135, 540, 540, 135, 540, 135, 540, 8640, 8640, 540, 135, 8640, 135, 8640, 540, 540, 540, 540, 540, 135, 135, 8640, 135, 8640, 135, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 135, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 135, 135, 135, 135, 135, 540, 135, 135, 540, 8640, 8640, 135, 135, 8640, 135, 135, 135, 540, 135, 540, 8640, 8640, 540, 540, 135, 8640, 540, 8640, 135, 540, 540, 135, 135, 540, 135, 8640, 8640, 135, 8640, 8640, 135, 540, 8640, 135, 135, 540, 540, 135, 135, 8640, 8640, 8640, 8640, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 8640, 540, 540, 540, 8640, 135, 540, 540, 8640, 8640, 135, 8640, 8640, 135, 8640, 135, 135, 540, 135, 8640, 8640, 8640, 540, 135, 8640, 8640, 540, 540, 8640, 8640, 135, 8640, 8640, 540, 135, 8640, 540, 540, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 135, 8640, 135, 540, 8640, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 8640, 135, 135, 135, 540, 135, 540, 540, 135, 8640, 540, 8640, 135, 8640, 135, 540, 540, 540, 540, 135, 540, 8640, 8640, 135, 8640, 8640, 135, 8640, 540, 8640, 540, 540, 540, 135, 540, 135, 135, 8640, 135, 540, 135, 135, 540, 8640, 540, 8640, 135, 8640, 8640, 540, 8640, 540, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1192320 . Total input tokens: 265725538 . Total output tokens: 238232918
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 90.37487155385315,
    "estimated_duration": 3600.1850383280726,
    "input_throughput": 5312.819423549032,
    "output_throughput": 4674.900823379927,
    "total_throughput": 9987.720246928959,
    "itl": 182.0054131162846,
    "ttft": 1956119.675803339,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 554,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8064423452434182,
    "arrivals": 397780,
    "finished_requests": 77214,
    "scheduler_time": 135.28190417185147
}
#Debug simulation 
Total elapsed time: 90.37502308515832. Arrivals time: 0.44054785277694464 Scheduler time: 89.7744618607685 Scheduler overhead time: 0.06440865574404597 Adapter cache time: 0.01948209572583437 Engine time: 0.05527530610561371 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-32/adapters_384_slots_96_rate_0.8-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-32/adapters_384_slots_96_rate_0.8-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 8640, 540, 135, 8640, 8640, 135, 540, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 135, 8640, 135, 8640, 540, 540, 540, 135, 135, 540, 135, 8640, 135, 8640, 540, 8640, 540, 135, 540, 8640, 540, 8640, 135, 8640, 8640, 8640, 8640, 135, 540, 540, 540, 8640, 540, 135, 540, 135, 8640, 540, 8640, 8640, 540, 8640, 8640, 135, 135, 8640, 540, 540, 135, 135, 135, 540, 135, 540, 135, 8640, 135, 540, 8640, 135, 8640, 540, 135, 8640, 8640, 8640, 8640, 540, 135, 540, 8640, 8640, 540, 135, 135, 8640, 540, 540, 135, 135, 8640, 540, 8640, 540, 8640, 8640, 540, 8640, 8640, 135, 540, 540, 540, 540, 135, 135, 8640, 135, 8640, 135, 135, 135, 540, 540, 8640, 135, 135, 8640, 135, 8640, 540, 135, 8640, 540, 540, 135, 8640, 8640, 8640, 135, 540, 8640, 135, 8640, 540, 540, 8640, 8640, 135, 540, 8640, 135, 540, 540, 135, 540, 135, 540, 8640, 8640, 540, 135, 8640, 135, 8640, 540, 540, 540, 540, 540, 135, 135, 8640, 135, 8640, 135, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 135, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 135, 135, 135, 135, 135, 540, 135, 135, 540, 8640, 8640, 135, 135, 8640, 135, 135, 135, 540, 135, 540, 8640, 8640, 540, 540, 135, 8640, 540, 8640, 135, 540, 540, 135, 135, 540, 135, 8640, 8640, 135, 8640, 8640, 135, 540, 8640, 135, 135, 540, 540, 135, 135, 8640, 8640, 8640, 8640, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 8640, 540, 540, 540, 8640, 135, 540, 540, 8640, 8640, 135, 8640, 8640, 135, 8640, 135, 135, 540, 135, 8640, 8640, 8640, 540, 135, 8640, 8640, 540, 540, 8640, 8640, 135, 8640, 8640, 540, 135, 8640, 540, 540, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 135, 8640, 135, 540, 8640, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 8640, 135, 135, 135, 540, 135, 540, 540, 135, 8640, 540, 8640, 135, 8640, 135, 540, 540, 540, 540, 135, 540, 8640, 8640, 135, 8640, 8640, 135, 8640, 540, 8640, 540, 540, 540, 135, 540, 135, 135, 8640, 135, 540, 135, 135, 540, 8640, 540, 8640, 135, 8640, 8640, 540, 8640, 540, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1192320 . Total input tokens: 265725538 . Total output tokens: 238232918
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 89.20489691663533,
    "estimated_duration": 3600.151635266575,
    "input_throughput": 5299.916207164751,
    "output_throughput": 4667.263688396232,
    "total_throughput": 9967.179895560983,
    "itl": 180.3908646325807,
    "ttft": 1956528.4990730986,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 570,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8616108017414923,
    "arrivals": 397780,
    "finished_requests": 77026,
    "scheduler_time": 135.738021560097
}
#Debug simulation 
Total elapsed time: 89.20505949063227. Arrivals time: 0.4165165829472244 Scheduler time: 88.62951214844361 Scheduler overhead time: 0.06249827379360795 Adapter cache time: 0.019659653771668673 Engine time: 0.055981243029236794 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-16/adapters_384_slots_96_rate_0.8-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-16/adapters_384_slots_96_rate_0.8-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 8640, 540, 135, 8640, 8640, 135, 540, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 135, 8640, 135, 8640, 540, 540, 540, 135, 135, 540, 135, 8640, 135, 8640, 540, 8640, 540, 135, 540, 8640, 540, 8640, 135, 8640, 8640, 8640, 8640, 135, 540, 540, 540, 8640, 540, 135, 540, 135, 8640, 540, 8640, 8640, 540, 8640, 8640, 135, 135, 8640, 540, 540, 135, 135, 135, 540, 135, 540, 135, 8640, 135, 540, 8640, 135, 8640, 540, 135, 8640, 8640, 8640, 8640, 540, 135, 540, 8640, 8640, 540, 135, 135, 8640, 540, 540, 135, 135, 8640, 540, 8640, 540, 8640, 8640, 540, 8640, 8640, 135, 540, 540, 540, 540, 135, 135, 8640, 135, 8640, 135, 135, 135, 540, 540, 8640, 135, 135, 8640, 135, 8640, 540, 135, 8640, 540, 540, 135, 8640, 8640, 8640, 135, 540, 8640, 135, 8640, 540, 540, 8640, 8640, 135, 540, 8640, 135, 540, 540, 135, 540, 135, 540, 8640, 8640, 540, 135, 8640, 135, 8640, 540, 540, 540, 540, 540, 135, 135, 8640, 135, 8640, 135, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 135, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 135, 135, 135, 135, 135, 540, 135, 135, 540, 8640, 8640, 135, 135, 8640, 135, 135, 135, 540, 135, 540, 8640, 8640, 540, 540, 135, 8640, 540, 8640, 135, 540, 540, 135, 135, 540, 135, 8640, 8640, 135, 8640, 8640, 135, 540, 8640, 135, 135, 540, 540, 135, 135, 8640, 8640, 8640, 8640, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 8640, 540, 540, 540, 8640, 135, 540, 540, 8640, 8640, 135, 8640, 8640, 135, 8640, 135, 135, 540, 135, 8640, 8640, 8640, 540, 135, 8640, 8640, 540, 540, 8640, 8640, 135, 8640, 8640, 540, 135, 8640, 540, 540, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 135, 8640, 135, 540, 8640, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 8640, 135, 135, 135, 540, 135, 540, 540, 135, 8640, 540, 8640, 135, 8640, 135, 540, 540, 540, 540, 135, 540, 8640, 8640, 135, 8640, 8640, 135, 8640, 540, 8640, 540, 540, 540, 135, 540, 135, 135, 8640, 135, 540, 135, 135, 540, 8640, 540, 8640, 135, 8640, 8640, 540, 8640, 540, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1192320 . Total input tokens: 265725538 . Total output tokens: 238232918
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 90.43387442221865,
    "estimated_duration": 3600.02721275407,
    "input_throughput": 5313.667333466012,
    "output_throughput": 4676.2927069990565,
    "total_throughput": 9989.960040465068,
    "itl": 181.99468916352745,
    "ttft": 1956372.3895547837,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 568,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.776390273326532,
    "arrivals": 397780,
    "finished_requests": 77220,
    "scheduler_time": 135.28023005352472
}
#Debug simulation 
Total elapsed time: 90.43402872420847. Arrivals time: 0.42805380187928677 Scheduler time: 89.84612058475614 Scheduler overhead time: 0.06330624641850591 Adapter cache time: 0.019729611929506063 Engine time: 0.05579063389450312 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-32/adapters_384_slots_96_rate_0.8-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-32/adapters_384_slots_96_rate_0.8-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 8640, 540, 135, 8640, 8640, 135, 540, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 135, 8640, 135, 8640, 540, 540, 540, 135, 135, 540, 135, 8640, 135, 8640, 540, 8640, 540, 135, 540, 8640, 540, 8640, 135, 8640, 8640, 8640, 8640, 135, 540, 540, 540, 8640, 540, 135, 540, 135, 8640, 540, 8640, 8640, 540, 8640, 8640, 135, 135, 8640, 540, 540, 135, 135, 135, 540, 135, 540, 135, 8640, 135, 540, 8640, 135, 8640, 540, 135, 8640, 8640, 8640, 8640, 540, 135, 540, 8640, 8640, 540, 135, 135, 8640, 540, 540, 135, 135, 8640, 540, 8640, 540, 8640, 8640, 540, 8640, 8640, 135, 540, 540, 540, 540, 135, 135, 8640, 135, 8640, 135, 135, 135, 540, 540, 8640, 135, 135, 8640, 135, 8640, 540, 135, 8640, 540, 540, 135, 8640, 8640, 8640, 135, 540, 8640, 135, 8640, 540, 540, 8640, 8640, 135, 540, 8640, 135, 540, 540, 135, 540, 135, 540, 8640, 8640, 540, 135, 8640, 135, 8640, 540, 540, 540, 540, 540, 135, 135, 8640, 135, 8640, 135, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 135, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 135, 135, 135, 135, 135, 540, 135, 135, 540, 8640, 8640, 135, 135, 8640, 135, 135, 135, 540, 135, 540, 8640, 8640, 540, 540, 135, 8640, 540, 8640, 135, 540, 540, 135, 135, 540, 135, 8640, 8640, 135, 8640, 8640, 135, 540, 8640, 135, 135, 540, 540, 135, 135, 8640, 8640, 8640, 8640, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 8640, 540, 540, 540, 8640, 135, 540, 540, 8640, 8640, 135, 8640, 8640, 135, 8640, 135, 135, 540, 135, 8640, 8640, 8640, 540, 135, 8640, 8640, 540, 540, 8640, 8640, 135, 8640, 8640, 540, 135, 8640, 540, 540, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 135, 8640, 135, 540, 8640, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 8640, 135, 135, 135, 540, 135, 540, 540, 135, 8640, 540, 8640, 135, 8640, 135, 540, 540, 540, 540, 135, 540, 8640, 8640, 135, 8640, 8640, 135, 8640, 540, 8640, 540, 540, 540, 135, 540, 135, 135, 8640, 135, 540, 135, 135, 540, 8640, 540, 8640, 135, 8640, 8640, 540, 8640, 540, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1192320 . Total input tokens: 265725538 . Total output tokens: 238232918
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 89.0504593490623,
    "estimated_duration": 3600.176428979233,
    "input_throughput": 5299.879707675866,
    "output_throughput": 4667.23154586181,
    "total_throughput": 9967.111253537676,
    "itl": 180.39016458056403,
    "ttft": 1956535.0134771876,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 571,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8882560185715591,
    "arrivals": 397780,
    "finished_requests": 77026,
    "scheduler_time": 135.73851464549017
}
#Debug simulation 
Total elapsed time: 89.05061879986897. Arrivals time: 0.42048792308196425 Scheduler time: 88.4701322875917 Scheduler overhead time: 0.06309537030756474 Adapter cache time: 0.019637611228972673 Engine time: 0.0558548322878778 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-16/adapters_384_slots_96_rate_0.8-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-16/adapters_384_slots_96_rate_0.8-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 8640, 540, 135, 8640, 8640, 135, 540, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 135, 8640, 135, 8640, 540, 540, 540, 135, 135, 540, 135, 8640, 135, 8640, 540, 8640, 540, 135, 540, 8640, 540, 8640, 135, 8640, 8640, 8640, 8640, 135, 540, 540, 540, 8640, 540, 135, 540, 135, 8640, 540, 8640, 8640, 540, 8640, 8640, 135, 135, 8640, 540, 540, 135, 135, 135, 540, 135, 540, 135, 8640, 135, 540, 8640, 135, 8640, 540, 135, 8640, 8640, 8640, 8640, 540, 135, 540, 8640, 8640, 540, 135, 135, 8640, 540, 540, 135, 135, 8640, 540, 8640, 540, 8640, 8640, 540, 8640, 8640, 135, 540, 540, 540, 540, 135, 135, 8640, 135, 8640, 135, 135, 135, 540, 540, 8640, 135, 135, 8640, 135, 8640, 540, 135, 8640, 540, 540, 135, 8640, 8640, 8640, 135, 540, 8640, 135, 8640, 540, 540, 8640, 8640, 135, 540, 8640, 135, 540, 540, 135, 540, 135, 540, 8640, 8640, 540, 135, 8640, 135, 8640, 540, 540, 540, 540, 540, 135, 135, 8640, 135, 8640, 135, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 135, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 135, 135, 135, 135, 135, 540, 135, 135, 540, 8640, 8640, 135, 135, 8640, 135, 135, 135, 540, 135, 540, 8640, 8640, 540, 540, 135, 8640, 540, 8640, 135, 540, 540, 135, 135, 540, 135, 8640, 8640, 135, 8640, 8640, 135, 540, 8640, 135, 135, 540, 540, 135, 135, 8640, 8640, 8640, 8640, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 8640, 540, 540, 540, 8640, 135, 540, 540, 8640, 8640, 135, 8640, 8640, 135, 8640, 135, 135, 540, 135, 8640, 8640, 8640, 540, 135, 8640, 8640, 540, 540, 8640, 8640, 135, 8640, 8640, 540, 135, 8640, 540, 540, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 135, 8640, 135, 540, 8640, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 8640, 135, 135, 135, 540, 135, 540, 540, 135, 8640, 540, 8640, 135, 8640, 135, 540, 540, 540, 540, 135, 540, 8640, 8640, 135, 8640, 8640, 135, 8640, 540, 8640, 540, 540, 540, 135, 540, 135, 135, 8640, 135, 540, 135, 135, 540, 8640, 540, 8640, 135, 8640, 8640, 540, 8640, 540, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1192320 . Total input tokens: 265725538 . Total output tokens: 238232918
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 90.60213105520234,
    "estimated_duration": 3600.1758840746947,
    "input_throughput": 5313.276522020924,
    "output_throughput": 4676.402915333427,
    "total_throughput": 9989.67943735435,
    "itl": 182.00015468519607,
    "ttft": 1956187.7508969055,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 562,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.680408265735,
    "arrivals": 397780,
    "finished_requests": 77230,
    "scheduler_time": 135.28669692483365
}
#Debug simulation 
Total elapsed time: 90.60228779818863. Arrivals time: 0.43845335161313415 Scheduler time: 90.00591116584837 Scheduler overhead time: 0.06169867143034935 Adapter cache time: 0.019637188408523798 Engine time: 0.05520706623792648 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-32/adapters_384_slots_96_rate_0.8-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-32/adapters_384_slots_96_rate_0.8-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 8640, 540, 135, 8640, 8640, 135, 540, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 135, 8640, 135, 8640, 540, 540, 540, 135, 135, 540, 135, 8640, 135, 8640, 540, 8640, 540, 135, 540, 8640, 540, 8640, 135, 8640, 8640, 8640, 8640, 135, 540, 540, 540, 8640, 540, 135, 540, 135, 8640, 540, 8640, 8640, 540, 8640, 8640, 135, 135, 8640, 540, 540, 135, 135, 135, 540, 135, 540, 135, 8640, 135, 540, 8640, 135, 8640, 540, 135, 8640, 8640, 8640, 8640, 540, 135, 540, 8640, 8640, 540, 135, 135, 8640, 540, 540, 135, 135, 8640, 540, 8640, 540, 8640, 8640, 540, 8640, 8640, 135, 540, 540, 540, 540, 135, 135, 8640, 135, 8640, 135, 135, 135, 540, 540, 8640, 135, 135, 8640, 135, 8640, 540, 135, 8640, 540, 540, 135, 8640, 8640, 8640, 135, 540, 8640, 135, 8640, 540, 540, 8640, 8640, 135, 540, 8640, 135, 540, 540, 135, 540, 135, 540, 8640, 8640, 540, 135, 8640, 135, 8640, 540, 540, 540, 540, 540, 135, 135, 8640, 135, 8640, 135, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 135, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 135, 135, 135, 135, 135, 540, 135, 135, 540, 8640, 8640, 135, 135, 8640, 135, 135, 135, 540, 135, 540, 8640, 8640, 540, 540, 135, 8640, 540, 8640, 135, 540, 540, 135, 135, 540, 135, 8640, 8640, 135, 8640, 8640, 135, 540, 8640, 135, 135, 540, 540, 135, 135, 8640, 8640, 8640, 8640, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 8640, 540, 540, 540, 8640, 135, 540, 540, 8640, 8640, 135, 8640, 8640, 135, 8640, 135, 135, 540, 135, 8640, 8640, 8640, 540, 135, 8640, 8640, 540, 540, 8640, 8640, 135, 8640, 8640, 540, 135, 8640, 540, 540, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 135, 8640, 135, 540, 8640, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 8640, 135, 135, 135, 540, 135, 540, 540, 135, 8640, 540, 8640, 135, 8640, 135, 540, 540, 540, 540, 135, 540, 8640, 8640, 135, 8640, 8640, 135, 8640, 540, 8640, 540, 540, 540, 135, 540, 135, 135, 8640, 135, 540, 135, 135, 540, 8640, 540, 8640, 135, 8640, 8640, 540, 8640, 540, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1192320 . Total input tokens: 265725538 . Total output tokens: 238232918
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 88.56680562114343,
    "estimated_duration": 3600.031837852843,
    "input_throughput": 5299.924517161984,
    "output_throughput": 4667.163446538054,
    "total_throughput": 9967.087963700038,
    "itl": 180.3824504376594,
    "ttft": 1956495.9556816514,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 571,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9124007455632053,
    "arrivals": 397780,
    "finished_requests": 77023,
    "scheduler_time": 135.73447372151398
}
#Debug simulation 
Total elapsed time: 88.56696314923465. Arrivals time: 0.42964340187609196 Scheduler time: 87.9778633248061 Scheduler overhead time: 0.0628689001314342 Adapter cache time: 0.01977253006771207 Engine time: 0.05547316325828433 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-8/adapters_384_slots_96_rate_0.8-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-8/adapters_384_slots_96_rate_0.8-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 8640, 540, 66, 8640, 8640, 66, 540, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 66, 8640, 66, 8640, 540, 540, 540, 66, 66, 540, 66, 8640, 66, 8640, 540, 8640, 540, 66, 540, 8640, 540, 8640, 66, 8640, 8640, 8640, 8640, 66, 540, 540, 540, 8640, 540, 66, 540, 66, 8640, 540, 8640, 8640, 540, 8640, 8640, 66, 66, 8640, 540, 540, 66, 66, 66, 540, 66, 540, 66, 8640, 66, 540, 8640, 66, 8640, 540, 66, 8640, 8640, 8640, 8640, 540, 66, 540, 8640, 8640, 540, 66, 66, 8640, 540, 540, 66, 66, 8640, 540, 8640, 540, 8640, 8640, 540, 8640, 8640, 66, 540, 540, 540, 540, 66, 66, 8640, 66, 8640, 66, 66, 66, 540, 540, 8640, 66, 66, 8640, 66, 8640, 540, 66, 8640, 540, 540, 66, 8640, 8640, 8640, 66, 540, 8640, 66, 8640, 540, 540, 8640, 8640, 66, 540, 8640, 66, 540, 540, 66, 540, 66, 540, 8640, 8640, 540, 66, 8640, 66, 8640, 540, 540, 540, 540, 540, 66, 66, 8640, 66, 8640, 66, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 66, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 66, 66, 66, 66, 66, 540, 66, 66, 540, 8640, 8640, 66, 66, 8640, 66, 66, 66, 540, 66, 540, 8640, 8640, 540, 540, 66, 8640, 540, 8640, 66, 540, 540, 66, 66, 540, 66, 8640, 8640, 66, 8640, 8640, 66, 540, 8640, 66, 66, 540, 540, 66, 66, 8640, 8640, 8640, 8640, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 8640, 540, 540, 540, 8640, 66, 540, 540, 8640, 8640, 66, 8640, 8640, 66, 8640, 66, 66, 540, 66, 8640, 8640, 8640, 540, 66, 8640, 8640, 540, 540, 8640, 8640, 66, 8640, 8640, 540, 66, 8640, 540, 540, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 66, 8640, 66, 540, 8640, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 8640, 66, 66, 66, 540, 66, 540, 540, 66, 8640, 540, 8640, 66, 8640, 66, 540, 540, 540, 540, 66, 540, 8640, 8640, 66, 8640, 8640, 66, 8640, 540, 8640, 540, 540, 540, 66, 540, 66, 66, 8640, 66, 540, 66, 66, 540, 8640, 540, 8640, 66, 8640, 8640, 540, 8640, 540, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1183488 . Total input tokens: 263745087 . Total output tokens: 236448662
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 72.42208387516439,
    "estimated_duration": 3600.1086516066816,
    "input_throughput": 5298.444254310793,
    "output_throughput": 4693.505567521977,
    "total_throughput": 9991.949821832772,
    "itl": 183.7352083930776,
    "ttft": 1965953.9131460267,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 668,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0444058129471143,
    "arrivals": 394936,
    "finished_requests": 77149,
    "scheduler_time": 134.76399280066255
}
#Debug simulation 
Total elapsed time: 72.42224562400952. Arrivals time: 0.41314041754230857 Scheduler time: 71.85555736161768 Scheduler overhead time: 0.0592321096919477 Adapter cache time: 0.02104459749534726 Engine time: 0.05318118957802653 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-16/adapters_384_slots_96_rate_0.8-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-16/adapters_384_slots_96_rate_0.8-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 8640, 540, 66, 8640, 8640, 66, 540, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 66, 8640, 66, 8640, 540, 540, 540, 66, 66, 540, 66, 8640, 66, 8640, 540, 8640, 540, 66, 540, 8640, 540, 8640, 66, 8640, 8640, 8640, 8640, 66, 540, 540, 540, 8640, 540, 66, 540, 66, 8640, 540, 8640, 8640, 540, 8640, 8640, 66, 66, 8640, 540, 540, 66, 66, 66, 540, 66, 540, 66, 8640, 66, 540, 8640, 66, 8640, 540, 66, 8640, 8640, 8640, 8640, 540, 66, 540, 8640, 8640, 540, 66, 66, 8640, 540, 540, 66, 66, 8640, 540, 8640, 540, 8640, 8640, 540, 8640, 8640, 66, 540, 540, 540, 540, 66, 66, 8640, 66, 8640, 66, 66, 66, 540, 540, 8640, 66, 66, 8640, 66, 8640, 540, 66, 8640, 540, 540, 66, 8640, 8640, 8640, 66, 540, 8640, 66, 8640, 540, 540, 8640, 8640, 66, 540, 8640, 66, 540, 540, 66, 540, 66, 540, 8640, 8640, 540, 66, 8640, 66, 8640, 540, 540, 540, 540, 540, 66, 66, 8640, 66, 8640, 66, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 66, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 66, 66, 66, 66, 66, 540, 66, 66, 540, 8640, 8640, 66, 66, 8640, 66, 66, 66, 540, 66, 540, 8640, 8640, 540, 540, 66, 8640, 540, 8640, 66, 540, 540, 66, 66, 540, 66, 8640, 8640, 66, 8640, 8640, 66, 540, 8640, 66, 66, 540, 540, 66, 66, 8640, 8640, 8640, 8640, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 8640, 540, 540, 540, 8640, 66, 540, 540, 8640, 8640, 66, 8640, 8640, 66, 8640, 66, 66, 540, 66, 8640, 8640, 8640, 540, 66, 8640, 8640, 540, 540, 8640, 8640, 66, 8640, 8640, 540, 66, 8640, 540, 540, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 66, 8640, 66, 540, 8640, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 8640, 66, 66, 66, 540, 66, 540, 540, 66, 8640, 540, 8640, 66, 8640, 66, 540, 540, 540, 540, 66, 540, 8640, 8640, 66, 8640, 8640, 66, 8640, 540, 8640, 540, 540, 540, 66, 540, 66, 66, 8640, 66, 540, 66, 66, 540, 8640, 540, 8640, 66, 8640, 8640, 540, 8640, 540, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1183488 . Total input tokens: 263745087 . Total output tokens: 236448662
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 71.63979098014534,
    "estimated_duration": 3600.076174157891,
    "input_throughput": 5299.046485998973,
    "output_throughput": 4692.382656028521,
    "total_throughput": 9991.429142027495,
    "itl": 183.72160783622942,
    "ttft": 1966111.3530973718,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 672,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.192773096153983,
    "arrivals": 394936,
    "finished_requests": 77126,
    "scheduler_time": 134.75986732681878
}
#Debug simulation 
Total elapsed time: 71.63994920207188. Arrivals time: 0.4016605238430202 Scheduler time: 71.0841805152595 Scheduler overhead time: 0.059436422772705555 Adapter cache time: 0.0211889510974288 Engine time: 0.05329787218943238 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-32/adapters_384_slots_96_rate_0.8-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-32/adapters_384_slots_96_rate_0.8-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 8640, 540, 66, 8640, 8640, 66, 540, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 66, 8640, 66, 8640, 540, 540, 540, 66, 66, 540, 66, 8640, 66, 8640, 540, 8640, 540, 66, 540, 8640, 540, 8640, 66, 8640, 8640, 8640, 8640, 66, 540, 540, 540, 8640, 540, 66, 540, 66, 8640, 540, 8640, 8640, 540, 8640, 8640, 66, 66, 8640, 540, 540, 66, 66, 66, 540, 66, 540, 66, 8640, 66, 540, 8640, 66, 8640, 540, 66, 8640, 8640, 8640, 8640, 540, 66, 540, 8640, 8640, 540, 66, 66, 8640, 540, 540, 66, 66, 8640, 540, 8640, 540, 8640, 8640, 540, 8640, 8640, 66, 540, 540, 540, 540, 66, 66, 8640, 66, 8640, 66, 66, 66, 540, 540, 8640, 66, 66, 8640, 66, 8640, 540, 66, 8640, 540, 540, 66, 8640, 8640, 8640, 66, 540, 8640, 66, 8640, 540, 540, 8640, 8640, 66, 540, 8640, 66, 540, 540, 66, 540, 66, 540, 8640, 8640, 540, 66, 8640, 66, 8640, 540, 540, 540, 540, 540, 66, 66, 8640, 66, 8640, 66, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 66, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 66, 66, 66, 66, 66, 540, 66, 66, 540, 8640, 8640, 66, 66, 8640, 66, 66, 66, 540, 66, 540, 8640, 8640, 540, 540, 66, 8640, 540, 8640, 66, 540, 540, 66, 66, 540, 66, 8640, 8640, 66, 8640, 8640, 66, 540, 8640, 66, 66, 540, 540, 66, 66, 8640, 8640, 8640, 8640, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 8640, 540, 540, 540, 8640, 66, 540, 540, 8640, 8640, 66, 8640, 8640, 66, 8640, 66, 66, 540, 66, 8640, 8640, 8640, 540, 66, 8640, 8640, 540, 540, 8640, 8640, 66, 8640, 8640, 540, 66, 8640, 540, 540, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 66, 8640, 66, 540, 8640, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 8640, 66, 66, 66, 540, 66, 540, 540, 66, 8640, 540, 8640, 66, 8640, 66, 540, 540, 540, 540, 66, 540, 8640, 8640, 66, 8640, 8640, 66, 8640, 540, 8640, 540, 540, 540, 66, 540, 66, 66, 8640, 66, 540, 66, 66, 540, 8640, 540, 8640, 66, 8640, 8640, 540, 8640, 540, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1183488 . Total input tokens: 263745087 . Total output tokens: 236448662
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 70.9623567094095,
    "estimated_duration": 3600.006800147732,
    "input_throughput": 5284.806406259917,
    "output_throughput": 4679.457827498741,
    "total_throughput": 9964.264233758659,
    "itl": 181.67853425864183,
    "ttft": 1968009.2777041835,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 682,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2287902173772487,
    "arrivals": 394936,
    "finished_requests": 76925,
    "scheduler_time": 135.30849090152162
}
#Debug simulation 
Total elapsed time: 70.96251608617604. Arrivals time: 0.4091210765764117 Scheduler time: 70.39980166172609 Scheduler overhead time: 0.05941087659448385 Adapter cache time: 0.021598794497549534 Engine time: 0.052668179385364056 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-16/adapters_384_slots_96_rate_0.8-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-16/adapters_384_slots_96_rate_0.8-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 8640, 540, 66, 8640, 8640, 66, 540, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 66, 8640, 66, 8640, 540, 540, 540, 66, 66, 540, 66, 8640, 66, 8640, 540, 8640, 540, 66, 540, 8640, 540, 8640, 66, 8640, 8640, 8640, 8640, 66, 540, 540, 540, 8640, 540, 66, 540, 66, 8640, 540, 8640, 8640, 540, 8640, 8640, 66, 66, 8640, 540, 540, 66, 66, 66, 540, 66, 540, 66, 8640, 66, 540, 8640, 66, 8640, 540, 66, 8640, 8640, 8640, 8640, 540, 66, 540, 8640, 8640, 540, 66, 66, 8640, 540, 540, 66, 66, 8640, 540, 8640, 540, 8640, 8640, 540, 8640, 8640, 66, 540, 540, 540, 540, 66, 66, 8640, 66, 8640, 66, 66, 66, 540, 540, 8640, 66, 66, 8640, 66, 8640, 540, 66, 8640, 540, 540, 66, 8640, 8640, 8640, 66, 540, 8640, 66, 8640, 540, 540, 8640, 8640, 66, 540, 8640, 66, 540, 540, 66, 540, 66, 540, 8640, 8640, 540, 66, 8640, 66, 8640, 540, 540, 540, 540, 540, 66, 66, 8640, 66, 8640, 66, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 66, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 66, 66, 66, 66, 66, 540, 66, 66, 540, 8640, 8640, 66, 66, 8640, 66, 66, 66, 540, 66, 540, 8640, 8640, 540, 540, 66, 8640, 540, 8640, 66, 540, 540, 66, 66, 540, 66, 8640, 8640, 66, 8640, 8640, 66, 540, 8640, 66, 66, 540, 540, 66, 66, 8640, 8640, 8640, 8640, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 8640, 540, 540, 540, 8640, 66, 540, 540, 8640, 8640, 66, 8640, 8640, 66, 8640, 66, 66, 540, 66, 8640, 8640, 8640, 540, 66, 8640, 8640, 540, 540, 8640, 8640, 66, 8640, 8640, 540, 66, 8640, 540, 540, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 66, 8640, 66, 540, 8640, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 8640, 66, 66, 66, 540, 66, 540, 540, 66, 8640, 540, 8640, 66, 8640, 66, 540, 540, 540, 540, 66, 540, 8640, 8640, 66, 8640, 8640, 66, 8640, 540, 8640, 540, 540, 540, 66, 540, 66, 66, 8640, 66, 540, 66, 66, 540, 8640, 540, 8640, 66, 8640, 8640, 540, 8640, 540, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1183488 . Total input tokens: 263745087 . Total output tokens: 236448662
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 72.0868200911209,
    "estimated_duration": 3600.1854780806907,
    "input_throughput": 5298.285356722523,
    "output_throughput": 4693.5070714768535,
    "total_throughput": 9991.792428199376,
    "itl": 183.73769431752868,
    "ttft": 1965975.5306899587,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 668,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0892875436437155,
    "arrivals": 394936,
    "finished_requests": 77150,
    "scheduler_time": 134.76552707669322
}
#Debug simulation 
Total elapsed time: 72.08698248118162. Arrivals time: 0.40974661987274885 Scheduler time: 71.5241065947339 Scheduler overhead time: 0.058786578476428986 Adapter cache time: 0.021368774585425854 Engine time: 0.05299420841038227 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-32/adapters_384_slots_96_rate_0.8-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-32/adapters_384_slots_96_rate_0.8-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 8640, 540, 66, 8640, 8640, 66, 540, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 66, 8640, 66, 8640, 540, 540, 540, 66, 66, 540, 66, 8640, 66, 8640, 540, 8640, 540, 66, 540, 8640, 540, 8640, 66, 8640, 8640, 8640, 8640, 66, 540, 540, 540, 8640, 540, 66, 540, 66, 8640, 540, 8640, 8640, 540, 8640, 8640, 66, 66, 8640, 540, 540, 66, 66, 66, 540, 66, 540, 66, 8640, 66, 540, 8640, 66, 8640, 540, 66, 8640, 8640, 8640, 8640, 540, 66, 540, 8640, 8640, 540, 66, 66, 8640, 540, 540, 66, 66, 8640, 540, 8640, 540, 8640, 8640, 540, 8640, 8640, 66, 540, 540, 540, 540, 66, 66, 8640, 66, 8640, 66, 66, 66, 540, 540, 8640, 66, 66, 8640, 66, 8640, 540, 66, 8640, 540, 540, 66, 8640, 8640, 8640, 66, 540, 8640, 66, 8640, 540, 540, 8640, 8640, 66, 540, 8640, 66, 540, 540, 66, 540, 66, 540, 8640, 8640, 540, 66, 8640, 66, 8640, 540, 540, 540, 540, 540, 66, 66, 8640, 66, 8640, 66, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 66, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 66, 66, 66, 66, 66, 540, 66, 66, 540, 8640, 8640, 66, 66, 8640, 66, 66, 66, 540, 66, 540, 8640, 8640, 540, 540, 66, 8640, 540, 8640, 66, 540, 540, 66, 66, 540, 66, 8640, 8640, 66, 8640, 8640, 66, 540, 8640, 66, 66, 540, 540, 66, 66, 8640, 8640, 8640, 8640, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 8640, 540, 540, 540, 8640, 66, 540, 540, 8640, 8640, 66, 8640, 8640, 66, 8640, 66, 66, 540, 66, 8640, 8640, 8640, 540, 66, 8640, 8640, 540, 540, 8640, 8640, 66, 8640, 8640, 540, 66, 8640, 540, 540, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 66, 8640, 66, 540, 8640, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 8640, 66, 66, 66, 540, 66, 540, 540, 66, 8640, 540, 8640, 66, 8640, 66, 540, 540, 540, 540, 66, 540, 8640, 8640, 66, 8640, 8640, 66, 8640, 540, 8640, 540, 540, 540, 66, 540, 66, 66, 8640, 66, 540, 66, 66, 540, 8640, 540, 8640, 66, 8640, 8640, 540, 8640, 540, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1183488 . Total input tokens: 263745087 . Total output tokens: 236448662
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 71.54343333886936,
    "estimated_duration": 3600.0372230650787,
    "input_throughput": 5284.7617458248915,
    "output_throughput": 4679.41828269687,
    "total_throughput": 9964.180028521761,
    "itl": 181.67938877855983,
    "ttft": 1968017.3175260094,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 682,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2572105731070073,
    "arrivals": 394936,
    "finished_requests": 76925,
    "scheduler_time": 135.30880722762157
}
#Debug simulation 
Total elapsed time: 71.54359225416556. Arrivals time: 0.40218930784612894 Scheduler time: 70.98646899592131 Scheduler overhead time: 0.05929264659062028 Adapter cache time: 0.022036193404346704 Engine time: 0.05355638125911355 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-16/adapters_384_slots_96_rate_0.8-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-16/adapters_384_slots_96_rate_0.8-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 8640, 540, 66, 8640, 8640, 66, 540, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 66, 8640, 66, 8640, 540, 540, 540, 66, 66, 540, 66, 8640, 66, 8640, 540, 8640, 540, 66, 540, 8640, 540, 8640, 66, 8640, 8640, 8640, 8640, 66, 540, 540, 540, 8640, 540, 66, 540, 66, 8640, 540, 8640, 8640, 540, 8640, 8640, 66, 66, 8640, 540, 540, 66, 66, 66, 540, 66, 540, 66, 8640, 66, 540, 8640, 66, 8640, 540, 66, 8640, 8640, 8640, 8640, 540, 66, 540, 8640, 8640, 540, 66, 66, 8640, 540, 540, 66, 66, 8640, 540, 8640, 540, 8640, 8640, 540, 8640, 8640, 66, 540, 540, 540, 540, 66, 66, 8640, 66, 8640, 66, 66, 66, 540, 540, 8640, 66, 66, 8640, 66, 8640, 540, 66, 8640, 540, 540, 66, 8640, 8640, 8640, 66, 540, 8640, 66, 8640, 540, 540, 8640, 8640, 66, 540, 8640, 66, 540, 540, 66, 540, 66, 540, 8640, 8640, 540, 66, 8640, 66, 8640, 540, 540, 540, 540, 540, 66, 66, 8640, 66, 8640, 66, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 66, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 66, 66, 66, 66, 66, 540, 66, 66, 540, 8640, 8640, 66, 66, 8640, 66, 66, 66, 540, 66, 540, 8640, 8640, 540, 540, 66, 8640, 540, 8640, 66, 540, 540, 66, 66, 540, 66, 8640, 8640, 66, 8640, 8640, 66, 540, 8640, 66, 66, 540, 540, 66, 66, 8640, 8640, 8640, 8640, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 8640, 540, 540, 540, 8640, 66, 540, 540, 8640, 8640, 66, 8640, 8640, 66, 8640, 66, 66, 540, 66, 8640, 8640, 8640, 540, 66, 8640, 8640, 540, 540, 8640, 8640, 66, 8640, 8640, 540, 66, 8640, 540, 540, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 66, 8640, 66, 540, 8640, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 8640, 66, 66, 66, 540, 66, 540, 540, 66, 8640, 540, 8640, 66, 8640, 66, 540, 540, 540, 540, 66, 540, 8640, 8640, 66, 8640, 8640, 66, 8640, 540, 8640, 540, 540, 540, 66, 540, 66, 66, 8640, 66, 540, 66, 66, 540, 8640, 540, 8640, 66, 8640, 8640, 540, 8640, 540, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1183488 . Total input tokens: 263745087 . Total output tokens: 236448662
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 72.55341987404972,
    "estimated_duration": 3600.164064123567,
    "input_throughput": 5297.487742310125,
    "output_throughput": 4693.943303418292,
    "total_throughput": 9991.431045728417,
    "itl": 183.73848115302684,
    "ttft": 1965905.2723259712,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 672,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0093137981742277,
    "arrivals": 394936,
    "finished_requests": 77150,
    "scheduler_time": 134.7669248602603
}
#Debug simulation 
Total elapsed time: 72.55358060635626. Arrivals time: 0.4032021532766521 Scheduler time: 71.99486899049953 Scheduler overhead time: 0.060787294525653124 Adapter cache time: 0.02140233013778925 Engine time: 0.052960120141506195 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-32/adapters_384_slots_96_rate_0.8-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-32/adapters_384_slots_96_rate_0.8-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 8640, 540, 66, 8640, 8640, 66, 540, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 66, 8640, 66, 8640, 540, 540, 540, 66, 66, 540, 66, 8640, 66, 8640, 540, 8640, 540, 66, 540, 8640, 540, 8640, 66, 8640, 8640, 8640, 8640, 66, 540, 540, 540, 8640, 540, 66, 540, 66, 8640, 540, 8640, 8640, 540, 8640, 8640, 66, 66, 8640, 540, 540, 66, 66, 66, 540, 66, 540, 66, 8640, 66, 540, 8640, 66, 8640, 540, 66, 8640, 8640, 8640, 8640, 540, 66, 540, 8640, 8640, 540, 66, 66, 8640, 540, 540, 66, 66, 8640, 540, 8640, 540, 8640, 8640, 540, 8640, 8640, 66, 540, 540, 540, 540, 66, 66, 8640, 66, 8640, 66, 66, 66, 540, 540, 8640, 66, 66, 8640, 66, 8640, 540, 66, 8640, 540, 540, 66, 8640, 8640, 8640, 66, 540, 8640, 66, 8640, 540, 540, 8640, 8640, 66, 540, 8640, 66, 540, 540, 66, 540, 66, 540, 8640, 8640, 540, 66, 8640, 66, 8640, 540, 540, 540, 540, 540, 66, 66, 8640, 66, 8640, 66, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 66, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 66, 66, 66, 66, 66, 540, 66, 66, 540, 8640, 8640, 66, 66, 8640, 66, 66, 66, 540, 66, 540, 8640, 8640, 540, 540, 66, 8640, 540, 8640, 66, 540, 540, 66, 66, 540, 66, 8640, 8640, 66, 8640, 8640, 66, 540, 8640, 66, 66, 540, 540, 66, 66, 8640, 8640, 8640, 8640, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 8640, 540, 540, 540, 8640, 66, 540, 540, 8640, 8640, 66, 8640, 8640, 66, 8640, 66, 66, 540, 66, 8640, 8640, 8640, 540, 66, 8640, 8640, 540, 540, 8640, 8640, 66, 8640, 8640, 540, 66, 8640, 540, 540, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 66, 8640, 66, 540, 8640, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 8640, 66, 66, 66, 540, 66, 540, 540, 66, 8640, 540, 8640, 66, 8640, 66, 540, 540, 540, 540, 66, 540, 8640, 8640, 66, 8640, 8640, 66, 8640, 540, 8640, 540, 540, 540, 66, 540, 66, 66, 8640, 66, 540, 66, 66, 540, 8640, 540, 8640, 66, 8640, 8640, 540, 8640, 540, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1183488 . Total input tokens: 263745087 . Total output tokens: 236448662
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 71.68691548332572,
    "estimated_duration": 3600.0714393308513,
    "input_throughput": 5284.711517707065,
    "output_throughput": 4679.3738079628765,
    "total_throughput": 9964.085325669941,
    "itl": 181.68055778685624,
    "ttft": 1968025.915811364,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 682,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2858824364095978,
    "arrivals": 394936,
    "finished_requests": 76925,
    "scheduler_time": 135.30969681806837
}
#Debug simulation 
Total elapsed time: 71.68707592226565. Arrivals time: 0.4182347101159394 Scheduler time: 71.11509680375457 Scheduler overhead time: 0.05910314992070198 Adapter cache time: 0.0210476815700531 Engine time: 0.053014598321169615 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-8/adapters_384_slots_96_rate_0.8-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-8/adapters_384_slots_96_rate_0.8-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 540, 33, 8640, 8640, 33, 540, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 33, 8640, 33, 8640, 540, 540, 540, 33, 33, 540, 33, 8640, 33, 8640, 540, 8640, 540, 33, 540, 8640, 540, 8640, 33, 8640, 8640, 8640, 8640, 33, 540, 540, 540, 8640, 540, 33, 540, 33, 8640, 540, 8640, 8640, 540, 8640, 8640, 33, 33, 8640, 540, 540, 33, 33, 33, 540, 33, 540, 33, 8640, 33, 540, 8640, 33, 8640, 540, 33, 8640, 8640, 8640, 8640, 540, 33, 540, 8640, 8640, 540, 33, 33, 8640, 540, 540, 33, 33, 8640, 540, 8640, 540, 8640, 8640, 540, 8640, 8640, 33, 540, 540, 540, 540, 33, 33, 8640, 33, 8640, 33, 33, 33, 540, 540, 8640, 33, 33, 8640, 33, 8640, 540, 33, 8640, 540, 540, 33, 8640, 8640, 8640, 33, 540, 8640, 33, 8640, 540, 540, 8640, 8640, 33, 540, 8640, 33, 540, 540, 33, 540, 33, 540, 8640, 8640, 540, 33, 8640, 33, 8640, 540, 540, 540, 540, 540, 33, 33, 8640, 33, 8640, 33, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 33, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 33, 33, 33, 33, 33, 540, 33, 33, 540, 8640, 8640, 33, 33, 8640, 33, 33, 33, 540, 33, 540, 8640, 8640, 540, 540, 33, 8640, 540, 8640, 33, 540, 540, 33, 33, 540, 33, 8640, 8640, 33, 8640, 8640, 33, 540, 8640, 33, 33, 540, 540, 33, 33, 8640, 8640, 8640, 8640, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 8640, 540, 540, 540, 8640, 33, 540, 540, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 540, 33, 8640, 8640, 8640, 540, 33, 8640, 8640, 540, 540, 8640, 8640, 33, 8640, 8640, 540, 33, 8640, 540, 540, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 540, 8640, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 8640, 33, 33, 33, 540, 33, 540, 540, 33, 8640, 540, 8640, 33, 8640, 33, 540, 540, 540, 540, 33, 540, 8640, 8640, 33, 8640, 8640, 33, 8640, 540, 8640, 540, 540, 540, 33, 540, 33, 33, 8640, 33, 540, 33, 33, 540, 8640, 540, 8640, 33, 8640, 8640, 540, 8640, 540, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1179264 . Total input tokens: 262812336 . Total output tokens: 235601473
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 76.29229015717283,
    "estimated_duration": 3600.116218454031,
    "input_throughput": 5341.013409910706,
    "output_throughput": 4688.068099992508,
    "total_throughput": 10029.081509903213,
    "itl": 182.4630717893708,
    "ttft": 1958474.303374337,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 611,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8699580115429415,
    "arrivals": 393551,
    "finished_requests": 77852,
    "scheduler_time": 134.9121932315484
}
#Debug simulation 
Total elapsed time: 76.29245187109336. Arrivals time: 0.4063632027246058 Scheduler time: 75.73269293038175 Scheduler overhead time: 0.0600171135738492 Adapter cache time: 0.01975730713456869 Engine time: 0.05322388373315334 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-16/adapters_384_slots_96_rate_0.8-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-16/adapters_384_slots_96_rate_0.8-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 540, 33, 8640, 8640, 33, 540, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 33, 8640, 33, 8640, 540, 540, 540, 33, 33, 540, 33, 8640, 33, 8640, 540, 8640, 540, 33, 540, 8640, 540, 8640, 33, 8640, 8640, 8640, 8640, 33, 540, 540, 540, 8640, 540, 33, 540, 33, 8640, 540, 8640, 8640, 540, 8640, 8640, 33, 33, 8640, 540, 540, 33, 33, 33, 540, 33, 540, 33, 8640, 33, 540, 8640, 33, 8640, 540, 33, 8640, 8640, 8640, 8640, 540, 33, 540, 8640, 8640, 540, 33, 33, 8640, 540, 540, 33, 33, 8640, 540, 8640, 540, 8640, 8640, 540, 8640, 8640, 33, 540, 540, 540, 540, 33, 33, 8640, 33, 8640, 33, 33, 33, 540, 540, 8640, 33, 33, 8640, 33, 8640, 540, 33, 8640, 540, 540, 33, 8640, 8640, 8640, 33, 540, 8640, 33, 8640, 540, 540, 8640, 8640, 33, 540, 8640, 33, 540, 540, 33, 540, 33, 540, 8640, 8640, 540, 33, 8640, 33, 8640, 540, 540, 540, 540, 540, 33, 33, 8640, 33, 8640, 33, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 33, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 33, 33, 33, 33, 33, 540, 33, 33, 540, 8640, 8640, 33, 33, 8640, 33, 33, 33, 540, 33, 540, 8640, 8640, 540, 540, 33, 8640, 540, 8640, 33, 540, 540, 33, 33, 540, 33, 8640, 8640, 33, 8640, 8640, 33, 540, 8640, 33, 33, 540, 540, 33, 33, 8640, 8640, 8640, 8640, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 8640, 540, 540, 540, 8640, 33, 540, 540, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 540, 33, 8640, 8640, 8640, 540, 33, 8640, 8640, 540, 540, 8640, 8640, 33, 8640, 8640, 540, 33, 8640, 540, 540, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 540, 8640, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 8640, 33, 33, 33, 540, 33, 540, 540, 33, 8640, 540, 8640, 33, 8640, 33, 540, 540, 540, 540, 33, 540, 8640, 8640, 33, 8640, 8640, 33, 8640, 540, 8640, 540, 540, 540, 33, 540, 33, 33, 8640, 33, 540, 33, 33, 540, 8640, 540, 8640, 33, 8640, 8640, 540, 8640, 540, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1179264 . Total input tokens: 262812336 . Total output tokens: 235601473
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 87.61117501277477,
    "estimated_duration": 3600.068494995851,
    "input_throughput": 5339.7970140626885,
    "output_throughput": 4683.88032712123,
    "total_throughput": 10023.677341183919,
    "itl": 181.92135650506498,
    "ttft": 1951506.0691180038,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 550,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7903961908794053,
    "arrivals": 393551,
    "finished_requests": 77671,
    "scheduler_time": 135.14415829790667
}
#Debug simulation 
Total elapsed time: 87.61132466001436. Arrivals time: 0.41277315840125084 Scheduler time: 87.04362127371132 Scheduler overhead time: 0.061210078187286854 Adapter cache time: 0.018979931250214577 Engine time: 0.05426440155133605 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-32/adapters_384_slots_96_rate_0.8-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-32/adapters_384_slots_96_rate_0.8-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 540, 33, 8640, 8640, 33, 540, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 33, 8640, 33, 8640, 540, 540, 540, 33, 33, 540, 33, 8640, 33, 8640, 540, 8640, 540, 33, 540, 8640, 540, 8640, 33, 8640, 8640, 8640, 8640, 33, 540, 540, 540, 8640, 540, 33, 540, 33, 8640, 540, 8640, 8640, 540, 8640, 8640, 33, 33, 8640, 540, 540, 33, 33, 33, 540, 33, 540, 33, 8640, 33, 540, 8640, 33, 8640, 540, 33, 8640, 8640, 8640, 8640, 540, 33, 540, 8640, 8640, 540, 33, 33, 8640, 540, 540, 33, 33, 8640, 540, 8640, 540, 8640, 8640, 540, 8640, 8640, 33, 540, 540, 540, 540, 33, 33, 8640, 33, 8640, 33, 33, 33, 540, 540, 8640, 33, 33, 8640, 33, 8640, 540, 33, 8640, 540, 540, 33, 8640, 8640, 8640, 33, 540, 8640, 33, 8640, 540, 540, 8640, 8640, 33, 540, 8640, 33, 540, 540, 33, 540, 33, 540, 8640, 8640, 540, 33, 8640, 33, 8640, 540, 540, 540, 540, 540, 33, 33, 8640, 33, 8640, 33, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 33, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 33, 33, 33, 33, 33, 540, 33, 33, 540, 8640, 8640, 33, 33, 8640, 33, 33, 33, 540, 33, 540, 8640, 8640, 540, 540, 33, 8640, 540, 8640, 33, 540, 540, 33, 33, 540, 33, 8640, 8640, 33, 8640, 8640, 33, 540, 8640, 33, 33, 540, 540, 33, 33, 8640, 8640, 8640, 8640, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 8640, 540, 540, 540, 8640, 33, 540, 540, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 540, 33, 8640, 8640, 8640, 540, 33, 8640, 8640, 540, 540, 8640, 8640, 33, 8640, 8640, 540, 33, 8640, 540, 540, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 540, 8640, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 8640, 33, 33, 33, 540, 33, 540, 540, 33, 8640, 540, 8640, 33, 8640, 33, 540, 540, 540, 540, 33, 540, 8640, 8640, 33, 8640, 8640, 33, 8640, 540, 8640, 540, 540, 540, 33, 540, 33, 33, 8640, 33, 540, 33, 33, 540, 8640, 540, 8640, 33, 8640, 8640, 540, 8640, 540, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1179264 . Total input tokens: 262812336 . Total output tokens: 235601473
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 74.8014757190831,
    "estimated_duration": 3600.00190777438,
    "input_throughput": 5330.025230976227,
    "output_throughput": 4678.033909824099,
    "total_throughput": 10008.059140800327,
    "itl": 180.79202860513251,
    "ttft": 1959769.0946827307,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 633,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.066167894005785,
    "arrivals": 393551,
    "finished_requests": 77683,
    "scheduler_time": 135.36276817728148
}
#Debug simulation 
Total elapsed time: 74.80162942642346. Arrivals time: 0.3992348490282893 Scheduler time: 74.24852716038004 Scheduler overhead time: 0.05961785698309541 Adapter cache time: 0.020491714123636484 Engine time: 0.05343078728765249 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-16/adapters_384_slots_96_rate_0.8-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-16/adapters_384_slots_96_rate_0.8-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 540, 33, 8640, 8640, 33, 540, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 33, 8640, 33, 8640, 540, 540, 540, 33, 33, 540, 33, 8640, 33, 8640, 540, 8640, 540, 33, 540, 8640, 540, 8640, 33, 8640, 8640, 8640, 8640, 33, 540, 540, 540, 8640, 540, 33, 540, 33, 8640, 540, 8640, 8640, 540, 8640, 8640, 33, 33, 8640, 540, 540, 33, 33, 33, 540, 33, 540, 33, 8640, 33, 540, 8640, 33, 8640, 540, 33, 8640, 8640, 8640, 8640, 540, 33, 540, 8640, 8640, 540, 33, 33, 8640, 540, 540, 33, 33, 8640, 540, 8640, 540, 8640, 8640, 540, 8640, 8640, 33, 540, 540, 540, 540, 33, 33, 8640, 33, 8640, 33, 33, 33, 540, 540, 8640, 33, 33, 8640, 33, 8640, 540, 33, 8640, 540, 540, 33, 8640, 8640, 8640, 33, 540, 8640, 33, 8640, 540, 540, 8640, 8640, 33, 540, 8640, 33, 540, 540, 33, 540, 33, 540, 8640, 8640, 540, 33, 8640, 33, 8640, 540, 540, 540, 540, 540, 33, 33, 8640, 33, 8640, 33, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 33, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 33, 33, 33, 33, 33, 540, 33, 33, 540, 8640, 8640, 33, 33, 8640, 33, 33, 33, 540, 33, 540, 8640, 8640, 540, 540, 33, 8640, 540, 8640, 33, 540, 540, 33, 33, 540, 33, 8640, 8640, 33, 8640, 8640, 33, 540, 8640, 33, 33, 540, 540, 33, 33, 8640, 8640, 8640, 8640, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 8640, 540, 540, 540, 8640, 33, 540, 540, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 540, 33, 8640, 8640, 8640, 540, 33, 8640, 8640, 540, 540, 8640, 8640, 33, 8640, 8640, 540, 33, 8640, 540, 540, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 540, 8640, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 8640, 33, 33, 33, 540, 33, 540, 540, 33, 8640, 540, 8640, 33, 8640, 33, 540, 540, 540, 540, 33, 540, 8640, 8640, 33, 8640, 8640, 33, 8640, 540, 8640, 540, 540, 540, 33, 540, 33, 33, 8640, 33, 540, 33, 33, 540, 8640, 540, 8640, 33, 8640, 8640, 540, 8640, 540, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1179264 . Total input tokens: 262812336 . Total output tokens: 235601473
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 76.01304640527815,
    "estimated_duration": 3600.0631900033477,
    "input_throughput": 5341.963733692718,
    "output_throughput": 4688.531314358486,
    "total_throughput": 10030.495048051203,
    "itl": 182.4541364079366,
    "ttft": 1958607.243544517,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 642,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0029657342890124,
    "arrivals": 393551,
    "finished_requests": 77865,
    "scheduler_time": 134.90886086956905
}
#Debug simulation 
Total elapsed time: 76.01320398505777. Arrivals time: 0.40977542474865913 Scheduler time: 75.44957961514592 Scheduler overhead time: 0.060338306706398726 Adapter cache time: 0.019609838258475065 Engine time: 0.05309738824144006 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-32/adapters_384_slots_96_rate_0.8-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-32/adapters_384_slots_96_rate_0.8-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 540, 33, 8640, 8640, 33, 540, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 33, 8640, 33, 8640, 540, 540, 540, 33, 33, 540, 33, 8640, 33, 8640, 540, 8640, 540, 33, 540, 8640, 540, 8640, 33, 8640, 8640, 8640, 8640, 33, 540, 540, 540, 8640, 540, 33, 540, 33, 8640, 540, 8640, 8640, 540, 8640, 8640, 33, 33, 8640, 540, 540, 33, 33, 33, 540, 33, 540, 33, 8640, 33, 540, 8640, 33, 8640, 540, 33, 8640, 8640, 8640, 8640, 540, 33, 540, 8640, 8640, 540, 33, 33, 8640, 540, 540, 33, 33, 8640, 540, 8640, 540, 8640, 8640, 540, 8640, 8640, 33, 540, 540, 540, 540, 33, 33, 8640, 33, 8640, 33, 33, 33, 540, 540, 8640, 33, 33, 8640, 33, 8640, 540, 33, 8640, 540, 540, 33, 8640, 8640, 8640, 33, 540, 8640, 33, 8640, 540, 540, 8640, 8640, 33, 540, 8640, 33, 540, 540, 33, 540, 33, 540, 8640, 8640, 540, 33, 8640, 33, 8640, 540, 540, 540, 540, 540, 33, 33, 8640, 33, 8640, 33, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 33, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 33, 33, 33, 33, 33, 540, 33, 33, 540, 8640, 8640, 33, 33, 8640, 33, 33, 33, 540, 33, 540, 8640, 8640, 540, 540, 33, 8640, 540, 8640, 33, 540, 540, 33, 33, 540, 33, 8640, 8640, 33, 8640, 8640, 33, 540, 8640, 33, 33, 540, 540, 33, 33, 8640, 8640, 8640, 8640, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 8640, 540, 540, 540, 8640, 33, 540, 540, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 540, 33, 8640, 8640, 8640, 540, 33, 8640, 8640, 540, 540, 8640, 8640, 33, 8640, 8640, 540, 33, 8640, 540, 540, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 540, 8640, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 8640, 33, 33, 33, 540, 33, 540, 540, 33, 8640, 540, 8640, 33, 8640, 33, 540, 540, 540, 540, 33, 540, 8640, 8640, 33, 8640, 8640, 33, 8640, 540, 8640, 540, 540, 540, 33, 540, 33, 33, 8640, 33, 540, 33, 33, 540, 8640, 540, 8640, 33, 8640, 8640, 540, 8640, 540, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1179264 . Total input tokens: 262812336 . Total output tokens: 235601473
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 75.41051522269845,
    "estimated_duration": 3600.0289460553868,
    "input_throughput": 5329.985199431446,
    "output_throughput": 4677.998775107877,
    "total_throughput": 10007.983974539324,
    "itl": 180.79279468643247,
    "ttft": 1959775.8201853777,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 633,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0923246815800693,
    "arrivals": 393551,
    "finished_requests": 77683,
    "scheduler_time": 135.36295294916536
}
#Debug simulation 
Total elapsed time: 75.41067949589342. Arrivals time: 0.41242643212899566 Scheduler time: 74.84518646541983 Scheduler overhead time: 0.05909562762826681 Adapter cache time: 0.02046188898384571 Engine time: 0.05303809279575944 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-16/adapters_384_slots_96_rate_0.8-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-16/adapters_384_slots_96_rate_0.8-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 540, 33, 8640, 8640, 33, 540, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 33, 8640, 33, 8640, 540, 540, 540, 33, 33, 540, 33, 8640, 33, 8640, 540, 8640, 540, 33, 540, 8640, 540, 8640, 33, 8640, 8640, 8640, 8640, 33, 540, 540, 540, 8640, 540, 33, 540, 33, 8640, 540, 8640, 8640, 540, 8640, 8640, 33, 33, 8640, 540, 540, 33, 33, 33, 540, 33, 540, 33, 8640, 33, 540, 8640, 33, 8640, 540, 33, 8640, 8640, 8640, 8640, 540, 33, 540, 8640, 8640, 540, 33, 33, 8640, 540, 540, 33, 33, 8640, 540, 8640, 540, 8640, 8640, 540, 8640, 8640, 33, 540, 540, 540, 540, 33, 33, 8640, 33, 8640, 33, 33, 33, 540, 540, 8640, 33, 33, 8640, 33, 8640, 540, 33, 8640, 540, 540, 33, 8640, 8640, 8640, 33, 540, 8640, 33, 8640, 540, 540, 8640, 8640, 33, 540, 8640, 33, 540, 540, 33, 540, 33, 540, 8640, 8640, 540, 33, 8640, 33, 8640, 540, 540, 540, 540, 540, 33, 33, 8640, 33, 8640, 33, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 33, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 33, 33, 33, 33, 33, 540, 33, 33, 540, 8640, 8640, 33, 33, 8640, 33, 33, 33, 540, 33, 540, 8640, 8640, 540, 540, 33, 8640, 540, 8640, 33, 540, 540, 33, 33, 540, 33, 8640, 8640, 33, 8640, 8640, 33, 540, 8640, 33, 33, 540, 540, 33, 33, 8640, 8640, 8640, 8640, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 8640, 540, 540, 540, 8640, 33, 540, 540, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 540, 33, 8640, 8640, 8640, 540, 33, 8640, 8640, 540, 540, 8640, 8640, 33, 8640, 8640, 540, 33, 8640, 540, 540, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 540, 8640, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 8640, 33, 33, 33, 540, 33, 540, 540, 33, 8640, 540, 8640, 33, 8640, 33, 540, 540, 540, 540, 33, 540, 8640, 8640, 33, 8640, 8640, 33, 8640, 540, 8640, 540, 540, 540, 33, 540, 33, 33, 8640, 33, 540, 33, 33, 540, 8640, 540, 8640, 33, 8640, 8640, 540, 8640, 540, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1179264 . Total input tokens: 262812336 . Total output tokens: 235601473
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 76.22370311804116,
    "estimated_duration": 3600.06837118924,
    "input_throughput": 5341.084395474458,
    "output_throughput": 4688.130407485757,
    "total_throughput": 10029.214802960216,
    "itl": 182.46146837395347,
    "ttft": 1958463.3379440985,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 611,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8269207301852013,
    "arrivals": 393551,
    "finished_requests": 77852,
    "scheduler_time": 134.91177258266475
}
#Debug simulation 
Total elapsed time: 76.223863852676. Arrivals time: 0.4064771067351103 Scheduler time: 75.66568970354274 Scheduler overhead time: 0.058740106876939535 Adapter cache time: 0.02015703683719039 Engine time: 0.052504672203212976 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-32/adapters_384_slots_96_rate_0.8-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-32/adapters_384_slots_96_rate_0.8-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 540, 33, 8640, 8640, 33, 540, 8640, 8640, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 33, 8640, 33, 8640, 540, 540, 540, 33, 33, 540, 33, 8640, 33, 8640, 540, 8640, 540, 33, 540, 8640, 540, 8640, 33, 8640, 8640, 8640, 8640, 33, 540, 540, 540, 8640, 540, 33, 540, 33, 8640, 540, 8640, 8640, 540, 8640, 8640, 33, 33, 8640, 540, 540, 33, 33, 33, 540, 33, 540, 33, 8640, 33, 540, 8640, 33, 8640, 540, 33, 8640, 8640, 8640, 8640, 540, 33, 540, 8640, 8640, 540, 33, 33, 8640, 540, 540, 33, 33, 8640, 540, 8640, 540, 8640, 8640, 540, 8640, 8640, 33, 540, 540, 540, 540, 33, 33, 8640, 33, 8640, 33, 33, 33, 540, 540, 8640, 33, 33, 8640, 33, 8640, 540, 33, 8640, 540, 540, 33, 8640, 8640, 8640, 33, 540, 8640, 33, 8640, 540, 540, 8640, 8640, 33, 540, 8640, 33, 540, 540, 33, 540, 33, 540, 8640, 8640, 540, 33, 8640, 33, 8640, 540, 540, 540, 540, 540, 33, 33, 8640, 33, 8640, 33, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 33, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 33, 33, 33, 33, 33, 540, 33, 33, 540, 8640, 8640, 33, 33, 8640, 33, 33, 33, 540, 33, 540, 8640, 8640, 540, 540, 33, 8640, 540, 8640, 33, 540, 540, 33, 33, 540, 33, 8640, 8640, 33, 8640, 8640, 33, 540, 8640, 33, 33, 540, 540, 33, 33, 8640, 8640, 8640, 8640, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 8640, 540, 540, 540, 8640, 33, 540, 540, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 540, 33, 8640, 8640, 8640, 540, 33, 8640, 8640, 540, 540, 8640, 8640, 33, 8640, 8640, 540, 33, 8640, 540, 540, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 540, 8640, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 8640, 33, 33, 33, 540, 33, 540, 540, 33, 8640, 540, 8640, 33, 8640, 33, 540, 540, 540, 540, 33, 540, 8640, 8640, 33, 8640, 8640, 33, 8640, 540, 8640, 540, 540, 540, 33, 540, 33, 33, 8640, 33, 540, 33, 33, 540, 8640, 540, 8640, 33, 8640, 8640, 540, 8640, 540, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1179264 . Total input tokens: 262812336 . Total output tokens: 235601473
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 74.78823791584,
    "estimated_duration": 3600.0571915956907,
    "input_throughput": 5329.9433811203035,
    "output_throughput": 4677.962072190142,
    "total_throughput": 10007.905453310444,
    "itl": 180.79214456784328,
    "ttft": 1959783.4563151936,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 633,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.118229961581527,
    "arrivals": 393551,
    "finished_requests": 77683,
    "scheduler_time": 135.36400243930538
}
#Debug simulation 
Total elapsed time: 74.78840809687972. Arrivals time: 0.3966516419313848 Scheduler time: 74.23754830425605 Scheduler overhead time: 0.06106160627678037 Adapter cache time: 0.020011025480926037 Engine time: 0.05277371732518077 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-8/adapters_384_slots_96_rate_0.8-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-8/adapters_384_slots_96_rate_0.8-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 8640, 270, 135, 8640, 8640, 135, 270, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 135, 8640, 135, 8640, 270, 270, 270, 135, 135, 270, 135, 8640, 135, 8640, 270, 8640, 270, 135, 270, 8640, 270, 8640, 135, 8640, 8640, 8640, 8640, 135, 270, 270, 270, 8640, 270, 135, 270, 135, 8640, 270, 8640, 8640, 270, 8640, 8640, 135, 135, 8640, 270, 270, 135, 135, 135, 270, 135, 270, 135, 8640, 135, 270, 8640, 135, 8640, 270, 135, 8640, 8640, 8640, 8640, 270, 135, 270, 8640, 8640, 270, 135, 135, 8640, 270, 270, 135, 135, 8640, 270, 8640, 270, 8640, 8640, 270, 8640, 8640, 135, 270, 270, 270, 270, 135, 135, 8640, 135, 8640, 135, 135, 135, 270, 270, 8640, 135, 135, 8640, 135, 8640, 270, 135, 8640, 270, 270, 135, 8640, 8640, 8640, 135, 270, 8640, 135, 8640, 270, 270, 8640, 8640, 135, 270, 8640, 135, 270, 270, 135, 270, 135, 270, 8640, 8640, 270, 135, 8640, 135, 8640, 270, 270, 270, 270, 270, 135, 135, 8640, 135, 8640, 135, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 135, 270, 270, 270, 270, 270, 270, 270, 270, 8640, 135, 135, 135, 135, 135, 270, 135, 135, 270, 8640, 8640, 135, 135, 8640, 135, 135, 135, 270, 135, 270, 8640, 8640, 270, 270, 135, 8640, 270, 8640, 135, 270, 270, 135, 135, 270, 135, 8640, 8640, 135, 8640, 8640, 135, 270, 8640, 135, 135, 270, 270, 135, 135, 8640, 8640, 8640, 8640, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 8640, 270, 270, 270, 8640, 135, 270, 270, 8640, 8640, 135, 8640, 8640, 135, 8640, 135, 135, 270, 135, 8640, 8640, 8640, 270, 135, 8640, 8640, 270, 270, 8640, 8640, 135, 8640, 8640, 270, 135, 8640, 270, 270, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 135, 8640, 135, 270, 8640, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 8640, 135, 135, 135, 270, 135, 270, 270, 135, 8640, 270, 8640, 135, 8640, 135, 270, 270, 270, 270, 135, 270, 8640, 8640, 135, 8640, 8640, 135, 8640, 270, 8640, 270, 270, 270, 135, 270, 135, 135, 8640, 135, 270, 135, 135, 270, 8640, 270, 8640, 135, 8640, 8640, 270, 8640, 270, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1157760 . Total input tokens: 258012646 . Total output tokens: 231273658
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 96.02275585196912,
    "estimated_duration": 3600.177569208831,
    "input_throughput": 5316.475821554055,
    "output_throughput": 4686.159967300598,
    "total_throughput": 10002.635788854654,
    "itl": 182.2266660882165,
    "ttft": 1929760.7254694628,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 519,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5883931391011183,
    "arrivals": 386177,
    "finished_requests": 77524,
    "scheduler_time": 135.10423225964087
}
#Debug simulation 
Total elapsed time: 96.02291741408408. Arrivals time: 0.4130486431531608 Scheduler time: 95.45174461044371 Scheduler overhead time: 0.0630401992239058 Adapter cache time: 0.01851483713835478 Engine time: 0.05549659812822938 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-16/adapters_384_slots_96_rate_0.8-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-16/adapters_384_slots_96_rate_0.8-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 8640, 270, 135, 8640, 8640, 135, 270, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 135, 8640, 135, 8640, 270, 270, 270, 135, 135, 270, 135, 8640, 135, 8640, 270, 8640, 270, 135, 270, 8640, 270, 8640, 135, 8640, 8640, 8640, 8640, 135, 270, 270, 270, 8640, 270, 135, 270, 135, 8640, 270, 8640, 8640, 270, 8640, 8640, 135, 135, 8640, 270, 270, 135, 135, 135, 270, 135, 270, 135, 8640, 135, 270, 8640, 135, 8640, 270, 135, 8640, 8640, 8640, 8640, 270, 135, 270, 8640, 8640, 270, 135, 135, 8640, 270, 270, 135, 135, 8640, 270, 8640, 270, 8640, 8640, 270, 8640, 8640, 135, 270, 270, 270, 270, 135, 135, 8640, 135, 8640, 135, 135, 135, 270, 270, 8640, 135, 135, 8640, 135, 8640, 270, 135, 8640, 270, 270, 135, 8640, 8640, 8640, 135, 270, 8640, 135, 8640, 270, 270, 8640, 8640, 135, 270, 8640, 135, 270, 270, 135, 270, 135, 270, 8640, 8640, 270, 135, 8640, 135, 8640, 270, 270, 270, 270, 270, 135, 135, 8640, 135, 8640, 135, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 135, 270, 270, 270, 270, 270, 270, 270, 270, 8640, 135, 135, 135, 135, 135, 270, 135, 135, 270, 8640, 8640, 135, 135, 8640, 135, 135, 135, 270, 135, 270, 8640, 8640, 270, 270, 135, 8640, 270, 8640, 135, 270, 270, 135, 135, 270, 135, 8640, 8640, 135, 8640, 8640, 135, 270, 8640, 135, 135, 270, 270, 135, 135, 8640, 8640, 8640, 8640, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 8640, 270, 270, 270, 8640, 135, 270, 270, 8640, 8640, 135, 8640, 8640, 135, 8640, 135, 135, 270, 135, 8640, 8640, 8640, 270, 135, 8640, 8640, 270, 270, 8640, 8640, 135, 8640, 8640, 270, 135, 8640, 270, 270, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 135, 8640, 135, 270, 8640, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 8640, 135, 135, 135, 270, 135, 270, 270, 135, 8640, 270, 8640, 135, 8640, 135, 270, 270, 270, 270, 135, 270, 8640, 8640, 135, 8640, 8640, 135, 8640, 270, 8640, 270, 270, 270, 135, 270, 135, 135, 8640, 135, 270, 135, 135, 270, 8640, 270, 8640, 135, 8640, 8640, 270, 8640, 270, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1157760 . Total input tokens: 258012646 . Total output tokens: 231273658
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 96.09920295327902,
    "estimated_duration": 3600.052756813543,
    "input_throughput": 5316.156815696141,
    "output_throughput": 4685.750776311107,
    "total_throughput": 10001.907592007248,
    "itl": 182.22852975375184,
    "ttft": 1929638.5407641188,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 502,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.637067489081533,
    "arrivals": 386177,
    "finished_requests": 77515,
    "scheduler_time": 135.09945154988276
}
#Debug simulation 
Total elapsed time: 96.09936227789149. Arrivals time: 0.43111103074625134 Scheduler time: 95.50732170324773 Scheduler overhead time: 0.06467334320768714 Adapter cache time: 0.018407687544822693 Engine time: 0.05645344452932477 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-32/adapters_384_slots_96_rate_0.8-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-32/adapters_384_slots_96_rate_0.8-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 8640, 270, 135, 8640, 8640, 135, 270, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 135, 8640, 135, 8640, 270, 270, 270, 135, 135, 270, 135, 8640, 135, 8640, 270, 8640, 270, 135, 270, 8640, 270, 8640, 135, 8640, 8640, 8640, 8640, 135, 270, 270, 270, 8640, 270, 135, 270, 135, 8640, 270, 8640, 8640, 270, 8640, 8640, 135, 135, 8640, 270, 270, 135, 135, 135, 270, 135, 270, 135, 8640, 135, 270, 8640, 135, 8640, 270, 135, 8640, 8640, 8640, 8640, 270, 135, 270, 8640, 8640, 270, 135, 135, 8640, 270, 270, 135, 135, 8640, 270, 8640, 270, 8640, 8640, 270, 8640, 8640, 135, 270, 270, 270, 270, 135, 135, 8640, 135, 8640, 135, 135, 135, 270, 270, 8640, 135, 135, 8640, 135, 8640, 270, 135, 8640, 270, 270, 135, 8640, 8640, 8640, 135, 270, 8640, 135, 8640, 270, 270, 8640, 8640, 135, 270, 8640, 135, 270, 270, 135, 270, 135, 270, 8640, 8640, 270, 135, 8640, 135, 8640, 270, 270, 270, 270, 270, 135, 135, 8640, 135, 8640, 135, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 135, 270, 270, 270, 270, 270, 270, 270, 270, 8640, 135, 135, 135, 135, 135, 270, 135, 135, 270, 8640, 8640, 135, 135, 8640, 135, 135, 135, 270, 135, 270, 8640, 8640, 270, 270, 135, 8640, 270, 8640, 135, 270, 270, 135, 135, 270, 135, 8640, 8640, 135, 8640, 8640, 135, 270, 8640, 135, 135, 270, 270, 135, 135, 8640, 8640, 8640, 8640, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 8640, 270, 270, 270, 8640, 135, 270, 270, 8640, 8640, 135, 8640, 8640, 135, 8640, 135, 135, 270, 135, 8640, 8640, 8640, 270, 135, 8640, 8640, 270, 270, 8640, 8640, 135, 8640, 8640, 270, 135, 8640, 270, 270, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 135, 8640, 135, 270, 8640, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 8640, 135, 135, 135, 270, 135, 270, 270, 135, 8640, 270, 8640, 135, 8640, 135, 270, 270, 270, 270, 135, 270, 8640, 8640, 135, 8640, 8640, 135, 8640, 270, 8640, 270, 270, 270, 135, 270, 135, 135, 8640, 135, 270, 135, 135, 270, 8640, 270, 8640, 135, 8640, 8640, 270, 8640, 270, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1157760 . Total input tokens: 258012646 . Total output tokens: 231273658
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 94.54816173389554,
    "estimated_duration": 3600.1720106713988,
    "input_throughput": 5304.674872031586,
    "output_throughput": 4678.733946620152,
    "total_throughput": 9983.408818651738,
    "itl": 180.7981236150147,
    "ttft": 1929967.0177444597,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 511,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6692277848720651,
    "arrivals": 386177,
    "finished_requests": 77366,
    "scheduler_time": 135.50561909319944
}
#Debug simulation 
Total elapsed time: 94.54830910312012. Arrivals time: 0.4172042356804013 Scheduler time: 93.97156004048884 Scheduler overhead time: 0.063225366640836 Adapter cache time: 0.01841446617618203 Engine time: 0.056641384959220886 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-16/adapters_384_slots_96_rate_0.8-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-16/adapters_384_slots_96_rate_0.8-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 8640, 270, 135, 8640, 8640, 135, 270, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 135, 8640, 135, 8640, 270, 270, 270, 135, 135, 270, 135, 8640, 135, 8640, 270, 8640, 270, 135, 270, 8640, 270, 8640, 135, 8640, 8640, 8640, 8640, 135, 270, 270, 270, 8640, 270, 135, 270, 135, 8640, 270, 8640, 8640, 270, 8640, 8640, 135, 135, 8640, 270, 270, 135, 135, 135, 270, 135, 270, 135, 8640, 135, 270, 8640, 135, 8640, 270, 135, 8640, 8640, 8640, 8640, 270, 135, 270, 8640, 8640, 270, 135, 135, 8640, 270, 270, 135, 135, 8640, 270, 8640, 270, 8640, 8640, 270, 8640, 8640, 135, 270, 270, 270, 270, 135, 135, 8640, 135, 8640, 135, 135, 135, 270, 270, 8640, 135, 135, 8640, 135, 8640, 270, 135, 8640, 270, 270, 135, 8640, 8640, 8640, 135, 270, 8640, 135, 8640, 270, 270, 8640, 8640, 135, 270, 8640, 135, 270, 270, 135, 270, 135, 270, 8640, 8640, 270, 135, 8640, 135, 8640, 270, 270, 270, 270, 270, 135, 135, 8640, 135, 8640, 135, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 135, 270, 270, 270, 270, 270, 270, 270, 270, 8640, 135, 135, 135, 135, 135, 270, 135, 135, 270, 8640, 8640, 135, 135, 8640, 135, 135, 135, 270, 135, 270, 8640, 8640, 270, 270, 135, 8640, 270, 8640, 135, 270, 270, 135, 135, 270, 135, 8640, 8640, 135, 8640, 8640, 135, 270, 8640, 135, 135, 270, 270, 135, 135, 8640, 8640, 8640, 8640, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 8640, 270, 270, 270, 8640, 135, 270, 270, 8640, 8640, 135, 8640, 8640, 135, 8640, 135, 135, 270, 135, 8640, 8640, 8640, 270, 135, 8640, 8640, 270, 270, 8640, 8640, 135, 8640, 8640, 270, 135, 8640, 270, 270, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 135, 8640, 135, 270, 8640, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 8640, 135, 135, 135, 270, 135, 270, 270, 135, 8640, 270, 8640, 135, 8640, 135, 270, 270, 270, 270, 135, 270, 8640, 8640, 135, 8640, 8640, 135, 8640, 270, 8640, 270, 270, 270, 135, 270, 135, 135, 8640, 135, 270, 135, 135, 270, 8640, 270, 8640, 135, 8640, 8640, 270, 8640, 270, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1157760 . Total input tokens: 258012646 . Total output tokens: 231273658
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 95.66935742693022,
    "estimated_duration": 3600.0018334707906,
    "input_throughput": 5316.293125758844,
    "output_throughput": 4685.846502399252,
    "total_throughput": 10002.139628158096,
    "itl": 182.22793236323486,
    "ttft": 1929654.5134282336,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 520,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6234701668471012,
    "arrivals": 386177,
    "finished_requests": 77518,
    "scheduler_time": 135.09761068652605
}
#Debug simulation 
Total elapsed time: 95.66951862117276. Arrivals time: 0.42223867448046803 Scheduler time: 95.08798650885001 Scheduler overhead time: 0.06387768499553204 Adapter cache time: 0.018253828398883343 Engine time: 0.05584359308704734 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-32/adapters_384_slots_96_rate_0.8-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-32/adapters_384_slots_96_rate_0.8-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 8640, 270, 135, 8640, 8640, 135, 270, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 135, 8640, 135, 8640, 270, 270, 270, 135, 135, 270, 135, 8640, 135, 8640, 270, 8640, 270, 135, 270, 8640, 270, 8640, 135, 8640, 8640, 8640, 8640, 135, 270, 270, 270, 8640, 270, 135, 270, 135, 8640, 270, 8640, 8640, 270, 8640, 8640, 135, 135, 8640, 270, 270, 135, 135, 135, 270, 135, 270, 135, 8640, 135, 270, 8640, 135, 8640, 270, 135, 8640, 8640, 8640, 8640, 270, 135, 270, 8640, 8640, 270, 135, 135, 8640, 270, 270, 135, 135, 8640, 270, 8640, 270, 8640, 8640, 270, 8640, 8640, 135, 270, 270, 270, 270, 135, 135, 8640, 135, 8640, 135, 135, 135, 270, 270, 8640, 135, 135, 8640, 135, 8640, 270, 135, 8640, 270, 270, 135, 8640, 8640, 8640, 135, 270, 8640, 135, 8640, 270, 270, 8640, 8640, 135, 270, 8640, 135, 270, 270, 135, 270, 135, 270, 8640, 8640, 270, 135, 8640, 135, 8640, 270, 270, 270, 270, 270, 135, 135, 8640, 135, 8640, 135, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 135, 270, 270, 270, 270, 270, 270, 270, 270, 8640, 135, 135, 135, 135, 135, 270, 135, 135, 270, 8640, 8640, 135, 135, 8640, 135, 135, 135, 270, 135, 270, 8640, 8640, 270, 270, 135, 8640, 270, 8640, 135, 270, 270, 135, 135, 270, 135, 8640, 8640, 135, 8640, 8640, 135, 270, 8640, 135, 135, 270, 270, 135, 135, 8640, 8640, 8640, 8640, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 8640, 270, 270, 270, 8640, 135, 270, 270, 8640, 8640, 135, 8640, 8640, 135, 8640, 135, 135, 270, 135, 8640, 8640, 8640, 270, 135, 8640, 8640, 270, 270, 8640, 8640, 135, 8640, 8640, 270, 135, 8640, 270, 270, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 135, 8640, 135, 270, 8640, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 8640, 135, 135, 135, 270, 135, 270, 270, 135, 8640, 270, 8640, 135, 8640, 135, 270, 270, 270, 270, 135, 270, 8640, 8640, 135, 8640, 8640, 135, 8640, 270, 8640, 270, 270, 270, 135, 270, 135, 135, 8640, 135, 270, 135, 135, 270, 8640, 270, 8640, 135, 8640, 8640, 270, 8640, 270, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1157760 . Total input tokens: 258012646 . Total output tokens: 231273658
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 94.70309137366712,
    "estimated_duration": 3600.1956855873686,
    "input_throughput": 5304.639988446689,
    "output_throughput": 4678.703179227847,
    "total_throughput": 9983.343167674537,
    "itl": 180.79830855854834,
    "ttft": 1929973.028586433,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 511,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6906059285625854,
    "arrivals": 386177,
    "finished_requests": 77366,
    "scheduler_time": 135.50606032166002
}
#Debug simulation 
Total elapsed time: 94.70323400292546. Arrivals time: 0.42568900855258107 Scheduler time: 94.11728960974142 Scheduler overhead time: 0.06452529644593596 Adapter cache time: 0.018734481185674667 Engine time: 0.05584962898865342 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-16/adapters_384_slots_96_rate_0.8-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-16/adapters_384_slots_96_rate_0.8-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 8640, 270, 135, 8640, 8640, 135, 270, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 135, 8640, 135, 8640, 270, 270, 270, 135, 135, 270, 135, 8640, 135, 8640, 270, 8640, 270, 135, 270, 8640, 270, 8640, 135, 8640, 8640, 8640, 8640, 135, 270, 270, 270, 8640, 270, 135, 270, 135, 8640, 270, 8640, 8640, 270, 8640, 8640, 135, 135, 8640, 270, 270, 135, 135, 135, 270, 135, 270, 135, 8640, 135, 270, 8640, 135, 8640, 270, 135, 8640, 8640, 8640, 8640, 270, 135, 270, 8640, 8640, 270, 135, 135, 8640, 270, 270, 135, 135, 8640, 270, 8640, 270, 8640, 8640, 270, 8640, 8640, 135, 270, 270, 270, 270, 135, 135, 8640, 135, 8640, 135, 135, 135, 270, 270, 8640, 135, 135, 8640, 135, 8640, 270, 135, 8640, 270, 270, 135, 8640, 8640, 8640, 135, 270, 8640, 135, 8640, 270, 270, 8640, 8640, 135, 270, 8640, 135, 270, 270, 135, 270, 135, 270, 8640, 8640, 270, 135, 8640, 135, 8640, 270, 270, 270, 270, 270, 135, 135, 8640, 135, 8640, 135, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 135, 270, 270, 270, 270, 270, 270, 270, 270, 8640, 135, 135, 135, 135, 135, 270, 135, 135, 270, 8640, 8640, 135, 135, 8640, 135, 135, 135, 270, 135, 270, 8640, 8640, 270, 270, 135, 8640, 270, 8640, 135, 270, 270, 135, 135, 270, 135, 8640, 8640, 135, 8640, 8640, 135, 270, 8640, 135, 135, 270, 270, 135, 135, 8640, 8640, 8640, 8640, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 8640, 270, 270, 270, 8640, 135, 270, 270, 8640, 8640, 135, 8640, 8640, 135, 8640, 135, 135, 270, 135, 8640, 8640, 8640, 270, 135, 8640, 8640, 270, 270, 8640, 8640, 135, 8640, 8640, 270, 135, 8640, 270, 270, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 135, 8640, 135, 270, 8640, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 8640, 135, 135, 135, 270, 135, 270, 270, 135, 8640, 270, 8640, 135, 8640, 135, 270, 270, 270, 270, 135, 270, 8640, 8640, 135, 8640, 8640, 135, 8640, 270, 8640, 270, 270, 270, 135, 270, 135, 135, 8640, 135, 270, 135, 135, 270, 8640, 270, 8640, 135, 8640, 8640, 270, 8640, 270, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1157760 . Total input tokens: 258012646 . Total output tokens: 231273658
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 95.10586752882227,
    "estimated_duration": 3600.035122435428,
    "input_throughput": 5316.379243281477,
    "output_throughput": 4686.216502406525,
    "total_throughput": 10002.595745688002,
    "itl": 182.2251893917294,
    "ttft": 1929614.7841497734,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 517,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5458560024644068,
    "arrivals": 386177,
    "finished_requests": 77521,
    "scheduler_time": 135.10054079877682
}
#Debug simulation 
Total elapsed time: 95.10601737396792. Arrivals time: 0.4248869423754513 Scheduler time: 94.52360122883692 Scheduler overhead time: 0.06334331026300788 Adapter cache time: 0.017642967402935028 Engine time: 0.0558737856335938 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-32/adapters_384_slots_96_rate_0.8-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-32/adapters_384_slots_96_rate_0.8-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 8640, 270, 135, 8640, 8640, 135, 270, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 135, 8640, 135, 8640, 270, 270, 270, 135, 135, 270, 135, 8640, 135, 8640, 270, 8640, 270, 135, 270, 8640, 270, 8640, 135, 8640, 8640, 8640, 8640, 135, 270, 270, 270, 8640, 270, 135, 270, 135, 8640, 270, 8640, 8640, 270, 8640, 8640, 135, 135, 8640, 270, 270, 135, 135, 135, 270, 135, 270, 135, 8640, 135, 270, 8640, 135, 8640, 270, 135, 8640, 8640, 8640, 8640, 270, 135, 270, 8640, 8640, 270, 135, 135, 8640, 270, 270, 135, 135, 8640, 270, 8640, 270, 8640, 8640, 270, 8640, 8640, 135, 270, 270, 270, 270, 135, 135, 8640, 135, 8640, 135, 135, 135, 270, 270, 8640, 135, 135, 8640, 135, 8640, 270, 135, 8640, 270, 270, 135, 8640, 8640, 8640, 135, 270, 8640, 135, 8640, 270, 270, 8640, 8640, 135, 270, 8640, 135, 270, 270, 135, 270, 135, 270, 8640, 8640, 270, 135, 8640, 135, 8640, 270, 270, 270, 270, 270, 135, 135, 8640, 135, 8640, 135, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 135, 270, 270, 270, 270, 270, 270, 270, 270, 8640, 135, 135, 135, 135, 135, 270, 135, 135, 270, 8640, 8640, 135, 135, 8640, 135, 135, 135, 270, 135, 270, 8640, 8640, 270, 270, 135, 8640, 270, 8640, 135, 270, 270, 135, 135, 270, 135, 8640, 8640, 135, 8640, 8640, 135, 270, 8640, 135, 135, 270, 270, 135, 135, 8640, 8640, 8640, 8640, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 8640, 270, 270, 270, 8640, 135, 270, 270, 8640, 8640, 135, 8640, 8640, 135, 8640, 135, 135, 270, 135, 8640, 8640, 8640, 270, 135, 8640, 8640, 270, 270, 8640, 8640, 135, 8640, 8640, 270, 135, 8640, 270, 270, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 135, 8640, 135, 270, 8640, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 8640, 135, 135, 135, 270, 135, 270, 270, 135, 8640, 270, 8640, 135, 8640, 135, 270, 270, 270, 270, 135, 270, 8640, 8640, 135, 8640, 8640, 135, 8640, 270, 8640, 270, 270, 270, 135, 270, 135, 135, 8640, 135, 270, 135, 135, 270, 8640, 270, 8640, 135, 8640, 8640, 270, 8640, 270, 135, 8640, 135, 8640, 8640, 135, 135, 135]
Prompts retrieved: 1157760 . Total input tokens: 258012646 . Total output tokens: 231273658
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 94.10801740596071,
    "estimated_duration": 3600.0158365457514,
    "input_throughput": 5303.76166853769,
    "output_throughput": 4678.0483099649755,
    "total_throughput": 9981.809978502664,
    "itl": 180.79626276320178,
    "ttft": 1929925.7138906433,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 510,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7082260445505362,
    "arrivals": 386177,
    "finished_requests": 77355,
    "scheduler_time": 135.49856327109828
}
#Debug simulation 
Total elapsed time: 94.10816910490394. Arrivals time: 0.4164769146591425 Scheduler time: 93.53479826357216 Scheduler overhead time: 0.06229740008711815 Adapter cache time: 0.017708007246255875 Engine time: 0.05601610662415624 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-8/adapters_384_slots_96_rate_0.8-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-8/adapters_384_slots_96_rate_0.8-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 8640, 270, 66, 8640, 8640, 66, 270, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 66, 8640, 66, 8640, 270, 270, 270, 66, 66, 270, 66, 8640, 66, 8640, 270, 8640, 270, 66, 270, 8640, 270, 8640, 66, 8640, 8640, 8640, 8640, 66, 270, 270, 270, 8640, 270, 66, 270, 66, 8640, 270, 8640, 8640, 270, 8640, 8640, 66, 66, 8640, 270, 270, 66, 66, 66, 270, 66, 270, 66, 8640, 66, 270, 8640, 66, 8640, 270, 66, 8640, 8640, 8640, 8640, 270, 66, 270, 8640, 8640, 270, 66, 66, 8640, 270, 270, 66, 66, 8640, 270, 8640, 270, 8640, 8640, 270, 8640, 8640, 66, 270, 270, 270, 270, 66, 66, 8640, 66, 8640, 66, 66, 66, 270, 270, 8640, 66, 66, 8640, 66, 8640, 270, 66, 8640, 270, 270, 66, 8640, 8640, 8640, 66, 270, 8640, 66, 8640, 270, 270, 8640, 8640, 66, 270, 8640, 66, 270, 270, 66, 270, 66, 270, 8640, 8640, 270, 66, 8640, 66, 8640, 270, 270, 270, 270, 270, 66, 66, 8640, 66, 8640, 66, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 66, 270, 270, 270, 270, 270, 270, 270, 270, 8640, 66, 66, 66, 66, 66, 270, 66, 66, 270, 8640, 8640, 66, 66, 8640, 66, 66, 66, 270, 66, 270, 8640, 8640, 270, 270, 66, 8640, 270, 8640, 66, 270, 270, 66, 66, 270, 66, 8640, 8640, 66, 8640, 8640, 66, 270, 8640, 66, 66, 270, 270, 66, 66, 8640, 8640, 8640, 8640, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 8640, 270, 270, 270, 8640, 66, 270, 270, 8640, 8640, 66, 8640, 8640, 66, 8640, 66, 66, 270, 66, 8640, 8640, 8640, 270, 66, 8640, 8640, 270, 270, 8640, 8640, 66, 8640, 8640, 270, 66, 8640, 270, 270, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 66, 8640, 66, 270, 8640, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 8640, 66, 66, 66, 270, 66, 270, 270, 66, 8640, 270, 8640, 66, 8640, 66, 270, 270, 270, 270, 66, 270, 8640, 8640, 66, 8640, 8640, 66, 8640, 270, 8640, 270, 270, 270, 66, 270, 66, 66, 8640, 66, 270, 66, 66, 270, 8640, 270, 8640, 66, 8640, 8640, 270, 8640, 270, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1148928 . Total input tokens: 256018509 . Total output tokens: 229496176
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 82.1696391091682,
    "estimated_duration": 3600.01521802713,
    "input_throughput": 5306.929788610695,
    "output_throughput": 4689.6662868142275,
    "total_throughput": 9996.596075424923,
    "itl": 183.36759818129642,
    "ttft": 1951528.2333527775,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 688,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1056155678257715,
    "arrivals": 383371,
    "finished_requests": 77395,
    "scheduler_time": 134.6676384522736
}
#Debug simulation 
Total elapsed time: 82.16981128929183. Arrivals time: 0.6422659805975854 Scheduler time: 81.37403357261792 Scheduler overhead time: 0.06078642699867487 Adapter cache time: 0.019838862121105194 Engine time: 0.05331833241507411 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-16/adapters_384_slots_96_rate_0.8-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-16/adapters_384_slots_96_rate_0.8-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 8640, 270, 66, 8640, 8640, 66, 270, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 66, 8640, 66, 8640, 270, 270, 270, 66, 66, 270, 66, 8640, 66, 8640, 270, 8640, 270, 66, 270, 8640, 270, 8640, 66, 8640, 8640, 8640, 8640, 66, 270, 270, 270, 8640, 270, 66, 270, 66, 8640, 270, 8640, 8640, 270, 8640, 8640, 66, 66, 8640, 270, 270, 66, 66, 66, 270, 66, 270, 66, 8640, 66, 270, 8640, 66, 8640, 270, 66, 8640, 8640, 8640, 8640, 270, 66, 270, 8640, 8640, 270, 66, 66, 8640, 270, 270, 66, 66, 8640, 270, 8640, 270, 8640, 8640, 270, 8640, 8640, 66, 270, 270, 270, 270, 66, 66, 8640, 66, 8640, 66, 66, 66, 270, 270, 8640, 66, 66, 8640, 66, 8640, 270, 66, 8640, 270, 270, 66, 8640, 8640, 8640, 66, 270, 8640, 66, 8640, 270, 270, 8640, 8640, 66, 270, 8640, 66, 270, 270, 66, 270, 66, 270, 8640, 8640, 270, 66, 8640, 66, 8640, 270, 270, 270, 270, 270, 66, 66, 8640, 66, 8640, 66, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 66, 270, 270, 270, 270, 270, 270, 270, 270, 8640, 66, 66, 66, 66, 66, 270, 66, 66, 270, 8640, 8640, 66, 66, 8640, 66, 66, 66, 270, 66, 270, 8640, 8640, 270, 270, 66, 8640, 270, 8640, 66, 270, 270, 66, 66, 270, 66, 8640, 8640, 66, 8640, 8640, 66, 270, 8640, 66, 66, 270, 270, 66, 66, 8640, 8640, 8640, 8640, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 8640, 270, 270, 270, 8640, 66, 270, 270, 8640, 8640, 66, 8640, 8640, 66, 8640, 66, 66, 270, 66, 8640, 8640, 8640, 270, 66, 8640, 8640, 270, 270, 8640, 8640, 66, 8640, 8640, 270, 66, 8640, 270, 270, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 66, 8640, 66, 270, 8640, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 8640, 66, 66, 66, 270, 66, 270, 270, 66, 8640, 270, 8640, 66, 8640, 66, 270, 270, 270, 270, 66, 270, 8640, 8640, 66, 8640, 8640, 66, 8640, 270, 8640, 270, 270, 270, 66, 270, 66, 66, 8640, 66, 270, 66, 66, 270, 8640, 270, 8640, 66, 8640, 8640, 270, 8640, 270, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1148928 . Total input tokens: 256018509 . Total output tokens: 229496176
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 81.39719984075055,
    "estimated_duration": 3600.114100967393,
    "input_throughput": 5307.406227726408,
    "output_throughput": 4689.680250818505,
    "total_throughput": 9997.086478544914,
    "itl": 183.37467837235295,
    "ttft": 1951721.37938695,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 679,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.209617495033893,
    "arrivals": 383371,
    "finished_requests": 77397,
    "scheduler_time": 134.66804814773081
}
#Debug simulation 
Total elapsed time: 81.39734611986205. Arrivals time: 0.35071136243641376 Scheduler time: 80.89991122484207 Scheduler overhead time: 0.05783177074044943 Adapter cache time: 0.01799876056611538 Engine time: 0.05120012769475579 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-32/adapters_384_slots_96_rate_0.8-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-32/adapters_384_slots_96_rate_0.8-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 8640, 270, 66, 8640, 8640, 66, 270, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 66, 8640, 66, 8640, 270, 270, 270, 66, 66, 270, 66, 8640, 66, 8640, 270, 8640, 270, 66, 270, 8640, 270, 8640, 66, 8640, 8640, 8640, 8640, 66, 270, 270, 270, 8640, 270, 66, 270, 66, 8640, 270, 8640, 8640, 270, 8640, 8640, 66, 66, 8640, 270, 270, 66, 66, 66, 270, 66, 270, 66, 8640, 66, 270, 8640, 66, 8640, 270, 66, 8640, 8640, 8640, 8640, 270, 66, 270, 8640, 8640, 270, 66, 66, 8640, 270, 270, 66, 66, 8640, 270, 8640, 270, 8640, 8640, 270, 8640, 8640, 66, 270, 270, 270, 270, 66, 66, 8640, 66, 8640, 66, 66, 66, 270, 270, 8640, 66, 66, 8640, 66, 8640, 270, 66, 8640, 270, 270, 66, 8640, 8640, 8640, 66, 270, 8640, 66, 8640, 270, 270, 8640, 8640, 66, 270, 8640, 66, 270, 270, 66, 270, 66, 270, 8640, 8640, 270, 66, 8640, 66, 8640, 270, 270, 270, 270, 270, 66, 66, 8640, 66, 8640, 66, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 66, 270, 270, 270, 270, 270, 270, 270, 270, 8640, 66, 66, 66, 66, 66, 270, 66, 66, 270, 8640, 8640, 66, 66, 8640, 66, 66, 66, 270, 66, 270, 8640, 8640, 270, 270, 66, 8640, 270, 8640, 66, 270, 270, 66, 66, 270, 66, 8640, 8640, 66, 8640, 8640, 66, 270, 8640, 66, 66, 270, 270, 66, 66, 8640, 8640, 8640, 8640, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 8640, 270, 270, 270, 8640, 66, 270, 270, 8640, 8640, 66, 8640, 8640, 66, 8640, 66, 66, 270, 66, 8640, 8640, 8640, 270, 66, 8640, 8640, 270, 270, 8640, 8640, 66, 8640, 8640, 270, 66, 8640, 270, 270, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 66, 8640, 66, 270, 8640, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 8640, 66, 66, 66, 270, 66, 270, 270, 66, 8640, 270, 8640, 66, 8640, 66, 270, 270, 270, 270, 66, 270, 8640, 8640, 66, 8640, 8640, 66, 8640, 270, 8640, 270, 270, 270, 66, 270, 66, 66, 8640, 66, 270, 66, 66, 270, 8640, 270, 8640, 66, 8640, 8640, 270, 8640, 270, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1148928 . Total input tokens: 256018509 . Total output tokens: 229496176
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 92.34614805411547,
    "estimated_duration": 3600.165452650823,
    "input_throughput": 5295.349963975395,
    "output_throughput": 4679.113841169854,
    "total_throughput": 9974.46380514525,
    "itl": 181.28516876979143,
    "ttft": 1933968.4368834216,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 528,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7250145752355561,
    "arrivals": 383371,
    "finished_requests": 77285,
    "scheduler_time": 135.2830697658315
}
#Debug simulation 
Total elapsed time: 92.34628958394751. Arrivals time: 0.3630440444685519 Scheduler time: 91.82819322263822 Scheduler overhead time: 0.06396262161433697 Adapter cache time: 0.01682139653712511 Engine time: 0.05453529115766287 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-16/adapters_384_slots_96_rate_0.8-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-16/adapters_384_slots_96_rate_0.8-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 8640, 270, 66, 8640, 8640, 66, 270, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 66, 8640, 66, 8640, 270, 270, 270, 66, 66, 270, 66, 8640, 66, 8640, 270, 8640, 270, 66, 270, 8640, 270, 8640, 66, 8640, 8640, 8640, 8640, 66, 270, 270, 270, 8640, 270, 66, 270, 66, 8640, 270, 8640, 8640, 270, 8640, 8640, 66, 66, 8640, 270, 270, 66, 66, 66, 270, 66, 270, 66, 8640, 66, 270, 8640, 66, 8640, 270, 66, 8640, 8640, 8640, 8640, 270, 66, 270, 8640, 8640, 270, 66, 66, 8640, 270, 270, 66, 66, 8640, 270, 8640, 270, 8640, 8640, 270, 8640, 8640, 66, 270, 270, 270, 270, 66, 66, 8640, 66, 8640, 66, 66, 66, 270, 270, 8640, 66, 66, 8640, 66, 8640, 270, 66, 8640, 270, 270, 66, 8640, 8640, 8640, 66, 270, 8640, 66, 8640, 270, 270, 8640, 8640, 66, 270, 8640, 66, 270, 270, 66, 270, 66, 270, 8640, 8640, 270, 66, 8640, 66, 8640, 270, 270, 270, 270, 270, 66, 66, 8640, 66, 8640, 66, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 66, 270, 270, 270, 270, 270, 270, 270, 270, 8640, 66, 66, 66, 66, 66, 270, 66, 66, 270, 8640, 8640, 66, 66, 8640, 66, 66, 66, 270, 66, 270, 8640, 8640, 270, 270, 66, 8640, 270, 8640, 66, 270, 270, 66, 66, 270, 66, 8640, 8640, 66, 8640, 8640, 66, 270, 8640, 66, 66, 270, 270, 66, 66, 8640, 8640, 8640, 8640, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 8640, 270, 270, 270, 8640, 66, 270, 270, 8640, 8640, 66, 8640, 8640, 66, 8640, 66, 66, 270, 66, 8640, 8640, 8640, 270, 66, 8640, 8640, 270, 270, 8640, 8640, 66, 8640, 8640, 270, 66, 8640, 270, 270, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 66, 8640, 66, 270, 8640, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 8640, 66, 66, 66, 270, 66, 270, 270, 66, 8640, 270, 8640, 66, 8640, 66, 270, 270, 270, 270, 66, 270, 8640, 8640, 66, 8640, 8640, 66, 8640, 270, 8640, 270, 270, 270, 66, 270, 66, 66, 8640, 66, 270, 66, 66, 270, 8640, 270, 8640, 66, 8640, 8640, 270, 8640, 270, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1148928 . Total input tokens: 256018509 . Total output tokens: 229496176
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 81.56839615525678,
    "estimated_duration": 3600.1899038086185,
    "input_throughput": 5307.218649712569,
    "output_throughput": 4689.751777298893,
    "total_throughput": 9996.970427011462,
    "itl": 183.37108544758487,
    "ttft": 1951530.2812580897,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 688,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.147045572949555,
    "arrivals": 383371,
    "finished_requests": 77401,
    "scheduler_time": 134.6735138501256
}
#Debug simulation 
Total elapsed time: 81.56853911234066. Arrivals time: 0.362946511246264 Scheduler time: 81.05373965436593 Scheduler overhead time: 0.059685669373720884 Adapter cache time: 0.01977750798687339 Engine time: 0.05267635500058532 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-32/adapters_384_slots_96_rate_0.8-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-32/adapters_384_slots_96_rate_0.8-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 8640, 270, 66, 8640, 8640, 66, 270, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 66, 8640, 66, 8640, 270, 270, 270, 66, 66, 270, 66, 8640, 66, 8640, 270, 8640, 270, 66, 270, 8640, 270, 8640, 66, 8640, 8640, 8640, 8640, 66, 270, 270, 270, 8640, 270, 66, 270, 66, 8640, 270, 8640, 8640, 270, 8640, 8640, 66, 66, 8640, 270, 270, 66, 66, 66, 270, 66, 270, 66, 8640, 66, 270, 8640, 66, 8640, 270, 66, 8640, 8640, 8640, 8640, 270, 66, 270, 8640, 8640, 270, 66, 66, 8640, 270, 270, 66, 66, 8640, 270, 8640, 270, 8640, 8640, 270, 8640, 8640, 66, 270, 270, 270, 270, 66, 66, 8640, 66, 8640, 66, 66, 66, 270, 270, 8640, 66, 66, 8640, 66, 8640, 270, 66, 8640, 270, 270, 66, 8640, 8640, 8640, 66, 270, 8640, 66, 8640, 270, 270, 8640, 8640, 66, 270, 8640, 66, 270, 270, 66, 270, 66, 270, 8640, 8640, 270, 66, 8640, 66, 8640, 270, 270, 270, 270, 270, 66, 66, 8640, 66, 8640, 66, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 66, 270, 270, 270, 270, 270, 270, 270, 270, 8640, 66, 66, 66, 66, 66, 270, 66, 66, 270, 8640, 8640, 66, 66, 8640, 66, 66, 66, 270, 66, 270, 8640, 8640, 270, 270, 66, 8640, 270, 8640, 66, 270, 270, 66, 66, 270, 66, 8640, 8640, 66, 8640, 8640, 66, 270, 8640, 66, 66, 270, 270, 66, 66, 8640, 8640, 8640, 8640, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 8640, 270, 270, 270, 8640, 66, 270, 270, 8640, 8640, 66, 8640, 8640, 66, 8640, 66, 66, 270, 66, 8640, 8640, 8640, 270, 66, 8640, 8640, 270, 270, 8640, 8640, 66, 8640, 8640, 270, 66, 8640, 270, 270, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 66, 8640, 66, 270, 8640, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 8640, 66, 66, 66, 270, 66, 270, 270, 66, 8640, 270, 8640, 66, 8640, 66, 270, 270, 270, 270, 66, 270, 8640, 8640, 66, 8640, 8640, 66, 8640, 270, 8640, 270, 270, 270, 66, 270, 66, 66, 8640, 66, 270, 66, 66, 270, 8640, 270, 8640, 66, 8640, 8640, 270, 8640, 270, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1148928 . Total input tokens: 256018509 . Total output tokens: 229496176
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 93.17917245998979,
    "estimated_duration": 3600.1892986582993,
    "input_throughput": 5295.314889998903,
    "output_throughput": 4679.082848859622,
    "total_throughput": 9974.397738858524,
    "itl": 181.28600218779516,
    "ttft": 1933974.3652631186,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 528,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7470214878581503,
    "arrivals": 383371,
    "finished_requests": 77285,
    "scheduler_time": 135.28329530728084
}
#Debug simulation 
Total elapsed time: 93.1793148550205. Arrivals time: 0.3742899256758392 Scheduler time: 92.64922019885853 Scheduler overhead time: 0.06273501785472035 Adapter cache time: 0.017187250312417746 Engine time: 0.05532553978264332 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-16/adapters_384_slots_96_rate_0.8-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-16/adapters_384_slots_96_rate_0.8-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 8640, 270, 66, 8640, 8640, 66, 270, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 66, 8640, 66, 8640, 270, 270, 270, 66, 66, 270, 66, 8640, 66, 8640, 270, 8640, 270, 66, 270, 8640, 270, 8640, 66, 8640, 8640, 8640, 8640, 66, 270, 270, 270, 8640, 270, 66, 270, 66, 8640, 270, 8640, 8640, 270, 8640, 8640, 66, 66, 8640, 270, 270, 66, 66, 66, 270, 66, 270, 66, 8640, 66, 270, 8640, 66, 8640, 270, 66, 8640, 8640, 8640, 8640, 270, 66, 270, 8640, 8640, 270, 66, 66, 8640, 270, 270, 66, 66, 8640, 270, 8640, 270, 8640, 8640, 270, 8640, 8640, 66, 270, 270, 270, 270, 66, 66, 8640, 66, 8640, 66, 66, 66, 270, 270, 8640, 66, 66, 8640, 66, 8640, 270, 66, 8640, 270, 270, 66, 8640, 8640, 8640, 66, 270, 8640, 66, 8640, 270, 270, 8640, 8640, 66, 270, 8640, 66, 270, 270, 66, 270, 66, 270, 8640, 8640, 270, 66, 8640, 66, 8640, 270, 270, 270, 270, 270, 66, 66, 8640, 66, 8640, 66, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 66, 270, 270, 270, 270, 270, 270, 270, 270, 8640, 66, 66, 66, 66, 66, 270, 66, 66, 270, 8640, 8640, 66, 66, 8640, 66, 66, 66, 270, 66, 270, 8640, 8640, 270, 270, 66, 8640, 270, 8640, 66, 270, 270, 66, 66, 270, 66, 8640, 8640, 66, 8640, 8640, 66, 270, 8640, 66, 66, 270, 270, 66, 66, 8640, 8640, 8640, 8640, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 8640, 270, 270, 270, 8640, 66, 270, 270, 8640, 8640, 66, 8640, 8640, 66, 8640, 66, 66, 270, 66, 8640, 8640, 8640, 270, 66, 8640, 8640, 270, 270, 8640, 8640, 66, 8640, 8640, 270, 66, 8640, 270, 270, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 66, 8640, 66, 270, 8640, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 8640, 66, 66, 66, 270, 66, 270, 270, 66, 8640, 270, 8640, 66, 8640, 66, 270, 270, 270, 270, 66, 270, 8640, 8640, 66, 8640, 8640, 66, 8640, 270, 8640, 270, 270, 270, 66, 270, 66, 66, 8640, 66, 270, 66, 66, 270, 8640, 270, 8640, 66, 8640, 8640, 270, 8640, 270, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1148928 . Total input tokens: 256018509 . Total output tokens: 229496176
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 81.86268067080528,
    "estimated_duration": 3600.160993304908,
    "input_throughput": 5307.303488797553,
    "output_throughput": 4689.865823055992,
    "total_throughput": 9997.169311853544,
    "itl": 183.36581895834698,
    "ttft": 1951540.8866039328,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 688,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.057154602892661,
    "arrivals": 383371,
    "finished_requests": 77402,
    "scheduler_time": 134.67484712872132
}
#Debug simulation 
Total elapsed time: 81.862823901698. Arrivals time: 0.3745269156061113 Scheduler time: 81.3376683020033 Scheduler overhead time: 0.06098405830562115 Adapter cache time: 0.01867432612925768 Engine time: 0.051630533300340176 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-32/adapters_384_slots_96_rate_0.8-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-32/adapters_384_slots_96_rate_0.8-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 8640, 270, 66, 8640, 8640, 66, 270, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 66, 8640, 66, 8640, 270, 270, 270, 66, 66, 270, 66, 8640, 66, 8640, 270, 8640, 270, 66, 270, 8640, 270, 8640, 66, 8640, 8640, 8640, 8640, 66, 270, 270, 270, 8640, 270, 66, 270, 66, 8640, 270, 8640, 8640, 270, 8640, 8640, 66, 66, 8640, 270, 270, 66, 66, 66, 270, 66, 270, 66, 8640, 66, 270, 8640, 66, 8640, 270, 66, 8640, 8640, 8640, 8640, 270, 66, 270, 8640, 8640, 270, 66, 66, 8640, 270, 270, 66, 66, 8640, 270, 8640, 270, 8640, 8640, 270, 8640, 8640, 66, 270, 270, 270, 270, 66, 66, 8640, 66, 8640, 66, 66, 66, 270, 270, 8640, 66, 66, 8640, 66, 8640, 270, 66, 8640, 270, 270, 66, 8640, 8640, 8640, 66, 270, 8640, 66, 8640, 270, 270, 8640, 8640, 66, 270, 8640, 66, 270, 270, 66, 270, 66, 270, 8640, 8640, 270, 66, 8640, 66, 8640, 270, 270, 270, 270, 270, 66, 66, 8640, 66, 8640, 66, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 66, 270, 270, 270, 270, 270, 270, 270, 270, 8640, 66, 66, 66, 66, 66, 270, 66, 66, 270, 8640, 8640, 66, 66, 8640, 66, 66, 66, 270, 66, 270, 8640, 8640, 270, 270, 66, 8640, 270, 8640, 66, 270, 270, 66, 66, 270, 66, 8640, 8640, 66, 8640, 8640, 66, 270, 8640, 66, 66, 270, 270, 66, 66, 8640, 8640, 8640, 8640, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 8640, 270, 270, 270, 8640, 66, 270, 270, 8640, 8640, 66, 8640, 8640, 66, 8640, 66, 66, 270, 66, 8640, 8640, 8640, 270, 66, 8640, 8640, 270, 270, 8640, 8640, 66, 8640, 8640, 270, 66, 8640, 270, 270, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 66, 8640, 66, 270, 8640, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 8640, 66, 66, 66, 270, 66, 270, 270, 66, 8640, 270, 8640, 66, 8640, 66, 270, 270, 270, 270, 66, 270, 8640, 8640, 66, 8640, 8640, 66, 8640, 270, 8640, 270, 270, 270, 66, 270, 66, 66, 8640, 66, 270, 66, 66, 270, 8640, 270, 8640, 66, 8640, 8640, 270, 8640, 270, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1148928 . Total input tokens: 256018509 . Total output tokens: 229496176
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 92.92934830812737,
    "estimated_duration": 3600.010736021766,
    "input_throughput": 5295.3272636809,
    "output_throughput": 4679.221045494724,
    "total_throughput": 9974.548309175623,
    "itl": 181.28557247256023,
    "ttft": 1933927.792606656,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 528,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7690284004807448,
    "arrivals": 383371,
    "finished_requests": 77282,
    "scheduler_time": 135.27576593565223
}
#Debug simulation 
Total elapsed time: 92.92948970291764. Arrivals time: 0.3676433521322906 Scheduler time: 92.4096748731099 Scheduler overhead time: 0.06219013128429651 Adapter cache time: 0.01648906571790576 Engine time: 0.05297356005758047 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-8/adapters_384_slots_96_rate_0.8-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-8/adapters_384_slots_96_rate_0.8-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 270, 33, 8640, 8640, 33, 270, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 33, 8640, 33, 8640, 270, 270, 270, 33, 33, 270, 33, 8640, 33, 8640, 270, 8640, 270, 33, 270, 8640, 270, 8640, 33, 8640, 8640, 8640, 8640, 33, 270, 270, 270, 8640, 270, 33, 270, 33, 8640, 270, 8640, 8640, 270, 8640, 8640, 33, 33, 8640, 270, 270, 33, 33, 33, 270, 33, 270, 33, 8640, 33, 270, 8640, 33, 8640, 270, 33, 8640, 8640, 8640, 8640, 270, 33, 270, 8640, 8640, 270, 33, 33, 8640, 270, 270, 33, 33, 8640, 270, 8640, 270, 8640, 8640, 270, 8640, 8640, 33, 270, 270, 270, 270, 33, 33, 8640, 33, 8640, 33, 33, 33, 270, 270, 8640, 33, 33, 8640, 33, 8640, 270, 33, 8640, 270, 270, 33, 8640, 8640, 8640, 33, 270, 8640, 33, 8640, 270, 270, 8640, 8640, 33, 270, 8640, 33, 270, 270, 33, 270, 33, 270, 8640, 8640, 270, 33, 8640, 33, 8640, 270, 270, 270, 270, 270, 33, 33, 8640, 33, 8640, 33, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 33, 270, 270, 270, 270, 270, 270, 270, 270, 8640, 33, 33, 33, 33, 33, 270, 33, 33, 270, 8640, 8640, 33, 33, 8640, 33, 33, 33, 270, 33, 270, 8640, 8640, 270, 270, 33, 8640, 270, 8640, 33, 270, 270, 33, 33, 270, 33, 8640, 8640, 33, 8640, 8640, 33, 270, 8640, 33, 33, 270, 270, 33, 33, 8640, 8640, 8640, 8640, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 8640, 270, 270, 270, 8640, 33, 270, 270, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 270, 33, 8640, 8640, 8640, 270, 33, 8640, 8640, 270, 270, 8640, 8640, 33, 8640, 8640, 270, 33, 8640, 270, 270, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 270, 8640, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 8640, 33, 33, 33, 270, 33, 270, 270, 33, 8640, 270, 8640, 33, 8640, 33, 270, 270, 270, 270, 33, 270, 8640, 8640, 33, 8640, 8640, 33, 8640, 270, 8640, 270, 270, 270, 33, 270, 33, 33, 8640, 33, 270, 33, 33, 270, 8640, 270, 8640, 33, 8640, 8640, 270, 8640, 270, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1144704 . Total input tokens: 255094017 . Total output tokens: 228644327
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 85.85137601103634,
    "estimated_duration": 3600.1096998611097,
    "input_throughput": 5322.146155918303,
    "output_throughput": 4689.03350379886,
    "total_throughput": 10011.179659717163,
    "itl": 182.73183553146214,
    "ttft": 1937421.9879040476,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 584,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7873248424567543,
    "arrivals": 381963,
    "finished_requests": 77493,
    "scheduler_time": 134.67879202752084
}
#Debug simulation 
Total elapsed time: 85.85154239227995. Arrivals time: 0.3676407770253718 Scheduler time: 85.33201925549656 Scheduler overhead time: 0.06168432394042611 Adapter cache time: 0.017429562751203775 Engine time: 0.05277239205315709 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-16/adapters_384_slots_96_rate_0.8-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-16/adapters_384_slots_96_rate_0.8-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 270, 33, 8640, 8640, 33, 270, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 33, 8640, 33, 8640, 270, 270, 270, 33, 33, 270, 33, 8640, 33, 8640, 270, 8640, 270, 33, 270, 8640, 270, 8640, 33, 8640, 8640, 8640, 8640, 33, 270, 270, 270, 8640, 270, 33, 270, 33, 8640, 270, 8640, 8640, 270, 8640, 8640, 33, 33, 8640, 270, 270, 33, 33, 33, 270, 33, 270, 33, 8640, 33, 270, 8640, 33, 8640, 270, 33, 8640, 8640, 8640, 8640, 270, 33, 270, 8640, 8640, 270, 33, 33, 8640, 270, 270, 33, 33, 8640, 270, 8640, 270, 8640, 8640, 270, 8640, 8640, 33, 270, 270, 270, 270, 33, 33, 8640, 33, 8640, 33, 33, 33, 270, 270, 8640, 33, 33, 8640, 33, 8640, 270, 33, 8640, 270, 270, 33, 8640, 8640, 8640, 33, 270, 8640, 33, 8640, 270, 270, 8640, 8640, 33, 270, 8640, 33, 270, 270, 33, 270, 33, 270, 8640, 8640, 270, 33, 8640, 33, 8640, 270, 270, 270, 270, 270, 33, 33, 8640, 33, 8640, 33, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 33, 270, 270, 270, 270, 270, 270, 270, 270, 8640, 33, 33, 33, 33, 33, 270, 33, 33, 270, 8640, 8640, 33, 33, 8640, 33, 33, 33, 270, 33, 270, 8640, 8640, 270, 270, 33, 8640, 270, 8640, 33, 270, 270, 33, 33, 270, 33, 8640, 8640, 33, 8640, 8640, 33, 270, 8640, 33, 33, 270, 270, 33, 33, 8640, 8640, 8640, 8640, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 8640, 270, 270, 270, 8640, 33, 270, 270, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 270, 33, 8640, 8640, 8640, 270, 33, 8640, 8640, 270, 270, 8640, 8640, 33, 8640, 8640, 270, 33, 8640, 270, 270, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 270, 8640, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 8640, 33, 33, 33, 270, 33, 270, 270, 33, 8640, 270, 8640, 33, 8640, 33, 270, 270, 270, 270, 33, 270, 8640, 8640, 33, 8640, 8640, 33, 8640, 270, 8640, 270, 270, 270, 33, 270, 33, 33, 8640, 33, 270, 33, 33, 270, 8640, 270, 8640, 33, 8640, 8640, 270, 8640, 270, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1144704 . Total input tokens: 255094017 . Total output tokens: 228644327
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 85.62402347987518,
    "estimated_duration": 3600.1190847396833,
    "input_throughput": 5321.183980053036,
    "output_throughput": 4688.731012135549,
    "total_throughput": 10009.914992188584,
    "itl": 182.74268205398818,
    "ttft": 1937320.1907442433,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 569,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8602821966726388,
    "arrivals": 381963,
    "finished_requests": 77481,
    "scheduler_time": 134.67458656757697
}
#Debug simulation 
Total elapsed time: 85.62418315326795. Arrivals time: 0.36918215127661824 Scheduler time: 85.10588318249211 Scheduler overhead time: 0.06055790185928345 Adapter cache time: 0.01667780801653862 Engine time: 0.05196725903078914 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-32/adapters_384_slots_96_rate_0.8-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-32/adapters_384_slots_96_rate_0.8-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 270, 33, 8640, 8640, 33, 270, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 33, 8640, 33, 8640, 270, 270, 270, 33, 33, 270, 33, 8640, 33, 8640, 270, 8640, 270, 33, 270, 8640, 270, 8640, 33, 8640, 8640, 8640, 8640, 33, 270, 270, 270, 8640, 270, 33, 270, 33, 8640, 270, 8640, 8640, 270, 8640, 8640, 33, 33, 8640, 270, 270, 33, 33, 33, 270, 33, 270, 33, 8640, 33, 270, 8640, 33, 8640, 270, 33, 8640, 8640, 8640, 8640, 270, 33, 270, 8640, 8640, 270, 33, 33, 8640, 270, 270, 33, 33, 8640, 270, 8640, 270, 8640, 8640, 270, 8640, 8640, 33, 270, 270, 270, 270, 33, 33, 8640, 33, 8640, 33, 33, 33, 270, 270, 8640, 33, 33, 8640, 33, 8640, 270, 33, 8640, 270, 270, 33, 8640, 8640, 8640, 33, 270, 8640, 33, 8640, 270, 270, 8640, 8640, 33, 270, 8640, 33, 270, 270, 33, 270, 33, 270, 8640, 8640, 270, 33, 8640, 33, 8640, 270, 270, 270, 270, 270, 33, 33, 8640, 33, 8640, 33, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 33, 270, 270, 270, 270, 270, 270, 270, 270, 8640, 33, 33, 33, 33, 33, 270, 33, 33, 270, 8640, 8640, 33, 33, 8640, 33, 33, 33, 270, 33, 270, 8640, 8640, 270, 270, 33, 8640, 270, 8640, 33, 270, 270, 33, 33, 270, 33, 8640, 8640, 33, 8640, 8640, 33, 270, 8640, 33, 33, 270, 270, 33, 33, 8640, 8640, 8640, 8640, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 8640, 270, 270, 270, 8640, 33, 270, 270, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 270, 33, 8640, 8640, 8640, 270, 33, 8640, 8640, 270, 270, 8640, 8640, 33, 8640, 8640, 270, 33, 8640, 270, 270, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 270, 8640, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 8640, 33, 33, 33, 270, 33, 270, 270, 33, 8640, 270, 8640, 33, 8640, 33, 270, 270, 270, 270, 33, 270, 8640, 8640, 33, 8640, 8640, 33, 8640, 270, 8640, 270, 270, 270, 33, 270, 33, 33, 8640, 33, 270, 33, 33, 270, 8640, 270, 8640, 33, 8640, 8640, 270, 8640, 270, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1144704 . Total input tokens: 255094017 . Total output tokens: 228644327
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 84.16524090291932,
    "estimated_duration": 3600.038333444529,
    "input_throughput": 5309.727349961435,
    "output_throughput": 4678.444071978801,
    "total_throughput": 9988.171421940237,
    "itl": 180.88388022171048,
    "ttft": 1938451.697586121,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 574,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8788435895554838,
    "arrivals": 381963,
    "finished_requests": 77306,
    "scheduler_time": 135.19487637907696
}
#Debug simulation 
Total elapsed time: 84.16536302305758. Arrivals time: 0.3652843371964991 Scheduler time: 83.64825674053282 Scheduler overhead time: 0.06222095852717757 Adapter cache time: 0.017507816199213266 Engine time: 0.05247808899730444 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-16-16/adapters_384_slots_96_rate_0.8-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-16-16/adapters_384_slots_96_rate_0.8-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 270, 33, 8640, 8640, 33, 270, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 33, 8640, 33, 8640, 270, 270, 270, 33, 33, 270, 33, 8640, 33, 8640, 270, 8640, 270, 33, 270, 8640, 270, 8640, 33, 8640, 8640, 8640, 8640, 33, 270, 270, 270, 8640, 270, 33, 270, 33, 8640, 270, 8640, 8640, 270, 8640, 8640, 33, 33, 8640, 270, 270, 33, 33, 33, 270, 33, 270, 33, 8640, 33, 270, 8640, 33, 8640, 270, 33, 8640, 8640, 8640, 8640, 270, 33, 270, 8640, 8640, 270, 33, 33, 8640, 270, 270, 33, 33, 8640, 270, 8640, 270, 8640, 8640, 270, 8640, 8640, 33, 270, 270, 270, 270, 33, 33, 8640, 33, 8640, 33, 33, 33, 270, 270, 8640, 33, 33, 8640, 33, 8640, 270, 33, 8640, 270, 270, 33, 8640, 8640, 8640, 33, 270, 8640, 33, 8640, 270, 270, 8640, 8640, 33, 270, 8640, 33, 270, 270, 33, 270, 33, 270, 8640, 8640, 270, 33, 8640, 33, 8640, 270, 270, 270, 270, 270, 33, 33, 8640, 33, 8640, 33, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 33, 270, 270, 270, 270, 270, 270, 270, 270, 8640, 33, 33, 33, 33, 33, 270, 33, 33, 270, 8640, 8640, 33, 33, 8640, 33, 33, 33, 270, 33, 270, 8640, 8640, 270, 270, 33, 8640, 270, 8640, 33, 270, 270, 33, 33, 270, 33, 8640, 8640, 33, 8640, 8640, 33, 270, 8640, 33, 33, 270, 270, 33, 33, 8640, 8640, 8640, 8640, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 8640, 270, 270, 270, 8640, 33, 270, 270, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 270, 33, 8640, 8640, 8640, 270, 33, 8640, 8640, 270, 270, 8640, 8640, 33, 8640, 8640, 270, 33, 8640, 270, 270, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 270, 8640, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 8640, 33, 33, 33, 270, 33, 270, 270, 33, 8640, 270, 8640, 33, 8640, 33, 270, 270, 270, 270, 33, 270, 8640, 8640, 33, 8640, 8640, 33, 8640, 270, 8640, 270, 270, 270, 33, 270, 33, 33, 8640, 33, 270, 33, 33, 270, 8640, 270, 8640, 33, 8640, 8640, 270, 8640, 270, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1144704 . Total input tokens: 255094017 . Total output tokens: 228644327
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 85.30200580693781,
    "estimated_duration": 3600.019259805169,
    "input_throughput": 5321.9531945050985,
    "output_throughput": 4688.986025289642,
    "total_throughput": 10010.939219794742,
    "itl": 182.73250560136722,
    "ttft": 1937394.6458009668,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 583,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8228754090238253,
    "arrivals": 381963,
    "finished_requests": 77491,
    "scheduler_time": 134.67486803832318
}
#Debug simulation 
Total elapsed time: 85.30214726319537. Arrivals time: 0.3630125429481268 Scheduler time: 84.78512471960858 Scheduler overhead time: 0.06264984840527177 Adapter cache time: 0.01831229543313384 Engine time: 0.05242422362789512 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-16-32/adapters_384_slots_96_rate_0.8-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-16-32/adapters_384_slots_96_rate_0.8-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 270, 33, 8640, 8640, 33, 270, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 33, 8640, 33, 8640, 270, 270, 270, 33, 33, 270, 33, 8640, 33, 8640, 270, 8640, 270, 33, 270, 8640, 270, 8640, 33, 8640, 8640, 8640, 8640, 33, 270, 270, 270, 8640, 270, 33, 270, 33, 8640, 270, 8640, 8640, 270, 8640, 8640, 33, 33, 8640, 270, 270, 33, 33, 33, 270, 33, 270, 33, 8640, 33, 270, 8640, 33, 8640, 270, 33, 8640, 8640, 8640, 8640, 270, 33, 270, 8640, 8640, 270, 33, 33, 8640, 270, 270, 33, 33, 8640, 270, 8640, 270, 8640, 8640, 270, 8640, 8640, 33, 270, 270, 270, 270, 33, 33, 8640, 33, 8640, 33, 33, 33, 270, 270, 8640, 33, 33, 8640, 33, 8640, 270, 33, 8640, 270, 270, 33, 8640, 8640, 8640, 33, 270, 8640, 33, 8640, 270, 270, 8640, 8640, 33, 270, 8640, 33, 270, 270, 33, 270, 33, 270, 8640, 8640, 270, 33, 8640, 33, 8640, 270, 270, 270, 270, 270, 33, 33, 8640, 33, 8640, 33, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 33, 270, 270, 270, 270, 270, 270, 270, 270, 8640, 33, 33, 33, 33, 33, 270, 33, 33, 270, 8640, 8640, 33, 33, 8640, 33, 33, 33, 270, 33, 270, 8640, 8640, 270, 270, 33, 8640, 270, 8640, 33, 270, 270, 33, 33, 270, 33, 8640, 8640, 33, 8640, 8640, 33, 270, 8640, 33, 33, 270, 270, 33, 33, 8640, 8640, 8640, 8640, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 8640, 270, 270, 270, 8640, 33, 270, 270, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 270, 33, 8640, 8640, 8640, 270, 33, 8640, 8640, 270, 270, 8640, 8640, 33, 8640, 8640, 270, 33, 8640, 270, 270, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 270, 8640, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 8640, 33, 33, 33, 270, 33, 270, 270, 33, 8640, 270, 8640, 33, 8640, 33, 270, 270, 270, 270, 33, 270, 8640, 8640, 33, 8640, 8640, 33, 8640, 270, 8640, 270, 270, 270, 33, 270, 33, 33, 8640, 33, 270, 33, 33, 270, 8640, 270, 8640, 33, 8640, 8640, 270, 8640, 270, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1144704 . Total input tokens: 255094017 . Total output tokens: 228644327
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 84.04673343570903,
    "estimated_duration": 3600.0657788200733,
    "input_throughput": 5309.686870850744,
    "output_throughput": 4678.40840550424,
    "total_throughput": 9988.095276354983,
    "itl": 180.88485371607055,
    "ttft": 1938458.1266302618,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 574,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9041201006248627,
    "arrivals": 381963,
    "finished_requests": 77306,
    "scheduler_time": 135.19510428311412
}
#Debug simulation 
Total elapsed time: 84.04687649477273. Arrivals time: 0.36612034495919943 Scheduler time: 83.5299878702499 Scheduler overhead time: 0.06143566919490695 Adapter cache time: 0.01763602253049612 Engine time: 0.05183146893978119 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_16-16-16/adapters_384_slots_96_rate_0.8-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_16-16-16/adapters_384_slots_96_rate_0.8-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 270, 33, 8640, 8640, 33, 270, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 33, 8640, 33, 8640, 270, 270, 270, 33, 33, 270, 33, 8640, 33, 8640, 270, 8640, 270, 33, 270, 8640, 270, 8640, 33, 8640, 8640, 8640, 8640, 33, 270, 270, 270, 8640, 270, 33, 270, 33, 8640, 270, 8640, 8640, 270, 8640, 8640, 33, 33, 8640, 270, 270, 33, 33, 33, 270, 33, 270, 33, 8640, 33, 270, 8640, 33, 8640, 270, 33, 8640, 8640, 8640, 8640, 270, 33, 270, 8640, 8640, 270, 33, 33, 8640, 270, 270, 33, 33, 8640, 270, 8640, 270, 8640, 8640, 270, 8640, 8640, 33, 270, 270, 270, 270, 33, 33, 8640, 33, 8640, 33, 33, 33, 270, 270, 8640, 33, 33, 8640, 33, 8640, 270, 33, 8640, 270, 270, 33, 8640, 8640, 8640, 33, 270, 8640, 33, 8640, 270, 270, 8640, 8640, 33, 270, 8640, 33, 270, 270, 33, 270, 33, 270, 8640, 8640, 270, 33, 8640, 33, 8640, 270, 270, 270, 270, 270, 33, 33, 8640, 33, 8640, 33, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 33, 270, 270, 270, 270, 270, 270, 270, 270, 8640, 33, 33, 33, 33, 33, 270, 33, 33, 270, 8640, 8640, 33, 33, 8640, 33, 33, 33, 270, 33, 270, 8640, 8640, 270, 270, 33, 8640, 270, 8640, 33, 270, 270, 33, 33, 270, 33, 8640, 8640, 33, 8640, 8640, 33, 270, 8640, 33, 33, 270, 270, 33, 33, 8640, 8640, 8640, 8640, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 8640, 270, 270, 270, 8640, 33, 270, 270, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 270, 33, 8640, 8640, 8640, 270, 33, 8640, 8640, 270, 270, 8640, 8640, 33, 8640, 8640, 270, 33, 8640, 270, 270, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 270, 8640, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 8640, 33, 33, 33, 270, 33, 270, 270, 33, 8640, 270, 8640, 33, 8640, 33, 270, 270, 270, 270, 33, 270, 8640, 8640, 33, 8640, 8640, 33, 8640, 270, 8640, 270, 270, 270, 33, 270, 33, 33, 8640, 33, 270, 33, 33, 270, 8640, 270, 8640, 33, 8640, 8640, 270, 8640, 270, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1144704 . Total input tokens: 255094017 . Total output tokens: 228644327
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 85.50439812289551,
    "estimated_duration": 3600.05103333667,
    "input_throughput": 5322.232885749251,
    "output_throughput": 4689.1099164097095,
    "total_throughput": 10011.34280215896,
    "itl": 182.7310558819094,
    "ttft": 1937413.7909088193,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 584,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7461893722228454,
    "arrivals": 381963,
    "finished_requests": 77493,
    "scheduler_time": 134.6778195443331
}
#Debug simulation 
Total elapsed time: 85.5045219999738. Arrivals time: 0.367326945066452 Scheduler time: 84.98604845628142 Scheduler overhead time: 0.06089886510744691 Adapter cache time: 0.01738164434209466 Engine time: 0.05247247405350208 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_16-16-32/adapters_384_slots_96_rate_0.8-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_16-16-32/adapters_384_slots_96_rate_0.8-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 270, 33, 8640, 8640, 33, 270, 8640, 8640, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 33, 8640, 33, 8640, 270, 270, 270, 33, 33, 270, 33, 8640, 33, 8640, 270, 8640, 270, 33, 270, 8640, 270, 8640, 33, 8640, 8640, 8640, 8640, 33, 270, 270, 270, 8640, 270, 33, 270, 33, 8640, 270, 8640, 8640, 270, 8640, 8640, 33, 33, 8640, 270, 270, 33, 33, 33, 270, 33, 270, 33, 8640, 33, 270, 8640, 33, 8640, 270, 33, 8640, 8640, 8640, 8640, 270, 33, 270, 8640, 8640, 270, 33, 33, 8640, 270, 270, 33, 33, 8640, 270, 8640, 270, 8640, 8640, 270, 8640, 8640, 33, 270, 270, 270, 270, 33, 33, 8640, 33, 8640, 33, 33, 33, 270, 270, 8640, 33, 33, 8640, 33, 8640, 270, 33, 8640, 270, 270, 33, 8640, 8640, 8640, 33, 270, 8640, 33, 8640, 270, 270, 8640, 8640, 33, 270, 8640, 33, 270, 270, 33, 270, 33, 270, 8640, 8640, 270, 33, 8640, 33, 8640, 270, 270, 270, 270, 270, 33, 33, 8640, 33, 8640, 33, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 33, 270, 270, 270, 270, 270, 270, 270, 270, 8640, 33, 33, 33, 33, 33, 270, 33, 33, 270, 8640, 8640, 33, 33, 8640, 33, 33, 33, 270, 33, 270, 8640, 8640, 270, 270, 33, 8640, 270, 8640, 33, 270, 270, 33, 33, 270, 33, 8640, 8640, 33, 8640, 8640, 33, 270, 8640, 33, 33, 270, 270, 33, 33, 8640, 8640, 8640, 8640, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 8640, 270, 270, 270, 8640, 33, 270, 270, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 270, 33, 8640, 8640, 8640, 270, 33, 8640, 8640, 270, 270, 8640, 8640, 33, 8640, 8640, 270, 33, 8640, 270, 270, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 270, 8640, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 8640, 33, 33, 33, 270, 33, 270, 270, 33, 8640, 270, 8640, 33, 8640, 33, 270, 270, 270, 270, 33, 270, 8640, 8640, 33, 8640, 8640, 33, 8640, 270, 8640, 270, 270, 270, 33, 270, 33, 33, 8640, 33, 270, 33, 33, 270, 8640, 270, 8640, 33, 8640, 8640, 270, 8640, 270, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1144704 . Total input tokens: 255094017 . Total output tokens: 228644327
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 84.25255409674719,
    "estimated_duration": 3600.1097874685065,
    "input_throughput": 5310.296665547798,
    "output_throughput": 4677.746789450464,
    "total_throughput": 9988.043454998262,
    "itl": 180.88635638444944,
    "ttft": 1938607.9742240855,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 581,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9525589609518599,
    "arrivals": 381963,
    "finished_requests": 77312,
    "scheduler_time": 135.19342974967455
}
#Debug simulation 
Total elapsed time: 84.25267261592671. Arrivals time: 0.36813415586948395 Scheduler time: 83.72936594113708 Scheduler overhead time: 0.064602458383888 Adapter cache time: 0.01734791463240981 Engine time: 0.05323464749380946 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-8/adapters_384_slots_96_rate_0.8-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-8/adapters_384_slots_96_rate_0.8-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 8640, 135, 66, 8640, 8640, 66, 135, 8640, 8640, 8640, 8640, 135, 135, 135, 135, 8640, 8640, 135, 135, 66, 8640, 66, 8640, 135, 135, 135, 66, 66, 135, 66, 8640, 66, 8640, 135, 8640, 135, 66, 135, 8640, 135, 8640, 66, 8640, 8640, 8640, 8640, 66, 135, 135, 135, 8640, 135, 66, 135, 66, 8640, 135, 8640, 8640, 135, 8640, 8640, 66, 66, 8640, 135, 135, 66, 66, 66, 135, 66, 135, 66, 8640, 66, 135, 8640, 66, 8640, 135, 66, 8640, 8640, 8640, 8640, 135, 66, 135, 8640, 8640, 135, 66, 66, 8640, 135, 135, 66, 66, 8640, 135, 8640, 135, 8640, 8640, 135, 8640, 8640, 66, 135, 135, 135, 135, 66, 66, 8640, 66, 8640, 66, 66, 66, 135, 135, 8640, 66, 66, 8640, 66, 8640, 135, 66, 8640, 135, 135, 66, 8640, 8640, 8640, 66, 135, 8640, 66, 8640, 135, 135, 8640, 8640, 66, 135, 8640, 66, 135, 135, 66, 135, 66, 135, 8640, 8640, 135, 66, 8640, 66, 8640, 135, 135, 135, 135, 135, 66, 66, 8640, 66, 8640, 66, 135, 8640, 135, 8640, 135, 8640, 135, 8640, 66, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 66, 66, 66, 66, 66, 135, 66, 66, 135, 8640, 8640, 66, 66, 8640, 66, 66, 66, 135, 66, 135, 8640, 8640, 135, 135, 66, 8640, 135, 8640, 66, 135, 135, 66, 66, 135, 66, 8640, 8640, 66, 8640, 8640, 66, 135, 8640, 66, 66, 135, 135, 66, 66, 8640, 8640, 8640, 8640, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 8640, 135, 135, 135, 8640, 66, 135, 135, 8640, 8640, 66, 8640, 8640, 66, 8640, 66, 66, 135, 66, 8640, 8640, 8640, 135, 66, 8640, 8640, 135, 135, 8640, 8640, 66, 8640, 8640, 135, 66, 8640, 135, 135, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 66, 8640, 66, 135, 8640, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 8640, 66, 66, 66, 135, 66, 135, 135, 66, 8640, 135, 8640, 66, 8640, 66, 135, 135, 135, 135, 66, 135, 8640, 8640, 66, 8640, 8640, 66, 8640, 135, 8640, 135, 135, 135, 66, 135, 66, 66, 8640, 66, 135, 66, 66, 135, 8640, 135, 8640, 66, 8640, 8640, 135, 8640, 135, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1131648 . Total input tokens: 252197743 . Total output tokens: 226050656
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 99.28432499803603,
    "estimated_duration": 3600.098145288094,
    "input_throughput": 5326.784778103704,
    "output_throughput": 4684.100354894779,
    "total_throughput": 10010.885132998485,
    "itl": 182.20953863665164,
    "ttft": 1904020.9887810408,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 504,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5424858229421254,
    "arrivals": 377711,
    "finished_requests": 77387,
    "scheduler_time": 134.92035625827282
}
#Debug simulation 
Total elapsed time: 99.28444247087464. Arrivals time: 0.37783545535057783 Scheduler time: 98.74968360224739 Scheduler overhead time: 0.06498448038473725 Adapter cache time: 0.016219192184507847 Engine time: 0.055063833482563496 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-16/adapters_384_slots_96_rate_0.8-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-16/adapters_384_slots_96_rate_0.8-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 8640, 135, 66, 8640, 8640, 66, 135, 8640, 8640, 8640, 8640, 135, 135, 135, 135, 8640, 8640, 135, 135, 66, 8640, 66, 8640, 135, 135, 135, 66, 66, 135, 66, 8640, 66, 8640, 135, 8640, 135, 66, 135, 8640, 135, 8640, 66, 8640, 8640, 8640, 8640, 66, 135, 135, 135, 8640, 135, 66, 135, 66, 8640, 135, 8640, 8640, 135, 8640, 8640, 66, 66, 8640, 135, 135, 66, 66, 66, 135, 66, 135, 66, 8640, 66, 135, 8640, 66, 8640, 135, 66, 8640, 8640, 8640, 8640, 135, 66, 135, 8640, 8640, 135, 66, 66, 8640, 135, 135, 66, 66, 8640, 135, 8640, 135, 8640, 8640, 135, 8640, 8640, 66, 135, 135, 135, 135, 66, 66, 8640, 66, 8640, 66, 66, 66, 135, 135, 8640, 66, 66, 8640, 66, 8640, 135, 66, 8640, 135, 135, 66, 8640, 8640, 8640, 66, 135, 8640, 66, 8640, 135, 135, 8640, 8640, 66, 135, 8640, 66, 135, 135, 66, 135, 66, 135, 8640, 8640, 135, 66, 8640, 66, 8640, 135, 135, 135, 135, 135, 66, 66, 8640, 66, 8640, 66, 135, 8640, 135, 8640, 135, 8640, 135, 8640, 66, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 66, 66, 66, 66, 66, 135, 66, 66, 135, 8640, 8640, 66, 66, 8640, 66, 66, 66, 135, 66, 135, 8640, 8640, 135, 135, 66, 8640, 135, 8640, 66, 135, 135, 66, 66, 135, 66, 8640, 8640, 66, 8640, 8640, 66, 135, 8640, 66, 66, 135, 135, 66, 66, 8640, 8640, 8640, 8640, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 8640, 135, 135, 135, 8640, 66, 135, 135, 8640, 8640, 66, 8640, 8640, 66, 8640, 66, 66, 135, 66, 8640, 8640, 8640, 135, 66, 8640, 8640, 135, 135, 8640, 8640, 66, 8640, 8640, 135, 66, 8640, 135, 135, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 66, 8640, 66, 135, 8640, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 8640, 66, 66, 66, 135, 66, 135, 135, 66, 8640, 135, 8640, 66, 8640, 66, 135, 135, 135, 135, 66, 135, 8640, 8640, 66, 8640, 8640, 66, 8640, 135, 8640, 135, 135, 135, 66, 135, 66, 66, 8640, 66, 135, 66, 66, 135, 8640, 135, 8640, 66, 8640, 8640, 135, 8640, 135, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1131648 . Total input tokens: 252197743 . Total output tokens: 226050656
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 98.69087709812447,
    "estimated_duration": 3600.175369350091,
    "input_throughput": 5326.996891115908,
    "output_throughput": 4684.230980404803,
    "total_throughput": 10011.22787152071,
    "itl": 182.21613016252152,
    "ttft": 1903956.1009067951,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 507,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6548779077851272,
    "arrivals": 377711,
    "finished_requests": 77388,
    "scheduler_time": 134.92008370395038
}
#Debug simulation 
Total elapsed time: 98.69099429389462. Arrivals time: 0.3790760333649814 Scheduler time: 98.15610781917349 Scheduler overhead time: 0.06484511634334922 Adapter cache time: 0.016079214867204428 Engine time: 0.05435542156919837 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-32/adapters_384_slots_96_rate_0.8-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-32/adapters_384_slots_96_rate_0.8-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 8640, 135, 66, 8640, 8640, 66, 135, 8640, 8640, 8640, 8640, 135, 135, 135, 135, 8640, 8640, 135, 135, 66, 8640, 66, 8640, 135, 135, 135, 66, 66, 135, 66, 8640, 66, 8640, 135, 8640, 135, 66, 135, 8640, 135, 8640, 66, 8640, 8640, 8640, 8640, 66, 135, 135, 135, 8640, 135, 66, 135, 66, 8640, 135, 8640, 8640, 135, 8640, 8640, 66, 66, 8640, 135, 135, 66, 66, 66, 135, 66, 135, 66, 8640, 66, 135, 8640, 66, 8640, 135, 66, 8640, 8640, 8640, 8640, 135, 66, 135, 8640, 8640, 135, 66, 66, 8640, 135, 135, 66, 66, 8640, 135, 8640, 135, 8640, 8640, 135, 8640, 8640, 66, 135, 135, 135, 135, 66, 66, 8640, 66, 8640, 66, 66, 66, 135, 135, 8640, 66, 66, 8640, 66, 8640, 135, 66, 8640, 135, 135, 66, 8640, 8640, 8640, 66, 135, 8640, 66, 8640, 135, 135, 8640, 8640, 66, 135, 8640, 66, 135, 135, 66, 135, 66, 135, 8640, 8640, 135, 66, 8640, 66, 8640, 135, 135, 135, 135, 135, 66, 66, 8640, 66, 8640, 66, 135, 8640, 135, 8640, 135, 8640, 135, 8640, 66, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 66, 66, 66, 66, 66, 135, 66, 66, 135, 8640, 8640, 66, 66, 8640, 66, 66, 66, 135, 66, 135, 8640, 8640, 135, 135, 66, 8640, 135, 8640, 66, 135, 135, 66, 66, 135, 66, 8640, 8640, 66, 8640, 8640, 66, 135, 8640, 66, 66, 135, 135, 66, 66, 8640, 8640, 8640, 8640, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 8640, 135, 135, 135, 8640, 66, 135, 135, 8640, 8640, 66, 8640, 8640, 66, 8640, 66, 66, 135, 66, 8640, 8640, 8640, 135, 66, 8640, 8640, 135, 135, 8640, 8640, 66, 8640, 8640, 135, 66, 8640, 135, 135, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 66, 8640, 66, 135, 8640, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 8640, 66, 66, 66, 135, 66, 135, 135, 66, 8640, 135, 8640, 66, 8640, 66, 135, 135, 135, 135, 66, 135, 8640, 8640, 66, 8640, 8640, 66, 8640, 135, 8640, 135, 135, 135, 66, 135, 66, 66, 8640, 66, 135, 66, 66, 135, 8640, 135, 8640, 66, 8640, 8640, 135, 8640, 135, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1131648 . Total input tokens: 252197743 . Total output tokens: 226050656
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 97.9406315907836,
    "estimated_duration": 3600.082662204195,
    "input_throughput": 5315.328784224076,
    "output_throughput": 4673.2840822324815,
    "total_throughput": 9988.612866456559,
    "itl": 180.42735297771355,
    "ttft": 1903886.159350455,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 512,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6742947886884314,
    "arrivals": 377711,
    "finished_requests": 77206,
    "scheduler_time": 135.4164882765229
}
#Debug simulation 
Total elapsed time: 97.94074666174129. Arrivals time: 0.38369103241711855 Scheduler time: 97.3989310786128 Scheduler overhead time: 0.0655792891047895 Adapter cache time: 0.016635844483971596 Engine time: 0.05532225454226136 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-16-16/adapters_384_slots_96_rate_0.8-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-16-16/adapters_384_slots_96_rate_0.8-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 8640, 135, 66, 8640, 8640, 66, 135, 8640, 8640, 8640, 8640, 135, 135, 135, 135, 8640, 8640, 135, 135, 66, 8640, 66, 8640, 135, 135, 135, 66, 66, 135, 66, 8640, 66, 8640, 135, 8640, 135, 66, 135, 8640, 135, 8640, 66, 8640, 8640, 8640, 8640, 66, 135, 135, 135, 8640, 135, 66, 135, 66, 8640, 135, 8640, 8640, 135, 8640, 8640, 66, 66, 8640, 135, 135, 66, 66, 66, 135, 66, 135, 66, 8640, 66, 135, 8640, 66, 8640, 135, 66, 8640, 8640, 8640, 8640, 135, 66, 135, 8640, 8640, 135, 66, 66, 8640, 135, 135, 66, 66, 8640, 135, 8640, 135, 8640, 8640, 135, 8640, 8640, 66, 135, 135, 135, 135, 66, 66, 8640, 66, 8640, 66, 66, 66, 135, 135, 8640, 66, 66, 8640, 66, 8640, 135, 66, 8640, 135, 135, 66, 8640, 8640, 8640, 66, 135, 8640, 66, 8640, 135, 135, 8640, 8640, 66, 135, 8640, 66, 135, 135, 66, 135, 66, 135, 8640, 8640, 135, 66, 8640, 66, 8640, 135, 135, 135, 135, 135, 66, 66, 8640, 66, 8640, 66, 135, 8640, 135, 8640, 135, 8640, 135, 8640, 66, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 66, 66, 66, 66, 66, 135, 66, 66, 135, 8640, 8640, 66, 66, 8640, 66, 66, 66, 135, 66, 135, 8640, 8640, 135, 135, 66, 8640, 135, 8640, 66, 135, 135, 66, 66, 135, 66, 8640, 8640, 66, 8640, 8640, 66, 135, 8640, 66, 66, 135, 135, 66, 66, 8640, 8640, 8640, 8640, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 8640, 135, 135, 135, 8640, 66, 135, 135, 8640, 8640, 66, 8640, 8640, 66, 8640, 66, 66, 135, 66, 8640, 8640, 8640, 135, 66, 8640, 8640, 135, 135, 8640, 8640, 66, 8640, 8640, 135, 66, 8640, 135, 135, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 66, 8640, 66, 135, 8640, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 8640, 66, 66, 66, 135, 66, 135, 135, 66, 8640, 135, 8640, 66, 8640, 66, 135, 135, 135, 135, 66, 135, 8640, 8640, 66, 8640, 8640, 66, 8640, 135, 8640, 135, 135, 135, 66, 135, 66, 66, 8640, 66, 135, 66, 66, 135, 8640, 135, 8640, 66, 8640, 8640, 135, 8640, 135, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1131648 . Total input tokens: 252197743 . Total output tokens: 226050656
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 98.99353911727667,
    "estimated_duration": 3600.0990862979147,
    "input_throughput": 5327.042267528576,
    "output_throughput": 4684.079964404776,
    "total_throughput": 10011.122231933352,
    "itl": 182.2056683372954,
    "ttft": 1904037.8767280474,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 482,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5061708977748587,
    "arrivals": 377711,
    "finished_requests": 77390,
    "scheduler_time": 134.92231934549272
}
#Debug simulation 
Total elapsed time: 98.99365892913193. Arrivals time: 0.3787434627301991 Scheduler time: 98.45847072452307 Scheduler overhead time: 0.06558131286874413 Adapter cache time: 0.016232518944889307 Engine time: 0.05448959581553936 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-16-32/adapters_384_slots_96_rate_0.8-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-16-32/adapters_384_slots_96_rate_0.8-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 8640, 135, 66, 8640, 8640, 66, 135, 8640, 8640, 8640, 8640, 135, 135, 135, 135, 8640, 8640, 135, 135, 66, 8640, 66, 8640, 135, 135, 135, 66, 66, 135, 66, 8640, 66, 8640, 135, 8640, 135, 66, 135, 8640, 135, 8640, 66, 8640, 8640, 8640, 8640, 66, 135, 135, 135, 8640, 135, 66, 135, 66, 8640, 135, 8640, 8640, 135, 8640, 8640, 66, 66, 8640, 135, 135, 66, 66, 66, 135, 66, 135, 66, 8640, 66, 135, 8640, 66, 8640, 135, 66, 8640, 8640, 8640, 8640, 135, 66, 135, 8640, 8640, 135, 66, 66, 8640, 135, 135, 66, 66, 8640, 135, 8640, 135, 8640, 8640, 135, 8640, 8640, 66, 135, 135, 135, 135, 66, 66, 8640, 66, 8640, 66, 66, 66, 135, 135, 8640, 66, 66, 8640, 66, 8640, 135, 66, 8640, 135, 135, 66, 8640, 8640, 8640, 66, 135, 8640, 66, 8640, 135, 135, 8640, 8640, 66, 135, 8640, 66, 135, 135, 66, 135, 66, 135, 8640, 8640, 135, 66, 8640, 66, 8640, 135, 135, 135, 135, 135, 66, 66, 8640, 66, 8640, 66, 135, 8640, 135, 8640, 135, 8640, 135, 8640, 66, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 66, 66, 66, 66, 66, 135, 66, 66, 135, 8640, 8640, 66, 66, 8640, 66, 66, 66, 135, 66, 135, 8640, 8640, 135, 135, 66, 8640, 135, 8640, 66, 135, 135, 66, 66, 135, 66, 8640, 8640, 66, 8640, 8640, 66, 135, 8640, 66, 66, 135, 135, 66, 66, 8640, 8640, 8640, 8640, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 8640, 135, 135, 135, 8640, 66, 135, 135, 8640, 8640, 66, 8640, 8640, 66, 8640, 66, 66, 135, 66, 8640, 8640, 8640, 135, 66, 8640, 8640, 135, 135, 8640, 8640, 66, 8640, 8640, 135, 66, 8640, 135, 135, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 66, 8640, 66, 135, 8640, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 8640, 66, 66, 66, 135, 66, 135, 135, 66, 8640, 135, 8640, 66, 8640, 66, 135, 135, 135, 135, 66, 135, 8640, 8640, 66, 8640, 8640, 66, 8640, 135, 8640, 135, 135, 135, 66, 135, 66, 66, 8640, 66, 135, 66, 66, 135, 8640, 135, 8640, 66, 8640, 8640, 135, 8640, 135, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1131648 . Total input tokens: 252197743 . Total output tokens: 226050656
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 97.73995255259797,
    "estimated_duration": 3600.107700042625,
    "input_throughput": 5315.29181745686,
    "output_throughput": 4673.251580723767,
    "total_throughput": 9988.543398180627,
    "itl": 180.42817031020087,
    "ttft": 1903892.4260452096,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 512,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6961759475246108,
    "arrivals": 377711,
    "finished_requests": 77206,
    "scheduler_time": 135.41683419775828
}
#Debug simulation 
Total elapsed time: 97.74007101077586. Arrivals time: 0.37738748686388135 Scheduler time: 97.20712918508798 Scheduler overhead time: 0.06449975026771426 Adapter cache time: 0.016613643616437912 Engine time: 0.054117532912641764 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_16-16-16/adapters_384_slots_96_rate_0.8-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_16-16-16/adapters_384_slots_96_rate_0.8-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 8640, 135, 66, 8640, 8640, 66, 135, 8640, 8640, 8640, 8640, 135, 135, 135, 135, 8640, 8640, 135, 135, 66, 8640, 66, 8640, 135, 135, 135, 66, 66, 135, 66, 8640, 66, 8640, 135, 8640, 135, 66, 135, 8640, 135, 8640, 66, 8640, 8640, 8640, 8640, 66, 135, 135, 135, 8640, 135, 66, 135, 66, 8640, 135, 8640, 8640, 135, 8640, 8640, 66, 66, 8640, 135, 135, 66, 66, 66, 135, 66, 135, 66, 8640, 66, 135, 8640, 66, 8640, 135, 66, 8640, 8640, 8640, 8640, 135, 66, 135, 8640, 8640, 135, 66, 66, 8640, 135, 135, 66, 66, 8640, 135, 8640, 135, 8640, 8640, 135, 8640, 8640, 66, 135, 135, 135, 135, 66, 66, 8640, 66, 8640, 66, 66, 66, 135, 135, 8640, 66, 66, 8640, 66, 8640, 135, 66, 8640, 135, 135, 66, 8640, 8640, 8640, 66, 135, 8640, 66, 8640, 135, 135, 8640, 8640, 66, 135, 8640, 66, 135, 135, 66, 135, 66, 135, 8640, 8640, 135, 66, 8640, 66, 8640, 135, 135, 135, 135, 135, 66, 66, 8640, 66, 8640, 66, 135, 8640, 135, 8640, 135, 8640, 135, 8640, 66, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 66, 66, 66, 66, 66, 135, 66, 66, 135, 8640, 8640, 66, 66, 8640, 66, 66, 66, 135, 66, 135, 8640, 8640, 135, 135, 66, 8640, 135, 8640, 66, 135, 135, 66, 66, 135, 66, 8640, 8640, 66, 8640, 8640, 66, 135, 8640, 66, 66, 135, 135, 66, 66, 8640, 8640, 8640, 8640, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 8640, 135, 135, 135, 8640, 66, 135, 135, 8640, 8640, 66, 8640, 8640, 66, 8640, 66, 66, 135, 66, 8640, 8640, 8640, 135, 66, 8640, 8640, 135, 135, 8640, 8640, 66, 8640, 8640, 135, 66, 8640, 135, 135, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 66, 8640, 66, 135, 8640, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 8640, 66, 66, 66, 135, 66, 135, 135, 66, 8640, 135, 8640, 66, 8640, 66, 135, 135, 135, 135, 66, 135, 8640, 8640, 66, 8640, 8640, 66, 8640, 135, 8640, 135, 135, 135, 66, 135, 66, 66, 8640, 66, 135, 66, 66, 135, 8640, 135, 8640, 66, 8640, 8640, 135, 8640, 135, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1131648 . Total input tokens: 252197743 . Total output tokens: 226050656
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 95.12722869496793,
    "estimated_duration": 3600.0561753779175,
    "input_throughput": 5326.846878434304,
    "output_throughput": 4684.154962729096,
    "total_throughput": 10011.0018411634,
    "itl": 182.2085622860389,
    "ttft": 1904011.789680512,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 504,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.50698534863068,
    "arrivals": 377711,
    "finished_requests": 77387,
    "scheduler_time": 134.9199187514627
}
#Debug simulation 
Total elapsed time: 95.12734123365954. Arrivals time: 0.35423697577789426 Scheduler time: 94.62927076360211 Scheduler overhead time: 0.05781497759744525 Adapter cache time: 0.01519007794559002 Engine time: 0.05100620072335005 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_16-16-32/adapters_384_slots_96_rate_0.8-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_16-16-32/adapters_384_slots_96_rate_0.8-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 8640, 135, 66, 8640, 8640, 66, 135, 8640, 8640, 8640, 8640, 135, 135, 135, 135, 8640, 8640, 135, 135, 66, 8640, 66, 8640, 135, 135, 135, 66, 66, 135, 66, 8640, 66, 8640, 135, 8640, 135, 66, 135, 8640, 135, 8640, 66, 8640, 8640, 8640, 8640, 66, 135, 135, 135, 8640, 135, 66, 135, 66, 8640, 135, 8640, 8640, 135, 8640, 8640, 66, 66, 8640, 135, 135, 66, 66, 66, 135, 66, 135, 66, 8640, 66, 135, 8640, 66, 8640, 135, 66, 8640, 8640, 8640, 8640, 135, 66, 135, 8640, 8640, 135, 66, 66, 8640, 135, 135, 66, 66, 8640, 135, 8640, 135, 8640, 8640, 135, 8640, 8640, 66, 135, 135, 135, 135, 66, 66, 8640, 66, 8640, 66, 66, 66, 135, 135, 8640, 66, 66, 8640, 66, 8640, 135, 66, 8640, 135, 135, 66, 8640, 8640, 8640, 66, 135, 8640, 66, 8640, 135, 135, 8640, 8640, 66, 135, 8640, 66, 135, 135, 66, 135, 66, 135, 8640, 8640, 135, 66, 8640, 66, 8640, 135, 135, 135, 135, 135, 66, 66, 8640, 66, 8640, 66, 135, 8640, 135, 8640, 135, 8640, 135, 8640, 66, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 66, 66, 66, 66, 66, 135, 66, 66, 135, 8640, 8640, 66, 66, 8640, 66, 66, 66, 135, 66, 135, 8640, 8640, 135, 135, 66, 8640, 135, 8640, 66, 135, 135, 66, 66, 135, 66, 8640, 8640, 66, 8640, 8640, 66, 135, 8640, 66, 66, 135, 135, 66, 66, 8640, 8640, 8640, 8640, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 8640, 135, 135, 135, 8640, 66, 135, 135, 8640, 8640, 66, 8640, 8640, 66, 8640, 66, 66, 135, 66, 8640, 8640, 8640, 135, 66, 8640, 8640, 135, 135, 8640, 8640, 66, 8640, 8640, 135, 66, 8640, 135, 135, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 66, 8640, 66, 135, 8640, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 8640, 66, 66, 66, 135, 66, 135, 135, 66, 8640, 135, 8640, 66, 8640, 66, 135, 135, 135, 135, 66, 135, 8640, 8640, 66, 8640, 8640, 66, 8640, 135, 8640, 135, 135, 135, 66, 135, 66, 66, 8640, 66, 135, 66, 66, 135, 8640, 135, 8640, 66, 8640, 8640, 135, 8640, 135, 66, 8640, 66, 8640, 8640, 66, 66, 66]
Prompts retrieved: 1131648 . Total input tokens: 252197743 . Total output tokens: 226050656
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 93.60272103967145,
    "estimated_duration": 3600.128662669284,
    "input_throughput": 5315.2608678746665,
    "output_throughput": 4673.224369577347,
    "total_throughput": 9988.485237452012,
    "itl": 180.4288165484778,
    "ttft": 1903896.7189817745,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 512,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7175540912151308,
    "arrivals": 377711,
    "finished_requests": 77206,
    "scheduler_time": 135.4169724367662
}
#Debug simulation 
Total elapsed time: 93.60283504100516. Arrivals time: 0.3574650422669947 Scheduler time: 93.10020984429866 Scheduler overhead time: 0.057680191937834024 Adapter cache time: 0.01571028307080269 Engine time: 0.05221734847873449 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-8/adapters_384_slots_96_rate_0.8-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-8/adapters_384_slots_96_rate_0.8-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 135, 33, 8640, 8640, 33, 135, 8640, 8640, 8640, 8640, 135, 135, 135, 135, 8640, 8640, 135, 135, 33, 8640, 33, 8640, 135, 135, 135, 33, 33, 135, 33, 8640, 33, 8640, 135, 8640, 135, 33, 135, 8640, 135, 8640, 33, 8640, 8640, 8640, 8640, 33, 135, 135, 135, 8640, 135, 33, 135, 33, 8640, 135, 8640, 8640, 135, 8640, 8640, 33, 33, 8640, 135, 135, 33, 33, 33, 135, 33, 135, 33, 8640, 33, 135, 8640, 33, 8640, 135, 33, 8640, 8640, 8640, 8640, 135, 33, 135, 8640, 8640, 135, 33, 33, 8640, 135, 135, 33, 33, 8640, 135, 8640, 135, 8640, 8640, 135, 8640, 8640, 33, 135, 135, 135, 135, 33, 33, 8640, 33, 8640, 33, 33, 33, 135, 135, 8640, 33, 33, 8640, 33, 8640, 135, 33, 8640, 135, 135, 33, 8640, 8640, 8640, 33, 135, 8640, 33, 8640, 135, 135, 8640, 8640, 33, 135, 8640, 33, 135, 135, 33, 135, 33, 135, 8640, 8640, 135, 33, 8640, 33, 8640, 135, 135, 135, 135, 135, 33, 33, 8640, 33, 8640, 33, 135, 8640, 135, 8640, 135, 8640, 135, 8640, 33, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 33, 33, 33, 33, 33, 135, 33, 33, 135, 8640, 8640, 33, 33, 8640, 33, 33, 33, 135, 33, 135, 8640, 8640, 135, 135, 33, 8640, 135, 8640, 33, 135, 135, 33, 33, 135, 33, 8640, 8640, 33, 8640, 8640, 33, 135, 8640, 33, 33, 135, 135, 33, 33, 8640, 8640, 8640, 8640, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 8640, 135, 135, 135, 8640, 33, 135, 135, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 135, 33, 8640, 8640, 8640, 135, 33, 8640, 8640, 135, 135, 8640, 8640, 33, 8640, 8640, 135, 33, 8640, 135, 135, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 135, 8640, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 8640, 33, 33, 33, 135, 33, 135, 135, 33, 8640, 135, 8640, 33, 8640, 33, 135, 135, 135, 135, 33, 135, 8640, 8640, 33, 8640, 8640, 33, 8640, 135, 8640, 135, 135, 135, 33, 135, 33, 33, 8640, 33, 135, 33, 33, 135, 8640, 135, 8640, 33, 8640, 8640, 135, 8640, 135, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1127424 . Total input tokens: 251258154 . Total output tokens: 225216556
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 55.64348961832002,
    "estimated_duration": 3600.0279252103483,
    "input_throughput": 5315.359046522375,
    "output_throughput": 4694.700249863334,
    "total_throughput": 10010.059296385709,
    "itl": 183.0924918853404,
    "ttft": 1917224.847753373,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 591,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8087482566642843,
    "arrivals": 376270,
    "finished_requests": 77456,
    "scheduler_time": 134.67594651044791
}
#Debug simulation 
Total elapsed time: 55.643620629329234. Arrivals time: 0.3332715965807438 Scheduler time: 55.17716411687434 Scheduler overhead time: 0.05230250395834446 Adapter cache time: 0.015184542164206505 Engine time: 0.04715341003611684 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-16/adapters_384_slots_96_rate_0.8-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-16/adapters_384_slots_96_rate_0.8-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 135, 33, 8640, 8640, 33, 135, 8640, 8640, 8640, 8640, 135, 135, 135, 135, 8640, 8640, 135, 135, 33, 8640, 33, 8640, 135, 135, 135, 33, 33, 135, 33, 8640, 33, 8640, 135, 8640, 135, 33, 135, 8640, 135, 8640, 33, 8640, 8640, 8640, 8640, 33, 135, 135, 135, 8640, 135, 33, 135, 33, 8640, 135, 8640, 8640, 135, 8640, 8640, 33, 33, 8640, 135, 135, 33, 33, 33, 135, 33, 135, 33, 8640, 33, 135, 8640, 33, 8640, 135, 33, 8640, 8640, 8640, 8640, 135, 33, 135, 8640, 8640, 135, 33, 33, 8640, 135, 135, 33, 33, 8640, 135, 8640, 135, 8640, 8640, 135, 8640, 8640, 33, 135, 135, 135, 135, 33, 33, 8640, 33, 8640, 33, 33, 33, 135, 135, 8640, 33, 33, 8640, 33, 8640, 135, 33, 8640, 135, 135, 33, 8640, 8640, 8640, 33, 135, 8640, 33, 8640, 135, 135, 8640, 8640, 33, 135, 8640, 33, 135, 135, 33, 135, 33, 135, 8640, 8640, 135, 33, 8640, 33, 8640, 135, 135, 135, 135, 135, 33, 33, 8640, 33, 8640, 33, 135, 8640, 135, 8640, 135, 8640, 135, 8640, 33, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 33, 33, 33, 33, 33, 135, 33, 33, 135, 8640, 8640, 33, 33, 8640, 33, 33, 33, 135, 33, 135, 8640, 8640, 135, 135, 33, 8640, 135, 8640, 33, 135, 135, 33, 33, 135, 33, 8640, 8640, 33, 8640, 8640, 33, 135, 8640, 33, 33, 135, 135, 33, 33, 8640, 8640, 8640, 8640, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 8640, 135, 135, 135, 8640, 33, 135, 135, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 135, 33, 8640, 8640, 8640, 135, 33, 8640, 8640, 135, 135, 8640, 8640, 33, 8640, 8640, 135, 33, 8640, 135, 135, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 135, 8640, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 8640, 33, 33, 33, 135, 33, 135, 135, 33, 8640, 135, 8640, 33, 8640, 33, 135, 135, 135, 135, 33, 135, 8640, 8640, 33, 8640, 8640, 33, 8640, 135, 8640, 135, 135, 135, 33, 135, 33, 33, 8640, 33, 135, 33, 33, 135, 8640, 135, 8640, 33, 8640, 8640, 135, 8640, 135, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1127424 . Total input tokens: 251258154 . Total output tokens: 225216556
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 55.72676927084103,
    "estimated_duration": 3600.109931135958,
    "input_throughput": 5322.994676985683,
    "output_throughput": 4696.692690899235,
    "total_throughput": 10019.687367884917,
    "itl": 182.93083339437638,
    "ttft": 1916932.5656074784,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 604,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9694285054970575,
    "arrivals": 376270,
    "finished_requests": 77514,
    "scheduler_time": 134.77421901178562
}
#Debug simulation 
Total elapsed time: 55.726902212016284. Arrivals time: 0.3350347778759897 Scheduler time: 55.25654465472326 Scheduler overhead time: 0.05328827491030097 Adapter cache time: 0.015615588519722223 Engine time: 0.04756571399047971 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-32/adapters_384_slots_96_rate_0.8-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-32/adapters_384_slots_96_rate_0.8-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 135, 33, 8640, 8640, 33, 135, 8640, 8640, 8640, 8640, 135, 135, 135, 135, 8640, 8640, 135, 135, 33, 8640, 33, 8640, 135, 135, 135, 33, 33, 135, 33, 8640, 33, 8640, 135, 8640, 135, 33, 135, 8640, 135, 8640, 33, 8640, 8640, 8640, 8640, 33, 135, 135, 135, 8640, 135, 33, 135, 33, 8640, 135, 8640, 8640, 135, 8640, 8640, 33, 33, 8640, 135, 135, 33, 33, 33, 135, 33, 135, 33, 8640, 33, 135, 8640, 33, 8640, 135, 33, 8640, 8640, 8640, 8640, 135, 33, 135, 8640, 8640, 135, 33, 33, 8640, 135, 135, 33, 33, 8640, 135, 8640, 135, 8640, 8640, 135, 8640, 8640, 33, 135, 135, 135, 135, 33, 33, 8640, 33, 8640, 33, 33, 33, 135, 135, 8640, 33, 33, 8640, 33, 8640, 135, 33, 8640, 135, 135, 33, 8640, 8640, 8640, 33, 135, 8640, 33, 8640, 135, 135, 8640, 8640, 33, 135, 8640, 33, 135, 135, 33, 135, 33, 135, 8640, 8640, 135, 33, 8640, 33, 8640, 135, 135, 135, 135, 135, 33, 33, 8640, 33, 8640, 33, 135, 8640, 135, 8640, 135, 8640, 135, 8640, 33, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 33, 33, 33, 33, 33, 135, 33, 33, 135, 8640, 8640, 33, 33, 8640, 33, 33, 33, 135, 33, 135, 8640, 8640, 135, 135, 33, 8640, 135, 8640, 33, 135, 135, 33, 33, 135, 33, 8640, 8640, 33, 8640, 8640, 33, 135, 8640, 33, 33, 135, 135, 33, 33, 8640, 8640, 8640, 8640, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 8640, 135, 135, 135, 8640, 33, 135, 135, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 135, 33, 8640, 8640, 8640, 135, 33, 8640, 8640, 135, 135, 8640, 8640, 33, 8640, 8640, 135, 33, 8640, 135, 135, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 135, 8640, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 8640, 33, 33, 33, 135, 33, 135, 135, 33, 8640, 135, 8640, 33, 8640, 33, 135, 135, 135, 135, 33, 135, 8640, 8640, 33, 8640, 8640, 33, 8640, 135, 8640, 135, 135, 135, 33, 135, 33, 33, 8640, 33, 135, 33, 33, 135, 8640, 135, 8640, 33, 8640, 8640, 135, 8640, 135, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1127424 . Total input tokens: 251258154 . Total output tokens: 225216556
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 55.05932263704017,
    "estimated_duration": 3600.139796697954,
    "input_throughput": 5309.035503990895,
    "output_throughput": 4683.327579519152,
    "total_throughput": 9992.363083510047,
    "itl": 180.820992486582,
    "ttft": 1919985.5570841199,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 607,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9840011764876668,
    "arrivals": 376270,
    "finished_requests": 77311,
    "scheduler_time": 135.33915790101904
}
#Debug simulation 
Total elapsed time: 55.059453608002514. Arrivals time: 0.3499720795080066 Scheduler time: 54.57399076828733 Scheduler overhead time: 0.05297353584319353 Adapter cache time: 0.015656631905585527 Engine time: 0.04779532924294472 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-16/adapters_384_slots_96_rate_0.8-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-16/adapters_384_slots_96_rate_0.8-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 135, 33, 8640, 8640, 33, 135, 8640, 8640, 8640, 8640, 135, 135, 135, 135, 8640, 8640, 135, 135, 33, 8640, 33, 8640, 135, 135, 135, 33, 33, 135, 33, 8640, 33, 8640, 135, 8640, 135, 33, 135, 8640, 135, 8640, 33, 8640, 8640, 8640, 8640, 33, 135, 135, 135, 8640, 135, 33, 135, 33, 8640, 135, 8640, 8640, 135, 8640, 8640, 33, 33, 8640, 135, 135, 33, 33, 33, 135, 33, 135, 33, 8640, 33, 135, 8640, 33, 8640, 135, 33, 8640, 8640, 8640, 8640, 135, 33, 135, 8640, 8640, 135, 33, 33, 8640, 135, 135, 33, 33, 8640, 135, 8640, 135, 8640, 8640, 135, 8640, 8640, 33, 135, 135, 135, 135, 33, 33, 8640, 33, 8640, 33, 33, 33, 135, 135, 8640, 33, 33, 8640, 33, 8640, 135, 33, 8640, 135, 135, 33, 8640, 8640, 8640, 33, 135, 8640, 33, 8640, 135, 135, 8640, 8640, 33, 135, 8640, 33, 135, 135, 33, 135, 33, 135, 8640, 8640, 135, 33, 8640, 33, 8640, 135, 135, 135, 135, 135, 33, 33, 8640, 33, 8640, 33, 135, 8640, 135, 8640, 135, 8640, 135, 8640, 33, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 33, 33, 33, 33, 33, 135, 33, 33, 135, 8640, 8640, 33, 33, 8640, 33, 33, 33, 135, 33, 135, 8640, 8640, 135, 135, 33, 8640, 135, 8640, 33, 135, 135, 33, 33, 135, 33, 8640, 8640, 33, 8640, 8640, 33, 135, 8640, 33, 33, 135, 135, 33, 33, 8640, 8640, 8640, 8640, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 8640, 135, 135, 135, 8640, 33, 135, 135, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 135, 33, 8640, 8640, 8640, 135, 33, 8640, 8640, 135, 135, 8640, 8640, 33, 8640, 8640, 135, 33, 8640, 135, 135, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 135, 8640, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 8640, 33, 33, 33, 135, 33, 135, 135, 33, 8640, 135, 8640, 33, 8640, 33, 135, 135, 135, 135, 33, 135, 8640, 8640, 33, 8640, 8640, 33, 8640, 135, 8640, 135, 135, 135, 33, 135, 33, 33, 8640, 33, 135, 33, 33, 135, 8640, 135, 8640, 33, 8640, 8640, 135, 8640, 135, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1127424 . Total input tokens: 251258154 . Total output tokens: 225216556
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 55.81033976608887,
    "estimated_duration": 3600.100544913667,
    "input_throughput": 5318.133691307538,
    "output_throughput": 4695.801905834106,
    "total_throughput": 10013.935597141644,
    "itl": 183.0030538356954,
    "ttft": 1917082.4683077652,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 608,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.90007823830702,
    "arrivals": 376270,
    "finished_requests": 77502,
    "scheduler_time": 134.74026723335595
}
#Debug simulation 
Total elapsed time: 55.81047245301306. Arrivals time: 0.3530348613858223 Scheduler time: 55.322948137298226 Scheduler overhead time: 0.05233742156997323 Adapter cache time: 0.01567114284262061 Engine time: 0.04818102391436696 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-32/adapters_384_slots_96_rate_0.8-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-32/adapters_384_slots_96_rate_0.8-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 135, 33, 8640, 8640, 33, 135, 8640, 8640, 8640, 8640, 135, 135, 135, 135, 8640, 8640, 135, 135, 33, 8640, 33, 8640, 135, 135, 135, 33, 33, 135, 33, 8640, 33, 8640, 135, 8640, 135, 33, 135, 8640, 135, 8640, 33, 8640, 8640, 8640, 8640, 33, 135, 135, 135, 8640, 135, 33, 135, 33, 8640, 135, 8640, 8640, 135, 8640, 8640, 33, 33, 8640, 135, 135, 33, 33, 33, 135, 33, 135, 33, 8640, 33, 135, 8640, 33, 8640, 135, 33, 8640, 8640, 8640, 8640, 135, 33, 135, 8640, 8640, 135, 33, 33, 8640, 135, 135, 33, 33, 8640, 135, 8640, 135, 8640, 8640, 135, 8640, 8640, 33, 135, 135, 135, 135, 33, 33, 8640, 33, 8640, 33, 33, 33, 135, 135, 8640, 33, 33, 8640, 33, 8640, 135, 33, 8640, 135, 135, 33, 8640, 8640, 8640, 33, 135, 8640, 33, 8640, 135, 135, 8640, 8640, 33, 135, 8640, 33, 135, 135, 33, 135, 33, 135, 8640, 8640, 135, 33, 8640, 33, 8640, 135, 135, 135, 135, 135, 33, 33, 8640, 33, 8640, 33, 135, 8640, 135, 8640, 135, 8640, 135, 8640, 33, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 33, 33, 33, 33, 33, 135, 33, 33, 135, 8640, 8640, 33, 33, 8640, 33, 33, 33, 135, 33, 135, 8640, 8640, 135, 135, 33, 8640, 135, 8640, 33, 135, 135, 33, 33, 135, 33, 8640, 8640, 33, 8640, 8640, 33, 135, 8640, 33, 33, 135, 135, 33, 33, 8640, 8640, 8640, 8640, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 8640, 135, 135, 135, 8640, 33, 135, 135, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 135, 33, 8640, 8640, 8640, 135, 33, 8640, 8640, 135, 135, 8640, 8640, 33, 8640, 8640, 135, 33, 8640, 135, 135, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 135, 8640, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 8640, 33, 33, 33, 135, 33, 135, 135, 33, 8640, 135, 8640, 33, 8640, 33, 135, 135, 135, 135, 33, 135, 8640, 8640, 33, 8640, 8640, 33, 8640, 135, 8640, 135, 135, 135, 33, 135, 33, 33, 8640, 33, 135, 33, 33, 135, 8640, 135, 8640, 33, 8640, 8640, 135, 8640, 135, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1127424 . Total input tokens: 251258154 . Total output tokens: 225216556
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 55.00930793816224,
    "estimated_duration": 3600.126574924002,
    "input_throughput": 5309.055001879616,
    "output_throughput": 4683.344779441796,
    "total_throughput": 9992.399781321412,
    "itl": 180.81069967369686,
    "ttft": 1919979.4177301505,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 606,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.006022675000135,
    "arrivals": 376270,
    "finished_requests": 77311,
    "scheduler_time": 135.34352293510895
}
#Debug simulation 
Total elapsed time: 55.00944187492132. Arrivals time: 0.5725755207240582 Scheduler time: 54.30437371134758 Scheduler overhead time: 0.0513516440987587 Adapter cache time: 0.015627249144017696 Engine time: 0.04721743706613779 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-16/adapters_384_slots_96_rate_0.8-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-16/adapters_384_slots_96_rate_0.8-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 135, 33, 8640, 8640, 33, 135, 8640, 8640, 8640, 8640, 135, 135, 135, 135, 8640, 8640, 135, 135, 33, 8640, 33, 8640, 135, 135, 135, 33, 33, 135, 33, 8640, 33, 8640, 135, 8640, 135, 33, 135, 8640, 135, 8640, 33, 8640, 8640, 8640, 8640, 33, 135, 135, 135, 8640, 135, 33, 135, 33, 8640, 135, 8640, 8640, 135, 8640, 8640, 33, 33, 8640, 135, 135, 33, 33, 33, 135, 33, 135, 33, 8640, 33, 135, 8640, 33, 8640, 135, 33, 8640, 8640, 8640, 8640, 135, 33, 135, 8640, 8640, 135, 33, 33, 8640, 135, 135, 33, 33, 8640, 135, 8640, 135, 8640, 8640, 135, 8640, 8640, 33, 135, 135, 135, 135, 33, 33, 8640, 33, 8640, 33, 33, 33, 135, 135, 8640, 33, 33, 8640, 33, 8640, 135, 33, 8640, 135, 135, 33, 8640, 8640, 8640, 33, 135, 8640, 33, 8640, 135, 135, 8640, 8640, 33, 135, 8640, 33, 135, 135, 33, 135, 33, 135, 8640, 8640, 135, 33, 8640, 33, 8640, 135, 135, 135, 135, 135, 33, 33, 8640, 33, 8640, 33, 135, 8640, 135, 8640, 135, 8640, 135, 8640, 33, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 33, 33, 33, 33, 33, 135, 33, 33, 135, 8640, 8640, 33, 33, 8640, 33, 33, 33, 135, 33, 135, 8640, 8640, 135, 135, 33, 8640, 135, 8640, 33, 135, 135, 33, 33, 135, 33, 8640, 8640, 33, 8640, 8640, 33, 135, 8640, 33, 33, 135, 135, 33, 33, 8640, 8640, 8640, 8640, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 8640, 135, 135, 135, 8640, 33, 135, 135, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 135, 33, 8640, 8640, 8640, 135, 33, 8640, 8640, 135, 135, 8640, 8640, 33, 8640, 8640, 135, 33, 8640, 135, 135, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 135, 8640, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 8640, 33, 33, 33, 135, 33, 135, 135, 33, 8640, 135, 8640, 33, 8640, 33, 135, 135, 135, 135, 33, 135, 8640, 8640, 33, 8640, 8640, 33, 8640, 135, 8640, 135, 135, 135, 33, 135, 33, 33, 8640, 33, 135, 33, 33, 135, 8640, 135, 8640, 33, 8640, 8640, 135, 8640, 135, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1127424 . Total input tokens: 251258154 . Total output tokens: 225216556
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 55.82020562607795,
    "estimated_duration": 3600.195459341727,
    "input_throughput": 5314.837268168382,
    "output_throughput": 4693.14046718157,
    "total_throughput": 10007.977735349952,
    "itl": 183.13061689169388,
    "ttft": 1917585.238053878,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 581,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7372192213381392,
    "arrivals": 376270,
    "finished_requests": 77454,
    "scheduler_time": 134.64404934877786
}
#Debug simulation 
Total elapsed time: 55.82034659618512. Arrivals time: 0.362889816518873 Scheduler time: 55.32305284962058 Scheduler overhead time: 0.05241037765517831 Adapter cache time: 0.015635670628398657 Engine time: 0.047925114165991545 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-32/adapters_384_slots_96_rate_0.8-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-32/adapters_384_slots_96_rate_0.8-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 135, 33, 8640, 8640, 33, 135, 8640, 8640, 8640, 8640, 135, 135, 135, 135, 8640, 8640, 135, 135, 33, 8640, 33, 8640, 135, 135, 135, 33, 33, 135, 33, 8640, 33, 8640, 135, 8640, 135, 33, 135, 8640, 135, 8640, 33, 8640, 8640, 8640, 8640, 33, 135, 135, 135, 8640, 135, 33, 135, 33, 8640, 135, 8640, 8640, 135, 8640, 8640, 33, 33, 8640, 135, 135, 33, 33, 33, 135, 33, 135, 33, 8640, 33, 135, 8640, 33, 8640, 135, 33, 8640, 8640, 8640, 8640, 135, 33, 135, 8640, 8640, 135, 33, 33, 8640, 135, 135, 33, 33, 8640, 135, 8640, 135, 8640, 8640, 135, 8640, 8640, 33, 135, 135, 135, 135, 33, 33, 8640, 33, 8640, 33, 33, 33, 135, 135, 8640, 33, 33, 8640, 33, 8640, 135, 33, 8640, 135, 135, 33, 8640, 8640, 8640, 33, 135, 8640, 33, 8640, 135, 135, 8640, 8640, 33, 135, 8640, 33, 135, 135, 33, 135, 33, 135, 8640, 8640, 135, 33, 8640, 33, 8640, 135, 135, 135, 135, 135, 33, 33, 8640, 33, 8640, 33, 135, 8640, 135, 8640, 135, 8640, 135, 8640, 33, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 33, 33, 33, 33, 33, 135, 33, 33, 135, 8640, 8640, 33, 33, 8640, 33, 33, 33, 135, 33, 135, 8640, 8640, 135, 135, 33, 8640, 135, 8640, 33, 135, 135, 33, 33, 135, 33, 8640, 8640, 33, 8640, 8640, 33, 135, 8640, 33, 33, 135, 135, 33, 33, 8640, 8640, 8640, 8640, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 8640, 135, 135, 135, 8640, 33, 135, 135, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 135, 33, 8640, 8640, 8640, 135, 33, 8640, 8640, 135, 135, 8640, 8640, 33, 8640, 8640, 135, 33, 8640, 135, 135, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 135, 8640, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 8640, 33, 33, 33, 135, 33, 135, 135, 33, 8640, 135, 8640, 33, 8640, 33, 135, 135, 135, 135, 33, 135, 8640, 8640, 33, 8640, 8640, 33, 8640, 135, 8640, 135, 135, 135, 33, 135, 33, 33, 8640, 33, 135, 33, 33, 135, 8640, 135, 8640, 33, 8640, 8640, 135, 8640, 135, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1127424 . Total input tokens: 251258154 . Total output tokens: 225216556
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 56.48025825433433,
    "estimated_duration": 3600.0069267801546,
    "input_throughput": 5308.271730769089,
    "output_throughput": 4684.761263802403,
    "total_throughput": 9993.032994571491,
    "itl": 181.15063691667805,
    "ttft": 1917637.357667419,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 599,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.006416297666724,
    "arrivals": 376270,
    "finished_requests": 77336,
    "scheduler_time": 135.2562333701137
}
#Debug simulation 
Total elapsed time: 56.4803912229836. Arrivals time: 0.34386959578841925 Scheduler time: 56.002587599214166 Scheduler overhead time: 0.05189577117562294 Adapter cache time: 0.015356526710093021 Engine time: 0.04844724386930466 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-8/adapters_384_slots_96_rate_0.8-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-8/adapters_384_slots_96_rate_0.8-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 66, 33, 8640, 8640, 33, 66, 8640, 8640, 8640, 8640, 66, 66, 66, 66, 8640, 8640, 66, 66, 33, 8640, 33, 8640, 66, 66, 66, 33, 33, 66, 33, 8640, 33, 8640, 66, 8640, 66, 33, 66, 8640, 66, 8640, 33, 8640, 8640, 8640, 8640, 33, 66, 66, 66, 8640, 66, 33, 66, 33, 8640, 66, 8640, 8640, 66, 8640, 8640, 33, 33, 8640, 66, 66, 33, 33, 33, 66, 33, 66, 33, 8640, 33, 66, 8640, 33, 8640, 66, 33, 8640, 8640, 8640, 8640, 66, 33, 66, 8640, 8640, 66, 33, 33, 8640, 66, 66, 33, 33, 8640, 66, 8640, 66, 8640, 8640, 66, 8640, 8640, 33, 66, 66, 66, 66, 33, 33, 8640, 33, 8640, 33, 33, 33, 66, 66, 8640, 33, 33, 8640, 33, 8640, 66, 33, 8640, 66, 66, 33, 8640, 8640, 8640, 33, 66, 8640, 33, 8640, 66, 66, 8640, 8640, 33, 66, 8640, 33, 66, 66, 33, 66, 33, 66, 8640, 8640, 66, 33, 8640, 33, 8640, 66, 66, 66, 66, 66, 33, 33, 8640, 33, 8640, 33, 66, 8640, 66, 8640, 66, 8640, 66, 8640, 33, 66, 66, 66, 66, 66, 66, 66, 66, 8640, 33, 33, 33, 33, 33, 66, 33, 33, 66, 8640, 8640, 33, 33, 8640, 33, 33, 33, 66, 33, 66, 8640, 8640, 66, 66, 33, 8640, 66, 8640, 33, 66, 66, 33, 33, 66, 33, 8640, 8640, 33, 8640, 8640, 33, 66, 8640, 33, 33, 66, 66, 33, 33, 8640, 8640, 8640, 8640, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 8640, 66, 66, 66, 8640, 33, 66, 66, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 66, 33, 8640, 8640, 8640, 66, 33, 8640, 8640, 66, 66, 8640, 8640, 33, 8640, 8640, 66, 33, 8640, 66, 66, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 66, 8640, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 8640, 33, 33, 33, 66, 33, 66, 66, 33, 8640, 66, 8640, 33, 8640, 33, 66, 66, 66, 66, 33, 66, 8640, 8640, 33, 8640, 8640, 33, 8640, 66, 8640, 66, 66, 66, 33, 66, 33, 33, 8640, 33, 66, 33, 33, 66, 8640, 66, 8640, 33, 8640, 8640, 66, 8640, 66, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1118592 . Total input tokens: 249274283 . Total output tokens: 223465232
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 104.60496732406318,
    "estimated_duration": 3600.1255463599146,
    "input_throughput": 5309.877323397349,
    "output_throughput": 4685.402712429089,
    "total_throughput": 9995.280035826438,
    "itl": 182.25408754716648,
    "ttft": 1864370.0729272354,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 255,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7804243747028512,
    "arrivals": 373284,
    "finished_requests": 77342,
    "scheduler_time": 134.96359312438474
}
#Debug simulation 
Total elapsed time: 104.60508319176733. Arrivals time: 0.35811643674969673 Scheduler time: 104.10451188357547 Scheduler overhead time: 0.0572471059858799 Adapter cache time: 0.012227651663124561 Engine time: 0.05244864709675312 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-16/adapters_384_slots_96_rate_0.8-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-16/adapters_384_slots_96_rate_0.8-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 66, 33, 8640, 8640, 33, 66, 8640, 8640, 8640, 8640, 66, 66, 66, 66, 8640, 8640, 66, 66, 33, 8640, 33, 8640, 66, 66, 66, 33, 33, 66, 33, 8640, 33, 8640, 66, 8640, 66, 33, 66, 8640, 66, 8640, 33, 8640, 8640, 8640, 8640, 33, 66, 66, 66, 8640, 66, 33, 66, 33, 8640, 66, 8640, 8640, 66, 8640, 8640, 33, 33, 8640, 66, 66, 33, 33, 33, 66, 33, 66, 33, 8640, 33, 66, 8640, 33, 8640, 66, 33, 8640, 8640, 8640, 8640, 66, 33, 66, 8640, 8640, 66, 33, 33, 8640, 66, 66, 33, 33, 8640, 66, 8640, 66, 8640, 8640, 66, 8640, 8640, 33, 66, 66, 66, 66, 33, 33, 8640, 33, 8640, 33, 33, 33, 66, 66, 8640, 33, 33, 8640, 33, 8640, 66, 33, 8640, 66, 66, 33, 8640, 8640, 8640, 33, 66, 8640, 33, 8640, 66, 66, 8640, 8640, 33, 66, 8640, 33, 66, 66, 33, 66, 33, 66, 8640, 8640, 66, 33, 8640, 33, 8640, 66, 66, 66, 66, 66, 33, 33, 8640, 33, 8640, 33, 66, 8640, 66, 8640, 66, 8640, 66, 8640, 33, 66, 66, 66, 66, 66, 66, 66, 66, 8640, 33, 33, 33, 33, 33, 66, 33, 33, 66, 8640, 8640, 33, 33, 8640, 33, 33, 33, 66, 33, 66, 8640, 8640, 66, 66, 33, 8640, 66, 8640, 33, 66, 66, 33, 33, 66, 33, 8640, 8640, 33, 8640, 8640, 33, 66, 8640, 33, 33, 66, 66, 33, 33, 8640, 8640, 8640, 8640, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 8640, 66, 66, 66, 8640, 33, 66, 66, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 66, 33, 8640, 8640, 8640, 66, 33, 8640, 8640, 66, 66, 8640, 8640, 33, 8640, 8640, 66, 33, 8640, 66, 66, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 66, 8640, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 8640, 33, 33, 33, 66, 33, 66, 66, 33, 8640, 66, 8640, 33, 8640, 33, 66, 66, 66, 66, 33, 66, 8640, 8640, 33, 8640, 8640, 33, 8640, 66, 8640, 66, 66, 66, 33, 66, 33, 33, 8640, 33, 66, 33, 33, 66, 8640, 66, 8640, 33, 8640, 8640, 66, 8640, 66, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1118592 . Total input tokens: 249274283 . Total output tokens: 223465232
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 104.6642509480007,
    "estimated_duration": 3600.150438146873,
    "input_throughput": 5309.690616661989,
    "output_throughput": 4685.288376083094,
    "total_throughput": 9994.978992745082,
    "itl": 182.2561639101583,
    "ttft": 1864372.2427702064,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 255,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8343756012455598,
    "arrivals": 373284,
    "finished_requests": 77341,
    "scheduler_time": 134.96349977789106
}
#Debug simulation 
Total elapsed time: 104.66436917940155. Arrivals time: 0.36228597769513726 Scheduler time: 104.15774485748261 Scheduler overhead time: 0.059048670809715986 Adapter cache time: 0.012133391108363867 Engine time: 0.05307847773656249 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-32/adapters_384_slots_96_rate_0.8-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-32/adapters_384_slots_96_rate_0.8-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 66, 33, 8640, 8640, 33, 66, 8640, 8640, 8640, 8640, 66, 66, 66, 66, 8640, 8640, 66, 66, 33, 8640, 33, 8640, 66, 66, 66, 33, 33, 66, 33, 8640, 33, 8640, 66, 8640, 66, 33, 66, 8640, 66, 8640, 33, 8640, 8640, 8640, 8640, 33, 66, 66, 66, 8640, 66, 33, 66, 33, 8640, 66, 8640, 8640, 66, 8640, 8640, 33, 33, 8640, 66, 66, 33, 33, 33, 66, 33, 66, 33, 8640, 33, 66, 8640, 33, 8640, 66, 33, 8640, 8640, 8640, 8640, 66, 33, 66, 8640, 8640, 66, 33, 33, 8640, 66, 66, 33, 33, 8640, 66, 8640, 66, 8640, 8640, 66, 8640, 8640, 33, 66, 66, 66, 66, 33, 33, 8640, 33, 8640, 33, 33, 33, 66, 66, 8640, 33, 33, 8640, 33, 8640, 66, 33, 8640, 66, 66, 33, 8640, 8640, 8640, 33, 66, 8640, 33, 8640, 66, 66, 8640, 8640, 33, 66, 8640, 33, 66, 66, 33, 66, 33, 66, 8640, 8640, 66, 33, 8640, 33, 8640, 66, 66, 66, 66, 66, 33, 33, 8640, 33, 8640, 33, 66, 8640, 66, 8640, 66, 8640, 66, 8640, 33, 66, 66, 66, 66, 66, 66, 66, 66, 8640, 33, 33, 33, 33, 33, 66, 33, 33, 66, 8640, 8640, 33, 33, 8640, 33, 33, 33, 66, 33, 66, 8640, 8640, 66, 66, 33, 8640, 66, 8640, 33, 66, 66, 33, 33, 66, 33, 8640, 8640, 33, 8640, 8640, 33, 66, 8640, 33, 33, 66, 66, 33, 33, 8640, 8640, 8640, 8640, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 8640, 66, 66, 66, 8640, 33, 66, 66, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 66, 33, 8640, 8640, 8640, 66, 33, 8640, 8640, 66, 66, 8640, 8640, 33, 8640, 8640, 66, 33, 8640, 66, 66, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 66, 8640, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 8640, 33, 33, 33, 66, 33, 66, 66, 33, 8640, 66, 8640, 33, 8640, 33, 66, 66, 66, 66, 33, 66, 8640, 8640, 33, 8640, 8640, 33, 8640, 66, 8640, 66, 66, 66, 33, 66, 33, 33, 8640, 33, 66, 33, 33, 66, 8640, 66, 8640, 33, 8640, 8640, 66, 8640, 66, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1118592 . Total input tokens: 249274283 . Total output tokens: 223465232
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 103.31743329903111,
    "estimated_duration": 3600.19261585526,
    "input_throughput": 5299.525063179856,
    "output_throughput": 4675.059863707211,
    "total_throughput": 9974.584926887068,
    "itl": 180.58404603381342,
    "ttft": 1864536.2550942765,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 241,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7901456216350236,
    "arrivals": 373284,
    "finished_requests": 77178,
    "scheduler_time": 135.42582793942714
}
#Debug simulation 
Total elapsed time: 103.3175556580536. Arrivals time: 0.35874627251178026 Scheduler time: 102.81469974806532 Scheduler overhead time: 0.05861332546919584 Adapter cache time: 0.012032922357320786 Engine time: 0.05311873275786638 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-16/adapters_384_slots_96_rate_0.8-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-16/adapters_384_slots_96_rate_0.8-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 66, 33, 8640, 8640, 33, 66, 8640, 8640, 8640, 8640, 66, 66, 66, 66, 8640, 8640, 66, 66, 33, 8640, 33, 8640, 66, 66, 66, 33, 33, 66, 33, 8640, 33, 8640, 66, 8640, 66, 33, 66, 8640, 66, 8640, 33, 8640, 8640, 8640, 8640, 33, 66, 66, 66, 8640, 66, 33, 66, 33, 8640, 66, 8640, 8640, 66, 8640, 8640, 33, 33, 8640, 66, 66, 33, 33, 33, 66, 33, 66, 33, 8640, 33, 66, 8640, 33, 8640, 66, 33, 8640, 8640, 8640, 8640, 66, 33, 66, 8640, 8640, 66, 33, 33, 8640, 66, 66, 33, 33, 8640, 66, 8640, 66, 8640, 8640, 66, 8640, 8640, 33, 66, 66, 66, 66, 33, 33, 8640, 33, 8640, 33, 33, 33, 66, 66, 8640, 33, 33, 8640, 33, 8640, 66, 33, 8640, 66, 66, 33, 8640, 8640, 8640, 33, 66, 8640, 33, 8640, 66, 66, 8640, 8640, 33, 66, 8640, 33, 66, 66, 33, 66, 33, 66, 8640, 8640, 66, 33, 8640, 33, 8640, 66, 66, 66, 66, 66, 33, 33, 8640, 33, 8640, 33, 66, 8640, 66, 8640, 66, 8640, 66, 8640, 33, 66, 66, 66, 66, 66, 66, 66, 66, 8640, 33, 33, 33, 33, 33, 66, 33, 33, 66, 8640, 8640, 33, 33, 8640, 33, 33, 33, 66, 33, 66, 8640, 8640, 66, 66, 33, 8640, 66, 8640, 33, 66, 66, 33, 33, 66, 33, 8640, 8640, 33, 8640, 8640, 33, 66, 8640, 33, 33, 66, 66, 33, 33, 8640, 8640, 8640, 8640, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 8640, 66, 66, 66, 8640, 33, 66, 66, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 66, 33, 8640, 8640, 8640, 66, 33, 8640, 8640, 66, 66, 8640, 8640, 33, 8640, 8640, 66, 33, 8640, 66, 66, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 66, 8640, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 8640, 33, 33, 33, 66, 33, 66, 66, 33, 8640, 66, 8640, 33, 8640, 33, 66, 66, 66, 66, 33, 66, 8640, 8640, 33, 8640, 8640, 33, 8640, 66, 8640, 66, 66, 66, 33, 66, 33, 33, 8640, 33, 66, 33, 33, 66, 8640, 66, 8640, 33, 8640, 8640, 66, 8640, 66, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1118592 . Total input tokens: 249274283 . Total output tokens: 223465232
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 104.38296589395031,
    "estimated_duration": 3600.088376180779,
    "input_throughput": 5309.808538722411,
    "output_throughput": 4685.500253717371,
    "total_throughput": 9995.308792439782,
    "itl": 182.2563474889741,
    "ttft": 1864352.5042393433,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 254,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.796246353564786,
    "arrivals": 373284,
    "finished_requests": 77342,
    "scheduler_time": 134.96066241935114
}
#Debug simulation 
Total elapsed time: 104.38307759119198. Arrivals time: 0.3600675011985004 Scheduler time: 103.88051628740504 Scheduler overhead time: 0.05868945550173521 Adapter cache time: 0.011951026506721973 Engine time: 0.05225663213059306 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-32/adapters_384_slots_96_rate_0.8-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-32/adapters_384_slots_96_rate_0.8-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 66, 33, 8640, 8640, 33, 66, 8640, 8640, 8640, 8640, 66, 66, 66, 66, 8640, 8640, 66, 66, 33, 8640, 33, 8640, 66, 66, 66, 33, 33, 66, 33, 8640, 33, 8640, 66, 8640, 66, 33, 66, 8640, 66, 8640, 33, 8640, 8640, 8640, 8640, 33, 66, 66, 66, 8640, 66, 33, 66, 33, 8640, 66, 8640, 8640, 66, 8640, 8640, 33, 33, 8640, 66, 66, 33, 33, 33, 66, 33, 66, 33, 8640, 33, 66, 8640, 33, 8640, 66, 33, 8640, 8640, 8640, 8640, 66, 33, 66, 8640, 8640, 66, 33, 33, 8640, 66, 66, 33, 33, 8640, 66, 8640, 66, 8640, 8640, 66, 8640, 8640, 33, 66, 66, 66, 66, 33, 33, 8640, 33, 8640, 33, 33, 33, 66, 66, 8640, 33, 33, 8640, 33, 8640, 66, 33, 8640, 66, 66, 33, 8640, 8640, 8640, 33, 66, 8640, 33, 8640, 66, 66, 8640, 8640, 33, 66, 8640, 33, 66, 66, 33, 66, 33, 66, 8640, 8640, 66, 33, 8640, 33, 8640, 66, 66, 66, 66, 66, 33, 33, 8640, 33, 8640, 33, 66, 8640, 66, 8640, 66, 8640, 66, 8640, 33, 66, 66, 66, 66, 66, 66, 66, 66, 8640, 33, 33, 33, 33, 33, 66, 33, 33, 66, 8640, 8640, 33, 33, 8640, 33, 33, 33, 66, 33, 66, 8640, 8640, 66, 66, 33, 8640, 66, 8640, 33, 66, 66, 33, 33, 66, 33, 8640, 8640, 33, 8640, 8640, 33, 66, 8640, 33, 33, 66, 66, 33, 33, 8640, 8640, 8640, 8640, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 8640, 66, 66, 66, 8640, 33, 66, 66, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 66, 33, 8640, 8640, 8640, 66, 33, 8640, 8640, 66, 66, 8640, 8640, 33, 8640, 8640, 66, 33, 8640, 66, 66, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 66, 8640, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 8640, 33, 33, 33, 66, 33, 66, 66, 33, 8640, 66, 8640, 33, 8640, 33, 66, 66, 66, 66, 33, 66, 8640, 8640, 33, 8640, 8640, 33, 8640, 66, 8640, 66, 66, 66, 33, 66, 33, 33, 8640, 33, 66, 33, 33, 66, 8640, 66, 8640, 33, 8640, 8640, 66, 8640, 66, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1118592 . Total input tokens: 249274283 . Total output tokens: 223465232
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 103.1577355270274,
    "estimated_duration": 3600.109738633941,
    "input_throughput": 5299.15985484347,
    "output_throughput": 4674.934438633594,
    "total_throughput": 9974.094293477065,
    "itl": 180.56699770161708,
    "ttft": 1864524.9547670046,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 240,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7970766657777166,
    "arrivals": 373284,
    "finished_requests": 77172,
    "scheduler_time": 135.42681051158408
}
#Debug simulation 
Total elapsed time: 103.15785532770678. Arrivals time: 0.575649578589946 Scheduler time: 102.44047090830281 Scheduler overhead time: 0.05818350147455931 Adapter cache time: 0.011803461238741875 Engine time: 0.0519514475017786 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-16/adapters_384_slots_96_rate_0.8-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-16/adapters_384_slots_96_rate_0.8-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 66, 33, 8640, 8640, 33, 66, 8640, 8640, 8640, 8640, 66, 66, 66, 66, 8640, 8640, 66, 66, 33, 8640, 33, 8640, 66, 66, 66, 33, 33, 66, 33, 8640, 33, 8640, 66, 8640, 66, 33, 66, 8640, 66, 8640, 33, 8640, 8640, 8640, 8640, 33, 66, 66, 66, 8640, 66, 33, 66, 33, 8640, 66, 8640, 8640, 66, 8640, 8640, 33, 33, 8640, 66, 66, 33, 33, 33, 66, 33, 66, 33, 8640, 33, 66, 8640, 33, 8640, 66, 33, 8640, 8640, 8640, 8640, 66, 33, 66, 8640, 8640, 66, 33, 33, 8640, 66, 66, 33, 33, 8640, 66, 8640, 66, 8640, 8640, 66, 8640, 8640, 33, 66, 66, 66, 66, 33, 33, 8640, 33, 8640, 33, 33, 33, 66, 66, 8640, 33, 33, 8640, 33, 8640, 66, 33, 8640, 66, 66, 33, 8640, 8640, 8640, 33, 66, 8640, 33, 8640, 66, 66, 8640, 8640, 33, 66, 8640, 33, 66, 66, 33, 66, 33, 66, 8640, 8640, 66, 33, 8640, 33, 8640, 66, 66, 66, 66, 66, 33, 33, 8640, 33, 8640, 33, 66, 8640, 66, 8640, 66, 8640, 66, 8640, 33, 66, 66, 66, 66, 66, 66, 66, 66, 8640, 33, 33, 33, 33, 33, 66, 33, 33, 66, 8640, 8640, 33, 33, 8640, 33, 33, 33, 66, 33, 66, 8640, 8640, 66, 66, 33, 8640, 66, 8640, 33, 66, 66, 33, 33, 66, 33, 8640, 8640, 33, 8640, 8640, 33, 66, 8640, 33, 33, 66, 66, 33, 33, 8640, 8640, 8640, 8640, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 8640, 66, 66, 66, 8640, 33, 66, 66, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 66, 33, 8640, 8640, 8640, 66, 33, 8640, 8640, 66, 66, 8640, 8640, 33, 8640, 8640, 66, 33, 8640, 66, 66, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 66, 8640, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 8640, 33, 33, 33, 66, 33, 66, 66, 33, 8640, 66, 8640, 33, 8640, 33, 66, 66, 66, 66, 33, 66, 8640, 8640, 33, 8640, 8640, 33, 8640, 66, 8640, 66, 66, 66, 33, 66, 33, 33, 8640, 33, 66, 33, 33, 66, 8640, 66, 8640, 33, 8640, 8640, 66, 8640, 66, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1118592 . Total input tokens: 249274283 . Total output tokens: 223465232
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 104.45361260976642,
    "estimated_duration": 3600.107738261722,
    "input_throughput": 5309.753593438242,
    "output_throughput": 4685.343946996551,
    "total_throughput": 9995.097540434792,
    "itl": 182.25431109290156,
    "ttft": 1864365.7221295147,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 255,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7624628252000558,
    "arrivals": 373284,
    "finished_requests": 77341,
    "scheduler_time": 134.96332088553845
}
#Debug simulation 
Total elapsed time: 104.45377017464489. Arrivals time: 0.35947474697604775 Scheduler time: 103.95130000216886 Scheduler overhead time: 0.05868761753663421 Adapter cache time: 0.012182490434497595 Engine time: 0.05243356712162495 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-32/adapters_384_slots_96_rate_0.8-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-32/adapters_384_slots_96_rate_0.8-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 8640, 66, 33, 8640, 8640, 33, 66, 8640, 8640, 8640, 8640, 66, 66, 66, 66, 8640, 8640, 66, 66, 33, 8640, 33, 8640, 66, 66, 66, 33, 33, 66, 33, 8640, 33, 8640, 66, 8640, 66, 33, 66, 8640, 66, 8640, 33, 8640, 8640, 8640, 8640, 33, 66, 66, 66, 8640, 66, 33, 66, 33, 8640, 66, 8640, 8640, 66, 8640, 8640, 33, 33, 8640, 66, 66, 33, 33, 33, 66, 33, 66, 33, 8640, 33, 66, 8640, 33, 8640, 66, 33, 8640, 8640, 8640, 8640, 66, 33, 66, 8640, 8640, 66, 33, 33, 8640, 66, 66, 33, 33, 8640, 66, 8640, 66, 8640, 8640, 66, 8640, 8640, 33, 66, 66, 66, 66, 33, 33, 8640, 33, 8640, 33, 33, 33, 66, 66, 8640, 33, 33, 8640, 33, 8640, 66, 33, 8640, 66, 66, 33, 8640, 8640, 8640, 33, 66, 8640, 33, 8640, 66, 66, 8640, 8640, 33, 66, 8640, 33, 66, 66, 33, 66, 33, 66, 8640, 8640, 66, 33, 8640, 33, 8640, 66, 66, 66, 66, 66, 33, 33, 8640, 33, 8640, 33, 66, 8640, 66, 8640, 66, 8640, 66, 8640, 33, 66, 66, 66, 66, 66, 66, 66, 66, 8640, 33, 33, 33, 33, 33, 66, 33, 33, 66, 8640, 8640, 33, 33, 8640, 33, 33, 33, 66, 33, 66, 8640, 8640, 66, 66, 33, 8640, 66, 8640, 33, 66, 66, 33, 33, 66, 33, 8640, 8640, 33, 8640, 8640, 33, 66, 8640, 33, 33, 66, 66, 33, 33, 8640, 8640, 8640, 8640, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 8640, 66, 66, 66, 8640, 33, 66, 66, 8640, 8640, 33, 8640, 8640, 33, 8640, 33, 33, 66, 33, 8640, 8640, 8640, 66, 33, 8640, 8640, 66, 66, 8640, 8640, 33, 8640, 8640, 66, 33, 8640, 66, 66, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 33, 8640, 33, 66, 8640, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 8640, 33, 33, 33, 66, 33, 66, 66, 33, 8640, 66, 8640, 33, 8640, 33, 66, 66, 66, 66, 33, 66, 8640, 8640, 33, 8640, 8640, 33, 8640, 66, 8640, 66, 66, 66, 33, 66, 33, 33, 8640, 33, 66, 33, 33, 66, 8640, 66, 8640, 33, 8640, 8640, 66, 8640, 66, 33, 8640, 33, 8640, 8640, 33, 33, 33]
Prompts retrieved: 1118592 . Total input tokens: 249274283 . Total output tokens: 223465232
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 103.06123028788716,
    "estimated_duration": 3600.1220612910956,
    "input_throughput": 5299.141716644546,
    "output_throughput": 4674.918437061057,
    "total_throughput": 9974.060153705605,
    "itl": 180.56679989523434,
    "ttft": 1864530.4211605252,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 240,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8077657376229795,
    "arrivals": 373284,
    "finished_requests": 77172,
    "scheduler_time": 135.42704634393715
}
#Debug simulation 
Total elapsed time: 103.06134588783607. Arrivals time: 0.36369118792936206 Scheduler time: 102.55290264775977 Scheduler overhead time: 0.059266462456434965 Adapter cache time: 0.012042471207678318 Engine time: 0.05374315055087209 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-8/adapters_384_slots_96_rate_0.4-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-8/adapters_384_slots_96_rate_0.4-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 4320, 1080, 540, 4320, 4320, 540, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 540, 4320, 540, 4320, 1080, 1080, 1080, 540, 540, 1080, 540, 4320, 540, 4320, 1080, 4320, 1080, 540, 1080, 4320, 1080, 4320, 540, 4320, 4320, 4320, 4320, 540, 1080, 1080, 1080, 4320, 1080, 540, 1080, 540, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 540, 540, 4320, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 4320, 540, 1080, 4320, 540, 4320, 1080, 540, 4320, 4320, 4320, 4320, 1080, 540, 1080, 4320, 4320, 1080, 540, 540, 4320, 1080, 1080, 540, 540, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 540, 1080, 1080, 1080, 1080, 540, 540, 4320, 540, 4320, 540, 540, 540, 1080, 1080, 4320, 540, 540, 4320, 540, 4320, 1080, 540, 4320, 1080, 1080, 540, 4320, 4320, 4320, 540, 1080, 4320, 540, 4320, 1080, 1080, 4320, 4320, 540, 1080, 4320, 540, 1080, 1080, 540, 1080, 540, 1080, 4320, 4320, 1080, 540, 4320, 540, 4320, 1080, 1080, 1080, 1080, 1080, 540, 540, 4320, 540, 4320, 540, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 4320, 4320, 540, 540, 4320, 540, 540, 540, 1080, 540, 1080, 4320, 4320, 1080, 1080, 540, 4320, 1080, 4320, 540, 1080, 1080, 540, 540, 1080, 540, 4320, 4320, 540, 4320, 4320, 540, 1080, 4320, 540, 540, 1080, 1080, 540, 540, 4320, 4320, 4320, 4320, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 4320, 1080, 1080, 1080, 4320, 540, 1080, 1080, 4320, 4320, 540, 4320, 4320, 540, 4320, 540, 540, 1080, 540, 4320, 4320, 4320, 1080, 540, 4320, 4320, 1080, 1080, 4320, 4320, 540, 4320, 4320, 1080, 540, 4320, 1080, 1080, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 4320, 540, 1080, 4320, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 4320, 540, 540, 540, 1080, 540, 1080, 1080, 540, 4320, 1080, 4320, 540, 4320, 540, 1080, 1080, 1080, 1080, 540, 1080, 4320, 4320, 540, 4320, 4320, 540, 4320, 1080, 4320, 1080, 1080, 1080, 540, 1080, 540, 540, 4320, 540, 1080, 540, 540, 1080, 4320, 1080, 4320, 540, 4320, 4320, 1080, 4320, 1080, 540, 4320, 540, 4320, 4320, 540, 540, 540]
Prompts retrieved: 760320 . Total input tokens: 169471057 . Total output tokens: 151920508
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 64.24417836079374,
    "estimated_duration": 3600.1932445970624,
    "input_throughput": 5278.615537796486,
    "output_throughput": 4677.509193505734,
    "total_throughput": 9956.124731302221,
    "itl": 181.7509707723875,
    "ttft": 1818526.3359627167,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 710,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1729462981922945,
    "arrivals": 253064,
    "finished_requests": 76938,
    "scheduler_time": 132.78108053988936
}
#Debug simulation 
Total elapsed time: 64.24434738373384. Arrivals time: 0.35418349225074053 Scheduler time: 63.75239282893017 Scheduler overhead time: 0.05319932056590915 Adapter cache time: 0.019013275858014822 Engine time: 0.04727243585512042 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-16/adapters_384_slots_96_rate_0.4-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-16/adapters_384_slots_96_rate_0.4-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 4320, 1080, 540, 4320, 4320, 540, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 540, 4320, 540, 4320, 1080, 1080, 1080, 540, 540, 1080, 540, 4320, 540, 4320, 1080, 4320, 1080, 540, 1080, 4320, 1080, 4320, 540, 4320, 4320, 4320, 4320, 540, 1080, 1080, 1080, 4320, 1080, 540, 1080, 540, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 540, 540, 4320, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 4320, 540, 1080, 4320, 540, 4320, 1080, 540, 4320, 4320, 4320, 4320, 1080, 540, 1080, 4320, 4320, 1080, 540, 540, 4320, 1080, 1080, 540, 540, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 540, 1080, 1080, 1080, 1080, 540, 540, 4320, 540, 4320, 540, 540, 540, 1080, 1080, 4320, 540, 540, 4320, 540, 4320, 1080, 540, 4320, 1080, 1080, 540, 4320, 4320, 4320, 540, 1080, 4320, 540, 4320, 1080, 1080, 4320, 4320, 540, 1080, 4320, 540, 1080, 1080, 540, 1080, 540, 1080, 4320, 4320, 1080, 540, 4320, 540, 4320, 1080, 1080, 1080, 1080, 1080, 540, 540, 4320, 540, 4320, 540, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 4320, 4320, 540, 540, 4320, 540, 540, 540, 1080, 540, 1080, 4320, 4320, 1080, 1080, 540, 4320, 1080, 4320, 540, 1080, 1080, 540, 540, 1080, 540, 4320, 4320, 540, 4320, 4320, 540, 1080, 4320, 540, 540, 1080, 1080, 540, 540, 4320, 4320, 4320, 4320, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 4320, 1080, 1080, 1080, 4320, 540, 1080, 1080, 4320, 4320, 540, 4320, 4320, 540, 4320, 540, 540, 1080, 540, 4320, 4320, 4320, 1080, 540, 4320, 4320, 1080, 1080, 4320, 4320, 540, 4320, 4320, 1080, 540, 4320, 1080, 1080, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 4320, 540, 1080, 4320, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 4320, 540, 540, 540, 1080, 540, 1080, 1080, 540, 4320, 1080, 4320, 540, 4320, 540, 1080, 1080, 1080, 1080, 540, 1080, 4320, 4320, 540, 4320, 4320, 540, 4320, 1080, 4320, 1080, 1080, 1080, 540, 1080, 540, 540, 4320, 540, 1080, 540, 540, 1080, 4320, 1080, 4320, 540, 4320, 4320, 1080, 4320, 1080, 540, 4320, 540, 4320, 4320, 540, 540, 540]
Prompts retrieved: 760320 . Total input tokens: 169471057 . Total output tokens: 151920508
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 68.19900731090456,
    "estimated_duration": 3600.023350436598,
    "input_throughput": 5293.238444603139,
    "output_throughput": 4674.528013258334,
    "total_throughput": 9967.766457861473,
    "itl": 181.31913951310372,
    "ttft": 1821782.1148743718,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 665,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.167348195586824,
    "arrivals": 253064,
    "finished_requests": 77003,
    "scheduler_time": 132.980313732893
}
#Debug simulation 
Total elapsed time: 68.1991318911314. Arrivals time: 0.3491786099039018 Scheduler time: 67.71305306907743 Scheduler overhead time: 0.0524653559550643 Adapter cache time: 0.01856145029887557 Engine time: 0.04730143351480365 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-32/adapters_384_slots_96_rate_0.4-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-32/adapters_384_slots_96_rate_0.4-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 4320, 1080, 540, 4320, 4320, 540, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 540, 4320, 540, 4320, 1080, 1080, 1080, 540, 540, 1080, 540, 4320, 540, 4320, 1080, 4320, 1080, 540, 1080, 4320, 1080, 4320, 540, 4320, 4320, 4320, 4320, 540, 1080, 1080, 1080, 4320, 1080, 540, 1080, 540, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 540, 540, 4320, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 4320, 540, 1080, 4320, 540, 4320, 1080, 540, 4320, 4320, 4320, 4320, 1080, 540, 1080, 4320, 4320, 1080, 540, 540, 4320, 1080, 1080, 540, 540, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 540, 1080, 1080, 1080, 1080, 540, 540, 4320, 540, 4320, 540, 540, 540, 1080, 1080, 4320, 540, 540, 4320, 540, 4320, 1080, 540, 4320, 1080, 1080, 540, 4320, 4320, 4320, 540, 1080, 4320, 540, 4320, 1080, 1080, 4320, 4320, 540, 1080, 4320, 540, 1080, 1080, 540, 1080, 540, 1080, 4320, 4320, 1080, 540, 4320, 540, 4320, 1080, 1080, 1080, 1080, 1080, 540, 540, 4320, 540, 4320, 540, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 4320, 4320, 540, 540, 4320, 540, 540, 540, 1080, 540, 1080, 4320, 4320, 1080, 1080, 540, 4320, 1080, 4320, 540, 1080, 1080, 540, 540, 1080, 540, 4320, 4320, 540, 4320, 4320, 540, 1080, 4320, 540, 540, 1080, 1080, 540, 540, 4320, 4320, 4320, 4320, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 4320, 1080, 1080, 1080, 4320, 540, 1080, 1080, 4320, 4320, 540, 4320, 4320, 540, 4320, 540, 540, 1080, 540, 4320, 4320, 4320, 1080, 540, 4320, 4320, 1080, 1080, 4320, 4320, 540, 4320, 4320, 1080, 540, 4320, 1080, 1080, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 4320, 540, 1080, 4320, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 4320, 540, 540, 540, 1080, 540, 1080, 1080, 540, 4320, 1080, 4320, 540, 4320, 540, 1080, 1080, 1080, 1080, 540, 1080, 4320, 4320, 540, 4320, 4320, 540, 4320, 1080, 4320, 1080, 1080, 1080, 540, 1080, 540, 540, 4320, 540, 1080, 540, 540, 1080, 4320, 1080, 4320, 540, 4320, 4320, 1080, 4320, 1080, 540, 4320, 540, 4320, 4320, 540, 540, 540]
Prompts retrieved: 760320 . Total input tokens: 169471057 . Total output tokens: 151920508
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 68.76662740996107,
    "estimated_duration": 3600.1798761425666,
    "input_throughput": 5276.456636481614,
    "output_throughput": 4656.348176125453,
    "total_throughput": 9932.804812607066,
    "itl": 178.5985902358479,
    "ttft": 1816657.758902284,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 748,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.444164103660728,
    "arrivals": 253064,
    "finished_requests": 76892,
    "scheduler_time": 133.6128060704959
}
#Debug simulation 
Total elapsed time: 68.76674658805132. Arrivals time: 0.3455020640976727 Scheduler time: 68.28542842250317 Scheduler overhead time: 0.05172801436856389 Adapter cache time: 0.019229711033403873 Engine time: 0.04624177701771259 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-16-16/adapters_384_slots_96_rate_0.4-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-16-16/adapters_384_slots_96_rate_0.4-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 4320, 1080, 540, 4320, 4320, 540, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 540, 4320, 540, 4320, 1080, 1080, 1080, 540, 540, 1080, 540, 4320, 540, 4320, 1080, 4320, 1080, 540, 1080, 4320, 1080, 4320, 540, 4320, 4320, 4320, 4320, 540, 1080, 1080, 1080, 4320, 1080, 540, 1080, 540, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 540, 540, 4320, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 4320, 540, 1080, 4320, 540, 4320, 1080, 540, 4320, 4320, 4320, 4320, 1080, 540, 1080, 4320, 4320, 1080, 540, 540, 4320, 1080, 1080, 540, 540, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 540, 1080, 1080, 1080, 1080, 540, 540, 4320, 540, 4320, 540, 540, 540, 1080, 1080, 4320, 540, 540, 4320, 540, 4320, 1080, 540, 4320, 1080, 1080, 540, 4320, 4320, 4320, 540, 1080, 4320, 540, 4320, 1080, 1080, 4320, 4320, 540, 1080, 4320, 540, 1080, 1080, 540, 1080, 540, 1080, 4320, 4320, 1080, 540, 4320, 540, 4320, 1080, 1080, 1080, 1080, 1080, 540, 540, 4320, 540, 4320, 540, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 4320, 4320, 540, 540, 4320, 540, 540, 540, 1080, 540, 1080, 4320, 4320, 1080, 1080, 540, 4320, 1080, 4320, 540, 1080, 1080, 540, 540, 1080, 540, 4320, 4320, 540, 4320, 4320, 540, 1080, 4320, 540, 540, 1080, 1080, 540, 540, 4320, 4320, 4320, 4320, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 4320, 1080, 1080, 1080, 4320, 540, 1080, 1080, 4320, 4320, 540, 4320, 4320, 540, 4320, 540, 540, 1080, 540, 4320, 4320, 4320, 1080, 540, 4320, 4320, 1080, 1080, 4320, 4320, 540, 4320, 4320, 1080, 540, 4320, 1080, 1080, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 4320, 540, 1080, 4320, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 4320, 540, 540, 540, 1080, 540, 1080, 1080, 540, 4320, 1080, 4320, 540, 4320, 540, 1080, 1080, 1080, 1080, 540, 1080, 4320, 4320, 540, 4320, 4320, 540, 4320, 1080, 4320, 1080, 1080, 1080, 540, 1080, 540, 540, 4320, 540, 1080, 540, 540, 1080, 4320, 1080, 4320, 540, 4320, 4320, 1080, 4320, 1080, 540, 4320, 540, 4320, 4320, 540, 540, 540]
Prompts retrieved: 760320 . Total input tokens: 169471057 . Total output tokens: 151920508
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 67.22339447773993,
    "estimated_duration": 3600.1766150192893,
    "input_throughput": 5299.303350954569,
    "output_throughput": 4679.112388465348,
    "total_throughput": 9978.415739419917,
    "itl": 181.45398019564627,
    "ttft": 1821952.6349756345,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 680,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1276197190931843,
    "arrivals": 253064,
    "finished_requests": 77149,
    "scheduler_time": 132.87776182348244
}
#Debug simulation 
Total elapsed time: 67.22351482883096. Arrivals time: 0.3535877517424524 Scheduler time: 66.73284379160032 Scheduler overhead time: 0.052342711947858334 Adapter cache time: 0.019019545055925846 Engine time: 0.04696214431896806 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-16-32/adapters_384_slots_96_rate_0.4-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-16-32/adapters_384_slots_96_rate_0.4-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 4320, 1080, 540, 4320, 4320, 540, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 540, 4320, 540, 4320, 1080, 1080, 1080, 540, 540, 1080, 540, 4320, 540, 4320, 1080, 4320, 1080, 540, 1080, 4320, 1080, 4320, 540, 4320, 4320, 4320, 4320, 540, 1080, 1080, 1080, 4320, 1080, 540, 1080, 540, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 540, 540, 4320, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 4320, 540, 1080, 4320, 540, 4320, 1080, 540, 4320, 4320, 4320, 4320, 1080, 540, 1080, 4320, 4320, 1080, 540, 540, 4320, 1080, 1080, 540, 540, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 540, 1080, 1080, 1080, 1080, 540, 540, 4320, 540, 4320, 540, 540, 540, 1080, 1080, 4320, 540, 540, 4320, 540, 4320, 1080, 540, 4320, 1080, 1080, 540, 4320, 4320, 4320, 540, 1080, 4320, 540, 4320, 1080, 1080, 4320, 4320, 540, 1080, 4320, 540, 1080, 1080, 540, 1080, 540, 1080, 4320, 4320, 1080, 540, 4320, 540, 4320, 1080, 1080, 1080, 1080, 1080, 540, 540, 4320, 540, 4320, 540, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 4320, 4320, 540, 540, 4320, 540, 540, 540, 1080, 540, 1080, 4320, 4320, 1080, 1080, 540, 4320, 1080, 4320, 540, 1080, 1080, 540, 540, 1080, 540, 4320, 4320, 540, 4320, 4320, 540, 1080, 4320, 540, 540, 1080, 1080, 540, 540, 4320, 4320, 4320, 4320, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 4320, 1080, 1080, 1080, 4320, 540, 1080, 1080, 4320, 4320, 540, 4320, 4320, 540, 4320, 540, 540, 1080, 540, 4320, 4320, 4320, 1080, 540, 4320, 4320, 1080, 1080, 4320, 4320, 540, 4320, 4320, 1080, 540, 4320, 1080, 1080, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 4320, 540, 1080, 4320, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 4320, 540, 540, 540, 1080, 540, 1080, 1080, 540, 4320, 1080, 4320, 540, 4320, 540, 1080, 1080, 1080, 1080, 540, 1080, 4320, 4320, 540, 4320, 4320, 540, 4320, 1080, 4320, 1080, 1080, 1080, 540, 1080, 540, 540, 4320, 540, 1080, 540, 540, 1080, 4320, 1080, 4320, 540, 4320, 4320, 1080, 4320, 1080, 540, 4320, 540, 4320, 4320, 540, 540, 540]
Prompts retrieved: 760320 . Total input tokens: 169471057 . Total output tokens: 151920508
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 59.81312128296122,
    "estimated_duration": 3600.1827374168356,
    "input_throughput": 5272.131551194199,
    "output_throughput": 4662.548882739249,
    "total_throughput": 9934.680433933449,
    "itl": 179.53116030463633,
    "ttft": 1826080.754225161,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 826,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7318714557774393,
    "arrivals": 253064,
    "finished_requests": 76824,
    "scheduler_time": 133.30735646932175
}
#Debug simulation 
Total elapsed time: 59.813239632640034. Arrivals time: 0.35008469549939036 Scheduler time: 59.32516777794808 Scheduler overhead time: 0.051369667518883944 Adapter cache time: 0.021070231683552265 Engine time: 0.04719429835677147 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_16-16-16/adapters_384_slots_96_rate_0.4-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_16-16-16/adapters_384_slots_96_rate_0.4-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 4320, 1080, 540, 4320, 4320, 540, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 540, 4320, 540, 4320, 1080, 1080, 1080, 540, 540, 1080, 540, 4320, 540, 4320, 1080, 4320, 1080, 540, 1080, 4320, 1080, 4320, 540, 4320, 4320, 4320, 4320, 540, 1080, 1080, 1080, 4320, 1080, 540, 1080, 540, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 540, 540, 4320, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 4320, 540, 1080, 4320, 540, 4320, 1080, 540, 4320, 4320, 4320, 4320, 1080, 540, 1080, 4320, 4320, 1080, 540, 540, 4320, 1080, 1080, 540, 540, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 540, 1080, 1080, 1080, 1080, 540, 540, 4320, 540, 4320, 540, 540, 540, 1080, 1080, 4320, 540, 540, 4320, 540, 4320, 1080, 540, 4320, 1080, 1080, 540, 4320, 4320, 4320, 540, 1080, 4320, 540, 4320, 1080, 1080, 4320, 4320, 540, 1080, 4320, 540, 1080, 1080, 540, 1080, 540, 1080, 4320, 4320, 1080, 540, 4320, 540, 4320, 1080, 1080, 1080, 1080, 1080, 540, 540, 4320, 540, 4320, 540, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 4320, 4320, 540, 540, 4320, 540, 540, 540, 1080, 540, 1080, 4320, 4320, 1080, 1080, 540, 4320, 1080, 4320, 540, 1080, 1080, 540, 540, 1080, 540, 4320, 4320, 540, 4320, 4320, 540, 1080, 4320, 540, 540, 1080, 1080, 540, 540, 4320, 4320, 4320, 4320, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 4320, 1080, 1080, 1080, 4320, 540, 1080, 1080, 4320, 4320, 540, 4320, 4320, 540, 4320, 540, 540, 1080, 540, 4320, 4320, 4320, 1080, 540, 4320, 4320, 1080, 1080, 4320, 4320, 540, 4320, 4320, 1080, 540, 4320, 1080, 1080, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 4320, 540, 1080, 4320, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 4320, 540, 540, 540, 1080, 540, 1080, 1080, 540, 4320, 1080, 4320, 540, 4320, 540, 1080, 1080, 1080, 1080, 540, 1080, 4320, 4320, 540, 4320, 4320, 540, 4320, 1080, 4320, 1080, 1080, 1080, 540, 1080, 540, 540, 4320, 540, 1080, 540, 540, 1080, 4320, 1080, 4320, 540, 4320, 4320, 1080, 4320, 1080, 540, 4320, 540, 4320, 4320, 540, 540, 540]
Prompts retrieved: 760320 . Total input tokens: 169471057 . Total output tokens: 151920508
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 63.87140782782808,
    "estimated_duration": 3600.1583440523195,
    "input_throughput": 5285.544462630854,
    "output_throughput": 4676.308204002523,
    "total_throughput": 9961.852666633376,
    "itl": 181.66822964623145,
    "ttft": 1819493.9803703127,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 713,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1319058602652126,
    "arrivals": 253064,
    "finished_requests": 77047,
    "scheduler_time": 132.78901829460932
}
#Debug simulation 
Total elapsed time: 63.87153322668746. Arrivals time: 0.36034157034009695 Scheduler time: 63.37227979069576 Scheduler overhead time: 0.05270675150677562 Adapter cache time: 0.019871666096150875 Engine time: 0.04817098192870617 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_16-16-32/adapters_384_slots_96_rate_0.4-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_16-16-32/adapters_384_slots_96_rate_0.4-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 4320, 1080, 540, 4320, 4320, 540, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 540, 4320, 540, 4320, 1080, 1080, 1080, 540, 540, 1080, 540, 4320, 540, 4320, 1080, 4320, 1080, 540, 1080, 4320, 1080, 4320, 540, 4320, 4320, 4320, 4320, 540, 1080, 1080, 1080, 4320, 1080, 540, 1080, 540, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 540, 540, 4320, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 4320, 540, 1080, 4320, 540, 4320, 1080, 540, 4320, 4320, 4320, 4320, 1080, 540, 1080, 4320, 4320, 1080, 540, 540, 4320, 1080, 1080, 540, 540, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 540, 1080, 1080, 1080, 1080, 540, 540, 4320, 540, 4320, 540, 540, 540, 1080, 1080, 4320, 540, 540, 4320, 540, 4320, 1080, 540, 4320, 1080, 1080, 540, 4320, 4320, 4320, 540, 1080, 4320, 540, 4320, 1080, 1080, 4320, 4320, 540, 1080, 4320, 540, 1080, 1080, 540, 1080, 540, 1080, 4320, 4320, 1080, 540, 4320, 540, 4320, 1080, 1080, 1080, 1080, 1080, 540, 540, 4320, 540, 4320, 540, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 4320, 4320, 540, 540, 4320, 540, 540, 540, 1080, 540, 1080, 4320, 4320, 1080, 1080, 540, 4320, 1080, 4320, 540, 1080, 1080, 540, 540, 1080, 540, 4320, 4320, 540, 4320, 4320, 540, 1080, 4320, 540, 540, 1080, 1080, 540, 540, 4320, 4320, 4320, 4320, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 4320, 1080, 1080, 1080, 4320, 540, 1080, 1080, 4320, 4320, 540, 4320, 4320, 540, 4320, 540, 540, 1080, 540, 4320, 4320, 4320, 1080, 540, 4320, 4320, 1080, 1080, 4320, 4320, 540, 4320, 4320, 1080, 540, 4320, 1080, 1080, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 540, 4320, 540, 1080, 4320, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 4320, 540, 540, 540, 1080, 540, 1080, 1080, 540, 4320, 1080, 4320, 540, 4320, 540, 1080, 1080, 1080, 1080, 540, 1080, 4320, 4320, 540, 4320, 4320, 540, 4320, 1080, 4320, 1080, 1080, 1080, 540, 1080, 540, 540, 4320, 540, 1080, 540, 540, 1080, 4320, 1080, 4320, 540, 4320, 4320, 1080, 4320, 1080, 540, 4320, 540, 4320, 4320, 540, 540, 540]
Prompts retrieved: 760320 . Total input tokens: 169471057 . Total output tokens: 151920508
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 59.468658480327576,
    "estimated_duration": 3600.021561974231,
    "input_throughput": 5272.015368039024,
    "output_throughput": 4662.458741162436,
    "total_throughput": 9934.474109201461,
    "itl": 179.53335629223508,
    "ttft": 1826035.9454485546,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 825,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7637017496302922,
    "arrivals": 253064,
    "finished_requests": 76820,
    "scheduler_time": 133.30008860371885
}
#Debug simulation 
Total elapsed time: 59.46877771895379. Arrivals time: 0.34752096980810165 Scheduler time: 58.985046822577715 Scheduler overhead time: 0.05048087006434798 Adapter cache time: 0.021060761995613575 Engine time: 0.04640263272449374 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-8/adapters_384_slots_96_rate_0.4-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-8/adapters_384_slots_96_rate_0.4-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 4320, 1080, 270, 4320, 4320, 270, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 270, 4320, 270, 4320, 1080, 1080, 1080, 270, 270, 1080, 270, 4320, 270, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 4320, 270, 4320, 4320, 4320, 4320, 270, 1080, 1080, 1080, 4320, 1080, 270, 1080, 270, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 270, 270, 4320, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 4320, 270, 1080, 4320, 270, 4320, 1080, 270, 4320, 4320, 4320, 4320, 1080, 270, 1080, 4320, 4320, 1080, 270, 270, 4320, 1080, 1080, 270, 270, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 270, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 4320, 270, 270, 270, 1080, 1080, 4320, 270, 270, 4320, 270, 4320, 1080, 270, 4320, 1080, 1080, 270, 4320, 4320, 4320, 270, 1080, 4320, 270, 4320, 1080, 1080, 4320, 4320, 270, 1080, 4320, 270, 1080, 1080, 270, 1080, 270, 1080, 4320, 4320, 1080, 270, 4320, 270, 4320, 1080, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 4320, 270, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 4320, 4320, 270, 270, 4320, 270, 270, 270, 1080, 270, 1080, 4320, 4320, 1080, 1080, 270, 4320, 1080, 4320, 270, 1080, 1080, 270, 270, 1080, 270, 4320, 4320, 270, 4320, 4320, 270, 1080, 4320, 270, 270, 1080, 1080, 270, 270, 4320, 4320, 4320, 4320, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 4320, 1080, 1080, 1080, 4320, 270, 1080, 1080, 4320, 4320, 270, 4320, 4320, 270, 4320, 270, 270, 1080, 270, 4320, 4320, 4320, 1080, 270, 4320, 4320, 1080, 1080, 4320, 4320, 270, 4320, 4320, 1080, 270, 4320, 1080, 1080, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 4320, 270, 1080, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 4320, 270, 270, 270, 1080, 270, 1080, 1080, 270, 4320, 1080, 4320, 270, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 4320, 4320, 270, 4320, 4320, 270, 4320, 1080, 4320, 1080, 1080, 1080, 270, 1080, 270, 270, 4320, 270, 1080, 270, 270, 1080, 4320, 1080, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 725760 . Total input tokens: 161737649 . Total output tokens: 145027066
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 72.60796731617302,
    "estimated_duration": 3600.049568627975,
    "input_throughput": 5309.959109058989,
    "output_throughput": 4682.799688901206,
    "total_throughput": 9992.758797960194,
    "itl": 181.94803597648382,
    "ttft": 1799883.2976706438,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 656,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.00767996001992,
    "arrivals": 241330,
    "finished_requests": 77155,
    "scheduler_time": 132.29146923347406
}
#Debug simulation 
Total elapsed time: 72.60809404635802. Arrivals time: 0.36875369027256966 Scheduler time: 72.0983738610521 Scheduler overhead time: 0.05444616079330444 Adapter cache time: 0.018977935891598463 Engine time: 0.04860913846641779 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-16/adapters_384_slots_96_rate_0.4-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-16/adapters_384_slots_96_rate_0.4-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 4320, 1080, 270, 4320, 4320, 270, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 270, 4320, 270, 4320, 1080, 1080, 1080, 270, 270, 1080, 270, 4320, 270, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 4320, 270, 4320, 4320, 4320, 4320, 270, 1080, 1080, 1080, 4320, 1080, 270, 1080, 270, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 270, 270, 4320, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 4320, 270, 1080, 4320, 270, 4320, 1080, 270, 4320, 4320, 4320, 4320, 1080, 270, 1080, 4320, 4320, 1080, 270, 270, 4320, 1080, 1080, 270, 270, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 270, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 4320, 270, 270, 270, 1080, 1080, 4320, 270, 270, 4320, 270, 4320, 1080, 270, 4320, 1080, 1080, 270, 4320, 4320, 4320, 270, 1080, 4320, 270, 4320, 1080, 1080, 4320, 4320, 270, 1080, 4320, 270, 1080, 1080, 270, 1080, 270, 1080, 4320, 4320, 1080, 270, 4320, 270, 4320, 1080, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 4320, 270, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 4320, 4320, 270, 270, 4320, 270, 270, 270, 1080, 270, 1080, 4320, 4320, 1080, 1080, 270, 4320, 1080, 4320, 270, 1080, 1080, 270, 270, 1080, 270, 4320, 4320, 270, 4320, 4320, 270, 1080, 4320, 270, 270, 1080, 1080, 270, 270, 4320, 4320, 4320, 4320, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 4320, 1080, 1080, 1080, 4320, 270, 1080, 1080, 4320, 4320, 270, 4320, 4320, 270, 4320, 270, 270, 1080, 270, 4320, 4320, 4320, 1080, 270, 4320, 4320, 1080, 1080, 4320, 4320, 270, 4320, 4320, 1080, 270, 4320, 1080, 1080, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 4320, 270, 1080, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 4320, 270, 270, 270, 1080, 270, 1080, 1080, 270, 4320, 1080, 4320, 270, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 4320, 4320, 270, 4320, 4320, 270, 4320, 1080, 4320, 1080, 1080, 1080, 270, 1080, 270, 270, 4320, 270, 1080, 270, 270, 1080, 4320, 1080, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 725760 . Total input tokens: 161737649 . Total output tokens: 145027066
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 74.5461152610369,
    "estimated_duration": 3600.1949079989763,
    "input_throughput": 5298.598683537004,
    "output_throughput": 4680.282993168656,
    "total_throughput": 9978.88167670566,
    "itl": 181.91508530951728,
    "ttft": 1796234.0662525992,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 640,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.089328175666748,
    "arrivals": 241330,
    "finished_requests": 76995,
    "scheduler_time": 132.26516653558363
}
#Debug simulation 
Total elapsed time: 74.54622890707105. Arrivals time: 0.36064336309209466 Scheduler time: 74.04594073677436 Scheduler overhead time: 0.054147785529494286 Adapter cache time: 0.01847501052543521 Engine time: 0.04820255329832435 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-32/adapters_384_slots_96_rate_0.4-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-32/adapters_384_slots_96_rate_0.4-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 4320, 1080, 270, 4320, 4320, 270, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 270, 4320, 270, 4320, 1080, 1080, 1080, 270, 270, 1080, 270, 4320, 270, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 4320, 270, 4320, 4320, 4320, 4320, 270, 1080, 1080, 1080, 4320, 1080, 270, 1080, 270, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 270, 270, 4320, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 4320, 270, 1080, 4320, 270, 4320, 1080, 270, 4320, 4320, 4320, 4320, 1080, 270, 1080, 4320, 4320, 1080, 270, 270, 4320, 1080, 1080, 270, 270, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 270, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 4320, 270, 270, 270, 1080, 1080, 4320, 270, 270, 4320, 270, 4320, 1080, 270, 4320, 1080, 1080, 270, 4320, 4320, 4320, 270, 1080, 4320, 270, 4320, 1080, 1080, 4320, 4320, 270, 1080, 4320, 270, 1080, 1080, 270, 1080, 270, 1080, 4320, 4320, 1080, 270, 4320, 270, 4320, 1080, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 4320, 270, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 4320, 4320, 270, 270, 4320, 270, 270, 270, 1080, 270, 1080, 4320, 4320, 1080, 1080, 270, 4320, 1080, 4320, 270, 1080, 1080, 270, 270, 1080, 270, 4320, 4320, 270, 4320, 4320, 270, 1080, 4320, 270, 270, 1080, 1080, 270, 270, 4320, 4320, 4320, 4320, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 4320, 1080, 1080, 1080, 4320, 270, 1080, 1080, 4320, 4320, 270, 4320, 4320, 270, 4320, 270, 270, 1080, 270, 4320, 4320, 4320, 1080, 270, 4320, 4320, 1080, 1080, 4320, 4320, 270, 4320, 4320, 1080, 270, 4320, 1080, 1080, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 4320, 270, 1080, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 4320, 270, 270, 270, 1080, 270, 1080, 1080, 270, 4320, 1080, 4320, 270, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 4320, 4320, 270, 4320, 4320, 270, 4320, 1080, 4320, 1080, 1080, 1080, 270, 1080, 270, 270, 4320, 270, 1080, 270, 270, 1080, 4320, 1080, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 725760 . Total input tokens: 161737649 . Total output tokens: 145027066
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 71.49953051982448,
    "estimated_duration": 3600.0912186638843,
    "input_throughput": 5294.253629238244,
    "output_throughput": 4670.673318727896,
    "total_throughput": 9964.92694796614,
    "itl": 179.85683345845854,
    "ttft": 1802630.8714920029,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 679,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.221683145798745,
    "arrivals": 241330,
    "finished_requests": 76945,
    "scheduler_time": 132.9017200902053
}
#Debug simulation 
Total elapsed time: 71.49965846678242. Arrivals time: 0.3573337416164577 Scheduler time: 71.00087192095816 Scheduler overhead time: 0.054774502757936716 Adapter cache time: 0.01978257903829217 Engine time: 0.04798950906842947 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-16-16/adapters_384_slots_96_rate_0.4-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-16-16/adapters_384_slots_96_rate_0.4-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 4320, 1080, 270, 4320, 4320, 270, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 270, 4320, 270, 4320, 1080, 1080, 1080, 270, 270, 1080, 270, 4320, 270, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 4320, 270, 4320, 4320, 4320, 4320, 270, 1080, 1080, 1080, 4320, 1080, 270, 1080, 270, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 270, 270, 4320, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 4320, 270, 1080, 4320, 270, 4320, 1080, 270, 4320, 4320, 4320, 4320, 1080, 270, 1080, 4320, 4320, 1080, 270, 270, 4320, 1080, 1080, 270, 270, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 270, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 4320, 270, 270, 270, 1080, 1080, 4320, 270, 270, 4320, 270, 4320, 1080, 270, 4320, 1080, 1080, 270, 4320, 4320, 4320, 270, 1080, 4320, 270, 4320, 1080, 1080, 4320, 4320, 270, 1080, 4320, 270, 1080, 1080, 270, 1080, 270, 1080, 4320, 4320, 1080, 270, 4320, 270, 4320, 1080, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 4320, 270, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 4320, 4320, 270, 270, 4320, 270, 270, 270, 1080, 270, 1080, 4320, 4320, 1080, 1080, 270, 4320, 1080, 4320, 270, 1080, 1080, 270, 270, 1080, 270, 4320, 4320, 270, 4320, 4320, 270, 1080, 4320, 270, 270, 1080, 1080, 270, 270, 4320, 4320, 4320, 4320, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 4320, 1080, 1080, 1080, 4320, 270, 1080, 1080, 4320, 4320, 270, 4320, 4320, 270, 4320, 270, 270, 1080, 270, 4320, 4320, 4320, 1080, 270, 4320, 4320, 1080, 1080, 4320, 4320, 270, 4320, 4320, 1080, 270, 4320, 1080, 1080, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 4320, 270, 1080, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 4320, 270, 270, 270, 1080, 270, 1080, 1080, 270, 4320, 1080, 4320, 270, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 4320, 4320, 270, 4320, 4320, 270, 4320, 1080, 4320, 1080, 1080, 1080, 270, 1080, 270, 270, 4320, 270, 1080, 270, 270, 1080, 4320, 1080, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 725760 . Total input tokens: 161737649 . Total output tokens: 145027066
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 74.79727744590491,
    "estimated_duration": 3600.0638489931694,
    "input_throughput": 5305.603122939568,
    "output_throughput": 4682.196957344015,
    "total_throughput": 9987.800080283583,
    "itl": 182.08300604871596,
    "ttft": 1796805.781130567,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 638,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9934571050200471,
    "arrivals": 241330,
    "finished_requests": 77109,
    "scheduler_time": 132.26369802868763
}
#Debug simulation 
Total elapsed time: 74.79739954695106. Arrivals time: 0.36239736061543226 Scheduler time: 74.29370487527922 Scheduler overhead time: 0.054730054922401905 Adapter cache time: 0.018691231030970812 Engine time: 0.04893064917996526 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-16-32/adapters_384_slots_96_rate_0.4-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-16-32/adapters_384_slots_96_rate_0.4-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 4320, 1080, 270, 4320, 4320, 270, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 270, 4320, 270, 4320, 1080, 1080, 1080, 270, 270, 1080, 270, 4320, 270, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 4320, 270, 4320, 4320, 4320, 4320, 270, 1080, 1080, 1080, 4320, 1080, 270, 1080, 270, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 270, 270, 4320, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 4320, 270, 1080, 4320, 270, 4320, 1080, 270, 4320, 4320, 4320, 4320, 1080, 270, 1080, 4320, 4320, 1080, 270, 270, 4320, 1080, 1080, 270, 270, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 270, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 4320, 270, 270, 270, 1080, 1080, 4320, 270, 270, 4320, 270, 4320, 1080, 270, 4320, 1080, 1080, 270, 4320, 4320, 4320, 270, 1080, 4320, 270, 4320, 1080, 1080, 4320, 4320, 270, 1080, 4320, 270, 1080, 1080, 270, 1080, 270, 1080, 4320, 4320, 1080, 270, 4320, 270, 4320, 1080, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 4320, 270, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 4320, 4320, 270, 270, 4320, 270, 270, 270, 1080, 270, 1080, 4320, 4320, 1080, 1080, 270, 4320, 1080, 4320, 270, 1080, 1080, 270, 270, 1080, 270, 4320, 4320, 270, 4320, 4320, 270, 1080, 4320, 270, 270, 1080, 1080, 270, 270, 4320, 4320, 4320, 4320, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 4320, 1080, 1080, 1080, 4320, 270, 1080, 1080, 4320, 4320, 270, 4320, 4320, 270, 4320, 270, 270, 1080, 270, 4320, 4320, 4320, 1080, 270, 4320, 4320, 1080, 1080, 4320, 4320, 270, 4320, 4320, 1080, 270, 4320, 1080, 1080, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 4320, 270, 1080, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 4320, 270, 270, 270, 1080, 270, 1080, 1080, 270, 4320, 1080, 4320, 270, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 4320, 4320, 270, 4320, 4320, 270, 4320, 1080, 4320, 1080, 1080, 1080, 270, 1080, 270, 270, 4320, 270, 1080, 270, 270, 1080, 4320, 1080, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 725760 . Total input tokens: 161737649 . Total output tokens: 145027066
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 71.77827586606145,
    "estimated_duration": 3600.171986730595,
    "input_throughput": 5297.736349901563,
    "output_throughput": 4671.8895824958345,
    "total_throughput": 9969.625932397397,
    "itl": 179.88564737730556,
    "ttft": 1802748.345370008,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 661,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1889581859111784,
    "arrivals": 241330,
    "finished_requests": 76970,
    "scheduler_time": 132.9050835133592
}
#Debug simulation 
Total elapsed time: 71.77840421721339. Arrivals time: 0.3480670126155019 Scheduler time: 71.29161647288129 Scheduler overhead time: 0.05354547267779708 Adapter cache time: 0.018275505397468805 Engine time: 0.047896206844598055 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_16-16-16/adapters_384_slots_96_rate_0.4-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_16-16-16/adapters_384_slots_96_rate_0.4-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 4320, 1080, 270, 4320, 4320, 270, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 270, 4320, 270, 4320, 1080, 1080, 1080, 270, 270, 1080, 270, 4320, 270, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 4320, 270, 4320, 4320, 4320, 4320, 270, 1080, 1080, 1080, 4320, 1080, 270, 1080, 270, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 270, 270, 4320, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 4320, 270, 1080, 4320, 270, 4320, 1080, 270, 4320, 4320, 4320, 4320, 1080, 270, 1080, 4320, 4320, 1080, 270, 270, 4320, 1080, 1080, 270, 270, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 270, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 4320, 270, 270, 270, 1080, 1080, 4320, 270, 270, 4320, 270, 4320, 1080, 270, 4320, 1080, 1080, 270, 4320, 4320, 4320, 270, 1080, 4320, 270, 4320, 1080, 1080, 4320, 4320, 270, 1080, 4320, 270, 1080, 1080, 270, 1080, 270, 1080, 4320, 4320, 1080, 270, 4320, 270, 4320, 1080, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 4320, 270, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 4320, 4320, 270, 270, 4320, 270, 270, 270, 1080, 270, 1080, 4320, 4320, 1080, 1080, 270, 4320, 1080, 4320, 270, 1080, 1080, 270, 270, 1080, 270, 4320, 4320, 270, 4320, 4320, 270, 1080, 4320, 270, 270, 1080, 1080, 270, 270, 4320, 4320, 4320, 4320, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 4320, 1080, 1080, 1080, 4320, 270, 1080, 1080, 4320, 4320, 270, 4320, 4320, 270, 4320, 270, 270, 1080, 270, 4320, 4320, 4320, 1080, 270, 4320, 4320, 1080, 1080, 4320, 4320, 270, 4320, 4320, 1080, 270, 4320, 1080, 1080, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 4320, 270, 1080, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 4320, 270, 270, 270, 1080, 270, 1080, 1080, 270, 4320, 1080, 4320, 270, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 4320, 4320, 270, 4320, 4320, 270, 4320, 1080, 4320, 1080, 1080, 1080, 270, 1080, 270, 270, 4320, 270, 1080, 270, 270, 1080, 4320, 1080, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 725760 . Total input tokens: 161737649 . Total output tokens: 145027066
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 74.67560661071911,
    "estimated_duration": 3600.139993342038,
    "input_throughput": 5301.558838072291,
    "output_throughput": 4680.252721049999,
    "total_throughput": 9981.81155912229,
    "itl": 182.12280972916992,
    "ttft": 1797473.8576158278,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 652,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9495127922761861,
    "arrivals": 241330,
    "finished_requests": 77053,
    "scheduler_time": 132.2272394276998
}
#Debug simulation 
Total elapsed time: 74.67571975896135. Arrivals time: 0.36109467316418886 Scheduler time: 74.17210758570582 Scheduler overhead time: 0.05564328283071518 Adapter cache time: 0.01869965484365821 Engine time: 0.04915878036990762 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_16-16-32/adapters_384_slots_96_rate_0.4-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_16-16-32/adapters_384_slots_96_rate_0.4-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 4320, 1080, 270, 4320, 4320, 270, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 270, 4320, 270, 4320, 1080, 1080, 1080, 270, 270, 1080, 270, 4320, 270, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 4320, 270, 4320, 4320, 4320, 4320, 270, 1080, 1080, 1080, 4320, 1080, 270, 1080, 270, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 270, 270, 4320, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 4320, 270, 1080, 4320, 270, 4320, 1080, 270, 4320, 4320, 4320, 4320, 1080, 270, 1080, 4320, 4320, 1080, 270, 270, 4320, 1080, 1080, 270, 270, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 270, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 4320, 270, 270, 270, 1080, 1080, 4320, 270, 270, 4320, 270, 4320, 1080, 270, 4320, 1080, 1080, 270, 4320, 4320, 4320, 270, 1080, 4320, 270, 4320, 1080, 1080, 4320, 4320, 270, 1080, 4320, 270, 1080, 1080, 270, 1080, 270, 1080, 4320, 4320, 1080, 270, 4320, 270, 4320, 1080, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 4320, 270, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 4320, 4320, 270, 270, 4320, 270, 270, 270, 1080, 270, 1080, 4320, 4320, 1080, 1080, 270, 4320, 1080, 4320, 270, 1080, 1080, 270, 270, 1080, 270, 4320, 4320, 270, 4320, 4320, 270, 1080, 4320, 270, 270, 1080, 1080, 270, 270, 4320, 4320, 4320, 4320, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 4320, 1080, 1080, 1080, 4320, 270, 1080, 1080, 4320, 4320, 270, 4320, 4320, 270, 4320, 270, 270, 1080, 270, 4320, 4320, 4320, 1080, 270, 4320, 4320, 1080, 1080, 4320, 4320, 270, 4320, 4320, 1080, 270, 4320, 1080, 1080, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 4320, 270, 1080, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 4320, 270, 270, 270, 1080, 270, 1080, 1080, 270, 4320, 1080, 4320, 270, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 4320, 4320, 270, 4320, 4320, 270, 4320, 1080, 4320, 1080, 1080, 1080, 270, 1080, 270, 270, 4320, 270, 1080, 270, 270, 1080, 4320, 1080, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 725760 . Total input tokens: 161737649 . Total output tokens: 145027066
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 71.42923379596323,
    "estimated_duration": 3600.0275206482975,
    "input_throughput": 5294.326193530794,
    "output_throughput": 4670.479018163766,
    "total_throughput": 9964.80521169456,
    "itl": 179.84986256660184,
    "ttft": 1802542.8932913945,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 679,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.279066886268561,
    "arrivals": 241330,
    "finished_requests": 76941,
    "scheduler_time": 132.89933367806944
}
#Debug simulation 
Total elapsed time: 71.42935544019565. Arrivals time: 0.358131037093699 Scheduler time: 70.93019072478637 Scheduler overhead time: 0.05449703987687826 Adapter cache time: 0.019256627187132835 Engine time: 0.04840444354340434 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-8/adapters_384_slots_96_rate_0.4-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-8/adapters_384_slots_96_rate_0.4-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 1080, 135, 4320, 4320, 135, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 135, 4320, 135, 4320, 1080, 1080, 1080, 135, 135, 1080, 135, 4320, 135, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 4320, 135, 4320, 4320, 4320, 4320, 135, 1080, 1080, 1080, 4320, 1080, 135, 1080, 135, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 135, 135, 4320, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 4320, 135, 1080, 4320, 135, 4320, 1080, 135, 4320, 4320, 4320, 4320, 1080, 135, 1080, 4320, 4320, 1080, 135, 135, 4320, 1080, 1080, 135, 135, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 135, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 4320, 135, 135, 135, 1080, 1080, 4320, 135, 135, 4320, 135, 4320, 1080, 135, 4320, 1080, 1080, 135, 4320, 4320, 4320, 135, 1080, 4320, 135, 4320, 1080, 1080, 4320, 4320, 135, 1080, 4320, 135, 1080, 1080, 135, 1080, 135, 1080, 4320, 4320, 1080, 135, 4320, 135, 4320, 1080, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 4320, 135, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 4320, 4320, 135, 135, 4320, 135, 135, 135, 1080, 135, 1080, 4320, 4320, 1080, 1080, 135, 4320, 1080, 4320, 135, 1080, 1080, 135, 135, 1080, 135, 4320, 4320, 135, 4320, 4320, 135, 1080, 4320, 135, 135, 1080, 1080, 135, 135, 4320, 4320, 4320, 4320, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 4320, 1080, 1080, 1080, 4320, 135, 1080, 1080, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 1080, 135, 4320, 4320, 4320, 1080, 135, 4320, 4320, 1080, 1080, 4320, 4320, 135, 4320, 4320, 1080, 135, 4320, 1080, 1080, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 1080, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 4320, 135, 135, 135, 1080, 135, 1080, 1080, 135, 4320, 1080, 4320, 135, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 4320, 4320, 135, 4320, 4320, 135, 4320, 1080, 4320, 1080, 1080, 1080, 135, 1080, 135, 135, 4320, 135, 1080, 135, 135, 1080, 4320, 1080, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 708480 . Total input tokens: 157845104 . Total output tokens: 141621177
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 76.53616002807394,
    "estimated_duration": 3600.125100679366,
    "input_throughput": 5293.539381840856,
    "output_throughput": 4692.027228946126,
    "total_throughput": 9985.566610786982,
    "itl": 182.01794386998307,
    "ttft": 1782338.246024131,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 607,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.85771606056721,
    "arrivals": 235580,
    "finished_requests": 77074,
    "scheduler_time": 132.13885121003193
}
#Debug simulation 
Total elapsed time: 76.53627988090739. Arrivals time: 0.3577225534245372 Scheduler time: 76.03720520762727 Scheduler overhead time: 0.05492196138948202 Adapter cache time: 0.01882596407085657 Engine time: 0.04884271463379264 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-16/adapters_384_slots_96_rate_0.4-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-16/adapters_384_slots_96_rate_0.4-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 1080, 135, 4320, 4320, 135, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 135, 4320, 135, 4320, 1080, 1080, 1080, 135, 135, 1080, 135, 4320, 135, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 4320, 135, 4320, 4320, 4320, 4320, 135, 1080, 1080, 1080, 4320, 1080, 135, 1080, 135, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 135, 135, 4320, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 4320, 135, 1080, 4320, 135, 4320, 1080, 135, 4320, 4320, 4320, 4320, 1080, 135, 1080, 4320, 4320, 1080, 135, 135, 4320, 1080, 1080, 135, 135, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 135, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 4320, 135, 135, 135, 1080, 1080, 4320, 135, 135, 4320, 135, 4320, 1080, 135, 4320, 1080, 1080, 135, 4320, 4320, 4320, 135, 1080, 4320, 135, 4320, 1080, 1080, 4320, 4320, 135, 1080, 4320, 135, 1080, 1080, 135, 1080, 135, 1080, 4320, 4320, 1080, 135, 4320, 135, 4320, 1080, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 4320, 135, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 4320, 4320, 135, 135, 4320, 135, 135, 135, 1080, 135, 1080, 4320, 4320, 1080, 1080, 135, 4320, 1080, 4320, 135, 1080, 1080, 135, 135, 1080, 135, 4320, 4320, 135, 4320, 4320, 135, 1080, 4320, 135, 135, 1080, 1080, 135, 135, 4320, 4320, 4320, 4320, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 4320, 1080, 1080, 1080, 4320, 135, 1080, 1080, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 1080, 135, 4320, 4320, 4320, 1080, 135, 4320, 4320, 1080, 1080, 4320, 4320, 135, 4320, 4320, 1080, 135, 4320, 1080, 1080, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 1080, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 4320, 135, 135, 135, 1080, 135, 1080, 1080, 135, 4320, 1080, 4320, 135, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 4320, 4320, 135, 4320, 4320, 135, 4320, 1080, 4320, 1080, 1080, 1080, 135, 1080, 135, 135, 4320, 135, 1080, 135, 135, 1080, 4320, 1080, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 708480 . Total input tokens: 157845104 . Total output tokens: 141621177
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 75.04531648708507,
    "estimated_duration": 3600.148342100569,
    "input_throughput": 5287.874051571012,
    "output_throughput": 4685.430264842345,
    "total_throughput": 9973.304316413358,
    "itl": 182.43282499654438,
    "ttft": 1783132.9005347828,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 684,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2315138669218926,
    "arrivals": 235580,
    "finished_requests": 76980,
    "scheduler_time": 131.86934261265546
}
#Debug simulation 
Total elapsed time: 75.04543978814036. Arrivals time: 0.36032854998484254 Scheduler time: 74.54389035794884 Scheduler overhead time: 0.054501309990882874 Adapter cache time: 0.019020480569452047 Engine time: 0.04873728891834617 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-32/adapters_384_slots_96_rate_0.4-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-32/adapters_384_slots_96_rate_0.4-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 1080, 135, 4320, 4320, 135, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 135, 4320, 135, 4320, 1080, 1080, 1080, 135, 135, 1080, 135, 4320, 135, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 4320, 135, 4320, 4320, 4320, 4320, 135, 1080, 1080, 1080, 4320, 1080, 135, 1080, 135, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 135, 135, 4320, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 4320, 135, 1080, 4320, 135, 4320, 1080, 135, 4320, 4320, 4320, 4320, 1080, 135, 1080, 4320, 4320, 1080, 135, 135, 4320, 1080, 1080, 135, 135, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 135, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 4320, 135, 135, 135, 1080, 1080, 4320, 135, 135, 4320, 135, 4320, 1080, 135, 4320, 1080, 1080, 135, 4320, 4320, 4320, 135, 1080, 4320, 135, 4320, 1080, 1080, 4320, 4320, 135, 1080, 4320, 135, 1080, 1080, 135, 1080, 135, 1080, 4320, 4320, 1080, 135, 4320, 135, 4320, 1080, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 4320, 135, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 4320, 4320, 135, 135, 4320, 135, 135, 135, 1080, 135, 1080, 4320, 4320, 1080, 1080, 135, 4320, 1080, 4320, 135, 1080, 1080, 135, 135, 1080, 135, 4320, 4320, 135, 4320, 4320, 135, 1080, 4320, 135, 135, 1080, 1080, 135, 135, 4320, 4320, 4320, 4320, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 4320, 1080, 1080, 1080, 4320, 135, 1080, 1080, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 1080, 135, 4320, 4320, 4320, 1080, 135, 4320, 4320, 1080, 1080, 4320, 4320, 135, 4320, 4320, 1080, 135, 4320, 1080, 1080, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 1080, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 4320, 135, 135, 135, 1080, 135, 1080, 1080, 135, 4320, 1080, 4320, 135, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 4320, 4320, 135, 4320, 4320, 135, 4320, 1080, 4320, 1080, 1080, 1080, 135, 1080, 135, 135, 4320, 135, 1080, 135, 135, 1080, 4320, 1080, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 708480 . Total input tokens: 157845104 . Total output tokens: 141621177
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 74.07656795391813,
    "estimated_duration": 3600.0349159190355,
    "input_throughput": 5280.736282844306,
    "output_throughput": 4679.851555189444,
    "total_throughput": 9960.58783803375,
    "itl": 180.43875657807953,
    "ttft": 1785948.8562548736,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 659,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.153056076448417,
    "arrivals": 235580,
    "finished_requests": 76909,
    "scheduler_time": 132.44309737047968
}
#Debug simulation 
Total elapsed time: 74.07667508115992. Arrivals time: 0.32594455080106854 Scheduler time: 73.61093743145466 Scheduler overhead time: 0.054535118862986565 Adapter cache time: 0.018402517307549715 Engine time: 0.0482420171611011 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-16/adapters_384_slots_96_rate_0.4-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-16/adapters_384_slots_96_rate_0.4-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 1080, 135, 4320, 4320, 135, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 135, 4320, 135, 4320, 1080, 1080, 1080, 135, 135, 1080, 135, 4320, 135, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 4320, 135, 4320, 4320, 4320, 4320, 135, 1080, 1080, 1080, 4320, 1080, 135, 1080, 135, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 135, 135, 4320, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 4320, 135, 1080, 4320, 135, 4320, 1080, 135, 4320, 4320, 4320, 4320, 1080, 135, 1080, 4320, 4320, 1080, 135, 135, 4320, 1080, 1080, 135, 135, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 135, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 4320, 135, 135, 135, 1080, 1080, 4320, 135, 135, 4320, 135, 4320, 1080, 135, 4320, 1080, 1080, 135, 4320, 4320, 4320, 135, 1080, 4320, 135, 4320, 1080, 1080, 4320, 4320, 135, 1080, 4320, 135, 1080, 1080, 135, 1080, 135, 1080, 4320, 4320, 1080, 135, 4320, 135, 4320, 1080, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 4320, 135, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 4320, 4320, 135, 135, 4320, 135, 135, 135, 1080, 135, 1080, 4320, 4320, 1080, 1080, 135, 4320, 1080, 4320, 135, 1080, 1080, 135, 135, 1080, 135, 4320, 4320, 135, 4320, 4320, 135, 1080, 4320, 135, 135, 1080, 1080, 135, 135, 4320, 4320, 4320, 4320, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 4320, 1080, 1080, 1080, 4320, 135, 1080, 1080, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 1080, 135, 4320, 4320, 4320, 1080, 135, 4320, 4320, 1080, 1080, 4320, 4320, 135, 4320, 4320, 1080, 135, 4320, 1080, 1080, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 1080, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 4320, 135, 135, 135, 1080, 135, 1080, 1080, 135, 4320, 1080, 4320, 135, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 4320, 4320, 135, 4320, 4320, 135, 4320, 1080, 4320, 1080, 1080, 1080, 135, 1080, 135, 135, 4320, 135, 1080, 135, 135, 1080, 4320, 1080, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 708480 . Total input tokens: 157845104 . Total output tokens: 141621177
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 75.47308086697012,
    "estimated_duration": 3600.180748551326,
    "input_throughput": 5295.13080910477,
    "output_throughput": 4692.3263524470685,
    "total_throughput": 9987.457161551838,
    "itl": 181.9042653478379,
    "ttft": 1783090.3002475586,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 616,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9272674032137604,
    "arrivals": 235580,
    "finished_requests": 77100,
    "scheduler_time": 132.1950855036444
}
#Debug simulation 
Total elapsed time: 75.4731880472973. Arrivals time: 0.3277072608470917 Scheduler time: 75.00507044279948 Scheduler overhead time: 0.05420525884255767 Adapter cache time: 0.018180707935243845 Engine time: 0.04860711423680186 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-32/adapters_384_slots_96_rate_0.4-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-32/adapters_384_slots_96_rate_0.4-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 1080, 135, 4320, 4320, 135, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 135, 4320, 135, 4320, 1080, 1080, 1080, 135, 135, 1080, 135, 4320, 135, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 4320, 135, 4320, 4320, 4320, 4320, 135, 1080, 1080, 1080, 4320, 1080, 135, 1080, 135, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 135, 135, 4320, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 4320, 135, 1080, 4320, 135, 4320, 1080, 135, 4320, 4320, 4320, 4320, 1080, 135, 1080, 4320, 4320, 1080, 135, 135, 4320, 1080, 1080, 135, 135, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 135, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 4320, 135, 135, 135, 1080, 1080, 4320, 135, 135, 4320, 135, 4320, 1080, 135, 4320, 1080, 1080, 135, 4320, 4320, 4320, 135, 1080, 4320, 135, 4320, 1080, 1080, 4320, 4320, 135, 1080, 4320, 135, 1080, 1080, 135, 1080, 135, 1080, 4320, 4320, 1080, 135, 4320, 135, 4320, 1080, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 4320, 135, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 4320, 4320, 135, 135, 4320, 135, 135, 135, 1080, 135, 1080, 4320, 4320, 1080, 1080, 135, 4320, 1080, 4320, 135, 1080, 1080, 135, 135, 1080, 135, 4320, 4320, 135, 4320, 4320, 135, 1080, 4320, 135, 135, 1080, 1080, 135, 135, 4320, 4320, 4320, 4320, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 4320, 1080, 1080, 1080, 4320, 135, 1080, 1080, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 1080, 135, 4320, 4320, 4320, 1080, 135, 4320, 4320, 1080, 1080, 4320, 4320, 135, 4320, 4320, 1080, 135, 4320, 1080, 1080, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 1080, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 4320, 135, 135, 135, 1080, 135, 1080, 1080, 135, 4320, 1080, 4320, 135, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 4320, 4320, 135, 4320, 4320, 135, 4320, 1080, 4320, 1080, 1080, 1080, 135, 1080, 135, 135, 4320, 135, 1080, 135, 135, 1080, 4320, 1080, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 708480 . Total input tokens: 157845104 . Total output tokens: 141621177
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 74.85268972534686,
    "estimated_duration": 3600.0041377850534,
    "input_throughput": 5280.634208297417,
    "output_throughput": 4679.129066324913,
    "total_throughput": 9959.76327462233,
    "itl": 180.41101342936886,
    "ttft": 1785491.8927431304,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 645,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1329338915646074,
    "arrivals": 235580,
    "finished_requests": 76902,
    "scheduler_time": 132.4533701953342
}
#Debug simulation 
Total elapsed time: 74.85280089313164. Arrivals time: 0.33607547357678413 Scheduler time: 74.377601608634 Scheduler overhead time: 0.05367180937901139 Adapter cache time: 0.018462430220097303 Engine time: 0.04849213548004627 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-16/adapters_384_slots_96_rate_0.4-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-16/adapters_384_slots_96_rate_0.4-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 1080, 135, 4320, 4320, 135, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 135, 4320, 135, 4320, 1080, 1080, 1080, 135, 135, 1080, 135, 4320, 135, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 4320, 135, 4320, 4320, 4320, 4320, 135, 1080, 1080, 1080, 4320, 1080, 135, 1080, 135, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 135, 135, 4320, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 4320, 135, 1080, 4320, 135, 4320, 1080, 135, 4320, 4320, 4320, 4320, 1080, 135, 1080, 4320, 4320, 1080, 135, 135, 4320, 1080, 1080, 135, 135, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 135, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 4320, 135, 135, 135, 1080, 1080, 4320, 135, 135, 4320, 135, 4320, 1080, 135, 4320, 1080, 1080, 135, 4320, 4320, 4320, 135, 1080, 4320, 135, 4320, 1080, 1080, 4320, 4320, 135, 1080, 4320, 135, 1080, 1080, 135, 1080, 135, 1080, 4320, 4320, 1080, 135, 4320, 135, 4320, 1080, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 4320, 135, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 4320, 4320, 135, 135, 4320, 135, 135, 135, 1080, 135, 1080, 4320, 4320, 1080, 1080, 135, 4320, 1080, 4320, 135, 1080, 1080, 135, 135, 1080, 135, 4320, 4320, 135, 4320, 4320, 135, 1080, 4320, 135, 135, 1080, 1080, 135, 135, 4320, 4320, 4320, 4320, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 4320, 1080, 1080, 1080, 4320, 135, 1080, 1080, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 1080, 135, 4320, 4320, 4320, 1080, 135, 4320, 4320, 1080, 1080, 4320, 4320, 135, 4320, 4320, 1080, 135, 4320, 1080, 1080, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 1080, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 4320, 135, 135, 135, 1080, 135, 1080, 1080, 135, 4320, 1080, 4320, 135, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 4320, 4320, 135, 4320, 4320, 135, 4320, 1080, 4320, 1080, 1080, 1080, 135, 1080, 135, 135, 4320, 135, 1080, 135, 135, 1080, 4320, 1080, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 708480 . Total input tokens: 157845104 . Total output tokens: 141621177
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 75.40582149289548,
    "estimated_duration": 3600.099888038671,
    "input_throughput": 5285.845557570705,
    "output_throughput": 4686.137475255182,
    "total_throughput": 9971.983032825887,
    "itl": 182.05029369685522,
    "ttft": 1783598.2446214363,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 673,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.01230384846913,
    "arrivals": 235580,
    "finished_requests": 76975,
    "scheduler_time": 132.07833986781188
}
#Debug simulation 
Total elapsed time: 75.40593090001494. Arrivals time: 0.32331952964887023 Scheduler time: 74.94397418852895 Scheduler overhead time: 0.0531386649236083 Adapter cache time: 0.018646107520908117 Engine time: 0.0480916784144938 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-32/adapters_384_slots_96_rate_0.4-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-32/adapters_384_slots_96_rate_0.4-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 1080, 135, 4320, 4320, 135, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 135, 4320, 135, 4320, 1080, 1080, 1080, 135, 135, 1080, 135, 4320, 135, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 4320, 135, 4320, 4320, 4320, 4320, 135, 1080, 1080, 1080, 4320, 1080, 135, 1080, 135, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 135, 135, 4320, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 4320, 135, 1080, 4320, 135, 4320, 1080, 135, 4320, 4320, 4320, 4320, 1080, 135, 1080, 4320, 4320, 1080, 135, 135, 4320, 1080, 1080, 135, 135, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 135, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 4320, 135, 135, 135, 1080, 1080, 4320, 135, 135, 4320, 135, 4320, 1080, 135, 4320, 1080, 1080, 135, 4320, 4320, 4320, 135, 1080, 4320, 135, 4320, 1080, 1080, 4320, 4320, 135, 1080, 4320, 135, 1080, 1080, 135, 1080, 135, 1080, 4320, 4320, 1080, 135, 4320, 135, 4320, 1080, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 4320, 135, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 4320, 4320, 135, 135, 4320, 135, 135, 135, 1080, 135, 1080, 4320, 4320, 1080, 1080, 135, 4320, 1080, 4320, 135, 1080, 1080, 135, 135, 1080, 135, 4320, 4320, 135, 4320, 4320, 135, 1080, 4320, 135, 135, 1080, 1080, 135, 135, 4320, 4320, 4320, 4320, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 4320, 1080, 1080, 1080, 4320, 135, 1080, 1080, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 1080, 135, 4320, 4320, 4320, 1080, 135, 4320, 4320, 1080, 1080, 4320, 4320, 135, 4320, 4320, 1080, 135, 4320, 1080, 1080, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 1080, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 4320, 135, 135, 135, 1080, 135, 1080, 1080, 135, 4320, 1080, 4320, 135, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 4320, 4320, 135, 4320, 4320, 135, 4320, 1080, 4320, 1080, 1080, 1080, 135, 1080, 135, 135, 4320, 135, 1080, 135, 135, 1080, 4320, 1080, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 708480 . Total input tokens: 157845104 . Total output tokens: 141621177
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 74.63768217293546,
    "estimated_duration": 3600.1335552442497,
    "input_throughput": 5279.165816588869,
    "output_throughput": 4679.453065139703,
    "total_throughput": 9958.618881728573,
    "itl": 180.4608084823955,
    "ttft": 1786295.1748519146,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 660,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2115170012414493,
    "arrivals": 235580,
    "finished_requests": 76896,
    "scheduler_time": 132.44192512530253
}
#Debug simulation 
Total elapsed time: 74.63779353676364. Arrivals time: 0.3292803973890841 Scheduler time: 74.17016582842916 Scheduler overhead time: 0.05336394812911749 Adapter cache time: 0.01848582550883293 Engine time: 0.047875845804810524 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-8/adapters_384_slots_96_rate_0.4-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-8/adapters_384_slots_96_rate_0.4-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 1080, 66, 4320, 4320, 66, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 66, 4320, 66, 4320, 1080, 1080, 1080, 66, 66, 1080, 66, 4320, 66, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 4320, 66, 4320, 4320, 4320, 4320, 66, 1080, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 66, 66, 4320, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 4320, 66, 1080, 4320, 66, 4320, 1080, 66, 4320, 4320, 4320, 4320, 1080, 66, 1080, 4320, 4320, 1080, 66, 66, 4320, 1080, 1080, 66, 66, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 66, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 4320, 66, 66, 66, 1080, 1080, 4320, 66, 66, 4320, 66, 4320, 1080, 66, 4320, 1080, 1080, 66, 4320, 4320, 4320, 66, 1080, 4320, 66, 4320, 1080, 1080, 4320, 4320, 66, 1080, 4320, 66, 1080, 1080, 66, 1080, 66, 1080, 4320, 4320, 1080, 66, 4320, 66, 4320, 1080, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 4320, 66, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 4320, 4320, 66, 66, 4320, 66, 66, 66, 1080, 66, 1080, 4320, 4320, 1080, 1080, 66, 4320, 1080, 4320, 66, 1080, 1080, 66, 66, 1080, 66, 4320, 4320, 66, 4320, 4320, 66, 1080, 4320, 66, 66, 1080, 1080, 66, 66, 4320, 4320, 4320, 4320, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 4320, 1080, 1080, 1080, 4320, 66, 1080, 1080, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 1080, 66, 4320, 4320, 4320, 1080, 66, 4320, 4320, 1080, 1080, 4320, 4320, 66, 4320, 4320, 1080, 66, 4320, 1080, 1080, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 1080, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 4320, 66, 66, 66, 1080, 66, 1080, 1080, 66, 4320, 1080, 4320, 66, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 4320, 4320, 66, 4320, 4320, 66, 4320, 1080, 4320, 1080, 1080, 1080, 66, 1080, 66, 66, 4320, 66, 1080, 66, 66, 1080, 4320, 1080, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 699648 . Total input tokens: 155898747 . Total output tokens: 139865162
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 76.83264062320814,
    "estimated_duration": 3600.095577633304,
    "input_throughput": 5285.198570341418,
    "output_throughput": 4677.167768715028,
    "total_throughput": 9962.366339056447,
    "itl": 181.60539941849456,
    "ttft": 1769931.1490326668,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 582,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7812038669688885,
    "arrivals": 232701,
    "finished_requests": 77280,
    "scheduler_time": 131.93168189628202
}
#Debug simulation 
Total elapsed time: 76.83275785623118. Arrivals time: 0.32707071397453547 Scheduler time: 76.36799717508256 Scheduler overhead time: 0.05380541132763028 Adapter cache time: 0.01729159103706479 Engine time: 0.048020335379987955 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-16/adapters_384_slots_96_rate_0.4-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-16/adapters_384_slots_96_rate_0.4-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 1080, 66, 4320, 4320, 66, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 66, 4320, 66, 4320, 1080, 1080, 1080, 66, 66, 1080, 66, 4320, 66, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 4320, 66, 4320, 4320, 4320, 4320, 66, 1080, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 66, 66, 4320, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 4320, 66, 1080, 4320, 66, 4320, 1080, 66, 4320, 4320, 4320, 4320, 1080, 66, 1080, 4320, 4320, 1080, 66, 66, 4320, 1080, 1080, 66, 66, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 66, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 4320, 66, 66, 66, 1080, 1080, 4320, 66, 66, 4320, 66, 4320, 1080, 66, 4320, 1080, 1080, 66, 4320, 4320, 4320, 66, 1080, 4320, 66, 4320, 1080, 1080, 4320, 4320, 66, 1080, 4320, 66, 1080, 1080, 66, 1080, 66, 1080, 4320, 4320, 1080, 66, 4320, 66, 4320, 1080, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 4320, 66, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 4320, 4320, 66, 66, 4320, 66, 66, 66, 1080, 66, 1080, 4320, 4320, 1080, 1080, 66, 4320, 1080, 4320, 66, 1080, 1080, 66, 66, 1080, 66, 4320, 4320, 66, 4320, 4320, 66, 1080, 4320, 66, 66, 1080, 1080, 66, 66, 4320, 4320, 4320, 4320, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 4320, 1080, 1080, 1080, 4320, 66, 1080, 1080, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 1080, 66, 4320, 4320, 4320, 1080, 66, 4320, 4320, 1080, 1080, 4320, 4320, 66, 4320, 4320, 1080, 66, 4320, 1080, 1080, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 1080, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 4320, 66, 66, 66, 1080, 66, 1080, 1080, 66, 4320, 1080, 4320, 66, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 4320, 4320, 66, 4320, 4320, 66, 4320, 1080, 4320, 1080, 1080, 1080, 66, 1080, 66, 66, 4320, 66, 1080, 66, 66, 1080, 4320, 1080, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 699648 . Total input tokens: 155898747 . Total output tokens: 139865162
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 77.63903893902898,
    "estimated_duration": 3600.0220119394103,
    "input_throughput": 5289.524324253074,
    "output_throughput": 4678.682503645614,
    "total_throughput": 9968.206827898688,
    "itl": 181.6694582409598,
    "ttft": 1770166.0283645713,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 590,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9279763966868684,
    "arrivals": 232701,
    "finished_requests": 77307,
    "scheduler_time": 131.91436518771772
}
#Debug simulation 
Total elapsed time: 77.63914973381907. Arrivals time: 0.3383184429258108 Scheduler time: 77.16034705098718 Scheduler overhead time: 0.05456685833632946 Adapter cache time: 0.017915378790348768 Engine time: 0.048966989386826754 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-32/adapters_384_slots_96_rate_0.4-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-32/adapters_384_slots_96_rate_0.4-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 1080, 66, 4320, 4320, 66, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 66, 4320, 66, 4320, 1080, 1080, 1080, 66, 66, 1080, 66, 4320, 66, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 4320, 66, 4320, 4320, 4320, 4320, 66, 1080, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 66, 66, 4320, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 4320, 66, 1080, 4320, 66, 4320, 1080, 66, 4320, 4320, 4320, 4320, 1080, 66, 1080, 4320, 4320, 1080, 66, 66, 4320, 1080, 1080, 66, 66, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 66, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 4320, 66, 66, 66, 1080, 1080, 4320, 66, 66, 4320, 66, 4320, 1080, 66, 4320, 1080, 1080, 66, 4320, 4320, 4320, 66, 1080, 4320, 66, 4320, 1080, 1080, 4320, 4320, 66, 1080, 4320, 66, 1080, 1080, 66, 1080, 66, 1080, 4320, 4320, 1080, 66, 4320, 66, 4320, 1080, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 4320, 66, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 4320, 4320, 66, 66, 4320, 66, 66, 66, 1080, 66, 1080, 4320, 4320, 1080, 1080, 66, 4320, 1080, 4320, 66, 1080, 1080, 66, 66, 1080, 66, 4320, 4320, 66, 4320, 4320, 66, 1080, 4320, 66, 66, 1080, 1080, 66, 66, 4320, 4320, 4320, 4320, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 4320, 1080, 1080, 1080, 4320, 66, 1080, 1080, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 1080, 66, 4320, 4320, 4320, 1080, 66, 4320, 4320, 1080, 1080, 4320, 4320, 66, 4320, 4320, 1080, 66, 4320, 1080, 1080, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 1080, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 4320, 66, 66, 66, 1080, 66, 1080, 1080, 66, 4320, 1080, 4320, 66, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 4320, 4320, 66, 4320, 4320, 66, 4320, 1080, 4320, 1080, 1080, 1080, 66, 1080, 66, 66, 4320, 66, 1080, 66, 66, 1080, 4320, 1080, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 699648 . Total input tokens: 155898747 . Total output tokens: 139865162
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 75.77148371282965,
    "estimated_duration": 3600.006357663017,
    "input_throughput": 5274.980684291775,
    "output_throughput": 4670.267585559026,
    "total_throughput": 9945.248269850801,
    "itl": 180.0700846767634,
    "ttft": 1772189.6810361522,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 611,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.000222221817834,
    "arrivals": 232701,
    "finished_requests": 77092,
    "scheduler_time": 132.31259945966826
}
#Debug simulation 
Total elapsed time: 75.77159321820363. Arrivals time: 0.32240294804796576 Scheduler time: 75.31067459797487 Scheduler overhead time: 0.05421570735052228 Adapter cache time: 0.01756155677139759 Engine time: 0.04807864874601364 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-16/adapters_384_slots_96_rate_0.4-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-16/adapters_384_slots_96_rate_0.4-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 1080, 66, 4320, 4320, 66, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 66, 4320, 66, 4320, 1080, 1080, 1080, 66, 66, 1080, 66, 4320, 66, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 4320, 66, 4320, 4320, 4320, 4320, 66, 1080, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 66, 66, 4320, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 4320, 66, 1080, 4320, 66, 4320, 1080, 66, 4320, 4320, 4320, 4320, 1080, 66, 1080, 4320, 4320, 1080, 66, 66, 4320, 1080, 1080, 66, 66, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 66, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 4320, 66, 66, 66, 1080, 1080, 4320, 66, 66, 4320, 66, 4320, 1080, 66, 4320, 1080, 1080, 66, 4320, 4320, 4320, 66, 1080, 4320, 66, 4320, 1080, 1080, 4320, 4320, 66, 1080, 4320, 66, 1080, 1080, 66, 1080, 66, 1080, 4320, 4320, 1080, 66, 4320, 66, 4320, 1080, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 4320, 66, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 4320, 4320, 66, 66, 4320, 66, 66, 66, 1080, 66, 1080, 4320, 4320, 1080, 1080, 66, 4320, 1080, 4320, 66, 1080, 1080, 66, 66, 1080, 66, 4320, 4320, 66, 4320, 4320, 66, 1080, 4320, 66, 66, 1080, 1080, 66, 66, 4320, 4320, 4320, 4320, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 4320, 1080, 1080, 1080, 4320, 66, 1080, 1080, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 1080, 66, 4320, 4320, 4320, 1080, 66, 4320, 4320, 1080, 1080, 4320, 4320, 66, 4320, 4320, 1080, 66, 4320, 1080, 1080, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 1080, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 4320, 66, 66, 66, 1080, 66, 1080, 1080, 66, 4320, 1080, 4320, 66, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 4320, 4320, 66, 4320, 4320, 66, 4320, 1080, 4320, 1080, 1080, 1080, 66, 1080, 66, 66, 4320, 66, 1080, 66, 66, 1080, 4320, 1080, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 699648 . Total input tokens: 155898747 . Total output tokens: 139865162
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 77.59870341420174,
    "estimated_duration": 3600.0255184731027,
    "input_throughput": 5283.9003230365915,
    "output_throughput": 4677.437955257042,
    "total_throughput": 9961.338278293633,
    "itl": 181.4408922278675,
    "ttft": 1769540.1840351883,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 594,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8586261294968305,
    "arrivals": 232701,
    "finished_requests": 77228,
    "scheduler_time": 131.99790694443115
}
#Debug simulation 
Total elapsed time: 77.5988117591478. Arrivals time: 0.32775436295196414 Scheduler time: 77.13007262768224 Scheduler overhead time: 0.05462538683786988 Adapter cache time: 0.017718293238431215 Engine time: 0.04924660827964544 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-32/adapters_384_slots_96_rate_0.4-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-32/adapters_384_slots_96_rate_0.4-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 1080, 66, 4320, 4320, 66, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 66, 4320, 66, 4320, 1080, 1080, 1080, 66, 66, 1080, 66, 4320, 66, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 4320, 66, 4320, 4320, 4320, 4320, 66, 1080, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 66, 66, 4320, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 4320, 66, 1080, 4320, 66, 4320, 1080, 66, 4320, 4320, 4320, 4320, 1080, 66, 1080, 4320, 4320, 1080, 66, 66, 4320, 1080, 1080, 66, 66, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 66, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 4320, 66, 66, 66, 1080, 1080, 4320, 66, 66, 4320, 66, 4320, 1080, 66, 4320, 1080, 1080, 66, 4320, 4320, 4320, 66, 1080, 4320, 66, 4320, 1080, 1080, 4320, 4320, 66, 1080, 4320, 66, 1080, 1080, 66, 1080, 66, 1080, 4320, 4320, 1080, 66, 4320, 66, 4320, 1080, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 4320, 66, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 4320, 4320, 66, 66, 4320, 66, 66, 66, 1080, 66, 1080, 4320, 4320, 1080, 1080, 66, 4320, 1080, 4320, 66, 1080, 1080, 66, 66, 1080, 66, 4320, 4320, 66, 4320, 4320, 66, 1080, 4320, 66, 66, 1080, 1080, 66, 66, 4320, 4320, 4320, 4320, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 4320, 1080, 1080, 1080, 4320, 66, 1080, 1080, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 1080, 66, 4320, 4320, 4320, 1080, 66, 4320, 4320, 1080, 1080, 4320, 4320, 66, 4320, 4320, 1080, 66, 4320, 1080, 1080, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 1080, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 4320, 66, 66, 66, 1080, 66, 1080, 1080, 66, 4320, 1080, 4320, 66, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 4320, 4320, 66, 4320, 4320, 66, 4320, 1080, 4320, 1080, 1080, 1080, 66, 1080, 66, 66, 4320, 66, 1080, 66, 66, 1080, 4320, 1080, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 699648 . Total input tokens: 155898747 . Total output tokens: 139865162
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 76.36712512280792,
    "estimated_duration": 3600.019592311088,
    "input_throughput": 5269.000491139793,
    "output_throughput": 4669.28125499697,
    "total_throughput": 9938.281746136763,
    "itl": 179.73524753309275,
    "ttft": 1773488.7860851693,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 578,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9169286571443116,
    "arrivals": 232701,
    "finished_requests": 77057,
    "scheduler_time": 132.50834810638787
}
#Debug simulation 
Total elapsed time: 76.36723826173693. Arrivals time: 0.32467781100422144 Scheduler time: 75.90240760333836 Scheduler overhead time: 0.054698371794074774 Adapter cache time: 0.017412303481251 Engine time: 0.048714178148657084 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-16/adapters_384_slots_96_rate_0.4-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-16/adapters_384_slots_96_rate_0.4-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 1080, 66, 4320, 4320, 66, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 66, 4320, 66, 4320, 1080, 1080, 1080, 66, 66, 1080, 66, 4320, 66, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 4320, 66, 4320, 4320, 4320, 4320, 66, 1080, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 66, 66, 4320, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 4320, 66, 1080, 4320, 66, 4320, 1080, 66, 4320, 4320, 4320, 4320, 1080, 66, 1080, 4320, 4320, 1080, 66, 66, 4320, 1080, 1080, 66, 66, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 66, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 4320, 66, 66, 66, 1080, 1080, 4320, 66, 66, 4320, 66, 4320, 1080, 66, 4320, 1080, 1080, 66, 4320, 4320, 4320, 66, 1080, 4320, 66, 4320, 1080, 1080, 4320, 4320, 66, 1080, 4320, 66, 1080, 1080, 66, 1080, 66, 1080, 4320, 4320, 1080, 66, 4320, 66, 4320, 1080, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 4320, 66, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 4320, 4320, 66, 66, 4320, 66, 66, 66, 1080, 66, 1080, 4320, 4320, 1080, 1080, 66, 4320, 1080, 4320, 66, 1080, 1080, 66, 66, 1080, 66, 4320, 4320, 66, 4320, 4320, 66, 1080, 4320, 66, 66, 1080, 1080, 66, 66, 4320, 4320, 4320, 4320, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 4320, 1080, 1080, 1080, 4320, 66, 1080, 1080, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 1080, 66, 4320, 4320, 4320, 1080, 66, 4320, 4320, 1080, 1080, 4320, 4320, 66, 4320, 4320, 1080, 66, 4320, 1080, 1080, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 1080, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 4320, 66, 66, 66, 1080, 66, 1080, 1080, 66, 4320, 1080, 4320, 66, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 4320, 4320, 66, 4320, 4320, 66, 4320, 1080, 4320, 1080, 1080, 1080, 66, 1080, 66, 66, 4320, 66, 1080, 66, 66, 1080, 4320, 1080, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 699648 . Total input tokens: 155898747 . Total output tokens: 139865162
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 76.9176680711098,
    "estimated_duration": 3600.0843087136113,
    "input_throughput": 5289.910281796951,
    "output_throughput": 4678.758483303049,
    "total_throughput": 9968.6687651,
    "itl": 181.6639425645021,
    "ttft": 1770125.1845560889,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 590,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7641296739922578,
    "arrivals": 232701,
    "finished_requests": 77311,
    "scheduler_time": 131.92135849640843
}
#Debug simulation 
Total elapsed time: 76.91777807381004. Arrivals time: 0.3286339840851724 Scheduler time: 76.44791304226965 Scheduler overhead time: 0.05455042980611324 Adapter cache time: 0.017801492009311914 Engine time: 0.04945359518751502 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-32/adapters_384_slots_96_rate_0.4-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-32/adapters_384_slots_96_rate_0.4-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 1080, 66, 4320, 4320, 66, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 66, 4320, 66, 4320, 1080, 1080, 1080, 66, 66, 1080, 66, 4320, 66, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 4320, 66, 4320, 4320, 4320, 4320, 66, 1080, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 66, 66, 4320, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 4320, 66, 1080, 4320, 66, 4320, 1080, 66, 4320, 4320, 4320, 4320, 1080, 66, 1080, 4320, 4320, 1080, 66, 66, 4320, 1080, 1080, 66, 66, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 66, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 4320, 66, 66, 66, 1080, 1080, 4320, 66, 66, 4320, 66, 4320, 1080, 66, 4320, 1080, 1080, 66, 4320, 4320, 4320, 66, 1080, 4320, 66, 4320, 1080, 1080, 4320, 4320, 66, 1080, 4320, 66, 1080, 1080, 66, 1080, 66, 1080, 4320, 4320, 1080, 66, 4320, 66, 4320, 1080, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 4320, 66, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 4320, 4320, 66, 66, 4320, 66, 66, 66, 1080, 66, 1080, 4320, 4320, 1080, 1080, 66, 4320, 1080, 4320, 66, 1080, 1080, 66, 66, 1080, 66, 4320, 4320, 66, 4320, 4320, 66, 1080, 4320, 66, 66, 1080, 1080, 66, 66, 4320, 4320, 4320, 4320, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 4320, 1080, 1080, 1080, 4320, 66, 1080, 1080, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 1080, 66, 4320, 4320, 4320, 1080, 66, 4320, 4320, 1080, 1080, 4320, 4320, 66, 4320, 4320, 1080, 66, 4320, 1080, 1080, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 1080, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 4320, 66, 66, 66, 1080, 66, 1080, 1080, 66, 4320, 1080, 4320, 66, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 4320, 4320, 66, 4320, 4320, 66, 4320, 1080, 4320, 1080, 1080, 1080, 66, 1080, 66, 66, 4320, 66, 1080, 66, 66, 1080, 4320, 1080, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 699648 . Total input tokens: 155898747 . Total output tokens: 139865162
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 75.9732846012339,
    "estimated_duration": 3600.0438876133917,
    "input_throughput": 5268.964932695572,
    "output_throughput": 4669.2497438256705,
    "total_throughput": 9938.214676521242,
    "itl": 179.7354093505182,
    "ttft": 1773496.9849250133,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 577,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9380698791518765,
    "arrivals": 232701,
    "finished_requests": 77057,
    "scheduler_time": 132.50864577066858
}
#Debug simulation 
Total elapsed time: 75.97339257691056. Arrivals time: 0.32263599522411823 Scheduler time: 75.50949280848727 Scheduler overhead time: 0.054984166752547026 Adapter cache time: 0.01765316491946578 Engine time: 0.04951808648183942 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-8/adapters_384_slots_96_rate_0.4-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-8/adapters_384_slots_96_rate_0.4-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 1080, 33, 4320, 4320, 33, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 33, 4320, 33, 4320, 1080, 1080, 1080, 33, 33, 1080, 33, 4320, 33, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 4320, 33, 4320, 4320, 4320, 4320, 33, 1080, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 33, 33, 4320, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 4320, 33, 1080, 4320, 33, 4320, 1080, 33, 4320, 4320, 4320, 4320, 1080, 33, 1080, 4320, 4320, 1080, 33, 33, 4320, 1080, 1080, 33, 33, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 33, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 4320, 33, 33, 33, 1080, 1080, 4320, 33, 33, 4320, 33, 4320, 1080, 33, 4320, 1080, 1080, 33, 4320, 4320, 4320, 33, 1080, 4320, 33, 4320, 1080, 1080, 4320, 4320, 33, 1080, 4320, 33, 1080, 1080, 33, 1080, 33, 1080, 4320, 4320, 1080, 33, 4320, 33, 4320, 1080, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 4320, 33, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 4320, 4320, 33, 33, 4320, 33, 33, 33, 1080, 33, 1080, 4320, 4320, 1080, 1080, 33, 4320, 1080, 4320, 33, 1080, 1080, 33, 33, 1080, 33, 4320, 4320, 33, 4320, 4320, 33, 1080, 4320, 33, 33, 1080, 1080, 33, 33, 4320, 4320, 4320, 4320, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 4320, 1080, 1080, 1080, 4320, 33, 1080, 1080, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 1080, 33, 4320, 4320, 4320, 1080, 33, 4320, 4320, 1080, 1080, 4320, 4320, 33, 4320, 4320, 1080, 33, 4320, 1080, 1080, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 1080, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 4320, 33, 33, 33, 1080, 33, 1080, 1080, 33, 4320, 1080, 4320, 33, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 4320, 4320, 33, 4320, 4320, 33, 4320, 1080, 4320, 1080, 1080, 1080, 33, 1080, 33, 33, 4320, 33, 1080, 33, 33, 1080, 4320, 1080, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 695424 . Total input tokens: 154965070 . Total output tokens: 139036309
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 66.21534929005429,
    "estimated_duration": 3600.043438271827,
    "input_throughput": 5253.600220190435,
    "output_throughput": 4693.1519826634585,
    "total_throughput": 9946.752202853893,
    "itl": 182.92447204914993,
    "ttft": 1776195.4899317154,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 584,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7873248424567543,
    "arrivals": 231176,
    "finished_requests": 77125,
    "scheduler_time": 131.49353794274134
}
#Debug simulation 
Total elapsed time: 66.21545718237758. Arrivals time: 0.31874343985691667 Scheduler time: 65.76154188252985 Scheduler overhead time: 0.0527398306876421 Adapter cache time: 0.016309103462845087 Engine time: 0.04787946818396449 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-16/adapters_384_slots_96_rate_0.4-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-16/adapters_384_slots_96_rate_0.4-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 1080, 33, 4320, 4320, 33, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 33, 4320, 33, 4320, 1080, 1080, 1080, 33, 33, 1080, 33, 4320, 33, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 4320, 33, 4320, 4320, 4320, 4320, 33, 1080, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 33, 33, 4320, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 4320, 33, 1080, 4320, 33, 4320, 1080, 33, 4320, 4320, 4320, 4320, 1080, 33, 1080, 4320, 4320, 1080, 33, 33, 4320, 1080, 1080, 33, 33, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 33, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 4320, 33, 33, 33, 1080, 1080, 4320, 33, 33, 4320, 33, 4320, 1080, 33, 4320, 1080, 1080, 33, 4320, 4320, 4320, 33, 1080, 4320, 33, 4320, 1080, 1080, 4320, 4320, 33, 1080, 4320, 33, 1080, 1080, 33, 1080, 33, 1080, 4320, 4320, 1080, 33, 4320, 33, 4320, 1080, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 4320, 33, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 4320, 4320, 33, 33, 4320, 33, 33, 33, 1080, 33, 1080, 4320, 4320, 1080, 1080, 33, 4320, 1080, 4320, 33, 1080, 1080, 33, 33, 1080, 33, 4320, 4320, 33, 4320, 4320, 33, 1080, 4320, 33, 33, 1080, 1080, 33, 33, 4320, 4320, 4320, 4320, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 4320, 1080, 1080, 1080, 4320, 33, 1080, 1080, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 1080, 33, 4320, 4320, 4320, 1080, 33, 4320, 4320, 1080, 1080, 4320, 4320, 33, 4320, 4320, 1080, 33, 4320, 1080, 1080, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 1080, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 4320, 33, 33, 33, 1080, 33, 1080, 1080, 33, 4320, 1080, 4320, 33, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 4320, 4320, 33, 4320, 4320, 33, 4320, 1080, 4320, 1080, 1080, 1080, 33, 1080, 33, 33, 4320, 33, 1080, 33, 33, 1080, 4320, 1080, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 695424 . Total input tokens: 154965070 . Total output tokens: 139036309
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 76.32265551574528,
    "estimated_duration": 3600.0724112111684,
    "input_throughput": 5255.009577331057,
    "output_throughput": 4689.695948176773,
    "total_throughput": 9944.705525507828,
    "itl": 181.6102752007604,
    "ttft": 1773521.2629416164,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 576,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8812125487369542,
    "arrivals": 231176,
    "finished_requests": 77155,
    "scheduler_time": 132.13321571093576
}
#Debug simulation 
Total elapsed time: 76.3227662248537. Arrivals time: 0.3331809458322823 Scheduler time: 75.84865036141127 Scheduler overhead time: 0.05496482132002711 Adapter cache time: 0.0173307447694242 Engine time: 0.04942201543599367 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-32/adapters_384_slots_96_rate_0.4-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-32/adapters_384_slots_96_rate_0.4-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 1080, 33, 4320, 4320, 33, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 33, 4320, 33, 4320, 1080, 1080, 1080, 33, 33, 1080, 33, 4320, 33, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 4320, 33, 4320, 4320, 4320, 4320, 33, 1080, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 33, 33, 4320, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 4320, 33, 1080, 4320, 33, 4320, 1080, 33, 4320, 4320, 4320, 4320, 1080, 33, 1080, 4320, 4320, 1080, 33, 33, 4320, 1080, 1080, 33, 33, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 33, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 4320, 33, 33, 33, 1080, 1080, 4320, 33, 33, 4320, 33, 4320, 1080, 33, 4320, 1080, 1080, 33, 4320, 4320, 4320, 33, 1080, 4320, 33, 4320, 1080, 1080, 4320, 4320, 33, 1080, 4320, 33, 1080, 1080, 33, 1080, 33, 1080, 4320, 4320, 1080, 33, 4320, 33, 4320, 1080, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 4320, 33, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 4320, 4320, 33, 33, 4320, 33, 33, 33, 1080, 33, 1080, 4320, 4320, 1080, 1080, 33, 4320, 1080, 4320, 33, 1080, 1080, 33, 33, 1080, 33, 4320, 4320, 33, 4320, 4320, 33, 1080, 4320, 33, 33, 1080, 1080, 33, 33, 4320, 4320, 4320, 4320, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 4320, 1080, 1080, 1080, 4320, 33, 1080, 1080, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 1080, 33, 4320, 4320, 4320, 1080, 33, 4320, 4320, 1080, 1080, 4320, 4320, 33, 4320, 4320, 1080, 33, 4320, 1080, 1080, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 1080, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 4320, 33, 33, 33, 1080, 33, 1080, 1080, 33, 4320, 1080, 4320, 33, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 4320, 4320, 33, 4320, 4320, 33, 4320, 1080, 4320, 1080, 1080, 1080, 33, 1080, 33, 33, 4320, 33, 1080, 33, 33, 1080, 4320, 1080, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 695424 . Total input tokens: 154965070 . Total output tokens: 139036309
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 74.97374678496271,
    "estimated_duration": 3600.1473984906684,
    "input_throughput": 5233.404612238639,
    "output_throughput": 4672.131759675117,
    "total_throughput": 9905.536371913755,
    "itl": 179.71472365054305,
    "ttft": 1774634.7130485175,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 588,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.923139090910566,
    "arrivals": 231176,
    "finished_requests": 76840,
    "scheduler_time": 132.56442537988994
}
#Debug simulation 
Total elapsed time: 74.9738642689772. Arrivals time: 0.32724693790078163 Scheduler time: 74.50582820503041 Scheduler overhead time: 0.05552016803994775 Adapter cache time: 0.01729469746351242 Engine time: 0.04873816296458244 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-16/adapters_384_slots_96_rate_0.4-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-16/adapters_384_slots_96_rate_0.4-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 1080, 33, 4320, 4320, 33, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 33, 4320, 33, 4320, 1080, 1080, 1080, 33, 33, 1080, 33, 4320, 33, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 4320, 33, 4320, 4320, 4320, 4320, 33, 1080, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 33, 33, 4320, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 4320, 33, 1080, 4320, 33, 4320, 1080, 33, 4320, 4320, 4320, 4320, 1080, 33, 1080, 4320, 4320, 1080, 33, 33, 4320, 1080, 1080, 33, 33, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 33, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 4320, 33, 33, 33, 1080, 1080, 4320, 33, 33, 4320, 33, 4320, 1080, 33, 4320, 1080, 1080, 33, 4320, 4320, 4320, 33, 1080, 4320, 33, 4320, 1080, 1080, 4320, 4320, 33, 1080, 4320, 33, 1080, 1080, 33, 1080, 33, 1080, 4320, 4320, 1080, 33, 4320, 33, 4320, 1080, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 4320, 33, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 4320, 4320, 33, 33, 4320, 33, 33, 33, 1080, 33, 1080, 4320, 4320, 1080, 1080, 33, 4320, 1080, 4320, 33, 1080, 1080, 33, 33, 1080, 33, 4320, 4320, 33, 4320, 4320, 33, 1080, 4320, 33, 33, 1080, 1080, 33, 33, 4320, 4320, 4320, 4320, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 4320, 1080, 1080, 1080, 4320, 33, 1080, 1080, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 1080, 33, 4320, 4320, 4320, 1080, 33, 4320, 4320, 1080, 1080, 4320, 4320, 33, 4320, 4320, 1080, 33, 4320, 1080, 1080, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 1080, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 4320, 33, 33, 33, 1080, 33, 1080, 1080, 33, 4320, 1080, 4320, 33, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 4320, 4320, 33, 4320, 4320, 33, 4320, 1080, 4320, 1080, 1080, 1080, 33, 1080, 33, 33, 4320, 33, 1080, 33, 33, 1080, 4320, 1080, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 695424 . Total input tokens: 154965070 . Total output tokens: 139036309
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 76.21073522791266,
    "estimated_duration": 3600.049278379794,
    "input_throughput": 5254.923623854966,
    "output_throughput": 4694.211854679275,
    "total_throughput": 9949.135478534241,
    "itl": 181.2542472225126,
    "ttft": 1773659.0917194874,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 599,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8727591903344607,
    "arrivals": 231176,
    "finished_requests": 77179,
    "scheduler_time": 132.4282752339028
}
#Debug simulation 
Total elapsed time: 76.21084940200672. Arrivals time: 0.3308658367022872 Scheduler time: 75.74037794396281 Scheduler overhead time: 0.05411405162885785 Adapter cache time: 0.01703893393278122 Engine time: 0.04939214512705803 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-32/adapters_384_slots_96_rate_0.4-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-32/adapters_384_slots_96_rate_0.4-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 1080, 33, 4320, 4320, 33, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 33, 4320, 33, 4320, 1080, 1080, 1080, 33, 33, 1080, 33, 4320, 33, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 4320, 33, 4320, 4320, 4320, 4320, 33, 1080, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 33, 33, 4320, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 4320, 33, 1080, 4320, 33, 4320, 1080, 33, 4320, 4320, 4320, 4320, 1080, 33, 1080, 4320, 4320, 1080, 33, 33, 4320, 1080, 1080, 33, 33, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 33, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 4320, 33, 33, 33, 1080, 1080, 4320, 33, 33, 4320, 33, 4320, 1080, 33, 4320, 1080, 1080, 33, 4320, 4320, 4320, 33, 1080, 4320, 33, 4320, 1080, 1080, 4320, 4320, 33, 1080, 4320, 33, 1080, 1080, 33, 1080, 33, 1080, 4320, 4320, 1080, 33, 4320, 33, 4320, 1080, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 4320, 33, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 4320, 4320, 33, 33, 4320, 33, 33, 33, 1080, 33, 1080, 4320, 4320, 1080, 1080, 33, 4320, 1080, 4320, 33, 1080, 1080, 33, 33, 1080, 33, 4320, 4320, 33, 4320, 4320, 33, 1080, 4320, 33, 33, 1080, 1080, 33, 33, 4320, 4320, 4320, 4320, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 4320, 1080, 1080, 1080, 4320, 33, 1080, 1080, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 1080, 33, 4320, 4320, 4320, 1080, 33, 4320, 4320, 1080, 1080, 4320, 4320, 33, 4320, 4320, 1080, 33, 4320, 1080, 1080, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 1080, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 4320, 33, 33, 33, 1080, 33, 1080, 1080, 33, 4320, 1080, 4320, 33, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 4320, 4320, 33, 4320, 4320, 33, 4320, 1080, 4320, 1080, 1080, 1080, 33, 1080, 33, 33, 4320, 33, 1080, 33, 33, 1080, 4320, 1080, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 695424 . Total input tokens: 154965070 . Total output tokens: 139036309
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 74.55491335038096,
    "estimated_duration": 3600.1335087389452,
    "input_throughput": 5233.424803348373,
    "output_throughput": 4672.149785326111,
    "total_throughput": 9905.574588674483,
    "itl": 179.72354362351788,
    "ttft": 1774615.558562553,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 588,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9480383406207,
    "arrivals": 231176,
    "finished_requests": 76840,
    "scheduler_time": 132.56217102961503
}
#Debug simulation 
Total elapsed time: 74.55502692004666. Arrivals time: 0.3278347831219435 Scheduler time: 74.08757237391546 Scheduler overhead time: 0.054377253632992506 Adapter cache time: 0.01725742034614086 Engine time: 0.048732977360486984 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-16/adapters_384_slots_96_rate_0.4-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-16/adapters_384_slots_96_rate_0.4-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 1080, 33, 4320, 4320, 33, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 33, 4320, 33, 4320, 1080, 1080, 1080, 33, 33, 1080, 33, 4320, 33, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 4320, 33, 4320, 4320, 4320, 4320, 33, 1080, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 33, 33, 4320, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 4320, 33, 1080, 4320, 33, 4320, 1080, 33, 4320, 4320, 4320, 4320, 1080, 33, 1080, 4320, 4320, 1080, 33, 33, 4320, 1080, 1080, 33, 33, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 33, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 4320, 33, 33, 33, 1080, 1080, 4320, 33, 33, 4320, 33, 4320, 1080, 33, 4320, 1080, 1080, 33, 4320, 4320, 4320, 33, 1080, 4320, 33, 4320, 1080, 1080, 4320, 4320, 33, 1080, 4320, 33, 1080, 1080, 33, 1080, 33, 1080, 4320, 4320, 1080, 33, 4320, 33, 4320, 1080, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 4320, 33, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 4320, 4320, 33, 33, 4320, 33, 33, 33, 1080, 33, 1080, 4320, 4320, 1080, 1080, 33, 4320, 1080, 4320, 33, 1080, 1080, 33, 33, 1080, 33, 4320, 4320, 33, 4320, 4320, 33, 1080, 4320, 33, 33, 1080, 1080, 33, 33, 4320, 4320, 4320, 4320, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 4320, 1080, 1080, 1080, 4320, 33, 1080, 1080, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 1080, 33, 4320, 4320, 4320, 1080, 33, 4320, 4320, 1080, 1080, 4320, 4320, 33, 4320, 4320, 1080, 33, 4320, 1080, 1080, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 1080, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 4320, 33, 33, 33, 1080, 33, 1080, 1080, 33, 4320, 1080, 4320, 33, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 4320, 4320, 33, 4320, 4320, 33, 4320, 1080, 4320, 1080, 1080, 1080, 33, 1080, 33, 33, 4320, 33, 1080, 33, 33, 1080, 4320, 1080, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 695424 . Total input tokens: 154965070 . Total output tokens: 139036309
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 66.32822286197916,
    "estimated_duration": 3600.0401939324624,
    "input_throughput": 5253.528844449011,
    "output_throughput": 4693.267877529973,
    "total_throughput": 9946.796721978983,
    "itl": 182.92698862884868,
    "ttft": 1776187.0393992828,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 585,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7491794225177475,
    "arrivals": 231176,
    "finished_requests": 77126,
    "scheduler_time": 131.4936700945618
}
#Debug simulation 
Total elapsed time: 66.32833953015506. Arrivals time: 0.32999588968232274 Scheduler time: 65.86087138671428 Scheduler overhead time: 0.05368844419717789 Adapter cache time: 0.016555710695683956 Engine time: 0.04824763396754861 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-32/adapters_384_slots_96_rate_0.4-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-32/adapters_384_slots_96_rate_0.4-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 1080, 33, 4320, 4320, 33, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 33, 4320, 33, 4320, 1080, 1080, 1080, 33, 33, 1080, 33, 4320, 33, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 4320, 33, 4320, 4320, 4320, 4320, 33, 1080, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 33, 33, 4320, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 4320, 33, 1080, 4320, 33, 4320, 1080, 33, 4320, 4320, 4320, 4320, 1080, 33, 1080, 4320, 4320, 1080, 33, 33, 4320, 1080, 1080, 33, 33, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 33, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 4320, 33, 33, 33, 1080, 1080, 4320, 33, 33, 4320, 33, 4320, 1080, 33, 4320, 1080, 1080, 33, 4320, 4320, 4320, 33, 1080, 4320, 33, 4320, 1080, 1080, 4320, 4320, 33, 1080, 4320, 33, 1080, 1080, 33, 1080, 33, 1080, 4320, 4320, 1080, 33, 4320, 33, 4320, 1080, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 4320, 33, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 4320, 4320, 33, 33, 4320, 33, 33, 33, 1080, 33, 1080, 4320, 4320, 1080, 1080, 33, 4320, 1080, 4320, 33, 1080, 1080, 33, 33, 1080, 33, 4320, 4320, 33, 4320, 4320, 33, 1080, 4320, 33, 33, 1080, 1080, 33, 33, 4320, 4320, 4320, 4320, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 4320, 1080, 1080, 1080, 4320, 33, 1080, 1080, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 1080, 33, 4320, 4320, 4320, 1080, 33, 4320, 4320, 1080, 1080, 4320, 4320, 33, 4320, 4320, 1080, 33, 4320, 1080, 1080, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 1080, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 4320, 33, 33, 33, 1080, 33, 1080, 1080, 33, 4320, 1080, 4320, 33, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 4320, 4320, 33, 4320, 4320, 33, 4320, 1080, 4320, 1080, 1080, 1080, 33, 1080, 33, 33, 4320, 33, 1080, 33, 33, 1080, 4320, 1080, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 695424 . Total input tokens: 154965070 . Total output tokens: 139036309
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 74.67147360602394,
    "estimated_duration": 3600.100827886115,
    "input_throughput": 5241.90124171627,
    "output_throughput": 4680.526686774519,
    "total_throughput": 9922.42792849079,
    "itl": 180.02866307481338,
    "ttft": 1774135.9536717373,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 570,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9139872395247173,
    "arrivals": 231176,
    "finished_requests": 76987,
    "scheduler_time": 132.4505691277945
}
#Debug simulation 
Total elapsed time: 74.6715855798684. Arrivals time: 0.3312003151513636 Scheduler time: 74.20106207067147 Scheduler overhead time: 0.05395511956885457 Adapter cache time: 0.01705854432657361 Engine time: 0.0490699028596282 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-8/adapters_384_slots_96_rate_0.4-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-8/adapters_384_slots_96_rate_0.4-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 4320, 540, 270, 4320, 4320, 270, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 270, 4320, 270, 4320, 540, 540, 540, 270, 270, 540, 270, 4320, 270, 4320, 540, 4320, 540, 270, 540, 4320, 540, 4320, 270, 4320, 4320, 4320, 4320, 270, 540, 540, 540, 4320, 540, 270, 540, 270, 4320, 540, 4320, 4320, 540, 4320, 4320, 270, 270, 4320, 540, 540, 270, 270, 270, 540, 270, 540, 270, 4320, 270, 540, 4320, 270, 4320, 540, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 4320, 4320, 540, 270, 270, 4320, 540, 540, 270, 270, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 270, 540, 540, 540, 540, 270, 270, 4320, 270, 4320, 270, 270, 270, 540, 540, 4320, 270, 270, 4320, 270, 4320, 540, 270, 4320, 540, 540, 270, 4320, 4320, 4320, 270, 540, 4320, 270, 4320, 540, 540, 4320, 4320, 270, 540, 4320, 270, 540, 540, 270, 540, 270, 540, 4320, 4320, 540, 270, 4320, 270, 4320, 540, 540, 540, 540, 540, 270, 270, 4320, 270, 4320, 270, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 270, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 270, 270, 270, 270, 270, 540, 270, 270, 540, 4320, 4320, 270, 270, 4320, 270, 270, 270, 540, 270, 540, 4320, 4320, 540, 540, 270, 4320, 540, 4320, 270, 540, 540, 270, 270, 540, 270, 4320, 4320, 270, 4320, 4320, 270, 540, 4320, 270, 270, 540, 540, 270, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 4320, 540, 540, 540, 4320, 270, 540, 540, 4320, 4320, 270, 4320, 4320, 270, 4320, 270, 270, 540, 270, 4320, 4320, 4320, 540, 270, 4320, 4320, 540, 540, 4320, 4320, 270, 4320, 4320, 540, 270, 4320, 540, 540, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 4320, 270, 540, 4320, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 4320, 270, 270, 270, 540, 270, 540, 540, 270, 4320, 540, 4320, 270, 4320, 270, 540, 540, 540, 540, 270, 540, 4320, 4320, 270, 4320, 4320, 270, 4320, 540, 4320, 540, 540, 540, 270, 540, 270, 270, 4320, 270, 540, 270, 270, 540, 4320, 540, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 656640 . Total input tokens: 146385497 . Total output tokens: 131206172
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 75.89188964804634,
    "estimated_duration": 3600.1429011244595,
    "input_throughput": 5334.695185016503,
    "output_throughput": 4684.682098239007,
    "total_throughput": 10019.377283255511,
    "itl": 181.63243142571665,
    "ttft": 1750351.6457416008,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 647,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9801355703245245,
    "arrivals": 218283,
    "finished_requests": 77378,
    "scheduler_time": 131.18970236997228
}
#Debug simulation 
Total elapsed time: 75.8920052582398. Arrivals time: 0.32913162000477314 Scheduler time: 75.42115175211802 Scheduler overhead time: 0.0538635915145278 Adapter cache time: 0.01922651007771492 Engine time: 0.049151414539664984 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-16/adapters_384_slots_96_rate_0.4-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-16/adapters_384_slots_96_rate_0.4-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 4320, 540, 270, 4320, 4320, 270, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 270, 4320, 270, 4320, 540, 540, 540, 270, 270, 540, 270, 4320, 270, 4320, 540, 4320, 540, 270, 540, 4320, 540, 4320, 270, 4320, 4320, 4320, 4320, 270, 540, 540, 540, 4320, 540, 270, 540, 270, 4320, 540, 4320, 4320, 540, 4320, 4320, 270, 270, 4320, 540, 540, 270, 270, 270, 540, 270, 540, 270, 4320, 270, 540, 4320, 270, 4320, 540, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 4320, 4320, 540, 270, 270, 4320, 540, 540, 270, 270, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 270, 540, 540, 540, 540, 270, 270, 4320, 270, 4320, 270, 270, 270, 540, 540, 4320, 270, 270, 4320, 270, 4320, 540, 270, 4320, 540, 540, 270, 4320, 4320, 4320, 270, 540, 4320, 270, 4320, 540, 540, 4320, 4320, 270, 540, 4320, 270, 540, 540, 270, 540, 270, 540, 4320, 4320, 540, 270, 4320, 270, 4320, 540, 540, 540, 540, 540, 270, 270, 4320, 270, 4320, 270, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 270, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 270, 270, 270, 270, 270, 540, 270, 270, 540, 4320, 4320, 270, 270, 4320, 270, 270, 270, 540, 270, 540, 4320, 4320, 540, 540, 270, 4320, 540, 4320, 270, 540, 540, 270, 270, 540, 270, 4320, 4320, 270, 4320, 4320, 270, 540, 4320, 270, 270, 540, 540, 270, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 4320, 540, 540, 540, 4320, 270, 540, 540, 4320, 4320, 270, 4320, 4320, 270, 4320, 270, 270, 540, 270, 4320, 4320, 4320, 540, 270, 4320, 4320, 540, 540, 4320, 4320, 270, 4320, 4320, 540, 270, 4320, 540, 540, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 4320, 270, 540, 4320, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 4320, 270, 270, 270, 540, 270, 540, 540, 270, 4320, 540, 4320, 270, 4320, 270, 540, 540, 540, 540, 270, 540, 4320, 4320, 270, 4320, 4320, 270, 4320, 540, 4320, 540, 540, 540, 270, 540, 270, 270, 4320, 270, 540, 270, 270, 540, 4320, 540, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 656640 . Total input tokens: 146385497 . Total output tokens: 131206172
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 75.70980504481122,
    "estimated_duration": 3600.091284020798,
    "input_throughput": 5333.8339183871285,
    "output_throughput": 4685.097868174656,
    "total_throughput": 10018.931786561783,
    "itl": 181.6718463036247,
    "ttft": 1750110.0030992643,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 652,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1260259698424533,
    "arrivals": 218283,
    "finished_requests": 77363,
    "scheduler_time": 131.17983462503778
}
#Debug simulation 
Total elapsed time: 75.70990995969623. Arrivals time: 0.32428326830267906 Scheduler time: 75.24322727881372 Scheduler overhead time: 0.05469100084155798 Adapter cache time: 0.019371445756405592 Engine time: 0.049423654563724995 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-32/adapters_384_slots_96_rate_0.4-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-32/adapters_384_slots_96_rate_0.4-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 4320, 540, 270, 4320, 4320, 270, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 270, 4320, 270, 4320, 540, 540, 540, 270, 270, 540, 270, 4320, 270, 4320, 540, 4320, 540, 270, 540, 4320, 540, 4320, 270, 4320, 4320, 4320, 4320, 270, 540, 540, 540, 4320, 540, 270, 540, 270, 4320, 540, 4320, 4320, 540, 4320, 4320, 270, 270, 4320, 540, 540, 270, 270, 270, 540, 270, 540, 270, 4320, 270, 540, 4320, 270, 4320, 540, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 4320, 4320, 540, 270, 270, 4320, 540, 540, 270, 270, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 270, 540, 540, 540, 540, 270, 270, 4320, 270, 4320, 270, 270, 270, 540, 540, 4320, 270, 270, 4320, 270, 4320, 540, 270, 4320, 540, 540, 270, 4320, 4320, 4320, 270, 540, 4320, 270, 4320, 540, 540, 4320, 4320, 270, 540, 4320, 270, 540, 540, 270, 540, 270, 540, 4320, 4320, 540, 270, 4320, 270, 4320, 540, 540, 540, 540, 540, 270, 270, 4320, 270, 4320, 270, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 270, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 270, 270, 270, 270, 270, 540, 270, 270, 540, 4320, 4320, 270, 270, 4320, 270, 270, 270, 540, 270, 540, 4320, 4320, 540, 540, 270, 4320, 540, 4320, 270, 540, 540, 270, 270, 540, 270, 4320, 4320, 270, 4320, 4320, 270, 540, 4320, 270, 270, 540, 540, 270, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 4320, 540, 540, 540, 4320, 270, 540, 540, 4320, 4320, 270, 4320, 4320, 270, 4320, 270, 270, 540, 270, 4320, 4320, 4320, 540, 270, 4320, 4320, 540, 540, 4320, 4320, 270, 4320, 4320, 540, 270, 4320, 540, 540, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 4320, 270, 540, 4320, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 4320, 270, 270, 270, 540, 270, 540, 540, 270, 4320, 540, 4320, 270, 4320, 270, 540, 540, 540, 540, 270, 540, 4320, 4320, 270, 4320, 4320, 270, 4320, 540, 4320, 540, 540, 540, 270, 540, 270, 270, 4320, 270, 540, 270, 270, 540, 4320, 540, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 656640 . Total input tokens: 146385497 . Total output tokens: 131206172
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 74.80621589394286,
    "estimated_duration": 3600.072339726216,
    "input_throughput": 5319.162003688043,
    "output_throughput": 4672.951933315701,
    "total_throughput": 9992.113937003744,
    "itl": 179.77849324559813,
    "ttft": 1752936.8971257186,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 648,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1172166366502725,
    "arrivals": 218283,
    "finished_requests": 77146,
    "scheduler_time": 131.65528463467012
}
#Debug simulation 
Total elapsed time: 74.80632640980184. Arrivals time: 0.3243283503688872 Scheduler time: 74.3375452524051 Scheduler overhead time: 0.05606858851388097 Adapter cache time: 0.019603395834565163 Engine time: 0.0489367600530386 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-16/adapters_384_slots_96_rate_0.4-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-16/adapters_384_slots_96_rate_0.4-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 4320, 540, 270, 4320, 4320, 270, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 270, 4320, 270, 4320, 540, 540, 540, 270, 270, 540, 270, 4320, 270, 4320, 540, 4320, 540, 270, 540, 4320, 540, 4320, 270, 4320, 4320, 4320, 4320, 270, 540, 540, 540, 4320, 540, 270, 540, 270, 4320, 540, 4320, 4320, 540, 4320, 4320, 270, 270, 4320, 540, 540, 270, 270, 270, 540, 270, 540, 270, 4320, 270, 540, 4320, 270, 4320, 540, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 4320, 4320, 540, 270, 270, 4320, 540, 540, 270, 270, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 270, 540, 540, 540, 540, 270, 270, 4320, 270, 4320, 270, 270, 270, 540, 540, 4320, 270, 270, 4320, 270, 4320, 540, 270, 4320, 540, 540, 270, 4320, 4320, 4320, 270, 540, 4320, 270, 4320, 540, 540, 4320, 4320, 270, 540, 4320, 270, 540, 540, 270, 540, 270, 540, 4320, 4320, 540, 270, 4320, 270, 4320, 540, 540, 540, 540, 540, 270, 270, 4320, 270, 4320, 270, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 270, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 270, 270, 270, 270, 270, 540, 270, 270, 540, 4320, 4320, 270, 270, 4320, 270, 270, 270, 540, 270, 540, 4320, 4320, 540, 540, 270, 4320, 540, 4320, 270, 540, 540, 270, 270, 540, 270, 4320, 4320, 270, 4320, 4320, 270, 540, 4320, 270, 270, 540, 540, 270, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 4320, 540, 540, 540, 4320, 270, 540, 540, 4320, 4320, 270, 4320, 4320, 270, 4320, 270, 270, 540, 270, 4320, 4320, 4320, 540, 270, 4320, 4320, 540, 540, 4320, 4320, 270, 4320, 4320, 540, 270, 4320, 540, 540, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 4320, 270, 540, 4320, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 4320, 270, 270, 270, 540, 270, 540, 540, 270, 4320, 540, 4320, 270, 4320, 270, 540, 540, 540, 540, 270, 540, 4320, 4320, 270, 4320, 4320, 270, 4320, 540, 4320, 540, 540, 540, 270, 540, 270, 270, 4320, 270, 540, 270, 270, 540, 4320, 540, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 656640 . Total input tokens: 146385497 . Total output tokens: 131206172
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 75.59895677119493,
    "estimated_duration": 3600.0115449839973,
    "input_throughput": 5334.81011380628,
    "output_throughput": 4684.83914266863,
    "total_throughput": 10019.64925647491,
    "itl": 181.6352309932577,
    "ttft": 1750096.067837296,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 645,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.013161671129039,
    "arrivals": 218283,
    "finished_requests": 77368,
    "scheduler_time": 131.18724098907236
}
#Debug simulation 
Total elapsed time: 75.59907284006476. Arrivals time: 0.33023716043680906 Scheduler time: 75.12561125261709 Scheduler overhead time: 0.05435831844806671 Adapter cache time: 0.01943469839170575 Engine time: 0.0499101122841239 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-32/adapters_384_slots_96_rate_0.4-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-32/adapters_384_slots_96_rate_0.4-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 4320, 540, 270, 4320, 4320, 270, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 270, 4320, 270, 4320, 540, 540, 540, 270, 270, 540, 270, 4320, 270, 4320, 540, 4320, 540, 270, 540, 4320, 540, 4320, 270, 4320, 4320, 4320, 4320, 270, 540, 540, 540, 4320, 540, 270, 540, 270, 4320, 540, 4320, 4320, 540, 4320, 4320, 270, 270, 4320, 540, 540, 270, 270, 270, 540, 270, 540, 270, 4320, 270, 540, 4320, 270, 4320, 540, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 4320, 4320, 540, 270, 270, 4320, 540, 540, 270, 270, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 270, 540, 540, 540, 540, 270, 270, 4320, 270, 4320, 270, 270, 270, 540, 540, 4320, 270, 270, 4320, 270, 4320, 540, 270, 4320, 540, 540, 270, 4320, 4320, 4320, 270, 540, 4320, 270, 4320, 540, 540, 4320, 4320, 270, 540, 4320, 270, 540, 540, 270, 540, 270, 540, 4320, 4320, 540, 270, 4320, 270, 4320, 540, 540, 540, 540, 540, 270, 270, 4320, 270, 4320, 270, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 270, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 270, 270, 270, 270, 270, 540, 270, 270, 540, 4320, 4320, 270, 270, 4320, 270, 270, 270, 540, 270, 540, 4320, 4320, 540, 540, 270, 4320, 540, 4320, 270, 540, 540, 270, 270, 540, 270, 4320, 4320, 270, 4320, 4320, 270, 540, 4320, 270, 270, 540, 540, 270, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 4320, 540, 540, 540, 4320, 270, 540, 540, 4320, 4320, 270, 4320, 4320, 270, 4320, 270, 270, 540, 270, 4320, 4320, 4320, 540, 270, 4320, 4320, 540, 540, 4320, 4320, 270, 4320, 4320, 540, 270, 4320, 540, 540, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 4320, 270, 540, 4320, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 4320, 270, 270, 270, 540, 270, 540, 540, 270, 4320, 540, 4320, 270, 4320, 270, 540, 540, 540, 540, 270, 540, 4320, 4320, 270, 4320, 4320, 270, 4320, 540, 4320, 540, 540, 540, 270, 540, 270, 270, 4320, 270, 540, 270, 270, 540, 4320, 540, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 656640 . Total input tokens: 146385497 . Total output tokens: 131206172
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 74.90630681719631,
    "estimated_duration": 3600.195076367178,
    "input_throughput": 5319.599242195831,
    "output_throughput": 4672.244598749197,
    "total_throughput": 9991.843840945028,
    "itl": 179.77854036269625,
    "ttft": 1752453.8756767507,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 651,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.154687521196906,
    "arrivals": 218283,
    "finished_requests": 77152,
    "scheduler_time": 131.65195334879974
}
#Debug simulation 
Total elapsed time: 74.90641539078206. Arrivals time: 0.3253035834059119 Scheduler time: 74.43840924883261 Scheduler overhead time: 0.05514256935566664 Adapter cache time: 0.018850394524633884 Engine time: 0.04872955055907369 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-16/adapters_384_slots_96_rate_0.4-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-16/adapters_384_slots_96_rate_0.4-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 4320, 540, 270, 4320, 4320, 270, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 270, 4320, 270, 4320, 540, 540, 540, 270, 270, 540, 270, 4320, 270, 4320, 540, 4320, 540, 270, 540, 4320, 540, 4320, 270, 4320, 4320, 4320, 4320, 270, 540, 540, 540, 4320, 540, 270, 540, 270, 4320, 540, 4320, 4320, 540, 4320, 4320, 270, 270, 4320, 540, 540, 270, 270, 270, 540, 270, 540, 270, 4320, 270, 540, 4320, 270, 4320, 540, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 4320, 4320, 540, 270, 270, 4320, 540, 540, 270, 270, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 270, 540, 540, 540, 540, 270, 270, 4320, 270, 4320, 270, 270, 270, 540, 540, 4320, 270, 270, 4320, 270, 4320, 540, 270, 4320, 540, 540, 270, 4320, 4320, 4320, 270, 540, 4320, 270, 4320, 540, 540, 4320, 4320, 270, 540, 4320, 270, 540, 540, 270, 540, 270, 540, 4320, 4320, 540, 270, 4320, 270, 4320, 540, 540, 540, 540, 540, 270, 270, 4320, 270, 4320, 270, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 270, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 270, 270, 270, 270, 270, 540, 270, 270, 540, 4320, 4320, 270, 270, 4320, 270, 270, 270, 540, 270, 540, 4320, 4320, 540, 540, 270, 4320, 540, 4320, 270, 540, 540, 270, 270, 540, 270, 4320, 4320, 270, 4320, 4320, 270, 540, 4320, 270, 270, 540, 540, 270, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 4320, 540, 540, 540, 4320, 270, 540, 540, 4320, 4320, 270, 4320, 4320, 270, 4320, 270, 270, 540, 270, 4320, 4320, 4320, 540, 270, 4320, 4320, 540, 540, 4320, 4320, 270, 4320, 4320, 540, 270, 4320, 540, 540, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 4320, 270, 540, 4320, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 4320, 270, 270, 270, 540, 270, 540, 540, 270, 4320, 540, 4320, 270, 4320, 270, 540, 540, 540, 540, 270, 540, 4320, 4320, 270, 4320, 4320, 270, 4320, 540, 4320, 540, 540, 540, 270, 540, 270, 270, 4320, 270, 540, 270, 270, 540, 4320, 540, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 656640 . Total input tokens: 146385497 . Total output tokens: 131206172
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 76.09115455532447,
    "estimated_duration": 3600.123961747682,
    "input_throughput": 5334.980462916102,
    "output_throughput": 4683.917048182419,
    "total_throughput": 10018.897511098521,
    "itl": 181.62883244823686,
    "ttft": 1750451.1864352657,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 641,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9166222390322634,
    "arrivals": 218283,
    "finished_requests": 77368,
    "scheduler_time": 131.19211286646882
}
#Debug simulation 
Total elapsed time: 76.0912647601217. Arrivals time: 0.3278874256648123 Scheduler time: 75.61744736414403 Scheduler overhead time: 0.05633097933605313 Adapter cache time: 0.01948694698512554 Engine time: 0.050819522235542536 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-32/adapters_384_slots_96_rate_0.4-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-32/adapters_384_slots_96_rate_0.4-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 4320, 540, 270, 4320, 4320, 270, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 270, 4320, 270, 4320, 540, 540, 540, 270, 270, 540, 270, 4320, 270, 4320, 540, 4320, 540, 270, 540, 4320, 540, 4320, 270, 4320, 4320, 4320, 4320, 270, 540, 540, 540, 4320, 540, 270, 540, 270, 4320, 540, 4320, 4320, 540, 4320, 4320, 270, 270, 4320, 540, 540, 270, 270, 270, 540, 270, 540, 270, 4320, 270, 540, 4320, 270, 4320, 540, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 4320, 4320, 540, 270, 270, 4320, 540, 540, 270, 270, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 270, 540, 540, 540, 540, 270, 270, 4320, 270, 4320, 270, 270, 270, 540, 540, 4320, 270, 270, 4320, 270, 4320, 540, 270, 4320, 540, 540, 270, 4320, 4320, 4320, 270, 540, 4320, 270, 4320, 540, 540, 4320, 4320, 270, 540, 4320, 270, 540, 540, 270, 540, 270, 540, 4320, 4320, 540, 270, 4320, 270, 4320, 540, 540, 540, 540, 540, 270, 270, 4320, 270, 4320, 270, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 270, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 270, 270, 270, 270, 270, 540, 270, 270, 540, 4320, 4320, 270, 270, 4320, 270, 270, 270, 540, 270, 540, 4320, 4320, 540, 540, 270, 4320, 540, 4320, 270, 540, 540, 270, 270, 540, 270, 4320, 4320, 270, 4320, 4320, 270, 540, 4320, 270, 270, 540, 540, 270, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 4320, 540, 540, 540, 4320, 270, 540, 540, 4320, 4320, 270, 4320, 4320, 270, 4320, 270, 270, 540, 270, 4320, 4320, 4320, 540, 270, 4320, 4320, 540, 540, 4320, 4320, 270, 4320, 4320, 540, 270, 4320, 540, 540, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 4320, 270, 540, 4320, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 4320, 270, 270, 270, 540, 270, 540, 540, 270, 4320, 540, 4320, 270, 4320, 270, 540, 540, 540, 540, 270, 540, 4320, 4320, 270, 4320, 4320, 270, 4320, 540, 4320, 540, 540, 540, 270, 540, 270, 270, 4320, 270, 540, 270, 270, 540, 4320, 540, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 656640 . Total input tokens: 146385497 . Total output tokens: 131206172
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 74.51728495070711,
    "estimated_duration": 3600.0924503364713,
    "input_throughput": 5319.132290119456,
    "output_throughput": 4672.925829565209,
    "total_throughput": 9992.058119684665,
    "itl": 179.78682377350756,
    "ttft": 1752930.3972591287,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 648,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.171290764808656,
    "arrivals": 218283,
    "finished_requests": 77146,
    "scheduler_time": 131.65264876471548
}
#Debug simulation 
Total elapsed time: 74.51739962073043. Arrivals time: 0.3300300221890211 Scheduler time: 74.04513505334035 Scheduler overhead time: 0.05450658733025193 Adapter cache time: 0.01941486680880189 Engine time: 0.048978581093251705 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-8/adapters_384_slots_96_rate_0.4-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-8/adapters_384_slots_96_rate_0.4-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 540, 135, 4320, 4320, 135, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 135, 4320, 135, 4320, 540, 540, 540, 135, 135, 540, 135, 4320, 135, 4320, 540, 4320, 540, 135, 540, 4320, 540, 4320, 135, 4320, 4320, 4320, 4320, 135, 540, 540, 540, 4320, 540, 135, 540, 135, 4320, 540, 4320, 4320, 540, 4320, 4320, 135, 135, 4320, 540, 540, 135, 135, 135, 540, 135, 540, 135, 4320, 135, 540, 4320, 135, 4320, 540, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 4320, 4320, 540, 135, 135, 4320, 540, 540, 135, 135, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 135, 540, 540, 540, 540, 135, 135, 4320, 135, 4320, 135, 135, 135, 540, 540, 4320, 135, 135, 4320, 135, 4320, 540, 135, 4320, 540, 540, 135, 4320, 4320, 4320, 135, 540, 4320, 135, 4320, 540, 540, 4320, 4320, 135, 540, 4320, 135, 540, 540, 135, 540, 135, 540, 4320, 4320, 540, 135, 4320, 135, 4320, 540, 540, 540, 540, 540, 135, 135, 4320, 135, 4320, 135, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 135, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 135, 135, 135, 135, 135, 540, 135, 135, 540, 4320, 4320, 135, 135, 4320, 135, 135, 135, 540, 135, 540, 4320, 4320, 540, 540, 135, 4320, 540, 4320, 135, 540, 540, 135, 135, 540, 135, 4320, 4320, 135, 4320, 4320, 135, 540, 4320, 135, 135, 540, 540, 135, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 4320, 540, 540, 540, 4320, 135, 540, 540, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 540, 135, 4320, 4320, 4320, 540, 135, 4320, 4320, 540, 540, 4320, 4320, 135, 4320, 4320, 540, 135, 4320, 540, 540, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 540, 4320, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 4320, 135, 135, 135, 540, 135, 540, 540, 135, 4320, 540, 4320, 135, 4320, 135, 540, 540, 540, 540, 135, 540, 4320, 4320, 135, 4320, 4320, 135, 4320, 540, 4320, 540, 540, 540, 135, 540, 135, 135, 4320, 135, 540, 135, 135, 540, 4320, 540, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 639360 . Total input tokens: 142592364 . Total output tokens: 127777710
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 74.88779968814924,
    "estimated_duration": 3600.175633939019,
    "input_throughput": 5280.752644614456,
    "output_throughput": 4688.070726575525,
    "total_throughput": 9968.823371189981,
    "itl": 182.439430785527,
    "ttft": 1750178.3068863498,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 566,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7322360630659628,
    "arrivals": 212473,
    "finished_requests": 76745,
    "scheduler_time": 130.95574429053698
}
#Debug simulation 
Total elapsed time: 74.88791363500059. Arrivals time: 0.3168376605026424 Scheduler time: 74.43275795783848 Scheduler overhead time: 0.0533930235542357 Adapter cache time: 0.016926463693380356 Engine time: 0.049099518451839685 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-16/adapters_384_slots_96_rate_0.4-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-16/adapters_384_slots_96_rate_0.4-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 540, 135, 4320, 4320, 135, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 135, 4320, 135, 4320, 540, 540, 540, 135, 135, 540, 135, 4320, 135, 4320, 540, 4320, 540, 135, 540, 4320, 540, 4320, 135, 4320, 4320, 4320, 4320, 135, 540, 540, 540, 4320, 540, 135, 540, 135, 4320, 540, 4320, 4320, 540, 4320, 4320, 135, 135, 4320, 540, 540, 135, 135, 135, 540, 135, 540, 135, 4320, 135, 540, 4320, 135, 4320, 540, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 4320, 4320, 540, 135, 135, 4320, 540, 540, 135, 135, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 135, 540, 540, 540, 540, 135, 135, 4320, 135, 4320, 135, 135, 135, 540, 540, 4320, 135, 135, 4320, 135, 4320, 540, 135, 4320, 540, 540, 135, 4320, 4320, 4320, 135, 540, 4320, 135, 4320, 540, 540, 4320, 4320, 135, 540, 4320, 135, 540, 540, 135, 540, 135, 540, 4320, 4320, 540, 135, 4320, 135, 4320, 540, 540, 540, 540, 540, 135, 135, 4320, 135, 4320, 135, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 135, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 135, 135, 135, 135, 135, 540, 135, 135, 540, 4320, 4320, 135, 135, 4320, 135, 135, 135, 540, 135, 540, 4320, 4320, 540, 540, 135, 4320, 540, 4320, 135, 540, 540, 135, 135, 540, 135, 4320, 4320, 135, 4320, 4320, 135, 540, 4320, 135, 135, 540, 540, 135, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 4320, 540, 540, 540, 4320, 135, 540, 540, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 540, 135, 4320, 4320, 4320, 540, 135, 4320, 4320, 540, 540, 4320, 4320, 135, 4320, 4320, 540, 135, 4320, 540, 540, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 540, 4320, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 4320, 135, 135, 135, 540, 135, 540, 540, 135, 4320, 540, 4320, 135, 4320, 135, 540, 540, 540, 540, 135, 540, 4320, 4320, 135, 4320, 4320, 135, 4320, 540, 4320, 540, 540, 540, 135, 540, 135, 135, 4320, 135, 540, 135, 135, 540, 4320, 540, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 639360 . Total input tokens: 142592364 . Total output tokens: 127777710
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 75.54291865695268,
    "estimated_duration": 3600.088208652404,
    "input_throughput": 5279.324532749268,
    "output_throughput": 4687.5443105648,
    "total_throughput": 9966.868843314069,
    "itl": 182.4588031366298,
    "ttft": 1748876.0665466436,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 559,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8222097873548095,
    "arrivals": 212473,
    "finished_requests": 76755,
    "scheduler_time": 130.95307617067584
}
#Debug simulation 
Total elapsed time: 75.54303618194535. Arrivals time: 0.32148319901898503 Scheduler time: 75.0813527321443 Scheduler overhead time: 0.054901115130633116 Adapter cache time: 0.017297017388045788 Engine time: 0.04890877939760685 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-32/adapters_384_slots_96_rate_0.4-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-32/adapters_384_slots_96_rate_0.4-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 540, 135, 4320, 4320, 135, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 135, 4320, 135, 4320, 540, 540, 540, 135, 135, 540, 135, 4320, 135, 4320, 540, 4320, 540, 135, 540, 4320, 540, 4320, 135, 4320, 4320, 4320, 4320, 135, 540, 540, 540, 4320, 540, 135, 540, 135, 4320, 540, 4320, 4320, 540, 4320, 4320, 135, 135, 4320, 540, 540, 135, 135, 135, 540, 135, 540, 135, 4320, 135, 540, 4320, 135, 4320, 540, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 4320, 4320, 540, 135, 135, 4320, 540, 540, 135, 135, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 135, 540, 540, 540, 540, 135, 135, 4320, 135, 4320, 135, 135, 135, 540, 540, 4320, 135, 135, 4320, 135, 4320, 540, 135, 4320, 540, 540, 135, 4320, 4320, 4320, 135, 540, 4320, 135, 4320, 540, 540, 4320, 4320, 135, 540, 4320, 135, 540, 540, 135, 540, 135, 540, 4320, 4320, 540, 135, 4320, 135, 4320, 540, 540, 540, 540, 540, 135, 135, 4320, 135, 4320, 135, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 135, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 135, 135, 135, 135, 135, 540, 135, 135, 540, 4320, 4320, 135, 135, 4320, 135, 135, 135, 540, 135, 540, 4320, 4320, 540, 540, 135, 4320, 540, 4320, 135, 540, 540, 135, 135, 540, 135, 4320, 4320, 135, 4320, 4320, 135, 540, 4320, 135, 135, 540, 540, 135, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 4320, 540, 540, 540, 4320, 135, 540, 540, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 540, 135, 4320, 4320, 4320, 540, 135, 4320, 4320, 540, 540, 4320, 4320, 135, 4320, 4320, 540, 135, 4320, 540, 540, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 540, 4320, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 4320, 135, 135, 135, 540, 135, 540, 540, 135, 4320, 540, 4320, 135, 4320, 135, 540, 540, 540, 540, 135, 540, 4320, 4320, 135, 4320, 4320, 135, 4320, 540, 4320, 540, 540, 540, 135, 540, 135, 135, 4320, 135, 540, 135, 135, 540, 4320, 540, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 639360 . Total input tokens: 142592364 . Total output tokens: 127777710
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 73.69004101818427,
    "estimated_duration": 3600.030541209289,
    "input_throughput": 5262.701741867966,
    "output_throughput": 4671.15592701367,
    "total_throughput": 9933.857668881636,
    "itl": 179.69403631721346,
    "ttft": 1753877.2412309179,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 569,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8595790253765996,
    "arrivals": 212473,
    "finished_requests": 76485,
    "scheduler_time": 131.6817438090145
}
#Debug simulation 
Total elapsed time: 73.69014989119023. Arrivals time: 0.3206813191063702 Scheduler time: 73.227806027513 Scheduler overhead time: 0.05522943567484617 Adapter cache time: 0.017625259701162577 Engine time: 0.04934586863964796 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-16/adapters_384_slots_96_rate_0.4-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-16/adapters_384_slots_96_rate_0.4-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 540, 135, 4320, 4320, 135, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 135, 4320, 135, 4320, 540, 540, 540, 135, 135, 540, 135, 4320, 135, 4320, 540, 4320, 540, 135, 540, 4320, 540, 4320, 135, 4320, 4320, 4320, 4320, 135, 540, 540, 540, 4320, 540, 135, 540, 135, 4320, 540, 4320, 4320, 540, 4320, 4320, 135, 135, 4320, 540, 540, 135, 135, 135, 540, 135, 540, 135, 4320, 135, 540, 4320, 135, 4320, 540, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 4320, 4320, 540, 135, 135, 4320, 540, 540, 135, 135, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 135, 540, 540, 540, 540, 135, 135, 4320, 135, 4320, 135, 135, 135, 540, 540, 4320, 135, 135, 4320, 135, 4320, 540, 135, 4320, 540, 540, 135, 4320, 4320, 4320, 135, 540, 4320, 135, 4320, 540, 540, 4320, 4320, 135, 540, 4320, 135, 540, 540, 135, 540, 135, 540, 4320, 4320, 540, 135, 4320, 135, 4320, 540, 540, 540, 540, 540, 135, 135, 4320, 135, 4320, 135, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 135, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 135, 135, 135, 135, 135, 540, 135, 135, 540, 4320, 4320, 135, 135, 4320, 135, 135, 135, 540, 135, 540, 4320, 4320, 540, 540, 135, 4320, 540, 4320, 135, 540, 540, 135, 135, 540, 135, 4320, 4320, 135, 4320, 4320, 135, 540, 4320, 135, 135, 540, 540, 135, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 4320, 540, 540, 540, 4320, 135, 540, 540, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 540, 135, 4320, 4320, 4320, 540, 135, 4320, 4320, 540, 540, 4320, 4320, 135, 4320, 4320, 540, 135, 4320, 540, 540, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 540, 4320, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 4320, 135, 135, 135, 540, 135, 540, 540, 135, 4320, 540, 4320, 135, 4320, 135, 540, 540, 540, 540, 135, 540, 4320, 4320, 135, 4320, 4320, 135, 4320, 540, 4320, 540, 540, 540, 135, 540, 135, 135, 4320, 135, 540, 135, 135, 540, 4320, 540, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 639360 . Total input tokens: 142592364 . Total output tokens: 127777710
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 75.66268822131678,
    "estimated_duration": 3600.034584968201,
    "input_throughput": 5279.63094559212,
    "output_throughput": 4688.273848943893,
    "total_throughput": 9967.904794536013,
    "itl": 182.46453152488752,
    "ttft": 1749712.1796279708,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 569,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7785631329845537,
    "arrivals": 212473,
    "finished_requests": 76752,
    "scheduler_time": 130.94735310162685
}
#Debug simulation 
Total elapsed time: 75.66279710829258. Arrivals time: 0.3242370868101716 Scheduler time: 75.19678658479825 Scheduler overhead time: 0.055560487788170576 Adapter cache time: 0.017302505671977997 Engine time: 0.04916329775005579 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-32/adapters_384_slots_96_rate_0.4-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-32/adapters_384_slots_96_rate_0.4-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 540, 135, 4320, 4320, 135, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 135, 4320, 135, 4320, 540, 540, 540, 135, 135, 540, 135, 4320, 135, 4320, 540, 4320, 540, 135, 540, 4320, 540, 4320, 135, 4320, 4320, 4320, 4320, 135, 540, 540, 540, 4320, 540, 135, 540, 135, 4320, 540, 4320, 4320, 540, 4320, 4320, 135, 135, 4320, 540, 540, 135, 135, 135, 540, 135, 540, 135, 4320, 135, 540, 4320, 135, 4320, 540, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 4320, 4320, 540, 135, 135, 4320, 540, 540, 135, 135, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 135, 540, 540, 540, 540, 135, 135, 4320, 135, 4320, 135, 135, 135, 540, 540, 4320, 135, 135, 4320, 135, 4320, 540, 135, 4320, 540, 540, 135, 4320, 4320, 4320, 135, 540, 4320, 135, 4320, 540, 540, 4320, 4320, 135, 540, 4320, 135, 540, 540, 135, 540, 135, 540, 4320, 4320, 540, 135, 4320, 135, 4320, 540, 540, 540, 540, 540, 135, 135, 4320, 135, 4320, 135, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 135, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 135, 135, 135, 135, 135, 540, 135, 135, 540, 4320, 4320, 135, 135, 4320, 135, 135, 135, 540, 135, 540, 4320, 4320, 540, 540, 135, 4320, 540, 4320, 135, 540, 540, 135, 135, 540, 135, 4320, 4320, 135, 4320, 4320, 135, 540, 4320, 135, 135, 540, 540, 135, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 4320, 540, 540, 540, 4320, 135, 540, 540, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 540, 135, 4320, 4320, 4320, 540, 135, 4320, 4320, 540, 540, 4320, 4320, 135, 4320, 4320, 540, 135, 4320, 540, 540, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 540, 4320, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 4320, 135, 135, 135, 540, 135, 540, 540, 135, 4320, 540, 4320, 135, 4320, 135, 540, 540, 540, 540, 135, 540, 4320, 4320, 135, 4320, 4320, 135, 4320, 540, 4320, 540, 540, 540, 135, 540, 135, 135, 4320, 135, 540, 135, 135, 540, 4320, 540, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 639360 . Total input tokens: 142592364 . Total output tokens: 127777710
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 73.89962192904204,
    "estimated_duration": 3600.076021482623,
    "input_throughput": 5263.83273211984,
    "output_throughput": 4671.750790716234,
    "total_throughput": 9935.583522836074,
    "itl": 179.7657181012304,
    "ttft": 1754086.8532174444,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 572,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8937803114764427,
    "arrivals": 212473,
    "finished_requests": 76506,
    "scheduler_time": 131.66359749287085
}
#Debug simulation 
Total elapsed time: 73.89973533386365. Arrivals time: 0.32237686635926366 Scheduler time: 73.43803879152983 Scheduler overhead time: 0.054278642404824495 Adapter cache time: 0.017386953812092543 Engine time: 0.04882361413910985 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-16/adapters_384_slots_96_rate_0.4-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-16/adapters_384_slots_96_rate_0.4-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 540, 135, 4320, 4320, 135, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 135, 4320, 135, 4320, 540, 540, 540, 135, 135, 540, 135, 4320, 135, 4320, 540, 4320, 540, 135, 540, 4320, 540, 4320, 135, 4320, 4320, 4320, 4320, 135, 540, 540, 540, 4320, 540, 135, 540, 135, 4320, 540, 4320, 4320, 540, 4320, 4320, 135, 135, 4320, 540, 540, 135, 135, 135, 540, 135, 540, 135, 4320, 135, 540, 4320, 135, 4320, 540, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 4320, 4320, 540, 135, 135, 4320, 540, 540, 135, 135, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 135, 540, 540, 540, 540, 135, 135, 4320, 135, 4320, 135, 135, 135, 540, 540, 4320, 135, 135, 4320, 135, 4320, 540, 135, 4320, 540, 540, 135, 4320, 4320, 4320, 135, 540, 4320, 135, 4320, 540, 540, 4320, 4320, 135, 540, 4320, 135, 540, 540, 135, 540, 135, 540, 4320, 4320, 540, 135, 4320, 135, 4320, 540, 540, 540, 540, 540, 135, 135, 4320, 135, 4320, 135, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 135, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 135, 135, 135, 135, 135, 540, 135, 135, 540, 4320, 4320, 135, 135, 4320, 135, 135, 135, 540, 135, 540, 4320, 4320, 540, 540, 135, 4320, 540, 4320, 135, 540, 540, 135, 135, 540, 135, 4320, 4320, 135, 4320, 4320, 135, 540, 4320, 135, 135, 540, 540, 135, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 4320, 540, 540, 540, 4320, 135, 540, 540, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 540, 135, 4320, 4320, 4320, 540, 135, 4320, 4320, 540, 540, 4320, 4320, 135, 4320, 4320, 540, 135, 4320, 540, 540, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 540, 4320, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 4320, 135, 135, 135, 540, 135, 540, 540, 135, 4320, 540, 4320, 135, 4320, 135, 540, 540, 540, 540, 135, 540, 4320, 4320, 135, 4320, 4320, 135, 4320, 540, 4320, 540, 540, 540, 135, 540, 135, 135, 4320, 135, 540, 135, 135, 540, 4320, 540, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 639360 . Total input tokens: 142592364 . Total output tokens: 127777710
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 75.51053334865719,
    "estimated_duration": 3600.0212032394275,
    "input_throughput": 5278.168912700224,
    "output_throughput": 4688.478774739441,
    "total_throughput": 9966.647687439665,
    "itl": 182.45670492788932,
    "ttft": 1749726.069619715,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 566,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6923684669146082,
    "arrivals": 212473,
    "finished_requests": 76754,
    "scheduler_time": 130.9492755480778
}
#Debug simulation 
Total elapsed time: 75.51064017275348. Arrivals time: 0.3184714182280004 Scheduler time: 75.0526183033362 Scheduler overhead time: 0.05433482304215431 Adapter cache time: 0.01763343159109354 Engine time: 0.04862729599699378 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-32/adapters_384_slots_96_rate_0.4-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-32/adapters_384_slots_96_rate_0.4-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 540, 135, 4320, 4320, 135, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 135, 4320, 135, 4320, 540, 540, 540, 135, 135, 540, 135, 4320, 135, 4320, 540, 4320, 540, 135, 540, 4320, 540, 4320, 135, 4320, 4320, 4320, 4320, 135, 540, 540, 540, 4320, 540, 135, 540, 135, 4320, 540, 4320, 4320, 540, 4320, 4320, 135, 135, 4320, 540, 540, 135, 135, 135, 540, 135, 540, 135, 4320, 135, 540, 4320, 135, 4320, 540, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 4320, 4320, 540, 135, 135, 4320, 540, 540, 135, 135, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 135, 540, 540, 540, 540, 135, 135, 4320, 135, 4320, 135, 135, 135, 540, 540, 4320, 135, 135, 4320, 135, 4320, 540, 135, 4320, 540, 540, 135, 4320, 4320, 4320, 135, 540, 4320, 135, 4320, 540, 540, 4320, 4320, 135, 540, 4320, 135, 540, 540, 135, 540, 135, 540, 4320, 4320, 540, 135, 4320, 135, 4320, 540, 540, 540, 540, 540, 135, 135, 4320, 135, 4320, 135, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 135, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 135, 135, 135, 135, 135, 540, 135, 135, 540, 4320, 4320, 135, 135, 4320, 135, 135, 135, 540, 135, 540, 4320, 4320, 540, 540, 135, 4320, 540, 4320, 135, 540, 540, 135, 135, 540, 135, 4320, 4320, 135, 4320, 4320, 135, 540, 4320, 135, 135, 540, 540, 135, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 4320, 540, 540, 540, 4320, 135, 540, 540, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 540, 135, 4320, 4320, 4320, 540, 135, 4320, 4320, 540, 540, 4320, 4320, 135, 4320, 4320, 540, 135, 4320, 540, 540, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 540, 4320, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 4320, 135, 135, 135, 540, 135, 540, 540, 135, 4320, 540, 4320, 135, 4320, 135, 540, 540, 540, 540, 135, 540, 4320, 4320, 135, 4320, 4320, 135, 4320, 540, 4320, 540, 540, 540, 135, 540, 135, 135, 4320, 135, 540, 135, 135, 540, 4320, 540, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 639360 . Total input tokens: 142592364 . Total output tokens: 127777710
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 73.92051951307803,
    "estimated_duration": 3600.194809985819,
    "input_throughput": 5261.251126595177,
    "output_throughput": 4672.81685794838,
    "total_throughput": 9934.067984543557,
    "itl": 179.80827213392644,
    "ttft": 1753307.3741346595,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 571,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9142527506872968,
    "arrivals": 212473,
    "finished_requests": 76474,
    "scheduler_time": 131.65226850762224
}
#Debug simulation 
Total elapsed time: 73.92062719305977. Arrivals time: 0.3218787699006498 Scheduler time: 73.45779383322224 Scheduler overhead time: 0.055136147886514664 Adapter cache time: 0.017247606068849564 Engine time: 0.04986363323405385 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-8/adapters_384_slots_96_rate_0.4-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-8/adapters_384_slots_96_rate_0.4-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 540, 66, 4320, 4320, 66, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 66, 4320, 66, 4320, 540, 540, 540, 66, 66, 540, 66, 4320, 66, 4320, 540, 4320, 540, 66, 540, 4320, 540, 4320, 66, 4320, 4320, 4320, 4320, 66, 540, 540, 540, 4320, 540, 66, 540, 66, 4320, 540, 4320, 4320, 540, 4320, 4320, 66, 66, 4320, 540, 540, 66, 66, 66, 540, 66, 540, 66, 4320, 66, 540, 4320, 66, 4320, 540, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 4320, 4320, 540, 66, 66, 4320, 540, 540, 66, 66, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 66, 540, 540, 540, 540, 66, 66, 4320, 66, 4320, 66, 66, 66, 540, 540, 4320, 66, 66, 4320, 66, 4320, 540, 66, 4320, 540, 540, 66, 4320, 4320, 4320, 66, 540, 4320, 66, 4320, 540, 540, 4320, 4320, 66, 540, 4320, 66, 540, 540, 66, 540, 66, 540, 4320, 4320, 540, 66, 4320, 66, 4320, 540, 540, 540, 540, 540, 66, 66, 4320, 66, 4320, 66, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 66, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 66, 66, 66, 66, 66, 540, 66, 66, 540, 4320, 4320, 66, 66, 4320, 66, 66, 66, 540, 66, 540, 4320, 4320, 540, 540, 66, 4320, 540, 4320, 66, 540, 540, 66, 66, 540, 66, 4320, 4320, 66, 4320, 4320, 66, 540, 4320, 66, 66, 540, 540, 66, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 4320, 540, 540, 540, 4320, 66, 540, 540, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 540, 66, 4320, 4320, 4320, 540, 66, 4320, 4320, 540, 540, 4320, 4320, 66, 4320, 4320, 540, 66, 4320, 540, 540, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 540, 4320, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 4320, 66, 66, 66, 540, 66, 540, 540, 66, 4320, 540, 4320, 66, 4320, 66, 540, 540, 540, 540, 66, 540, 4320, 4320, 66, 4320, 4320, 66, 4320, 540, 4320, 540, 540, 540, 66, 540, 66, 66, 4320, 66, 540, 66, 66, 540, 4320, 540, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 630528 . Total input tokens: 140630688 . Total output tokens: 125979895
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 73.13864635117352,
    "estimated_duration": 3600.2014974820536,
    "input_throughput": 5360.684121013203,
    "output_throughput": 4676.643796680696,
    "total_throughput": 10037.3279176939,
    "itl": 180.7651813494145,
    "ttft": 1729503.042991285,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 607,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.85771606056721,
    "arrivals": 209565,
    "finished_requests": 77365,
    "scheduler_time": 131.09481523021205
}
#Debug simulation 
Total elapsed time: 73.13875501416624. Arrivals time: 0.31313553964719176 Scheduler time: 72.69013455091044 Scheduler overhead time: 0.05211231531575322 Adapter cache time: 0.017232022248208523 Engine time: 0.0476418687030673 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-16/adapters_384_slots_96_rate_0.4-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-16/adapters_384_slots_96_rate_0.4-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 540, 66, 4320, 4320, 66, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 66, 4320, 66, 4320, 540, 540, 540, 66, 66, 540, 66, 4320, 66, 4320, 540, 4320, 540, 66, 540, 4320, 540, 4320, 66, 4320, 4320, 4320, 4320, 66, 540, 540, 540, 4320, 540, 66, 540, 66, 4320, 540, 4320, 4320, 540, 4320, 4320, 66, 66, 4320, 540, 540, 66, 66, 66, 540, 66, 540, 66, 4320, 66, 540, 4320, 66, 4320, 540, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 4320, 4320, 540, 66, 66, 4320, 540, 540, 66, 66, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 66, 540, 540, 540, 540, 66, 66, 4320, 66, 4320, 66, 66, 66, 540, 540, 4320, 66, 66, 4320, 66, 4320, 540, 66, 4320, 540, 540, 66, 4320, 4320, 4320, 66, 540, 4320, 66, 4320, 540, 540, 4320, 4320, 66, 540, 4320, 66, 540, 540, 66, 540, 66, 540, 4320, 4320, 540, 66, 4320, 66, 4320, 540, 540, 540, 540, 540, 66, 66, 4320, 66, 4320, 66, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 66, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 66, 66, 66, 66, 66, 540, 66, 66, 540, 4320, 4320, 66, 66, 4320, 66, 66, 66, 540, 66, 540, 4320, 4320, 540, 540, 66, 4320, 540, 4320, 66, 540, 540, 66, 66, 540, 66, 4320, 4320, 66, 4320, 4320, 66, 540, 4320, 66, 66, 540, 540, 66, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 4320, 540, 540, 540, 4320, 66, 540, 540, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 540, 66, 4320, 4320, 4320, 540, 66, 4320, 4320, 540, 540, 4320, 4320, 66, 4320, 4320, 540, 66, 4320, 540, 540, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 540, 4320, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 4320, 66, 66, 66, 540, 66, 540, 540, 66, 4320, 540, 4320, 66, 4320, 66, 540, 540, 540, 540, 66, 540, 4320, 4320, 66, 4320, 4320, 66, 4320, 540, 4320, 540, 540, 540, 66, 540, 66, 66, 4320, 66, 540, 66, 66, 540, 4320, 540, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 630528 . Total input tokens: 140630688 . Total output tokens: 125979895
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 73.6260593123734,
    "estimated_duration": 3600.0914678981894,
    "input_throughput": 5360.702129956487,
    "output_throughput": 4676.514791394772,
    "total_throughput": 10037.216921351259,
    "itl": 180.77052139403187,
    "ttft": 1729469.5457256394,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 607,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9792158470186445,
    "arrivals": 209565,
    "finished_requests": 77362,
    "scheduler_time": 131.08716420778816
}
#Debug simulation 
Total elapsed time: 73.62617286434397. Arrivals time: 0.3192852418869734 Scheduler time: 73.16982778767124 Scheduler overhead time: 0.053452130407094955 Adapter cache time: 0.017193008679896593 Engine time: 0.04775598319247365 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-32/adapters_384_slots_96_rate_0.4-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-32/adapters_384_slots_96_rate_0.4-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 540, 66, 4320, 4320, 66, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 66, 4320, 66, 4320, 540, 540, 540, 66, 66, 540, 66, 4320, 66, 4320, 540, 4320, 540, 66, 540, 4320, 540, 4320, 66, 4320, 4320, 4320, 4320, 66, 540, 540, 540, 4320, 540, 66, 540, 66, 4320, 540, 4320, 4320, 540, 4320, 4320, 66, 66, 4320, 540, 540, 66, 66, 66, 540, 66, 540, 66, 4320, 66, 540, 4320, 66, 4320, 540, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 4320, 4320, 540, 66, 66, 4320, 540, 540, 66, 66, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 66, 540, 540, 540, 540, 66, 66, 4320, 66, 4320, 66, 66, 66, 540, 540, 4320, 66, 66, 4320, 66, 4320, 540, 66, 4320, 540, 540, 66, 4320, 4320, 4320, 66, 540, 4320, 66, 4320, 540, 540, 4320, 4320, 66, 540, 4320, 66, 540, 540, 66, 540, 66, 540, 4320, 4320, 540, 66, 4320, 66, 4320, 540, 540, 540, 540, 540, 66, 66, 4320, 66, 4320, 66, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 66, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 66, 66, 66, 66, 66, 540, 66, 66, 540, 4320, 4320, 66, 66, 4320, 66, 66, 66, 540, 66, 540, 4320, 4320, 540, 540, 66, 4320, 540, 4320, 66, 540, 540, 66, 66, 540, 66, 4320, 4320, 66, 4320, 4320, 66, 540, 4320, 66, 66, 540, 540, 66, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 4320, 540, 540, 540, 4320, 66, 540, 540, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 540, 66, 4320, 4320, 4320, 540, 66, 4320, 4320, 540, 540, 4320, 4320, 66, 4320, 4320, 540, 66, 4320, 540, 540, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 540, 4320, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 4320, 66, 66, 66, 540, 66, 540, 540, 66, 4320, 540, 4320, 66, 4320, 66, 540, 540, 540, 540, 66, 540, 4320, 4320, 66, 4320, 4320, 66, 4320, 540, 4320, 540, 540, 540, 66, 540, 66, 66, 4320, 66, 540, 66, 66, 540, 4320, 540, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 630528 . Total input tokens: 140630688 . Total output tokens: 125979895
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 72.56595777301118,
    "estimated_duration": 3600.084084703884,
    "input_throughput": 5349.612827608194,
    "output_throughput": 4665.306588632491,
    "total_throughput": 10014.919416240684,
    "itl": 179.17236469983058,
    "ttft": 1731241.870572363,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 605,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9769023963064078,
    "arrivals": 209565,
    "finished_requests": 77189,
    "scheduler_time": 131.49458526997222
}
#Debug simulation 
Total elapsed time: 72.56606965325773. Arrivals time: 0.3143168380483985 Scheduler time: 72.11700476752594 Scheduler overhead time: 0.05184777174144983 Adapter cache time: 0.0173550290055573 Engine time: 0.04700357234105468 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-16/adapters_384_slots_96_rate_0.4-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-16/adapters_384_slots_96_rate_0.4-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 540, 66, 4320, 4320, 66, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 66, 4320, 66, 4320, 540, 540, 540, 66, 66, 540, 66, 4320, 66, 4320, 540, 4320, 540, 66, 540, 4320, 540, 4320, 66, 4320, 4320, 4320, 4320, 66, 540, 540, 540, 4320, 540, 66, 540, 66, 4320, 540, 4320, 4320, 540, 4320, 4320, 66, 66, 4320, 540, 540, 66, 66, 66, 540, 66, 540, 66, 4320, 66, 540, 4320, 66, 4320, 540, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 4320, 4320, 540, 66, 66, 4320, 540, 540, 66, 66, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 66, 540, 540, 540, 540, 66, 66, 4320, 66, 4320, 66, 66, 66, 540, 540, 4320, 66, 66, 4320, 66, 4320, 540, 66, 4320, 540, 540, 66, 4320, 4320, 4320, 66, 540, 4320, 66, 4320, 540, 540, 4320, 4320, 66, 540, 4320, 66, 540, 540, 66, 540, 66, 540, 4320, 4320, 540, 66, 4320, 66, 4320, 540, 540, 540, 540, 540, 66, 66, 4320, 66, 4320, 66, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 66, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 66, 66, 66, 66, 66, 540, 66, 66, 540, 4320, 4320, 66, 66, 4320, 66, 66, 66, 540, 66, 540, 4320, 4320, 540, 540, 66, 4320, 540, 4320, 66, 540, 540, 66, 66, 540, 66, 4320, 4320, 66, 4320, 4320, 66, 540, 4320, 66, 66, 540, 540, 66, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 4320, 540, 540, 540, 4320, 66, 540, 540, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 540, 66, 4320, 4320, 4320, 540, 66, 4320, 4320, 540, 540, 4320, 4320, 66, 4320, 4320, 540, 66, 4320, 540, 540, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 540, 4320, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 4320, 66, 66, 66, 540, 66, 540, 540, 66, 4320, 540, 4320, 66, 4320, 66, 540, 540, 540, 540, 66, 540, 4320, 4320, 66, 4320, 4320, 66, 4320, 540, 4320, 540, 540, 540, 66, 540, 66, 66, 4320, 66, 540, 66, 66, 540, 4320, 540, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 630528 . Total input tokens: 140630688 . Total output tokens: 125979895
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 73.55837008636445,
    "estimated_duration": 3600.139781778652,
    "input_throughput": 5358.360832997807,
    "output_throughput": 4677.805035581095,
    "total_throughput": 10036.1658685789,
    "itl": 180.8162120566221,
    "ttft": 1729739.4660560337,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 591,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8463872160646004,
    "arrivals": 209565,
    "finished_requests": 77373,
    "scheduler_time": 131.08033430213712
}
#Debug simulation 
Total elapsed time: 73.558477061335. Arrivals time: 0.3177019148133695 Scheduler time: 73.10133250243962 Scheduler overhead time: 0.05507700052112341 Adapter cache time: 0.017639984842389822 Engine time: 0.04780260846018791 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-32/adapters_384_slots_96_rate_0.4-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-32/adapters_384_slots_96_rate_0.4-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 540, 66, 4320, 4320, 66, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 66, 4320, 66, 4320, 540, 540, 540, 66, 66, 540, 66, 4320, 66, 4320, 540, 4320, 540, 66, 540, 4320, 540, 4320, 66, 4320, 4320, 4320, 4320, 66, 540, 540, 540, 4320, 540, 66, 540, 66, 4320, 540, 4320, 4320, 540, 4320, 4320, 66, 66, 4320, 540, 540, 66, 66, 66, 540, 66, 540, 66, 4320, 66, 540, 4320, 66, 4320, 540, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 4320, 4320, 540, 66, 66, 4320, 540, 540, 66, 66, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 66, 540, 540, 540, 540, 66, 66, 4320, 66, 4320, 66, 66, 66, 540, 540, 4320, 66, 66, 4320, 66, 4320, 540, 66, 4320, 540, 540, 66, 4320, 4320, 4320, 66, 540, 4320, 66, 4320, 540, 540, 4320, 4320, 66, 540, 4320, 66, 540, 540, 66, 540, 66, 540, 4320, 4320, 540, 66, 4320, 66, 4320, 540, 540, 540, 540, 540, 66, 66, 4320, 66, 4320, 66, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 66, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 66, 66, 66, 66, 66, 540, 66, 66, 540, 4320, 4320, 66, 66, 4320, 66, 66, 66, 540, 66, 540, 4320, 4320, 540, 540, 66, 4320, 540, 4320, 66, 540, 540, 66, 66, 540, 66, 4320, 4320, 66, 4320, 4320, 66, 540, 4320, 66, 66, 540, 540, 66, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 4320, 540, 540, 540, 4320, 66, 540, 540, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 540, 66, 4320, 4320, 4320, 540, 66, 4320, 4320, 540, 540, 4320, 4320, 66, 4320, 4320, 540, 66, 4320, 540, 540, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 540, 4320, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 4320, 66, 66, 66, 540, 66, 540, 540, 66, 4320, 540, 4320, 66, 4320, 66, 540, 540, 540, 540, 66, 540, 4320, 4320, 66, 4320, 4320, 66, 4320, 540, 4320, 540, 540, 540, 66, 540, 66, 66, 4320, 66, 540, 66, 66, 540, 4320, 540, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 630528 . Total input tokens: 140630688 . Total output tokens: 125979895
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 72.51331704016775,
    "estimated_duration": 3600.1116612631013,
    "input_throughput": 5349.571850013938,
    "output_throughput": 4665.270852767741,
    "total_throughput": 10014.84270278168,
    "itl": 179.1725423763887,
    "ttft": 1731250.653129991,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 605,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.002304661162201,
    "arrivals": 209565,
    "finished_requests": 77189,
    "scheduler_time": 131.49486026012954
}
#Debug simulation 
Total elapsed time: 72.5134331882. Arrivals time: 0.3199217929504812 Scheduler time: 72.05661367159337 Scheduler overhead time: 0.05277791526168585 Adapter cache time: 0.017723895143717527 Engine time: 0.047435423359274864 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-16/adapters_384_slots_96_rate_0.4-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-16/adapters_384_slots_96_rate_0.4-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 540, 66, 4320, 4320, 66, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 66, 4320, 66, 4320, 540, 540, 540, 66, 66, 540, 66, 4320, 66, 4320, 540, 4320, 540, 66, 540, 4320, 540, 4320, 66, 4320, 4320, 4320, 4320, 66, 540, 540, 540, 4320, 540, 66, 540, 66, 4320, 540, 4320, 4320, 540, 4320, 4320, 66, 66, 4320, 540, 540, 66, 66, 66, 540, 66, 540, 66, 4320, 66, 540, 4320, 66, 4320, 540, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 4320, 4320, 540, 66, 66, 4320, 540, 540, 66, 66, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 66, 540, 540, 540, 540, 66, 66, 4320, 66, 4320, 66, 66, 66, 540, 540, 4320, 66, 66, 4320, 66, 4320, 540, 66, 4320, 540, 540, 66, 4320, 4320, 4320, 66, 540, 4320, 66, 4320, 540, 540, 4320, 4320, 66, 540, 4320, 66, 540, 540, 66, 540, 66, 540, 4320, 4320, 540, 66, 4320, 66, 4320, 540, 540, 540, 540, 540, 66, 66, 4320, 66, 4320, 66, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 66, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 66, 66, 66, 66, 66, 540, 66, 66, 540, 4320, 4320, 66, 66, 4320, 66, 66, 66, 540, 66, 540, 4320, 4320, 540, 540, 66, 4320, 540, 4320, 66, 540, 540, 66, 66, 540, 66, 4320, 4320, 66, 4320, 4320, 66, 540, 4320, 66, 66, 540, 540, 66, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 4320, 540, 540, 540, 4320, 66, 540, 540, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 540, 66, 4320, 4320, 4320, 540, 66, 4320, 4320, 540, 540, 4320, 4320, 66, 4320, 4320, 540, 66, 4320, 540, 540, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 540, 4320, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 4320, 66, 66, 66, 540, 66, 540, 540, 66, 4320, 540, 4320, 66, 4320, 66, 540, 540, 540, 540, 66, 540, 4320, 4320, 66, 4320, 4320, 66, 4320, 540, 4320, 540, 540, 540, 66, 540, 66, 66, 4320, 66, 540, 66, 66, 540, 4320, 540, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 630528 . Total input tokens: 140630688 . Total output tokens: 125979895
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 73.74306001001969,
    "estimated_duration": 3600.1458247313017,
    "input_throughput": 5359.540124028198,
    "output_throughput": 4677.621357534002,
    "total_throughput": 10037.1614815622,
    "itl": 180.8098251998709,
    "ttft": 1729554.6708494315,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 591,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.76711972428716,
    "arrivals": 209565,
    "finished_requests": 77379,
    "scheduler_time": 131.08269858163078
}
#Debug simulation 
Total elapsed time: 73.74316715123132. Arrivals time: 0.31689197150990367 Scheduler time: 73.28853502962738 Scheduler overhead time: 0.054242055863142014 Adapter cache time: 0.017563965171575546 Engine time: 0.047603811137378216 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-32/adapters_384_slots_96_rate_0.4-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-32/adapters_384_slots_96_rate_0.4-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 540, 66, 4320, 4320, 66, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 66, 4320, 66, 4320, 540, 540, 540, 66, 66, 540, 66, 4320, 66, 4320, 540, 4320, 540, 66, 540, 4320, 540, 4320, 66, 4320, 4320, 4320, 4320, 66, 540, 540, 540, 4320, 540, 66, 540, 66, 4320, 540, 4320, 4320, 540, 4320, 4320, 66, 66, 4320, 540, 540, 66, 66, 66, 540, 66, 540, 66, 4320, 66, 540, 4320, 66, 4320, 540, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 4320, 4320, 540, 66, 66, 4320, 540, 540, 66, 66, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 66, 540, 540, 540, 540, 66, 66, 4320, 66, 4320, 66, 66, 66, 540, 540, 4320, 66, 66, 4320, 66, 4320, 540, 66, 4320, 540, 540, 66, 4320, 4320, 4320, 66, 540, 4320, 66, 4320, 540, 540, 4320, 4320, 66, 540, 4320, 66, 540, 540, 66, 540, 66, 540, 4320, 4320, 540, 66, 4320, 66, 4320, 540, 540, 540, 540, 540, 66, 66, 4320, 66, 4320, 66, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 66, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 66, 66, 66, 66, 66, 540, 66, 66, 540, 4320, 4320, 66, 66, 4320, 66, 66, 66, 540, 66, 540, 4320, 4320, 540, 540, 66, 4320, 540, 4320, 66, 540, 540, 66, 66, 540, 66, 4320, 4320, 66, 4320, 4320, 66, 540, 4320, 66, 66, 540, 540, 66, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 4320, 540, 540, 540, 4320, 66, 540, 540, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 540, 66, 4320, 4320, 4320, 540, 66, 4320, 4320, 540, 540, 4320, 4320, 66, 4320, 4320, 540, 66, 4320, 540, 540, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 540, 4320, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 4320, 66, 66, 66, 540, 66, 540, 540, 66, 4320, 540, 4320, 66, 4320, 66, 540, 540, 540, 540, 66, 540, 4320, 4320, 66, 4320, 4320, 66, 4320, 540, 4320, 540, 540, 540, 66, 540, 66, 66, 4320, 66, 540, 66, 66, 540, 4320, 540, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 630528 . Total input tokens: 140630688 . Total output tokens: 125979895
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 72.45865597901866,
    "estimated_duration": 3600.1541724309504,
    "input_throughput": 5349.280635666823,
    "output_throughput": 4669.679740034088,
    "total_throughput": 10018.960375700912,
    "itl": 179.27671917834442,
    "ttft": 1732009.9098686571,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 592,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9851116657257033,
    "arrivals": 209565,
    "finished_requests": 77227,
    "scheduler_time": 131.46681003842193
}
#Debug simulation 
Total elapsed time: 72.45876462804154. Arrivals time: 0.31317239301279187 Scheduler time: 72.00873306114227 Scheduler overhead time: 0.05302301608026028 Adapter cache time: 0.01772014331072569 Engine time: 0.04752104822546244 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-8/adapters_384_slots_96_rate_0.4-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-8/adapters_384_slots_96_rate_0.4-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 540, 33, 4320, 4320, 33, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 33, 4320, 33, 4320, 540, 540, 540, 33, 33, 540, 33, 4320, 33, 4320, 540, 4320, 540, 33, 540, 4320, 540, 4320, 33, 4320, 4320, 4320, 4320, 33, 540, 540, 540, 4320, 540, 33, 540, 33, 4320, 540, 4320, 4320, 540, 4320, 4320, 33, 33, 4320, 540, 540, 33, 33, 33, 540, 33, 540, 33, 4320, 33, 540, 4320, 33, 4320, 540, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 4320, 4320, 540, 33, 33, 4320, 540, 540, 33, 33, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 33, 540, 540, 540, 540, 33, 33, 4320, 33, 4320, 33, 33, 33, 540, 540, 4320, 33, 33, 4320, 33, 4320, 540, 33, 4320, 540, 540, 33, 4320, 4320, 4320, 33, 540, 4320, 33, 4320, 540, 540, 4320, 4320, 33, 540, 4320, 33, 540, 540, 33, 540, 33, 540, 4320, 4320, 540, 33, 4320, 33, 4320, 540, 540, 540, 540, 540, 33, 33, 4320, 33, 4320, 33, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 33, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 33, 33, 33, 33, 33, 540, 33, 33, 540, 4320, 4320, 33, 33, 4320, 33, 33, 33, 540, 33, 540, 4320, 4320, 540, 540, 33, 4320, 540, 4320, 33, 540, 540, 33, 33, 540, 33, 4320, 4320, 33, 4320, 4320, 33, 540, 4320, 33, 33, 540, 540, 33, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 4320, 540, 540, 540, 4320, 33, 540, 540, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 540, 33, 4320, 4320, 4320, 540, 33, 4320, 4320, 540, 540, 4320, 4320, 33, 4320, 4320, 540, 33, 4320, 540, 540, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 540, 4320, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 4320, 33, 33, 33, 540, 33, 540, 540, 33, 4320, 540, 4320, 33, 4320, 33, 540, 540, 540, 540, 33, 540, 4320, 4320, 33, 4320, 4320, 33, 4320, 540, 4320, 540, 540, 540, 33, 540, 33, 33, 4320, 33, 540, 33, 33, 540, 4320, 540, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 626304 . Total input tokens: 139684315 . Total output tokens: 125137764
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 73.78766122413799,
    "estimated_duration": 3600.0757100996607,
    "input_throughput": 5301.46878479721,
    "output_throughput": 4686.9703191694525,
    "total_throughput": 9988.439103966663,
    "itl": 182.4244165833331,
    "ttft": 1730375.5492385759,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 576,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7628409405052914,
    "arrivals": 208142,
    "finished_requests": 77048,
    "scheduler_time": 130.61586452296316
}
#Debug simulation 
Total elapsed time: 73.78776724915951. Arrivals time: 0.31845481833443046 Scheduler time: 73.33404193492606 Scheduler overhead time: 0.05215723905712366 Adapter cache time: 0.017206859309226274 Engine time: 0.047015666496008635 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-16/adapters_384_slots_96_rate_0.4-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-16/adapters_384_slots_96_rate_0.4-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 540, 33, 4320, 4320, 33, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 33, 4320, 33, 4320, 540, 540, 540, 33, 33, 540, 33, 4320, 33, 4320, 540, 4320, 540, 33, 540, 4320, 540, 4320, 33, 4320, 4320, 4320, 4320, 33, 540, 540, 540, 4320, 540, 33, 540, 33, 4320, 540, 4320, 4320, 540, 4320, 4320, 33, 33, 4320, 540, 540, 33, 33, 33, 540, 33, 540, 33, 4320, 33, 540, 4320, 33, 4320, 540, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 4320, 4320, 540, 33, 33, 4320, 540, 540, 33, 33, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 33, 540, 540, 540, 540, 33, 33, 4320, 33, 4320, 33, 33, 33, 540, 540, 4320, 33, 33, 4320, 33, 4320, 540, 33, 4320, 540, 540, 33, 4320, 4320, 4320, 33, 540, 4320, 33, 4320, 540, 540, 4320, 4320, 33, 540, 4320, 33, 540, 540, 33, 540, 33, 540, 4320, 4320, 540, 33, 4320, 33, 4320, 540, 540, 540, 540, 540, 33, 33, 4320, 33, 4320, 33, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 33, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 33, 33, 33, 33, 33, 540, 33, 33, 540, 4320, 4320, 33, 33, 4320, 33, 33, 33, 540, 33, 540, 4320, 4320, 540, 540, 33, 4320, 540, 4320, 33, 540, 540, 33, 33, 540, 33, 4320, 4320, 33, 4320, 4320, 33, 540, 4320, 33, 33, 540, 540, 33, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 4320, 540, 540, 540, 4320, 33, 540, 540, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 540, 33, 4320, 4320, 4320, 540, 33, 4320, 4320, 540, 540, 4320, 4320, 33, 4320, 4320, 540, 33, 4320, 540, 540, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 540, 4320, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 4320, 33, 33, 33, 540, 33, 540, 540, 33, 4320, 540, 4320, 33, 4320, 33, 540, 540, 540, 540, 33, 540, 4320, 4320, 33, 4320, 4320, 33, 4320, 540, 4320, 540, 540, 540, 33, 540, 33, 33, 4320, 33, 540, 33, 33, 540, 4320, 540, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 626304 . Total input tokens: 139684315 . Total output tokens: 125137764
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 73.26396800717339,
    "estimated_duration": 3600.1220363013704,
    "input_throughput": 5301.637502157786,
    "output_throughput": 4686.312527708904,
    "total_throughput": 9987.95002986669,
    "itl": 182.42533057921983,
    "ttft": 1730710.3139819126,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 577,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8837940037134153,
    "arrivals": 208142,
    "finished_requests": 77038,
    "scheduler_time": 130.61709766122772
}
#Debug simulation 
Total elapsed time: 73.26407400798053. Arrivals time: 0.311350273899734 Scheduler time: 72.8185229091905 Scheduler overhead time: 0.05142770288512111 Adapter cache time: 0.016933836042881012 Engine time: 0.04694275325164199 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-32/adapters_384_slots_96_rate_0.4-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-32/adapters_384_slots_96_rate_0.4-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 540, 33, 4320, 4320, 33, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 33, 4320, 33, 4320, 540, 540, 540, 33, 33, 540, 33, 4320, 33, 4320, 540, 4320, 540, 33, 540, 4320, 540, 4320, 33, 4320, 4320, 4320, 4320, 33, 540, 540, 540, 4320, 540, 33, 540, 33, 4320, 540, 4320, 4320, 540, 4320, 4320, 33, 33, 4320, 540, 540, 33, 33, 33, 540, 33, 540, 33, 4320, 33, 540, 4320, 33, 4320, 540, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 4320, 4320, 540, 33, 33, 4320, 540, 540, 33, 33, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 33, 540, 540, 540, 540, 33, 33, 4320, 33, 4320, 33, 33, 33, 540, 540, 4320, 33, 33, 4320, 33, 4320, 540, 33, 4320, 540, 540, 33, 4320, 4320, 4320, 33, 540, 4320, 33, 4320, 540, 540, 4320, 4320, 33, 540, 4320, 33, 540, 540, 33, 540, 33, 540, 4320, 4320, 540, 33, 4320, 33, 4320, 540, 540, 540, 540, 540, 33, 33, 4320, 33, 4320, 33, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 33, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 33, 33, 33, 33, 33, 540, 33, 33, 540, 4320, 4320, 33, 33, 4320, 33, 33, 33, 540, 33, 540, 4320, 4320, 540, 540, 33, 4320, 540, 4320, 33, 540, 540, 33, 33, 540, 33, 4320, 4320, 33, 4320, 4320, 33, 540, 4320, 33, 33, 540, 540, 33, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 4320, 540, 540, 540, 4320, 33, 540, 540, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 540, 33, 4320, 4320, 4320, 540, 33, 4320, 4320, 540, 540, 4320, 4320, 33, 4320, 4320, 540, 33, 4320, 540, 540, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 540, 4320, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 4320, 33, 33, 33, 540, 33, 540, 540, 33, 4320, 540, 4320, 33, 4320, 33, 540, 540, 540, 540, 33, 540, 4320, 4320, 33, 4320, 4320, 33, 4320, 540, 4320, 540, 540, 540, 33, 540, 33, 33, 4320, 33, 540, 33, 33, 540, 4320, 540, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 626304 . Total input tokens: 139684315 . Total output tokens: 125137764
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 72.54025792656466,
    "estimated_duration": 3600.155004728532,
    "input_throughput": 5284.627460487526,
    "output_throughput": 4674.176244605582,
    "total_throughput": 9958.803705093109,
    "itl": 180.2831287401011,
    "ttft": 1733480.009705111,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 582,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9025172453560053,
    "arrivals": 208142,
    "finished_requests": 76835,
    "scheduler_time": 131.2111387276987
}
#Debug simulation 
Total elapsed time: 72.54036398185417. Arrivals time: 0.31298190634697676 Scheduler time: 72.09221447305754 Scheduler overhead time: 0.05152101954445243 Adapter cache time: 0.017383324913680553 Engine time: 0.04769563116133213 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-16/adapters_384_slots_96_rate_0.4-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-16/adapters_384_slots_96_rate_0.4-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 540, 33, 4320, 4320, 33, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 33, 4320, 33, 4320, 540, 540, 540, 33, 33, 540, 33, 4320, 33, 4320, 540, 4320, 540, 33, 540, 4320, 540, 4320, 33, 4320, 4320, 4320, 4320, 33, 540, 540, 540, 4320, 540, 33, 540, 33, 4320, 540, 4320, 4320, 540, 4320, 4320, 33, 33, 4320, 540, 540, 33, 33, 33, 540, 33, 540, 33, 4320, 33, 540, 4320, 33, 4320, 540, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 4320, 4320, 540, 33, 33, 4320, 540, 540, 33, 33, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 33, 540, 540, 540, 540, 33, 33, 4320, 33, 4320, 33, 33, 33, 540, 540, 4320, 33, 33, 4320, 33, 4320, 540, 33, 4320, 540, 540, 33, 4320, 4320, 4320, 33, 540, 4320, 33, 4320, 540, 540, 4320, 4320, 33, 540, 4320, 33, 540, 540, 33, 540, 33, 540, 4320, 4320, 540, 33, 4320, 33, 4320, 540, 540, 540, 540, 540, 33, 33, 4320, 33, 4320, 33, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 33, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 33, 33, 33, 33, 33, 540, 33, 33, 540, 4320, 4320, 33, 33, 4320, 33, 33, 33, 540, 33, 540, 4320, 4320, 540, 540, 33, 4320, 540, 4320, 33, 540, 540, 33, 33, 540, 33, 4320, 4320, 33, 4320, 4320, 33, 540, 4320, 33, 33, 540, 540, 33, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 4320, 540, 540, 540, 4320, 33, 540, 540, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 540, 33, 4320, 4320, 4320, 540, 33, 4320, 4320, 540, 540, 4320, 4320, 33, 4320, 4320, 540, 33, 4320, 540, 540, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 540, 4320, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 4320, 33, 33, 33, 540, 33, 540, 540, 33, 4320, 540, 4320, 33, 4320, 33, 540, 540, 540, 540, 33, 540, 4320, 4320, 33, 4320, 4320, 33, 4320, 540, 4320, 540, 540, 540, 33, 540, 33, 33, 4320, 33, 540, 33, 33, 540, 4320, 540, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 626304 . Total input tokens: 139684315 . Total output tokens: 125137764
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 73.29285156494007,
    "estimated_duration": 3600.195328758445,
    "input_throughput": 5301.550126332219,
    "output_throughput": 4686.562105456268,
    "total_throughput": 9988.112231788487,
    "itl": 182.4196072303702,
    "ttft": 1730499.4927196556,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 574,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.796373551688146,
    "arrivals": 208142,
    "finished_requests": 77047,
    "scheduler_time": 130.62186734335864
}
#Debug simulation 
Total elapsed time: 73.2929582959041. Arrivals time: 0.3155946540646255 Scheduler time: 72.84219447290525 Scheduler overhead time: 0.05182649893686175 Adapter cache time: 0.017014810349792242 Engine time: 0.04749057674780488 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-32/adapters_384_slots_96_rate_0.4-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-32/adapters_384_slots_96_rate_0.4-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 540, 33, 4320, 4320, 33, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 33, 4320, 33, 4320, 540, 540, 540, 33, 33, 540, 33, 4320, 33, 4320, 540, 4320, 540, 33, 540, 4320, 540, 4320, 33, 4320, 4320, 4320, 4320, 33, 540, 540, 540, 4320, 540, 33, 540, 33, 4320, 540, 4320, 4320, 540, 4320, 4320, 33, 33, 4320, 540, 540, 33, 33, 33, 540, 33, 540, 33, 4320, 33, 540, 4320, 33, 4320, 540, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 4320, 4320, 540, 33, 33, 4320, 540, 540, 33, 33, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 33, 540, 540, 540, 540, 33, 33, 4320, 33, 4320, 33, 33, 33, 540, 540, 4320, 33, 33, 4320, 33, 4320, 540, 33, 4320, 540, 540, 33, 4320, 4320, 4320, 33, 540, 4320, 33, 4320, 540, 540, 4320, 4320, 33, 540, 4320, 33, 540, 540, 33, 540, 33, 540, 4320, 4320, 540, 33, 4320, 33, 4320, 540, 540, 540, 540, 540, 33, 33, 4320, 33, 4320, 33, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 33, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 33, 33, 33, 33, 33, 540, 33, 33, 540, 4320, 4320, 33, 33, 4320, 33, 33, 33, 540, 33, 540, 4320, 4320, 540, 540, 33, 4320, 540, 4320, 33, 540, 540, 33, 33, 540, 33, 4320, 4320, 33, 4320, 4320, 33, 540, 4320, 33, 33, 540, 540, 33, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 4320, 540, 540, 540, 4320, 33, 540, 540, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 540, 33, 4320, 4320, 4320, 540, 33, 4320, 4320, 540, 540, 4320, 4320, 33, 4320, 4320, 540, 33, 4320, 540, 540, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 540, 4320, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 4320, 33, 33, 33, 540, 33, 540, 540, 33, 4320, 540, 4320, 33, 4320, 33, 540, 540, 540, 540, 33, 540, 4320, 4320, 33, 4320, 4320, 33, 4320, 540, 4320, 540, 540, 540, 33, 540, 33, 33, 4320, 33, 540, 33, 33, 540, 4320, 540, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 626304 . Total input tokens: 139684315 . Total output tokens: 125137764
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 72.47710466198623,
    "estimated_duration": 3600.118933216133,
    "input_throughput": 5283.702108976414,
    "output_throughput": 4672.713127555465,
    "total_throughput": 9956.415236531879,
    "itl": 180.33596929378845,
    "ttft": 1733492.610960874,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 586,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9402250515855886,
    "arrivals": 208142,
    "finished_requests": 76817,
    "scheduler_time": 131.18891573898793
}
#Debug simulation 
Total elapsed time: 72.47720755683258. Arrivals time: 0.30984980054199696 Scheduler time: 72.03270904580131 Scheduler overhead time: 0.05150993913412094 Adapter cache time: 0.017425627447664738 Engine time: 0.04704806860536337 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-16/adapters_384_slots_96_rate_0.4-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-16/adapters_384_slots_96_rate_0.4-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 540, 33, 4320, 4320, 33, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 33, 4320, 33, 4320, 540, 540, 540, 33, 33, 540, 33, 4320, 33, 4320, 540, 4320, 540, 33, 540, 4320, 540, 4320, 33, 4320, 4320, 4320, 4320, 33, 540, 540, 540, 4320, 540, 33, 540, 33, 4320, 540, 4320, 4320, 540, 4320, 4320, 33, 33, 4320, 540, 540, 33, 33, 33, 540, 33, 540, 33, 4320, 33, 540, 4320, 33, 4320, 540, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 4320, 4320, 540, 33, 33, 4320, 540, 540, 33, 33, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 33, 540, 540, 540, 540, 33, 33, 4320, 33, 4320, 33, 33, 33, 540, 540, 4320, 33, 33, 4320, 33, 4320, 540, 33, 4320, 540, 540, 33, 4320, 4320, 4320, 33, 540, 4320, 33, 4320, 540, 540, 4320, 4320, 33, 540, 4320, 33, 540, 540, 33, 540, 33, 540, 4320, 4320, 540, 33, 4320, 33, 4320, 540, 540, 540, 540, 540, 33, 33, 4320, 33, 4320, 33, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 33, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 33, 33, 33, 33, 33, 540, 33, 33, 540, 4320, 4320, 33, 33, 4320, 33, 33, 33, 540, 33, 540, 4320, 4320, 540, 540, 33, 4320, 540, 4320, 33, 540, 540, 33, 33, 540, 33, 4320, 4320, 33, 4320, 4320, 33, 540, 4320, 33, 33, 540, 540, 33, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 4320, 540, 540, 540, 4320, 33, 540, 540, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 540, 33, 4320, 4320, 4320, 540, 33, 4320, 4320, 540, 540, 4320, 4320, 33, 4320, 4320, 540, 33, 4320, 540, 540, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 540, 4320, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 4320, 33, 33, 33, 540, 33, 540, 540, 33, 4320, 540, 4320, 33, 4320, 33, 540, 540, 540, 540, 33, 540, 4320, 4320, 33, 4320, 4320, 33, 4320, 540, 4320, 540, 540, 540, 33, 540, 33, 33, 4320, 33, 540, 33, 33, 540, 4320, 540, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 626304 . Total input tokens: 139684315 . Total output tokens: 125137764
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 73.23016271134838,
    "estimated_duration": 3600.1950674393634,
    "input_throughput": 5302.111036326924,
    "output_throughput": 4686.50855965992,
    "total_throughput": 9988.619595986844,
    "itl": 182.41864260594815,
    "ttft": 1730683.8145166768,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 577,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.725259020158531,
    "arrivals": 208142,
    "finished_requests": 77045,
    "scheduler_time": 130.6244509532478
}
#Debug simulation 
Total elapsed time: 73.23027566215023. Arrivals time: 0.3208061340264976 Scheduler time: 72.77412958443165 Scheduler overhead time: 0.05247013922780752 Adapter cache time: 0.01735127903521061 Engine time: 0.04701109090819955 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-32/adapters_384_slots_96_rate_0.4-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-32/adapters_384_slots_96_rate_0.4-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 540, 33, 4320, 4320, 33, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 33, 4320, 33, 4320, 540, 540, 540, 33, 33, 540, 33, 4320, 33, 4320, 540, 4320, 540, 33, 540, 4320, 540, 4320, 33, 4320, 4320, 4320, 4320, 33, 540, 540, 540, 4320, 540, 33, 540, 33, 4320, 540, 4320, 4320, 540, 4320, 4320, 33, 33, 4320, 540, 540, 33, 33, 33, 540, 33, 540, 33, 4320, 33, 540, 4320, 33, 4320, 540, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 4320, 4320, 540, 33, 33, 4320, 540, 540, 33, 33, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 33, 540, 540, 540, 540, 33, 33, 4320, 33, 4320, 33, 33, 33, 540, 540, 4320, 33, 33, 4320, 33, 4320, 540, 33, 4320, 540, 540, 33, 4320, 4320, 4320, 33, 540, 4320, 33, 4320, 540, 540, 4320, 4320, 33, 540, 4320, 33, 540, 540, 33, 540, 33, 540, 4320, 4320, 540, 33, 4320, 33, 4320, 540, 540, 540, 540, 540, 33, 33, 4320, 33, 4320, 33, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 33, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 33, 33, 33, 33, 33, 540, 33, 33, 540, 4320, 4320, 33, 33, 4320, 33, 33, 33, 540, 33, 540, 4320, 4320, 540, 540, 33, 4320, 540, 4320, 33, 540, 540, 33, 33, 540, 33, 4320, 4320, 33, 4320, 4320, 33, 540, 4320, 33, 33, 540, 540, 33, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 4320, 540, 540, 540, 4320, 33, 540, 540, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 540, 33, 4320, 4320, 4320, 540, 33, 4320, 4320, 540, 540, 4320, 4320, 33, 4320, 4320, 540, 33, 4320, 540, 540, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 540, 4320, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 4320, 33, 33, 33, 540, 33, 540, 540, 33, 4320, 540, 4320, 33, 4320, 33, 540, 540, 540, 540, 33, 540, 4320, 4320, 33, 4320, 4320, 33, 4320, 540, 4320, 540, 540, 540, 33, 540, 33, 33, 4320, 33, 540, 33, 33, 540, 4320, 540, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 626304 . Total input tokens: 139684315 . Total output tokens: 125137764
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 72.78238124772906,
    "estimated_duration": 3600.006246546636,
    "input_throughput": 5285.129718386316,
    "output_throughput": 4674.407444748862,
    "total_throughput": 9959.537163135177,
    "itl": 180.3612714319221,
    "ttft": 1733111.6042643709,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 579,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9413789091631732,
    "arrivals": 208142,
    "finished_requests": 76841,
    "scheduler_time": 131.1768303998523
}
#Debug simulation 
Total elapsed time: 72.7824925580062. Arrivals time: 0.3192527242936194 Scheduler time: 72.32844037516043 Scheduler overhead time: 0.05195006309077144 Adapter cache time: 0.016999148298054934 Engine time: 0.04678162652999163 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-8/adapters_384_slots_96_rate_0.4-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-8/adapters_384_slots_96_rate_0.4-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 270, 135, 4320, 4320, 135, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 135, 4320, 135, 4320, 270, 270, 270, 135, 135, 270, 135, 4320, 135, 4320, 270, 4320, 270, 135, 270, 4320, 270, 4320, 135, 4320, 4320, 4320, 4320, 135, 270, 270, 270, 4320, 270, 135, 270, 135, 4320, 270, 4320, 4320, 270, 4320, 4320, 135, 135, 4320, 270, 270, 135, 135, 135, 270, 135, 270, 135, 4320, 135, 270, 4320, 135, 4320, 270, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 4320, 4320, 270, 135, 135, 4320, 270, 270, 135, 135, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 135, 270, 270, 270, 270, 135, 135, 4320, 135, 4320, 135, 135, 135, 270, 270, 4320, 135, 135, 4320, 135, 4320, 270, 135, 4320, 270, 270, 135, 4320, 4320, 4320, 135, 270, 4320, 135, 4320, 270, 270, 4320, 4320, 135, 270, 4320, 135, 270, 270, 135, 270, 135, 270, 4320, 4320, 270, 135, 4320, 135, 4320, 270, 270, 270, 270, 270, 135, 135, 4320, 135, 4320, 135, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 135, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 135, 135, 135, 135, 135, 270, 135, 135, 270, 4320, 4320, 135, 135, 4320, 135, 135, 135, 270, 135, 270, 4320, 4320, 270, 270, 135, 4320, 270, 4320, 135, 270, 270, 135, 135, 270, 135, 4320, 4320, 135, 4320, 4320, 135, 270, 4320, 135, 135, 270, 270, 135, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 4320, 270, 270, 270, 4320, 135, 270, 270, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 270, 135, 4320, 4320, 4320, 270, 135, 4320, 4320, 270, 270, 4320, 4320, 135, 4320, 4320, 270, 135, 4320, 270, 270, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 270, 4320, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 4320, 135, 135, 135, 270, 135, 270, 270, 135, 4320, 270, 4320, 135, 4320, 135, 270, 270, 270, 270, 135, 270, 4320, 4320, 135, 4320, 4320, 135, 4320, 270, 4320, 270, 270, 270, 135, 270, 135, 135, 4320, 135, 270, 135, 135, 270, 4320, 270, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 604800 . Total input tokens: 134855028 . Total output tokens: 120795858
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 77.70475116930902,
    "estimated_duration": 3600.110486583267,
    "input_throughput": 5308.068202689038,
    "output_throughput": 4683.186269652851,
    "total_throughput": 9991.254472341889,
    "itl": 182.01718923290227,
    "ttft": 1712871.488289287,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 610,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8668975237990086,
    "arrivals": 200966,
    "finished_requests": 76942,
    "scheduler_time": 130.21293666258677
}
#Debug simulation 
Total elapsed time: 77.7048598639667. Arrivals time: 0.3178554689511657 Scheduler time: 77.25198317226022 Scheduler overhead time: 0.05156835913658142 Adapter cache time: 0.017284087371081114 Engine time: 0.047262074425816536 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-16/adapters_384_slots_96_rate_0.4-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-16/adapters_384_slots_96_rate_0.4-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 270, 135, 4320, 4320, 135, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 135, 4320, 135, 4320, 270, 270, 270, 135, 135, 270, 135, 4320, 135, 4320, 270, 4320, 270, 135, 270, 4320, 270, 4320, 135, 4320, 4320, 4320, 4320, 135, 270, 270, 270, 4320, 270, 135, 270, 135, 4320, 270, 4320, 4320, 270, 4320, 4320, 135, 135, 4320, 270, 270, 135, 135, 135, 270, 135, 270, 135, 4320, 135, 270, 4320, 135, 4320, 270, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 4320, 4320, 270, 135, 135, 4320, 270, 270, 135, 135, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 135, 270, 270, 270, 270, 135, 135, 4320, 135, 4320, 135, 135, 135, 270, 270, 4320, 135, 135, 4320, 135, 4320, 270, 135, 4320, 270, 270, 135, 4320, 4320, 4320, 135, 270, 4320, 135, 4320, 270, 270, 4320, 4320, 135, 270, 4320, 135, 270, 270, 135, 270, 135, 270, 4320, 4320, 270, 135, 4320, 135, 4320, 270, 270, 270, 270, 270, 135, 135, 4320, 135, 4320, 135, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 135, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 135, 135, 135, 135, 135, 270, 135, 135, 270, 4320, 4320, 135, 135, 4320, 135, 135, 135, 270, 135, 270, 4320, 4320, 270, 270, 135, 4320, 270, 4320, 135, 270, 270, 135, 135, 270, 135, 4320, 4320, 135, 4320, 4320, 135, 270, 4320, 135, 135, 270, 270, 135, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 4320, 270, 270, 270, 4320, 135, 270, 270, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 270, 135, 4320, 4320, 4320, 270, 135, 4320, 4320, 270, 270, 4320, 4320, 135, 4320, 4320, 270, 135, 4320, 270, 270, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 270, 4320, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 4320, 135, 135, 135, 270, 135, 270, 270, 135, 4320, 270, 4320, 135, 4320, 135, 270, 270, 270, 270, 135, 270, 4320, 4320, 135, 4320, 4320, 135, 4320, 270, 4320, 270, 270, 270, 135, 270, 135, 135, 4320, 135, 270, 135, 135, 270, 4320, 270, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 604800 . Total input tokens: 134855028 . Total output tokens: 120795858
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 77.13473928300664,
    "estimated_duration": 3600.207142749333,
    "input_throughput": 5308.071242091461,
    "output_throughput": 4683.627172386295,
    "total_throughput": 9991.698414477756,
    "itl": 182.0347150918235,
    "ttft": 1712540.9132849735,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 596,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9438737218640794,
    "arrivals": 200966,
    "finished_requests": 76942,
    "scheduler_time": 130.21080753496972
}
#Debug simulation 
Total elapsed time: 77.13484504306689. Arrivals time: 0.3017160031013191 Scheduler time: 76.70054891332984 Scheduler overhead time: 0.05089695332571864 Adapter cache time: 0.016833784990012646 Engine time: 0.04649361502379179 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-32/adapters_384_slots_96_rate_0.4-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-32/adapters_384_slots_96_rate_0.4-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 270, 135, 4320, 4320, 135, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 135, 4320, 135, 4320, 270, 270, 270, 135, 135, 270, 135, 4320, 135, 4320, 270, 4320, 270, 135, 270, 4320, 270, 4320, 135, 4320, 4320, 4320, 4320, 135, 270, 270, 270, 4320, 270, 135, 270, 135, 4320, 270, 4320, 4320, 270, 4320, 4320, 135, 135, 4320, 270, 270, 135, 135, 135, 270, 135, 270, 135, 4320, 135, 270, 4320, 135, 4320, 270, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 4320, 4320, 270, 135, 135, 4320, 270, 270, 135, 135, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 135, 270, 270, 270, 270, 135, 135, 4320, 135, 4320, 135, 135, 135, 270, 270, 4320, 135, 135, 4320, 135, 4320, 270, 135, 4320, 270, 270, 135, 4320, 4320, 4320, 135, 270, 4320, 135, 4320, 270, 270, 4320, 4320, 135, 270, 4320, 135, 270, 270, 135, 270, 135, 270, 4320, 4320, 270, 135, 4320, 135, 4320, 270, 270, 270, 270, 270, 135, 135, 4320, 135, 4320, 135, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 135, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 135, 135, 135, 135, 135, 270, 135, 135, 270, 4320, 4320, 135, 135, 4320, 135, 135, 135, 270, 135, 270, 4320, 4320, 270, 270, 135, 4320, 270, 4320, 135, 270, 270, 135, 135, 270, 135, 4320, 4320, 135, 4320, 4320, 135, 270, 4320, 135, 135, 270, 270, 135, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 4320, 270, 270, 270, 4320, 135, 270, 270, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 270, 135, 4320, 4320, 4320, 270, 135, 4320, 4320, 270, 270, 4320, 4320, 135, 4320, 4320, 270, 135, 4320, 270, 270, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 270, 4320, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 4320, 135, 135, 135, 270, 135, 270, 270, 135, 4320, 270, 4320, 135, 4320, 135, 270, 270, 270, 270, 135, 270, 4320, 4320, 135, 4320, 4320, 135, 4320, 270, 4320, 270, 270, 270, 135, 270, 135, 135, 4320, 135, 270, 135, 135, 270, 4320, 270, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 604800 . Total input tokens: 134855028 . Total output tokens: 120795858
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 49.71057610819116,
    "estimated_duration": 3600.0240900048475,
    "input_throughput": 5288.848219894651,
    "output_throughput": 4674.930383584555,
    "total_throughput": 9963.778603479206,
    "itl": 180.348911574372,
    "ttft": 1719104.888399811,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 828,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7041707387938962,
    "arrivals": 200966,
    "finished_requests": 76693,
    "scheduler_time": 130.55214421680483
}
#Debug simulation 
Total elapsed time: 49.71068843500689. Arrivals time: 0.2816081391647458 Scheduler time: 49.30167370522395 Scheduler overhead time: 0.04678409127518535 Adapter cache time: 0.019677213858813047 Engine time: 0.043040686286985874 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-16/adapters_384_slots_96_rate_0.4-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-16/adapters_384_slots_96_rate_0.4-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 270, 135, 4320, 4320, 135, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 135, 4320, 135, 4320, 270, 270, 270, 135, 135, 270, 135, 4320, 135, 4320, 270, 4320, 270, 135, 270, 4320, 270, 4320, 135, 4320, 4320, 4320, 4320, 135, 270, 270, 270, 4320, 270, 135, 270, 135, 4320, 270, 4320, 4320, 270, 4320, 4320, 135, 135, 4320, 270, 270, 135, 135, 135, 270, 135, 270, 135, 4320, 135, 270, 4320, 135, 4320, 270, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 4320, 4320, 270, 135, 135, 4320, 270, 270, 135, 135, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 135, 270, 270, 270, 270, 135, 135, 4320, 135, 4320, 135, 135, 135, 270, 270, 4320, 135, 135, 4320, 135, 4320, 270, 135, 4320, 270, 270, 135, 4320, 4320, 4320, 135, 270, 4320, 135, 4320, 270, 270, 4320, 4320, 135, 270, 4320, 135, 270, 270, 135, 270, 135, 270, 4320, 4320, 270, 135, 4320, 135, 4320, 270, 270, 270, 270, 270, 135, 135, 4320, 135, 4320, 135, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 135, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 135, 135, 135, 135, 135, 270, 135, 135, 270, 4320, 4320, 135, 135, 4320, 135, 135, 135, 270, 135, 270, 4320, 4320, 270, 270, 135, 4320, 270, 4320, 135, 270, 270, 135, 135, 270, 135, 4320, 4320, 135, 4320, 4320, 135, 270, 4320, 135, 135, 270, 270, 135, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 4320, 270, 270, 270, 4320, 135, 270, 270, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 270, 135, 4320, 4320, 4320, 270, 135, 4320, 4320, 270, 270, 4320, 4320, 135, 4320, 4320, 270, 135, 4320, 270, 270, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 270, 4320, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 4320, 135, 135, 135, 270, 135, 270, 270, 135, 4320, 270, 4320, 135, 4320, 135, 270, 270, 270, 270, 135, 270, 4320, 4320, 135, 4320, 4320, 135, 4320, 270, 4320, 270, 270, 270, 135, 270, 135, 135, 4320, 135, 270, 135, 135, 270, 4320, 270, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 604800 . Total input tokens: 134855028 . Total output tokens: 120795858
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 77.42089023487642,
    "estimated_duration": 3600.070447659729,
    "input_throughput": 5308.393898909139,
    "output_throughput": 4683.885008684083,
    "total_throughput": 9992.278907593223,
    "itl": 182.03734009361793,
    "ttft": 1712718.817640285,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 610,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9085099108074666,
    "arrivals": 200966,
    "finished_requests": 76950,
    "scheduler_time": 130.20643404811804
}
#Debug simulation 
Total elapsed time: 77.42100107483566. Arrivals time: 0.29918444342911243 Scheduler time: 76.98903207061812 Scheduler overhead time: 0.050689836498349905 Adapter cache time: 0.016976754646748304 Engine time: 0.04636452626436949 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-32/adapters_384_slots_96_rate_0.4-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-32/adapters_384_slots_96_rate_0.4-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 270, 135, 4320, 4320, 135, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 135, 4320, 135, 4320, 270, 270, 270, 135, 135, 270, 135, 4320, 135, 4320, 270, 4320, 270, 135, 270, 4320, 270, 4320, 135, 4320, 4320, 4320, 4320, 135, 270, 270, 270, 4320, 270, 135, 270, 135, 4320, 270, 4320, 4320, 270, 4320, 4320, 135, 135, 4320, 270, 270, 135, 135, 135, 270, 135, 270, 135, 4320, 135, 270, 4320, 135, 4320, 270, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 4320, 4320, 270, 135, 135, 4320, 270, 270, 135, 135, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 135, 270, 270, 270, 270, 135, 135, 4320, 135, 4320, 135, 135, 135, 270, 270, 4320, 135, 135, 4320, 135, 4320, 270, 135, 4320, 270, 270, 135, 4320, 4320, 4320, 135, 270, 4320, 135, 4320, 270, 270, 4320, 4320, 135, 270, 4320, 135, 270, 270, 135, 270, 135, 270, 4320, 4320, 270, 135, 4320, 135, 4320, 270, 270, 270, 270, 270, 135, 135, 4320, 135, 4320, 135, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 135, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 135, 135, 135, 135, 135, 270, 135, 135, 270, 4320, 4320, 135, 135, 4320, 135, 135, 135, 270, 135, 270, 4320, 4320, 270, 270, 135, 4320, 270, 4320, 135, 270, 270, 135, 135, 270, 135, 4320, 4320, 135, 4320, 4320, 135, 270, 4320, 135, 135, 270, 270, 135, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 4320, 270, 270, 270, 4320, 135, 270, 270, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 270, 135, 4320, 4320, 4320, 270, 135, 4320, 4320, 270, 270, 4320, 4320, 135, 4320, 4320, 270, 135, 4320, 270, 270, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 270, 4320, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 4320, 135, 135, 135, 270, 135, 270, 270, 135, 4320, 270, 4320, 135, 4320, 135, 270, 270, 270, 270, 135, 270, 4320, 4320, 135, 4320, 4320, 135, 4320, 270, 4320, 270, 270, 270, 135, 270, 135, 135, 4320, 135, 270, 135, 135, 270, 4320, 270, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 604800 . Total input tokens: 134855028 . Total output tokens: 120795858
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 49.96426374465227,
    "estimated_duration": 3600.022502586043,
    "input_throughput": 5291.564979473263,
    "output_throughput": 4675.426608558459,
    "total_throughput": 9966.991588031722,
    "itl": 180.3227369701651,
    "ttft": 1718840.7951807957,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 825,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.728444963376972,
    "arrivals": 200966,
    "finished_requests": 76683,
    "scheduler_time": 130.56922707972424
}
#Debug simulation 
Total elapsed time: 49.96436785394326. Arrivals time: 0.287558794952929 Scheduler time: 49.54510166030377 Scheduler overhead time: 0.04862890159711242 Adapter cache time: 0.020310234744101763 Engine time: 0.044878087006509304 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-16/adapters_384_slots_96_rate_0.4-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-16/adapters_384_slots_96_rate_0.4-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 270, 135, 4320, 4320, 135, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 135, 4320, 135, 4320, 270, 270, 270, 135, 135, 270, 135, 4320, 135, 4320, 270, 4320, 270, 135, 270, 4320, 270, 4320, 135, 4320, 4320, 4320, 4320, 135, 270, 270, 270, 4320, 270, 135, 270, 135, 4320, 270, 4320, 4320, 270, 4320, 4320, 135, 135, 4320, 270, 270, 135, 135, 135, 270, 135, 270, 135, 4320, 135, 270, 4320, 135, 4320, 270, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 4320, 4320, 270, 135, 135, 4320, 270, 270, 135, 135, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 135, 270, 270, 270, 270, 135, 135, 4320, 135, 4320, 135, 135, 135, 270, 270, 4320, 135, 135, 4320, 135, 4320, 270, 135, 4320, 270, 270, 135, 4320, 4320, 4320, 135, 270, 4320, 135, 4320, 270, 270, 4320, 4320, 135, 270, 4320, 135, 270, 270, 135, 270, 135, 270, 4320, 4320, 270, 135, 4320, 135, 4320, 270, 270, 270, 270, 270, 135, 135, 4320, 135, 4320, 135, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 135, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 135, 135, 135, 135, 135, 270, 135, 135, 270, 4320, 4320, 135, 135, 4320, 135, 135, 135, 270, 135, 270, 4320, 4320, 270, 270, 135, 4320, 270, 4320, 135, 270, 270, 135, 135, 270, 135, 4320, 4320, 135, 4320, 4320, 135, 270, 4320, 135, 135, 270, 270, 135, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 4320, 270, 270, 270, 4320, 135, 270, 270, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 270, 135, 4320, 4320, 4320, 270, 135, 4320, 4320, 270, 270, 4320, 4320, 135, 4320, 4320, 270, 135, 4320, 270, 270, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 270, 4320, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 4320, 135, 135, 135, 270, 135, 270, 270, 135, 4320, 270, 4320, 135, 4320, 135, 270, 270, 270, 270, 135, 270, 4320, 4320, 135, 4320, 4320, 135, 4320, 270, 4320, 270, 270, 270, 135, 270, 135, 135, 4320, 135, 270, 135, 135, 270, 4320, 270, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 604800 . Total input tokens: 134855028 . Total output tokens: 120795858
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 78.84699779609218,
    "estimated_duration": 3600.063436353238,
    "input_throughput": 5308.13757530826,
    "output_throughput": 4683.247475516345,
    "total_throughput": 9991.385050824605,
    "itl": 182.01718017861091,
    "ttft": 1712859.74346575,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 610,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8239306798902992,
    "arrivals": 200966,
    "finished_requests": 76942,
    "scheduler_time": 130.2122029353902
}
#Debug simulation 
Total elapsed time: 78.8471111129038. Arrivals time: 0.3145682015456259 Scheduler time: 78.39355553127825 Scheduler overhead time: 0.05461224773898721 Adapter cache time: 0.01755609130486846 Engine time: 0.04756011255085468 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-32/adapters_384_slots_96_rate_0.4-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-32/adapters_384_slots_96_rate_0.4-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 270, 135, 4320, 4320, 135, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 135, 4320, 135, 4320, 270, 270, 270, 135, 135, 270, 135, 4320, 135, 4320, 270, 4320, 270, 135, 270, 4320, 270, 4320, 135, 4320, 4320, 4320, 4320, 135, 270, 270, 270, 4320, 270, 135, 270, 135, 4320, 270, 4320, 4320, 270, 4320, 4320, 135, 135, 4320, 270, 270, 135, 135, 135, 270, 135, 270, 135, 4320, 135, 270, 4320, 135, 4320, 270, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 4320, 4320, 270, 135, 135, 4320, 270, 270, 135, 135, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 135, 270, 270, 270, 270, 135, 135, 4320, 135, 4320, 135, 135, 135, 270, 270, 4320, 135, 135, 4320, 135, 4320, 270, 135, 4320, 270, 270, 135, 4320, 4320, 4320, 135, 270, 4320, 135, 4320, 270, 270, 4320, 4320, 135, 270, 4320, 135, 270, 270, 135, 270, 135, 270, 4320, 4320, 270, 135, 4320, 135, 4320, 270, 270, 270, 270, 270, 135, 135, 4320, 135, 4320, 135, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 135, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 135, 135, 135, 135, 135, 270, 135, 135, 270, 4320, 4320, 135, 135, 4320, 135, 135, 135, 270, 135, 270, 4320, 4320, 270, 270, 135, 4320, 270, 4320, 135, 270, 270, 135, 135, 270, 135, 4320, 4320, 135, 4320, 4320, 135, 270, 4320, 135, 135, 270, 270, 135, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 4320, 270, 270, 270, 4320, 135, 270, 270, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 270, 135, 4320, 4320, 4320, 270, 135, 4320, 4320, 270, 270, 4320, 4320, 135, 4320, 4320, 270, 135, 4320, 270, 270, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 270, 4320, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 4320, 135, 135, 135, 270, 135, 270, 270, 135, 4320, 270, 4320, 135, 4320, 135, 270, 270, 270, 270, 135, 270, 4320, 4320, 135, 4320, 4320, 135, 4320, 270, 4320, 270, 270, 270, 135, 270, 135, 135, 4320, 135, 270, 135, 135, 270, 4320, 270, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 604800 . Total input tokens: 134855028 . Total output tokens: 120795858
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 51.10130531108007,
    "estimated_duration": 3600.0667497570266,
    "input_throughput": 5291.499942684589,
    "output_throughput": 4675.369144512665,
    "total_throughput": 9966.869087197254,
    "itl": 180.3244080093457,
    "ttft": 1718857.3280111577,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 825,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7627757470682464,
    "arrivals": 200966,
    "finished_requests": 76683,
    "scheduler_time": 130.56875682486083
}
#Debug simulation 
Total elapsed time: 51.10142465215176. Arrivals time: 0.30159724736586213 Scheduler time: 50.66796245472506 Scheduler overhead time: 0.04822401609271765 Adapter cache time: 0.020345944445580244 Engine time: 0.04508641641587019 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_384_slots_96_rate_0.4-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_384_slots_96_rate_0.4-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 270, 66, 4320, 4320, 66, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 66, 4320, 66, 4320, 270, 270, 270, 66, 66, 270, 66, 4320, 66, 4320, 270, 4320, 270, 66, 270, 4320, 270, 4320, 66, 4320, 4320, 4320, 4320, 66, 270, 270, 270, 4320, 270, 66, 270, 66, 4320, 270, 4320, 4320, 270, 4320, 4320, 66, 66, 4320, 270, 270, 66, 66, 66, 270, 66, 270, 66, 4320, 66, 270, 4320, 66, 4320, 270, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 4320, 4320, 270, 66, 66, 4320, 270, 270, 66, 66, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 66, 270, 270, 270, 270, 66, 66, 4320, 66, 4320, 66, 66, 66, 270, 270, 4320, 66, 66, 4320, 66, 4320, 270, 66, 4320, 270, 270, 66, 4320, 4320, 4320, 66, 270, 4320, 66, 4320, 270, 270, 4320, 4320, 66, 270, 4320, 66, 270, 270, 66, 270, 66, 270, 4320, 4320, 270, 66, 4320, 66, 4320, 270, 270, 270, 270, 270, 66, 66, 4320, 66, 4320, 66, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 66, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 66, 66, 66, 66, 66, 270, 66, 66, 270, 4320, 4320, 66, 66, 4320, 66, 66, 66, 270, 66, 270, 4320, 4320, 270, 270, 66, 4320, 270, 4320, 66, 270, 270, 66, 66, 270, 66, 4320, 4320, 66, 4320, 4320, 66, 270, 4320, 66, 66, 270, 270, 66, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 4320, 270, 270, 270, 4320, 66, 270, 270, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 270, 66, 4320, 4320, 4320, 270, 66, 4320, 4320, 270, 270, 4320, 4320, 66, 4320, 4320, 270, 66, 4320, 270, 270, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 270, 4320, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 4320, 66, 66, 66, 270, 66, 270, 270, 66, 4320, 270, 4320, 66, 4320, 66, 270, 270, 270, 270, 66, 270, 4320, 4320, 66, 4320, 4320, 66, 4320, 270, 4320, 270, 270, 270, 66, 270, 66, 66, 4320, 66, 270, 66, 66, 270, 4320, 270, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 595968 . Total input tokens: 132907362 . Total output tokens: 119020776
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 83.23724415479228,
    "estimated_duration": 3600.0197632784384,
    "input_throughput": 5313.820828188723,
    "output_throughput": 4689.609254985146,
    "total_throughput": 10003.43008317387,
    "itl": 182.027131624489,
    "ttft": 1698355.3550957667,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 601,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.839353134103613,
    "arrivals": 198105,
    "finished_requests": 77216,
    "scheduler_time": 130.1374052177411
}
#Debug simulation 
Total elapsed time: 83.23735726997256. Arrivals time: 0.3194182016886771 Scheduler time: 82.77931130770594 Scheduler overhead time: 0.053794159553945065 Adapter cache time: 0.017293067183345556 Engine time: 0.04912212723866105 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_384_slots_96_rate_0.4-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_384_slots_96_rate_0.4-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 270, 66, 4320, 4320, 66, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 66, 4320, 66, 4320, 270, 270, 270, 66, 66, 270, 66, 4320, 66, 4320, 270, 4320, 270, 66, 270, 4320, 270, 4320, 66, 4320, 4320, 4320, 4320, 66, 270, 270, 270, 4320, 270, 66, 270, 66, 4320, 270, 4320, 4320, 270, 4320, 4320, 66, 66, 4320, 270, 270, 66, 66, 66, 270, 66, 270, 66, 4320, 66, 270, 4320, 66, 4320, 270, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 4320, 4320, 270, 66, 66, 4320, 270, 270, 66, 66, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 66, 270, 270, 270, 270, 66, 66, 4320, 66, 4320, 66, 66, 66, 270, 270, 4320, 66, 66, 4320, 66, 4320, 270, 66, 4320, 270, 270, 66, 4320, 4320, 4320, 66, 270, 4320, 66, 4320, 270, 270, 4320, 4320, 66, 270, 4320, 66, 270, 270, 66, 270, 66, 270, 4320, 4320, 270, 66, 4320, 66, 4320, 270, 270, 270, 270, 270, 66, 66, 4320, 66, 4320, 66, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 66, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 66, 66, 66, 66, 66, 270, 66, 66, 270, 4320, 4320, 66, 66, 4320, 66, 66, 66, 270, 66, 270, 4320, 4320, 270, 270, 66, 4320, 270, 4320, 66, 270, 270, 66, 66, 270, 66, 4320, 4320, 66, 4320, 4320, 66, 270, 4320, 66, 66, 270, 270, 66, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 4320, 270, 270, 270, 4320, 66, 270, 270, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 270, 66, 4320, 4320, 4320, 270, 66, 4320, 4320, 270, 270, 4320, 4320, 66, 4320, 4320, 270, 66, 4320, 270, 270, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 270, 4320, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 4320, 66, 66, 66, 270, 66, 270, 270, 66, 4320, 270, 4320, 66, 4320, 66, 270, 270, 270, 270, 66, 270, 4320, 4320, 66, 4320, 4320, 66, 4320, 270, 4320, 270, 270, 270, 66, 270, 66, 66, 4320, 66, 270, 66, 66, 270, 4320, 270, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 595968 . Total input tokens: 132907362 . Total output tokens: 119020776
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 82.89636910799891,
    "estimated_duration": 3600.051671171276,
    "input_throughput": 5312.8890213337245,
    "output_throughput": 4688.317152544837,
    "total_throughput": 10001.206173878561,
    "itl": 182.04515737338482,
    "ttft": 1698397.5105530042,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 611,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9899502622429324,
    "arrivals": 198105,
    "finished_requests": 77201,
    "scheduler_time": 130.13152128258136
}
#Debug simulation 
Total elapsed time: 82.89648091606796. Arrivals time: 0.3143302481621504 Scheduler time: 82.44391037197784 Scheduler overhead time: 0.053975789807736874 Adapter cache time: 0.017319746781140566 Engine time: 0.048483702819794416 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-32/adapters_384_slots_96_rate_0.4-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-32/adapters_384_slots_96_rate_0.4-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 270, 66, 4320, 4320, 66, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 66, 4320, 66, 4320, 270, 270, 270, 66, 66, 270, 66, 4320, 66, 4320, 270, 4320, 270, 66, 270, 4320, 270, 4320, 66, 4320, 4320, 4320, 4320, 66, 270, 270, 270, 4320, 270, 66, 270, 66, 4320, 270, 4320, 4320, 270, 4320, 4320, 66, 66, 4320, 270, 270, 66, 66, 66, 270, 66, 270, 66, 4320, 66, 270, 4320, 66, 4320, 270, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 4320, 4320, 270, 66, 66, 4320, 270, 270, 66, 66, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 66, 270, 270, 270, 270, 66, 66, 4320, 66, 4320, 66, 66, 66, 270, 270, 4320, 66, 66, 4320, 66, 4320, 270, 66, 4320, 270, 270, 66, 4320, 4320, 4320, 66, 270, 4320, 66, 4320, 270, 270, 4320, 4320, 66, 270, 4320, 66, 270, 270, 66, 270, 66, 270, 4320, 4320, 270, 66, 4320, 66, 4320, 270, 270, 270, 270, 270, 66, 66, 4320, 66, 4320, 66, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 66, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 66, 66, 66, 66, 66, 270, 66, 66, 270, 4320, 4320, 66, 66, 4320, 66, 66, 66, 270, 66, 270, 4320, 4320, 270, 270, 66, 4320, 270, 4320, 66, 270, 270, 66, 66, 270, 66, 4320, 4320, 66, 4320, 4320, 66, 270, 4320, 66, 66, 270, 270, 66, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 4320, 270, 270, 270, 4320, 66, 270, 270, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 270, 66, 4320, 4320, 4320, 270, 66, 4320, 4320, 270, 270, 4320, 4320, 66, 4320, 4320, 270, 66, 4320, 270, 270, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 270, 4320, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 4320, 66, 66, 66, 270, 66, 270, 270, 66, 4320, 270, 4320, 66, 4320, 66, 270, 270, 270, 270, 66, 270, 4320, 4320, 66, 4320, 4320, 66, 4320, 270, 4320, 270, 270, 270, 66, 270, 66, 66, 4320, 66, 270, 66, 66, 270, 4320, 270, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 595968 . Total input tokens: 132907362 . Total output tokens: 119020776
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 81.84815033711493,
    "estimated_duration": 3600.0767569009286,
    "input_throughput": 5298.900631335891,
    "output_throughput": 4675.848637874818,
    "total_throughput": 9974.74926921071,
    "itl": 180.14800641268715,
    "ttft": 1701106.8092553692,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 611,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9941517669148867,
    "arrivals": 198105,
    "finished_requests": 77009,
    "scheduler_time": 130.6200419533304
}
#Debug simulation 
Total elapsed time: 81.84826071513817. Arrivals time: 0.31672819005325437 Scheduler time: 81.39251242671162 Scheduler overhead time: 0.0543298264965415 Adapter cache time: 0.016725650522857904 Engine time: 0.04891093075275421 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_384_slots_96_rate_0.4-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_384_slots_96_rate_0.4-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 270, 66, 4320, 4320, 66, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 66, 4320, 66, 4320, 270, 270, 270, 66, 66, 270, 66, 4320, 66, 4320, 270, 4320, 270, 66, 270, 4320, 270, 4320, 66, 4320, 4320, 4320, 4320, 66, 270, 270, 270, 4320, 270, 66, 270, 66, 4320, 270, 4320, 4320, 270, 4320, 4320, 66, 66, 4320, 270, 270, 66, 66, 66, 270, 66, 270, 66, 4320, 66, 270, 4320, 66, 4320, 270, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 4320, 4320, 270, 66, 66, 4320, 270, 270, 66, 66, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 66, 270, 270, 270, 270, 66, 66, 4320, 66, 4320, 66, 66, 66, 270, 270, 4320, 66, 66, 4320, 66, 4320, 270, 66, 4320, 270, 270, 66, 4320, 4320, 4320, 66, 270, 4320, 66, 4320, 270, 270, 4320, 4320, 66, 270, 4320, 66, 270, 270, 66, 270, 66, 270, 4320, 4320, 270, 66, 4320, 66, 4320, 270, 270, 270, 270, 270, 66, 66, 4320, 66, 4320, 66, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 66, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 66, 66, 66, 66, 66, 270, 66, 66, 270, 4320, 4320, 66, 66, 4320, 66, 66, 66, 270, 66, 270, 4320, 4320, 270, 270, 66, 4320, 270, 4320, 66, 270, 270, 66, 66, 270, 66, 4320, 4320, 66, 4320, 4320, 66, 270, 4320, 66, 66, 270, 270, 66, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 4320, 270, 270, 270, 4320, 66, 270, 270, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 270, 66, 4320, 4320, 4320, 270, 66, 4320, 4320, 270, 270, 4320, 4320, 66, 4320, 4320, 270, 66, 4320, 270, 270, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 270, 4320, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 4320, 66, 66, 66, 270, 66, 270, 270, 66, 4320, 270, 4320, 66, 4320, 66, 270, 270, 270, 270, 66, 270, 4320, 4320, 66, 4320, 4320, 66, 4320, 270, 4320, 270, 270, 270, 66, 270, 66, 66, 4320, 66, 270, 66, 66, 270, 4320, 270, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 595968 . Total input tokens: 132907362 . Total output tokens: 119020776
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 83.08537010382861,
    "estimated_duration": 3600.1837886180974,
    "input_throughput": 5314.232862357217,
    "output_throughput": 4690.35387953947,
    "total_throughput": 10004.586741896686,
    "itl": 182.0269426806101,
    "ttft": 1698373.0567621044,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 605,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8882479201932316,
    "arrivals": 198105,
    "finished_requests": 77228,
    "scheduler_time": 130.14129267347022
}
#Debug simulation 
Total elapsed time: 83.08548402925953. Arrivals time: 0.31695091631263494 Scheduler time: 82.62880637776107 Scheduler overhead time: 0.054673164151608944 Adapter cache time: 0.017218337394297123 Engine time: 0.049138928297907114 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-32/adapters_384_slots_96_rate_0.4-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-32/adapters_384_slots_96_rate_0.4-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 270, 66, 4320, 4320, 66, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 66, 4320, 66, 4320, 270, 270, 270, 66, 66, 270, 66, 4320, 66, 4320, 270, 4320, 270, 66, 270, 4320, 270, 4320, 66, 4320, 4320, 4320, 4320, 66, 270, 270, 270, 4320, 270, 66, 270, 66, 4320, 270, 4320, 4320, 270, 4320, 4320, 66, 66, 4320, 270, 270, 66, 66, 66, 270, 66, 270, 66, 4320, 66, 270, 4320, 66, 4320, 270, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 4320, 4320, 270, 66, 66, 4320, 270, 270, 66, 66, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 66, 270, 270, 270, 270, 66, 66, 4320, 66, 4320, 66, 66, 66, 270, 270, 4320, 66, 66, 4320, 66, 4320, 270, 66, 4320, 270, 270, 66, 4320, 4320, 4320, 66, 270, 4320, 66, 4320, 270, 270, 4320, 4320, 66, 270, 4320, 66, 270, 270, 66, 270, 66, 270, 4320, 4320, 270, 66, 4320, 66, 4320, 270, 270, 270, 270, 270, 66, 66, 4320, 66, 4320, 66, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 66, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 66, 66, 66, 66, 66, 270, 66, 66, 270, 4320, 4320, 66, 66, 4320, 66, 66, 66, 270, 66, 270, 4320, 4320, 270, 270, 66, 4320, 270, 4320, 66, 270, 270, 66, 66, 270, 66, 4320, 4320, 66, 4320, 4320, 66, 270, 4320, 66, 66, 270, 270, 66, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 4320, 270, 270, 270, 4320, 66, 270, 270, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 270, 66, 4320, 4320, 4320, 270, 66, 4320, 4320, 270, 270, 4320, 4320, 66, 4320, 4320, 270, 66, 4320, 270, 270, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 270, 4320, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 4320, 66, 66, 66, 270, 66, 270, 270, 66, 4320, 270, 4320, 66, 4320, 66, 270, 270, 270, 270, 66, 270, 4320, 4320, 66, 4320, 4320, 66, 4320, 270, 4320, 270, 270, 270, 66, 270, 66, 66, 4320, 66, 270, 66, 66, 270, 4320, 270, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 595968 . Total input tokens: 132907362 . Total output tokens: 119020776
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 81.88502286793664,
    "estimated_duration": 3600.1031197197235,
    "input_throughput": 5298.861828570384,
    "output_throughput": 4675.814397591623,
    "total_throughput": 9974.676226162008,
    "itl": 180.14834199323033,
    "ttft": 1701114.1791917013,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 611,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.019679785557095,
    "arrivals": 198105,
    "finished_requests": 77009,
    "scheduler_time": 130.62032055449316
}
#Debug simulation 
Total elapsed time: 81.88513065315783. Arrivals time: 0.3103978605940938 Scheduler time: 81.43718768656254 Scheduler overhead time: 0.053796864580363035 Adapter cache time: 0.016572786960750818 Engine time: 0.04864624561741948 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_384_slots_96_rate_0.4-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_384_slots_96_rate_0.4-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 270, 66, 4320, 4320, 66, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 66, 4320, 66, 4320, 270, 270, 270, 66, 66, 270, 66, 4320, 66, 4320, 270, 4320, 270, 66, 270, 4320, 270, 4320, 66, 4320, 4320, 4320, 4320, 66, 270, 270, 270, 4320, 270, 66, 270, 66, 4320, 270, 4320, 4320, 270, 4320, 4320, 66, 66, 4320, 270, 270, 66, 66, 66, 270, 66, 270, 66, 4320, 66, 270, 4320, 66, 4320, 270, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 4320, 4320, 270, 66, 66, 4320, 270, 270, 66, 66, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 66, 270, 270, 270, 270, 66, 66, 4320, 66, 4320, 66, 66, 66, 270, 270, 4320, 66, 66, 4320, 66, 4320, 270, 66, 4320, 270, 270, 66, 4320, 4320, 4320, 66, 270, 4320, 66, 4320, 270, 270, 4320, 4320, 66, 270, 4320, 66, 270, 270, 66, 270, 66, 270, 4320, 4320, 270, 66, 4320, 66, 4320, 270, 270, 270, 270, 270, 66, 66, 4320, 66, 4320, 66, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 66, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 66, 66, 66, 66, 66, 270, 66, 66, 270, 4320, 4320, 66, 66, 4320, 66, 66, 66, 270, 66, 270, 4320, 4320, 270, 270, 66, 4320, 270, 4320, 66, 270, 270, 66, 66, 270, 66, 4320, 4320, 66, 4320, 4320, 66, 270, 4320, 66, 66, 270, 270, 66, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 4320, 270, 270, 270, 4320, 66, 270, 270, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 270, 66, 4320, 4320, 4320, 270, 66, 4320, 4320, 270, 270, 4320, 4320, 66, 4320, 4320, 270, 66, 4320, 270, 270, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 270, 4320, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 4320, 66, 66, 66, 270, 66, 270, 270, 66, 4320, 270, 4320, 66, 4320, 66, 270, 270, 270, 270, 66, 270, 4320, 4320, 66, 4320, 4320, 66, 4320, 270, 4320, 270, 270, 270, 66, 270, 66, 66, 4320, 66, 270, 66, 66, 270, 4320, 270, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 595968 . Total input tokens: 132907362 . Total output tokens: 119020776
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 83.17644692072645,
    "estimated_duration": 3600.1647304240305,
    "input_throughput": 5313.7774053318935,
    "output_throughput": 4689.962894562136,
    "total_throughput": 10003.74029989403,
    "itl": 182.02472562792846,
    "ttft": 1698389.5576331445,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 603,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8030003278259847,
    "arrivals": 198105,
    "finished_requests": 77223,
    "scheduler_time": 130.14326620731663
}
#Debug simulation 
Total elapsed time: 83.17655778769404. Arrivals time: 0.31682309973984957 Scheduler time: 82.71953324927017 Scheduler overhead time: 0.05567078897729516 Adapter cache time: 0.016799893230199814 Engine time: 0.04914084495976567 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-32/adapters_384_slots_96_rate_0.4-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-32/adapters_384_slots_96_rate_0.4-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 270, 66, 4320, 4320, 66, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 66, 4320, 66, 4320, 270, 270, 270, 66, 66, 270, 66, 4320, 66, 4320, 270, 4320, 270, 66, 270, 4320, 270, 4320, 66, 4320, 4320, 4320, 4320, 66, 270, 270, 270, 4320, 270, 66, 270, 66, 4320, 270, 4320, 4320, 270, 4320, 4320, 66, 66, 4320, 270, 270, 66, 66, 66, 270, 66, 270, 66, 4320, 66, 270, 4320, 66, 4320, 270, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 4320, 4320, 270, 66, 66, 4320, 270, 270, 66, 66, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 66, 270, 270, 270, 270, 66, 66, 4320, 66, 4320, 66, 66, 66, 270, 270, 4320, 66, 66, 4320, 66, 4320, 270, 66, 4320, 270, 270, 66, 4320, 4320, 4320, 66, 270, 4320, 66, 4320, 270, 270, 4320, 4320, 66, 270, 4320, 66, 270, 270, 66, 270, 66, 270, 4320, 4320, 270, 66, 4320, 66, 4320, 270, 270, 270, 270, 270, 66, 66, 4320, 66, 4320, 66, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 66, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 66, 66, 66, 66, 66, 270, 66, 66, 270, 4320, 4320, 66, 66, 4320, 66, 66, 66, 270, 66, 270, 4320, 4320, 270, 270, 66, 4320, 270, 4320, 66, 270, 270, 66, 66, 270, 66, 4320, 4320, 66, 4320, 4320, 66, 270, 4320, 66, 66, 270, 270, 66, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 4320, 270, 270, 270, 4320, 66, 270, 270, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 270, 66, 4320, 4320, 4320, 270, 66, 4320, 4320, 270, 270, 4320, 4320, 66, 4320, 4320, 270, 66, 4320, 270, 270, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 270, 4320, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 4320, 66, 66, 66, 270, 66, 270, 270, 66, 4320, 270, 4320, 66, 4320, 66, 270, 270, 270, 270, 66, 270, 4320, 4320, 66, 4320, 4320, 66, 4320, 270, 4320, 270, 270, 270, 66, 270, 66, 66, 4320, 66, 270, 66, 66, 270, 4320, 270, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 595968 . Total input tokens: 132907362 . Total output tokens: 119020776
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 82.2485324088484,
    "estimated_duration": 3600.092474280846,
    "input_throughput": 5299.267209465498,
    "output_throughput": 4675.921277095169,
    "total_throughput": 9975.188486560666,
    "itl": 180.17019875727567,
    "ttft": 1700795.5891560186,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 617,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.06490364719182,
    "arrivals": 198105,
    "finished_requests": 77008,
    "scheduler_time": 130.61523888929798
}
#Debug simulation 
Total elapsed time: 82.24863799195737. Arrivals time: 0.31460866099223495 Scheduler time: 81.79494345095009 Scheduler overhead time: 0.05399056011810899 Adapter cache time: 0.01750913541764021 Engine time: 0.048740881495177746 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_384_slots_96_rate_0.4-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_384_slots_96_rate_0.4-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 270, 33, 4320, 4320, 33, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 33, 4320, 33, 4320, 270, 270, 270, 33, 33, 270, 33, 4320, 33, 4320, 270, 4320, 270, 33, 270, 4320, 270, 4320, 33, 4320, 4320, 4320, 4320, 33, 270, 270, 270, 4320, 270, 33, 270, 33, 4320, 270, 4320, 4320, 270, 4320, 4320, 33, 33, 4320, 270, 270, 33, 33, 33, 270, 33, 270, 33, 4320, 33, 270, 4320, 33, 4320, 270, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 4320, 4320, 270, 33, 33, 4320, 270, 270, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 33, 270, 270, 270, 270, 33, 33, 4320, 33, 4320, 33, 33, 33, 270, 270, 4320, 33, 33, 4320, 33, 4320, 270, 33, 4320, 270, 270, 33, 4320, 4320, 4320, 33, 270, 4320, 33, 4320, 270, 270, 4320, 4320, 33, 270, 4320, 33, 270, 270, 33, 270, 33, 270, 4320, 4320, 270, 33, 4320, 33, 4320, 270, 270, 270, 270, 270, 33, 33, 4320, 33, 4320, 33, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 33, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 33, 33, 33, 33, 33, 270, 33, 33, 270, 4320, 4320, 33, 33, 4320, 33, 33, 33, 270, 33, 270, 4320, 4320, 270, 270, 33, 4320, 270, 4320, 33, 270, 270, 33, 33, 270, 33, 4320, 4320, 33, 4320, 4320, 33, 270, 4320, 33, 33, 270, 270, 33, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 4320, 270, 270, 270, 4320, 33, 270, 270, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 270, 33, 4320, 4320, 4320, 270, 33, 4320, 4320, 270, 270, 4320, 4320, 33, 4320, 4320, 270, 33, 4320, 270, 270, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 270, 4320, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 4320, 33, 33, 33, 270, 33, 270, 270, 33, 4320, 270, 4320, 33, 4320, 33, 270, 270, 270, 270, 33, 270, 4320, 4320, 33, 4320, 4320, 33, 4320, 270, 4320, 270, 270, 270, 33, 270, 33, 33, 4320, 33, 270, 33, 33, 270, 4320, 270, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 591744 . Total input tokens: 131952871 . Total output tokens: 118169411
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 65.0516576631926,
    "estimated_duration": 3600.1991427059247,
    "input_throughput": 5349.20187374009,
    "output_throughput": 4688.796183455694,
    "total_throughput": 10037.998057195784,
    "itl": 182.01379512044153,
    "ttft": 1690796.1198261143,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 795,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4330877564265876,
    "arrivals": 196756,
    "finished_requests": 77702,
    "scheduler_time": 129.8594026820589
}
#Debug simulation 
Total elapsed time: 65.05176945729181. Arrivals time: 0.3126000319607556 Scheduler time: 64.60173949459568 Scheduler overhead time: 0.052753111347556114 Adapter cache time: 0.019907931331545115 Engine time: 0.046740008518099785 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_384_slots_96_rate_0.4-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_384_slots_96_rate_0.4-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 270, 33, 4320, 4320, 33, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 33, 4320, 33, 4320, 270, 270, 270, 33, 33, 270, 33, 4320, 33, 4320, 270, 4320, 270, 33, 270, 4320, 270, 4320, 33, 4320, 4320, 4320, 4320, 33, 270, 270, 270, 4320, 270, 33, 270, 33, 4320, 270, 4320, 4320, 270, 4320, 4320, 33, 33, 4320, 270, 270, 33, 33, 33, 270, 33, 270, 33, 4320, 33, 270, 4320, 33, 4320, 270, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 4320, 4320, 270, 33, 33, 4320, 270, 270, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 33, 270, 270, 270, 270, 33, 33, 4320, 33, 4320, 33, 33, 33, 270, 270, 4320, 33, 33, 4320, 33, 4320, 270, 33, 4320, 270, 270, 33, 4320, 4320, 4320, 33, 270, 4320, 33, 4320, 270, 270, 4320, 4320, 33, 270, 4320, 33, 270, 270, 33, 270, 33, 270, 4320, 4320, 270, 33, 4320, 33, 4320, 270, 270, 270, 270, 270, 33, 33, 4320, 33, 4320, 33, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 33, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 33, 33, 33, 33, 33, 270, 33, 33, 270, 4320, 4320, 33, 33, 4320, 33, 33, 33, 270, 33, 270, 4320, 4320, 270, 270, 33, 4320, 270, 4320, 33, 270, 270, 33, 33, 270, 33, 4320, 4320, 33, 4320, 4320, 33, 270, 4320, 33, 33, 270, 270, 33, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 4320, 270, 270, 270, 4320, 33, 270, 270, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 270, 33, 4320, 4320, 4320, 270, 33, 4320, 4320, 270, 270, 4320, 4320, 33, 4320, 4320, 270, 33, 4320, 270, 270, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 270, 4320, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 4320, 33, 33, 33, 270, 33, 270, 270, 33, 4320, 270, 4320, 33, 4320, 33, 270, 270, 270, 270, 33, 270, 4320, 4320, 33, 4320, 4320, 33, 4320, 270, 4320, 270, 270, 270, 33, 270, 33, 33, 4320, 33, 270, 33, 33, 270, 4320, 270, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 591744 . Total input tokens: 131952871 . Total output tokens: 118169411
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 64.4595099594444,
    "estimated_duration": 3600.046955058907,
    "input_throughput": 5344.801676256235,
    "output_throughput": 4686.103323261781,
    "total_throughput": 10030.904999518016,
    "itl": 182.01774151648215,
    "ttft": 1691846.6216556367,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 818,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6705885663721767,
    "arrivals": 196756,
    "finished_requests": 77656,
    "scheduler_time": 129.84194934128087
}
#Debug simulation 
Total elapsed time: 64.459627549164. Arrivals time: 0.31252592615783215 Scheduler time: 64.00815250352025 Scheduler overhead time: 0.052681971807032824 Adapter cache time: 0.020280125085264444 Engine time: 0.0474444841966033 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-32/adapters_384_slots_96_rate_0.4-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-32/adapters_384_slots_96_rate_0.4-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 270, 33, 4320, 4320, 33, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 33, 4320, 33, 4320, 270, 270, 270, 33, 33, 270, 33, 4320, 33, 4320, 270, 4320, 270, 33, 270, 4320, 270, 4320, 33, 4320, 4320, 4320, 4320, 33, 270, 270, 270, 4320, 270, 33, 270, 33, 4320, 270, 4320, 4320, 270, 4320, 4320, 33, 33, 4320, 270, 270, 33, 33, 33, 270, 33, 270, 33, 4320, 33, 270, 4320, 33, 4320, 270, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 4320, 4320, 270, 33, 33, 4320, 270, 270, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 33, 270, 270, 270, 270, 33, 33, 4320, 33, 4320, 33, 33, 33, 270, 270, 4320, 33, 33, 4320, 33, 4320, 270, 33, 4320, 270, 270, 33, 4320, 4320, 4320, 33, 270, 4320, 33, 4320, 270, 270, 4320, 4320, 33, 270, 4320, 33, 270, 270, 33, 270, 33, 270, 4320, 4320, 270, 33, 4320, 33, 4320, 270, 270, 270, 270, 270, 33, 33, 4320, 33, 4320, 33, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 33, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 33, 33, 33, 33, 33, 270, 33, 33, 270, 4320, 4320, 33, 33, 4320, 33, 33, 33, 270, 33, 270, 4320, 4320, 270, 270, 33, 4320, 270, 4320, 33, 270, 270, 33, 33, 270, 33, 4320, 4320, 33, 4320, 4320, 33, 270, 4320, 33, 33, 270, 270, 33, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 4320, 270, 270, 270, 4320, 33, 270, 270, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 270, 33, 4320, 4320, 4320, 270, 33, 4320, 4320, 270, 270, 4320, 4320, 33, 4320, 4320, 270, 33, 4320, 270, 270, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 270, 4320, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 4320, 33, 33, 33, 270, 33, 270, 270, 33, 4320, 270, 4320, 33, 4320, 33, 270, 270, 270, 270, 33, 270, 4320, 4320, 33, 4320, 4320, 33, 4320, 270, 4320, 270, 270, 270, 33, 270, 33, 33, 4320, 33, 270, 33, 33, 270, 4320, 270, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 591744 . Total input tokens: 131952871 . Total output tokens: 118169411
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 63.86374241998419,
    "estimated_duration": 3600.0140846616773,
    "input_throughput": 5336.898286553675,
    "output_throughput": 4679.558358334368,
    "total_throughput": 10016.456644888041,
    "itl": 180.61479492916055,
    "ttft": 1693226.78527956,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 814,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6629104648902873,
    "arrivals": 196756,
    "finished_requests": 77544,
    "scheduler_time": 130.22008295756845
}
#Debug simulation 
Total elapsed time: 63.86385442502797. Arrivals time: 0.31103532621636987 Scheduler time: 63.4136236095801 Scheduler overhead time: 0.05287820752710104 Adapter cache time: 0.02035142108798027 Engine time: 0.04750386858358979 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_384_slots_96_rate_0.4-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_384_slots_96_rate_0.4-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 270, 33, 4320, 4320, 33, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 33, 4320, 33, 4320, 270, 270, 270, 33, 33, 270, 33, 4320, 33, 4320, 270, 4320, 270, 33, 270, 4320, 270, 4320, 33, 4320, 4320, 4320, 4320, 33, 270, 270, 270, 4320, 270, 33, 270, 33, 4320, 270, 4320, 4320, 270, 4320, 4320, 33, 33, 4320, 270, 270, 33, 33, 33, 270, 33, 270, 33, 4320, 33, 270, 4320, 33, 4320, 270, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 4320, 4320, 270, 33, 33, 4320, 270, 270, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 33, 270, 270, 270, 270, 33, 33, 4320, 33, 4320, 33, 33, 33, 270, 270, 4320, 33, 33, 4320, 33, 4320, 270, 33, 4320, 270, 270, 33, 4320, 4320, 4320, 33, 270, 4320, 33, 4320, 270, 270, 4320, 4320, 33, 270, 4320, 33, 270, 270, 33, 270, 33, 270, 4320, 4320, 270, 33, 4320, 33, 4320, 270, 270, 270, 270, 270, 33, 33, 4320, 33, 4320, 33, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 33, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 33, 33, 33, 33, 33, 270, 33, 33, 270, 4320, 4320, 33, 33, 4320, 33, 33, 33, 270, 33, 270, 4320, 4320, 270, 270, 33, 4320, 270, 4320, 33, 270, 270, 33, 33, 270, 33, 4320, 4320, 33, 4320, 4320, 33, 270, 4320, 33, 33, 270, 270, 33, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 4320, 270, 270, 270, 4320, 33, 270, 270, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 270, 33, 4320, 4320, 4320, 270, 33, 4320, 4320, 270, 270, 4320, 4320, 33, 4320, 4320, 270, 33, 4320, 270, 270, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 270, 4320, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 4320, 33, 33, 33, 270, 33, 270, 270, 33, 4320, 270, 4320, 33, 4320, 33, 270, 270, 270, 270, 33, 270, 4320, 4320, 33, 4320, 4320, 33, 4320, 270, 4320, 270, 270, 270, 33, 270, 33, 33, 4320, 33, 270, 33, 33, 270, 4320, 270, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 591744 . Total input tokens: 131952871 . Total output tokens: 118169411
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 64.45964336581528,
    "estimated_duration": 3600.1646659670614,
    "input_throughput": 5345.422719666254,
    "output_throughput": 4686.4236959750115,
    "total_throughput": 10031.846415641267,
    "itl": 181.97686978370558,
    "ttft": 1691548.450471264,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 801,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.503716640921752,
    "arrivals": 196756,
    "finished_requests": 77692,
    "scheduler_time": 129.85873365625005
}
#Debug simulation 
Total elapsed time: 64.45975958602503. Arrivals time: 0.31588582787662745 Scheduler time: 64.00426122359931 Scheduler overhead time: 0.05292922677472234 Adapter cache time: 0.02040498238056898 Engine time: 0.047852461226284504 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-32/adapters_384_slots_96_rate_0.4-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-32/adapters_384_slots_96_rate_0.4-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 270, 33, 4320, 4320, 33, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 33, 4320, 33, 4320, 270, 270, 270, 33, 33, 270, 33, 4320, 33, 4320, 270, 4320, 270, 33, 270, 4320, 270, 4320, 33, 4320, 4320, 4320, 4320, 33, 270, 270, 270, 4320, 270, 33, 270, 33, 4320, 270, 4320, 4320, 270, 4320, 4320, 33, 33, 4320, 270, 270, 33, 33, 33, 270, 33, 270, 33, 4320, 33, 270, 4320, 33, 4320, 270, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 4320, 4320, 270, 33, 33, 4320, 270, 270, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 33, 270, 270, 270, 270, 33, 33, 4320, 33, 4320, 33, 33, 33, 270, 270, 4320, 33, 33, 4320, 33, 4320, 270, 33, 4320, 270, 270, 33, 4320, 4320, 4320, 33, 270, 4320, 33, 4320, 270, 270, 4320, 4320, 33, 270, 4320, 33, 270, 270, 33, 270, 33, 270, 4320, 4320, 270, 33, 4320, 33, 4320, 270, 270, 270, 270, 270, 33, 33, 4320, 33, 4320, 33, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 33, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 33, 33, 33, 33, 33, 270, 33, 33, 270, 4320, 4320, 33, 33, 4320, 33, 33, 33, 270, 33, 270, 4320, 4320, 270, 270, 33, 4320, 270, 4320, 33, 270, 270, 33, 33, 270, 33, 4320, 4320, 33, 4320, 4320, 33, 270, 4320, 33, 33, 270, 270, 33, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 4320, 270, 270, 270, 4320, 33, 270, 270, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 270, 33, 4320, 4320, 4320, 270, 33, 4320, 4320, 270, 270, 4320, 4320, 33, 4320, 4320, 270, 33, 4320, 270, 270, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 270, 4320, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 4320, 33, 33, 33, 270, 33, 270, 270, 33, 4320, 270, 4320, 33, 4320, 33, 270, 270, 270, 270, 33, 270, 4320, 4320, 33, 4320, 4320, 33, 4320, 270, 4320, 270, 270, 270, 33, 270, 33, 33, 4320, 33, 270, 33, 33, 270, 4320, 270, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 591744 . Total input tokens: 131952871 . Total output tokens: 118169411
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 63.99976213788614,
    "estimated_duration": 3600.0515418852196,
    "input_throughput": 5336.842758073091,
    "output_throughput": 4679.50966923604,
    "total_throughput": 10016.352427309132,
    "itl": 180.61536627468553,
    "ttft": 1693236.6026001791,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 814,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.697995771300051,
    "arrivals": 196756,
    "finished_requests": 77544,
    "scheduler_time": 130.2204732885329
}
#Debug simulation 
Total elapsed time: 63.99988170992583. Arrivals time: 0.3136531771160662 Scheduler time: 63.54740933096036 Scheduler overhead time: 0.05240938626229763 Adapter cache time: 0.020470747724175453 Engine time: 0.04768283758312464 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_384_slots_96_rate_0.4-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_384_slots_96_rate_0.4-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 270, 33, 4320, 4320, 33, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 33, 4320, 33, 4320, 270, 270, 270, 33, 33, 270, 33, 4320, 33, 4320, 270, 4320, 270, 33, 270, 4320, 270, 4320, 33, 4320, 4320, 4320, 4320, 33, 270, 270, 270, 4320, 270, 33, 270, 33, 4320, 270, 4320, 4320, 270, 4320, 4320, 33, 33, 4320, 270, 270, 33, 33, 33, 270, 33, 270, 33, 4320, 33, 270, 4320, 33, 4320, 270, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 4320, 4320, 270, 33, 33, 4320, 270, 270, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 33, 270, 270, 270, 270, 33, 33, 4320, 33, 4320, 33, 33, 33, 270, 270, 4320, 33, 33, 4320, 33, 4320, 270, 33, 4320, 270, 270, 33, 4320, 4320, 4320, 33, 270, 4320, 33, 4320, 270, 270, 4320, 4320, 33, 270, 4320, 33, 270, 270, 33, 270, 33, 270, 4320, 4320, 270, 33, 4320, 33, 4320, 270, 270, 270, 270, 270, 33, 33, 4320, 33, 4320, 33, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 33, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 33, 33, 33, 33, 33, 270, 33, 33, 270, 4320, 4320, 33, 33, 4320, 33, 33, 33, 270, 33, 270, 4320, 4320, 270, 270, 33, 4320, 270, 4320, 33, 270, 270, 33, 33, 270, 33, 4320, 4320, 33, 4320, 4320, 33, 270, 4320, 33, 33, 270, 270, 33, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 4320, 270, 270, 270, 4320, 33, 270, 270, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 270, 33, 4320, 4320, 4320, 270, 33, 4320, 4320, 270, 270, 4320, 4320, 33, 4320, 4320, 270, 33, 4320, 270, 270, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 270, 4320, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 4320, 33, 33, 33, 270, 33, 270, 270, 33, 4320, 270, 4320, 33, 4320, 33, 270, 270, 270, 270, 33, 270, 4320, 4320, 33, 4320, 4320, 33, 4320, 270, 4320, 270, 270, 270, 33, 270, 33, 33, 4320, 33, 270, 33, 33, 270, 4320, 270, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 591744 . Total input tokens: 131952871 . Total output tokens: 118169411
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 65.05555586935952,
    "estimated_duration": 3600.201925689135,
    "input_throughput": 5345.802929183207,
    "output_throughput": 4687.853444989599,
    "total_throughput": 10033.656374172806,
    "itl": 182.02045573582996,
    "ttft": 1691537.830295861,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 795,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3770899844471822,
    "arrivals": 196756,
    "finished_requests": 77682,
    "scheduler_time": 129.85397864694758
}
#Debug simulation 
Total elapsed time: 65.05566558334976. Arrivals time: 0.31307959789410233 Scheduler time: 64.60244938591495 Scheduler overhead time: 0.05294318590313196 Adapter cache time: 0.020376827102154493 Engine time: 0.04788950318470597 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-32/adapters_384_slots_96_rate_0.4-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-32/adapters_384_slots_96_rate_0.4-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 270, 33, 4320, 4320, 33, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 33, 4320, 33, 4320, 270, 270, 270, 33, 33, 270, 33, 4320, 33, 4320, 270, 4320, 270, 33, 270, 4320, 270, 4320, 33, 4320, 4320, 4320, 4320, 33, 270, 270, 270, 4320, 270, 33, 270, 33, 4320, 270, 4320, 4320, 270, 4320, 4320, 33, 33, 4320, 270, 270, 33, 33, 33, 270, 33, 270, 33, 4320, 33, 270, 4320, 33, 4320, 270, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 4320, 4320, 270, 33, 33, 4320, 270, 270, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 33, 270, 270, 270, 270, 33, 33, 4320, 33, 4320, 33, 33, 33, 270, 270, 4320, 33, 33, 4320, 33, 4320, 270, 33, 4320, 270, 270, 33, 4320, 4320, 4320, 33, 270, 4320, 33, 4320, 270, 270, 4320, 4320, 33, 270, 4320, 33, 270, 270, 33, 270, 33, 270, 4320, 4320, 270, 33, 4320, 33, 4320, 270, 270, 270, 270, 270, 33, 33, 4320, 33, 4320, 33, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 33, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 33, 33, 33, 33, 33, 270, 33, 33, 270, 4320, 4320, 33, 33, 4320, 33, 33, 33, 270, 33, 270, 4320, 4320, 270, 270, 33, 4320, 270, 4320, 33, 270, 270, 33, 33, 270, 33, 4320, 4320, 33, 4320, 4320, 33, 270, 4320, 33, 33, 270, 270, 33, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 4320, 270, 270, 270, 4320, 33, 270, 270, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 270, 33, 4320, 4320, 4320, 270, 33, 4320, 4320, 270, 270, 4320, 4320, 33, 4320, 4320, 270, 33, 4320, 270, 270, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 270, 4320, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 4320, 33, 33, 33, 270, 33, 270, 270, 33, 4320, 270, 4320, 33, 4320, 33, 270, 270, 270, 270, 33, 270, 4320, 4320, 33, 4320, 4320, 33, 4320, 270, 4320, 270, 270, 270, 33, 270, 33, 33, 4320, 33, 270, 33, 33, 270, 4320, 270, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 591744 . Total input tokens: 131952871 . Total output tokens: 118169411
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 63.89578181086108,
    "estimated_duration": 3600.194282792483,
    "input_throughput": 5334.574051126844,
    "output_throughput": 4678.544455366237,
    "total_throughput": 10013.118506493081,
    "itl": 180.6308833710783,
    "ttft": 1693782.6038750387,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 821,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.755231684483609,
    "arrivals": 196756,
    "finished_requests": 77535,
    "scheduler_time": 130.21514971093862
}
#Debug simulation 
Total elapsed time: 63.89589228108525. Arrivals time: 0.31294605461880565 Scheduler time: 63.441939685028046 Scheduler overhead time: 0.053357786033302546 Adapter cache time: 0.02102050418034196 Engine time: 0.04790179617702961 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_384_slots_96_rate_0.4-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_384_slots_96_rate_0.4-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 135, 66, 4320, 4320, 66, 135, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 66, 4320, 66, 4320, 135, 135, 135, 66, 66, 135, 66, 4320, 66, 4320, 135, 4320, 135, 66, 135, 4320, 135, 4320, 66, 4320, 4320, 4320, 4320, 66, 135, 135, 135, 4320, 135, 66, 135, 66, 4320, 135, 4320, 4320, 135, 4320, 4320, 66, 66, 4320, 135, 135, 66, 66, 66, 135, 66, 135, 66, 4320, 66, 135, 4320, 66, 4320, 135, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 4320, 4320, 135, 66, 66, 4320, 135, 135, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 135, 4320, 4320, 66, 135, 135, 135, 135, 66, 66, 4320, 66, 4320, 66, 66, 66, 135, 135, 4320, 66, 66, 4320, 66, 4320, 135, 66, 4320, 135, 135, 66, 4320, 4320, 4320, 66, 135, 4320, 66, 4320, 135, 135, 4320, 4320, 66, 135, 4320, 66, 135, 135, 66, 135, 66, 135, 4320, 4320, 135, 66, 4320, 66, 4320, 135, 135, 135, 135, 135, 66, 66, 4320, 66, 4320, 66, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 66, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 66, 66, 66, 66, 66, 135, 66, 66, 135, 4320, 4320, 66, 66, 4320, 66, 66, 66, 135, 66, 135, 4320, 4320, 135, 135, 66, 4320, 135, 4320, 66, 135, 135, 66, 66, 135, 66, 4320, 4320, 66, 4320, 4320, 66, 135, 4320, 66, 66, 135, 135, 66, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 4320, 135, 135, 135, 4320, 66, 135, 135, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 135, 66, 4320, 4320, 4320, 135, 66, 4320, 4320, 135, 135, 4320, 4320, 66, 4320, 4320, 135, 66, 4320, 135, 135, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 135, 4320, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 4320, 66, 66, 66, 135, 66, 135, 135, 66, 4320, 135, 4320, 66, 4320, 66, 135, 135, 135, 135, 66, 135, 4320, 4320, 66, 4320, 4320, 66, 4320, 135, 4320, 135, 135, 135, 66, 135, 66, 66, 4320, 66, 135, 66, 66, 135, 4320, 135, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 578688 . Total input tokens: 129047464 . Total output tokens: 115563730
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 71.59197791898623,
    "estimated_duration": 3600.0041677502395,
    "input_throughput": 5312.983571336514,
    "output_throughput": 4692.289289919497,
    "total_throughput": 10005.27286125601,
    "itl": 182.8414387712711,
    "ttft": 1686848.1433286346,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 771,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.359636050572199,
    "arrivals": 192504,
    "finished_requests": 77253,
    "scheduler_time": 129.33550162426272
}
#Debug simulation 
Total elapsed time: 71.5920872730203. Arrivals time: 0.31544144824147224 Scheduler time: 71.13430527877063 Scheduler overhead time: 0.055834258906543255 Adapter cache time: 0.019085591658949852 Engine time: 0.04842373402789235 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_384_slots_96_rate_0.4-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_384_slots_96_rate_0.4-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 135, 66, 4320, 4320, 66, 135, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 66, 4320, 66, 4320, 135, 135, 135, 66, 66, 135, 66, 4320, 66, 4320, 135, 4320, 135, 66, 135, 4320, 135, 4320, 66, 4320, 4320, 4320, 4320, 66, 135, 135, 135, 4320, 135, 66, 135, 66, 4320, 135, 4320, 4320, 135, 4320, 4320, 66, 66, 4320, 135, 135, 66, 66, 66, 135, 66, 135, 66, 4320, 66, 135, 4320, 66, 4320, 135, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 4320, 4320, 135, 66, 66, 4320, 135, 135, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 135, 4320, 4320, 66, 135, 135, 135, 135, 66, 66, 4320, 66, 4320, 66, 66, 66, 135, 135, 4320, 66, 66, 4320, 66, 4320, 135, 66, 4320, 135, 135, 66, 4320, 4320, 4320, 66, 135, 4320, 66, 4320, 135, 135, 4320, 4320, 66, 135, 4320, 66, 135, 135, 66, 135, 66, 135, 4320, 4320, 135, 66, 4320, 66, 4320, 135, 135, 135, 135, 135, 66, 66, 4320, 66, 4320, 66, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 66, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 66, 66, 66, 66, 66, 135, 66, 66, 135, 4320, 4320, 66, 66, 4320, 66, 66, 66, 135, 66, 135, 4320, 4320, 135, 135, 66, 4320, 135, 4320, 66, 135, 135, 66, 66, 135, 66, 4320, 4320, 66, 4320, 4320, 66, 135, 4320, 66, 66, 135, 135, 66, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 4320, 135, 135, 135, 4320, 66, 135, 135, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 135, 66, 4320, 4320, 4320, 135, 66, 4320, 4320, 135, 135, 4320, 4320, 66, 4320, 4320, 135, 66, 4320, 135, 135, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 135, 4320, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 4320, 66, 66, 66, 135, 66, 135, 135, 66, 4320, 135, 4320, 66, 4320, 66, 135, 135, 135, 135, 66, 135, 4320, 4320, 66, 4320, 4320, 66, 4320, 135, 4320, 135, 135, 135, 66, 135, 66, 66, 4320, 66, 135, 66, 66, 135, 4320, 135, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 578688 . Total input tokens: 129047464 . Total output tokens: 115563730
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 71.06120470818132,
    "estimated_duration": 3600.0845281424963,
    "input_throughput": 5312.96191811053,
    "output_throughput": 4692.192604909686,
    "total_throughput": 10005.154523020217,
    "itl": 182.8447145751334,
    "ttft": 1686787.0120405164,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 773,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5180581090902017,
    "arrivals": 192504,
    "finished_requests": 77255,
    "scheduler_time": 129.3336709933488
}
#Debug simulation 
Total elapsed time: 71.06131772510707. Arrivals time: 0.3205634648911655 Scheduler time: 70.59865308599547 Scheduler overhead time: 0.055424015037715435 Adapter cache time: 0.019306326750665903 Engine time: 0.048470328096300364 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-32/adapters_384_slots_96_rate_0.4-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-32/adapters_384_slots_96_rate_0.4-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 135, 66, 4320, 4320, 66, 135, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 66, 4320, 66, 4320, 135, 135, 135, 66, 66, 135, 66, 4320, 66, 4320, 135, 4320, 135, 66, 135, 4320, 135, 4320, 66, 4320, 4320, 4320, 4320, 66, 135, 135, 135, 4320, 135, 66, 135, 66, 4320, 135, 4320, 4320, 135, 4320, 4320, 66, 66, 4320, 135, 135, 66, 66, 66, 135, 66, 135, 66, 4320, 66, 135, 4320, 66, 4320, 135, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 4320, 4320, 135, 66, 66, 4320, 135, 135, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 135, 4320, 4320, 66, 135, 135, 135, 135, 66, 66, 4320, 66, 4320, 66, 66, 66, 135, 135, 4320, 66, 66, 4320, 66, 4320, 135, 66, 4320, 135, 135, 66, 4320, 4320, 4320, 66, 135, 4320, 66, 4320, 135, 135, 4320, 4320, 66, 135, 4320, 66, 135, 135, 66, 135, 66, 135, 4320, 4320, 135, 66, 4320, 66, 4320, 135, 135, 135, 135, 135, 66, 66, 4320, 66, 4320, 66, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 66, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 66, 66, 66, 66, 66, 135, 66, 66, 135, 4320, 4320, 66, 66, 4320, 66, 66, 66, 135, 66, 135, 4320, 4320, 135, 135, 66, 4320, 135, 4320, 66, 135, 135, 66, 66, 135, 66, 4320, 4320, 66, 4320, 4320, 66, 135, 4320, 66, 66, 135, 135, 66, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 4320, 135, 135, 135, 4320, 66, 135, 135, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 135, 66, 4320, 4320, 4320, 135, 66, 4320, 4320, 135, 135, 4320, 4320, 66, 4320, 4320, 135, 66, 4320, 135, 135, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 135, 4320, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 4320, 66, 66, 66, 135, 66, 135, 135, 66, 4320, 135, 4320, 66, 4320, 66, 135, 135, 135, 135, 66, 135, 4320, 4320, 66, 4320, 4320, 66, 4320, 135, 4320, 135, 135, 135, 66, 135, 66, 66, 4320, 66, 135, 66, 66, 135, 4320, 135, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 578688 . Total input tokens: 129047464 . Total output tokens: 115563730
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 70.0590472491458,
    "estimated_duration": 3600.045840739272,
    "input_throughput": 5298.663362598418,
    "output_throughput": 4679.466247168842,
    "total_throughput": 9978.12960976726,
    "itl": 180.66328383843754,
    "ttft": 1689963.4343523192,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 797,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6017277146130695,
    "arrivals": 192504,
    "finished_requests": 77043,
    "scheduler_time": 129.89892150661484
}
#Debug simulation 
Total elapsed time: 70.05915409792215. Arrivals time: 0.3114072550088167 Scheduler time: 69.6070012091659 Scheduler overhead time: 0.05378187447786331 Adapter cache time: 0.01960323005914688 Engine time: 0.04837097832933068 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_384_slots_96_rate_0.4-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_384_slots_96_rate_0.4-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 135, 66, 4320, 4320, 66, 135, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 66, 4320, 66, 4320, 135, 135, 135, 66, 66, 135, 66, 4320, 66, 4320, 135, 4320, 135, 66, 135, 4320, 135, 4320, 66, 4320, 4320, 4320, 4320, 66, 135, 135, 135, 4320, 135, 66, 135, 66, 4320, 135, 4320, 4320, 135, 4320, 4320, 66, 66, 4320, 135, 135, 66, 66, 66, 135, 66, 135, 66, 4320, 66, 135, 4320, 66, 4320, 135, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 4320, 4320, 135, 66, 66, 4320, 135, 135, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 135, 4320, 4320, 66, 135, 135, 135, 135, 66, 66, 4320, 66, 4320, 66, 66, 66, 135, 135, 4320, 66, 66, 4320, 66, 4320, 135, 66, 4320, 135, 135, 66, 4320, 4320, 4320, 66, 135, 4320, 66, 4320, 135, 135, 4320, 4320, 66, 135, 4320, 66, 135, 135, 66, 135, 66, 135, 4320, 4320, 135, 66, 4320, 66, 4320, 135, 135, 135, 135, 135, 66, 66, 4320, 66, 4320, 66, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 66, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 66, 66, 66, 66, 66, 135, 66, 66, 135, 4320, 4320, 66, 66, 4320, 66, 66, 66, 135, 66, 135, 4320, 4320, 135, 135, 66, 4320, 135, 4320, 66, 135, 135, 66, 66, 135, 66, 4320, 4320, 66, 4320, 4320, 66, 135, 4320, 66, 66, 135, 135, 66, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 4320, 135, 135, 135, 4320, 66, 135, 135, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 135, 66, 4320, 4320, 4320, 135, 66, 4320, 4320, 135, 135, 4320, 4320, 66, 4320, 4320, 135, 66, 4320, 135, 135, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 135, 4320, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 4320, 66, 66, 66, 135, 66, 135, 135, 66, 4320, 135, 4320, 66, 4320, 66, 135, 135, 135, 135, 66, 135, 4320, 4320, 66, 4320, 4320, 66, 4320, 135, 4320, 135, 135, 135, 66, 135, 66, 66, 4320, 66, 135, 66, 66, 135, 4320, 135, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 578688 . Total input tokens: 129047464 . Total output tokens: 115563730
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 69.59464935399592,
    "estimated_duration": 3600.0369899584166,
    "input_throughput": 5312.459025655987,
    "output_throughput": 4691.939012603064,
    "total_throughput": 10004.39803825905,
    "itl": 182.84552667717801,
    "ttft": 1686920.2088290853,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 774,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4193079250934315,
    "arrivals": 192504,
    "finished_requests": 77252,
    "scheduler_time": 129.3334362537791
}
#Debug simulation 
Total elapsed time: 69.59475674526766. Arrivals time: 0.31117943255230784 Scheduler time: 69.14659369224682 Scheduler overhead time: 0.05341861303895712 Adapter cache time: 0.0186862600967288 Engine time: 0.046744704246520996 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-32/adapters_384_slots_96_rate_0.4-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-32/adapters_384_slots_96_rate_0.4-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 135, 66, 4320, 4320, 66, 135, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 66, 4320, 66, 4320, 135, 135, 135, 66, 66, 135, 66, 4320, 66, 4320, 135, 4320, 135, 66, 135, 4320, 135, 4320, 66, 4320, 4320, 4320, 4320, 66, 135, 135, 135, 4320, 135, 66, 135, 66, 4320, 135, 4320, 4320, 135, 4320, 4320, 66, 66, 4320, 135, 135, 66, 66, 66, 135, 66, 135, 66, 4320, 66, 135, 4320, 66, 4320, 135, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 4320, 4320, 135, 66, 66, 4320, 135, 135, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 135, 4320, 4320, 66, 135, 135, 135, 135, 66, 66, 4320, 66, 4320, 66, 66, 66, 135, 135, 4320, 66, 66, 4320, 66, 4320, 135, 66, 4320, 135, 135, 66, 4320, 4320, 4320, 66, 135, 4320, 66, 4320, 135, 135, 4320, 4320, 66, 135, 4320, 66, 135, 135, 66, 135, 66, 135, 4320, 4320, 135, 66, 4320, 66, 4320, 135, 135, 135, 135, 135, 66, 66, 4320, 66, 4320, 66, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 66, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 66, 66, 66, 66, 66, 135, 66, 66, 135, 4320, 4320, 66, 66, 4320, 66, 66, 66, 135, 66, 135, 4320, 4320, 135, 135, 66, 4320, 135, 4320, 66, 135, 135, 66, 66, 135, 66, 4320, 4320, 66, 4320, 4320, 66, 135, 4320, 66, 66, 135, 135, 66, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 4320, 135, 135, 135, 4320, 66, 135, 135, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 135, 66, 4320, 4320, 4320, 135, 66, 4320, 4320, 135, 135, 4320, 4320, 66, 4320, 4320, 135, 66, 4320, 135, 135, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 135, 4320, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 4320, 66, 66, 66, 135, 66, 135, 135, 66, 4320, 135, 4320, 66, 4320, 66, 135, 135, 135, 135, 66, 135, 4320, 4320, 66, 4320, 4320, 66, 4320, 135, 4320, 135, 135, 135, 66, 135, 66, 66, 4320, 66, 135, 66, 66, 135, 4320, 135, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 578688 . Total input tokens: 129047464 . Total output tokens: 115563730
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 68.92119273077697,
    "estimated_duration": 3600.099030896534,
    "input_throughput": 5298.685629558793,
    "output_throughput": 4679.808209554833,
    "total_throughput": 9978.493839113626,
    "itl": 180.65257197084165,
    "ttft": 1689925.8048938098,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 790,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6118958309479092,
    "arrivals": 192504,
    "finished_requests": 77046,
    "scheduler_time": 129.90306355329042
}
#Debug simulation 
Total elapsed time: 68.92130255093798. Arrivals time: 0.3063030820339918 Scheduler time: 68.47918463498354 Scheduler overhead time: 0.051712005864828825 Adapter cache time: 0.01902679819613695 Engine time: 0.04648197768256068 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_384_slots_96_rate_0.4-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_384_slots_96_rate_0.4-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 135, 66, 4320, 4320, 66, 135, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 66, 4320, 66, 4320, 135, 135, 135, 66, 66, 135, 66, 4320, 66, 4320, 135, 4320, 135, 66, 135, 4320, 135, 4320, 66, 4320, 4320, 4320, 4320, 66, 135, 135, 135, 4320, 135, 66, 135, 66, 4320, 135, 4320, 4320, 135, 4320, 4320, 66, 66, 4320, 135, 135, 66, 66, 66, 135, 66, 135, 66, 4320, 66, 135, 4320, 66, 4320, 135, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 4320, 4320, 135, 66, 66, 4320, 135, 135, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 135, 4320, 4320, 66, 135, 135, 135, 135, 66, 66, 4320, 66, 4320, 66, 66, 66, 135, 135, 4320, 66, 66, 4320, 66, 4320, 135, 66, 4320, 135, 135, 66, 4320, 4320, 4320, 66, 135, 4320, 66, 4320, 135, 135, 4320, 4320, 66, 135, 4320, 66, 135, 135, 66, 135, 66, 135, 4320, 4320, 135, 66, 4320, 66, 4320, 135, 135, 135, 135, 135, 66, 66, 4320, 66, 4320, 66, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 66, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 66, 66, 66, 66, 66, 135, 66, 66, 135, 4320, 4320, 66, 66, 4320, 66, 66, 66, 135, 66, 135, 4320, 4320, 135, 135, 66, 4320, 135, 4320, 66, 135, 135, 66, 66, 135, 66, 4320, 4320, 66, 4320, 4320, 66, 135, 4320, 66, 66, 135, 135, 66, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 4320, 135, 135, 135, 4320, 66, 135, 135, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 135, 66, 4320, 4320, 4320, 135, 66, 4320, 4320, 135, 135, 4320, 4320, 66, 4320, 4320, 135, 66, 4320, 135, 135, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 135, 4320, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 4320, 66, 66, 66, 135, 66, 135, 135, 66, 4320, 135, 4320, 66, 4320, 66, 135, 135, 135, 135, 66, 135, 4320, 4320, 66, 4320, 4320, 66, 4320, 135, 4320, 135, 135, 135, 66, 135, 66, 66, 4320, 66, 135, 66, 66, 135, 4320, 135, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 578688 . Total input tokens: 129047464 . Total output tokens: 115563730
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 69.74265281204134,
    "estimated_duration": 3600.1078777958696,
    "input_throughput": 5313.271615547016,
    "output_throughput": 4692.397998457384,
    "total_throughput": 10005.6696140044,
    "itl": 182.83646318885383,
    "ttft": 1686800.7948202942,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 774,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3142989282542388,
    "arrivals": 192504,
    "finished_requests": 77259,
    "scheduler_time": 129.3409921195933
}
#Debug simulation 
Total elapsed time: 69.74276141403243. Arrivals time: 0.30716546485200524 Scheduler time: 69.30014413967729 Scheduler overhead time: 0.0515693430788815 Adapter cache time: 0.018837662879377604 Engine time: 0.04660719307139516 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-32/adapters_384_slots_96_rate_0.4-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-32/adapters_384_slots_96_rate_0.4-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 135, 66, 4320, 4320, 66, 135, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 66, 4320, 66, 4320, 135, 135, 135, 66, 66, 135, 66, 4320, 66, 4320, 135, 4320, 135, 66, 135, 4320, 135, 4320, 66, 4320, 4320, 4320, 4320, 66, 135, 135, 135, 4320, 135, 66, 135, 66, 4320, 135, 4320, 4320, 135, 4320, 4320, 66, 66, 4320, 135, 135, 66, 66, 66, 135, 66, 135, 66, 4320, 66, 135, 4320, 66, 4320, 135, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 4320, 4320, 135, 66, 66, 4320, 135, 135, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 135, 4320, 4320, 66, 135, 135, 135, 135, 66, 66, 4320, 66, 4320, 66, 66, 66, 135, 135, 4320, 66, 66, 4320, 66, 4320, 135, 66, 4320, 135, 135, 66, 4320, 4320, 4320, 66, 135, 4320, 66, 4320, 135, 135, 4320, 4320, 66, 135, 4320, 66, 135, 135, 66, 135, 66, 135, 4320, 4320, 135, 66, 4320, 66, 4320, 135, 135, 135, 135, 135, 66, 66, 4320, 66, 4320, 66, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 66, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 66, 66, 66, 66, 66, 135, 66, 66, 135, 4320, 4320, 66, 66, 4320, 66, 66, 66, 135, 66, 135, 4320, 4320, 135, 135, 66, 4320, 135, 4320, 66, 135, 135, 66, 66, 135, 66, 4320, 4320, 66, 4320, 4320, 66, 135, 4320, 66, 66, 135, 135, 66, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 4320, 135, 135, 135, 4320, 66, 135, 135, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 135, 66, 4320, 4320, 4320, 135, 66, 4320, 4320, 135, 135, 4320, 4320, 66, 4320, 4320, 135, 66, 4320, 135, 135, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 135, 4320, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 4320, 66, 66, 66, 135, 66, 135, 135, 66, 4320, 135, 4320, 66, 4320, 66, 135, 135, 135, 135, 66, 135, 4320, 4320, 66, 4320, 4320, 66, 4320, 135, 4320, 135, 135, 135, 66, 135, 66, 66, 4320, 66, 135, 66, 66, 135, 4320, 135, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 578688 . Total input tokens: 129047464 . Total output tokens: 115563730
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 68.62186090834439,
    "estimated_duration": 3600.123609869899,
    "input_throughput": 5298.929166681973,
    "output_throughput": 4679.760982042736,
    "total_throughput": 9978.690148724709,
    "itl": 180.6884551718981,
    "ttft": 1689919.3355955582,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 797,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.666908189840632,
    "arrivals": 192504,
    "finished_requests": 77048,
    "scheduler_time": 129.89387313805827
}
#Debug simulation 
Total elapsed time: 68.62196981534362. Arrivals time: 0.4833112903870642 Scheduler time: 68.0044706100598 Scheduler overhead time: 0.050905018113553524 Adapter cache time: 0.018853973131626844 Engine time: 0.04640460340306163 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_384_slots_96_rate_0.4-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_384_slots_96_rate_0.4-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 135, 33, 4320, 4320, 33, 135, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 33, 4320, 33, 4320, 135, 135, 135, 33, 33, 135, 33, 4320, 33, 4320, 135, 4320, 135, 33, 135, 4320, 135, 4320, 33, 4320, 4320, 4320, 4320, 33, 135, 135, 135, 4320, 135, 33, 135, 33, 4320, 135, 4320, 4320, 135, 4320, 4320, 33, 33, 4320, 135, 135, 33, 33, 33, 135, 33, 135, 33, 4320, 33, 135, 4320, 33, 4320, 135, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 4320, 4320, 135, 33, 33, 4320, 135, 135, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 135, 4320, 4320, 33, 135, 135, 135, 135, 33, 33, 4320, 33, 4320, 33, 33, 33, 135, 135, 4320, 33, 33, 4320, 33, 4320, 135, 33, 4320, 135, 135, 33, 4320, 4320, 4320, 33, 135, 4320, 33, 4320, 135, 135, 4320, 4320, 33, 135, 4320, 33, 135, 135, 33, 135, 33, 135, 4320, 4320, 135, 33, 4320, 33, 4320, 135, 135, 135, 135, 135, 33, 33, 4320, 33, 4320, 33, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 33, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 33, 33, 33, 33, 33, 135, 33, 33, 135, 4320, 4320, 33, 33, 4320, 33, 33, 33, 135, 33, 135, 4320, 4320, 135, 135, 33, 4320, 135, 4320, 33, 135, 135, 33, 33, 135, 33, 4320, 4320, 33, 4320, 4320, 33, 135, 4320, 33, 33, 135, 135, 33, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 4320, 135, 135, 135, 4320, 33, 135, 135, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 135, 33, 4320, 4320, 4320, 135, 33, 4320, 4320, 135, 135, 4320, 4320, 33, 4320, 4320, 135, 33, 4320, 135, 135, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 135, 4320, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 4320, 33, 33, 33, 135, 33, 135, 135, 33, 4320, 135, 4320, 33, 4320, 33, 135, 135, 135, 135, 33, 135, 4320, 4320, 33, 4320, 4320, 33, 4320, 135, 4320, 135, 135, 135, 33, 135, 33, 33, 4320, 33, 135, 33, 33, 135, 4320, 135, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 574464 . Total input tokens: 128075419 . Total output tokens: 114736704
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 92.71383665688336,
    "estimated_duration": 3600.0496934031216,
    "input_throughput": 5289.5417068532315,
    "output_throughput": 4691.4246853171935,
    "total_throughput": 9980.966392170425,
    "itl": 182.24940640655163,
    "ttft": 1630512.7380211153,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 514,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.573090700381454,
    "arrivals": 191087,
    "finished_requests": 77155,
    "scheduler_time": 129.37791367608196
}
#Debug simulation 
Total elapsed time: 92.7139428788796. Arrivals time: 0.31908012414351106 Scheduler time: 92.25454852823168 Scheduler overhead time: 0.05532071040943265 Adapter cache time: 0.01556606125086546 Engine time: 0.04964455682784319 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_384_slots_96_rate_0.4-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_384_slots_96_rate_0.4-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 135, 33, 4320, 4320, 33, 135, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 33, 4320, 33, 4320, 135, 135, 135, 33, 33, 135, 33, 4320, 33, 4320, 135, 4320, 135, 33, 135, 4320, 135, 4320, 33, 4320, 4320, 4320, 4320, 33, 135, 135, 135, 4320, 135, 33, 135, 33, 4320, 135, 4320, 4320, 135, 4320, 4320, 33, 33, 4320, 135, 135, 33, 33, 33, 135, 33, 135, 33, 4320, 33, 135, 4320, 33, 4320, 135, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 4320, 4320, 135, 33, 33, 4320, 135, 135, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 135, 4320, 4320, 33, 135, 135, 135, 135, 33, 33, 4320, 33, 4320, 33, 33, 33, 135, 135, 4320, 33, 33, 4320, 33, 4320, 135, 33, 4320, 135, 135, 33, 4320, 4320, 4320, 33, 135, 4320, 33, 4320, 135, 135, 4320, 4320, 33, 135, 4320, 33, 135, 135, 33, 135, 33, 135, 4320, 4320, 135, 33, 4320, 33, 4320, 135, 135, 135, 135, 135, 33, 33, 4320, 33, 4320, 33, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 33, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 33, 33, 33, 33, 33, 135, 33, 33, 135, 4320, 4320, 33, 33, 4320, 33, 33, 33, 135, 33, 135, 4320, 4320, 135, 135, 33, 4320, 135, 4320, 33, 135, 135, 33, 33, 135, 33, 4320, 4320, 33, 4320, 4320, 33, 135, 4320, 33, 33, 135, 135, 33, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 4320, 135, 135, 135, 4320, 33, 135, 135, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 135, 33, 4320, 4320, 4320, 135, 33, 4320, 4320, 135, 135, 4320, 4320, 33, 4320, 4320, 135, 33, 4320, 135, 135, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 135, 4320, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 4320, 33, 33, 33, 135, 33, 135, 135, 33, 4320, 135, 4320, 33, 4320, 33, 135, 135, 135, 135, 33, 135, 4320, 4320, 33, 4320, 4320, 33, 4320, 135, 4320, 135, 135, 135, 33, 135, 33, 33, 4320, 33, 135, 33, 33, 135, 4320, 135, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 574464 . Total input tokens: 128075419 . Total output tokens: 114736704
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 92.26010964391753,
    "estimated_duration": 3600.1712250953938,
    "input_throughput": 5289.570359114075,
    "output_throughput": 4691.493527381454,
    "total_throughput": 9981.063886495529,
    "itl": 182.2587587236345,
    "ttft": 1630448.89444378,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 513,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6736354001914202,
    "arrivals": 191087,
    "finished_requests": 77155,
    "scheduler_time": 129.378879002002
}
#Debug simulation 
Total elapsed time: 92.26021963311359. Arrivals time: 0.3175711897201836 Scheduler time: 91.80225351219997 Scheduler overhead time: 0.05518941069021821 Adapter cache time: 0.015636466443538666 Engine time: 0.05000336980447173 
