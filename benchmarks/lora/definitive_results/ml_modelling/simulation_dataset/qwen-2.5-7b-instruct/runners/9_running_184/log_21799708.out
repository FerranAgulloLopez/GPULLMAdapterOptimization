INFO 06-01 00:47:03 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:47:04 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-32/adapters_32_slots_16_rate_0.025-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-32/adapters_32_slots_16_rate_0.025-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [10 11 11]
Adapter prompts. [270, 135, 66, 66, 135, 66, 270, 135, 66, 66, 66, 270, 270, 66, 66, 135, 135, 135, 270, 270, 66, 270, 270, 270, 270, 135, 66, 135, 135, 135, 135, 270]
Prompts retrieved: 5115 . Total input tokens: 1122780 . Total output tokens: 1024077
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 0.5949010287877172,
    "estimated_duration": 3595.9889876992615,
    "input_throughput": 110.39132804852709,
    "output_throughput": 95.99278562331034,
    "total_throughput": 206.38411367183744,
    "itl": 17.788973428235728,
    "ttft": 8772.317366761376,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 651,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.167285720091316,
    "arrivals": 1647,
    "finished_requests": 1643,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.595064511988312. Arrivals time: 0.01714015589095652 Scheduler time: 0.2195971654728055 Scheduler overhead time: 0.1317318556830287 Adapter cache time: 0.02518072468228638 Engine time: 0.13475675927475095 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-16/adapters_32_slots_16_rate_0.025-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-16/adapters_32_slots_16_rate_0.025-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [10 11 11]
Adapter prompts. [270, 135, 66, 66, 135, 66, 270, 135, 66, 66, 66, 270, 270, 66, 66, 135, 135, 135, 270, 270, 66, 270, 270, 270, 270, 135, 66, 135, 135, 135, 135, 270]
Prompts retrieved: 5115 . Total input tokens: 1122780 . Total output tokens: 1024077
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.610041803913191,
    "estimated_duration": 3595.9885435146593,
    "input_throughput": 110.3913416843125,
    "output_throughput": 95.99279748055538,
    "total_throughput": 206.3841391648679,
    "itl": 17.787898952613055,
    "ttft": 8772.138126579694,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 651,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.946522741981284,
    "arrivals": 1647,
    "finished_requests": 1643,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.610213550971821. Arrivals time: 0.018346732016652822 Scheduler time: 0.22438311576843262 Scheduler overhead time: 0.13605294306762516 Adapter cache time: 0.025571464793756604 Engine time: 0.13665526919066906 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-32/adapters_32_slots_16_rate_0.025-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-32/adapters_32_slots_16_rate_0.025-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [10 11 11]
Adapter prompts. [270, 135, 66, 66, 135, 66, 270, 135, 66, 66, 66, 270, 270, 66, 66, 135, 135, 135, 270, 270, 66, 270, 270, 270, 270, 135, 66, 135, 135, 135, 135, 270]
Prompts retrieved: 5115 . Total input tokens: 1122780 . Total output tokens: 1024077
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.6103726539295167,
    "estimated_duration": 3595.9891134530476,
    "input_throughput": 110.39132418807951,
    "output_throughput": 95.99278226638799,
    "total_throughput": 206.3841064544675,
    "itl": 17.789101352975358,
    "ttft": 8772.3592815305,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 651,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.197089367471636,
    "arrivals": 1647,
    "finished_requests": 1643,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6104941200464964. Arrivals time: 0.01751206465996802 Scheduler time: 0.2225722169969231 Scheduler overhead time: 0.13818016671575606 Adapter cache time: 0.025957856560125947 Engine time: 0.13641743478365242 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-8/adapters_32_slots_16_rate_0.025-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-8/adapters_32_slots_16_rate_0.025-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [10 11 11]
Adapter prompts. [270, 135, 33, 33, 135, 33, 270, 135, 33, 33, 33, 270, 270, 33, 33, 135, 135, 135, 270, 270, 33, 270, 270, 270, 270, 135, 33, 135, 135, 135, 135, 270]
Prompts retrieved: 4785 . Total input tokens: 1048094 . Total output tokens: 961085
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.5676581820007414,
    "estimated_duration": 3589.9947827592296,
    "input_throughput": 104.30906523830303,
    "output_throughput": 91.45333624904582,
    "total_throughput": 195.76240148734885,
    "itl": 17.701234938907675,
    "ttft": 9422.07980244107,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 541,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6557238694676413,
    "arrivals": 1533,
    "finished_requests": 1529,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5677961220499128. Arrivals time: 0.016390267526730895 Scheduler time: 0.20225381734780967 Scheduler overhead time: 0.12806880986317992 Adapter cache time: 0.023755154106765985 Engine time: 0.13015978760086 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-16/adapters_32_slots_16_rate_0.025-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-16/adapters_32_slots_16_rate_0.025-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [10 11 11]
Adapter prompts. [270, 135, 33, 33, 135, 33, 270, 135, 33, 33, 33, 270, 270, 33, 33, 135, 135, 135, 270, 270, 33, 270, 270, 270, 270, 135, 33, 135, 135, 135, 135, 270]
Prompts retrieved: 4785 . Total input tokens: 1048094 . Total output tokens: 961085
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.621552508091554,
    "estimated_duration": 3589.997345513981,
    "input_throughput": 104.30899077625561,
    "output_throughput": 91.45327096418639,
    "total_throughput": 195.762261740442,
    "itl": 17.70184261754385,
    "ttft": 9422.151487075726,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 541,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7830983135104272,
    "arrivals": 1533,
    "finished_requests": 1529,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6216362090781331. Arrivals time: 0.01776594901457429 Scheduler time: 0.2230717286001891 Scheduler overhead time: 0.14018384041264653 Adapter cache time: 0.0263388161547482 Engine time: 0.14325514691881835 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-32/adapters_32_slots_16_rate_0.025-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-32/adapters_32_slots_16_rate_0.025-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [10 11 11]
Adapter prompts. [270, 135, 33, 33, 135, 33, 270, 135, 33, 33, 33, 270, 270, 33, 33, 135, 135, 135, 270, 270, 33, 270, 270, 270, 270, 135, 33, 135, 135, 135, 135, 270]
Prompts retrieved: 4785 . Total input tokens: 1048094 . Total output tokens: 961085
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.6262558379676193,
    "estimated_duration": 3589.9973094169304,
    "input_throughput": 104.3089918250717,
    "output_throughput": 91.45327188373955,
    "total_throughput": 195.76226370881125,
    "itl": 17.7018427829883,
    "ttft": 9422.163929058797,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 541,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7831289324723296,
    "arrivals": 1533,
    "finished_requests": 1529,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6263711741194129. Arrivals time: 0.017926294123753905 Scheduler time: 0.22500950330868363 Scheduler overhead time: 0.14140680409036577 Adapter cache time: 0.026442053960636258 Engine time: 0.14394779014401138 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-16/adapters_32_slots_16_rate_0.025-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-16/adapters_32_slots_16_rate_0.025-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [10 11 11]
Adapter prompts. [270, 135, 33, 33, 135, 33, 270, 135, 33, 33, 33, 270, 270, 33, 33, 135, 135, 135, 270, 270, 33, 270, 270, 270, 270, 135, 33, 135, 135, 135, 135, 270]
Prompts retrieved: 4785 . Total input tokens: 1048094 . Total output tokens: 961085
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 0.5644376240670681,
    "estimated_duration": 3589.9961197280263,
    "input_throughput": 104.30902639203111,
    "output_throughput": 91.45330219044162,
    "total_throughput": 195.76232858247272,
    "itl": 17.7014476376597,
    "ttft": 9422.001396624979,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 541,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6997448685485808,
    "arrivals": 1533,
    "finished_requests": 1529,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5645566030871123. Arrivals time: 0.016437976621091366 Scheduler time: 0.20234047481790185 Scheduler overhead time: 0.12893033283762634 Adapter cache time: 0.02389562502503395 Engine time: 0.12798057938925922 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-32/adapters_32_slots_16_rate_0.025-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-32/adapters_32_slots_16_rate_0.025-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [10 11 11]
Adapter prompts. [270, 135, 33, 33, 135, 33, 270, 135, 33, 33, 33, 270, 270, 33, 33, 135, 135, 135, 270, 270, 33, 270, 270, 270, 270, 135, 33, 135, 135, 135, 135, 270]
Prompts retrieved: 4785 . Total input tokens: 1048094 . Total output tokens: 961085
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 0.6492934750858694,
    "estimated_duration": 3589.9976866782886,
    "input_throughput": 104.30898086357385,
    "output_throughput": 91.45326227320814,
    "total_throughput": 195.762243136782,
    "itl": 17.701965143393092,
    "ttft": 9422.123404966105,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 541,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.808782704900954,
    "arrivals": 1533,
    "finished_requests": 1529,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6493870459962636. Arrivals time: 0.018467335496097803 Scheduler time: 0.2378667863085866 Scheduler overhead time: 0.14459047466516495 Adapter cache time: 0.026809197617694736 Engine time: 0.14868743903934956 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-16/adapters_32_slots_16_rate_0.025-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-16/adapters_32_slots_16_rate_0.025-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [10 11 11]
Adapter prompts. [270, 135, 33, 33, 135, 33, 270, 135, 33, 33, 33, 270, 270, 33, 33, 135, 135, 135, 270, 270, 33, 270, 270, 270, 270, 135, 33, 135, 135, 135, 135, 270]
Prompts retrieved: 4785 . Total input tokens: 1048094 . Total output tokens: 961085
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.5711683959234506,
    "estimated_duration": 3589.9940783847414,
    "input_throughput": 104.30908570425446,
    "output_throughput": 91.45335419264,
    "total_throughput": 195.76243989689448,
    "itl": 17.701072556460254,
    "ttft": 9422.027697645743,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 541,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6176172095420565,
    "arrivals": 1533,
    "finished_requests": 1529,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5712497159838676. Arrivals time: 0.016228283755481243 Scheduler time: 0.20563909877091646 Scheduler overhead time: 0.13010490918532014 Adapter cache time: 0.02404644782654941 Engine time: 0.1298031280748546 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-32/adapters_32_slots_16_rate_0.025-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-32/adapters_32_slots_16_rate_0.025-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [10 11 11]
Adapter prompts. [270, 135, 33, 33, 135, 33, 270, 135, 33, 33, 33, 270, 270, 33, 33, 135, 135, 135, 270, 270, 33, 270, 270, 270, 270, 135, 33, 135, 135, 135, 135, 270]
Prompts retrieved: 4785 . Total input tokens: 1048094 . Total output tokens: 961085
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.5999533389694989,
    "estimated_duration": 3589.9985869120856,
    "input_throughput": 104.30895470688671,
    "output_throughput": 91.45323934024157,
    "total_throughput": 195.76219404712828,
    "itl": 17.702086716709793,
    "ttft": 9422.126458746594,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 541,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8340592159703326,
    "arrivals": 1533,
    "finished_requests": 1529,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6000520449597389. Arrivals time: 0.017280602594837546 Scheduler time: 0.21486999350599945 Scheduler overhead time: 0.13608746067620814 Adapter cache time: 0.025163308018818498 Engine time: 0.13805098901502788 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-8/adapters_32_slots_16_rate_0.025-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-8/adapters_32_slots_16_rate_0.025-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [10 11 11]
Adapter prompts. [270, 66, 33, 33, 66, 33, 270, 66, 33, 33, 33, 270, 270, 33, 33, 66, 66, 66, 270, 270, 33, 270, 270, 270, 270, 66, 33, 66, 66, 66, 66, 270]
Prompts retrieved: 4026 . Total input tokens: 878074 . Total output tokens: 796133
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.5309170400723815,
    "estimated_duration": 3599.8418209378756,
    "input_throughput": 88.07775890480488,
    "output_throughput": 76.96754851517726,
    "total_throughput": 165.04530741998215,
    "itl": 17.599069387483514,
    "ttft": 2807.8338626006994,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 353,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0803521736082635,
    "arrivals": 1295,
    "finished_requests": 1294,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5310009839013219. Arrivals time: 0.015165318502113223 Scheduler time: 0.18769813934341073 Scheduler overhead time: 0.12166003417223692 Adapter cache time: 0.02184984483756125 Engine time: 0.12339932890608907 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-16/adapters_32_slots_16_rate_0.025-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-16/adapters_32_slots_16_rate_0.025-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [10 11 11]
Adapter prompts. [270, 66, 33, 33, 66, 33, 270, 66, 33, 33, 33, 270, 270, 33, 33, 66, 66, 66, 270, 270, 33, 270, 270, 270, 270, 66, 33, 66, 66, 66, 66, 270]
Prompts retrieved: 4026 . Total input tokens: 878074 . Total output tokens: 796133
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.573507979977876,
    "estimated_duration": 3599.8418209378756,
    "input_throughput": 88.07775890480488,
    "output_throughput": 76.96754851517726,
    "total_throughput": 165.04530741998215,
    "itl": 17.600876257060396,
    "ttft": 2808.014132311489,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 353,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1600881556212035,
    "arrivals": 1295,
    "finished_requests": 1294,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5735936900600791. Arrivals time: 0.016235128743574023 Scheduler time: 0.20228293165564537 Scheduler overhead time: 0.13088910817168653 Adapter cache time: 0.02383373724296689 Engine time: 0.1335407302249223 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-32/adapters_32_slots_16_rate_0.025-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-32/adapters_32_slots_16_rate_0.025-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [10 11 11]
Adapter prompts. [270, 66, 33, 33, 66, 33, 270, 66, 33, 33, 33, 270, 270, 33, 33, 66, 66, 66, 270, 270, 33, 270, 270, 270, 270, 66, 33, 66, 66, 66, 66, 270]
Prompts retrieved: 4026 . Total input tokens: 878074 . Total output tokens: 796133
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.510142405051738,
    "estimated_duration": 3599.8418209378756,
    "input_throughput": 88.07775890480488,
    "output_throughput": 76.96754851517726,
    "total_throughput": 165.04530741998215,
    "itl": 17.600876490883042,
    "ttft": 2808.017042736795,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 353,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1606975122168726,
    "arrivals": 1295,
    "finished_requests": 1294,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5102362411562353. Arrivals time: 0.014464637730270624 Scheduler time: 0.18303697579540312 Scheduler overhead time: 0.11635001376271248 Adapter cache time: 0.021233580075204372 Engine time: 0.11617307225242257 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-16/adapters_32_slots_16_rate_0.025-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-16/adapters_32_slots_16_rate_0.025-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [10 11 11]
Adapter prompts. [270, 66, 33, 33, 66, 33, 270, 66, 33, 33, 33, 270, 270, 33, 33, 66, 66, 66, 270, 270, 33, 270, 270, 270, 270, 66, 33, 66, 66, 66, 66, 270]
Prompts retrieved: 4026 . Total input tokens: 878074 . Total output tokens: 796133
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 0.5396810860838741,
    "estimated_duration": 3599.8418209378756,
    "input_throughput": 88.07775890480488,
    "output_throughput": 76.96754851517726,
    "total_throughput": 165.04530741998215,
    "itl": 17.599201453738214,
    "ttft": 2807.907115213366,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 353,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1102395267714766,
    "arrivals": 1295,
    "finished_requests": 1294,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.539793121162802. Arrivals time: 0.015326503897085786 Scheduler time: 0.19162634806707501 Scheduler overhead time: 0.12257743114605546 Adapter cache time: 0.022466878406703472 Engine time: 0.12534357327967882 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-32/adapters_32_slots_16_rate_0.025-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-32/adapters_32_slots_16_rate_0.025-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [10 11 11]
Adapter prompts. [270, 66, 33, 33, 66, 33, 270, 66, 33, 33, 33, 270, 270, 33, 33, 66, 66, 66, 270, 270, 33, 270, 270, 270, 270, 66, 33, 66, 66, 66, 66, 270]
Prompts retrieved: 4026 . Total input tokens: 878074 . Total output tokens: 796133
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 0.5292814241256565,
    "estimated_duration": 3599.8418209378756,
    "input_throughput": 88.07775890480488,
    "output_throughput": 76.96754851517726,
    "total_throughput": 165.04530741998215,
    "itl": 17.601008177516896,
    "ttft": 2808.047439438443,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 353,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1760394741594837,
    "arrivals": 1295,
    "finished_requests": 1294,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5293709130492061. Arrivals time: 0.01511792279779911 Scheduler time: 0.18618225143291056 Scheduler overhead time: 0.11948925955221057 Adapter cache time: 0.022219674661755562 Engine time: 0.12153033260256052 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-16/adapters_32_slots_16_rate_0.025-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-16/adapters_32_slots_16_rate_0.025-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [10 11 11]
Adapter prompts. [270, 66, 33, 33, 66, 33, 270, 66, 33, 33, 33, 270, 270, 33, 33, 66, 66, 66, 270, 270, 33, 270, 270, 270, 270, 66, 33, 66, 66, 66, 66, 270]
Prompts retrieved: 4026 . Total input tokens: 878074 . Total output tokens: 796133
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.5055522480979562,
    "estimated_duration": 3599.8418209378756,
    "input_throughput": 88.07775890480488,
    "output_throughput": 76.96754851517726,
    "total_throughput": 165.04530741998215,
    "itl": 17.59893621897815,
    "ttft": 2807.8449374475986,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 353,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0554877541004675,
    "arrivals": 1295,
    "finished_requests": 1294,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5056304631289095. Arrivals time: 0.01456058630719781 Scheduler time: 0.1789471199735999 Scheduler overhead time: 0.11665003933012486 Adapter cache time: 0.02098529483191669 Engine time: 0.1160997305996716 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-32/adapters_32_slots_16_rate_0.025-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-32/adapters_32_slots_16_rate_0.025-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [10 11 11]
Adapter prompts. [270, 66, 33, 33, 66, 33, 270, 66, 33, 33, 33, 270, 270, 33, 33, 66, 66, 66, 270, 270, 33, 270, 270, 270, 270, 66, 33, 66, 66, 66, 66, 270]
Prompts retrieved: 4026 . Total input tokens: 878074 . Total output tokens: 796133
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.5822778209112585,
    "estimated_duration": 3599.8418209378756,
    "input_throughput": 88.07775890480488,
    "output_throughput": 76.96754851517726,
    "total_throughput": 165.04530741998215,
    "itl": 17.601072744222286,
    "ttft": 2808.0858903592048,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 353,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.192890481539074,
    "arrivals": 1295,
    "finished_requests": 1294,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5823852820321918. Arrivals time: 0.016615783562883735 Scheduler time: 0.2067982042208314 Scheduler overhead time: 0.13220014027319849 Adapter cache time: 0.024448464391753078 Engine time: 0.13474950031377375 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-8/adapters_32_slots_16_rate_0.0125-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-8/adapters_32_slots_16_rate_0.0125-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [10 11 11]
Adapter prompts. [135, 66, 33, 33, 66, 33, 135, 66, 33, 33, 33, 135, 135, 33, 33, 66, 66, 66, 135, 135, 33, 135, 135, 135, 135, 66, 33, 66, 66, 66, 66, 135]
Prompts retrieved: 2541 . Total input tokens: 554808 . Total output tokens: 519874
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.45042488700710237,
    "estimated_duration": 3598.008070038666,
    "input_throughput": 55.96735640391044,
    "output_throughput": 53.83006269853047,
    "total_throughput": 109.79741910244091,
    "itl": 17.551480048116954,
    "ttft": 4222.930019359484,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 357,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.092594124583995,
    "arrivals": 858,
    "finished_requests": 857,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.45052844705060124. Arrivals time: 0.012608899269253016 Scheduler time: 0.15170638961717486 Scheduler overhead time: 0.10636820737272501 Adapter cache time: 0.019024593057110906 Engine time: 0.10680667427368462 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-16/adapters_32_slots_16_rate_0.0125-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-16/adapters_32_slots_16_rate_0.0125-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [10 11 11]
Adapter prompts. [135, 66, 33, 33, 66, 33, 135, 66, 33, 33, 33, 135, 135, 33, 33, 66, 66, 66, 135, 135, 33, 135, 135, 135, 135, 66, 33, 66, 66, 66, 66, 135]
Prompts retrieved: 2541 . Total input tokens: 554808 . Total output tokens: 519874
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.42857812298461795,
    "estimated_duration": 3598.008070038666,
    "input_throughput": 55.96735640391044,
    "output_throughput": 53.83006269853047,
    "total_throughput": 109.79741910244091,
    "itl": 17.55182792568274,
    "ttft": 4222.958013433351,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 357,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1687795942532888,
    "arrivals": 858,
    "finished_requests": 857,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.4286537591833621. Arrivals time: 0.01212622132152319 Scheduler time: 0.1434489015955478 Scheduler overhead time: 0.1016475991345942 Adapter cache time: 0.018120917724445462 Engine time: 0.10171751724556088 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-32/adapters_32_slots_16_rate_0.0125-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-32/adapters_32_slots_16_rate_0.0125-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [10 11 11]
Adapter prompts. [135, 66, 33, 33, 66, 33, 135, 66, 33, 33, 33, 135, 135, 33, 33, 66, 66, 66, 135, 135, 33, 135, 135, 135, 135, 66, 33, 66, 66, 66, 66, 135]
Prompts retrieved: 2541 . Total input tokens: 554808 . Total output tokens: 519874
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.4526996589265764,
    "estimated_duration": 3598.008070038666,
    "input_throughput": 55.96735640391044,
    "output_throughput": 53.83006269853047,
    "total_throughput": 109.79741910244091,
    "itl": 17.55186191987127,
    "ttft": 4222.961116851104,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 357,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.170173607654876,
    "arrivals": 858,
    "finished_requests": 857,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.45277979713864625. Arrivals time: 0.012570664519444108 Scheduler time: 0.15341861313208938 Scheduler overhead time: 0.10733976983465254 Adapter cache time: 0.01954814908094704 Engine time: 0.105140594067052 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-16/adapters_32_slots_16_rate_0.0125-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-16/adapters_32_slots_16_rate_0.0125-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [10 11 11]
Adapter prompts. [135, 66, 33, 33, 66, 33, 135, 66, 33, 33, 33, 135, 135, 33, 33, 66, 66, 66, 135, 135, 33, 135, 135, 135, 135, 66, 33, 66, 66, 66, 66, 135]
Prompts retrieved: 2541 . Total input tokens: 554808 . Total output tokens: 519874
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 0.4468322789762169,
    "estimated_duration": 3598.008070038666,
    "input_throughput": 55.96735640391044,
    "output_throughput": 53.83006269853047,
    "total_throughput": 109.79741910244091,
    "itl": 17.551605501796736,
    "ttft": 4222.937370328644,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 357,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1189309654035624,
    "arrivals": 858,
    "finished_requests": 857,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.44691673084162176. Arrivals time: 0.012672452256083488 Scheduler time: 0.1506642361637205 Scheduler overhead time: 0.10533572337590158 Adapter cache time: 0.018888890044763684 Engine time: 0.10572214657440782 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-32/adapters_32_slots_16_rate_0.0125-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-32/adapters_32_slots_16_rate_0.0125-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [10 11 11]
Adapter prompts. [135, 66, 33, 33, 66, 33, 135, 66, 33, 33, 33, 135, 135, 33, 33, 66, 66, 66, 135, 135, 33, 135, 135, 135, 135, 66, 33, 66, 66, 66, 66, 135]
Prompts retrieved: 2541 . Total input tokens: 554808 . Total output tokens: 519874
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 0.41194130294024944,
    "estimated_duration": 3598.008070038666,
    "input_throughput": 55.96735640391044,
    "output_throughput": 53.83006269853047,
    "total_throughput": 109.79741910244091,
    "itl": 17.551935753069408,
    "ttft": 4222.97815881969,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 357,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1855155695974875,
    "arrivals": 858,
    "finished_requests": 857,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.4120202648919076. Arrivals time: 0.011766380397602916 Scheduler time: 0.13793653366155922 Scheduler overhead time: 0.09664113819599152 Adapter cache time: 0.017678050557151437 Engine time: 0.09864119603298604 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-16/adapters_32_slots_16_rate_0.0125-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-16/adapters_32_slots_16_rate_0.0125-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [10 11 11]
Adapter prompts. [135, 66, 33, 33, 66, 33, 135, 66, 33, 33, 33, 135, 135, 33, 33, 66, 66, 66, 135, 135, 33, 135, 135, 135, 135, 66, 33, 66, 66, 66, 66, 135]
Prompts retrieved: 2541 . Total input tokens: 554808 . Total output tokens: 519874
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.4258320399094373,
    "estimated_duration": 3598.008070038666,
    "input_throughput": 55.96735640391044,
    "output_throughput": 53.83006269853047,
    "total_throughput": 109.79741910244091,
    "itl": 17.551323470535678,
    "ttft": 4222.947485649037,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 357,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0674479552800757,
    "arrivals": 858,
    "finished_requests": 857,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.42593335499987006. Arrivals time: 0.011991630075499415 Scheduler time: 0.14128307136707008 Scheduler overhead time: 0.10114069958217442 Adapter cache time: 0.018593142507597804 Engine time: 0.10170090454630554 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-32/adapters_32_slots_16_rate_0.0125-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-32/adapters_32_slots_16_rate_0.0125-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [10 11 11]
Adapter prompts. [135, 66, 33, 33, 66, 33, 135, 66, 33, 33, 33, 135, 135, 33, 33, 66, 66, 66, 135, 135, 33, 135, 135, 135, 135, 66, 33, 66, 66, 66, 66, 135]
Prompts retrieved: 2541 . Total input tokens: 554808 . Total output tokens: 519874
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.4154598598834127,
    "estimated_duration": 3598.008070038666,
    "input_throughput": 55.96735640391044,
    "output_throughput": 53.83006269853047,
    "total_throughput": 109.79741910244091,
    "itl": 17.552021834464032,
    "ttft": 4223.014635431894,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 357,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2013605466857586,
    "arrivals": 858,
    "finished_requests": 857,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.4155504140071571. Arrivals time: 0.011817899299785495 Scheduler time: 0.13785080006346107 Scheduler overhead time: 0.09848618786782026 Adapter cache time: 0.017624271102249622 Engine time: 0.09881823556497693 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-8/adapters_32_slots_32_rate_3.2-1.6-0.8_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-8/adapters_32_slots_32_rate_3.2-1.6-0.8_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 8640, 8640, 17280, 8640, 34560, 17280, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 17280, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 656640 . Total input tokens: 146529371 . Total output tokens: 131331924
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 8.799516082042828,
    "estimated_duration": 3600.095215043596,
    "input_throughput": 7903.750401128052,
    "output_throughput": 7005.853871477278,
    "total_throughput": 14909.60427260533,
    "itl": 123.13085092161559,
    "ttft": 1346047.3024517011,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 218245,
    "finished_requests": 115017,
    "scheduler_time": 73.6138549270734
}
#Debug simulation 
Total elapsed time: 8.799741301918402. Arrivals time: 0.41492281714454293 Scheduler time: 8.256409224588424 Scheduler overhead time: 0.04803228913806379 Adapter cache time: 0.00795833277516067 Engine time: 0.04983872780576348 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-16/adapters_32_slots_32_rate_3.2-1.6-0.8_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-16/adapters_32_slots_32_rate_3.2-1.6-0.8_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 8640, 8640, 17280, 8640, 34560, 17280, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 17280, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 656640 . Total input tokens: 146529371 . Total output tokens: 131331924
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 9.845215850044042,
    "estimated_duration": 3600.130438885157,
    "input_throughput": 7903.722790891823,
    "output_throughput": 7005.78588141666,
    "total_throughput": 14909.508672308484,
    "itl": 123.13050909464468,
    "ttft": 1346053.4019679802,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255724,
    "arrivals": 218245,
    "finished_requests": 115018,
    "scheduler_time": 73.61452255721161
}
#Debug simulation 
Total elapsed time: 9.845438114833087. Arrivals time: 0.47281041042879224 Scheduler time: 9.229115021415055 Scheduler overhead time: 0.054385051131248474 Adapter cache time: 0.008927538990974426 Engine time: 0.05497679999098182 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-32/adapters_32_slots_32_rate_3.2-1.6-0.8_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-32/adapters_32_slots_32_rate_3.2-1.6-0.8_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 8640, 8640, 17280, 8640, 34560, 17280, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 17280, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 656640 . Total input tokens: 146529371 . Total output tokens: 131331924
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 9.899868877138942,
    "estimated_duration": 3600.1305771946113,
    "input_throughput": 7903.722487247397,
    "output_throughput": 7005.785612269084,
    "total_throughput": 14909.50809951648,
    "itl": 123.13050797571974,
    "ttft": 1346053.5143554874,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033038,
    "arrivals": 218245,
    "finished_requests": 115018,
    "scheduler_time": 73.61451952506768
}
#Debug simulation 
Total elapsed time: 9.90000044903718. Arrivals time: 0.4776855972595513 Scheduler time: 9.2780354951974 Scheduler overhead time: 0.05459006782621145 Adapter cache time: 0.008994027273729444 Engine time: 0.05530788144096732 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-16/adapters_32_slots_32_rate_3.2-1.6-0.8_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-16/adapters_32_slots_32_rate_3.2-1.6-0.8_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 8640, 8640, 17280, 8640, 34560, 17280, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 17280, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 656640 . Total input tokens: 146529371 . Total output tokens: 131331924
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 10.08757372200489,
    "estimated_duration": 3600.099953343857,
    "input_throughput": 7903.739998543936,
    "output_throughput": 7005.84465066684,
    "total_throughput": 14909.584649210776,
    "itl": 123.13081702540214,
    "ttft": 1346050.968360607,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971346,
    "arrivals": 218245,
    "finished_requests": 115017,
    "scheduler_time": 73.61385177782917
}
#Debug simulation 
Total elapsed time: 10.088178869104013. Arrivals time: 0.48784252791665494 Scheduler time: 9.452966383192688 Scheduler overhead time: 0.05589803331531584 Adapter cache time: 0.009164279792457819 Engine time: 0.05609628837555647 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-32/adapters_32_slots_32_rate_3.2-1.6-0.8_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-32/adapters_32_slots_32_rate_3.2-1.6-0.8_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 8640, 8640, 17280, 8640, 34560, 17280, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 17280, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 656640 . Total input tokens: 146529371 . Total output tokens: 131331924
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 9.860811117105186,
    "estimated_duration": 3600.132713260906,
    "input_throughput": 7903.717797732717,
    "output_throughput": 7005.781455527179,
    "total_throughput": 14909.499253259897,
    "itl": 123.13046939032266,
    "ttft": 1346054.5715747052,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089384,
    "arrivals": 218245,
    "finished_requests": 115018,
    "scheduler_time": 73.61450261412325
}
#Debug simulation 
Total elapsed time: 9.860947017092258. Arrivals time: 0.4968937241937965 Scheduler time: 9.220691004768014 Scheduler overhead time: 0.05440970626659691 Adapter cache time: 0.008901100140064955 Engine time: 0.05487887538038194 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-16/adapters_32_slots_32_rate_3.2-1.6-0.8_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-16/adapters_32_slots_32_rate_3.2-1.6-0.8_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 8640, 8640, 17280, 8640, 34560, 17280, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 17280, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 656640 . Total input tokens: 146529371 . Total output tokens: 131331924
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 8.71681403904222,
    "estimated_duration": 3600.0750300301265,
    "input_throughput": 7903.794716123426,
    "output_throughput": 7005.893152118259,
    "total_throughput": 14909.687868241686,
    "itl": 123.13062583682277,
    "ttft": 1346015.3910549881,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 218245,
    "finished_requests": 115017,
    "scheduler_time": 73.61344226306676
}
#Debug simulation 
Total elapsed time: 8.716948217945173. Arrivals time: 0.4104188389610499 Scheduler time: 8.180288492701948 Scheduler overhead time: 0.047379470663145185 Adapter cache time: 0.007870947709307075 Engine time: 0.04874424519948661 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-32/adapters_32_slots_32_rate_3.2-1.6-0.8_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-32/adapters_32_slots_32_rate_3.2-1.6-0.8_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 8640, 8640, 17280, 8640, 34560, 17280, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 17280, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 656640 . Total input tokens: 146529371 . Total output tokens: 131331924
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 9.386300868121907,
    "estimated_duration": 3600.1328909038443,
    "input_throughput": 7903.717407736099,
    "output_throughput": 7005.781109837827,
    "total_throughput": 14909.498517573926,
    "itl": 123.13036518187849,
    "ttft": 1346055.09441096,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.1075786313414573,
    "arrivals": 218245,
    "finished_requests": 115018,
    "scheduler_time": 73.6144345489486
}
#Debug simulation 
Total elapsed time: 9.386426338925958. Arrivals time: 0.46534492494538426 Scheduler time: 8.78533990867436 Scheduler overhead time: 0.05171368340961635 Adapter cache time: 0.008545317687094212 Engine time: 0.051517033483833075 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-8/adapters_32_slots_32_rate_3.2-1.6-0.4_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-8/adapters_32_slots_32_rate_3.2-1.6-0.4_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 4320, 4320, 17280, 4320, 34560, 17280, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 17280, 17280, 17280, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 17280, 4320, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 613440 . Total input tokens: 136853950 . Total output tokens: 122688465
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 9.86951379594393,
    "estimated_duration": 3600.037391154924,
    "input_throughput": 7895.039109824865,
    "output_throughput": 7003.121984772476,
    "total_throughput": 14898.16109459734,
    "itl": 123.33320413317448,
    "ttft": 1295924.7279017824,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 203816,
    "finished_requests": 114770,
    "scheduler_time": 74.2228798248215
}
#Debug simulation 
Total elapsed time: 9.86969800805673. Arrivals time: 0.45696975477039814 Scheduler time: 9.268992237513885 Scheduler overhead time: 0.05462908442132175 Adapter cache time: 0.00909577147103846 Engine time: 0.05463733780197799 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-16/adapters_32_slots_32_rate_3.2-1.6-0.4_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-16/adapters_32_slots_32_rate_3.2-1.6-0.4_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 4320, 4320, 17280, 4320, 34560, 17280, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 17280, 17280, 17280, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 17280, 4320, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 613440 . Total input tokens: 136853950 . Total output tokens: 122688465
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 9.665400735102594,
    "estimated_duration": 3600.0793262822167,
    "input_throughput": 7894.947145331851,
    "output_throughput": 7003.040409677802,
    "total_throughput": 14897.987555009653,
    "itl": 123.33360591337218,
    "ttft": 1295944.2872022658,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255726,
    "arrivals": 203816,
    "finished_requests": 114770,
    "scheduler_time": 74.22372001502228
}
#Debug simulation 
Total elapsed time: 9.66554488404654. Arrivals time: 0.4740999925415963 Scheduler time: 9.050016562221572 Scheduler overhead time: 0.053725288482382894 Adapter cache time: 0.008908769581466913 Engine time: 0.05392518197186291 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-32/adapters_32_slots_32_rate_3.2-1.6-0.4_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-32/adapters_32_slots_32_rate_3.2-1.6-0.4_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 4320, 4320, 17280, 4320, 34560, 17280, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 17280, 17280, 17280, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 17280, 4320, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 613440 . Total input tokens: 136853950 . Total output tokens: 122688465
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 9.397794437827542,
    "estimated_duration": 3600.07979614079,
    "input_throughput": 7894.946114935634,
    "output_throughput": 7003.039495687345,
    "total_throughput": 14897.985610622978,
    "itl": 123.33360515844093,
    "ttft": 1295944.6180773193,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.1048120480403304,
    "arrivals": 203816,
    "finished_requests": 114770,
    "scheduler_time": 74.22372146670166
}
#Debug simulation 
Total elapsed time: 9.3979211919941. Arrivals time: 0.46563235647045076 Scheduler time: 8.796080529689789 Scheduler overhead time: 0.051575250923633575 Adapter cache time: 0.008656357415020466 Engine time: 0.051960305543616414 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-16-16/adapters_32_slots_32_rate_3.2-1.6-0.4_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-16-16/adapters_32_slots_32_rate_3.2-1.6-0.4_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 4320, 4320, 17280, 4320, 34560, 17280, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 17280, 17280, 17280, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 17280, 4320, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 613440 . Total input tokens: 136853950 . Total output tokens: 122688465
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 8.645854736911133,
    "estimated_duration": 3600.050382265175,
    "input_throughput": 7895.010619855942,
    "output_throughput": 7003.096713367872,
    "total_throughput": 14898.107333223816,
    "itl": 123.3334125263631,
    "ttft": 1295940.6252140608,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971346,
    "arrivals": 203816,
    "finished_requests": 114770,
    "scheduler_time": 74.22320628938198
}
#Debug simulation 
Total elapsed time: 8.646011102944613. Arrivals time: 0.41185377701185644 Scheduler time: 8.109258027980104 Scheduler overhead time: 0.04718280560337007 Adapter cache time: 0.007937267888337374 Engine time: 0.04776446474716067 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-16-32/adapters_32_slots_32_rate_3.2-1.6-0.4_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-16-32/adapters_32_slots_32_rate_3.2-1.6-0.4_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 4320, 4320, 17280, 4320, 34560, 17280, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 17280, 17280, 17280, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 17280, 4320, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 613440 . Total input tokens: 136853950 . Total output tokens: 122688465
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 9.333265261957422,
    "estimated_duration": 3600.0811226065252,
    "input_throughput": 7894.943206007989,
    "output_throughput": 7003.0369153866195,
    "total_throughput": 14897.980121394608,
    "itl": 123.33318352468928,
    "ttft": 1295958.9779124146,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089386,
    "arrivals": 203816,
    "finished_requests": 114770,
    "scheduler_time": 74.22367375713065
}
#Debug simulation 
Total elapsed time: 9.333396557951346. Arrivals time: 0.4664813887793571 Scheduler time: 8.730866908095777 Scheduler overhead time: 0.05154605582356453 Adapter cache time: 0.00861601741053164 Engine time: 0.05183364497497678 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_16-16-16/adapters_32_slots_32_rate_3.2-1.6-0.4_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_16-16-16/adapters_32_slots_32_rate_3.2-1.6-0.4_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 4320, 4320, 17280, 4320, 34560, 17280, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 17280, 17280, 17280, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 17280, 4320, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 613440 . Total input tokens: 136853950 . Total output tokens: 122688465
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 9.208700991002843,
    "estimated_duration": 3600.031084702593,
    "input_throughput": 7895.052940174277,
    "output_throughput": 7003.134252681815,
    "total_throughput": 14898.187192856092,
    "itl": 123.33326687966616,
    "ttft": 1295926.2414987544,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 203816,
    "finished_requests": 114770,
    "scheduler_time": 74.22279379512355
}
#Debug simulation 
Total elapsed time: 9.208826115820557. Arrivals time: 0.4301560497842729 Scheduler time: 8.645416254876181 Scheduler overhead time: 0.050360454712063074 Adapter cache time: 0.008569525787606835 Engine time: 0.05074157007038593 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_16-16-32/adapters_32_slots_32_rate_3.2-1.6-0.4_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_16-16-32/adapters_32_slots_32_rate_3.2-1.6-0.4_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 4320, 4320, 17280, 4320, 34560, 17280, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 17280, 17280, 17280, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 17280, 4320, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 613440 . Total input tokens: 136853950 . Total output tokens: 122688465
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 9.930953736184165,
    "estimated_duration": 3600.08777108741,
    "input_throughput": 7894.928625980409,
    "output_throughput": 7003.023982491638,
    "total_throughput": 14897.952608472047,
    "itl": 123.33311678846914,
    "ttft": 1295960.3132902517,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.1075786313414573,
    "arrivals": 203816,
    "finished_requests": 114770,
    "scheduler_time": 74.22378844585408
}
#Debug simulation 
Total elapsed time: 9.931130497017875. Arrivals time: 0.4774299282580614 Scheduler time: 9.308961406815797 Scheduler overhead time: 0.05526717100292444 Adapter cache time: 0.009180657332763076 Engine time: 0.05464610015042126 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-8/adapters_32_slots_32_rate_3.2-1.6-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-8/adapters_32_slots_32_rate_3.2-1.6-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 1080, 1080, 17280, 1080, 34560, 17280, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 17280, 17280, 17280, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 17280, 1080, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 581040 . Total input tokens: 129651291 . Total output tokens: 116171458
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 9.612496532965451,
    "estimated_duration": 3600.1074944764464,
    "input_throughput": 8053.626744336007,
    "output_throughput": 7072.769643425043,
    "total_throughput": 15126.39638776105,
    "itl": 121.16703141725175,
    "ttft": 1231359.5593065694,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 193289,
    "finished_requests": 116413,
    "scheduler_time": 75.45451023194647
}
#Debug simulation 
Total elapsed time: 9.612643676809967. Arrivals time: 0.4536635570693761 Scheduler time: 9.014111243421212 Scheduler overhead time: 0.05325544020161033 Adapter cache time: 0.012525136582553387 Engine time: 0.054291546577587724 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-16/adapters_32_slots_32_rate_3.2-1.6-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-16/adapters_32_slots_32_rate_3.2-1.6-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 1080, 1080, 17280, 1080, 34560, 17280, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 17280, 17280, 17280, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 17280, 1080, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 581040 . Total input tokens: 129651291 . Total output tokens: 116171458
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 9.162310014944524,
    "estimated_duration": 3600.047374488163,
    "input_throughput": 8053.658461681261,
    "output_throughput": 7072.887201552498,
    "total_throughput": 15126.54566323376,
    "itl": 121.16871594046036,
    "ttft": 1231361.4489213051,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255727,
    "arrivals": 193289,
    "finished_requests": 116412,
    "scheduler_time": 75.45292763245507
}
#Debug simulation 
Total elapsed time: 9.162444596877322. Arrivals time: 0.4210926895029843 Scheduler time: 8.60511895804666 Scheduler overhead time: 0.05058214766904712 Adapter cache time: 0.011578191770240664 Engine time: 0.05054687475785613 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-32/adapters_32_slots_32_rate_3.2-1.6-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-32/adapters_32_slots_32_rate_3.2-1.6-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 1080, 1080, 17280, 1080, 34560, 17280, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 17280, 17280, 17280, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 17280, 1080, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 581040 . Total input tokens: 129651291 . Total output tokens: 116171458
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 9.289388892007992,
    "estimated_duration": 3600.0475134532153,
    "input_throughput": 8053.658150802845,
    "output_throughput": 7072.886928532729,
    "total_throughput": 15126.545079335574,
    "itl": 121.16871846159346,
    "ttft": 1231361.5616986337,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033041,
    "arrivals": 193289,
    "finished_requests": 116412,
    "scheduler_time": 75.45292525590983
}
#Debug simulation 
Total elapsed time: 9.289523033192381. Arrivals time: 0.4403426081407815 Scheduler time: 8.7098289700225 Scheduler overhead time: 0.05158053571358323 Adapter cache time: 0.012246494181454182 Engine time: 0.051528657553717494 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-16-16/adapters_32_slots_32_rate_3.2-1.6-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-16-16/adapters_32_slots_32_rate_3.2-1.6-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 1080, 1080, 17280, 1080, 34560, 17280, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 17280, 17280, 17280, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 17280, 1080, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 581040 . Total input tokens: 129651291 . Total output tokens: 116171458
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 9.158405337948352,
    "estimated_duration": 3600.118301301453,
    "input_throughput": 8053.6025689818625,
    "output_throughput": 7072.74841240499,
    "total_throughput": 15126.350981386853,
    "itl": 121.16711384665142,
    "ttft": 1231360.8748813777,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971348,
    "arrivals": 193289,
    "finished_requests": 116413,
    "scheduler_time": 75.45465798156816
}
#Debug simulation 
Total elapsed time: 9.15857375995256. Arrivals time: 0.4208223829045892 Scheduler time: 8.601189093664289 Scheduler overhead time: 0.05065116472542286 Adapter cache time: 0.011845799628645182 Engine time: 0.050581726245582104 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-16-32/adapters_32_slots_32_rate_3.2-1.6-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-16-32/adapters_32_slots_32_rate_3.2-1.6-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 1080, 1080, 17280, 1080, 34560, 17280, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 17280, 17280, 17280, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 17280, 1080, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 581040 . Total input tokens: 129651291 . Total output tokens: 116171458
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 9.474900978151709,
    "estimated_duration": 3600.050212963333,
    "input_throughput": 8053.652111739394,
    "output_throughput": 7072.8816249039755,
    "total_throughput": 15126.533736643369,
    "itl": 121.16863863883854,
    "ttft": 1231363.7101233068,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089387,
    "arrivals": 193289,
    "finished_requests": 116412,
    "scheduler_time": 75.45290347479877
}
#Debug simulation 
Total elapsed time: 9.475029565161094. Arrivals time: 0.45092602889053524 Scheduler time: 8.882211522432044 Scheduler overhead time: 0.052381423534825444 Adapter cache time: 0.012512307846918702 Engine time: 0.052666716976091266 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_16-16-16/adapters_32_slots_32_rate_3.2-1.6-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_16-16-16/adapters_32_slots_32_rate_3.2-1.6-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 1080, 1080, 17280, 1080, 34560, 17280, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 17280, 17280, 17280, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 17280, 1080, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 581040 . Total input tokens: 129651291 . Total output tokens: 116171458
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 9.67789640603587,
    "estimated_duration": 3600.106590448629,
    "input_throughput": 8053.628766693519,
    "output_throughput": 7072.771419478152,
    "total_throughput": 15126.40018617167,
    "itl": 121.16725301736416,
    "ttft": 1231358.5114379444,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 193289,
    "finished_requests": 116413,
    "scheduler_time": 75.45445866213008
}
#Debug simulation 
Total elapsed time: 9.67801841115579. Arrivals time: 0.4665510810445994 Scheduler time: 9.066666597034782 Scheduler overhead time: 0.05377690168097615 Adapter cache time: 0.012915362371131778 Engine time: 0.053254937985911965 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_16-16-32/adapters_32_slots_32_rate_3.2-1.6-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_16-16-32/adapters_32_slots_32_rate_3.2-1.6-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 1080, 1080, 17280, 1080, 34560, 17280, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 17280, 17280, 17280, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 17280, 1080, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 581040 . Total input tokens: 129651291 . Total output tokens: 116171458
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 9.670438919914886,
    "estimated_duration": 3600.0506550737873,
    "input_throughput": 8053.6511226967,
    "output_throughput": 7072.8807563065,
    "total_throughput": 15126.531879003202,
    "itl": 121.16855429361395,
    "ttft": 1231364.1873871975,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145734,
    "arrivals": 193289,
    "finished_requests": 116412,
    "scheduler_time": 75.45290540060785
}
#Debug simulation 
Total elapsed time: 9.67056108196266. Arrivals time: 0.46061467146500945 Scheduler time: 9.064873582916334 Scheduler overhead time: 0.05392628093250096 Adapter cache time: 0.012922624358907342 Engine time: 0.05355282174423337 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-8/adapters_32_slots_32_rate_3.2-1.6-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-8/adapters_32_slots_32_rate_3.2-1.6-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 540, 540, 17280, 540, 34560, 17280, 540, 540, 540, 34560, 34560, 540, 540, 17280, 17280, 17280, 34560, 34560, 540, 34560, 34560, 34560, 34560, 17280, 540, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 575640 . Total input tokens: 128448450 . Total output tokens: 115096958
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 10.036849537864327,
    "estimated_duration": 3600.0161683785536,
    "input_throughput": 8170.543859876079,
    "output_throughput": 7192.466863742504,
    "total_throughput": 15363.010723618583,
    "itl": 119.33713682894295,
    "ttft": 1204536.7988048964,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 191429,
    "finished_requests": 118570,
    "scheduler_time": 76.8477203930772
}
#Debug simulation 
Total elapsed time: 10.036967045860365. Arrivals time: 0.4841763465665281 Scheduler time: 9.402515948517248 Scheduler overhead time: 0.055492938961833715 Adapter cache time: 0.013770054094493389 Engine time: 0.05532249854877591 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-16/adapters_32_slots_32_rate_3.2-1.6-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-16/adapters_32_slots_32_rate_3.2-1.6-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 540, 540, 17280, 540, 34560, 17280, 540, 540, 540, 34560, 34560, 540, 540, 17280, 17280, 17280, 34560, 34560, 540, 34560, 34560, 34560, 34560, 17280, 540, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 575640 . Total input tokens: 128448450 . Total output tokens: 115096958
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 9.485076651209965,
    "estimated_duration": 3600.0671348539263,
    "input_throughput": 8170.44346624205,
    "output_throughput": 7192.365594885112,
    "total_throughput": 15362.809061127162,
    "itl": 119.33733779016963,
    "ttft": 1204576.8595737056,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255727,
    "arrivals": 191429,
    "finished_requests": 118571,
    "scheduler_time": 76.84839793628227
}
#Debug simulation 
Total elapsed time: 9.485176280140877. Arrivals time: 0.4067492976319045 Scheduler time: 8.942330757156014 Scheduler overhead time: 0.050167204812169075 Adapter cache time: 0.011968183564022183 Engine time: 0.05056623904965818 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-32/adapters_32_slots_32_rate_3.2-1.6-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-32/adapters_32_slots_32_rate_3.2-1.6-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 540, 540, 17280, 540, 34560, 17280, 540, 540, 540, 34560, 34560, 540, 540, 17280, 17280, 17280, 34560, 34560, 540, 34560, 34560, 34560, 34560, 17280, 540, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 575640 . Total input tokens: 128448450 . Total output tokens: 115096958
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 9.691910162102431,
    "estimated_duration": 3600.0672743897826,
    "input_throughput": 8170.443149561906,
    "output_throughput": 7192.3653161145185,
    "total_throughput": 15362.808465676424,
    "itl": 119.33733774583584,
    "ttft": 1204576.9727593977,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033041,
    "arrivals": 191429,
    "finished_requests": 118571,
    "scheduler_time": 76.84839531388752
}
#Debug simulation 
Total elapsed time: 9.692055193008855. Arrivals time: 0.4508844465017319 Scheduler time: 9.09561869269237 Scheduler overhead time: 0.053619987331330776 Adapter cache time: 0.013480052351951599 Engine time: 0.05371156893670559 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-16-16/adapters_32_slots_32_rate_3.2-1.6-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-16-16/adapters_32_slots_32_rate_3.2-1.6-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 540, 540, 17280, 540, 34560, 17280, 540, 540, 540, 34560, 34560, 540, 540, 17280, 17280, 17280, 34560, 34560, 540, 34560, 34560, 34560, 34560, 17280, 540, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 575640 . Total input tokens: 128448450 . Total output tokens: 115096958
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 9.41596756502986,
    "estimated_duration": 3600.024781917676,
    "input_throughput": 8170.524310760878,
    "output_throughput": 7192.449654806879,
    "total_throughput": 15362.973965567757,
    "itl": 119.33717856295146,
    "ttft": 1204541.57662687,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971346,
    "arrivals": 191429,
    "finished_requests": 118570,
    "scheduler_time": 76.84769971826483
}
#Debug simulation 
Total elapsed time: 9.416167791001499. Arrivals time: 0.43061350914649665 Scheduler time: 8.845599838299677 Scheduler overhead time: 0.05132299708202481 Adapter cache time: 0.012752135749906301 Engine time: 0.05161445261910558 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-16-32/adapters_32_slots_32_rate_3.2-1.6-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-16-32/adapters_32_slots_32_rate_3.2-1.6-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 540, 540, 17280, 540, 34560, 17280, 540, 540, 540, 34560, 34560, 540, 540, 17280, 17280, 17280, 34560, 34560, 540, 34560, 34560, 34560, 34560, 17280, 540, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 575640 . Total input tokens: 128448450 . Total output tokens: 115096958
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 10.375238426029682,
    "estimated_duration": 3600.0729921848565,
    "input_throughput": 8170.430172902907,
    "output_throughput": 7192.353892881972,
    "total_throughput": 15362.784065784877,
    "itl": 119.33725578317991,
    "ttft": 1204577.3906750842,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089387,
    "arrivals": 191429,
    "finished_requests": 118571,
    "scheduler_time": 76.84837871903385
}
#Debug simulation 
Total elapsed time: 10.375325775006786. Arrivals time: 0.44724822463467717 Scheduler time: 9.77752313343808 Scheduler overhead time: 0.05592382303439081 Adapter cache time: 0.013177560642361641 Engine time: 0.05555429426021874 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_16-16-16/adapters_32_slots_32_rate_3.2-1.6-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_16-16-16/adapters_32_slots_32_rate_3.2-1.6-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 540, 540, 17280, 540, 34560, 17280, 540, 540, 540, 34560, 34560, 540, 540, 17280, 17280, 17280, 34560, 34560, 540, 34560, 34560, 34560, 34560, 17280, 540, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 575640 . Total input tokens: 128448450 . Total output tokens: 115096958
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 9.169105872046202,
    "estimated_duration": 3600.0027695921467,
    "input_throughput": 8170.574269678241,
    "output_throughput": 7192.493633257255,
    "total_throughput": 15363.067902935496,
    "itl": 119.33721453797504,
    "ttft": 1204538.4514679501,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 191429,
    "finished_requests": 118570,
    "scheduler_time": 76.84727249061716
}
#Debug simulation 
Total elapsed time: 9.169229282066226. Arrivals time: 0.42762976768426597 Scheduler time: 8.605129018425941 Scheduler overhead time: 0.049957943148911 Adapter cache time: 0.01251147035509348 Engine time: 0.05041571240872145 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_16-16-32/adapters_32_slots_32_rate_3.2-1.6-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_16-16-32/adapters_32_slots_32_rate_3.2-1.6-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 540, 540, 17280, 540, 34560, 17280, 540, 540, 540, 34560, 34560, 540, 540, 17280, 17280, 17280, 34560, 34560, 540, 34560, 34560, 34560, 34560, 17280, 540, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 575640 . Total input tokens: 128448450 . Total output tokens: 115096958
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 9.313118422869593,
    "estimated_duration": 3600.076255546264,
    "input_throughput": 8170.422766652423,
    "output_throughput": 7192.347373228371,
    "total_throughput": 15362.770139880793,
    "itl": 119.33722566555002,
    "ttft": 1204579.210774117,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145734,
    "arrivals": 191429,
    "finished_requests": 118571,
    "scheduler_time": 76.84837852863487
}
#Debug simulation 
Total elapsed time: 9.313239625887945. Arrivals time: 0.42372635123319924 Scheduler time: 8.750820511486381 Scheduler overhead time: 0.05112856440246105 Adapter cache time: 0.01272403378970921 Engine time: 0.05105735035613179 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-8/adapters_32_slots_32_rate_3.2-1.6-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-8/adapters_32_slots_32_rate_3.2-1.6-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 270, 270, 17280, 270, 34560, 17280, 270, 270, 270, 34560, 34560, 270, 270, 17280, 17280, 17280, 34560, 34560, 270, 34560, 34560, 34560, 34560, 17280, 270, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 572940 . Total input tokens: 127851067 . Total output tokens: 114578169
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 9.900119384983554,
    "estimated_duration": 3600.1170069466702,
    "input_throughput": 8264.112233739053,
    "output_throughput": 7339.575338527718,
    "total_throughput": 15603.68757226677,
    "itl": 117.56121130755005,
    "ttft": 1177012.7293505943,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 190474,
    "finished_requests": 120410,
    "scheduler_time": 78.81766507129933
}
#Debug simulation 
Total elapsed time: 9.900252543156967. Arrivals time: 0.46713416022248566 Scheduler time: 9.285082343500108 Scheduler overhead time: 0.05492470879107714 Adapter cache time: 0.013003879925236106 Engine time: 0.054560750257223845 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-16/adapters_32_slots_32_rate_3.2-1.6-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-16/adapters_32_slots_32_rate_3.2-1.6-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 270, 270, 17280, 270, 34560, 17280, 270, 270, 270, 34560, 34560, 270, 270, 17280, 17280, 17280, 34560, 34560, 270, 34560, 34560, 34560, 34560, 17280, 270, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 572940 . Total input tokens: 127851067 . Total output tokens: 114578169
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 9.607512729940936,
    "estimated_duration": 3600.1195277548227,
    "input_throughput": 8264.1681118167,
    "output_throughput": 7339.570754885085,
    "total_throughput": 15603.738866701784,
    "itl": 117.56000831368763,
    "ttft": 1177014.0153753727,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255728,
    "arrivals": 190474,
    "finished_requests": 120411,
    "scheduler_time": 78.81773118717591
}
#Debug simulation 
Total elapsed time: 9.607662978116423. Arrivals time: 0.4316840211395174 Scheduler time: 9.034077157499269 Scheduler overhead time: 0.05270978738553822 Adapter cache time: 0.011785267386585474 Engine time: 0.0529016237705946 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-32/adapters_32_slots_32_rate_3.2-1.6-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-32/adapters_32_slots_32_rate_3.2-1.6-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 270, 270, 17280, 270, 34560, 17280, 270, 270, 270, 34560, 34560, 270, 270, 17280, 17280, 17280, 34560, 34560, 270, 34560, 34560, 34560, 34560, 17280, 270, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 572940 . Total input tokens: 127851067 . Total output tokens: 114578169
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 9.33463356201537,
    "estimated_duration": 3600.119667495553,
    "input_throughput": 8264.167791038226,
    "output_throughput": 7339.570469995394,
    "total_throughput": 15603.73826103362,
    "itl": 117.56001926015591,
    "ttft": 1177014.1240480673,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033042,
    "arrivals": 190474,
    "finished_requests": 120411,
    "scheduler_time": 78.81772876965574
}
#Debug simulation 
Total elapsed time: 9.334739820100367. Arrivals time: 0.42947775847278535 Scheduler time: 8.767211890313774 Scheduler overhead time: 0.0512213537003845 Adapter cache time: 0.011924560414627194 Engine time: 0.051105467369779944 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-16-16/adapters_32_slots_32_rate_3.2-1.6-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-16-16/adapters_32_slots_32_rate_3.2-1.6-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 270, 270, 17280, 270, 34560, 17280, 270, 270, 270, 34560, 34560, 270, 270, 17280, 17280, 17280, 34560, 34560, 270, 34560, 34560, 34560, 34560, 17280, 270, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 572940 . Total input tokens: 127851067 . Total output tokens: 114578169
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 10.174845179077238,
    "estimated_duration": 3600.1188657277285,
    "input_throughput": 8264.16963151741,
    "output_throughput": 7339.572104561271,
    "total_throughput": 15603.741736078682,
    "itl": 117.56048505850961,
    "ttft": 1177013.5564137953,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971348,
    "arrivals": 190474,
    "finished_requests": 120411,
    "scheduler_time": 78.81767320187852
}
#Debug simulation 
Total elapsed time: 10.17500867601484. Arrivals time: 0.4722718303091824 Scheduler time: 9.551341289654374 Scheduler overhead time: 0.0564019693993032 Adapter cache time: 0.012823622208088636 Engine time: 0.056058757938444614 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-16-32/adapters_32_slots_32_rate_3.2-1.6-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-16-32/adapters_32_slots_32_rate_3.2-1.6-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 270, 270, 17280, 270, 34560, 17280, 270, 270, 270, 34560, 34560, 270, 270, 17280, 17280, 17280, 34560, 34560, 270, 34560, 34560, 34560, 34560, 17280, 270, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 572940 . Total input tokens: 127851067 . Total output tokens: 114578169
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 9.379907190101221,
    "estimated_duration": 3600.1161051005215,
    "input_throughput": 8264.175968616233,
    "output_throughput": 7339.577732663768,
    "total_throughput": 15603.75370128,
    "itl": 117.5596683556455,
    "ttft": 1177013.0663329675,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089387,
    "arrivals": 190474,
    "finished_requests": 120411,
    "scheduler_time": 78.81764936028888
}
#Debug simulation 
Total elapsed time: 9.380006856983528. Arrivals time: 0.4275433914735913 Scheduler time: 8.813381114276126 Scheduler overhead time: 0.05141710978932679 Adapter cache time: 0.011827511480078101 Engine time: 0.05156629625707865 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_16-16-16/adapters_32_slots_32_rate_3.2-1.6-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_16-16-16/adapters_32_slots_32_rate_3.2-1.6-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 270, 270, 17280, 270, 34560, 17280, 270, 270, 270, 34560, 34560, 270, 270, 17280, 17280, 17280, 34560, 34560, 270, 34560, 34560, 34560, 34560, 17280, 270, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 572940 . Total input tokens: 127851067 . Total output tokens: 114578169
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 10.056645174976438,
    "estimated_duration": 3600.0914986136045,
    "input_throughput": 8264.170788841731,
    "output_throughput": 7339.627342853821,
    "total_throughput": 15603.798131695552,
    "itl": 117.56059575641927,
    "ttft": 1177007.9417770032,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 190474,
    "finished_requests": 120410,
    "scheduler_time": 78.8174526516083
}
#Debug simulation 
Total elapsed time: 10.056763089029118. Arrivals time: 0.4924721880815923 Scheduler time: 9.415345712797716 Scheduler overhead time: 0.055415102979168296 Adapter cache time: 0.012950016185641289 Engine time: 0.05502453679218888 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_16-16-32/adapters_32_slots_32_rate_3.2-1.6-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_16-16-32/adapters_32_slots_32_rate_3.2-1.6-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 270, 270, 17280, 270, 34560, 17280, 270, 270, 270, 34560, 34560, 270, 270, 17280, 17280, 17280, 34560, 34560, 270, 34560, 34560, 34560, 34560, 17280, 270, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 572940 . Total input tokens: 127851067 . Total output tokens: 114578169
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 9.762468575965613,
    "estimated_duration": 3600.1145387754386,
    "input_throughput": 8264.179564164644,
    "output_throughput": 7339.580925941253,
    "total_throughput": 15603.760490105897,
    "itl": 117.55942641384787,
    "ttft": 1177012.546610128,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145734,
    "arrivals": 190474,
    "finished_requests": 120411,
    "scheduler_time": 78.81776339034329
}
#Debug simulation 
Total elapsed time: 9.762620036955923. Arrivals time: 0.4587759361602366 Scheduler time: 9.158801037818193 Scheduler overhead time: 0.05392777221277356 Adapter cache time: 0.012531658401712775 Engine time: 0.05360672948881984 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-8/adapters_32_slots_32_rate_3.2-1.6-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-8/adapters_32_slots_32_rate_3.2-1.6-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 135, 135, 17280, 135, 34560, 17280, 135, 135, 135, 34560, 34560, 135, 135, 17280, 17280, 17280, 34560, 34560, 135, 34560, 34560, 34560, 34560, 17280, 135, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 571590 . Total input tokens: 127539524 . Total output tokens: 114313627
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 9.65483913407661,
    "estimated_duration": 3600.1196120873205,
    "input_throughput": 8411.156923323228,
    "output_throughput": 7403.999553377473,
    "total_throughput": 15815.1564767007,
    "itl": 115.92981972339449,
    "ttft": 1161863.8537175858,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 190041,
    "finished_requests": 121848,
    "scheduler_time": 79.47811002920459
}
#Debug simulation 
Total elapsed time: 9.654965494992211. Arrivals time: 0.48485025204718113 Scheduler time: 9.026960231130943 Scheduler overhead time: 0.05327760451473296 Adapter cache time: 0.011883959639817476 Engine time: 0.05333704757504165 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-16/adapters_32_slots_32_rate_3.2-1.6-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-16/adapters_32_slots_32_rate_3.2-1.6-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 135, 135, 17280, 135, 34560, 17280, 135, 135, 135, 34560, 34560, 135, 135, 17280, 17280, 17280, 34560, 34560, 135, 34560, 34560, 34560, 34560, 17280, 135, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 571590 . Total input tokens: 127539524 . Total output tokens: 114313627
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 9.682963747065514,
    "estimated_duration": 3600.04429769801,
    "input_throughput": 8410.86983828553,
    "output_throughput": 7403.933061891427,
    "total_throughput": 15814.802900176957,
    "itl": 115.93069841625655,
    "ttft": 1161865.1961716826,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255728,
    "arrivals": 190041,
    "finished_requests": 121844,
    "scheduler_time": 79.4764506017654
}
#Debug simulation 
Total elapsed time: 9.68308731005527. Arrivals time: 0.4636894171126187 Scheduler time: 9.075466721784323 Scheduler overhead time: 0.053456660360097885 Adapter cache time: 0.011823939392343163 Engine time: 0.05399134359322488 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-32/adapters_32_slots_32_rate_3.2-1.6-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-32/adapters_32_slots_32_rate_3.2-1.6-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 135, 135, 17280, 135, 34560, 17280, 135, 135, 135, 34560, 34560, 135, 135, 17280, 17280, 17280, 34560, 34560, 135, 34560, 34560, 34560, 34560, 17280, 135, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 571590 . Total input tokens: 127539524 . Total output tokens: 114313627
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 10.02646921412088,
    "estimated_duration": 3600.042044492351,
    "input_throughput": 8410.875102507247,
    "output_throughput": 7403.937695888382,
    "total_throughput": 15814.81279839563,
    "itl": 115.93072861494149,
    "ttft": 1161863.798809529,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033041,
    "arrivals": 190041,
    "finished_requests": 121844,
    "scheduler_time": 79.476394032997
}
#Debug simulation 
Total elapsed time: 10.026547324145213. Arrivals time: 0.449290715623647 Scheduler time: 9.433845751686022 Scheduler overhead time: 0.05360745405778289 Adapter cache time: 0.011610893998295069 Engine time: 0.05349962669424713 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-16/adapters_32_slots_32_rate_3.2-1.6-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-16/adapters_32_slots_32_rate_3.2-1.6-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 135, 135, 17280, 135, 34560, 17280, 135, 135, 135, 34560, 34560, 135, 135, 17280, 17280, 17280, 34560, 34560, 135, 34560, 34560, 34560, 34560, 17280, 135, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 571590 . Total input tokens: 127539524 . Total output tokens: 114313627
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 10.544673889875412,
    "estimated_duration": 3600.001339961771,
    "input_throughput": 8410.801869401954,
    "output_throughput": 7404.01835524957,
    "total_throughput": 15814.820224651523,
    "itl": 115.9304704564106,
    "ttft": 1161879.513667625,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971348,
    "arrivals": 190041,
    "finished_requests": 121843,
    "scheduler_time": 79.47549452283688
}
#Debug simulation 
Total elapsed time: 10.54485543188639. Arrivals time: 0.5278684173244983 Scheduler time: 9.86003974918276 Scheduler overhead time: 0.058730371529236436 Adapter cache time: 0.012887486955150962 Engine time: 0.05825844476930797 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-32/adapters_32_slots_32_rate_3.2-1.6-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-32/adapters_32_slots_32_rate_3.2-1.6-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 135, 135, 17280, 135, 34560, 17280, 135, 135, 135, 34560, 34560, 135, 135, 17280, 17280, 17280, 34560, 34560, 135, 34560, 34560, 34560, 34560, 17280, 135, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 571590 . Total input tokens: 127539524 . Total output tokens: 114313627
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 9.939194175880402,
    "estimated_duration": 3600.044595217473,
    "input_throughput": 8410.869143183729,
    "output_throughput": 7403.932450006177,
    "total_throughput": 15814.801593189904,
    "itl": 115.93055566395506,
    "ttft": 1161865.4986482176,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089388,
    "arrivals": 190041,
    "finished_requests": 121844,
    "scheduler_time": 79.47639980457586
}
#Debug simulation 
Total elapsed time: 9.939311055000871. Arrivals time: 0.4502880808431655 Scheduler time: 9.34167528571561 Scheduler overhead time: 0.055131089175119996 Adapter cache time: 0.011786513030529022 Engine time: 0.055020750034600496 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-16/adapters_32_slots_32_rate_3.2-1.6-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-16/adapters_32_slots_32_rate_3.2-1.6-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 135, 135, 17280, 135, 34560, 17280, 135, 135, 135, 34560, 34560, 135, 135, 17280, 17280, 17280, 34560, 34560, 135, 34560, 34560, 34560, 34560, 17280, 135, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 571590 . Total input tokens: 127539524 . Total output tokens: 114313627
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 9.932791674043983,
    "estimated_duration": 3600.106742688477,
    "input_throughput": 8411.18699091314,
    "output_throughput": 7404.026020654723,
    "total_throughput": 15815.213011567863,
    "itl": 115.92962437563934,
    "ttft": 1161858.486334224,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 190041,
    "finished_requests": 121848,
    "scheduler_time": 79.4780277399324
}
#Debug simulation 
Total elapsed time: 9.9328963260632. Arrivals time: 0.43857906362973154 Scheduler time: 9.351833714405075 Scheduler overhead time: 0.053385555977001786 Adapter cache time: 0.011415236163884401 Engine time: 0.053137174574658275 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-32/adapters_32_slots_32_rate_3.2-1.6-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-32/adapters_32_slots_32_rate_3.2-1.6-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 135, 135, 17280, 135, 34560, 17280, 135, 135, 135, 34560, 34560, 135, 135, 17280, 17280, 17280, 34560, 34560, 135, 34560, 34560, 34560, 34560, 17280, 135, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 571590 . Total input tokens: 127539524 . Total output tokens: 114313627
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 9.820249998942018,
    "estimated_duration": 3600.051704929614,
    "input_throughput": 8410.995308355443,
    "output_throughput": 7403.918383589196,
    "total_throughput": 15814.913691944641,
    "itl": 115.93010776582024,
    "ttft": 1161868.6780128635,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145734,
    "arrivals": 190041,
    "finished_requests": 121845,
    "scheduler_time": 79.47661671396264
}
#Debug simulation 
Total elapsed time: 9.820396661059931. Arrivals time: 0.4651482533663511 Scheduler time: 9.209558972390369 Scheduler overhead time: 0.05470291175879538 Adapter cache time: 0.011910408269613981 Engine time: 0.054207995533943176 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-8/adapters_32_slots_32_rate_3.2-1.6-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-8/adapters_32_slots_32_rate_3.2-1.6-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 66, 66, 17280, 66, 34560, 17280, 66, 66, 66, 34560, 34560, 66, 66, 17280, 17280, 17280, 34560, 34560, 66, 34560, 34560, 34560, 34560, 17280, 66, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 570900 . Total input tokens: 127384163 . Total output tokens: 114175699
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 9.490446458104998,
    "estimated_duration": 3600.118233074338,
    "input_throughput": 8506.478403585154,
    "output_throughput": 7468.50360440504,
    "total_throughput": 15974.982007990195,
    "itl": 114.62747383609157,
    "ttft": 1146951.3345444102,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 189807,
    "finished_requests": 123193,
    "scheduler_time": 80.26082687637653
}
#Debug simulation 
Total elapsed time: 9.49057649099268. Arrivals time: 0.42427339078858495 Scheduler time: 8.927240967517719 Scheduler overhead time: 0.052405089139938354 Adapter cache time: 0.010026197182014585 Engine time: 0.05224230349995196 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-16/adapters_32_slots_32_rate_3.2-1.6-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-16/adapters_32_slots_32_rate_3.2-1.6-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 66, 66, 17280, 66, 34560, 17280, 66, 66, 66, 34560, 34560, 66, 66, 17280, 17280, 17280, 34560, 34560, 66, 34560, 34560, 34560, 34560, 17280, 66, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 570900 . Total input tokens: 127384163 . Total output tokens: 114175699
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 10.089215562911704,
    "estimated_duration": 3600.0383351664923,
    "input_throughput": 8506.565527609506,
    "output_throughput": 7468.602136081569,
    "total_throughput": 15975.167663691074,
    "itl": 114.62768347711385,
    "ttft": 1146934.072660193,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255728,
    "arrivals": 189807,
    "finished_requests": 123191,
    "scheduler_time": 80.25912652671528
}
#Debug simulation 
Total elapsed time: 10.089329971000552. Arrivals time: 0.4796979015227407 Scheduler time: 9.461615984560922 Scheduler overhead time: 0.055730033898726106 Adapter cache time: 0.010823701974004507 Engine time: 0.055698972661048174 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-32/adapters_32_slots_32_rate_3.2-1.6-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-32/adapters_32_slots_32_rate_3.2-1.6-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 66, 66, 17280, 66, 34560, 17280, 66, 66, 66, 34560, 34560, 66, 66, 17280, 17280, 17280, 34560, 34560, 66, 34560, 34560, 34560, 34560, 17280, 66, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 570900 . Total input tokens: 127384163 . Total output tokens: 114175699
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 10.553043666062877,
    "estimated_duration": 3600.0384745003194,
    "input_throughput": 8506.565198376265,
    "output_throughput": 7468.60184702107,
    "total_throughput": 15975.167045397337,
    "itl": 114.62769058592166,
    "ttft": 1146934.1784832634,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033042,
    "arrivals": 189807,
    "finished_requests": 123191,
    "scheduler_time": 80.2591245189443
}
#Debug simulation 
Total elapsed time: 10.553181089926511. Arrivals time: 0.4989048261195421 Scheduler time: 9.897958399029449 Scheduler overhead time: 0.05905575351789594 Adapter cache time: 0.011447637109085917 Engine time: 0.05876757320947945 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-16/adapters_32_slots_32_rate_3.2-1.6-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-16/adapters_32_slots_32_rate_3.2-1.6-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 66, 66, 17280, 66, 34560, 17280, 66, 66, 66, 34560, 34560, 66, 66, 17280, 17280, 17280, 34560, 34560, 66, 34560, 34560, 34560, 34560, 17280, 66, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 570900 . Total input tokens: 127384163 . Total output tokens: 114175699
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 9.749387149931863,
    "estimated_duration": 3600.122624648772,
    "input_throughput": 8506.468027040526,
    "output_throughput": 7468.4944940238365,
    "total_throughput": 15974.962521064363,
    "itl": 114.6271529329315,
    "ttft": 1146949.6501355218,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971346,
    "arrivals": 189807,
    "finished_requests": 123193,
    "scheduler_time": 80.26093005700804
}
#Debug simulation 
Total elapsed time: 9.749553315108642. Arrivals time: 0.4288387617561966 Scheduler time: 9.17774162022397 Scheduler overhead time: 0.053992011584341526 Adapter cache time: 0.01018202444538474 Engine time: 0.05387584143318236 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-32/adapters_32_slots_32_rate_3.2-1.6-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-32/adapters_32_slots_32_rate_3.2-1.6-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 66, 66, 17280, 66, 34560, 17280, 66, 66, 66, 34560, 34560, 66, 66, 17280, 17280, 17280, 34560, 34560, 66, 34560, 34560, 34560, 34560, 17280, 66, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 570900 . Total input tokens: 127384163 . Total output tokens: 114175699
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 9.960254647070542,
    "estimated_duration": 3600.0380515859474,
    "input_throughput": 8506.56619768478,
    "output_throughput": 7468.602724394868,
    "total_throughput": 15975.168922079649,
    "itl": 114.62760686559491,
    "ttft": 1146932.810487431,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089388,
    "arrivals": 189807,
    "finished_requests": 123191,
    "scheduler_time": 80.25903652826207
}
#Debug simulation 
Total elapsed time: 9.960411155130714. Arrivals time: 0.474876191932708 Scheduler time: 9.339343493338674 Scheduler overhead time: 0.05502592562697828 Adapter cache time: 0.010740160709246993 Engine time: 0.05489803943783045 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-16/adapters_32_slots_32_rate_3.2-1.6-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-16/adapters_32_slots_32_rate_3.2-1.6-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 66, 66, 17280, 66, 34560, 17280, 66, 66, 66, 34560, 34560, 66, 66, 17280, 17280, 17280, 34560, 34560, 66, 34560, 34560, 34560, 34560, 17280, 66, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 570900 . Total input tokens: 127384163 . Total output tokens: 114175699
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 10.540568835102022,
    "estimated_duration": 3600.114871535775,
    "input_throughput": 8506.486346347041,
    "output_throughput": 7468.510577977766,
    "total_throughput": 15974.996924324807,
    "itl": 114.62753712062589,
    "ttft": 1146948.640967794,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 189807,
    "finished_requests": 123193,
    "scheduler_time": 80.26085732661296
}
#Debug simulation 
Total elapsed time: 10.540696399053559. Arrivals time: 0.4932994700502604 Scheduler time: 9.891508374130353 Scheduler overhead time: 0.058850114000961185 Adapter cache time: 0.011404037708416581 Engine time: 0.058429596945643425 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-32/adapters_32_slots_32_rate_3.2-1.6-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-32/adapters_32_slots_32_rate_3.2-1.6-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 66, 66, 17280, 66, 34560, 17280, 66, 66, 66, 34560, 34560, 66, 66, 17280, 17280, 17280, 34560, 34560, 66, 34560, 34560, 34560, 34560, 17280, 66, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 570900 . Total input tokens: 127384163 . Total output tokens: 114175699
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 9.625555095029995,
    "estimated_duration": 3600.0413137715877,
    "input_throughput": 8506.558489440436,
    "output_throughput": 7468.59595670349,
    "total_throughput": 15975.154446143926,
    "itl": 114.62750165815781,
    "ttft": 1146934.512634215,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145734,
    "arrivals": 189807,
    "finished_requests": 123191,
    "scheduler_time": 80.25903068053383
}
#Debug simulation 
Total elapsed time: 9.625675864052027. Arrivals time: 0.48340860614553094 Scheduler time: 9.00097340089269 Scheduler overhead time: 0.05299183749593794 Adapter cache time: 0.010346615221351385 Engine time: 0.053301838459447026 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-8/adapters_32_slots_32_rate_3.2-1.6-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-8/adapters_32_slots_32_rate_3.2-1.6-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 33, 33, 17280, 33, 34560, 17280, 33, 33, 33, 34560, 34560, 33, 33, 17280, 17280, 17280, 34560, 34560, 33, 34560, 34560, 34560, 34560, 17280, 33, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 570570 . Total input tokens: 127313451 . Total output tokens: 114108338
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 9.235825904877856,
    "estimated_duration": 3600.0881750190742,
    "input_throughput": 8454.525145023354,
    "output_throughput": 7492.8481438811095,
    "total_throughput": 15947.373288904462,
    "itl": 115.02132416579852,
    "ttft": 1142309.2663944298,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 189688,
    "finished_requests": 123190,
    "scheduler_time": 80.69819957518193
}
#Debug simulation 
Total elapsed time: 9.235941723920405. Arrivals time: 0.39715189882554114 Scheduler time: 8.702657576883212 Scheduler overhead time: 0.05127592384815216 Adapter cache time: 0.009346137521788478 Engine time: 0.05135811981745064 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-16/adapters_32_slots_32_rate_3.2-1.6-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-16/adapters_32_slots_32_rate_3.2-1.6-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 33, 33, 17280, 33, 34560, 17280, 33, 33, 33, 34560, 34560, 33, 33, 17280, 17280, 17280, 34560, 34560, 33, 34560, 34560, 34560, 34560, 17280, 33, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 570570 . Total input tokens: 127313451 . Total output tokens: 114108338
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 9.756251690909266,
    "estimated_duration": 3600.105269514767,
    "input_throughput": 8454.571386492384,
    "output_throughput": 7492.865341583688,
    "total_throughput": 15947.436728076073,
    "itl": 115.02050605754133,
    "ttft": 1142312.629874516,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255728,
    "arrivals": 189688,
    "finished_requests": 123192,
    "scheduler_time": 80.69856028577125
}
#Debug simulation 
Total elapsed time: 9.756399333942682. Arrivals time: 0.44676601607352495 Scheduler time: 9.167381157167256 Scheduler overhead time: 0.05353415827266872 Adapter cache time: 0.010022730333730578 Engine time: 0.05383779969997704 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-32/adapters_32_slots_32_rate_3.2-1.6-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-32/adapters_32_slots_32_rate_3.2-1.6-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 33, 33, 17280, 33, 34560, 17280, 33, 33, 33, 34560, 34560, 33, 33, 17280, 17280, 17280, 34560, 34560, 33, 34560, 34560, 34560, 34560, 17280, 33, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 570570 . Total input tokens: 127313451 . Total output tokens: 114108338
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 9.721040047006682,
    "estimated_duration": 3600.1053049814604,
    "input_throughput": 8454.571303201572,
    "output_throughput": 7492.865267767193,
    "total_throughput": 15947.436570968764,
    "itl": 115.02051518260318,
    "ttft": 1142312.6300793383,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033042,
    "arrivals": 189688,
    "finished_requests": 123192,
    "scheduler_time": 80.69855771606024
}
#Debug simulation 
Total elapsed time: 9.721204157918692. Arrivals time: 0.4498607397545129 Scheduler time: 9.129572838777676 Scheduler overhead time: 0.053754524094983935 Adapter cache time: 0.009877329925075173 Engine time: 0.053285862086340785 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-16/adapters_32_slots_32_rate_3.2-1.6-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-16/adapters_32_slots_32_rate_3.2-1.6-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 33, 33, 17280, 33, 34560, 17280, 33, 33, 33, 34560, 34560, 33, 33, 17280, 17280, 17280, 34560, 34560, 33, 34560, 34560, 34560, 34560, 17280, 33, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 570570 . Total input tokens: 127313451 . Total output tokens: 114108338
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 10.550753799034283,
    "estimated_duration": 3600.0953230627865,
    "input_throughput": 8454.5947450373,
    "output_throughput": 7492.8860430981285,
    "total_throughput": 15947.48078813543,
    "itl": 115.0209052785956,
    "ttft": 1142311.1161848935,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971348,
    "arrivals": 189688,
    "finished_requests": 123192,
    "scheduler_time": 80.69838841674972
}
#Debug simulation 
Total elapsed time: 10.550929242977872. Arrivals time: 0.4971941215917468 Scheduler time: 9.899509888608009 Scheduler overhead time: 0.05819690623320639 Adapter cache time: 0.010797919472679496 Engine time: 0.058326499769464135 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-32/adapters_32_slots_32_rate_3.2-1.6-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-32/adapters_32_slots_32_rate_3.2-1.6-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 33, 33, 17280, 33, 34560, 17280, 33, 33, 33, 34560, 34560, 33, 33, 17280, 17280, 17280, 34560, 34560, 33, 34560, 34560, 34560, 34560, 17280, 33, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 570570 . Total input tokens: 127313451 . Total output tokens: 114108338
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 10.530523915076628,
    "estimated_duration": 3600.1099202137007,
    "input_throughput": 8454.6874052649,
    "output_throughput": 7492.978713938475,
    "total_throughput": 15947.666119203375,
    "itl": 115.02052948608178,
    "ttft": 1142296.8874776636,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089387,
    "arrivals": 189688,
    "finished_requests": 123193,
    "scheduler_time": 80.69863415179164
}
#Debug simulation 
Total elapsed time: 10.530631984118372. Arrivals time: 0.5019276153761894 Scheduler time: 9.874215878779069 Scheduler overhead time: 0.0585182192735374 Adapter cache time: 0.010981495724990964 Engine time: 0.0580667860340327 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-16/adapters_32_slots_32_rate_3.2-1.6-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-16/adapters_32_slots_32_rate_3.2-1.6-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 33, 33, 17280, 33, 34560, 17280, 33, 33, 33, 34560, 34560, 33, 33, 17280, 17280, 17280, 34560, 34560, 33, 34560, 34560, 34560, 34560, 17280, 33, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 570570 . Total input tokens: 127313451 . Total output tokens: 114108338
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 10.409008662914857,
    "estimated_duration": 3600.0822497927347,
    "input_throughput": 8454.539059976292,
    "output_throughput": 7492.860476049682,
    "total_throughput": 15947.399536025974,
    "itl": 115.02151548263932,
    "ttft": 1142310.8046499263,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 189688,
    "finished_requests": 123190,
    "scheduler_time": 80.69797887854507
}
#Debug simulation 
Total elapsed time: 10.409164326032624. Arrivals time: 0.4806754644960165 Scheduler time: 9.775419092504308 Scheduler overhead time: 0.05778656085021794 Adapter cache time: 0.0106893265619874 Engine time: 0.05781470681540668 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-32/adapters_32_slots_32_rate_3.2-1.6-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-32/adapters_32_slots_32_rate_3.2-1.6-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 33, 33, 17280, 33, 34560, 17280, 33, 33, 33, 34560, 34560, 33, 33, 17280, 17280, 17280, 34560, 34560, 33, 34560, 34560, 34560, 34560, 17280, 33, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 570570 . Total input tokens: 127313451 . Total output tokens: 114108338
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 10.13094332604669,
    "estimated_duration": 3600.003149768306,
    "input_throughput": 8454.65899160641,
    "output_throughput": 7492.8456664645,
    "total_throughput": 15947.50465807091,
    "itl": 115.02066753986934,
    "ttft": 1142276.1786788923,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145734,
    "arrivals": 189688,
    "finished_requests": 123188,
    "scheduler_time": 80.69640805329543
}
#Debug simulation 
Total elapsed time: 10.131091072922572. Arrivals time: 0.46668514516204596 Scheduler time: 9.51621157513 Scheduler overhead time: 0.056086127646267414 Adapter cache time: 0.010427547851577401 Engine time: 0.05576127301901579 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-8/adapters_32_slots_32_rate_3.2-0.8-0.4_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-8/adapters_32_slots_32_rate_3.2-0.8-0.4_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 4320, 4320, 8640, 4320, 34560, 8640, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 8640, 8640, 8640, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 8640, 4320, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 518400 . Total input tokens: 115631222 . Total output tokens: 103641843
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 9.349020055029541,
    "estimated_duration": 3600.1163982429393,
    "input_throughput": 7865.339580081321,
    "output_throughput": 6997.339867203947,
    "total_throughput": 14862.679447285269,
    "itl": 123.41136399495853,
    "ttft": 1143229.9461230042,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 172540,
    "finished_requests": 114750,
    "scheduler_time": 76.42554254432982
}
#Debug simulation 
Total elapsed time: 9.349142529070377. Arrivals time: 0.45156662818044424 Scheduler time: 8.761319874087349 Scheduler overhead time: 0.0515283162239939 Adapter cache time: 0.00859184772707522 Engine time: 0.051848312141373754 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-16/adapters_32_slots_32_rate_3.2-0.8-0.4_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-16/adapters_32_slots_32_rate_3.2-0.8-0.4_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 4320, 4320, 8640, 4320, 34560, 8640, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 8640, 8640, 8640, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 8640, 4320, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 518400 . Total input tokens: 115631222 . Total output tokens: 103641843
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 9.516024456126615,
    "estimated_duration": 3600.134028618606,
    "input_throughput": 7865.301062378802,
    "output_throughput": 6997.305600221233,
    "total_throughput": 14862.606662600036,
    "itl": 123.41067234171403,
    "ttft": 1143250.2661596576,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255727,
    "arrivals": 172540,
    "finished_requests": 114750,
    "scheduler_time": 76.42565161356906
}
#Debug simulation 
Total elapsed time: 9.516165080014616. Arrivals time: 0.442272927146405 Scheduler time: 8.940028870711103 Scheduler overhead time: 0.05101862386800349 Adapter cache time: 0.008466261439025402 Engine time: 0.05069823609665036 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-32/adapters_32_slots_32_rate_3.2-0.8-0.4_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-32/adapters_32_slots_32_rate_3.2-0.8-0.4_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 4320, 4320, 8640, 4320, 34560, 8640, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 8640, 8640, 8640, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 8640, 4320, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 518400 . Total input tokens: 115631222 . Total output tokens: 103641843
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 9.704512011026964,
    "estimated_duration": 3600.134497771741,
    "input_throughput": 7865.300037408582,
    "output_throughput": 6997.304688364229,
    "total_throughput": 14862.604725772811,
    "itl": 123.4106699142798,
    "ttft": 1143250.6442970857,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033041,
    "arrivals": 172540,
    "finished_requests": 114750,
    "scheduler_time": 76.42565317646437
}
#Debug simulation 
Total elapsed time: 9.704646012978628. Arrivals time: 0.43702873471193016 Scheduler time: 9.131648278795183 Scheduler overhead time: 0.05159945064224303 Adapter cache time: 0.008596504107117653 Engine time: 0.0518418422434479 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-16-16/adapters_32_slots_32_rate_3.2-0.8-0.4_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-16-16/adapters_32_slots_32_rate_3.2-0.8-0.4_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 4320, 4320, 8640, 4320, 34560, 8640, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 8640, 8640, 8640, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 8640, 4320, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 518400 . Total input tokens: 115631222 . Total output tokens: 103641843
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 9.508343769004568,
    "estimated_duration": 3600.1232815372373,
    "input_throughput": 7865.324541861002,
    "output_throughput": 6997.326488564983,
    "total_throughput": 14862.651030425985,
    "itl": 123.41079993076251,
    "ttft": 1143246.0662058527,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971346,
    "arrivals": 172540,
    "finished_requests": 114750,
    "scheduler_time": 76.42561114799135
}
#Debug simulation 
Total elapsed time: 9.50849786796607. Arrivals time: 0.4554835739545524 Scheduler time: 8.915408302098513 Scheduler overhead time: 0.052832708694040775 Adapter cache time: 0.00867169490084052 Engine time: 0.05178571492433548 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-16-32/adapters_32_slots_32_rate_3.2-0.8-0.4_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-16-32/adapters_32_slots_32_rate_3.2-0.8-0.4_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 4320, 4320, 8640, 4320, 34560, 8640, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 8640, 8640, 8640, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 8640, 4320, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 518400 . Total input tokens: 115631222 . Total output tokens: 103641843
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 9.435052278917283,
    "estimated_duration": 3600.01817888533,
    "input_throughput": 7865.471392915967,
    "output_throughput": 6997.510220295586,
    "total_throughput": 14862.981613211552,
    "itl": 123.4111830726028,
    "ttft": 1143212.097143436,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089387,
    "arrivals": 172540,
    "finished_requests": 114748,
    "scheduler_time": 76.4235231582659
}
#Debug simulation 
Total elapsed time: 9.435173836071044. Arrivals time: 0.45805624802596867 Scheduler time: 8.840161489089951 Scheduler overhead time: 0.05238325777463615 Adapter cache time: 0.008681806037202477 Engine time: 0.05165325501002371 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_16-16-16/adapters_32_slots_32_rate_3.2-0.8-0.4_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_16-16-16/adapters_32_slots_32_rate_3.2-0.8-0.4_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 4320, 4320, 8640, 4320, 34560, 8640, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 8640, 8640, 8640, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 8640, 4320, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 518400 . Total input tokens: 115631222 . Total output tokens: 103641843
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 9.41289980406873,
    "estimated_duration": 3600.1083533124333,
    "input_throughput": 7865.3571562496245,
    "output_throughput": 6997.355503709139,
    "total_throughput": 14862.712659958763,
    "itl": 123.41137641871047,
    "ttft": 1143226.8136405307,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 172540,
    "finished_requests": 114750,
    "scheduler_time": 76.42546021994335
}
#Debug simulation 
Total elapsed time: 9.413019793108106. Arrivals time: 0.4496303035411984 Scheduler time: 8.827983509982005 Scheduler overhead time: 0.05148409865796566 Adapter cache time: 0.008624453330412507 Engine time: 0.05139554152265191 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_16-16-32/adapters_32_slots_32_rate_3.2-0.8-0.4_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_16-16-32/adapters_32_slots_32_rate_3.2-0.8-0.4_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 4320, 4320, 8640, 4320, 34560, 8640, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 8640, 8640, 8640, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 8640, 4320, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 518400 . Total input tokens: 115631222 . Total output tokens: 103641843
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 9.111982238013297,
    "estimated_duration": 3600.018766378433,
    "input_throughput": 7865.470109336493,
    "output_throughput": 6997.509078360152,
    "total_throughput": 14862.979187696645,
    "itl": 123.41107951710313,
    "ttft": 1143212.6640932122,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145733,
    "arrivals": 172540,
    "finished_requests": 114748,
    "scheduler_time": 76.42347050550835
}
#Debug simulation 
Total elapsed time: 9.11211831215769. Arrivals time: 0.43566500418819487 Scheduler time: 8.544597922358662 Scheduler overhead time: 0.05011343862861395 Adapter cache time: 0.008375083794817328 Engine time: 0.05015248479321599 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-8/adapters_32_slots_32_rate_3.2-0.8-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-8/adapters_32_slots_32_rate_3.2-0.8-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 1080, 1080, 8640, 1080, 34560, 8640, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 8640, 8640, 8640, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 8640, 1080, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 486000 . Total input tokens: 108390605 . Total output tokens: 97143304
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 9.207838380942121,
    "estimated_duration": 3600.041543274754,
    "input_throughput": 7957.706225228853,
    "output_throughput": 7049.455317372468,
    "total_throughput": 15007.161542601321,
    "itl": 122.10315034853278,
    "ttft": 1067192.7611555974,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 161835,
    "finished_requests": 115879,
    "scheduler_time": 78.56351524415513
}
#Debug simulation 
Total elapsed time: 9.208064142847434. Arrivals time: 0.4189001386985183 Scheduler time: 8.652030802564695 Scheduler overhead time: 0.050942924339324236 Adapter cache time: 0.011667822487652302 Engine time: 0.05077475472353399 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-16/adapters_32_slots_32_rate_3.2-0.8-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-16/adapters_32_slots_32_rate_3.2-0.8-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 1080, 1080, 8640, 1080, 34560, 8640, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 8640, 8640, 8640, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 8640, 1080, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 486000 . Total input tokens: 108390605 . Total output tokens: 97143304
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 9.284847073955461,
    "estimated_duration": 3600.07964387422,
    "input_throughput": 7957.622006709391,
    "output_throughput": 7049.380711113698,
    "total_throughput": 15007.00271782309,
    "itl": 122.10323122673195,
    "ttft": 1067198.4312995172,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255727,
    "arrivals": 161835,
    "finished_requests": 115879,
    "scheduler_time": 78.5639124839512
}
#Debug simulation 
Total elapsed time: 9.284979013027623. Arrivals time: 0.42108399723656476 Scheduler time: 8.72640895145014 Scheduler overhead time: 0.051047408021986485 Adapter cache time: 0.011592332972213626 Engine time: 0.05114182969555259 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-32/adapters_32_slots_32_rate_3.2-0.8-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-32/adapters_32_slots_32_rate_3.2-0.8-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 1080, 1080, 8640, 1080, 34560, 8640, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 8640, 8640, 8640, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 8640, 1080, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 486000 . Total input tokens: 108390605 . Total output tokens: 97143304
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.951952063012868,
    "estimated_duration": 3600.079780954427,
    "input_throughput": 7957.621703707086,
    "output_throughput": 7049.38044269449,
    "total_throughput": 15007.002146401575,
    "itl": 122.10323414970452,
    "ttft": 1067198.5430284957,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033041,
    "arrivals": 161835,
    "finished_requests": 115879,
    "scheduler_time": 78.56390822255973
}
#Debug simulation 
Total elapsed time: 8.952078812988475. Arrivals time: 0.415875687263906 Scheduler time: 8.40265276376158 Scheduler overhead time: 0.049333276925608516 Adapter cache time: 0.011519520543515682 Engine time: 0.04951098910532892 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-16-16/adapters_32_slots_32_rate_3.2-0.8-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-16-16/adapters_32_slots_32_rate_3.2-0.8-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 1080, 1080, 8640, 1080, 34560, 8640, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 8640, 8640, 8640, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 8640, 1080, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 486000 . Total input tokens: 108390605 . Total output tokens: 97143304
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 9.837721885181963,
    "estimated_duration": 3600.0455817986267,
    "input_throughput": 7957.697298290061,
    "output_throughput": 7049.447409307711,
    "total_throughput": 15007.144707597772,
    "itl": 122.10298821343608,
    "ttft": 1067192.4725773134,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971348,
    "arrivals": 161835,
    "finished_requests": 115879,
    "scheduler_time": 78.56363777664502
}
#Debug simulation 
Total elapsed time: 9.837889922084287. Arrivals time: 0.4735396490432322 Scheduler time: 9.217451984295622 Scheduler overhead time: 0.05443261214531958 Adapter cache time: 0.012886641081422567 Engine time: 0.054314643843099475 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-16-32/adapters_32_slots_32_rate_3.2-0.8-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-16-32/adapters_32_slots_32_rate_3.2-0.8-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 1080, 1080, 8640, 1080, 34560, 8640, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 8640, 8640, 8640, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 8640, 1080, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 486000 . Total input tokens: 108390605 . Total output tokens: 97143304
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 9.955262873088941,
    "estimated_duration": 3600.0837167353216,
    "input_throughput": 7957.699668711963,
    "output_throughput": 7049.445789836846,
    "total_throughput": 15007.14545854881,
    "itl": 122.10339961807287,
    "ttft": 1067177.8364079045,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089387,
    "arrivals": 161835,
    "finished_requests": 115880,
    "scheduler_time": 78.56403767398601
}
#Debug simulation 
Total elapsed time: 9.955507311038673. Arrivals time: 0.5061119142919779 Scheduler time: 9.299706685356796 Scheduler overhead time: 0.05465416330844164 Adapter cache time: 0.013635515235364437 Engine time: 0.056173637276515365 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_16-16-16/adapters_32_slots_32_rate_3.2-0.8-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_16-16-16/adapters_32_slots_32_rate_3.2-0.8-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 1080, 1080, 8640, 1080, 34560, 8640, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 8640, 8640, 8640, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 8640, 1080, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 486000 . Total input tokens: 108390605 . Total output tokens: 97143304
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 9.665366433095187,
    "estimated_duration": 3600.0196555870875,
    "input_throughput": 7957.59349689667,
    "output_throughput": 7049.443733067996,
    "total_throughput": 15007.037229964666,
    "itl": 122.10294728770397,
    "ttft": 1067161.8563499213,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 161835,
    "finished_requests": 115878,
    "scheduler_time": 78.5627609196931
}
#Debug simulation 
Total elapsed time: 9.66561740101315. Arrivals time: 0.5291157173924148 Scheduler time: 8.991221459815279 Scheduler overhead time: 0.05319782858714461 Adapter cache time: 0.013257381273433566 Engine time: 0.05433463049121201 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_16-16-32/adapters_32_slots_32_rate_3.2-0.8-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_16-16-32/adapters_32_slots_32_rate_3.2-0.8-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 1080, 1080, 8640, 1080, 34560, 8640, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 8640, 8640, 8640, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 8640, 1080, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 486000 . Total input tokens: 108390605 . Total output tokens: 97143304
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.742438841145486,
    "estimated_duration": 3600.094111424579,
    "input_throughput": 7957.676692141712,
    "output_throughput": 7049.425435702718,
    "total_throughput": 15007.10212784443,
    "itl": 122.10357237224511,
    "ttft": 1067181.6195002436,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145733,
    "arrivals": 161835,
    "finished_requests": 115880,
    "scheduler_time": 78.564120612997
}
#Debug simulation 
Total elapsed time: 8.742587743094191. Arrivals time: 0.42460309294983745 Scheduler time: 8.189316971460357 Scheduler overhead time: 0.0471585295163095 Adapter cache time: 0.011288996320217848 Engine time: 0.048248568549752235 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-8/adapters_32_slots_32_rate_3.2-0.8-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-8/adapters_32_slots_32_rate_3.2-0.8-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 540, 540, 8640, 540, 34560, 8640, 540, 540, 540, 34560, 34560, 540, 540, 8640, 8640, 8640, 34560, 34560, 540, 34560, 34560, 34560, 34560, 8640, 540, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 480600 . Total input tokens: 107195754 . Total output tokens: 96078594
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 9.893657302949578,
    "estimated_duration": 3600.1148787063494,
    "input_throughput": 8129.430028220833,
    "output_throughput": 7160.862880371099,
    "total_throughput": 15290.292908591933,
    "itl": 119.70469888957614,
    "ttft": 1027695.3246891196,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 160041,
    "finished_requests": 117757,
    "scheduler_time": 80.51613688046024
}
#Debug simulation 
Total elapsed time: 9.893814611015841. Arrivals time: 0.5502329815644771 Scheduler time: 9.194904060103 Scheduler overhead time: 0.054451435804367065 Adapter cache time: 0.014023012947291136 Engine time: 0.055171292508021 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-16/adapters_32_slots_32_rate_3.2-0.8-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-16/adapters_32_slots_32_rate_3.2-0.8-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 540, 540, 8640, 540, 34560, 8640, 540, 540, 540, 34560, 34560, 540, 540, 8640, 8640, 8640, 34560, 34560, 540, 34560, 34560, 34560, 34560, 8640, 540, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 480600 . Total input tokens: 107195754 . Total output tokens: 96078594
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 9.63873316696845,
    "estimated_duration": 3600.0004729208526,
    "input_throughput": 8129.638932034507,
    "output_throughput": 7160.941837067023,
    "total_throughput": 15290.580769101529,
    "itl": 119.70441503600418,
    "ttft": 1027607.5958130346,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255727,
    "arrivals": 160041,
    "finished_requests": 117756,
    "scheduler_time": 80.51371712288814
}
#Debug simulation 
Total elapsed time: 9.638856961857527. Arrivals time: 0.5793327186256647 Scheduler time: 8.914105891948566 Scheduler overhead time: 0.05305843334645033 Adapter cache time: 0.014135724864900112 Engine time: 0.05386782577261329 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-32/adapters_32_slots_32_rate_3.2-0.8-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-32/adapters_32_slots_32_rate_3.2-0.8-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 540, 540, 8640, 540, 34560, 8640, 540, 540, 540, 34560, 34560, 540, 540, 8640, 8640, 8640, 34560, 34560, 540, 34560, 34560, 34560, 34560, 8640, 540, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 480600 . Total input tokens: 107195754 . Total output tokens: 96078594
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 10.160470764851198,
    "estimated_duration": 3600.002503890629,
    "input_throughput": 8129.634345634651,
    "output_throughput": 7160.937797165265,
    "total_throughput": 15290.572142799916,
    "itl": 119.70450669724873,
    "ttft": 1027608.9924861251,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033041,
    "arrivals": 160041,
    "finished_requests": 117756,
    "scheduler_time": 80.51373220749433
}
#Debug simulation 
Total elapsed time: 10.160608555888757. Arrivals time: 0.5485864134971052 Scheduler time: 9.458980271592736 Scheduler overhead time: 0.05617989506572485 Adapter cache time: 0.014481397811323404 Engine time: 0.05646296963095665 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-16-16/adapters_32_slots_32_rate_3.2-0.8-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-16-16/adapters_32_slots_32_rate_3.2-0.8-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 540, 540, 8640, 540, 34560, 8640, 540, 540, 540, 34560, 34560, 540, 540, 8640, 8640, 8640, 34560, 34560, 540, 34560, 34560, 34560, 34560, 8640, 540, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 480600 . Total input tokens: 107195754 . Total output tokens: 96078594
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 9.626944108866155,
    "estimated_duration": 3600.1295790264294,
    "input_throughput": 8129.5718272214835,
    "output_throughput": 7161.139740690077,
    "total_throughput": 15290.71156791156,
    "itl": 119.70482506818881,
    "ttft": 1027659.3647341045,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971348,
    "arrivals": 160041,
    "finished_requests": 117759,
    "scheduler_time": 80.51636011169234
}
#Debug simulation 
Total elapsed time: 9.627639079932123. Arrivals time: 0.5808301402721554 Scheduler time: 8.900067529641092 Scheduler overhead time: 0.052859424613416195 Adapter cache time: 0.014697215287014842 Engine time: 0.05408580577932298 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-16-32/adapters_32_slots_32_rate_3.2-0.8-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-16-32/adapters_32_slots_32_rate_3.2-0.8-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 540, 540, 8640, 540, 34560, 8640, 540, 540, 540, 34560, 34560, 540, 540, 8640, 8640, 8640, 34560, 34560, 540, 34560, 34560, 34560, 34560, 8640, 540, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 480600 . Total input tokens: 107195754 . Total output tokens: 96078594
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 9.163328334921971,
    "estimated_duration": 3600.038203480009,
    "input_throughput": 8129.603172463255,
    "output_throughput": 7161.015395636525,
    "total_throughput": 15290.61856809978,
    "itl": 119.70553996788844,
    "ttft": 1027584.2117957263,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089387,
    "arrivals": 160041,
    "finished_requests": 117757,
    "scheduler_time": 80.51491593717125
}
#Debug simulation 
Total elapsed time: 9.163521091919392. Arrivals time: 0.5235778009518981 Scheduler time: 8.502921128179878 Scheduler overhead time: 0.05008474504575133 Adapter cache time: 0.013202550821006298 Engine time: 0.05061560031026602 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_16-16-16/adapters_32_slots_32_rate_3.2-0.8-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_16-16-16/adapters_32_slots_32_rate_3.2-0.8-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 540, 540, 8640, 540, 34560, 8640, 540, 540, 540, 34560, 34560, 540, 540, 8640, 8640, 8640, 34560, 34560, 540, 34560, 34560, 34560, 34560, 8640, 540, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 480600 . Total input tokens: 107195754 . Total output tokens: 96078594
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 9.946703155059367,
    "estimated_duration": 3600.1061405360533,
    "input_throughput": 8129.44975995685,
    "output_throughput": 7160.880261202906,
    "total_throughput": 15290.330021159756,
    "itl": 119.70473029581488,
    "ttft": 1027677.0105174057,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 160041,
    "finished_requests": 117757,
    "scheduler_time": 80.51596651854437
}
#Debug simulation 
Total elapsed time: 9.946872773114592. Arrivals time: 0.5145756001584232 Scheduler time: 9.282213577069342 Scheduler overhead time: 0.05445928033441305 Adapter cache time: 0.014633973827585578 Engine time: 0.05561894061975181 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_16-16-32/adapters_32_slots_32_rate_3.2-0.8-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_16-16-32/adapters_32_slots_32_rate_3.2-0.8-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 540, 540, 8640, 540, 34560, 8640, 540, 540, 540, 34560, 34560, 540, 540, 8640, 8640, 8640, 34560, 34560, 540, 34560, 34560, 34560, 34560, 8640, 540, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 480600 . Total input tokens: 107195754 . Total output tokens: 96078594
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 9.320300879189745,
    "estimated_duration": 3600.0435045475997,
    "input_throughput": 8129.591201614612,
    "output_throughput": 7161.004851034332,
    "total_throughput": 15290.596052648945,
    "itl": 119.70547828356999,
    "ttft": 1027585.5324000554,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145734,
    "arrivals": 160041,
    "finished_requests": 117757,
    "scheduler_time": 80.51497589512547
}
#Debug simulation 
Total elapsed time: 9.320441368035972. Arrivals time: 0.51620859419927 Scheduler time: 8.664258302887902 Scheduler overhead time: 0.05130157759413123 Adapter cache time: 0.01370921591296792 Engine time: 0.05133860488422215 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-8/adapters_32_slots_32_rate_3.2-0.8-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-8/adapters_32_slots_32_rate_3.2-0.8-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 270, 270, 8640, 270, 34560, 8640, 270, 270, 270, 34560, 34560, 270, 270, 8640, 8640, 8640, 34560, 34560, 270, 34560, 34560, 34560, 34560, 8640, 270, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 477900 . Total input tokens: 106601693 . Total output tokens: 95531295
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 10.187918393872678,
    "estimated_duration": 3600.0880880060004,
    "input_throughput": 8230.812490038887,
    "output_throughput": 7285.471732589529,
    "total_throughput": 15516.284222628416,
    "itl": 118.23954363702175,
    "ttft": 1005144.485954104,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 159140,
    "finished_requests": 119203,
    "scheduler_time": 82.31859599439666
}
#Debug simulation 
Total elapsed time: 10.18807599786669. Arrivals time: 0.5147217442281544 Scheduler time: 9.520181050291285 Scheduler overhead time: 0.05616820533759892 Adapter cache time: 0.014268754050135612 Engine time: 0.056977262487635016 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-16/adapters_32_slots_32_rate_3.2-0.8-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-16/adapters_32_slots_32_rate_3.2-0.8-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 270, 270, 8640, 270, 34560, 8640, 270, 270, 270, 34560, 34560, 270, 270, 8640, 8640, 8640, 34560, 34560, 270, 34560, 34560, 34560, 34560, 8640, 270, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 477900 . Total input tokens: 106601693 . Total output tokens: 95531295
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 9.238795075099915,
    "estimated_duration": 3600.0198535823974,
    "input_throughput": 8230.746830608225,
    "output_throughput": 7285.3539887845245,
    "total_throughput": 15516.100819392748,
    "itl": 118.24073528409484,
    "ttft": 1005105.0088837513,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255727,
    "arrivals": 159140,
    "finished_requests": 119199,
    "scheduler_time": 82.3165703917338
}
#Debug simulation 
Total elapsed time: 9.23892986215651. Arrivals time: 0.4581710898783058 Scheduler time: 8.642626089509577 Scheduler overhead time: 0.050873682368546724 Adapter cache time: 0.012932309415191412 Engine time: 0.05108862672932446 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-32/adapters_32_slots_32_rate_3.2-0.8-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-32/adapters_32_slots_32_rate_3.2-0.8-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 270, 270, 8640, 270, 34560, 8640, 270, 270, 270, 34560, 34560, 270, 270, 8640, 8640, 8640, 34560, 34560, 270, 34560, 34560, 34560, 34560, 8640, 270, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 477900 . Total input tokens: 106601693 . Total output tokens: 95531295
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 10.28859633510001,
    "estimated_duration": 3600.020105307283,
    "input_throughput": 8230.74625508816,
    "output_throughput": 7285.3534793693425,
    "total_throughput": 15516.099734457503,
    "itl": 118.24074798580315,
    "ttft": 1005105.2124057277,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033041,
    "arrivals": 159140,
    "finished_requests": 119199,
    "scheduler_time": 82.31656603668367
}
#Debug simulation 
Total elapsed time: 10.288731714943424. Arrivals time: 0.4934819925110787 Scheduler time: 9.645463427295908 Scheduler overhead time: 0.05507022235542536 Adapter cache time: 0.013764718314632773 Engine time: 0.05548208695836365 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-16-16/adapters_32_slots_32_rate_3.2-0.8-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-16-16/adapters_32_slots_32_rate_3.2-0.8-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 270, 270, 8640, 270, 34560, 8640, 270, 270, 270, 34560, 34560, 270, 270, 8640, 8640, 8640, 34560, 34560, 270, 34560, 34560, 34560, 34560, 8640, 270, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 477900 . Total input tokens: 106601693 . Total output tokens: 95531295
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 9.867613006848842,
    "estimated_duration": 3600.0115574744364,
    "input_throughput": 8230.76579809297,
    "output_throughput": 7285.370777642633,
    "total_throughput": 15516.136575735603,
    "itl": 118.24090864438016,
    "ttft": 1005099.2187497377,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971346,
    "arrivals": 159140,
    "finished_requests": 119199,
    "scheduler_time": 82.31675030094989
}
#Debug simulation 
Total elapsed time: 9.867819033795968. Arrivals time: 0.513697104062885 Scheduler time: 9.206178648862988 Scheduler overhead time: 0.05378182348795235 Adapter cache time: 0.014482894679531455 Engine time: 0.05489209131337702 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-16-32/adapters_32_slots_32_rate_3.2-0.8-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-16-32/adapters_32_slots_32_rate_3.2-0.8-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 270, 270, 8640, 270, 34560, 8640, 270, 270, 270, 34560, 34560, 270, 270, 8640, 8640, 8640, 34560, 34560, 270, 34560, 34560, 34560, 34560, 8640, 270, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 477900 . Total input tokens: 106601693 . Total output tokens: 95531295
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 9.977364010177553,
    "estimated_duration": 3600.020107867963,
    "input_throughput": 8230.746249233662,
    "output_throughput": 7285.353474187299,
    "total_throughput": 15516.099723420963,
    "itl": 118.24063993951187,
    "ttft": 1005105.3096354548,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089388,
    "arrivals": 159140,
    "finished_requests": 119199,
    "scheduler_time": 82.31652984998252
}
#Debug simulation 
Total elapsed time: 9.977536846185103. Arrivals time: 0.49263690831139684 Scheduler time: 9.335048839217052 Scheduler overhead time: 0.054685553070157766 Adapter cache time: 0.013679975876584649 Engine time: 0.05619174335151911 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_16-16-16/adapters_32_slots_32_rate_3.2-0.8-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_16-16-16/adapters_32_slots_32_rate_3.2-0.8-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 270, 270, 8640, 270, 34560, 8640, 270, 270, 270, 34560, 34560, 270, 270, 8640, 8640, 8640, 34560, 34560, 270, 34560, 34560, 34560, 34560, 8640, 270, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 477900 . Total input tokens: 106601693 . Total output tokens: 95531295
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 9.231473427964374,
    "estimated_duration": 3600.088503626056,
    "input_throughput": 8230.811539814817,
    "output_throughput": 7285.470891502382,
    "total_throughput": 15516.282431317199,
    "itl": 118.23981319072927,
    "ttft": 1005146.187031696,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 159140,
    "finished_requests": 119203,
    "scheduler_time": 82.3185125343613
}
#Debug simulation 
Total elapsed time: 9.231594203040004. Arrivals time: 0.42647696076892316 Scheduler time: 8.667424290673807 Scheduler overhead time: 0.050768621265888214 Adapter cache time: 0.012249143328517675 Engine time: 0.05119976447895169 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_16-16-32/adapters_32_slots_32_rate_3.2-0.8-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_16-16-32/adapters_32_slots_32_rate_3.2-0.8-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 270, 270, 8640, 270, 34560, 8640, 270, 270, 270, 34560, 34560, 270, 270, 8640, 8640, 8640, 34560, 34560, 270, 34560, 34560, 34560, 34560, 8640, 270, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 477900 . Total input tokens: 106601693 . Total output tokens: 95531295
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 9.801305270055309,
    "estimated_duration": 3600.0498665272803,
    "input_throughput": 8230.756544653952,
    "output_throughput": 7285.399084013286,
    "total_throughput": 15516.155628667238,
    "itl": 118.24173779449931,
    "ttft": 1005122.5967427794,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145734,
    "arrivals": 159140,
    "finished_requests": 119201,
    "scheduler_time": 82.31720675529067
}
#Debug simulation 
Total elapsed time: 9.80150853516534. Arrivals time: 0.4625429231673479 Scheduler time: 9.191850859439 Scheduler overhead time: 0.05421063653193414 Adapter cache time: 0.013502557063475251 Engine time: 0.05435371515341103 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-8/adapters_32_slots_32_rate_3.2-0.8-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-8/adapters_32_slots_32_rate_3.2-0.8-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 135, 135, 8640, 135, 34560, 8640, 135, 135, 135, 34560, 34560, 135, 135, 8640, 8640, 8640, 34560, 34560, 135, 34560, 34560, 34560, 34560, 8640, 135, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 476550 . Total input tokens: 106318766 . Total output tokens: 95254797
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 10.102050343062729,
    "estimated_duration": 3600.0283824754815,
    "input_throughput": 8376.901456333278,
    "output_throughput": 7384.443447559695,
    "total_throughput": 15761.344903892976,
    "itl": 116.13627198620209,
    "ttft": 969726.5146567763,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 158673,
    "finished_requests": 121493,
    "scheduler_time": 84.22193127733799
}
#Debug simulation 
Total elapsed time: 10.102169155143201. Arrivals time: 0.4552158347796649 Scheduler time: 9.496857688296586 Scheduler overhead time: 0.05588580830954015 Adapter cache time: 0.012411203933879733 Engine time: 0.05600691679865122 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-16/adapters_32_slots_32_rate_3.2-0.8-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-16/adapters_32_slots_32_rate_3.2-0.8-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 135, 135, 8640, 135, 34560, 8640, 135, 135, 135, 34560, 34560, 135, 135, 8640, 8640, 8640, 34560, 34560, 135, 34560, 34560, 34560, 34560, 8640, 135, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 476550 . Total input tokens: 106318766 . Total output tokens: 95254797
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 10.350687877973542,
    "estimated_duration": 3600.0503716071535,
    "input_throughput": 8376.919733636118,
    "output_throughput": 7384.398898877667,
    "total_throughput": 15761.318632513785,
    "itl": 116.13526199027936,
    "ttft": 969730.8360119689,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255727,
    "arrivals": 158673,
    "finished_requests": 121494,
    "scheduler_time": 84.2219442779513
}
#Debug simulation 
Total elapsed time: 10.350830774055794. Arrivals time: 0.4835569963324815 Scheduler time: 9.713363345479593 Scheduler overhead time: 0.057263770373538136 Adapter cache time: 0.01295631960965693 Engine time: 0.05718272249214351 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-32/adapters_32_slots_32_rate_3.2-0.8-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-32/adapters_32_slots_32_rate_3.2-0.8-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 135, 135, 8640, 135, 34560, 8640, 135, 135, 135, 34560, 34560, 135, 135, 8640, 8640, 8640, 34560, 34560, 135, 34560, 34560, 34560, 34560, 8640, 135, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 476550 . Total input tokens: 106318766 . Total output tokens: 95254797
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 10.155570358969271,
    "estimated_duration": 3600.0505266915325,
    "input_throughput": 8376.919372771905,
    "output_throughput": 7384.3985807696545,
    "total_throughput": 15761.31795354156,
    "itl": 116.13530106743484,
    "ttft": 969730.9724039686,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033041,
    "arrivals": 158673,
    "finished_requests": 121494,
    "scheduler_time": 84.22194250432099
}
#Debug simulation 
Total elapsed time: 10.155716961948201. Arrivals time: 0.4705946920439601 Scheduler time: 9.533835074398667 Scheduler overhead time: 0.056189371505752206 Adapter cache time: 0.012635344406589866 Engine time: 0.05626891530118883 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-16/adapters_32_slots_32_rate_3.2-0.8-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-16/adapters_32_slots_32_rate_3.2-0.8-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 135, 135, 8640, 135, 34560, 8640, 135, 135, 135, 34560, 34560, 135, 135, 8640, 8640, 8640, 34560, 34560, 135, 34560, 34560, 34560, 34560, 8640, 135, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 476550 . Total input tokens: 106318766 . Total output tokens: 95254797
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 9.573969032149762,
    "estimated_duration": 3600.0382576867873,
    "input_throughput": 8376.878477779706,
    "output_throughput": 7384.4231914029,
    "total_throughput": 15761.301669182605,
    "itl": 116.13629463784132,
    "ttft": 969730.9316767036,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971346,
    "arrivals": 158673,
    "finished_requests": 121493,
    "scheduler_time": 84.22185516344982
}
#Debug simulation 
Total elapsed time: 9.574537794105709. Arrivals time: 0.4274555875454098 Scheduler time: 9.005115161882713 Scheduler overhead time: 0.052651149686425924 Adapter cache time: 0.011504048481583595 Engine time: 0.052916029235348105 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-32/adapters_32_slots_32_rate_3.2-0.8-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-32/adapters_32_slots_32_rate_3.2-0.8-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 135, 135, 8640, 135, 34560, 8640, 135, 135, 135, 34560, 34560, 135, 135, 8640, 8640, 8640, 34560, 34560, 135, 34560, 34560, 34560, 34560, 8640, 135, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 476550 . Total input tokens: 106318766 . Total output tokens: 95254797
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 10.293124296935275,
    "estimated_duration": 3600.053128733867,
    "input_throughput": 8376.913318111581,
    "output_throughput": 7384.393243482388,
    "total_throughput": 15761.306561593969,
    "itl": 116.1351666997417,
    "ttft": 969731.0076769184,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089387,
    "arrivals": 158673,
    "finished_requests": 121494,
    "scheduler_time": 84.22197794175295
}
#Debug simulation 
Total elapsed time: 10.293241804931313. Arrivals time: 0.4734962456859648 Scheduler time: 9.666547562228516 Scheduler overhead time: 0.057157315546646714 Adapter cache time: 0.012719188584014773 Engine time: 0.057150108739733696 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-16/adapters_32_slots_32_rate_3.2-0.8-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-16/adapters_32_slots_32_rate_3.2-0.8-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 135, 135, 8640, 135, 34560, 8640, 135, 135, 135, 34560, 34560, 135, 135, 8640, 8640, 8640, 34560, 34560, 135, 34560, 34560, 34560, 34560, 8640, 135, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 476550 . Total input tokens: 106318766 . Total output tokens: 95254797
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 9.80940151703544,
    "estimated_duration": 3600.1070404263673,
    "input_throughput": 8376.787873626226,
    "output_throughput": 7384.282662009845,
    "total_throughput": 15761.070535636072,
    "itl": 116.13477925604263,
    "ttft": 969759.9930034699,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 158673,
    "finished_requests": 121494,
    "scheduler_time": 84.22362347881473
}
#Debug simulation 
Total elapsed time: 9.809548215009272. Arrivals time: 0.4880037473049015 Scheduler time: 9.176523285917938 Scheduler overhead time: 0.05380045576021075 Adapter cache time: 0.012200168799608946 Engine time: 0.05412297369912267 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-32/adapters_32_slots_32_rate_3.2-0.8-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-32/adapters_32_slots_32_rate_3.2-0.8-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 135, 135, 8640, 135, 34560, 8640, 135, 135, 135, 34560, 34560, 135, 135, 8640, 8640, 8640, 34560, 34560, 135, 34560, 34560, 34560, 34560, 8640, 135, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 476550 . Total input tokens: 106318766 . Total output tokens: 95254797
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 9.550351910991594,
    "estimated_duration": 3600.062492916073,
    "input_throughput": 8376.891528783539,
    "output_throughput": 7384.374035814758,
    "total_throughput": 15761.265564598296,
    "itl": 116.13532755349219,
    "ttft": 969735.4826250528,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145733,
    "arrivals": 158673,
    "finished_requests": 121494,
    "scheduler_time": 84.22192989568333
}
#Debug simulation 
Total elapsed time: 9.55045036203228. Arrivals time: 0.48098433553241193 Scheduler time: 8.928080541081727 Scheduler overhead time: 0.05239192699082196 Adapter cache time: 0.01186339184641838 Engine time: 0.052820189855992794 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-8/adapters_32_slots_32_rate_3.2-0.8-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-8/adapters_32_slots_32_rate_3.2-0.8-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 66, 66, 8640, 66, 34560, 8640, 66, 66, 66, 34560, 34560, 66, 66, 8640, 8640, 8640, 34560, 34560, 66, 34560, 34560, 34560, 34560, 8640, 66, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 475860 . Total input tokens: 106162778 . Total output tokens: 95110281
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 10.275563996983692,
    "estimated_duration": 3600.03982437525,
    "input_throughput": 8431.186175910536,
    "output_throughput": 7445.398747679551,
    "total_throughput": 15876.584923590086,
    "itl": 115.4548731130353,
    "ttft": 959192.7791096639,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 158470,
    "finished_requests": 122342,
    "scheduler_time": 85.21157921002094
}
#Debug simulation 
Total elapsed time: 10.275712707079947. Arrivals time: 0.48643745947629213 Scheduler time: 9.6377330084797 Scheduler overhead time: 0.05658486485481262 Adapter cache time: 0.0115162821020931 Engine time: 0.057239319663494825 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-16/adapters_32_slots_32_rate_3.2-0.8-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-16/adapters_32_slots_32_rate_3.2-0.8-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 66, 66, 8640, 66, 34560, 8640, 66, 66, 66, 34560, 34560, 66, 66, 8640, 8640, 8640, 34560, 34560, 66, 34560, 34560, 34560, 34560, 8640, 66, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 475860 . Total input tokens: 106162778 . Total output tokens: 95110281
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 10.350597326876596,
    "estimated_duration": 3600.0630432741677,
    "input_throughput": 8431.131798290693,
    "output_throughput": 7445.350727975772,
    "total_throughput": 15876.482526266465,
    "itl": 115.45453996685553,
    "ttft": 959215.37758691,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255727,
    "arrivals": 158470,
    "finished_requests": 122342,
    "scheduler_time": 85.2115874633927
}
#Debug simulation 
Total elapsed time: 10.350713504943997. Arrivals time: 0.475575128570199 Scheduler time: 9.722454408649355 Scheduler overhead time: 0.0572368826251477 Adapter cache time: 0.011460490757599473 Engine time: 0.05763414059765637 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-32/adapters_32_slots_32_rate_3.2-0.8-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-32/adapters_32_slots_32_rate_3.2-0.8-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 66, 66, 8640, 66, 34560, 8640, 66, 66, 66, 34560, 34560, 66, 66, 8640, 8640, 8640, 34560, 34560, 66, 34560, 34560, 34560, 34560, 8640, 66, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 475860 . Total input tokens: 106162778 . Total output tokens: 95110281
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 10.298761661862954,
    "estimated_duration": 3600.0631810509476,
    "input_throughput": 8431.131475625747,
    "output_throughput": 7445.350443037315,
    "total_throughput": 15876.481918663063,
    "itl": 115.45454813784121,
    "ttft": 959215.4840907343,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033041,
    "arrivals": 158470,
    "finished_requests": 122342,
    "scheduler_time": 85.21158389857483
}
#Debug simulation 
Total elapsed time: 10.298918406944722. Arrivals time: 0.4485498773865402 Scheduler time: 9.698448808398098 Scheduler overhead time: 0.05685171321965754 Adapter cache time: 0.011216603219509125 Engine time: 0.05733929481357336 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-16/adapters_32_slots_32_rate_3.2-0.8-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-16/adapters_32_slots_32_rate_3.2-0.8-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 66, 66, 8640, 66, 34560, 8640, 66, 66, 66, 34560, 34560, 66, 66, 8640, 8640, 8640, 34560, 34560, 66, 34560, 34560, 34560, 34560, 8640, 66, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 475860 . Total input tokens: 106162778 . Total output tokens: 95110281
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 9.79084464488551,
    "estimated_duration": 3600.0512224791783,
    "input_throughput": 8431.159481974719,
    "output_throughput": 7445.375174840315,
    "total_throughput": 15876.534656815033,
    "itl": 115.45473240770228,
    "ttft": 959211.6776707087,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971348,
    "arrivals": 158470,
    "finished_requests": 122342,
    "scheduler_time": 85.21167888434336
}
#Debug simulation 
Total elapsed time: 9.791012388886884. Arrivals time: 0.45809346809983253 Scheduler time: 9.188956315629184 Scheduler overhead time: 0.053682064171880484 Adapter cache time: 0.0107796979136765 Engine time: 0.05453605717048049 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-32/adapters_32_slots_32_rate_3.2-0.8-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-32/adapters_32_slots_32_rate_3.2-0.8-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 66, 66, 8640, 66, 34560, 8640, 66, 66, 66, 34560, 34560, 66, 66, 8640, 8640, 8640, 34560, 34560, 66, 34560, 34560, 34560, 34560, 8640, 66, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 475860 . Total input tokens: 106162778 . Total output tokens: 95110281
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 10.238146327901632,
    "estimated_duration": 3600.0712265457123,
    "input_throughput": 8431.112633602943,
    "output_throughput": 7445.333804053184,
    "total_throughput": 15876.446437656128,
    "itl": 115.45463084845763,
    "ttft": 959218.6887453782,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089387,
    "arrivals": 158470,
    "finished_requests": 122342,
    "scheduler_time": 85.21165307000025
}
#Debug simulation 
Total elapsed time: 10.238284758059308. Arrivals time: 0.476780638564378 Scheduler time: 9.61040948680602 Scheduler overhead time: 0.05669898563064635 Adapter cache time: 0.0113504056353122 Engine time: 0.0568868275731802 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-16/adapters_32_slots_32_rate_3.2-0.8-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-16/adapters_32_slots_32_rate_3.2-0.8-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 66, 66, 8640, 66, 34560, 8640, 66, 66, 66, 34560, 34560, 66, 66, 8640, 8640, 8640, 34560, 34560, 66, 34560, 34560, 34560, 34560, 8640, 66, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 475860 . Total input tokens: 106162778 . Total output tokens: 95110281
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 10.182716972893104,
    "estimated_duration": 3600.0346129858385,
    "input_throughput": 8431.198380847178,
    "output_throughput": 7445.40952559598,
    "total_throughput": 15876.607906443158,
    "itl": 115.45496200610532,
    "ttft": 959189.4952267162,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 158470,
    "finished_requests": 122342,
    "scheduler_time": 85.21158593890954
}
#Debug simulation 
Total elapsed time: 10.182844158960506. Arrivals time: 0.4816214106976986 Scheduler time: 9.549606228712946 Scheduler overhead time: 0.05669846013188362 Adapter cache time: 0.011342693585902452 Engine time: 0.05706410598941147 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-32/adapters_32_slots_32_rate_3.2-0.8-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-32/adapters_32_slots_32_rate_3.2-0.8-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 66, 66, 8640, 66, 34560, 8640, 66, 66, 66, 34560, 34560, 66, 66, 8640, 8640, 8640, 34560, 34560, 66, 34560, 34560, 34560, 34560, 8640, 66, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 475860 . Total input tokens: 106162778 . Total output tokens: 95110281
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 9.685164497001097,
    "estimated_duration": 3600.0751953572317,
    "input_throughput": 8431.103338936826,
    "output_throughput": 7445.325596133915,
    "total_throughput": 15876.42893507074,
    "itl": 115.45446739454898,
    "ttft": 959218.3666157546,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145734,
    "arrivals": 158470,
    "finished_requests": 122342,
    "scheduler_time": 85.21173191740351
}
#Debug simulation 
Total elapsed time: 9.68529459903948. Arrivals time: 0.448126214556396 Scheduler time: 9.094528857851401 Scheduler overhead time: 0.05326143396086991 Adapter cache time: 0.010756999719887972 Engine time: 0.0538945272564888 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-8/adapters_32_slots_32_rate_3.2-0.8-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-8/adapters_32_slots_32_rate_3.2-0.8-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 33, 33, 8640, 33, 34560, 8640, 33, 33, 33, 34560, 34560, 33, 33, 8640, 8640, 8640, 34560, 34560, 33, 34560, 34560, 34560, 34560, 8640, 33, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 475530 . Total input tokens: 106083481 . Total output tokens: 95045931
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 9.943491174839437,
    "estimated_duration": 3600.0986206199605,
    "input_throughput": 8460.142959848985,
    "output_throughput": 7464.554400282587,
    "total_throughput": 15924.697360131573,
    "itl": 114.79171526603345,
    "ttft": 949809.9048723399,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 158357,
    "finished_requests": 122719,
    "scheduler_time": 85.72926152663186
}
#Debug simulation 
Total elapsed time: 9.943642432801425. Arrivals time: 0.47198889846913517 Scheduler time: 9.325886366190389 Scheduler overhead time: 0.05468225805088878 Adapter cache time: 0.010336346691474319 Engine time: 0.05529557727277279 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-16/adapters_32_slots_32_rate_3.2-0.8-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-16/adapters_32_slots_32_rate_3.2-0.8-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 33, 33, 8640, 33, 34560, 8640, 33, 33, 33, 34560, 34560, 33, 33, 8640, 8640, 8640, 34560, 34560, 33, 34560, 34560, 34560, 34560, 8640, 33, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 475530 . Total input tokens: 106083481 . Total output tokens: 95045931
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 10.348352087894455,
    "estimated_duration": 3600.0343211689064,
    "input_throughput": 8460.17239916503,
    "output_throughput": 7464.602723919193,
    "total_throughput": 15924.775123084222,
    "itl": 114.79266450427798,
    "ttft": 949766.4786246029,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255727,
    "arrivals": 158357,
    "finished_requests": 122717,
    "scheduler_time": 85.72870307449334
}
#Debug simulation 
Total elapsed time: 10.34847002895549. Arrivals time: 0.4739697673358023 Scheduler time: 9.723104758188128 Scheduler overhead time: 0.057131564477458596 Adapter cache time: 0.010599924717098475 Engine time: 0.05711444071494043 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-32/adapters_32_slots_32_rate_3.2-0.8-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-32/adapters_32_slots_32_rate_3.2-0.8-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 33, 33, 8640, 33, 34560, 8640, 33, 33, 33, 34560, 34560, 33, 33, 8640, 8640, 8640, 34560, 34560, 33, 34560, 34560, 34560, 34560, 8640, 33, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 475530 . Total input tokens: 106083481 . Total output tokens: 95045931
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 9.845166496001184,
    "estimated_duration": 3600.03445877894,
    "input_throughput": 8460.172075777957,
    "output_throughput": 7464.602438587415,
    "total_throughput": 15924.774514365372,
    "itl": 114.79267378294185,
    "ttft": 949766.5810029774,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033041,
    "arrivals": 158357,
    "finished_requests": 122717,
    "scheduler_time": 85.72869852627746
}
#Debug simulation 
Total elapsed time: 9.8453377711121. Arrivals time: 0.4823596572969109 Scheduler time: 9.22299842000939 Scheduler overhead time: 0.051638209726661444 Adapter cache time: 0.011656652437523007 Engine time: 0.0524266492575407 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-16/adapters_32_slots_32_rate_3.2-0.8-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-16/adapters_32_slots_32_rate_3.2-0.8-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 33, 33, 8640, 33, 34560, 8640, 33, 33, 33, 34560, 34560, 33, 33, 8640, 8640, 8640, 34560, 34560, 33, 34560, 34560, 34560, 34560, 8640, 33, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 475530 . Total input tokens: 106083481 . Total output tokens: 95045931
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 8.947504689916968,
    "estimated_duration": 3600.115497056093,
    "input_throughput": 8460.103300826253,
    "output_throughput": 7464.519408328664,
    "total_throughput": 15924.622709154917,
    "itl": 114.79189237982317,
    "ttft": 949810.4937320035,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971348,
    "arrivals": 158357,
    "finished_requests": 122719,
    "scheduler_time": 85.72959411120918
}
#Debug simulation 
Total elapsed time: 8.948078088928014. Arrivals time: 0.43251714552752674 Scheduler time: 8.38439059490338 Scheduler overhead time: 0.04943860718049109 Adapter cache time: 0.009248654125258327 Engine time: 0.0495302970521152 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-32/adapters_32_slots_32_rate_3.2-0.8-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-32/adapters_32_slots_32_rate_3.2-0.8-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 33, 33, 8640, 33, 34560, 8640, 33, 33, 33, 34560, 34560, 33, 33, 8640, 8640, 8640, 34560, 34560, 33, 34560, 34560, 34560, 34560, 8640, 33, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 475530 . Total input tokens: 106083481 . Total output tokens: 95045931
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 8.956978363916278,
    "estimated_duration": 3600.045122701867,
    "input_throughput": 8460.147015363465,
    "output_throughput": 7464.580327213148,
    "total_throughput": 15924.727342576613,
    "itl": 114.79280894277925,
    "ttft": 949784.899920026,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089387,
    "arrivals": 158357,
    "finished_requests": 122717,
    "scheduler_time": 85.72895485351125
}
#Debug simulation 
Total elapsed time: 8.957157000899315. Arrivals time: 0.41490557696670294 Scheduler time: 8.41143806069158 Scheduler overhead time: 0.04927860200405121 Adapter cache time: 0.009275869699195027 Engine time: 0.04958813823759556 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-16/adapters_32_slots_32_rate_3.2-0.8-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-16/adapters_32_slots_32_rate_3.2-0.8-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 33, 33, 8640, 33, 34560, 8640, 33, 33, 33, 34560, 34560, 33, 33, 8640, 8640, 8640, 34560, 34560, 33, 34560, 34560, 34560, 34560, 8640, 33, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 475530 . Total input tokens: 106083481 . Total output tokens: 95045931
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 8.945858459919691,
    "estimated_duration": 3600.0942680759554,
    "input_throughput": 8460.153188232405,
    "output_throughput": 7464.563424991133,
    "total_throughput": 15924.716613223538,
    "itl": 114.79178372596718,
    "ttft": 949790.6284545659,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 158357,
    "finished_requests": 122719,
    "scheduler_time": 85.7292405065466
}
#Debug simulation 
Total elapsed time: 8.945986097911373. Arrivals time: 0.4202331327833235 Scheduler time: 8.394687640247867 Scheduler overhead time: 0.049438119400292635 Adapter cache time: 0.009435239247977734 Engine time: 0.049433030653744936 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-32/adapters_32_slots_32_rate_3.2-0.8-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-32/adapters_32_slots_32_rate_3.2-0.8-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 33, 33, 8640, 33, 34560, 8640, 33, 33, 33, 34560, 34560, 33, 33, 8640, 8640, 8640, 34560, 34560, 33, 34560, 34560, 34560, 34560, 8640, 33, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 475530 . Total input tokens: 106083481 . Total output tokens: 95045931
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.944307022029534,
    "estimated_duration": 3600.048443791045,
    "input_throughput": 8460.139210773295,
    "output_throughput": 7464.573441045551,
    "total_throughput": 15924.712651818845,
    "itl": 114.7927881273626,
    "ttft": 949786.5408973708,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145734,
    "arrivals": 158357,
    "finished_requests": 122717,
    "scheduler_time": 85.72889078043688
}
#Debug simulation 
Total elapsed time: 8.94445078400895. Arrivals time: 0.4136137079913169 Scheduler time: 8.399986713891849 Scheduler overhead time: 0.04947822820395231 Adapter cache time: 0.009360047522932291 Engine time: 0.04936587065458298 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-8/adapters_32_slots_32_rate_3.2-0.4-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-8/adapters_32_slots_32_rate_3.2-0.4-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 1080, 1080, 4320, 1080, 34560, 4320, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 4320, 4320, 4320, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 4320, 1080, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 438480 . Total input tokens: 97768473 . Total output tokens: 87638546
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 8.359348342986777,
    "estimated_duration": 3600.1070018773976,
    "input_throughput": 7931.839521744432,
    "output_throughput": 7029.758278518485,
    "total_throughput": 14961.597800262918,
    "itl": 122.37969895243043,
    "ttft": 965932.2731093,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 145872,
    "finished_requests": 115178,
    "scheduler_time": 82.17090314091293
}
#Debug simulation 
Total elapsed time: 8.359475075965747. Arrivals time: 0.37915892573073506 Scheduler time: 7.856290948577225 Scheduler overhead time: 0.0462364349514246 Adapter cache time: 0.010169275104999542 Engine time: 0.046356792794540524 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-16/adapters_32_slots_32_rate_3.2-0.4-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-16/adapters_32_slots_32_rate_3.2-0.4-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 1080, 1080, 4320, 1080, 34560, 4320, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 4320, 4320, 4320, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 4320, 1080, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 438480 . Total input tokens: 97768473 . Total output tokens: 87638546
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.392551595112309,
    "estimated_duration": 3600.1154169426995,
    "input_throughput": 7931.820981520076,
    "output_throughput": 7029.741846857797,
    "total_throughput": 14961.562828377873,
    "itl": 122.37902095693397,
    "ttft": 965947.5326216705,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255726,
    "arrivals": 145872,
    "finished_requests": 115178,
    "scheduler_time": 82.17122109444689
}
#Debug simulation 
Total elapsed time: 8.392654084134847. Arrivals time: 0.3812990786973387 Scheduler time: 7.887143344385549 Scheduler overhead time: 0.04616803606040776 Adapter cache time: 0.010159783298149705 Engine time: 0.04670509044080973 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-32/adapters_32_slots_32_rate_3.2-0.4-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-32/adapters_32_slots_32_rate_3.2-0.4-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 1080, 1080, 4320, 1080, 34560, 4320, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 4320, 4320, 4320, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 4320, 1080, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 438480 . Total input tokens: 97768473 . Total output tokens: 87638546
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.456658167997375,
    "estimated_duration": 3600.1190471050877,
    "input_throughput": 7931.812983507282,
    "output_throughput": 7029.734758452076,
    "total_throughput": 14961.547741959357,
    "itl": 122.3790468667278,
    "ttft": 965948.7567514909,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.1048120480403304,
    "arrivals": 145872,
    "finished_requests": 115178,
    "scheduler_time": 82.17128743279092
}
#Debug simulation 
Total elapsed time: 8.456801627995446. Arrivals time: 0.4007870831992477 Scheduler time: 7.930842588655651 Scheduler overhead time: 0.04632920888252556 Adapter cache time: 0.01043361215852201 Engine time: 0.04671191377565265 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-16-16/adapters_32_slots_32_rate_3.2-0.4-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-16-16/adapters_32_slots_32_rate_3.2-0.4-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 1080, 1080, 4320, 1080, 34560, 4320, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 4320, 4320, 4320, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 4320, 1080, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 438480 . Total input tokens: 97768473 . Total output tokens: 87638546
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 8.401514034951106,
    "estimated_duration": 3600.116255590837,
    "input_throughput": 7931.8191338000515,
    "output_throughput": 7029.740209277372,
    "total_throughput": 14961.559343077424,
    "itl": 122.37952823764388,
    "ttft": 965930.9429336645,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971346,
    "arrivals": 145872,
    "finished_requests": 115178,
    "scheduler_time": 82.17113544519582
}
#Debug simulation 
Total elapsed time: 8.401669990969822. Arrivals time: 0.3804864911362529 Scheduler time: 7.897382833994925 Scheduler overhead time: 0.046160351717844605 Adapter cache time: 0.010003319475799799 Engine time: 0.046399367274716496 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-16-32/adapters_32_slots_32_rate_3.2-0.4-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-16-32/adapters_32_slots_32_rate_3.2-0.4-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 1080, 1080, 4320, 1080, 34560, 4320, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 4320, 4320, 4320, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 4320, 1080, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 438480 . Total input tokens: 97768473 . Total output tokens: 87638546
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 8.444587987149134,
    "estimated_duration": 3600.120467914279,
    "input_throughput": 7931.897350241651,
    "output_throughput": 7029.8230921873155,
    "total_throughput": 14961.720442428967,
    "itl": 122.37915171801177,
    "ttft": 965908.7327879276,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089384,
    "arrivals": 145872,
    "finished_requests": 115180,
    "scheduler_time": 82.171284061127
}
#Debug simulation 
Total elapsed time: 8.444736330071464. Arrivals time: 0.39587397896684706 Scheduler time: 7.924326705047861 Scheduler overhead time: 0.046288545709103346 Adapter cache time: 0.010562804760411382 Engine time: 0.04635191592387855 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_16-16-16/adapters_32_slots_32_rate_3.2-0.4-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_16-16-16/adapters_32_slots_32_rate_3.2-0.4-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 1080, 1080, 4320, 1080, 34560, 4320, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 4320, 4320, 4320, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 4320, 1080, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 438480 . Total input tokens: 97768473 . Total output tokens: 87638546
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 8.406470388174057,
    "estimated_duration": 3600.1103474917804,
    "input_throughput": 7931.832150615821,
    "output_throughput": 7029.75174570195,
    "total_throughput": 14961.583896317772,
    "itl": 122.38014534578875,
    "ttft": 965935.2603610009,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 145872,
    "finished_requests": 115178,
    "scheduler_time": 82.17085173493675
}
#Debug simulation 
Total elapsed time: 8.406595526030287. Arrivals time: 0.3839754923246801 Scheduler time: 7.897915011271834 Scheduler overhead time: 0.04634177847765386 Adapter cache time: 0.010461593512445688 Engine time: 0.04672994348220527 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_16-16-32/adapters_32_slots_32_rate_3.2-0.4-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_16-16-32/adapters_32_slots_32_rate_3.2-0.4-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 1080, 1080, 4320, 1080, 34560, 4320, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 4320, 4320, 4320, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 4320, 1080, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 438480 . Total input tokens: 97768473 . Total output tokens: 87638546
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.44554050709121,
    "estimated_duration": 3600.007425183613,
    "input_throughput": 7931.735584835254,
    "output_throughput": 7029.364668243516,
    "total_throughput": 14961.100253078768,
    "itl": 122.3786313090729,
    "ttft": 965974.2029745932,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.1075786313414573,
    "arrivals": 145872,
    "finished_requests": 115173,
    "scheduler_time": 82.16911510788634
}
#Debug simulation 
Total elapsed time: 8.445680001983419. Arrivals time: 0.3974814072716981 Scheduler time: 7.922647902276367 Scheduler overhead time: 0.04635136481374502 Adapter cache time: 0.010367325274273753 Engine time: 0.0473790792748332 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-8/adapters_32_slots_32_rate_3.2-0.4-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-8/adapters_32_slots_32_rate_3.2-0.4-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 540, 540, 4320, 540, 34560, 4320, 540, 540, 540, 34560, 34560, 540, 540, 4320, 4320, 4320, 34560, 34560, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 433080 . Total input tokens: 96509300 . Total output tokens: 86563691
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 9.723259245976806,
    "estimated_duration": 3600.1228537826582,
    "input_throughput": 8042.846362750277,
    "output_throughput": 7124.1899350883605,
    "total_throughput": 15167.036297838638,
    "itl": 120.53460171657171,
    "ttft": 929703.6026195543,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 144123,
    "finished_requests": 116897,
    "scheduler_time": 84.68863190494302
}
#Debug simulation 
Total elapsed time: 9.723423009971157. Arrivals time: 0.4671313245780766 Scheduler time: 9.10981394071132 Scheduler overhead time: 0.05387494387105107 Adapter cache time: 0.013584662694483995 Engine time: 0.054243248887360096 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-16/adapters_32_slots_32_rate_3.2-0.4-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-16/adapters_32_slots_32_rate_3.2-0.4-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 540, 540, 4320, 540, 34560, 4320, 540, 540, 540, 34560, 34560, 540, 540, 4320, 4320, 4320, 34560, 34560, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 433080 . Total input tokens: 96509300 . Total output tokens: 86563691
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.515131518943235,
    "estimated_duration": 3600.0230757460304,
    "input_throughput": 8042.792335157416,
    "output_throughput": 7124.1404458734405,
    "total_throughput": 15166.932781030857,
    "itl": 120.53397102158144,
    "ttft": 929752.523919024,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255727,
    "arrivals": 144123,
    "finished_requests": 116893,
    "scheduler_time": 84.68617077709517
}
#Debug simulation 
Total elapsed time: 8.5152677888982. Arrivals time: 0.373970212880522 Scheduler time: 8.014183678431436 Scheduler overhead time: 0.04698002920486033 Adapter cache time: 0.0112632701639086 Engine time: 0.04732177569530904 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-32/adapters_32_slots_32_rate_3.2-0.4-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-32/adapters_32_slots_32_rate_3.2-0.4-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 540, 540, 4320, 540, 34560, 4320, 540, 540, 540, 34560, 34560, 540, 540, 4320, 4320, 4320, 34560, 34560, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 433080 . Total input tokens: 96509300 . Total output tokens: 86563691
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.55934676202014,
    "estimated_duration": 3600.023249580085,
    "input_throughput": 8042.791946795702,
    "output_throughput": 7124.140101870601,
    "total_throughput": 15166.932048666302,
    "itl": 120.53394235966168,
    "ttft": 929754.6634773985,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033041,
    "arrivals": 144123,
    "finished_requests": 116893,
    "scheduler_time": 84.68610236066736
}
#Debug simulation 
Total elapsed time: 8.559459523996338. Arrivals time: 0.400761034572497 Scheduler time: 8.030499437591061 Scheduler overhead time: 0.046871648635715246 Adapter cache time: 0.012524927034974098 Engine time: 0.04726518061943352 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-16-16/adapters_32_slots_32_rate_3.2-0.4-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-16-16/adapters_32_slots_32_rate_3.2-0.4-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 540, 540, 4320, 540, 34560, 4320, 540, 540, 540, 34560, 34560, 540, 540, 4320, 4320, 4320, 34560, 34560, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 433080 . Total input tokens: 96509300 . Total output tokens: 86563691
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 8.54339897306636,
    "estimated_duration": 3600.128473834183,
    "input_throughput": 8042.963802667244,
    "output_throughput": 7124.31519775295,
    "total_throughput": 15167.279000420192,
    "itl": 120.53436478595697,
    "ttft": 929699.7928362493,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971348,
    "arrivals": 144123,
    "finished_requests": 116898,
    "scheduler_time": 84.68885423169321
}
#Debug simulation 
Total elapsed time: 8.543535385048017. Arrivals time: 0.4048102099914104 Scheduler time: 8.010791407665238 Scheduler overhead time: 0.04696653853170574 Adapter cache time: 0.012108228402212262 Engine time: 0.047184790251776576 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-16-32/adapters_32_slots_32_rate_3.2-0.4-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-16-32/adapters_32_slots_32_rate_3.2-0.4-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 540, 540, 4320, 540, 34560, 4320, 540, 540, 540, 34560, 34560, 540, 540, 4320, 4320, 4320, 34560, 34560, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 433080 . Total input tokens: 96509300 . Total output tokens: 86563691
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 8.520194650162011,
    "estimated_duration": 3600.031861369379,
    "input_throughput": 8042.772985066415,
    "output_throughput": 7124.22083682455,
    "total_throughput": 15166.993821890965,
    "itl": 120.53403939947235,
    "ttft": 929720.8563113054,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089387,
    "arrivals": 144123,
    "finished_requests": 116894,
    "scheduler_time": 84.68749180215725
}
#Debug simulation 
Total elapsed time: 8.520299804164097. Arrivals time: 0.39552716445177794 Scheduler time: 7.997634175233543 Scheduler overhead time: 0.04708000086247921 Adapter cache time: 0.011434400686994195 Engine time: 0.04710568767040968 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_16-16-16/adapters_32_slots_32_rate_3.2-0.4-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_16-16-16/adapters_32_slots_32_rate_3.2-0.4-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 540, 540, 4320, 540, 34560, 4320, 540, 540, 540, 34560, 34560, 540, 540, 4320, 4320, 4320, 34560, 34560, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 433080 . Total input tokens: 96509300 . Total output tokens: 86563691
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 8.630650276783854,
    "estimated_duration": 3600.125115588944,
    "input_throughput": 8042.841309770207,
    "output_throughput": 7124.185459261255,
    "total_throughput": 15167.026769031461,
    "itl": 120.534809070959,
    "ttft": 929704.9687715573,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 144123,
    "finished_requests": 116897,
    "scheduler_time": 84.68846187079032
}
#Debug simulation 
Total elapsed time: 8.630833053961396. Arrivals time: 0.4262780237477273 Scheduler time: 8.076000919565558 Scheduler overhead time: 0.04708088026382029 Adapter cache time: 0.012087763287127018 Engine time: 0.04757989989593625 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_16-16-32/adapters_32_slots_32_rate_3.2-0.4-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_16-16-32/adapters_32_slots_32_rate_3.2-0.4-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 540, 540, 4320, 540, 34560, 4320, 540, 540, 540, 34560, 34560, 540, 540, 4320, 4320, 4320, 34560, 34560, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 433080 . Total input tokens: 96509300 . Total output tokens: 86563691
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.590509257046506,
    "estimated_duration": 3600.032762557319,
    "input_throughput": 8042.770971737509,
    "output_throughput": 7124.219053434696,
    "total_throughput": 15166.990025172207,
    "itl": 120.53395263889838,
    "ttft": 929722.456233854,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145733,
    "arrivals": 144123,
    "finished_requests": 116894,
    "scheduler_time": 84.68737677971376
}
#Debug simulation 
Total elapsed time: 8.590646886033937. Arrivals time: 0.4093340774998069 Scheduler time: 8.05267948238179 Scheduler overhead time: 0.047190635930746794 Adapter cache time: 0.01216921559534967 Engine time: 0.047543590888381004 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-8/adapters_32_slots_32_rate_3.2-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-8/adapters_32_slots_32_rate_3.2-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 270, 270, 4320, 270, 34560, 4320, 270, 270, 270, 34560, 34560, 270, 270, 4320, 4320, 4320, 34560, 34560, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 430380 . Total input tokens: 95899884 . Total output tokens: 86032029
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 8.745578355155885,
    "estimated_duration": 3600.016331921861,
    "input_throughput": 8184.5542584720515,
    "output_throughput": 7245.32018611024,
    "total_throughput": 15429.87444458229,
    "itl": 118.27880871047219,
    "ttft": 843421.6685961818,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 143211,
    "finished_requests": 118962,
    "scheduler_time": 88.15642352185272
}
#Debug simulation 
Total elapsed time: 8.7457180400379. Arrivals time: 0.4113311886321753 Scheduler time: 8.203783358447254 Scheduler overhead time: 0.04793115076608956 Adapter cache time: 0.011990601196885109 Engine time: 0.04838810977526009 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-16/adapters_32_slots_32_rate_3.2-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-16/adapters_32_slots_32_rate_3.2-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 270, 270, 4320, 270, 34560, 4320, 270, 270, 270, 34560, 34560, 270, 270, 4320, 4320, 4320, 34560, 34560, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 430380 . Total input tokens: 95899884 . Total output tokens: 86032029
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.703128126915544,
    "estimated_duration": 3600.049375218314,
    "input_throughput": 8184.479135987744,
    "output_throughput": 7245.253684449331,
    "total_throughput": 15429.732820437075,
    "itl": 118.27892377975003,
    "ttft": 843450.4859577557,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255728,
    "arrivals": 143211,
    "finished_requests": 118962,
    "scheduler_time": 88.156148743921
}
#Debug simulation 
Total elapsed time: 8.703237585024908. Arrivals time: 0.39405768108554184 Scheduler time: 8.177944546099752 Scheduler overhead time: 0.04815799882635474 Adapter cache time: 0.011604029219597578 Engine time: 0.04943199292756617 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-32/adapters_32_slots_32_rate_3.2-0.4-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-32/adapters_32_slots_32_rate_3.2-0.4-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 270, 270, 4320, 270, 34560, 4320, 270, 270, 270, 34560, 34560, 270, 270, 4320, 4320, 4320, 34560, 34560, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 430380 . Total input tokens: 95899884 . Total output tokens: 86032029
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.667315300088376,
    "estimated_duration": 3600.0497416199905,
    "input_throughput": 8184.478302997342,
    "output_throughput": 7245.252947050326,
    "total_throughput": 15429.731250047667,
    "itl": 118.2789382990655,
    "ttft": 843450.7889765227,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033042,
    "arrivals": 143211,
    "finished_requests": 118962,
    "scheduler_time": 88.1561451439767
}
#Debug simulation 
Total elapsed time: 8.667433002963662. Arrivals time: 0.39181449776515365 Scheduler time: 8.14587345882319 Scheduler overhead time: 0.047910099383443594 Adapter cache time: 0.011568676913157105 Engine time: 0.048092776676639915 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-16-16/adapters_32_slots_32_rate_3.2-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-16-16/adapters_32_slots_32_rate_3.2-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 270, 270, 4320, 270, 34560, 4320, 270, 270, 270, 34560, 34560, 270, 270, 4320, 4320, 4320, 34560, 34560, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 430380 . Total input tokens: 95899884 . Total output tokens: 86032029
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 8.643884505145252,
    "estimated_duration": 3600.0230513569327,
    "input_throughput": 8184.53898201961,
    "output_throughput": 7245.3066627361195,
    "total_throughput": 15429.84564475573,
    "itl": 118.27867474986623,
    "ttft": 843424.9437540121,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971346,
    "arrivals": 143211,
    "finished_requests": 118962,
    "scheduler_time": 88.15634157782898
}
#Debug simulation 
Total elapsed time: 8.64405966293998. Arrivals time: 0.37274806341156363 Scheduler time: 8.142258417094126 Scheduler overhead time: 0.04781864723190665 Adapter cache time: 0.011248360620811582 Engine time: 0.048062304966151714 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-16-32/adapters_32_slots_32_rate_3.2-0.4-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-16-32/adapters_32_slots_32_rate_3.2-0.4-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 270, 270, 4320, 270, 34560, 4320, 270, 270, 270, 34560, 34560, 270, 270, 4320, 4320, 4320, 34560, 34560, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 430380 . Total input tokens: 95899884 . Total output tokens: 86032029
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 8.712832577060908,
    "estimated_duration": 3600.056744845615,
    "input_throughput": 8184.462381651587,
    "output_throughput": 7245.238852788849,
    "total_throughput": 15429.701234440436,
    "itl": 118.27904215865433,
    "ttft": 843450.146515915,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089388,
    "arrivals": 143211,
    "finished_requests": 118962,
    "scheduler_time": 88.15639227529569
}
#Debug simulation 
Total elapsed time: 8.712937207194045. Arrivals time: 0.3959048571996391 Scheduler time: 8.1868319879286 Scheduler overhead time: 0.047988056903705 Adapter cache time: 0.011834647273644805 Engine time: 0.04836619948036969 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_16-16-16/adapters_32_slots_32_rate_3.2-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_16-16-16/adapters_32_slots_32_rate_3.2-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 270, 270, 4320, 270, 34560, 4320, 270, 270, 270, 34560, 34560, 270, 270, 4320, 4320, 4320, 34560, 34560, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 430380 . Total input tokens: 95899884 . Total output tokens: 86032029
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 8.657846393063664,
    "estimated_duration": 3600.1211726066063,
    "input_throughput": 8184.316745835171,
    "output_throughput": 7245.401682164517,
    "total_throughput": 15429.718427999689,
    "itl": 118.27880660326434,
    "ttft": 843428.6511540405,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 143211,
    "finished_requests": 118965,
    "scheduler_time": 88.15942737683125
}
#Debug simulation 
Total elapsed time: 8.65797799010761. Arrivals time: 0.3875026726163924 Scheduler time: 8.14071580953896 Scheduler overhead time: 0.04784378269687295 Adapter cache time: 0.011583091225475073 Engine time: 0.048248569248244166 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_16-16-32/adapters_32_slots_32_rate_3.2-0.4-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_16-16-32/adapters_32_slots_32_rate_3.2-0.4-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 270, 270, 4320, 270, 34560, 4320, 270, 270, 270, 34560, 34560, 270, 270, 4320, 4320, 4320, 34560, 34560, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 430380 . Total input tokens: 95899884 . Total output tokens: 86032029
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.718899165047333,
    "estimated_duration": 3600.058290849034,
    "input_throughput": 8184.458866928822,
    "output_throughput": 7245.235741404773,
    "total_throughput": 15429.694608333595,
    "itl": 118.27897650780592,
    "ttft": 843451.4443253475,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145734,
    "arrivals": 143211,
    "finished_requests": 118962,
    "scheduler_time": 88.15631775362871
}
#Debug simulation 
Total elapsed time: 8.71901599294506. Arrivals time: 0.40024966769851744 Scheduler time: 8.188568267272785 Scheduler overhead time: 0.04808937106281519 Adapter cache time: 0.011713649146258831 Engine time: 0.04836029466241598 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-8/adapters_32_slots_32_rate_3.2-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-8/adapters_32_slots_32_rate_3.2-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 135, 135, 4320, 135, 34560, 4320, 135, 135, 135, 34560, 34560, 135, 135, 4320, 4320, 4320, 34560, 34560, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 429030 . Total input tokens: 95601350 . Total output tokens: 85757126
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 8.754660590086132,
    "estimated_duration": 3600.0389290604744,
    "input_throughput": 8273.666642758588,
    "output_throughput": 7341.500889518861,
    "total_throughput": 15615.16753227745,
    "itl": 117.21030142829893,
    "ttft": 779343.3993703036,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 142732,
    "finished_requests": 120651,
    "scheduler_time": 90.25423119974079
}
#Debug simulation 
Total elapsed time: 8.754783838056028. Arrivals time: 0.391355121973902 Scheduler time: 8.232890127925202 Scheduler overhead time: 0.04855123278684914 Adapter cache time: 0.011052011046558619 Engine time: 0.04875466716475785 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-16/adapters_32_slots_32_rate_3.2-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-16/adapters_32_slots_32_rate_3.2-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 135, 135, 4320, 135, 34560, 4320, 135, 135, 135, 34560, 34560, 135, 135, 4320, 4320, 4320, 34560, 34560, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 429030 . Total input tokens: 95601350 . Total output tokens: 85757126
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.766649015014991,
    "estimated_duration": 3600.0991251516466,
    "input_throughput": 8273.579966703095,
    "output_throughput": 7341.381190132287,
    "total_throughput": 15614.961156835381,
    "itl": 117.21116967964153,
    "ttft": 779332.7378909147,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255727,
    "arrivals": 142732,
    "finished_requests": 120652,
    "scheduler_time": 90.25638105911266
}
#Debug simulation 
Total elapsed time: 8.766750262118876. Arrivals time: 0.3714054338634014 Scheduler time: 8.26493765693158 Scheduler overhead time: 0.04832359356805682 Adapter cache time: 0.010750215500593185 Engine time: 0.048984942492097616 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-32/adapters_32_slots_32_rate_3.2-0.4-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-32/adapters_32_slots_32_rate_3.2-0.4-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 135, 135, 4320, 135, 34560, 4320, 135, 135, 135, 34560, 34560, 135, 135, 4320, 4320, 4320, 34560, 34560, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 429030 . Total input tokens: 95601350 . Total output tokens: 85757126
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.787120765075088,
    "estimated_duration": 3600.0992783844863,
    "input_throughput": 8273.579614550541,
    "output_throughput": 7341.38087765738,
    "total_throughput": 15614.960492207922,
    "itl": 117.21117169540562,
    "ttft": 779332.8677509382,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033041,
    "arrivals": 142732,
    "finished_requests": 120652,
    "scheduler_time": 90.25637343777795
}
#Debug simulation 
Total elapsed time: 8.787247986067086. Arrivals time: 0.3928796690888703 Scheduler time: 8.263096944661811 Scheduler overhead time: 0.048706911271438 Adapter cache time: 0.011201043613255024 Engine time: 0.04899894562549889 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-16/adapters_32_slots_32_rate_3.2-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-16/adapters_32_slots_32_rate_3.2-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 135, 135, 4320, 135, 34560, 4320, 135, 135, 135, 34560, 34560, 135, 135, 4320, 4320, 4320, 34560, 34560, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 429030 . Total input tokens: 95601350 . Total output tokens: 85757126
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 8.738441801862791,
    "estimated_duration": 3600.0454365034966,
    "input_throughput": 8273.651687276717,
    "output_throughput": 7341.487619020036,
    "total_throughput": 15615.139306296753,
    "itl": 117.21036984756246,
    "ttft": 779346.7647966101,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971346,
    "arrivals": 142732,
    "finished_requests": 120651,
    "scheduler_time": 90.25414720697144
}
#Debug simulation 
Total elapsed time: 8.738590569933876. Arrivals time: 0.3771219190675765 Scheduler time: 8.231532912934199 Scheduler overhead time: 0.0483432412147522 Adapter cache time: 0.010912710102275014 Engine time: 0.048462262377142906 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-32/adapters_32_slots_32_rate_3.2-0.4-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-32/adapters_32_slots_32_rate_3.2-0.4-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 135, 135, 4320, 135, 34560, 4320, 135, 135, 135, 34560, 34560, 135, 135, 4320, 4320, 4320, 34560, 34560, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 429030 . Total input tokens: 95601350 . Total output tokens: 85757126
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 8.669459925033152,
    "estimated_duration": 3600.100045673015,
    "input_throughput": 8273.577851204343,
    "output_throughput": 7341.3793129904925,
    "total_throughput": 15614.957164194837,
    "itl": 117.21095405395624,
    "ttft": 779332.4539967937,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089387,
    "arrivals": 142732,
    "finished_requests": 120652,
    "scheduler_time": 90.25646570739704
}
#Debug simulation 
Total elapsed time: 8.669570853933692. Arrivals time: 0.3325001613702625 Scheduler time: 8.208312631817535 Scheduler overhead time: 0.04806703398935497 Adapter cache time: 0.01002823212184012 Engine time: 0.04853496770374477 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-16/adapters_32_slots_32_rate_3.2-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-16/adapters_32_slots_32_rate_3.2-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 135, 135, 4320, 135, 34560, 4320, 135, 135, 135, 34560, 34560, 135, 135, 4320, 4320, 4320, 34560, 34560, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 429030 . Total input tokens: 95601350 . Total output tokens: 85757126
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 8.772720173932612,
    "estimated_duration": 3600.0269153585173,
    "input_throughput": 8273.694252931367,
    "output_throughput": 7341.525388947804,
    "total_throughput": 15615.21964187917,
    "itl": 117.21013729142561,
    "ttft": 779320.1908147748,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 142732,
    "finished_requests": 120651,
    "scheduler_time": 90.25423516269512
}
#Debug simulation 
Total elapsed time: 8.772865266073495. Arrivals time: 0.3867401147726923 Scheduler time: 8.255827479762957 Scheduler overhead time: 0.04831869178451598 Adapter cache time: 0.010863524861633778 Engine time: 0.04888916737399995 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-32/adapters_32_slots_32_rate_3.2-0.4-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-32/adapters_32_slots_32_rate_3.2-0.4-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 135, 135, 4320, 135, 34560, 4320, 135, 135, 135, 34560, 34560, 135, 135, 4320, 4320, 4320, 34560, 34560, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 429030 . Total input tokens: 95601350 . Total output tokens: 85757126
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.620890635997057,
    "estimated_duration": 3600.101489197235,
    "input_throughput": 8273.617588109099,
    "output_throughput": 7341.404424099562,
    "total_throughput": 15615.02201220866,
    "itl": 117.21081771454193,
    "ttft": 779311.081343716,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145733,
    "arrivals": 142732,
    "finished_requests": 120653,
    "scheduler_time": 90.25654174510026
}
#Debug simulation 
Total elapsed time: 8.621010354021564. Arrivals time: 0.3131629640702158 Scheduler time: 8.178784278454259 Scheduler overhead time: 0.048421622486785054 Adapter cache time: 0.010047232965007424 Engine time: 0.04845641530118883 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-8/adapters_32_slots_32_rate_3.2-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-8/adapters_32_slots_32_rate_3.2-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 66, 66, 4320, 66, 34560, 4320, 66, 66, 66, 34560, 34560, 66, 66, 4320, 4320, 4320, 34560, 34560, 66, 34560, 34560, 34560, 34560, 4320, 66, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 428340 . Total input tokens: 95433402 . Total output tokens: 85618390
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 8.903874247102067,
    "estimated_duration": 3600.110466749482,
    "input_throughput": 8368.060168776025,
    "output_throughput": 7414.304712738532,
    "total_throughput": 15782.364881514555,
    "itl": 115.85001820883598,
    "ttft": 731667.4015998262,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 142534,
    "finished_requests": 121814,
    "scheduler_time": 92.05859513535154
}
#Debug simulation 
Total elapsed time: 8.903980410192162. Arrivals time: 0.39555268199183047 Scheduler time: 8.377117994008586 Scheduler overhead time: 0.049056724179536104 Adapter cache time: 0.010228285565972328 Engine time: 0.0494610988534987 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-16/adapters_32_slots_32_rate_3.2-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-16/adapters_32_slots_32_rate_3.2-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 66, 66, 4320, 66, 34560, 4320, 66, 66, 66, 34560, 34560, 66, 66, 4320, 4320, 4320, 34560, 34560, 66, 34560, 34560, 34560, 34560, 4320, 66, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 428340 . Total input tokens: 95433402 . Total output tokens: 85618390
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.856730870204046,
    "estimated_duration": 3600.0260142634993,
    "input_throughput": 8367.9836980742,
    "output_throughput": 7414.438088570518,
    "total_throughput": 15782.421786644718,
    "itl": 115.85156042474398,
    "ttft": 731716.046699364,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255727,
    "arrivals": 142534,
    "finished_requests": 121810,
    "scheduler_time": 92.05649704224678
}
#Debug simulation 
Total elapsed time: 8.856858795043081. Arrivals time: 0.3700852848123759 Scheduler time: 8.356257849838585 Scheduler overhead time: 0.04869455681182444 Adapter cache time: 0.009904737118631601 Engine time: 0.04919268866069615 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-32/adapters_32_slots_32_rate_3.2-0.4-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-32/adapters_32_slots_32_rate_3.2-0.4-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 66, 66, 4320, 66, 34560, 4320, 66, 66, 66, 34560, 34560, 66, 66, 4320, 4320, 4320, 34560, 34560, 66, 34560, 34560, 34560, 34560, 4320, 66, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 428340 . Total input tokens: 95433402 . Total output tokens: 85618390
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.865748787065968,
    "estimated_duration": 3600.0261488032606,
    "input_throughput": 8367.98338534688,
    "output_throughput": 7414.437811478994,
    "total_throughput": 15782.421196825875,
    "itl": 115.85156480073566,
    "ttft": 731716.1604826421,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033041,
    "arrivals": 142534,
    "finished_requests": 121810,
    "scheduler_time": 92.0564902404104
}
#Debug simulation 
Total elapsed time: 8.865859211189672. Arrivals time: 0.3738723280839622 Scheduler time: 8.361317192437127 Scheduler overhead time: 0.04875663761049509 Adapter cache time: 0.009963625110685825 Engine time: 0.04945549974218011 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-16-16/adapters_32_slots_32_rate_3.2-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-16-16/adapters_32_slots_32_rate_3.2-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 66, 66, 4320, 66, 34560, 4320, 66, 66, 66, 34560, 34560, 66, 66, 4320, 4320, 4320, 34560, 34560, 66, 34560, 34560, 34560, 34560, 4320, 66, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 428340 . Total input tokens: 95433402 . Total output tokens: 85618390
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 8.821188509929925,
    "estimated_duration": 3600.12841756983,
    "input_throughput": 8368.018444279747,
    "output_throughput": 7414.26774382063,
    "total_throughput": 15782.286188100377,
    "itl": 115.85019904408523,
    "ttft": 731685.7029867215,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971346,
    "arrivals": 142534,
    "finished_requests": 121814,
    "scheduler_time": 92.05915963483586
}
#Debug simulation 
Total elapsed time: 8.82133811688982. Arrivals time: 0.37881332635879517 Scheduler time: 8.312370796687901 Scheduler overhead time: 0.048766999738290906 Adapter cache time: 0.00995983392931521 Engine time: 0.04915172839537263 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-16-32/adapters_32_slots_32_rate_3.2-0.4-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-16-32/adapters_32_slots_32_rate_3.2-0.4-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 66, 66, 4320, 66, 34560, 4320, 66, 66, 66, 34560, 34560, 66, 66, 4320, 4320, 4320, 34560, 34560, 66, 34560, 34560, 34560, 34560, 4320, 66, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 428340 . Total input tokens: 95433402 . Total output tokens: 85618390
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 8.878265131963417,
    "estimated_duration": 3600.0307833988672,
    "input_throughput": 8367.972612600377,
    "output_throughput": 7414.428266304807,
    "total_throughput": 15782.400878905184,
    "itl": 115.851587906828,
    "ttft": 731719.5168180419,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089386,
    "arrivals": 142534,
    "finished_requests": 121810,
    "scheduler_time": 92.0563281553319
}
#Debug simulation 
Total elapsed time: 8.87839274504222. Arrivals time: 0.38494003051891923 Scheduler time: 8.362580474931747 Scheduler overhead time: 0.04900015238672495 Adapter cache time: 0.01011361787095666 Engine time: 0.049195287050679326 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_16-16-16/adapters_32_slots_32_rate_3.2-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_16-16-16/adapters_32_slots_32_rate_3.2-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 66, 66, 4320, 66, 34560, 4320, 66, 66, 66, 34560, 34560, 66, 66, 4320, 4320, 4320, 34560, 34560, 66, 34560, 34560, 34560, 34560, 4320, 66, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 428340 . Total input tokens: 95433402 . Total output tokens: 85618390
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 8.84102619998157,
    "estimated_duration": 3600.105057452302,
    "input_throughput": 8368.072742110287,
    "output_throughput": 7414.315853018311,
    "total_throughput": 15782.3885951286,
    "itl": 115.85018561208267,
    "ttft": 731666.0389566432,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 142534,
    "finished_requests": 121814,
    "scheduler_time": 92.05859119009891
}
#Debug simulation 
Total elapsed time: 8.841144818114117. Arrivals time: 0.35997064551338553 Scheduler time: 8.350305746076629 Scheduler overhead time: 0.04900624812580645 Adapter cache time: 0.009578315308317542 Engine time: 0.04983143997378647 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_16-16-32/adapters_32_slots_32_rate_3.2-0.4-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_16-16-32/adapters_32_slots_32_rate_3.2-0.4-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 66, 66, 4320, 66, 34560, 4320, 66, 66, 66, 34560, 34560, 66, 66, 4320, 4320, 4320, 34560, 34560, 66, 34560, 34560, 34560, 34560, 4320, 66, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 428340 . Total input tokens: 95433402 . Total output tokens: 85618390
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.850818665931001,
    "estimated_duration": 3600.0346614308037,
    "input_throughput": 8367.963598446879,
    "output_throughput": 7414.420279329039,
    "total_throughput": 15782.383877775917,
    "itl": 115.8515746719275,
    "ttft": 731720.7125684604,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145731,
    "arrivals": 142534,
    "finished_requests": 121810,
    "scheduler_time": 92.05633867107125
}
#Debug simulation 
Total elapsed time: 8.850920215016231. Arrivals time: 0.3616726577747613 Scheduler time: 8.358568029478192 Scheduler overhead time: 0.04875138564966619 Adapter cache time: 0.00975402258336544 Engine time: 0.04955764510668814 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-8/adapters_32_slots_32_rate_3.2-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-8/adapters_32_slots_32_rate_3.2-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 33, 33, 4320, 33, 34560, 4320, 33, 33, 33, 34560, 34560, 33, 33, 4320, 4320, 4320, 34560, 34560, 33, 34560, 34560, 34560, 34560, 4320, 33, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 428010 . Total input tokens: 95363095 . Total output tokens: 85549163
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 8.880709324032068,
    "estimated_duration": 3600.025949301563,
    "input_throughput": 8480.420260838131,
    "output_throughput": 7446.3177147933575,
    "total_throughput": 15926.737975631488,
    "itl": 114.57039148877129,
    "ttft": 700419.0866992974,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 142385,
    "finished_requests": 122568,
    "scheduler_time": 92.93494424298454
}
#Debug simulation 
Total elapsed time: 8.880856530042365. Arrivals time: 0.3840404232032597 Scheduler time: 8.365348558872938 Scheduler overhead time: 0.04942899476736784 Adapter cache time: 0.009322744561359286 Engine time: 0.05009043589234352 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-16/adapters_32_slots_32_rate_3.2-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-16/adapters_32_slots_32_rate_3.2-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 33, 33, 4320, 33, 34560, 4320, 33, 33, 33, 34560, 34560, 33, 33, 4320, 4320, 4320, 34560, 34560, 33, 34560, 34560, 34560, 34560, 4320, 33, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 428010 . Total input tokens: 95363095 . Total output tokens: 85549163
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.918342071818188,
    "estimated_duration": 3600.070666808561,
    "input_throughput": 8480.319367470756,
    "output_throughput": 7446.292998399498,
    "total_throughput": 15926.612365870255,
    "itl": 114.57106435345399,
    "ttft": 700419.2006481582,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255728,
    "arrivals": 142385,
    "finished_requests": 122569,
    "scheduler_time": 92.93591784159614
}
#Debug simulation 
Total elapsed time: 8.918457974912599. Arrivals time: 0.3936626783106476 Scheduler time: 8.393184189219028 Scheduler overhead time: 0.049630364403128624 Adapter cache time: 0.0094171401578933 Engine time: 0.049863813212141395 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-32/adapters_32_slots_32_rate_3.2-0.4-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-32/adapters_32_slots_32_rate_3.2-0.4-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 33, 33, 4320, 33, 34560, 4320, 33, 33, 33, 34560, 34560, 33, 33, 4320, 4320, 4320, 34560, 34560, 33, 34560, 34560, 34560, 34560, 4320, 33, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 428010 . Total input tokens: 95363095 . Total output tokens: 85549163
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.860109554138035,
    "estimated_duration": 3600.0708043338022,
    "input_throughput": 8480.319043516582,
    "output_throughput": 7446.292713945859,
    "total_throughput": 15926.61175746244,
    "itl": 114.57108316857618,
    "ttft": 700419.3072438099,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033042,
    "arrivals": 142385,
    "finished_requests": 122569,
    "scheduler_time": 92.93591239193208
}
#Debug simulation 
Total elapsed time: 8.860245411051437. Arrivals time: 0.3844964844174683 Scheduler time: 8.344623612472787 Scheduler overhead time: 0.049225437454879284 Adapter cache time: 0.009445112897083163 Engine time: 0.04978577350266278 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-16/adapters_32_slots_32_rate_3.2-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-16/adapters_32_slots_32_rate_3.2-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 33, 33, 4320, 33, 34560, 4320, 33, 33, 33, 34560, 34560, 33, 33, 4320, 4320, 4320, 34560, 34560, 33, 34560, 34560, 34560, 34560, 4320, 33, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 428010 . Total input tokens: 95363095 . Total output tokens: 85549163
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 8.880275276955217,
    "estimated_duration": 3600.034630382016,
    "input_throughput": 8480.404255655827,
    "output_throughput": 7446.367535957666,
    "total_throughput": 15926.771791613493,
    "itl": 114.57045136805492,
    "ttft": 700419.5616288661,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971348,
    "arrivals": 142385,
    "finished_requests": 122569,
    "scheduler_time": 92.93506349744533
}
#Debug simulation 
Total elapsed time: 8.88044400094077. Arrivals time: 0.3896108299959451 Scheduler time: 8.359472455456853 Scheduler overhead time: 0.04944251198321581 Adapter cache time: 0.009398335823789239 Engine time: 0.04970371234230697 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-32/adapters_32_slots_32_rate_3.2-0.4-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-32/adapters_32_slots_32_rate_3.2-0.4-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 33, 33, 4320, 33, 34560, 4320, 33, 33, 33, 34560, 34560, 33, 33, 4320, 4320, 4320, 34560, 34560, 33, 34560, 34560, 34560, 34560, 4320, 33, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 428010 . Total input tokens: 95363095 . Total output tokens: 85549163
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 8.863289730856195,
    "estimated_duration": 3600.079137007437,
    "input_throughput": 8480.29941513392,
    "output_throughput": 7446.2754789005685,
    "total_throughput": 15926.57489403449,
    "itl": 114.57117305081026,
    "ttft": 700423.3617863398,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089388,
    "arrivals": 142385,
    "finished_requests": 122569,
    "scheduler_time": 92.93592159948365
}
#Debug simulation 
Total elapsed time: 8.863430311903358. Arrivals time: 0.38888618373312056 Scheduler time: 8.343741652788594 Scheduler overhead time: 0.04925530171021819 Adapter cache time: 0.009358199313282967 Engine time: 0.049599234480410814 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-16/adapters_32_slots_32_rate_3.2-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-16/adapters_32_slots_32_rate_3.2-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 33, 33, 4320, 33, 34560, 4320, 33, 33, 33, 34560, 34560, 33, 33, 4320, 4320, 4320, 34560, 34560, 33, 34560, 34560, 34560, 34560, 4320, 33, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 428010 . Total input tokens: 95363095 . Total output tokens: 85549163
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 8.870443460065871,
    "estimated_duration": 3600.025030684997,
    "input_throughput": 8480.422424782679,
    "output_throughput": 7446.319614866481,
    "total_throughput": 15926.74203964916,
    "itl": 114.57090159269998,
    "ttft": 700420.5512832629,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 142385,
    "finished_requests": 122568,
    "scheduler_time": 92.93476994159187
}
#Debug simulation 
Total elapsed time: 8.870559671893716. Arrivals time: 0.3896076090168208 Scheduler time: 8.349248121958226 Scheduler overhead time: 0.04960176348686218 Adapter cache time: 0.009440510300919414 Engine time: 0.050036834785714746 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-32/adapters_32_slots_32_rate_3.2-0.4-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-32/adapters_32_slots_32_rate_3.2-0.4-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 4320, 33, 33, 4320, 33, 34560, 4320, 33, 33, 33, 34560, 34560, 33, 33, 4320, 4320, 4320, 34560, 34560, 33, 34560, 34560, 34560, 34560, 4320, 33, 4320, 4320, 4320, 4320, 34560]
Prompts retrieved: 428010 . Total input tokens: 95363095 . Total output tokens: 85549163
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.947459495160729,
    "estimated_duration": 3600.0891614392235,
    "input_throughput": 8480.275801779027,
    "output_throughput": 7446.254744780592,
    "total_throughput": 15926.53054655962,
    "itl": 114.57131530652845,
    "ttft": 700421.6277532949,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145736,
    "arrivals": 142385,
    "finished_requests": 122569,
    "scheduler_time": 92.93625463177504
}
#Debug simulation 
Total elapsed time: 8.947631737217307. Arrivals time: 0.40727253956720233 Scheduler time: 8.406999212456867 Scheduler overhead time: 0.050226566614583135 Adapter cache time: 0.00962174916639924 Engine time: 0.050619423389434814 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-8/adapters_32_slots_32_rate_3.2-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-8/adapters_32_slots_32_rate_3.2-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [10 11 11]
Adapter prompts. [34560, 1080, 540, 540, 1080, 540, 34560, 1080, 540, 540, 540, 34560, 34560, 540, 540, 1080, 1080, 1080, 34560, 34560, 540, 34560, 34560, 34560, 34560, 1080, 540, 1080, 1080, 1080, 1080, 34560]
Prompts retrieved: 397440 . Total input tokens: 88554180 . Total output tokens: 79454492
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 8.3195154001005,
    "estimated_duration": 3600.047681265519,
    "input_throughput": 8113.178653715114,
    "output_throughput": 7122.661495135014,
    "total_throughput": 15235.840148850128,
    "itl": 119.80009372137185,
    "ttft": 569896.2156847577,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 132241,
    "finished_requests": 117345,
    "scheduler_time": 91.4778782873261
}
#Debug simulation 
Total elapsed time: 8.319642791058868. Arrivals time: 0.2727415047120303 Scheduler time: 7.91896235733293 Scheduler overhead time: 0.047018719371408224 Adapter cache time: 0.01187350251711905 Engine time: 0.04748564003966749 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-16/adapters_32_slots_32_rate_3.2-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-16/adapters_32_slots_32_rate_3.2-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [10 11 11]
Adapter prompts. [34560, 1080, 540, 540, 1080, 540, 34560, 1080, 540, 540, 540, 34560, 34560, 540, 540, 1080, 1080, 1080, 34560, 34560, 540, 34560, 34560, 34560, 34560, 1080, 540, 1080, 1080, 1080, 1080, 34560]
Prompts retrieved: 397440 . Total input tokens: 88554180 . Total output tokens: 79454492
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.346842842875049,
    "estimated_duration": 3600.0921600918928,
    "input_throughput": 8113.0789716379,
    "output_throughput": 7122.774879003506,
    "total_throughput": 15235.853850641406,
    "itl": 119.80078074374887,
    "ttft": 569863.1202657414,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255728,
    "arrivals": 132241,
    "finished_requests": 117347,
    "scheduler_time": 91.47938033357002
}
#Debug simulation 
Total elapsed time: 8.346950229024515. Arrivals time: 0.3080365965142846 Scheduler time: 7.912058416055515 Scheduler overhead time: 0.04652447090484202 Adapter cache time: 0.01166823087260127 Engine time: 0.047210115706548095 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-32/adapters_32_slots_32_rate_3.2-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-32/adapters_32_slots_32_rate_3.2-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [10 11 11]
Adapter prompts. [34560, 1080, 540, 540, 1080, 540, 34560, 1080, 540, 540, 540, 34560, 34560, 540, 540, 1080, 1080, 1080, 34560, 34560, 540, 34560, 34560, 34560, 34560, 1080, 540, 1080, 1080, 1080, 1080, 34560]
Prompts retrieved: 397440 . Total input tokens: 88554180 . Total output tokens: 79454492
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.402879122877494,
    "estimated_duration": 3600.09242095817,
    "input_throughput": 8113.078383756129,
    "output_throughput": 7122.7743628801545,
    "total_throughput": 15235.852746636283,
    "itl": 119.80079704852052,
    "ttft": 569863.3523613036,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033041,
    "arrivals": 132241,
    "finished_requests": 117347,
    "scheduler_time": 91.47937450342282
}
#Debug simulation 
Total elapsed time: 8.402991340961307. Arrivals time: 0.3085753773339093 Scheduler time: 7.965920948656276 Scheduler overhead time: 0.047027320601046085 Adapter cache time: 0.011987515026703477 Engine time: 0.04771143686957657 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-16-16/adapters_32_slots_32_rate_3.2-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-16-16/adapters_32_slots_32_rate_3.2-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [10 11 11]
Adapter prompts. [34560, 1080, 540, 540, 1080, 540, 34560, 1080, 540, 540, 540, 34560, 34560, 540, 540, 1080, 1080, 1080, 34560, 34560, 540, 34560, 34560, 34560, 34560, 1080, 540, 1080, 1080, 1080, 1080, 34560]
Prompts retrieved: 397440 . Total input tokens: 88554180 . Total output tokens: 79454492
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 8.38545327191241,
    "estimated_duration": 3600.0738065143496,
    "input_throughput": 8113.120333018812,
    "output_throughput": 7122.8111917037695,
    "total_throughput": 15235.93152472258,
    "itl": 119.80099435179262,
    "ttft": 569838.1772276651,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971346,
    "arrivals": 132241,
    "finished_requests": 117347,
    "scheduler_time": 91.4792065122401
}
#Debug simulation 
Total elapsed time: 8.38560777506791. Arrivals time: 0.3085903446190059 Scheduler time: 7.948680384317413 Scheduler overhead time: 0.047082462115213275 Adapter cache time: 0.011682852171361446 Engine time: 0.04782531573437154 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-16-32/adapters_32_slots_32_rate_3.2-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-16-32/adapters_32_slots_32_rate_3.2-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [10 11 11]
Adapter prompts. [34560, 1080, 540, 540, 1080, 540, 34560, 1080, 540, 540, 540, 34560, 34560, 540, 540, 1080, 1080, 1080, 34560, 34560, 540, 34560, 34560, 34560, 34560, 1080, 540, 1080, 1080, 1080, 1080, 34560]
Prompts retrieved: 397440 . Total input tokens: 88554180 . Total output tokens: 79454492
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 8.363548213848844,
    "estimated_duration": 3600.09798639474,
    "input_throughput": 8113.143895077698,
    "output_throughput": 7122.775851353829,
    "total_throughput": 15235.919746431528,
    "itl": 119.80058191217935,
    "ttft": 569887.4595838608,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089388,
    "arrivals": 132241,
    "finished_requests": 117348,
    "scheduler_time": 91.4792085257515
}
#Debug simulation 
Total elapsed time: 8.363657886860892. Arrivals time: 0.29938171384856105 Scheduler time: 7.936792191118002 Scheduler overhead time: 0.04693886102177203 Adapter cache time: 0.011679081479087472 Engine time: 0.047314259223639965 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_16-16-16/adapters_32_slots_32_rate_3.2-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_16-16-16/adapters_32_slots_32_rate_3.2-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [10 11 11]
Adapter prompts. [34560, 1080, 540, 540, 1080, 540, 34560, 1080, 540, 540, 540, 34560, 34560, 540, 540, 1080, 1080, 1080, 34560, 34560, 540, 34560, 34560, 34560, 34560, 1080, 540, 1080, 1080, 1080, 1080, 34560]
Prompts retrieved: 397440 . Total input tokens: 88554180 . Total output tokens: 79454492
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 8.284621767001227,
    "estimated_duration": 3600.047296251776,
    "input_throughput": 8113.1795213940695,
    "output_throughput": 7122.662256881273,
    "total_throughput": 15235.841778275342,
    "itl": 119.80046607109907,
    "ttft": 569898.1061795227,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 132241,
    "finished_requests": 117345,
    "scheduler_time": 91.47759172055461
}
#Debug simulation 
Total elapsed time: 8.284717568894848. Arrivals time: 0.26006360654719174 Scheduler time: 7.897234446136281 Scheduler overhead time: 0.046686617424711585 Adapter cache time: 0.011756004998460412 Engine time: 0.04747056239284575 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_16-16-32/adapters_32_slots_32_rate_3.2-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_16-16-32/adapters_32_slots_32_rate_3.2-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [10 11 11]
Adapter prompts. [34560, 1080, 540, 540, 1080, 540, 34560, 1080, 540, 540, 540, 34560, 34560, 540, 540, 1080, 1080, 1080, 34560, 34560, 540, 34560, 34560, 34560, 34560, 1080, 540, 1080, 1080, 1080, 1080, 34560]
Prompts retrieved: 397440 . Total input tokens: 88554180 . Total output tokens: 79454492
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.395117343170568,
    "estimated_duration": 3600.1056470883714,
    "input_throughput": 8113.126631053845,
    "output_throughput": 7122.760694742065,
    "total_throughput": 15235.88732579591,
    "itl": 119.80061251755212,
    "ttft": 569891.2017497843,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145736,
    "arrivals": 132241,
    "finished_requests": 117348,
    "scheduler_time": 91.47916012846399
}
#Debug simulation 
Total elapsed time: 8.395225448999554. Arrivals time: 0.30003755958750844 Scheduler time: 7.96718113287352 Scheduler overhead time: 0.04705200996249914 Adapter cache time: 0.01182805304415524 Engine time: 0.04747465602122247 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-8/adapters_32_slots_32_rate_3.2-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-8/adapters_32_slots_32_rate_3.2-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 1080, 270, 270, 1080, 270, 34560, 1080, 270, 270, 270, 34560, 34560, 270, 270, 1080, 1080, 1080, 34560, 34560, 270, 34560, 34560, 34560, 34560, 1080, 270, 1080, 1080, 1080, 1080, 34560]
Prompts retrieved: 394740 . Total input tokens: 87955617 . Total output tokens: 78939968
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 8.516922876005992,
    "estimated_duration": 3600.112814545696,
    "input_throughput": 8258.657028710903,
    "output_throughput": 7239.903675987753,
    "total_throughput": 15498.560704698655,
    "itl": 117.32850928567284,
    "ttft": 456059.7084614024,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 131339,
    "finished_requests": 119440,
    "scheduler_time": 94.78180781333683
}
#Debug simulation 
Total elapsed time: 8.517043536994606. Arrivals time: 0.3049068774562329 Scheduler time: 8.081084477948025 Scheduler overhead time: 0.048307739198207855 Adapter cache time: 0.012025181436911225 Engine time: 0.04861785238608718 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-16/adapters_32_slots_32_rate_3.2-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-16/adapters_32_slots_32_rate_3.2-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 1080, 270, 270, 1080, 270, 34560, 1080, 270, 270, 270, 34560, 34560, 270, 270, 1080, 1080, 1080, 34560, 34560, 270, 34560, 34560, 34560, 34560, 1080, 270, 1080, 1080, 1080, 1080, 34560]
Prompts retrieved: 394740 . Total input tokens: 87955617 . Total output tokens: 78939968
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.503444705856964,
    "estimated_duration": 3600.0175569304174,
    "input_throughput": 8258.722222830165,
    "output_throughput": 7240.047190832014,
    "total_throughput": 15498.76941366218,
    "itl": 117.32849729671887,
    "ttft": 456078.84551727556,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255727,
    "arrivals": 131339,
    "finished_requests": 119439,
    "scheduler_time": 94.78014505796382
}
#Debug simulation 
Total elapsed time: 8.503565847873688. Arrivals time: 0.3124887589365244 Scheduler time: 8.061005852883682 Scheduler overhead time: 0.047933539375662804 Adapter cache time: 0.011774946702644229 Engine time: 0.048440859420225024 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-32/adapters_32_slots_32_rate_3.2-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-32/adapters_32_slots_32_rate_3.2-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 1080, 270, 270, 1080, 270, 34560, 1080, 270, 270, 270, 34560, 34560, 270, 270, 1080, 1080, 1080, 34560, 34560, 270, 34560, 34560, 34560, 34560, 1080, 270, 1080, 1080, 1080, 1080, 34560]
Prompts retrieved: 394740 . Total input tokens: 87955617 . Total output tokens: 78939968
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.528543872991577,
    "estimated_duration": 3600.0176899654866,
    "input_throughput": 8258.72191763731,
    "output_throughput": 7240.046923283279,
    "total_throughput": 15498.76884092059,
    "itl": 117.32849900951102,
    "ttft": 456078.9658350344,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.1048120480403304,
    "arrivals": 131339,
    "finished_requests": 119439,
    "scheduler_time": 94.78014001804894
}
#Debug simulation 
Total elapsed time: 8.528649894054979. Arrivals time: 0.30380217591300607 Scheduler time: 8.094444468151778 Scheduler overhead time: 0.04778740368783474 Adapter cache time: 0.011790543561801314 Engine time: 0.048837122274562716 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-16-16/adapters_32_slots_32_rate_3.2-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-16-16/adapters_32_slots_32_rate_3.2-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 1080, 270, 270, 1080, 270, 34560, 1080, 270, 270, 270, 34560, 34560, 270, 270, 1080, 1080, 1080, 34560, 34560, 270, 34560, 34560, 34560, 34560, 1080, 270, 1080, 1080, 1080, 1080, 34560]
Prompts retrieved: 394740 . Total input tokens: 87955617 . Total output tokens: 78939968
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 8.548446720931679,
    "estimated_duration": 3600.0138396182447,
    "input_throughput": 8258.644084310738,
    "output_throughput": 7240.0168891472695,
    "total_throughput": 15498.660973458007,
    "itl": 117.32866440577614,
    "ttft": 456103.88331404247,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971346,
    "arrivals": 131339,
    "finished_requests": 119438,
    "scheduler_time": 94.77987219747759
}
#Debug simulation 
Total elapsed time: 8.548601288814098. Arrivals time: 0.31553610623814166 Scheduler time: 8.102462835377082 Scheduler overhead time: 0.048116950085386634 Adapter cache time: 0.011784577509388328 Engine time: 0.04854620364494622 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-16-32/adapters_32_slots_32_rate_3.2-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-16-32/adapters_32_slots_32_rate_3.2-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 1080, 270, 270, 1080, 270, 34560, 1080, 270, 270, 270, 34560, 34560, 270, 270, 1080, 1080, 1080, 34560, 34560, 270, 34560, 34560, 34560, 34560, 1080, 270, 1080, 1080, 1080, 1080, 34560]
Prompts retrieved: 394740 . Total input tokens: 87955617 . Total output tokens: 78939968
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 8.52638561394997,
    "estimated_duration": 3600.0243357605973,
    "input_throughput": 8258.706671692109,
    "output_throughput": 7240.033557854616,
    "total_throughput": 15498.740229546725,
    "itl": 117.32839745000844,
    "ttft": 456079.7206826944,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089386,
    "arrivals": 131339,
    "finished_requests": 119439,
    "scheduler_time": 94.78015746747964
}
#Debug simulation 
Total elapsed time: 8.526509847026318. Arrivals time: 0.3011657928582281 Scheduler time: 8.094787328038365 Scheduler overhead time: 0.047924275044351816 Adapter cache time: 0.011963208904489875 Engine time: 0.048578879330307245 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_16-16-16/adapters_32_slots_32_rate_3.2-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_16-16-16/adapters_32_slots_32_rate_3.2-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 1080, 270, 270, 1080, 270, 34560, 1080, 270, 270, 270, 34560, 34560, 270, 270, 1080, 1080, 1080, 34560, 34560, 270, 34560, 34560, 34560, 34560, 1080, 270, 1080, 1080, 1080, 1080, 34560]
Prompts retrieved: 394740 . Total input tokens: 87955617 . Total output tokens: 78939968
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 8.506442588986829,
    "estimated_duration": 3600.0994548834474,
    "input_throughput": 8258.687675883268,
    "output_throughput": 7239.930542653254,
    "total_throughput": 15498.618218536521,
    "itl": 117.3285703840082,
    "ttft": 456055.0825865751,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 131339,
    "finished_requests": 119440,
    "scheduler_time": 94.78176931459025
}
#Debug simulation 
Total elapsed time: 8.506563500035554. Arrivals time: 0.3093035249039531 Scheduler time: 8.06761072599329 Scheduler overhead time: 0.04782321164384484 Adapter cache time: 0.011618470307439566 Engine time: 0.0482419787440449 
