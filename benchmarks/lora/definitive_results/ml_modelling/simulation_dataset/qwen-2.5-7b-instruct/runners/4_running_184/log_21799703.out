INFO 06-01 00:46:59 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:47:00 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_16_slots_16_rate_0.1-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_16_slots_16_rate_0.1-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [5 5 6]
Adapter prompts. [270, 66, 66, 270, 1080, 66, 1080, 66, 270, 270, 66, 270, 1080, 1080, 1080, 1080]
Prompts retrieved: 8160 . Total input tokens: 1782495 . Total output tokens: 1691602
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 0.7143559413962066,
    "estimated_duration": 3599.1890048211885,
    "input_throughput": 176.47169936038276,
    "output_throughput": 159.64040766693373,
    "total_throughput": 336.1121070273165,
    "itl": 17.992826150206103,
    "ttft": 9596.376847520254,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 2634,
    "finished_requests": 2627,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7144419783726335. Arrivals time: 0.020840340293943882 Scheduler time: 0.29378844145685434 Scheduler overhead time: 0.1478972607292235 Adapter cache time: 0.027648880146443844 Engine time: 0.14864076348021626 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_16_slots_16_rate_0.1-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_16_slots_16_rate_0.1-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [5 5 6]
Adapter prompts. [270, 66, 66, 270, 1080, 66, 1080, 66, 270, 270, 66, 270, 1080, 1080, 1080, 1080]
Prompts retrieved: 8160 . Total input tokens: 1782495 . Total output tokens: 1691602
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 0.7005452262237668,
    "estimated_duration": 3599.1890048211885,
    "input_throughput": 176.47169936038276,
    "output_throughput": 159.64040766693373,
    "total_throughput": 336.1121070273165,
    "itl": 17.992826212366122,
    "ttft": 9596.383688328448,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 2634,
    "finished_requests": 2627,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7006351388990879. Arrivals time: 0.020753096789121628 Scheduler time: 0.28746354300528765 Scheduler overhead time: 0.14597760187461972 Adapter cache time: 0.02702210284769535 Engine time: 0.145334807690233 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_16_slots_16_rate_0.1-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_16_slots_16_rate_0.1-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [5 5 6]
Adapter prompts. [270, 66, 66, 270, 1080, 66, 1080, 66, 270, 270, 66, 270, 1080, 1080, 1080, 1080]
Prompts retrieved: 8160 . Total input tokens: 1782495 . Total output tokens: 1691602
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 0.7011737446300685,
    "estimated_duration": 3599.1890048211885,
    "input_throughput": 176.47169936038276,
    "output_throughput": 159.64040766693373,
    "total_throughput": 336.1121070273165,
    "itl": 17.99282297074116,
    "ttft": 9596.347745184645,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 2634,
    "finished_requests": 2627,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7012374736368656. Arrivals time: 0.02061327686533332 Scheduler time: 0.2874552197754383 Scheduler overhead time: 0.14659614954143763 Adapter cache time: 0.026711630634963512 Engine time: 0.14561299374327064 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_16_slots_16_rate_0.1-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_16_slots_16_rate_0.1-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [5 5 6]
Adapter prompts. [270, 66, 66, 270, 1080, 66, 1080, 66, 270, 270, 66, 270, 1080, 1080, 1080, 1080]
Prompts retrieved: 8160 . Total input tokens: 1782495 . Total output tokens: 1691602
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 0.6991647901013494,
    "estimated_duration": 3599.1890048211885,
    "input_throughput": 176.47169936038276,
    "output_throughput": 159.64040766693373,
    "total_throughput": 336.1121070273165,
    "itl": 17.992824796852112,
    "ttft": 9596.370644188293,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.0530347929522395,
    "arrivals": 2634,
    "finished_requests": 2627,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6992621188983321. Arrivals time: 0.020317472517490387 Scheduler time: 0.2858944870531559 Scheduler overhead time: 0.1459725913591683 Adapter cache time: 0.02706431271508336 Engine time: 0.14559005293995142 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_16_slots_16_rate_0.1-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_16_slots_16_rate_0.1-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [5 5 6]
Adapter prompts. [270, 66, 66, 270, 1080, 66, 1080, 66, 270, 270, 66, 270, 1080, 1080, 1080, 1080]
Prompts retrieved: 8160 . Total input tokens: 1782495 . Total output tokens: 1691602
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 0.7114327768795192,
    "estimated_duration": 3599.1890048211885,
    "input_throughput": 176.47169936038276,
    "output_throughput": 159.64040766693373,
    "total_throughput": 336.1121070273165,
    "itl": 17.992809875730103,
    "ttft": 9596.340270073688,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 2634,
    "finished_requests": 2627,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7115292777307332. Arrivals time: 0.020906980149447918 Scheduler time: 0.2930344962514937 Scheduler overhead time: 0.14763158466666937 Adapter cache time: 0.027514898218214512 Engine time: 0.14774883538484573 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_16_slots_16_rate_0.1-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_16_slots_16_rate_0.1-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [5 5 6]
Adapter prompts. [270, 66, 66, 270, 1080, 66, 1080, 66, 270, 270, 66, 270, 1080, 1080, 1080, 1080]
Prompts retrieved: 8160 . Total input tokens: 1782495 . Total output tokens: 1691602
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 0.7057714788243175,
    "estimated_duration": 3599.1890048211885,
    "input_throughput": 176.47169936038276,
    "output_throughput": 159.64040766693373,
    "total_throughput": 336.1121070273165,
    "itl": 17.992824257194705,
    "ttft": 9596.366905944407,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072867,
    "arrivals": 2634,
    "finished_requests": 2627,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7058470058254898. Arrivals time: 0.02092961734160781 Scheduler time: 0.28855975763872266 Scheduler overhead time: 0.14836133504286408 Adapter cache time: 0.027509959880262613 Engine time: 0.1458469438366592 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_16_slots_16_rate_0.1-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_16_slots_16_rate_0.1-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [5 5 6]
Adapter prompts. [270, 33, 33, 270, 1080, 33, 1080, 33, 270, 270, 33, 270, 1080, 1080, 1080, 1080]
Prompts retrieved: 7995 . Total input tokens: 1748656 . Total output tokens: 1658331
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 0.6987856808118522,
    "estimated_duration": 3599.8922369375896,
    "input_throughput": 173.4171355448891,
    "output_throughput": 160.8584262768417,
    "total_throughput": 334.2755618217308,
    "itl": 17.95609952603679,
    "ttft": 5608.372169287297,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 2581,
    "finished_requests": 2577,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6988499877043068. Arrivals time: 0.020178058184683323 Scheduler time: 0.2862690784968436 Scheduler overhead time: 0.14600297482684255 Adapter cache time: 0.026820840779691935 Engine time: 0.14559365902096033 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_16_slots_16_rate_0.1-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_16_slots_16_rate_0.1-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [5 5 6]
Adapter prompts. [270, 33, 33, 270, 1080, 33, 1080, 33, 270, 270, 33, 270, 1080, 1080, 1080, 1080]
Prompts retrieved: 7995 . Total input tokens: 1748656 . Total output tokens: 1658331
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 0.7098235902376473,
    "estimated_duration": 3599.8922369375896,
    "input_throughput": 173.4171355448891,
    "output_throughput": 160.8584262768417,
    "total_throughput": 334.2755618217308,
    "itl": 17.95611729838139,
    "ttft": 5608.380355100888,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 2581,
    "finished_requests": 2577,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7099194428883493. Arrivals time: 0.0208240351639688 Scheduler time: 0.2929363274015486 Scheduler overhead time: 0.14663331443443894 Adapter cache time: 0.027437867131084204 Engine time: 0.14767203899100423 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_16_slots_16_rate_0.1-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_16_slots_16_rate_0.1-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [5 5 6]
Adapter prompts. [270, 33, 33, 270, 1080, 33, 1080, 33, 270, 270, 33, 270, 1080, 1080, 1080, 1080]
Prompts retrieved: 7995 . Total input tokens: 1748656 . Total output tokens: 1658331
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 0.7036920040845871,
    "estimated_duration": 3599.8922369375896,
    "input_throughput": 173.4171355448891,
    "output_throughput": 160.8584262768417,
    "total_throughput": 334.2755618217308,
    "itl": 17.956117462950093,
    "ttft": 5608.381818738677,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 2581,
    "finished_requests": 2577,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7037728480063379. Arrivals time: 0.020892008673399687 Scheduler time: 0.2896419558674097 Scheduler overhead time: 0.14515403611585498 Adapter cache time: 0.02711320575326681 Engine time: 0.14694540901109576 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_16_slots_16_rate_0.1-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_16_slots_16_rate_0.1-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [5 5 6]
Adapter prompts. [270, 33, 33, 270, 1080, 33, 1080, 33, 270, 270, 33, 270, 1080, 1080, 1080, 1080]
Prompts retrieved: 7995 . Total input tokens: 1748656 . Total output tokens: 1658331
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 0.7022998011671007,
    "estimated_duration": 3599.8922369375896,
    "input_throughput": 173.4171355448891,
    "output_throughput": 160.8584262768417,
    "total_throughput": 334.2755618217308,
    "itl": 17.9561064001488,
    "ttft": 5608.368141684467,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 2581,
    "finished_requests": 2577,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7023894833400846. Arrivals time: 0.02094624238088727 Scheduler time: 0.28768389532342553 Scheduler overhead time: 0.14714654721319675 Adapter cache time: 0.02706385776400566 Engine time: 0.14542048843577504 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_16_slots_16_rate_0.1-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_16_slots_16_rate_0.1-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [5 5 6]
Adapter prompts. [270, 33, 33, 270, 1080, 33, 1080, 33, 270, 270, 33, 270, 1080, 1080, 1080, 1080]
Prompts retrieved: 7995 . Total input tokens: 1748656 . Total output tokens: 1658331
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 0.7009043088182807,
    "estimated_duration": 3599.8922369375896,
    "input_throughput": 173.4171355448891,
    "output_throughput": 160.8584262768417,
    "total_throughput": 334.2755618217308,
    "itl": 17.956120684268317,
    "ttft": 5608.380656849609,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.0530347929522395,
    "arrivals": 2581,
    "finished_requests": 2577,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7009951686486602. Arrivals time: 0.02029486559331417 Scheduler time: 0.2872600187547505 Scheduler overhead time: 0.14669230952858925 Adapter cache time: 0.027077407110482454 Engine time: 0.14558457443490624 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_16_slots_16_rate_0.1-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_16_slots_16_rate_0.1-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [5 5 6]
Adapter prompts. [270, 33, 33, 270, 1080, 33, 1080, 33, 270, 270, 33, 270, 1080, 1080, 1080, 1080]
Prompts retrieved: 7995 . Total input tokens: 1748656 . Total output tokens: 1658331
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 0.7052114508114755,
    "estimated_duration": 3599.8922369375896,
    "input_throughput": 173.4171355448891,
    "output_throughput": 160.8584262768417,
    "total_throughput": 334.2755618217308,
    "itl": 17.956095413486395,
    "ttft": 5608.366264865694,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 2581,
    "finished_requests": 2577,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7052770610898733. Arrivals time: 0.020350833423435688 Scheduler time: 0.28745570173487067 Scheduler overhead time: 0.14713778672739863 Adapter cache time: 0.02746735792607069 Engine time: 0.14816501317545772 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_16_slots_16_rate_0.1-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_16_slots_16_rate_0.1-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [5 5 6]
Adapter prompts. [270, 33, 33, 270, 1080, 33, 1080, 33, 270, 270, 33, 270, 1080, 1080, 1080, 1080]
Prompts retrieved: 7995 . Total input tokens: 1748656 . Total output tokens: 1658331
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 0.7067663781344891,
    "estimated_duration": 3599.8922369375896,
    "input_throughput": 173.4171355448891,
    "output_throughput": 160.8584262768417,
    "total_throughput": 334.2755618217308,
    "itl": 17.95612345354709,
    "ttft": 5608.390693765534,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072868,
    "arrivals": 2581,
    "finished_requests": 2577,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7068321011029184. Arrivals time: 0.020632296334952116 Scheduler time: 0.2889095791615546 Scheduler overhead time: 0.14720600843429565 Adapter cache time: 0.027330380864441395 Engine time: 0.1480562393553555 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_16_slots_16_rate_0.1-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_16_slots_16_rate_0.1-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [5 5 6]
Adapter prompts. [135, 66, 66, 135, 1080, 66, 1080, 66, 135, 135, 66, 135, 1080, 1080, 1080, 1080]
Prompts retrieved: 7485 . Total input tokens: 1638793 . Total output tokens: 1558698
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 0.6952408142387867,
    "estimated_duration": 3598.069410395735,
    "input_throughput": 158.62756798158196,
    "output_throughput": 148.80202100968194,
    "total_throughput": 307.4295889912639,
    "itl": 17.977356656833575,
    "ttft": 4484.322503379954,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 2424,
    "finished_requests": 2421,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6953281941823661. Arrivals time: 0.019979269243776798 Scheduler time: 0.2735234759747982 Scheduler overhead time: 0.1583821466192603 Adapter cache time: 0.026910025160759687 Engine time: 0.143235569819808 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_16_slots_16_rate_0.1-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_16_slots_16_rate_0.1-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [5 5 6]
Adapter prompts. [135, 66, 66, 135, 1080, 66, 1080, 66, 135, 135, 66, 135, 1080, 1080, 1080, 1080]
Prompts retrieved: 7485 . Total input tokens: 1638793 . Total output tokens: 1558698
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 0.6904092500917614,
    "estimated_duration": 3598.069410395735,
    "input_throughput": 158.62756798158196,
    "output_throughput": 148.80202100968194,
    "total_throughput": 307.4295889912639,
    "itl": 17.977368309215873,
    "ttft": 4484.32119899986,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 2424,
    "finished_requests": 2421,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6904834574088454. Arrivals time: 0.019895941950380802 Scheduler time: 0.27783105708658695 Scheduler overhead time: 0.14656861685216427 Adapter cache time: 0.026903463061898947 Engine time: 0.14559853496029973 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_16_slots_16_rate_0.1-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_16_slots_16_rate_0.1-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [5 5 6]
Adapter prompts. [135, 66, 66, 135, 1080, 66, 1080, 66, 135, 135, 66, 135, 1080, 1080, 1080, 1080]
Prompts retrieved: 7485 . Total input tokens: 1638793 . Total output tokens: 1558698
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 0.6799782263115048,
    "estimated_duration": 3598.069410395735,
    "input_throughput": 158.62756798158196,
    "output_throughput": 148.80202100968194,
    "total_throughput": 307.4295889912639,
    "itl": 17.977426286087958,
    "ttft": 4484.3145668294765,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 2424,
    "finished_requests": 2421,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6800413453020155. Arrivals time: 0.019728420302271843 Scheduler time: 0.27347034169360995 Scheduler overhead time: 0.14464245038107038 Adapter cache time: 0.02684201579540968 Engine time: 0.1420706883072853 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_16_slots_16_rate_0.1-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_16_slots_16_rate_0.1-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [5 5 6]
Adapter prompts. [135, 66, 66, 135, 1080, 66, 1080, 66, 135, 135, 66, 135, 1080, 1080, 1080, 1080]
Prompts retrieved: 7485 . Total input tokens: 1638793 . Total output tokens: 1558698
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 0.685919813811779,
    "estimated_duration": 3598.069410395735,
    "input_throughput": 158.62756798158196,
    "output_throughput": 148.80202100968194,
    "total_throughput": 307.4295889912639,
    "itl": 17.977360003409217,
    "ttft": 4484.321505743129,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 2424,
    "finished_requests": 2421,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6859870669431984. Arrivals time: 0.01974287861958146 Scheduler time: 0.2766973883844912 Scheduler overhead time: 0.14540083752945065 Adapter cache time: 0.026413832791149616 Engine time: 0.14410076616331935 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_16_slots_16_rate_0.1-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_16_slots_16_rate_0.1-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [5 5 6]
Adapter prompts. [135, 66, 66, 135, 1080, 66, 1080, 66, 135, 135, 66, 135, 1080, 1080, 1080, 1080]
Prompts retrieved: 7485 . Total input tokens: 1638793 . Total output tokens: 1558698
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 0.6810378599911928,
    "estimated_duration": 3598.069410395735,
    "input_throughput": 158.62756798158196,
    "output_throughput": 148.80202100968194,
    "total_throughput": 307.4295889912639,
    "itl": 17.977428597985508,
    "ttft": 4484.300897324719,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.0530347929522395,
    "arrivals": 2424,
    "finished_requests": 2421,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6811106251552701. Arrivals time: 0.020310838241130114 Scheduler time: 0.27371869096532464 Scheduler overhead time: 0.14466446917504072 Adapter cache time: 0.026724995579570532 Engine time: 0.14227685565128922 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_16_slots_16_rate_0.1-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_16_slots_16_rate_0.1-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [5 5 6]
Adapter prompts. [135, 66, 66, 135, 1080, 66, 1080, 66, 135, 135, 66, 135, 1080, 1080, 1080, 1080]
Prompts retrieved: 7485 . Total input tokens: 1638793 . Total output tokens: 1558698
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 0.6948494389653206,
    "estimated_duration": 3598.069410395735,
    "input_throughput": 158.62756798158196,
    "output_throughput": 148.80202100968194,
    "total_throughput": 307.4295889912639,
    "itl": 17.9773526861972,
    "ttft": 4484.31692417607,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 2424,
    "finished_requests": 2421,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6949146846309304. Arrivals time: 0.020624134223908186 Scheduler time: 0.27846944564953446 Scheduler overhead time: 0.14807643368840218 Adapter cache time: 0.026987870689481497 Engine time: 0.1469984487630427 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_16_slots_16_rate_0.1-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_16_slots_16_rate_0.1-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [5 5 6]
Adapter prompts. [135, 66, 66, 135, 1080, 66, 1080, 66, 135, 135, 66, 135, 1080, 1080, 1080, 1080]
Prompts retrieved: 7485 . Total input tokens: 1638793 . Total output tokens: 1558698
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 0.679894857108593,
    "estimated_duration": 3598.069410395735,
    "input_throughput": 158.62756798158196,
    "output_throughput": 148.80202100968194,
    "total_throughput": 307.4295889912639,
    "itl": 17.977430850011114,
    "ttft": 4484.30473634295,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072868,
    "arrivals": 2424,
    "finished_requests": 2421,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6799589721485972. Arrivals time: 0.01970866322517395 Scheduler time: 0.2723528388887644 Scheduler overhead time: 0.14474310958757997 Adapter cache time: 0.026525750290602446 Engine time: 0.14370670821517706 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_16_slots_16_rate_0.1-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_16_slots_16_rate_0.1-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [5 5 6]
Adapter prompts. [135, 33, 33, 135, 1080, 33, 1080, 33, 135, 135, 33, 135, 1080, 1080, 1080, 1080]
Prompts retrieved: 7320 . Total input tokens: 1602275 . Total output tokens: 1519268
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 0.6822224613279104,
    "estimated_duration": 3598.0775960341666,
    "input_throughput": 155.30432156769245,
    "output_throughput": 148.35616680094833,
    "total_throughput": 303.66048836864076,
    "itl": 17.994973079477447,
    "ttft": 9173.673305925762,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 2362,
    "finished_requests": 2356,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6823062472976744. Arrivals time: 0.02052947599440813 Scheduler time: 0.27195681910961866 Scheduler overhead time: 0.1442776545882225 Adapter cache time: 0.026004814077168703 Engine time: 0.14632728043943644 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_16_slots_16_rate_0.1-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_16_slots_16_rate_0.1-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [5 5 6]
Adapter prompts. [135, 33, 33, 135, 1080, 33, 1080, 33, 135, 135, 33, 135, 1080, 1080, 1080, 1080]
Prompts retrieved: 7320 . Total input tokens: 1602275 . Total output tokens: 1519268
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 0.6778720668517053,
    "estimated_duration": 3598.0775960341666,
    "input_throughput": 155.30432156769245,
    "output_throughput": 148.35616680094833,
    "total_throughput": 303.66048836864076,
    "itl": 17.994983168019974,
    "ttft": 9173.674899571242,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 2362,
    "finished_requests": 2356,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6779365637339652. Arrivals time: 0.01953149400651455 Scheduler time: 0.2711053933016956 Scheduler overhead time: 0.14468252891674638 Adapter cache time: 0.026145542040467262 Engine time: 0.14326065266504884 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_16_slots_16_rate_0.1-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_16_slots_16_rate_0.1-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [5 5 6]
Adapter prompts. [135, 33, 33, 135, 1080, 33, 1080, 33, 135, 135, 33, 135, 1080, 1080, 1080, 1080]
Prompts retrieved: 7320 . Total input tokens: 1602275 . Total output tokens: 1519268
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 0.6825141441076994,
    "estimated_duration": 3598.0775960341666,
    "input_throughput": 155.30432156769245,
    "output_throughput": 148.35616680094833,
    "total_throughput": 303.66048836864076,
    "itl": 17.994983474415548,
    "ttft": 9173.676894824155,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 2362,
    "finished_requests": 2356,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6825759918428957. Arrivals time: 0.019713683053851128 Scheduler time: 0.273448527790606 Scheduler overhead time: 0.14416749076917768 Adapter cache time: 0.02595003042370081 Engine time: 0.145967953838408 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_16_slots_16_rate_0.1-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_16_slots_16_rate_0.1-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [5 5 6]
Adapter prompts. [135, 33, 33, 135, 1080, 33, 1080, 33, 135, 135, 33, 135, 1080, 1080, 1080, 1080]
Prompts retrieved: 7320 . Total input tokens: 1602275 . Total output tokens: 1519268
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 0.6770890927873552,
    "estimated_duration": 3598.0775960341666,
    "input_throughput": 155.30432156769245,
    "output_throughput": 148.35616680094833,
    "total_throughput": 303.66048836864076,
    "itl": 17.99498036217587,
    "ttft": 9173.661233597426,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 2362,
    "finished_requests": 2356,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6771723749116063. Arrivals time: 0.019654301926493645 Scheduler time: 0.27132075326517224 Scheduler overhead time: 0.1442884407006204 Adapter cache time: 0.02611768152564764 Engine time: 0.1423370805568993 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_16_slots_16_rate_0.1-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_16_slots_16_rate_0.1-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [5 5 6]
Adapter prompts. [135, 33, 33, 135, 1080, 33, 1080, 33, 135, 135, 33, 135, 1080, 1080, 1080, 1080]
Prompts retrieved: 7320 . Total input tokens: 1602275 . Total output tokens: 1519268
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 0.6817878019064665,
    "estimated_duration": 3598.0775960341666,
    "input_throughput": 155.30432156769245,
    "output_throughput": 148.35616680094833,
    "total_throughput": 303.66048836864076,
    "itl": 17.994982902429133,
    "ttft": 9173.673833197565,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05303479295223951,
    "arrivals": 2362,
    "finished_requests": 2356,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6818626821041107. Arrivals time: 0.019890725146979094 Scheduler time: 0.2737662671133876 Scheduler overhead time: 0.14509623730555177 Adapter cache time: 0.026138016488403082 Engine time: 0.14365695556625724 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_16_slots_16_rate_0.1-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_16_slots_16_rate_0.1-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [5 5 6]
Adapter prompts. [135, 33, 33, 135, 1080, 33, 1080, 33, 135, 135, 33, 135, 1080, 1080, 1080, 1080]
Prompts retrieved: 7320 . Total input tokens: 1602275 . Total output tokens: 1519268
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 0.6816762229427695,
    "estimated_duration": 3598.0775960341666,
    "input_throughput": 155.30432156769245,
    "output_throughput": 148.35616680094833,
    "total_throughput": 303.66048836864076,
    "itl": 17.994969518078555,
    "ttft": 9173.663435140144,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 2362,
    "finished_requests": 2356,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6817400646395981. Arrivals time: 0.019602147862315178 Scheduler time: 0.2727984800003469 Scheduler overhead time: 0.1461099167354405 Adapter cache time: 0.02615635097026825 Engine time: 0.1436492307111621 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_16_slots_16_rate_0.1-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_16_slots_16_rate_0.1-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [5 5 6]
Adapter prompts. [135, 33, 33, 135, 1080, 33, 1080, 33, 135, 135, 33, 135, 1080, 1080, 1080, 1080]
Prompts retrieved: 7320 . Total input tokens: 1602275 . Total output tokens: 1519268
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 0.680347319226712,
    "estimated_duration": 3598.0775960341666,
    "input_throughput": 155.30432156769245,
    "output_throughput": 148.35616680094833,
    "total_throughput": 303.66048836864076,
    "itl": 17.994986263757372,
    "ttft": 9173.67931695709,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072868,
    "arrivals": 2362,
    "finished_requests": 2356,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.680408573243767. Arrivals time: 0.019557936117053032 Scheduler time: 0.27272589690983295 Scheduler overhead time: 0.14505727495998144 Adapter cache time: 0.02635296992957592 Engine time: 0.1432185536250472 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_16_slots_16_rate_0.1-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_16_slots_16_rate_0.1-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [5 5 6]
Adapter prompts. [66, 33, 33, 66, 1080, 33, 1080, 33, 66, 66, 33, 66, 1080, 1080, 1080, 1080]
Prompts retrieved: 6975 . Total input tokens: 1522996 . Total output tokens: 1452207
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 0.6758833359926939,
    "estimated_duration": 3599.8214234490324,
    "input_throughput": 156.21024874651303,
    "output_throughput": 142.97737011267253,
    "total_throughput": 299.1876188591856,
    "itl": 17.878691562128257,
    "ttft": 8004.110657764127,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 2257,
    "finished_requests": 2252,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.675980216357857. Arrivals time: 0.019766336772590876 Scheduler time: 0.27057630755007267 Scheduler overhead time: 0.1436162660829723 Adapter cache time: 0.025908034294843674 Engine time: 0.14318386651575565 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_16_slots_16_rate_0.1-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_16_slots_16_rate_0.1-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [5 5 6]
Adapter prompts. [66, 33, 33, 66, 1080, 33, 1080, 33, 66, 66, 33, 66, 1080, 1080, 1080, 1080]
Prompts retrieved: 6975 . Total input tokens: 1522996 . Total output tokens: 1452207
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 0.672941988799721,
    "estimated_duration": 3599.8214234490324,
    "input_throughput": 156.21024874651303,
    "output_throughput": 142.97737011267253,
    "total_throughput": 299.1876188591856,
    "itl": 17.878699800730725,
    "ttft": 8004.102457871051,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 2257,
    "finished_requests": 2252,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6730361809022725. Arrivals time: 0.019426523707807064 Scheduler time: 0.26633657794445753 Scheduler overhead time: 0.1441643349826336 Adapter cache time: 0.02599000046029687 Engine time: 0.1441867956891656 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_16_slots_16_rate_0.1-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_16_slots_16_rate_0.1-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [5 5 6]
Adapter prompts. [66, 33, 33, 66, 1080, 33, 1080, 33, 66, 66, 33, 66, 1080, 1080, 1080, 1080]
Prompts retrieved: 6975 . Total input tokens: 1522996 . Total output tokens: 1452207
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 0.6720476821064949,
    "estimated_duration": 3599.8214234490324,
    "input_throughput": 156.21024874651303,
    "output_throughput": 142.97737011267253,
    "total_throughput": 299.1876188591856,
    "itl": 17.87869973994391,
    "ttft": 8004.118221901217,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 2257,
    "finished_requests": 2252,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6721090069040656. Arrivals time: 0.01964909303933382 Scheduler time: 0.2681263778358698 Scheduler overhead time: 0.14342118706554174 Adapter cache time: 0.026000278536230326 Engine time: 0.14214280620217323 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_16_slots_16_rate_0.1-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_16_slots_16_rate_0.1-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [5 5 6]
Adapter prompts. [66, 33, 33, 66, 1080, 33, 1080, 33, 66, 66, 33, 66, 1080, 1080, 1080, 1080]
Prompts retrieved: 6975 . Total input tokens: 1522996 . Total output tokens: 1452207
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 0.6669923178851604,
    "estimated_duration": 3599.8214234490324,
    "input_throughput": 156.21024874651303,
    "output_throughput": 142.97737011267253,
    "total_throughput": 299.1876188591856,
    "itl": 17.878692999349745,
    "ttft": 8004.113518297599,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 2257,
    "finished_requests": 2252,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6670707957819104. Arrivals time: 0.01931061176583171 Scheduler time: 0.2652238351292908 Scheduler overhead time: 0.14230296574532986 Adapter cache time: 0.025914293248206377 Engine time: 0.1419466668739915 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_16_slots_16_rate_0.1-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_16_slots_16_rate_0.1-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [5 5 6]
Adapter prompts. [66, 33, 33, 66, 1080, 33, 1080, 33, 66, 66, 33, 66, 1080, 1080, 1080, 1080]
Prompts retrieved: 6975 . Total input tokens: 1522996 . Total output tokens: 1452207
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 0.6740058460272849,
    "estimated_duration": 3599.8214234490324,
    "input_throughput": 156.21024874651303,
    "output_throughput": 142.97737011267253,
    "total_throughput": 299.1876188591856,
    "itl": 17.878702855598505,
    "ttft": 8004.106859601335,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.0530347929522395,
    "arrivals": 2257,
    "finished_requests": 2252,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6740863979794085. Arrivals time: 0.019196289591491222 Scheduler time: 0.26748782908543944 Scheduler overhead time: 0.14285713527351618 Adapter cache time: 0.02645824383944273 Engine time: 0.1448267325758934 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_16_slots_16_rate_0.1-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_16_slots_16_rate_0.1-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [5 5 6]
Adapter prompts. [66, 33, 33, 66, 1080, 33, 1080, 33, 66, 66, 33, 66, 1080, 1080, 1080, 1080]
Prompts retrieved: 6975 . Total input tokens: 1522996 . Total output tokens: 1452207
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 0.6692148861475289,
    "estimated_duration": 3599.8214234490324,
    "input_throughput": 156.21024874651303,
    "output_throughput": 142.97737011267253,
    "total_throughput": 299.1876188591856,
    "itl": 17.87868763217318,
    "ttft": 8004.1035110313705,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 2257,
    "finished_requests": 2252,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.669275688007474. Arrivals time: 0.019126053899526596 Scheduler time: 0.2648484520614147 Scheduler overhead time: 0.1434414256364107 Adapter cache time: 0.025932966731488705 Engine time: 0.143049371894449 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_16_slots_16_rate_0.1-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_16_slots_16_rate_0.1-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [5 5 6]
Adapter prompts. [66, 33, 33, 66, 1080, 33, 1080, 33, 66, 66, 33, 66, 1080, 1080, 1080, 1080]
Prompts retrieved: 6975 . Total input tokens: 1522996 . Total output tokens: 1452207
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 0.6717567970044911,
    "estimated_duration": 3599.8214234490324,
    "input_throughput": 156.21024874651303,
    "output_throughput": 142.97737011267253,
    "total_throughput": 299.1876188591856,
    "itl": 17.878706492956145,
    "ttft": 8004.096479705494,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072867,
    "arrivals": 2257,
    "finished_requests": 2252,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.671819853130728. Arrivals time: 0.01935179578140378 Scheduler time: 0.2675107503309846 Scheduler overhead time: 0.1435135407373309 Adapter cache time: 0.0263223466463387 Engine time: 0.14185620611533523 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_16_slots_16_rate_0.05-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_16_slots_16_rate_0.05-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [5 5 6]
Adapter prompts. [270, 135, 135, 270, 540, 135, 540, 135, 270, 270, 135, 270, 540, 540, 540, 540]
Prompts retrieved: 5265 . Total input tokens: 1158054 . Total output tokens: 1096690
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 0.5931888511404395,
    "estimated_duration": 3595.0835935927494,
    "input_throughput": 111.11702679513618,
    "output_throughput": 105.48377808957238,
    "total_throughput": 216.60080488470857,
    "itl": 17.816796528241316,
    "ttft": 8599.362318893727,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 1680,
    "finished_requests": 1676,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5932676261290908. Arrivals time: 0.01683046482503414 Scheduler time: 0.2205563229508698 Scheduler overhead time: 0.132446582429111 Adapter cache time: 0.024493854492902756 Engine time: 0.1321248421445489 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_16_slots_16_rate_0.05-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_16_slots_16_rate_0.05-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [5 5 6]
Adapter prompts. [270, 135, 135, 270, 540, 135, 540, 135, 270, 270, 135, 270, 540, 540, 540, 540]
Prompts retrieved: 5265 . Total input tokens: 1158054 . Total output tokens: 1096690
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 0.5908143273554742,
    "estimated_duration": 3595.0835935927494,
    "input_throughput": 111.11702679513618,
    "output_throughput": 105.48377808957238,
    "total_throughput": 216.60080488470857,
    "itl": 17.81681541853816,
    "ttft": 8599.37582182621,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 1680,
    "finished_requests": 1676,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5908914380706847. Arrivals time: 0.017231842502951622 Scheduler time: 0.21909806272014976 Scheduler overhead time: 0.13226071326062083 Adapter cache time: 0.023960372898727655 Engine time: 0.13108095526695251 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_16_slots_16_rate_0.05-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_16_slots_16_rate_0.05-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [5 5 6]
Adapter prompts. [270, 135, 135, 270, 540, 135, 540, 135, 270, 270, 135, 270, 540, 540, 540, 540]
Prompts retrieved: 5265 . Total input tokens: 1158054 . Total output tokens: 1096690
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 0.5944053889252245,
    "estimated_duration": 3595.0835935927494,
    "input_throughput": 111.11702679513618,
    "output_throughput": 105.48377808957238,
    "total_throughput": 216.60080488470857,
    "itl": 17.816814815285404,
    "ttft": 8599.375522427908,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 1680,
    "finished_requests": 1676,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5944703640416265. Arrivals time: 0.017147525679320097 Scheduler time: 0.22006610594689846 Scheduler overhead time: 0.13372118584811687 Adapter cache time: 0.02417634055018425 Engine time: 0.13187136640772223 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_16_slots_16_rate_0.05-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_16_slots_16_rate_0.05-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [5 5 6]
Adapter prompts. [270, 135, 135, 270, 540, 135, 540, 135, 270, 270, 135, 270, 540, 540, 540, 540]
Prompts retrieved: 5265 . Total input tokens: 1158054 . Total output tokens: 1096690
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 0.5917169307358563,
    "estimated_duration": 3595.0835935927494,
    "input_throughput": 111.11702679513618,
    "output_throughput": 105.48377808957238,
    "total_throughput": 216.60080488470857,
    "itl": 17.816798014186887,
    "ttft": 8599.362445193761,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 1680,
    "finished_requests": 1676,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5917708207853138. Arrivals time: 0.016551015432924032 Scheduler time: 0.21791009698063135 Scheduler overhead time: 0.13359547592699528 Adapter cache time: 0.02410578029230237 Engine time: 0.1326680495403707 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_16_slots_16_rate_0.05-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_16_slots_16_rate_0.05-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [5 5 6]
Adapter prompts. [270, 135, 135, 270, 540, 135, 540, 135, 270, 270, 135, 270, 540, 540, 540, 540]
Prompts retrieved: 5265 . Total input tokens: 1158054 . Total output tokens: 1096690
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 0.5937850838527083,
    "estimated_duration": 3595.0835935927494,
    "input_throughput": 111.11702679513618,
    "output_throughput": 105.48377808957238,
    "total_throughput": 216.60080488470857,
    "itl": 17.81682611485939,
    "ttft": 8599.36842255877,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05303479295223951,
    "arrivals": 1680,
    "finished_requests": 1676,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5938786389306188. Arrivals time: 0.016890627797693014 Scheduler time: 0.21971572376787663 Scheduler overhead time: 0.13330956362187862 Adapter cache time: 0.0240882714278996 Engine time: 0.1321941390633583 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_16_slots_16_rate_0.05-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_16_slots_16_rate_0.05-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [5 5 6]
Adapter prompts. [270, 135, 135, 270, 540, 135, 540, 135, 270, 270, 135, 270, 540, 540, 540, 540]
Prompts retrieved: 5265 . Total input tokens: 1158054 . Total output tokens: 1096690
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 0.5906386412680149,
    "estimated_duration": 3595.0835935927494,
    "input_throughput": 111.11702679513618,
    "output_throughput": 105.48377808957238,
    "total_throughput": 216.60080488470857,
    "itl": 17.816791916720337,
    "ttft": 8599.358797021274,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 1680,
    "finished_requests": 1676,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5907222931273282. Arrivals time: 0.017203934025019407 Scheduler time: 0.21841713367030025 Scheduler overhead time: 0.1328547797165811 Adapter cache time: 0.02408806188032031 Engine time: 0.13095369329676032 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_16_slots_16_rate_0.05-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_16_slots_16_rate_0.05-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [5 5 6]
Adapter prompts. [270, 135, 135, 270, 540, 135, 540, 135, 270, 270, 135, 270, 540, 540, 540, 540]
Prompts retrieved: 5265 . Total input tokens: 1158054 . Total output tokens: 1096690
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 0.5949759287759662,
    "estimated_duration": 3595.0835935927494,
    "input_throughput": 111.11702679513618,
    "output_throughput": 105.48377808957238,
    "total_throughput": 216.60080488470857,
    "itl": 17.816827991482715,
    "ttft": 8599.369545360436,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072868,
    "arrivals": 1680,
    "finished_requests": 1676,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5950373336672783. Arrivals time: 0.016709026880562305 Scheduler time: 0.2186219678260386 Scheduler overhead time: 0.1335888304747641 Adapter cache time: 0.024331729393452406 Engine time: 0.13453394081443548 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_16_slots_16_rate_0.05-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_16_slots_16_rate_0.05-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [5 5 6]
Adapter prompts. [270, 66, 66, 270, 540, 66, 540, 66, 270, 270, 66, 270, 540, 540, 540, 540]
Prompts retrieved: 4920 . Total input tokens: 1090300 . Total output tokens: 1021728
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 0.57856301125139,
    "estimated_duration": 3598.550428455059,
    "input_throughput": 98.83785348332569,
    "output_throughput": 97.47813931583501,
    "total_throughput": 196.3159927991607,
    "itl": 17.843224956741235,
    "ttft": 2314.8308539103473,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 1574,
    "finished_requests": 1573,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5786276143044233. Arrivals time: 0.01642651716247201 Scheduler time: 0.21027873689308763 Scheduler overhead time: 0.1313376259058714 Adapter cache time: 0.02343514794483781 Engine time: 0.1307394690811634 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_16_slots_16_rate_0.05-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_16_slots_16_rate_0.05-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [5 5 6]
Adapter prompts. [270, 66, 66, 270, 540, 66, 540, 66, 270, 270, 66, 270, 540, 540, 540, 540]
Prompts retrieved: 4920 . Total input tokens: 1090300 . Total output tokens: 1021728
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 0.5897200787439942,
    "estimated_duration": 3598.550428455059,
    "input_throughput": 98.83785348332569,
    "output_throughput": 97.47813931583501,
    "total_throughput": 196.3159927991607,
    "itl": 17.843231360095693,
    "ttft": 2314.843091051231,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 1574,
    "finished_requests": 1573,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5897956159897149. Arrivals time: 0.01710330042988062 Scheduler time: 0.21629922045394778 Scheduler overhead time: 0.13318558130413294 Adapter cache time: 0.02469507372006774 Engine time: 0.13127035275101662 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_16_slots_16_rate_0.05-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_16_slots_16_rate_0.05-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [5 5 6]
Adapter prompts. [270, 66, 66, 270, 540, 66, 540, 66, 270, 270, 66, 270, 540, 540, 540, 540]
Prompts retrieved: 4920 . Total input tokens: 1090300 . Total output tokens: 1021728
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 0.5787227540276945,
    "estimated_duration": 3598.550428455059,
    "input_throughput": 98.83785348332569,
    "output_throughput": 97.47813931583501,
    "total_throughput": 196.3159927991607,
    "itl": 17.843231891912968,
    "ttft": 2314.843360551898,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 1574,
    "finished_requests": 1573,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5789134162478149. Arrivals time: 0.016258236952126026 Scheduler time: 0.21029056329280138 Scheduler overhead time: 0.1312735970132053 Adapter cache time: 0.023606921546161175 Engine time: 0.1308898995630443 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_16_slots_16_rate_0.05-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_16_slots_16_rate_0.05-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [5 5 6]
Adapter prompts. [270, 66, 66, 270, 540, 66, 540, 66, 270, 270, 66, 270, 540, 540, 540, 540]
Prompts retrieved: 4920 . Total input tokens: 1090300 . Total output tokens: 1021728
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 0.5801299596205354,
    "estimated_duration": 3598.550428455059,
    "input_throughput": 98.83785348332569,
    "output_throughput": 97.47813931583501,
    "total_throughput": 196.3159927991607,
    "itl": 17.843227801297843,
    "ttft": 2314.8363417003548,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 1574,
    "finished_requests": 1573,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5801944308914244. Arrivals time: 0.01643933681771159 Scheduler time: 0.20952313719317317 Scheduler overhead time: 0.1317816385999322 Adapter cache time: 0.023786425590515137 Engine time: 0.13185785291716456 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_16_slots_16_rate_0.05-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_16_slots_16_rate_0.05-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [5 5 6]
Adapter prompts. [270, 66, 66, 270, 540, 66, 540, 66, 270, 270, 66, 270, 540, 540, 540, 540]
Prompts retrieved: 4920 . Total input tokens: 1090300 . Total output tokens: 1021728
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 0.5816399222239852,
    "estimated_duration": 3598.550428455059,
    "input_throughput": 98.83785348332569,
    "output_throughput": 97.47813931583501,
    "total_throughput": 196.3159927991607,
    "itl": 17.843232987207713,
    "ttft": 2314.8454378063116,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.0530347929522395,
    "arrivals": 1574,
    "finished_requests": 1573,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5817023059353232. Arrivals time: 0.01676966529339552 Scheduler time: 0.2124669849872589 Scheduler overhead time: 0.1307930313050747 Adapter cache time: 0.023620123509317636 Engine time: 0.13148276694118977 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_16_slots_16_rate_0.05-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_16_slots_16_rate_0.05-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [5 5 6]
Adapter prompts. [270, 66, 66, 270, 540, 66, 540, 66, 270, 270, 66, 270, 540, 540, 540, 540]
Prompts retrieved: 4920 . Total input tokens: 1090300 . Total output tokens: 1021728
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 0.577406506985426,
    "estimated_duration": 3598.550428455059,
    "input_throughput": 98.83785348332569,
    "output_throughput": 97.47813931583501,
    "total_throughput": 196.3159927991607,
    "itl": 17.843222133775534,
    "ttft": 2314.826736854877,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 1574,
    "finished_requests": 1573,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5774689042009413. Arrivals time: 0.01689412072300911 Scheduler time: 0.20885731419548392 Scheduler overhead time: 0.13123581744730473 Adapter cache time: 0.02354938769713044 Engine time: 0.13066329713910818 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_16_slots_16_rate_0.05-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_16_slots_16_rate_0.05-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [5 5 6]
Adapter prompts. [270, 66, 66, 270, 540, 66, 540, 66, 270, 270, 66, 270, 540, 540, 540, 540]
Prompts retrieved: 4920 . Total input tokens: 1090300 . Total output tokens: 1021728
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 0.5813157870434225,
    "estimated_duration": 3598.550428455059,
    "input_throughput": 98.83785348332569,
    "output_throughput": 97.47813931583501,
    "total_throughput": 196.3159927991607,
    "itl": 17.843234731506673,
    "ttft": 2314.8483938991308,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072868,
    "arrivals": 1574,
    "finished_requests": 1573,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5813967399299145. Arrivals time: 0.01687028957530856 Scheduler time: 0.21250473009422421 Scheduler overhead time: 0.1316863507963717 Adapter cache time: 0.023736679460853338 Engine time: 0.1301823309622705 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_16_slots_16_rate_0.05-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_16_slots_16_rate_0.05-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [5 5 6]
Adapter prompts. [270, 33, 33, 270, 540, 33, 540, 33, 270, 270, 33, 270, 540, 540, 540, 540]
Prompts retrieved: 4755 . Total input tokens: 1052487 . Total output tokens: 985305
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 0.5568406828679144,
    "estimated_duration": 3599.5846616938416,
    "input_throughput": 101.84758366746856,
    "output_throughput": 89.89842729458857,
    "total_throughput": 191.7460109620571,
    "itl": 17.655096153377468,
    "ttft": 2394.323597821558,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 1521,
    "finished_requests": 1520,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5569056980311871. Arrivals time: 0.016270576044917107 Scheduler time: 0.198777181096375 Scheduler overhead time: 0.12765991874039173 Adapter cache time: 0.022715509869158268 Engine time: 0.12644234439358115 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_16_slots_16_rate_0.05-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_16_slots_16_rate_0.05-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [5 5 6]
Adapter prompts. [270, 33, 33, 270, 540, 33, 540, 33, 270, 270, 33, 270, 540, 540, 540, 540]
Prompts retrieved: 4755 . Total input tokens: 1052487 . Total output tokens: 985305
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 0.55704604415223,
    "estimated_duration": 3599.5846616938416,
    "input_throughput": 101.84758366746856,
    "output_throughput": 89.89842729458857,
    "total_throughput": 191.7460109620571,
    "itl": 17.65510577784814,
    "ttft": 2394.3336119070736,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 1521,
    "finished_requests": 1520,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5571208512410522. Arrivals time: 0.01616007136180997 Scheduler time: 0.19872780982404947 Scheduler overhead time: 0.12769937282428145 Adapter cache time: 0.02290807105600834 Engine time: 0.12689781142398715 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-32/adapters_16_slots_16_rate_0.05-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-32/adapters_16_slots_16_rate_0.05-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [5 5 6]
Adapter prompts. [270, 33, 33, 270, 540, 33, 540, 33, 270, 270, 33, 270, 540, 540, 540, 540]
Prompts retrieved: 4755 . Total input tokens: 1052487 . Total output tokens: 985305
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 0.559433301910758,
    "estimated_duration": 3599.5846616938416,
    "input_throughput": 101.84758366746856,
    "output_throughput": 89.89842729458857,
    "total_throughput": 191.7460109620571,
    "itl": 17.655106205081967,
    "ttft": 2394.3337038323143,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 1521,
    "finished_requests": 1520,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5594940837472677. Arrivals time: 0.016125021502375603 Scheduler time: 0.1996567090973258 Scheduler overhead time: 0.12831746507436037 Adapter cache time: 0.022730232682079077 Engine time: 0.12787477811798453 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_16_slots_16_rate_0.05-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_16_slots_16_rate_0.05-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [5 5 6]
Adapter prompts. [270, 33, 33, 270, 540, 33, 540, 33, 270, 270, 33, 270, 540, 540, 540, 540]
Prompts retrieved: 4755 . Total input tokens: 1052487 . Total output tokens: 985305
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 0.5647190450690687,
    "estimated_duration": 3599.5846616938416,
    "input_throughput": 101.84758366746856,
    "output_throughput": 89.89842729458857,
    "total_throughput": 191.7460109620571,
    "itl": 17.655099012348266,
    "ttft": 2394.3277019156167,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 1521,
    "finished_requests": 1520,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5647884369827807. Arrivals time: 0.01713168853893876 Scheduler time: 0.20283771539106965 Scheduler overhead time: 0.1283577042631805 Adapter cache time: 0.022884047590196133 Engine time: 0.12814678717404604 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-32/adapters_16_slots_16_rate_0.05-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-32/adapters_16_slots_16_rate_0.05-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [5 5 6]
Adapter prompts. [270, 33, 33, 270, 540, 33, 540, 33, 270, 270, 33, 270, 540, 540, 540, 540]
Prompts retrieved: 4755 . Total input tokens: 1052487 . Total output tokens: 985305
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 0.5600957688875496,
    "estimated_duration": 3599.5846616938416,
    "input_throughput": 101.84758366746856,
    "output_throughput": 89.89842729458857,
    "total_throughput": 191.7460109620571,
    "itl": 17.655108287306575,
    "ttft": 2394.3355227562465,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05303479295223951,
    "arrivals": 1521,
    "finished_requests": 1520,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5601799967698753. Arrivals time: 0.016131724696606398 Scheduler time: 0.19991589011624455 Scheduler overhead time: 0.12836155947297812 Adapter cache time: 0.0228555453941226 Engine time: 0.1281790821813047 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_16_slots_16_rate_0.05-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_16_slots_16_rate_0.05-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [5 5 6]
Adapter prompts. [270, 33, 33, 270, 540, 33, 540, 33, 270, 270, 33, 270, 540, 540, 540, 540]
Prompts retrieved: 4755 . Total input tokens: 1052487 . Total output tokens: 985305
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 0.5596001017838717,
    "estimated_duration": 3599.5846616938416,
    "input_throughput": 101.84758366746856,
    "output_throughput": 89.89842729458857,
    "total_throughput": 191.7460109620571,
    "itl": 17.655092547009616,
    "ttft": 2394.320448744283,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 1521,
    "finished_requests": 1520,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.559672418050468. Arrivals time: 0.016234905924648046 Scheduler time: 0.19863397534936666 Scheduler overhead time: 0.12873350642621517 Adapter cache time: 0.022695179097354412 Engine time: 0.1286765211261809 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-32/adapters_16_slots_16_rate_0.05-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-32/adapters_16_slots_16_rate_0.05-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [5 5 6]
Adapter prompts. [270, 33, 33, 270, 540, 33, 540, 33, 270, 270, 33, 270, 540, 540, 540, 540]
Prompts retrieved: 4755 . Total input tokens: 1052487 . Total output tokens: 985305
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 0.5577447609975934,
    "estimated_duration": 3599.5846616938416,
    "input_throughput": 101.84758366746856,
    "output_throughput": 89.89842729458857,
    "total_throughput": 191.7460109620571,
    "itl": 17.655110277150268,
    "ttft": 2394.337755071982,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072867,
    "arrivals": 1521,
    "finished_requests": 1520,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.557807985227555. Arrivals time: 0.015992044005542994 Scheduler time: 0.19771147286519408 Scheduler overhead time: 0.12854020344093442 Adapter cache time: 0.02281113900244236 Engine time: 0.12757050339132547 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_16_slots_16_rate_0.05-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_16_slots_16_rate_0.05-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [5 5 6]
Adapter prompts. [135, 66, 66, 135, 540, 66, 540, 66, 135, 135, 66, 135, 540, 540, 540, 540]
Prompts retrieved: 4245 . Total input tokens: 941014 . Total output tokens: 878666
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 0.5440177517011762,
    "estimated_duration": 3596.099548729764,
    "input_throughput": 92.28526504980209,
    "output_throughput": 87.15554053855602,
    "total_throughput": 179.44080558835813,
    "itl": 17.79594324904959,
    "ttft": 7922.080992486114,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 1368,
    "finished_requests": 1365,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.544078363571316. Arrivals time: 0.015541853848844767 Scheduler time: 0.19337438279762864 Scheduler overhead time: 0.1252670125104487 Adapter cache time: 0.022496969439089298 Engine time: 0.1240542521700263 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_16_slots_16_rate_0.05-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_16_slots_16_rate_0.05-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [5 5 6]
Adapter prompts. [135, 66, 66, 135, 540, 66, 540, 66, 135, 135, 66, 135, 540, 540, 540, 540]
Prompts retrieved: 4245 . Total input tokens: 941014 . Total output tokens: 878666
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 0.5444341613911092,
    "estimated_duration": 3596.099548729764,
    "input_throughput": 92.28526504980209,
    "output_throughput": 87.15554053855602,
    "total_throughput": 179.44080558835813,
    "itl": 17.795960759713644,
    "ttft": 7922.0578282956785,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 1368,
    "finished_requests": 1365,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5444937143474817. Arrivals time: 0.015329319518059492 Scheduler time: 0.1935384371317923 Scheduler overhead time: 0.12493411544710398 Adapter cache time: 0.02214176580309868 Engine time: 0.12505387468263507 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-32/adapters_16_slots_16_rate_0.05-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-32/adapters_16_slots_16_rate_0.05-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [5 5 6]
Adapter prompts. [135, 66, 66, 135, 540, 66, 540, 66, 135, 135, 66, 135, 540, 540, 540, 540]
Prompts retrieved: 4245 . Total input tokens: 941014 . Total output tokens: 878666
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 0.5478997370228171,
    "estimated_duration": 3596.099548729764,
    "input_throughput": 92.28526504980209,
    "output_throughput": 87.15554053855602,
    "total_throughput": 179.44080558835813,
    "itl": 17.795961999852107,
    "ttft": 7922.043634182676,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 1368,
    "finished_requests": 1365,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5479850671254098. Arrivals time: 0.01647868799045682 Scheduler time: 0.19325021095573902 Scheduler overhead time: 0.12485159793868661 Adapter cache time: 0.022316784132272005 Engine time: 0.12742526270449162 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_16_slots_16_rate_0.05-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_16_slots_16_rate_0.05-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [5 5 6]
Adapter prompts. [135, 66, 66, 135, 540, 66, 540, 66, 135, 135, 66, 135, 540, 540, 540, 540]
Prompts retrieved: 4245 . Total input tokens: 941014 . Total output tokens: 878666
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 0.5459693330340087,
    "estimated_duration": 3596.099548729764,
    "input_throughput": 92.28526504980209,
    "output_throughput": 87.15554053855602,
    "total_throughput": 179.44080558835813,
    "itl": 17.79595399406934,
    "ttft": 7922.07454460545,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 1368,
    "finished_requests": 1365,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5460546528920531. Arrivals time: 0.015331686474382877 Scheduler time: 0.1943977358750999 Scheduler overhead time: 0.1250833496451378 Adapter cache time: 0.022177754901349545 Engine time: 0.12576471967622638 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-32/adapters_16_slots_16_rate_0.05-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-32/adapters_16_slots_16_rate_0.05-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [5 5 6]
Adapter prompts. [135, 66, 66, 135, 540, 66, 540, 66, 135, 135, 66, 135, 540, 540, 540, 540]
Prompts retrieved: 4245 . Total input tokens: 941014 . Total output tokens: 878666
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 0.5410949541255832,
    "estimated_duration": 3596.099548729764,
    "input_throughput": 92.28526504980209,
    "output_throughput": 87.15554053855602,
    "total_throughput": 179.44080558835813,
    "itl": 17.79596410722931,
    "ttft": 7922.047035418127,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.0530347929522395,
    "arrivals": 1368,
    "finished_requests": 1365,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5411668601445854. Arrivals time: 0.015255318488925695 Scheduler time: 0.19161314237862825 Scheduler overhead time: 0.12541849398985505 Adapter cache time: 0.02240952430292964 Engine time: 0.12326367618516088 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_16_slots_16_rate_0.05-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_16_slots_16_rate_0.05-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [5 5 6]
Adapter prompts. [135, 66, 66, 135, 540, 66, 540, 66, 135, 135, 66, 135, 540, 540, 540, 540]
Prompts retrieved: 4245 . Total input tokens: 941014 . Total output tokens: 878666
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 0.5424006362445652,
    "estimated_duration": 3596.099548729764,
    "input_throughput": 92.28526504980209,
    "output_throughput": 87.15554053855602,
    "total_throughput": 179.44080558835813,
    "itl": 17.795937367291163,
    "ttft": 7922.075586102964,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 1368,
    "finished_requests": 1365,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5424679629504681. Arrivals time: 0.015379734802991152 Scheduler time: 0.19329286040738225 Scheduler overhead time: 0.12411091849207878 Adapter cache time: 0.02217102749273181 Engine time: 0.12405645428225398 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-32/adapters_16_slots_16_rate_0.05-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-32/adapters_16_slots_16_rate_0.05-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [5 5 6]
Adapter prompts. [135, 66, 66, 135, 540, 66, 540, 66, 135, 135, 66, 135, 540, 540, 540, 540]
Prompts retrieved: 4245 . Total input tokens: 941014 . Total output tokens: 878666
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 0.5423967819660902,
    "estimated_duration": 3596.099548729764,
    "input_throughput": 92.28526504980209,
    "output_throughput": 87.15554053855602,
    "total_throughput": 179.44080558835813,
    "itl": 17.795969010395513,
    "ttft": 7922.050896279991,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072868,
    "arrivals": 1368,
    "finished_requests": 1365,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5424653626978397. Arrivals time: 0.015384194441139698 Scheduler time: 0.19290403462946415 Scheduler overhead time: 0.1246094754897058 Adapter cache time: 0.02222412684932351 Engine time: 0.12378421099856496 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_16_slots_16_rate_0.05-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_16_slots_16_rate_0.05-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [5 5 6]
Adapter prompts. [135, 33, 33, 135, 540, 33, 540, 33, 135, 135, 33, 135, 540, 540, 540, 540]
Prompts retrieved: 4080 . Total input tokens: 907516 . Total output tokens: 841245
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 0.528512021061033,
    "estimated_duration": 3598.2653533022553,
    "input_throughput": 88.70051779452237,
    "output_throughput": 82.88299241919421,
    "total_throughput": 171.58351021371658,
    "itl": 17.810144671537703,
    "ttft": 5441.04242031335,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 1330,
    "finished_requests": 1328,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5285766134038568. Arrivals time: 0.015158170834183693 Scheduler time: 0.1870276816189289 Scheduler overhead time: 0.12111801374703646 Adapter cache time: 0.021220472641289234 Engine time: 0.12251770962029696 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_16_slots_16_rate_0.05-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_16_slots_16_rate_0.05-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [5 5 6]
Adapter prompts. [135, 33, 33, 135, 540, 33, 540, 33, 135, 135, 33, 135, 540, 540, 540, 540]
Prompts retrieved: 4080 . Total input tokens: 907516 . Total output tokens: 841245
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 0.529661513864994,
    "estimated_duration": 3598.2653533022553,
    "input_throughput": 88.70051779452237,
    "output_throughput": 82.88299241919421,
    "total_throughput": 171.58351021371658,
    "itl": 17.810158044799028,
    "ttft": 5441.058067812749,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 1330,
    "finished_requests": 1328,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5297211706638336. Arrivals time: 0.014769717119634151 Scheduler time: 0.19051071722060442 Scheduler overhead time: 0.12159271445125341 Adapter cache time: 0.02154390886425972 Engine time: 0.11982353776693344 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-32/adapters_16_slots_16_rate_0.05-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-32/adapters_16_slots_16_rate_0.05-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [5 5 6]
Adapter prompts. [135, 33, 33, 135, 540, 33, 540, 33, 135, 135, 33, 135, 540, 540, 540, 540]
Prompts retrieved: 4080 . Total input tokens: 907516 . Total output tokens: 841245
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 0.5240549058653414,
    "estimated_duration": 3598.2653533022553,
    "input_throughput": 88.70051779452237,
    "output_throughput": 82.88299241919421,
    "total_throughput": 171.58351021371658,
    "itl": 17.810159139102193,
    "ttft": 5441.0583999441815,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 1330,
    "finished_requests": 1328,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5241196760907769. Arrivals time: 0.015013972762972116 Scheduler time: 0.1852966034784913 Scheduler overhead time: 0.1212076316587627 Adapter cache time: 0.02131168730556965 Engine time: 0.1197326434776187 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-16/adapters_16_slots_16_rate_0.05-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-16/adapters_16_slots_16_rate_0.05-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [5 5 6]
Adapter prompts. [135, 33, 33, 135, 540, 33, 540, 33, 135, 135, 33, 135, 540, 540, 540, 540]
Prompts retrieved: 4080 . Total input tokens: 907516 . Total output tokens: 841245
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 0.5262177069671452,
    "estimated_duration": 3598.2653533022553,
    "input_throughput": 88.70051779452237,
    "output_throughput": 82.88299241919421,
    "total_throughput": 171.58351021371658,
    "itl": 17.810140937327716,
    "ttft": 5441.04854416247,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 1330,
    "finished_requests": 1328,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5262643340975046. Arrivals time: 0.014866417739540339 Scheduler time: 0.18614613311365247 Scheduler overhead time: 0.12159683648496866 Adapter cache time: 0.021406810265034437 Engine time: 0.12035307567566633 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-32/adapters_16_slots_16_rate_0.05-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-32/adapters_16_slots_16_rate_0.05-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [5 5 6]
Adapter prompts. [135, 33, 33, 135, 540, 33, 540, 33, 135, 135, 33, 135, 540, 540, 540, 540]
Prompts retrieved: 4080 . Total input tokens: 907516 . Total output tokens: 841245
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 0.5228365971706808,
    "estimated_duration": 3598.2653533022553,
    "input_throughput": 88.70051779452237,
    "output_throughput": 82.88299241919421,
    "total_throughput": 171.58351021371658,
    "itl": 17.81016466713991,
    "ttft": 5441.047348186484,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.0530347929522395,
    "arrivals": 1330,
    "finished_requests": 1328,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5228827819228172. Arrivals time: 0.01479871105402708 Scheduler time: 0.18483851151540875 Scheduler overhead time: 0.12078170012682676 Adapter cache time: 0.021525366697460413 Engine time: 0.11963670328259468 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-16/adapters_16_slots_16_rate_0.05-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-16/adapters_16_slots_16_rate_0.05-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [5 5 6]
Adapter prompts. [135, 33, 33, 135, 540, 33, 540, 33, 135, 135, 33, 135, 540, 540, 540, 540]
Prompts retrieved: 4080 . Total input tokens: 907516 . Total output tokens: 841245
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 0.5250941216945648,
    "estimated_duration": 3598.2653533022553,
    "input_throughput": 88.70051779452237,
    "output_throughput": 82.88299241919421,
    "total_throughput": 171.58351021371658,
    "itl": 17.810138803871585,
    "ttft": 5441.037177225039,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 1330,
    "finished_requests": 1328,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5251397900283337. Arrivals time: 0.01458687987178564 Scheduler time: 0.18596104672178626 Scheduler overhead time: 0.12181464862078428 Adapter cache time: 0.0212910040281713 Engine time: 0.12043314520269632 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-32/adapters_16_slots_16_rate_0.05-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-32/adapters_16_slots_16_rate_0.05-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [5 5 6]
Adapter prompts. [135, 33, 33, 135, 540, 33, 540, 33, 135, 135, 33, 135, 540, 540, 540, 540]
Prompts retrieved: 4080 . Total input tokens: 907516 . Total output tokens: 841245
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 0.5245678969658911,
    "estimated_duration": 3598.2653533022553,
    "input_throughput": 88.70051779452237,
    "output_throughput": 82.88299241919421,
    "total_throughput": 171.58351021371658,
    "itl": 17.810165323755825,
    "ttft": 5441.05084660009,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072868,
    "arrivals": 1330,
    "finished_requests": 1328,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5246204189024866. Arrivals time: 0.014735639095306396 Scheduler time: 0.18518221005797386 Scheduler overhead time: 0.12160786800086498 Adapter cache time: 0.021424311213195324 Engine time: 0.12032354949042201 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-8/adapters_16_slots_16_rate_0.05-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-8/adapters_16_slots_16_rate_0.05-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [5 5 6]
Adapter prompts. [66, 33, 33, 66, 540, 33, 540, 33, 66, 66, 33, 66, 540, 540, 540, 540]
Prompts retrieved: 3735 . Total input tokens: 826297 . Total output tokens: 774589
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 0.502125842962414,
    "estimated_duration": 3599.4027521715684,
    "input_throughput": 82.7378930630447,
    "output_throughput": 76.15568995012373,
    "total_throughput": 158.89358301316844,
    "itl": 17.778851085140207,
    "ttft": 2958.544413221392,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 1228,
    "finished_requests": 1227,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.502173796761781. Arrivals time: 0.014404582791030407 Scheduler time: 0.17825163947418332 Scheduler overhead time: 0.11625509057193995 Adapter cache time: 0.020235483068972826 Engine time: 0.11427812417969108 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-16/adapters_16_slots_16_rate_0.05-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-16/adapters_16_slots_16_rate_0.05-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [5 5 6]
Adapter prompts. [66, 33, 33, 66, 540, 33, 540, 33, 66, 66, 33, 66, 540, 540, 540, 540]
Prompts retrieved: 3735 . Total input tokens: 826297 . Total output tokens: 774589
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 0.504903266672045,
    "estimated_duration": 3599.4027521715684,
    "input_throughput": 82.7378930630447,
    "output_throughput": 76.15568995012373,
    "total_throughput": 158.89358301316844,
    "itl": 17.77886690733688,
    "ttft": 2958.5408957278373,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 1228,
    "finished_requests": 1227,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5049610990099609. Arrivals time: 0.014203839004039764 Scheduler time: 0.1786355315707624 Scheduler overhead time: 0.11743690818548203 Adapter cache time: 0.020256032701581717 Engine time: 0.11553275026381016 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-32/adapters_16_slots_16_rate_0.05-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-32/adapters_16_slots_16_rate_0.05-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [5 5 6]
Adapter prompts. [66, 33, 33, 66, 540, 33, 540, 33, 66, 66, 33, 66, 540, 540, 540, 540]
Prompts retrieved: 3735 . Total input tokens: 826297 . Total output tokens: 774589
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 0.5013030008412898,
    "estimated_duration": 3599.4027521715684,
    "input_throughput": 82.7378930630447,
    "output_throughput": 76.15568995012373,
    "total_throughput": 158.89358301316844,
    "itl": 17.77886704092504,
    "ttft": 2958.5411811322665,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 1228,
    "finished_requests": 1227,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5013672411441803. Arrivals time: 0.014129920396953821 Scheduler time: 0.1749216066673398 Scheduler overhead time: 0.11666427319869399 Adapter cache time: 0.020359295420348644 Engine time: 0.11650702869519591 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-16/adapters_16_slots_16_rate_0.05-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-16/adapters_16_slots_16_rate_0.05-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [5 5 6]
Adapter prompts. [66, 33, 33, 66, 540, 33, 540, 33, 66, 66, 33, 66, 540, 540, 540, 540]
Prompts retrieved: 3735 . Total input tokens: 826297 . Total output tokens: 774589
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 0.5004649721086025,
    "estimated_duration": 3599.4027521715684,
    "input_throughput": 82.7378930630447,
    "output_throughput": 76.15568995012373,
    "total_throughput": 158.89358301316844,
    "itl": 17.778857191956927,
    "ttft": 2958.5502315082294,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 1228,
    "finished_requests": 1227,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5005151350051165. Arrivals time: 0.014602322597056627 Scheduler time: 0.1749603319913149 Scheduler overhead time: 0.11610592110082507 Adapter cache time: 0.020525312051177025 Engine time: 0.11533327307552099 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-32/adapters_16_slots_16_rate_0.05-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-32/adapters_16_slots_16_rate_0.05-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [5 5 6]
Adapter prompts. [66, 33, 33, 66, 540, 33, 540, 33, 66, 66, 33, 66, 540, 540, 540, 540]
Prompts retrieved: 3735 . Total input tokens: 826297 . Total output tokens: 774589
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 0.4988605501130223,
    "estimated_duration": 3599.4027521715684,
    "input_throughput": 82.7378930630447,
    "output_throughput": 76.15568995012373,
    "total_throughput": 158.89358301316844,
    "itl": 17.778877056427103,
    "ttft": 2958.5164288895144,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05303479295223951,
    "arrivals": 1228,
    "finished_requests": 1227,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.4989087572321296. Arrivals time: 0.014122555498033762 Scheduler time: 0.17464938014745712 Scheduler overhead time: 0.11579396203160286 Adapter cache time: 0.02036577509716153 Engine time: 0.11522258445620537 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-16/adapters_16_slots_16_rate_0.05-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-16/adapters_16_slots_16_rate_0.05-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [5 5 6]
Adapter prompts. [66, 33, 33, 66, 540, 33, 540, 33, 66, 66, 33, 66, 540, 540, 540, 540]
Prompts retrieved: 3735 . Total input tokens: 826297 . Total output tokens: 774589
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 0.4950687470845878,
    "estimated_duration": 3599.4027521715684,
    "input_throughput": 82.7378930630447,
    "output_throughput": 76.15568995012373,
    "total_throughput": 158.89358301316844,
    "itl": 17.77884622337393,
    "ttft": 2958.535924017437,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 1228,
    "finished_requests": 1227,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.495115012396127. Arrivals time: 0.014230857603251934 Scheduler time: 0.1735689495690167 Scheduler overhead time: 0.11499651102349162 Adapter cache time: 0.020385427866131067 Engine time: 0.11355030676349998 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-32/adapters_16_slots_16_rate_0.05-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-32/adapters_16_slots_16_rate_0.05-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [5 5 6]
Adapter prompts. [66, 33, 33, 66, 540, 33, 540, 33, 66, 66, 33, 66, 540, 540, 540, 540]
Prompts retrieved: 3735 . Total input tokens: 826297 . Total output tokens: 774589
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 0.4980281591415405,
    "estimated_duration": 3599.4027521715684,
    "input_throughput": 82.7378930630447,
    "output_throughput": 76.15568995012373,
    "total_throughput": 158.89358301316844,
    "itl": 17.77888043223877,
    "ttft": 2958.5208323201464,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072867,
    "arrivals": 1228,
    "finished_requests": 1227,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.498080100864172. Arrivals time: 0.014326470904052258 Scheduler time: 0.1738136038184166 Scheduler overhead time: 0.11588890245184302 Adapter cache time: 0.02048426168039441 Engine time: 0.11473825108259916 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-8/adapters_16_slots_16_rate_0.025-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-8/adapters_16_slots_16_rate_0.025-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [5 5 6]
Adapter prompts. [135, 66, 66, 135, 270, 66, 270, 66, 135, 135, 66, 135, 270, 270, 270, 270]
Prompts retrieved: 2625 . Total input tokens: 582940 . Total output tokens: 547242
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 0.40598119515925646,
    "estimated_duration": 3597.865434346845,
    "input_throughput": 59.9322025614182,
    "output_throughput": 52.65705553948635,
    "total_throughput": 112.58925810090454,
    "itl": 17.710616772048052,
    "ttft": 8188.918813971634,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 882,
    "finished_requests": 880,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.40604135813191533. Arrivals time: 0.011807142291218042 Scheduler time: 0.1349688316695392 Scheduler overhead time: 0.09684571716934443 Adapter cache time: 0.017009788658469915 Engine time: 0.0960675785318017 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-16/adapters_16_slots_16_rate_0.025-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-16/adapters_16_slots_16_rate_0.025-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [5 5 6]
Adapter prompts. [135, 66, 66, 135, 270, 66, 270, 66, 135, 135, 66, 135, 270, 270, 270, 270]
Prompts retrieved: 2625 . Total input tokens: 582940 . Total output tokens: 547242
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 0.40472422260791063,
    "estimated_duration": 3597.865434346845,
    "input_throughput": 59.9322025614182,
    "output_throughput": 52.65705553948635,
    "total_throughput": 112.58925810090454,
    "itl": 17.710626724122484,
    "ttft": 8188.9525324380975,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 882,
    "finished_requests": 880,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.40476968698203564. Arrivals time: 0.011541855987161398 Scheduler time: 0.13566051702946424 Scheduler overhead time: 0.09609084250405431 Adapter cache time: 0.016767958644777536 Engine time: 0.09582271380349994 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-32/adapters_16_slots_16_rate_0.025-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-32/adapters_16_slots_16_rate_0.025-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [5 5 6]
Adapter prompts. [135, 66, 66, 135, 270, 66, 270, 66, 135, 135, 66, 135, 270, 270, 270, 270]
Prompts retrieved: 2625 . Total input tokens: 582940 . Total output tokens: 547242
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 0.40180557407438755,
    "estimated_duration": 3597.865434346845,
    "input_throughput": 59.9322025614182,
    "output_throughput": 52.65705553948635,
    "total_throughput": 112.58925810090454,
    "itl": 17.710627305546808,
    "ttft": 8188.953338491831,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 882,
    "finished_requests": 880,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.40185405872762203. Arrivals time: 0.011534401215612888 Scheduler time: 0.13314170623198152 Scheduler overhead time: 0.09618976805359125 Adapter cache time: 0.016766275744885206 Engine time: 0.09541414957493544 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-16/adapters_16_slots_16_rate_0.025-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-16/adapters_16_slots_16_rate_0.025-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [5 5 6]
Adapter prompts. [135, 66, 66, 135, 270, 66, 270, 66, 135, 135, 66, 135, 270, 270, 270, 270]
Prompts retrieved: 2625 . Total input tokens: 582940 . Total output tokens: 547242
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 0.40610017394647,
    "estimated_duration": 3597.865434346845,
    "input_throughput": 59.9322025614182,
    "output_throughput": 52.65705553948635,
    "total_throughput": 112.58925810090454,
    "itl": 17.710621193338408,
    "ttft": 8188.949289618108,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 882,
    "finished_requests": 880,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.4061468346044421. Arrivals time: 0.011599189136177301 Scheduler time: 0.13654100941494107 Scheduler overhead time: 0.09642800455912948 Adapter cache time: 0.016910296864807606 Engine time: 0.09629950346425176 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-32/adapters_16_slots_16_rate_0.025-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-32/adapters_16_slots_16_rate_0.025-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [5 5 6]
Adapter prompts. [135, 66, 66, 135, 270, 66, 270, 66, 135, 135, 66, 135, 270, 270, 270, 270]
Prompts retrieved: 2625 . Total input tokens: 582940 . Total output tokens: 547242
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 0.40217639273032546,
    "estimated_duration": 3597.865434346845,
    "input_throughput": 59.9322025614182,
    "output_throughput": 52.65705553948635,
    "total_throughput": 112.58925810090454,
    "itl": 17.710629007761707,
    "ttft": 8188.954336537757,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.0530347929522395,
    "arrivals": 882,
    "finished_requests": 880,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.4022231218405068. Arrivals time: 0.011726080905646086 Scheduler time: 0.13323764456436038 Scheduler overhead time: 0.09595482423901558 Adapter cache time: 0.016890488099306822 Engine time: 0.09555534739047289 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-16/adapters_16_slots_16_rate_0.025-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-16/adapters_16_slots_16_rate_0.025-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [5 5 6]
Adapter prompts. [135, 66, 66, 135, 270, 66, 270, 66, 135, 135, 66, 135, 270, 270, 270, 270]
Prompts retrieved: 2625 . Total input tokens: 582940 . Total output tokens: 547242
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 0.4069551113061607,
    "estimated_duration": 3597.865434346845,
    "input_throughput": 59.9322025614182,
    "output_throughput": 52.65705553948635,
    "total_throughput": 112.58925810090454,
    "itl": 17.710612803995524,
    "ttft": 8188.936318338159,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 882,
    "finished_requests": 880,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.40700073540210724. Arrivals time: 0.011939588002860546 Scheduler time: 0.13593981508165598 Scheduler overhead time: 0.09675861848518252 Adapter cache time: 0.016798645723611116 Engine time: 0.09642520360648632 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-32/adapters_16_slots_16_rate_0.025-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-32/adapters_16_slots_16_rate_0.025-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [5 5 6]
Adapter prompts. [135, 66, 66, 135, 270, 66, 270, 66, 135, 135, 66, 135, 270, 270, 270, 270]
Prompts retrieved: 2625 . Total input tokens: 582940 . Total output tokens: 547242
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 0.40836902102455497,
    "estimated_duration": 3597.865434346845,
    "input_throughput": 59.9322025614182,
    "output_throughput": 52.65705553948635,
    "total_throughput": 112.58925810090454,
    "itl": 17.710631589758087,
    "ttft": 8188.958328721451,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072867,
    "arrivals": 882,
    "finished_requests": 880,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.4084282419644296. Arrivals time: 0.011846681125462055 Scheduler time: 0.136356920003891 Scheduler overhead time: 0.09657238004729152 Adapter cache time: 0.016828203108161688 Engine time: 0.09792014630511403 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-8/adapters_16_slots_16_rate_0.025-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-8/adapters_16_slots_16_rate_0.025-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [5 5 6]
Adapter prompts. [135, 33, 33, 135, 270, 33, 270, 33, 135, 135, 33, 135, 270, 270, 270, 270]
Prompts retrieved: 2460 . Total input tokens: 551925 . Total output tokens: 512668
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 0.400641119107604,
    "estimated_duration": 3599.063516275376,
    "input_throughput": 60.3195800847293,
    "output_throughput": 48.17919973233743,
    "total_throughput": 108.49877981706673,
    "itl": 17.4136004704862,
    "ttft": 8881.25691241425,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 813,
    "finished_requests": 811,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.4006975321099162. Arrivals time: 0.011655514128506184 Scheduler time: 0.13109942618757486 Scheduler overhead time: 0.09608303429558873 Adapter cache time: 0.016500085592269897 Engine time: 0.09685397380962968 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-16/adapters_16_slots_16_rate_0.025-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-16/adapters_16_slots_16_rate_0.025-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [5 5 6]
Adapter prompts. [135, 33, 33, 135, 270, 33, 270, 33, 135, 135, 33, 135, 270, 270, 270, 270]
Prompts retrieved: 2460 . Total input tokens: 551925 . Total output tokens: 512668
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 0.39831724017858505,
    "estimated_duration": 3599.063516275376,
    "input_throughput": 60.3195800847293,
    "output_throughput": 48.17919973233743,
    "total_throughput": 108.49877981706673,
    "itl": 17.413612163977014,
    "ttft": 8881.271366360872,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 813,
    "finished_requests": 811,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.39837143989279866. Arrivals time: 0.011501583270728588 Scheduler time: 0.12937070708721876 Scheduler overhead time: 0.0960465376265347 Adapter cache time: 0.016703445930033922 Engine time: 0.09611513232812285 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-32/adapters_16_slots_16_rate_0.025-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-32/adapters_16_slots_16_rate_0.025-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [5 5 6]
Adapter prompts. [135, 33, 33, 135, 270, 33, 270, 33, 135, 135, 33, 135, 270, 270, 270, 270]
Prompts retrieved: 2460 . Total input tokens: 551925 . Total output tokens: 512668
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 0.4015781912021339,
    "estimated_duration": 3599.063516275376,
    "input_throughput": 60.3195800847293,
    "output_throughput": 48.17919973233743,
    "total_throughput": 108.49877981706673,
    "itl": 17.413612294495728,
    "ttft": 8881.270969260753,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.0524060240201652,
    "arrivals": 813,
    "finished_requests": 811,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.401630197186023. Arrivals time: 0.011410333681851625 Scheduler time: 0.1325188521295786 Scheduler overhead time: 0.09639956895262003 Adapter cache time: 0.016801623161882162 Engine time: 0.09557929448783398 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-16/adapters_16_slots_16_rate_0.025-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-16/adapters_16_slots_16_rate_0.025-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [5 5 6]
Adapter prompts. [135, 33, 33, 135, 270, 33, 270, 33, 135, 135, 33, 135, 270, 270, 270, 270]
Prompts retrieved: 2460 . Total input tokens: 551925 . Total output tokens: 512668
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 0.4007359719835222,
    "estimated_duration": 3599.063516275376,
    "input_throughput": 60.3195800847293,
    "output_throughput": 48.17919973233743,
    "total_throughput": 108.49877981706673,
    "itl": 17.413605266127075,
    "ttft": 8881.257796774653,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 813,
    "finished_requests": 811,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.40079787792637944. Arrivals time: 0.011520511005073786 Scheduler time: 0.129194017034024 Scheduler overhead time: 0.09763258323073387 Adapter cache time: 0.0169612648896873 Engine time: 0.09632356557995081 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-32/adapters_16_slots_16_rate_0.025-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-32/adapters_16_slots_16_rate_0.025-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [5 5 6]
Adapter prompts. [135, 33, 33, 135, 270, 33, 270, 33, 135, 135, 33, 135, 270, 270, 270, 270]
Prompts retrieved: 2460 . Total input tokens: 551925 . Total output tokens: 512668
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 0.402447038795799,
    "estimated_duration": 3599.063516275376,
    "input_throughput": 60.3195800847293,
    "output_throughput": 48.17919973233743,
    "total_throughput": 108.49877981706673,
    "itl": 17.413614417453847,
    "ttft": 8881.275145585763,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05303479295223951,
    "arrivals": 813,
    "finished_requests": 811,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.4025046597234905. Arrivals time: 0.01149563817307353 Scheduler time: 0.13101144693791866 Scheduler overhead time: 0.09753232402727008 Adapter cache time: 0.017166913487017155 Engine time: 0.09582852525636554 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-16/adapters_16_slots_16_rate_0.025-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-16/adapters_16_slots_16_rate_0.025-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [5 5 6]
Adapter prompts. [135, 33, 33, 135, 270, 33, 270, 33, 135, 135, 33, 135, 270, 270, 270, 270]
Prompts retrieved: 2460 . Total input tokens: 551925 . Total output tokens: 512668
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 0.3985371529124677,
    "estimated_duration": 3599.063516275376,
    "input_throughput": 60.3195800847293,
    "output_throughput": 48.17919973233743,
    "total_throughput": 108.49877981706673,
    "itl": 17.413596753640366,
    "ttft": 8881.253273579245,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 813,
    "finished_requests": 811,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.3985922238789499. Arrivals time: 0.01142650656402111 Scheduler time: 0.12976240692660213 Scheduler overhead time: 0.09644809877499938 Adapter cache time: 0.016634817700833082 Engine time: 0.09555272944271564 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-32/adapters_16_slots_16_rate_0.025-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-32/adapters_16_slots_16_rate_0.025-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [5 5 6]
Adapter prompts. [135, 33, 33, 135, 270, 33, 270, 33, 135, 135, 33, 135, 270, 270, 270, 270]
Prompts retrieved: 2460 . Total input tokens: 551925 . Total output tokens: 512668
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 0.39756515389308333,
    "estimated_duration": 3599.063516275376,
    "input_throughput": 60.3195800847293,
    "output_throughput": 48.17919973233743,
    "total_throughput": 108.49877981706673,
    "itl": 17.413617037350324,
    "ttft": 8881.2765376941,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072868,
    "arrivals": 813,
    "finished_requests": 811,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.39762116177007556. Arrivals time: 0.011405921541154385 Scheduler time: 0.12920641154050827 Scheduler overhead time: 0.09627927793189883 Adapter cache time: 0.016506644431501627 Engine time: 0.09553493931889534 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-8/adapters_16_slots_16_rate_0.025-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-8/adapters_16_slots_16_rate_0.025-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [5 5 6]
Adapter prompts. [66, 33, 33, 66, 270, 33, 270, 33, 66, 66, 33, 66, 270, 270, 270, 270]
Prompts retrieved: 2115 . Total input tokens: 465028 . Total output tokens: 442538
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 0.364666739013046,
    "estimated_duration": 3598.418417695971,
    "input_throughput": 50.69699485275738,
    "output_throughput": 44.342536491953176,
    "total_throughput": 95.03953134471055,
    "itl": 17.56827791316257,
    "ttft": 10151.650167096914,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 711,
    "finished_requests": 709,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.3647296531125903. Arrivals time: 0.010585822630673647 Scheduler time: 0.11809806572273374 Scheduler overhead time: 0.08859574003145099 Adapter cache time: 0.015296198893338442 Engine time: 0.08740574447438121 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-16/adapters_16_slots_16_rate_0.025-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-16/adapters_16_slots_16_rate_0.025-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [5 5 6]
Adapter prompts. [66, 33, 33, 66, 270, 33, 270, 33, 66, 66, 33, 66, 270, 270, 270, 270]
Prompts retrieved: 2115 . Total input tokens: 465028 . Total output tokens: 442538
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 0.3653623918071389,
    "estimated_duration": 3598.418417695971,
    "input_throughput": 50.69699485275738,
    "output_throughput": 44.342536491953176,
    "total_throughput": 95.03953134471055,
    "itl": 17.56829264939728,
    "ttft": 10151.688803666111,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 711,
    "finished_requests": 709,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.3654206022620201. Arrivals time: 0.010376990307122469 Scheduler time: 0.11895080236718059 Scheduler overhead time: 0.08819513907656074 Adapter cache time: 0.01531381020322442 Engine time: 0.08795611700043082 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-32/adapters_16_slots_16_rate_0.025-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-32/adapters_16_slots_16_rate_0.025-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [5 5 6]
Adapter prompts. [66, 33, 33, 66, 270, 33, 270, 33, 66, 66, 33, 66, 270, 270, 270, 270]
Prompts retrieved: 2115 . Total input tokens: 465028 . Total output tokens: 442538
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 0.36408615997061133,
    "estimated_duration": 3598.418417695971,
    "input_throughput": 50.69699485275738,
    "output_throughput": 44.342536491953176,
    "total_throughput": 95.03953134471055,
    "itl": 17.5682955004485,
    "ttft": 10151.661971581801,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 711,
    "finished_requests": 709,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.36414309591054916. Arrivals time: 0.010269631631672382 Scheduler time: 0.11819636076688766 Scheduler overhead time: 0.08834836445748806 Adapter cache time: 0.01525025861337781 Engine time: 0.08749389927834272 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-16/adapters_16_slots_16_rate_0.025-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-16/adapters_16_slots_16_rate_0.025-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [5 5 6]
Adapter prompts. [66, 33, 33, 66, 270, 33, 270, 33, 66, 66, 33, 66, 270, 270, 270, 270]
Prompts retrieved: 2115 . Total input tokens: 465028 . Total output tokens: 442538
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 0.36459642369300127,
    "estimated_duration": 3598.418417695971,
    "input_throughput": 50.69699485275738,
    "output_throughput": 44.342536491953176,
    "total_throughput": 95.03953134471055,
    "itl": 17.56827924916538,
    "ttft": 10151.679034157796,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 711,
    "finished_requests": 709,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.36465464998036623. Arrivals time: 0.010439622215926647 Scheduler time: 0.11775022791698575 Scheduler overhead time: 0.08858920400962234 Adapter cache time: 0.015219406224787235 Engine time: 0.0883479081094265 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-32/adapters_16_slots_16_rate_0.025-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-32/adapters_16_slots_16_rate_0.025-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [5 5 6]
Adapter prompts. [66, 33, 33, 66, 270, 33, 270, 33, 66, 66, 33, 66, 270, 270, 270, 270]
Prompts retrieved: 2115 . Total input tokens: 465028 . Total output tokens: 442538
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 0.36387094389647245,
    "estimated_duration": 3598.418417695971,
    "input_throughput": 50.69699485275738,
    "output_throughput": 44.342536491953176,
    "total_throughput": 95.03953134471055,
    "itl": 17.56829962465116,
    "ttft": 10151.664978353065,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05303479295223951,
    "arrivals": 711,
    "finished_requests": 709,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.36392952874302864. Arrivals time: 0.010392513126134872 Scheduler time: 0.11931661609560251 Scheduler overhead time: 0.08744141086935997 Adapter cache time: 0.015173946972936392 Engine time: 0.0871620262041688 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-16/adapters_16_slots_16_rate_0.025-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-16/adapters_16_slots_16_rate_0.025-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [5 5 6]
Adapter prompts. [66, 33, 33, 66, 270, 33, 270, 33, 66, 66, 33, 66, 270, 270, 270, 270]
Prompts retrieved: 2115 . Total input tokens: 465028 . Total output tokens: 442538
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 0.36657890770584345,
    "estimated_duration": 3598.418417695971,
    "input_throughput": 50.69699485275738,
    "output_throughput": 44.342536491953176,
    "total_throughput": 95.03953134471055,
    "itl": 17.568269760217415,
    "ttft": 10151.673287388197,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 711,
    "finished_requests": 709,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.3666371377184987. Arrivals time: 0.010505285579711199 Scheduler time: 0.12048992421478033 Scheduler overhead time: 0.0878101633861661 Adapter cache time: 0.01532697631046176 Engine time: 0.0881555201485753 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-32/adapters_16_slots_16_rate_0.025-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-32/adapters_16_slots_16_rate_0.025-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [5 5 6]
Adapter prompts. [66, 33, 33, 66, 270, 33, 270, 33, 66, 66, 33, 66, 270, 270, 270, 270]
Prompts retrieved: 2115 . Total input tokens: 465028 . Total output tokens: 442538
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 0.3672322407364845,
    "estimated_duration": 3598.418417695971,
    "input_throughput": 50.69699485275738,
    "output_throughput": 44.342536491953176,
    "total_throughput": 95.03953134471055,
    "itl": 17.568302545074086,
    "ttft": 10151.639465888793,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072868,
    "arrivals": 711,
    "finished_requests": 709,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.36728660389781. Arrivals time: 0.010424490552395582 Scheduler time: 0.11908438801765442 Scheduler overhead time: 0.08891998697072268 Adapter cache time: 0.015518851578235626 Engine time: 0.088436268735677 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-8/adapters_16_slots_16_rate_0.0125-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-8/adapters_16_slots_16_rate_0.0125-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [5 5 6]
Adapter prompts. [66, 33, 33, 66, 135, 33, 135, 33, 66, 66, 33, 66, 135, 135, 135, 135]
Prompts retrieved: 1305 . Total input tokens: 288295 . Total output tokens: 271182
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 0.25452054385095835,
    "estimated_duration": 3597.862889911071,
    "input_throughput": 31.74606801173103,
    "output_throughput": 26.84315743960636,
    "total_throughput": 58.58922545133739,
    "itl": 17.514219615390047,
    "ttft": 8186.276666212119,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 441,
    "finished_requests": 440,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.25459136813879013. Arrivals time: 0.007195961661636829 Scheduler time: 0.07924578385427594 Scheduler overhead time: 0.06241615302860737 Adapter cache time: 0.010733265429735184 Engine time: 0.06313521834090352 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-16/adapters_16_slots_16_rate_0.0125-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-16/adapters_16_slots_16_rate_0.0125-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [5 5 6]
Adapter prompts. [66, 33, 33, 66, 135, 33, 135, 33, 66, 66, 33, 66, 135, 135, 135, 135]
Prompts retrieved: 1305 . Total input tokens: 288295 . Total output tokens: 271182
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 0.25377108668908477,
    "estimated_duration": 3597.862889911071,
    "input_throughput": 31.74606801173103,
    "output_throughput": 26.84315743960636,
    "total_throughput": 58.58922545133739,
    "itl": 17.514232490174283,
    "ttft": 8186.293503953053,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 441,
    "finished_requests": 440,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.2538243909366429. Arrivals time: 0.007246963679790497 Scheduler time: 0.07890164665877819 Scheduler overhead time: 0.06277988431975245 Adapter cache time: 0.010755890514701605 Engine time: 0.06223975820466876 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-32/adapters_16_slots_16_rate_0.0125-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-32/adapters_16_slots_16_rate_0.0125-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [5 5 6]
Adapter prompts. [66, 33, 33, 66, 135, 33, 135, 33, 66, 66, 33, 66, 135, 135, 135, 135]
Prompts retrieved: 1305 . Total input tokens: 288295 . Total output tokens: 271182
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 0.25561144342646,
    "estimated_duration": 3597.862889911071,
    "input_throughput": 31.74606801173103,
    "output_throughput": 26.84315743960636,
    "total_throughput": 58.58922545133739,
    "itl": 17.51423248513511,
    "ttft": 8186.2931776935475,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 441,
    "finished_requests": 440,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.2556669660843909. Arrivals time: 0.007426590193063021 Scheduler time: 0.08088001841679215 Scheduler overhead time: 0.061792521737515926 Adapter cache time: 0.010642849374562502 Engine time: 0.06337265903130174 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-16/adapters_16_slots_16_rate_0.0125-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-16/adapters_16_slots_16_rate_0.0125-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [5 5 6]
Adapter prompts. [66, 33, 33, 66, 135, 33, 135, 33, 66, 66, 33, 66, 135, 135, 135, 135]
Prompts retrieved: 1305 . Total input tokens: 288295 . Total output tokens: 271182
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 0.25687358202412724,
    "estimated_duration": 3597.862889911071,
    "input_throughput": 31.74606801173103,
    "output_throughput": 26.84315743960636,
    "total_throughput": 58.58922545133739,
    "itl": 17.51421894692401,
    "ttft": 8186.284238753087,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 441,
    "finished_requests": 440,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.25694325426593423. Arrivals time: 0.007425008807331324 Scheduler time: 0.08161678118631244 Scheduler overhead time: 0.06283138412982225 Adapter cache time: 0.010733630508184433 Engine time: 0.06275760568678379 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-32/adapters_16_slots_16_rate_0.0125-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-32/adapters_16_slots_16_rate_0.0125-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [5 5 6]
Adapter prompts. [66, 33, 33, 66, 135, 33, 135, 33, 66, 66, 33, 66, 135, 135, 135, 135]
Prompts retrieved: 1305 . Total input tokens: 288295 . Total output tokens: 271182
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 0.25444478914141655,
    "estimated_duration": 3597.862889911071,
    "input_throughput": 31.74606801173103,
    "output_throughput": 26.84315743960636,
    "total_throughput": 58.58922545133739,
    "itl": 17.51423665335468,
    "ttft": 8186.296029253331,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.0530347929522395,
    "arrivals": 441,
    "finished_requests": 440,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.25450040213763714. Arrivals time: 0.007369686383754015 Scheduler time: 0.07869629841297865 Scheduler overhead time: 0.0628556115552783 Adapter cache time: 0.010801353957504034 Engine time: 0.06312854494899511 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-16/adapters_16_slots_16_rate_0.0125-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-16/adapters_16_slots_16_rate_0.0125-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [5 5 6]
Adapter prompts. [66, 33, 33, 66, 135, 33, 135, 33, 66, 66, 33, 66, 135, 135, 135, 135]
Prompts retrieved: 1305 . Total input tokens: 288295 . Total output tokens: 271182
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 0.25292428117245436,
    "estimated_duration": 3597.862889911071,
    "input_throughput": 31.74606801173103,
    "output_throughput": 26.84315743960636,
    "total_throughput": 58.58922545133739,
    "itl": 17.514215777552938,
    "ttft": 8186.272193993133,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 441,
    "finished_requests": 440,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.2529782042838633. Arrivals time: 0.007334992289543152 Scheduler time: 0.07851231098175049 Scheduler overhead time: 0.06251359637826681 Adapter cache time: 0.010696528479456902 Engine time: 0.062218303326517344 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-32/adapters_16_slots_16_rate_0.0125-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-32/adapters_16_slots_16_rate_0.0125-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [5 5 6]
Adapter prompts. [66, 33, 33, 66, 135, 33, 135, 33, 66, 66, 33, 66, 135, 135, 135, 135]
Prompts retrieved: 1305 . Total input tokens: 288295 . Total output tokens: 271182
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 0.2565263439901173,
    "estimated_duration": 3597.862889911071,
    "input_throughput": 31.74606801173103,
    "output_throughput": 26.84315743960636,
    "total_throughput": 58.58922545133739,
    "itl": 17.514237628795158,
    "ttft": 8186.299736281048,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072868,
    "arrivals": 441,
    "finished_requests": 440,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.2565919067710638. Arrivals time: 0.007461989764124155 Scheduler time: 0.07973798923194408 Scheduler overhead time: 0.06348736025393009 Adapter cache time: 0.010995622724294662 Engine time: 0.06281409924849868 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-8/adapters_32_slots_16_rate_3.2-1.6-0.8_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-8/adapters_32_slots_16_rate_3.2-1.6-0.8_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 8640, 8640, 17280, 8640, 34560, 17280, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 17280, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 656640 . Total input tokens: 146529371 . Total output tokens: 131331924
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 112.74449937604368,
    "estimated_duration": 3600.1169299974435,
    "input_throughput": 8639.801041135097,
    "output_throughput": 7656.066048949019,
    "total_throughput": 16295.867090084115,
    "itl": 110.35790543817471,
    "ttft": 1213813.1792322847,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 48,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.14690341170877208,
    "arrivals": 218245,
    "finished_requests": 125540,
    "scheduler_time": 166.72426339619506
}
#Debug simulation 
Total elapsed time: 112.74470514524728. Arrivals time: 0.6334424954839051 Scheduler time: 111.8853358803317 Scheduler overhead time: 0.08940556086599827 Adapter cache time: 0.015826338436454535 Engine time: 0.08997399359941483 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-16/adapters_32_slots_16_rate_3.2-1.6-0.8_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-16/adapters_32_slots_16_rate_3.2-1.6-0.8_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 8640, 8640, 17280, 8640, 34560, 17280, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 17280, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 656640 . Total input tokens: 146529371 . Total output tokens: 131331924
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 113.41586728673428,
    "estimated_duration": 3600.003046863073,
    "input_throughput": 8639.611021191171,
    "output_throughput": 7655.673520614181,
    "total_throughput": 16295.284541805351,
    "itl": 110.35792682681434,
    "ttft": 1213896.4650037254,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 48,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.15659746434539554,
    "arrivals": 218245,
    "finished_requests": 125532,
    "scheduler_time": 166.7184385198517
}
#Debug simulation 
Total elapsed time: 113.41606587264687. Arrivals time: 0.6328214528039098 Scheduler time: 112.55529282893986 Scheduler overhead time: 0.09035304840654135 Adapter cache time: 0.015557028818875551 Engine time: 0.09151075640693307 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-32/adapters_32_slots_16_rate_3.2-1.6-0.8_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-32/adapters_32_slots_16_rate_3.2-1.6-0.8_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 8640, 8640, 17280, 8640, 34560, 17280, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 17280, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 656640 . Total input tokens: 146529371 . Total output tokens: 131331924
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 113.6713563669473,
    "estimated_duration": 3600.003231355278,
    "input_throughput": 8639.61057843021,
    "output_throughput": 7655.673128277842,
    "total_throughput": 16295.283706708053,
    "itl": 110.35791385990876,
    "ttft": 1213896.5482979533,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 48,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.15688082456588737,
    "arrivals": 218245,
    "finished_requests": 125532,
    "scheduler_time": 166.71843969041467
}
#Debug simulation 
Total elapsed time: 113.671558144968. Arrivals time: 0.6444311132654548 Scheduler time: 112.79804604919627 Scheduler overhead time: 0.09090541722252965 Adapter cache time: 0.015485653188079596 Engine time: 0.09142927126958966 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-16/adapters_32_slots_16_rate_3.2-1.6-0.8_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-16/adapters_32_slots_16_rate_3.2-1.6-0.8_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 8640, 8640, 17280, 8640, 34560, 17280, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 17280, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 656640 . Total input tokens: 146529371 . Total output tokens: 131331924
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 114.69852842064574,
    "estimated_duration": 3600.1219408558595,
    "input_throughput": 8639.78901575916,
    "output_throughput": 7656.055392792471,
    "total_throughput": 16295.84440855163,
    "itl": 110.35789220293529,
    "ttft": 1213816.0647084548,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 48,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.1504685345687904,
    "arrivals": 218245,
    "finished_requests": 125540,
    "scheduler_time": 166.72442339796888
}
#Debug simulation 
Total elapsed time: 114.69873038074002. Arrivals time: 0.6291800034232438 Scheduler time: 113.839908298105 Scheduler overhead time: 0.0909652472473681 Adapter cache time: 0.015947211999446154 Engine time: 0.09082733793184161 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-32/adapters_32_slots_16_rate_3.2-1.6-0.8_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-32/adapters_32_slots_16_rate_3.2-1.6-0.8_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 8640, 8640, 17280, 8640, 34560, 17280, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 17280, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 656640 . Total input tokens: 146529371 . Total output tokens: 131331924
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 115.80981421424076,
    "estimated_duration": 3600.0050372341184,
    "input_throughput": 8639.606244522405,
    "output_throughput": 7655.669287944851,
    "total_throughput": 16295.275532467256,
    "itl": 110.35789110370932,
    "ttft": 1213897.4594215804,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 48,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.15876713136211026,
    "arrivals": 218245,
    "finished_requests": 125532,
    "scheduler_time": 166.71845930103933
}
#Debug simulation 
Total elapsed time: 115.81000458588824. Arrivals time: 0.6507502808235586 Scheduler time: 114.92407617531717 Scheduler overhead time: 0.09320583892986178 Adapter cache time: 0.016159418039023876 Engine time: 0.09370243642479181 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-16/adapters_32_slots_16_rate_3.2-1.6-0.8_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-16/adapters_32_slots_16_rate_3.2-1.6-0.8_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 8640, 8640, 17280, 8640, 34560, 17280, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 17280, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 656640 . Total input tokens: 146529371 . Total output tokens: 131331924
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 115.92628020467237,
    "estimated_duration": 3600.113070155333,
    "input_throughput": 8639.810304251903,
    "output_throughput": 7656.074257359578,
    "total_throughput": 16295.884561611481,
    "itl": 110.3573443769088,
    "ttft": 1213811.6752800578,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 48,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.14352241415530453,
    "arrivals": 218245,
    "finished_requests": 125540,
    "scheduler_time": 166.72396741105584
}
#Debug simulation 
Total elapsed time: 115.9264711770229. Arrivals time: 0.642515052575618 Scheduler time: 115.04696429055184 Scheduler overhead time: 0.09402528963983059 Adapter cache time: 0.016358557622879744 Engine time: 0.09525496885180473 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-32/adapters_32_slots_16_rate_3.2-1.6-0.8_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-32/adapters_32_slots_16_rate_3.2-1.6-0.8_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 8640, 8640, 17280, 8640, 34560, 17280, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 17280, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 656640 . Total input tokens: 146529371 . Total output tokens: 131331924
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 115.2057346641086,
    "estimated_duration": 3600.0051843855304,
    "input_throughput": 8639.605891375619,
    "output_throughput": 7655.668975016817,
    "total_throughput": 16295.274866392436,
    "itl": 110.35781218854176,
    "ttft": 1213897.194859128,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 48,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.16090494573116285,
    "arrivals": 218245,
    "finished_requests": 125532,
    "scheduler_time": 166.71836937111092
}
#Debug simulation 
Total elapsed time: 115.20592351909727. Arrivals time: 0.6567185530439019 Scheduler time: 114.314908107277 Scheduler overhead time: 0.09179319581016898 Adapter cache time: 0.01632925495505333 Engine time: 0.09398951521143317 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-8/adapters_32_slots_16_rate_3.2-1.6-0.4_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-8/adapters_32_slots_16_rate_3.2-1.6-0.4_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 4320, 4320, 17280, 4320, 34560, 17280, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 17280, 17280, 17280, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 17280, 4320, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 613440 . Total input tokens: 136853950 . Total output tokens: 122688465
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 97.2397768390365,
    "estimated_duration": 3600.061676383091,
    "input_throughput": 8616.658765459171,
    "output_throughput": 7640.159661829395,
    "total_throughput": 16256.818427288566,
    "itl": 109.17366652074942,
    "ttft": 1181887.9392604649,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 51,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.15608487494057033,
    "arrivals": 203816,
    "finished_requests": 125145,
    "scheduler_time": 165.3048374991323
}
#Debug simulation 
Total elapsed time: 97.23997129080817. Arrivals time: 0.5837773089297116 Scheduler time: 96.45068127801642 Scheduler overhead time: 0.08118786988779902 Adapter cache time: 0.013967284932732582 Engine time: 0.08087869687005877 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-16/adapters_32_slots_16_rate_3.2-1.6-0.4_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-16/adapters_32_slots_16_rate_3.2-1.6-0.4_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 4320, 4320, 17280, 4320, 34560, 17280, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 17280, 17280, 17280, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 17280, 4320, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 613440 . Total input tokens: 136853950 . Total output tokens: 122688465
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 102.87598908413202,
    "estimated_duration": 3600.07201924366,
    "input_throughput": 8616.634010148804,
    "output_throughput": 7640.137711961257,
    "total_throughput": 16256.771722110061,
    "itl": 109.17339021872256,
    "ttft": 1181893.1904822337,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 51,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.1663848058669828,
    "arrivals": 203816,
    "finished_requests": 125145,
    "scheduler_time": 165.30508220725204
}
#Debug simulation 
Total elapsed time: 102.87628079904243. Arrivals time: 0.6123725301586092 Scheduler time: 102.04556093597785 Scheduler overhead time: 0.08594045648351312 Adapter cache time: 0.015017872210592031 Engine time: 0.08709553815424442 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-32/adapters_32_slots_16_rate_3.2-1.6-0.4_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-32/adapters_32_slots_16_rate_3.2-1.6-0.4_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 4320, 4320, 17280, 4320, 34560, 17280, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 17280, 17280, 17280, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 17280, 4320, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 613440 . Total input tokens: 136853950 . Total output tokens: 122688465
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 102.25046921893954,
    "estimated_duration": 3600.069786343937,
    "input_throughput": 8616.639354511784,
    "output_throughput": 7640.142450664225,
    "total_throughput": 16256.781805176011,
    "itl": 109.17346375772021,
    "ttft": 1181891.619931526,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 51,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.16668587610125535,
    "arrivals": 203816,
    "finished_requests": 125145,
    "scheduler_time": 165.30504348523974
}
#Debug simulation 
Total elapsed time: 102.25070235878229. Arrivals time: 0.6021904260851443 Scheduler time: 101.4284114385955 Scheduler overhead time: 0.08703528251498938 Adapter cache time: 0.014826379250735044 Engine time: 0.087520488537848 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-16-16/adapters_32_slots_16_rate_3.2-1.6-0.4_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-16-16/adapters_32_slots_16_rate_3.2-1.6-0.4_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 4320, 4320, 17280, 4320, 34560, 17280, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 17280, 17280, 17280, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 17280, 4320, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 613440 . Total input tokens: 136853950 . Total output tokens: 122688465
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 102.21053477702662,
    "estimated_duration": 3600.0611489865714,
    "input_throughput": 8616.660027769909,
    "output_throughput": 7640.160781086387,
    "total_throughput": 16256.820808856295,
    "itl": 109.17337944559188,
    "ttft": 1181887.0852154666,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 51,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.15943868545349693,
    "arrivals": 203816,
    "finished_requests": 125145,
    "scheduler_time": 165.30465771957174
}
#Debug simulation 
Total elapsed time: 102.2107307757251. Arrivals time: 0.5843560816720128 Scheduler time: 101.4081589076668 Scheduler overhead time: 0.08574148174375296 Adapter cache time: 0.014668019954115152 Engine time: 0.0872197262942791 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-16-32/adapters_32_slots_16_rate_3.2-1.6-0.4_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-16-32/adapters_32_slots_16_rate_3.2-1.6-0.4_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 4320, 4320, 17280, 4320, 34560, 17280, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 17280, 17280, 17280, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 17280, 4320, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 613440 . Total input tokens: 136853950 . Total output tokens: 122688465
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 100.76964700268582,
    "estimated_duration": 3600.073325836744,
    "input_throughput": 8616.630882869611,
    "output_throughput": 7640.134939086876,
    "total_throughput": 16256.765821956487,
    "itl": 109.1732757646901,
    "ttft": 1181893.6166968197,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 51,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.16882369047030796,
    "arrivals": 203816,
    "finished_requests": 125145,
    "scheduler_time": 165.30505034011642
}
#Debug simulation 
Total elapsed time: 100.76983322994784. Arrivals time: 0.5857866909354925 Scheduler time: 99.96715163905174 Scheduler overhead time: 0.08567772665992379 Adapter cache time: 0.014782082755118608 Engine time: 0.08630317030474544 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_16-16-16/adapters_32_slots_16_rate_3.2-1.6-0.4_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_16-16-16/adapters_32_slots_16_rate_3.2-1.6-0.4_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 4320, 4320, 17280, 4320, 34560, 17280, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 17280, 17280, 17280, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 17280, 4320, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 613440 . Total input tokens: 136853950 . Total output tokens: 122688465
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 101.80816505802795,
    "estimated_duration": 3600.0546144117056,
    "input_throughput": 8616.675668146536,
    "output_throughput": 7640.174648987838,
    "total_throughput": 16256.850317134373,
    "itl": 109.17320384950098,
    "ttft": 1181884.1787345218,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 51,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.15249256504001107,
    "arrivals": 203816,
    "finished_requests": 125145,
    "scheduler_time": 165.3044674003209
}
#Debug simulation 
Total elapsed time: 101.80833720881492. Arrivals time: 0.611255697440356 Scheduler time: 100.98056267341599 Scheduler overhead time: 0.0847480776719749 Adapter cache time: 0.014890213031321764 Engine time: 0.08656305586919188 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_16-16-32/adapters_32_slots_16_rate_3.2-1.6-0.4_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_16-16-32/adapters_32_slots_16_rate_3.2-1.6-0.4_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 4320, 4320, 17280, 4320, 34560, 17280, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 17280, 17280, 17280, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 17280, 4320, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 613440 . Total input tokens: 136853950 . Total output tokens: 122688465
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 99.11333663389087,
    "estimated_duration": 3600.0745118312266,
    "input_throughput": 8616.628044240397,
    "output_throughput": 7640.13242215067,
    "total_throughput": 16256.760466391066,
    "itl": 109.17332332825815,
    "ttft": 1181894.1021244407,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 51,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.17096150483936054,
    "arrivals": 203816,
    "finished_requests": 125145,
    "scheduler_time": 165.30519322805725
}
#Debug simulation 
Total elapsed time: 99.11353490501642. Arrivals time: 0.5973903285339475 Scheduler time: 98.3042415655218 Scheduler overhead time: 0.08370515936985612 Adapter cache time: 0.01434685755521059 Engine time: 0.08376410370692611 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-8/adapters_32_slots_16_rate_3.2-1.6-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-8/adapters_32_slots_16_rate_3.2-1.6-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 1080, 1080, 17280, 1080, 34560, 17280, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 17280, 17280, 17280, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 17280, 1080, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 581040 . Total input tokens: 129651291 . Total output tokens: 116171458
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 158.620374399703,
    "estimated_duration": 3600.0190917451205,
    "input_throughput": 8725.875113282329,
    "output_throughput": 7676.970398121628,
    "total_throughput": 16402.845511403957,
    "itl": 110.26423576330079,
    "ttft": 1109521.0948321992,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 48,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.14690341170877208,
    "arrivals": 193289,
    "finished_requests": 126225,
    "scheduler_time": 162.89049757263695
}
#Debug simulation 
Total elapsed time: 158.62055641785264. Arrivals time: 0.6780232526361942 Scheduler time: 157.68187946733087 Scheduler overhead time: 0.10312179569154978 Adapter cache time: 0.018268595915287733 Engine time: 0.10479224706068635 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-16/adapters_32_slots_16_rate_3.2-1.6-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-16/adapters_32_slots_16_rate_3.2-1.6-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 1080, 1080, 17280, 1080, 34560, 17280, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 17280, 17280, 17280, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 17280, 1080, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 581040 . Total input tokens: 129651291 . Total output tokens: 116171458
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 158.61212805332616,
    "estimated_duration": 3600.0571754093603,
    "input_throughput": 8721.774535825158,
    "output_throughput": 7675.100603605863,
    "total_throughput": 16396.87513943102,
    "itl": 110.28134626287431,
    "ttft": 1109613.73643126,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 47,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.15442460468737407,
    "arrivals": 193289,
    "finished_requests": 126198,
    "scheduler_time": 162.85865252805436
}
#Debug simulation 
Total elapsed time: 158.61242016498. Arrivals time: 0.6649657092057168 Scheduler time: 157.68668280774727 Scheduler overhead time: 0.10492790723219514 Adapter cache time: 0.018201282247900963 Engine time: 0.10358877433463931 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-32/adapters_32_slots_16_rate_3.2-1.6-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-32/adapters_32_slots_16_rate_3.2-1.6-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 1080, 1080, 17280, 1080, 34560, 17280, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 17280, 17280, 17280, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 17280, 1080, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 581040 . Total input tokens: 129651291 . Total output tokens: 116171458
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 157.36236150981858,
    "estimated_duration": 3600.057262605384,
    "input_throughput": 8721.774324577389,
    "output_throughput": 7675.100417709305,
    "total_throughput": 16396.874742286695,
    "itl": 110.28135153497982,
    "ttft": 1109613.768426075,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 47,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.15451180070638654,
    "arrivals": 193289,
    "finished_requests": 126198,
    "scheduler_time": 162.85865252805436
}
#Debug simulation 
Total elapsed time: 157.36253774398938. Arrivals time: 0.6685711680911481 Scheduler time: 156.43664084468037 Scheduler overhead time: 0.1027336772531271 Adapter cache time: 0.01778328325599432 Engine time: 0.10277914302423596 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-16-16/adapters_32_slots_16_rate_3.2-1.6-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-16-16/adapters_32_slots_16_rate_3.2-1.6-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 1080, 1080, 17280, 1080, 34560, 17280, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 17280, 17280, 17280, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 17280, 1080, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 581040 . Total input tokens: 129651291 . Total output tokens: 116171458
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 155.56049698079005,
    "estimated_duration": 3600.052477638606,
    "input_throughput": 8721.786194793352,
    "output_throughput": 7675.353393216238,
    "total_throughput": 16397.13958800959,
    "itl": 110.28238654559004,
    "ttft": 1109600.810777461,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 47,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.14788707959232855,
    "arrivals": 193289,
    "finished_requests": 126199,
    "scheduler_time": 162.85839147220128
}
#Debug simulation 
Total elapsed time: 155.5606735139154. Arrivals time: 0.6751487297005951 Scheduler time: 154.63060725061223 Scheduler overhead time: 0.10177568020299077 Adapter cache time: 0.017356507945805788 Engine time: 0.10275031067430973 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-16-32/adapters_32_slots_16_rate_3.2-1.6-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-16-32/adapters_32_slots_16_rate_3.2-1.6-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 1080, 1080, 17280, 1080, 34560, 17280, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 17280, 17280, 17280, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 17280, 1080, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 581040 . Total input tokens: 129651291 . Total output tokens: 116171458
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 149.6850786381401,
    "estimated_duration": 3600.055760656755,
    "input_throughput": 8721.777963314637,
    "output_throughput": 7675.103619772639,
    "total_throughput": 16396.881583087277,
    "itl": 110.28128192145351,
    "ttft": 1109612.1013283532,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 47,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.1565238612890243,
    "arrivals": 193289,
    "finished_requests": 126198,
    "scheduler_time": 162.85853983057618
}
#Debug simulation 
Total elapsed time: 149.68525128019974. Arrivals time: 0.6734835295937955 Scheduler time: 148.76309777935967 Scheduler overhead time: 0.09895441774278879 Adapter cache time: 0.01745624467730522 Engine time: 0.09958732035011053 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_16-16-16/adapters_32_slots_16_rate_3.2-1.6-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_16-16-16/adapters_32_slots_16_rate_3.2-1.6-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 1080, 1080, 17280, 1080, 34560, 17280, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 17280, 17280, 17280, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 17280, 1080, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 581040 . Total input tokens: 129651291 . Total output tokens: 116171458
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 155.2021625279449,
    "estimated_duration": 3600.042887071673,
    "input_throughput": 8721.80915198494,
    "output_throughput": 7675.1310655844145,
    "total_throughput": 16396.940217569354,
    "itl": 110.28218375573474,
    "ttft": 1109614.5357821488,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 47,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.14053236386040235,
    "arrivals": 193289,
    "finished_requests": 126198,
    "scheduler_time": 162.85805635401775
}
#Debug simulation 
Total elapsed time: 155.20233992300928. Arrivals time: 0.6663013459183276 Scheduler time: 154.28103719372302 Scheduler overhead time: 0.10122162289917469 Adapter cache time: 0.018084297887980938 Engine time: 0.10239559039473534 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_16-16-32/adapters_32_slots_16_rate_3.2-1.6-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_16-16-32/adapters_32_slots_16_rate_3.2-1.6-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 1080, 1080, 17280, 1080, 34560, 17280, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 17280, 17280, 17280, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 17280, 1080, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 581040 . Total input tokens: 129651291 . Total output tokens: 116171458
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 156.77225185884163,
    "estimated_duration": 3600.0582900931504,
    "input_throughput": 8721.771835307578,
    "output_throughput": 7675.098227169277,
    "total_throughput": 16396.870062476857,
    "itl": 110.28119955590203,
    "ttft": 1109612.8734966796,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 47,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.15878742944449176,
    "arrivals": 193289,
    "finished_requests": 126198,
    "scheduler_time": 162.85860562165203
}
#Debug simulation 
Total elapsed time: 156.77243247069418. Arrivals time: 0.6843600980937481 Scheduler time: 155.8282413603738 Scheduler overhead time: 0.10333545925095677 Adapter cache time: 0.018837820272892714 Engine time: 0.10338070895522833 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-8/adapters_32_slots_16_rate_3.2-1.6-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-8/adapters_32_slots_16_rate_3.2-1.6-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 540, 540, 17280, 540, 34560, 17280, 540, 540, 540, 34560, 34560, 540, 540, 17280, 17280, 17280, 34560, 34560, 540, 34560, 34560, 34560, 34560, 17280, 540, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 575640 . Total input tokens: 128448450 . Total output tokens: 115096958
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 131.56467810366303,
    "estimated_duration": 3600.0223268482628,
    "input_throughput": 8732.860284098204,
    "output_throughput": 7694.267558682146,
    "total_throughput": 16427.12784278035,
    "itl": 110.52081737902526,
    "ttft": 1096042.3310339253,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 42,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.12854048524517558,
    "arrivals": 191429,
    "finished_requests": 126911,
    "scheduler_time": 162.47964224900136
}
#Debug simulation 
Total elapsed time: 131.56486378097907. Arrivals time: 0.6588751613162458 Scheduler time: 130.6657810532488 Scheduler overhead time: 0.09626006195321679 Adapter cache time: 0.016513066831976175 Engine time: 0.09554331144317985 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-16/adapters_32_slots_16_rate_3.2-1.6-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-16/adapters_32_slots_16_rate_3.2-1.6-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 540, 540, 17280, 540, 34560, 17280, 540, 540, 540, 34560, 34560, 540, 540, 17280, 17280, 17280, 34560, 34560, 540, 34560, 34560, 34560, 34560, 17280, 540, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 575640 . Total input tokens: 128448450 . Total output tokens: 115096958
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 132.34275780897588,
    "estimated_duration": 3600.009403754806,
    "input_throughput": 8732.89163278565,
    "output_throughput": 7694.295179092981,
    "total_throughput": 16427.18681187863,
    "itl": 110.5222945368934,
    "ttft": 1096037.7223064017,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 42,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.1378399719391018,
    "arrivals": 191429,
    "finished_requests": 126911,
    "scheduler_time": 162.47808077059864
}
#Debug simulation 
Total elapsed time: 132.34303978504613. Arrivals time: 0.6718116393312812 Scheduler time: 131.4252711152658 Scheduler overhead time: 0.09703926183283329 Adapter cache time: 0.017085269559174776 Engine time: 0.09739113319665194 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-32/adapters_32_slots_16_rate_3.2-1.6-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-32/adapters_32_slots_16_rate_3.2-1.6-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 540, 540, 17280, 540, 34560, 17280, 540, 540, 540, 34560, 34560, 540, 540, 17280, 17280, 17280, 34560, 34560, 540, 34560, 34560, 34560, 34560, 17280, 540, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 575640 . Total input tokens: 128448450 . Total output tokens: 115096958
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 130.68628915492445,
    "estimated_duration": 3600.0095089993547,
    "input_throughput": 8732.891377483758,
    "output_throughput": 7694.294954153957,
    "total_throughput": 16427.186331637713,
    "itl": 110.5222984078309,
    "ttft": 1096037.76246438,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 42,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.13794521648436786,
    "arrivals": 191429,
    "finished_requests": 126911,
    "scheduler_time": 162.47808077059864
}
#Debug simulation 
Total elapsed time: 130.68646928993985. Arrivals time: 0.6543362345546484 Scheduler time: 129.78952062875032 Scheduler overhead time: 0.09580561192706227 Adapter cache time: 0.01724560046568513 Engine time: 0.0971925426274538 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-16-16/adapters_32_slots_16_rate_3.2-1.6-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-16-16/adapters_32_slots_16_rate_3.2-1.6-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 540, 540, 17280, 540, 34560, 17280, 540, 540, 540, 34560, 34560, 540, 540, 17280, 17280, 17280, 34560, 34560, 540, 34560, 34560, 34560, 34560, 17280, 540, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 575640 . Total input tokens: 128448450 . Total output tokens: 115096958
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 131.43005342409015,
    "estimated_duration": 3600.023533468618,
    "input_throughput": 8732.857357104289,
    "output_throughput": 7694.264979793488,
    "total_throughput": 16427.122336897777,
    "itl": 110.52067264070223,
    "ttft": 1096043.0256984169,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 42,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.13171104216249663,
    "arrivals": 191429,
    "finished_requests": 126911,
    "scheduler_time": 162.47967908404954
}
#Debug simulation 
Total elapsed time: 131.4302513836883. Arrivals time: 0.6635170811787248 Scheduler time: 130.52683906070888 Scheduler overhead time: 0.09416799061000347 Adapter cache time: 0.01702652918174863 Engine time: 0.09731320152059197 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-16-32/adapters_32_slots_16_rate_3.2-1.6-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-16-32/adapters_32_slots_16_rate_3.2-1.6-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 540, 540, 17280, 540, 34560, 17280, 540, 540, 540, 34560, 34560, 540, 540, 17280, 17280, 17280, 34560, 34560, 540, 34560, 34560, 34560, 34560, 17280, 540, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 575640 . Total input tokens: 128448450 . Total output tokens: 115096958
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 127.06948527460918,
    "estimated_duration": 3600.0087241528927,
    "input_throughput": 8732.893281362172,
    "output_throughput": 7694.296631605495,
    "total_throughput": 16427.189912967668,
    "itl": 110.52222757360107,
    "ttft": 1096036.5806601678,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 42,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.13983152328059073,
    "arrivals": 191429,
    "finished_requests": 126911,
    "scheduler_time": 162.47807065447284
}
#Debug simulation 
Total elapsed time: 127.06966477585956. Arrivals time: 0.6387099176645279 Scheduler time: 126.19271105434746 Scheduler overhead time: 0.09465737082064152 Adapter cache time: 0.01659573009237647 Engine time: 0.09410240547731519 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_16-16-16/adapters_32_slots_16_rate_3.2-1.6-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_16-16-16/adapters_32_slots_16_rate_3.2-1.6-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 540, 540, 17280, 540, 34560, 17280, 540, 540, 540, 34560, 34560, 540, 540, 17280, 17280, 17280, 34560, 34560, 540, 34560, 34560, 34560, 34560, 17280, 540, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 575640 . Total input tokens: 128448450 . Total output tokens: 115096958
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 131.29881969373673,
    "estimated_duration": 3600.0193749416358,
    "input_throughput": 8732.867444778596,
    "output_throughput": 7694.273867748023,
    "total_throughput": 16427.14131252662,
    "itl": 110.52085745599192,
    "ttft": 1096041.6868262996,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 42,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.12558211238589145,
    "arrivals": 191429,
    "finished_requests": 126911,
    "scheduler_time": 162.47964871523183
}
#Debug simulation 
Total elapsed time: 131.2989970371127. Arrivals time: 0.6731895082630217 Scheduler time: 130.3841485492885 Scheduler overhead time: 0.09604460326954722 Adapter cache time: 0.016921330709010363 Engine time: 0.09664634149521589 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_16-16-32/adapters_32_slots_16_rate_3.2-1.6-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_16-16-32/adapters_32_slots_16_rate_3.2-1.6-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 540, 540, 17280, 540, 34560, 17280, 540, 540, 540, 34560, 34560, 540, 540, 17280, 17280, 17280, 34560, 34560, 540, 34560, 34560, 34560, 34560, 17280, 540, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 575640 . Total input tokens: 128448450 . Total output tokens: 115096958
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 126.93445888115093,
    "estimated_duration": 3600.0094501756985,
    "input_throughput": 8732.891520177995,
    "output_throughput": 7694.295079877672,
    "total_throughput": 16427.186600055666,
    "itl": 110.52214900852036,
    "ttft": 1096036.3821975575,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 42,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.14171783007681363,
    "arrivals": 191429,
    "finished_requests": 126911,
    "scheduler_time": 162.47801079486624
}
#Debug simulation 
Total elapsed time: 126.93464954011142. Arrivals time: 0.649790947791189 Scheduler time: 126.05148841068149 Scheduler overhead time: 0.09180162381380796 Adapter cache time: 0.016525205224752426 Engine time: 0.0930731170810759 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-8/adapters_32_slots_16_rate_3.2-1.6-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-8/adapters_32_slots_16_rate_3.2-1.6-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 270, 270, 17280, 270, 34560, 17280, 270, 270, 270, 34560, 34560, 270, 270, 17280, 17280, 17280, 34560, 34560, 270, 34560, 34560, 34560, 34560, 17280, 270, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 572940 . Total input tokens: 127851067 . Total output tokens: 114578169
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 155.30647582327947,
    "estimated_duration": 3600.102884757208,
    "input_throughput": 8681.781882494135,
    "output_throughput": 7714.10231568227,
    "total_throughput": 16395.884198176405,
    "itl": 110.97945516217456,
    "ttft": 1104524.20543081,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 44,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.13466146073304108,
    "arrivals": 190474,
    "finished_requests": 126532,
    "scheduler_time": 162.40886214130504
}
#Debug simulation 
Total elapsed time: 155.30666538095102. Arrivals time: 0.6737642358057201 Scheduler time: 154.37828311603516 Scheduler overhead time: 0.09996528644114733 Adapter cache time: 0.018006726168096066 Engine time: 0.10305769881233573 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-16/adapters_32_slots_16_rate_3.2-1.6-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-16/adapters_32_slots_16_rate_3.2-1.6-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 270, 270, 17280, 270, 34560, 17280, 270, 270, 270, 34560, 34560, 270, 270, 17280, 17280, 17280, 34560, 34560, 270, 34560, 34560, 34560, 34560, 17280, 270, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 572940 . Total input tokens: 127851067 . Total output tokens: 114578169
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 156.44956097379327,
    "estimated_duration": 3600.093747015548,
    "input_throughput": 8681.803918553627,
    "output_throughput": 7714.121895581865,
    "total_throughput": 16395.925814135495,
    "itl": 110.97950532330857,
    "ttft": 1104525.1612143123,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 44,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.14422866784734653,
    "arrivals": 190474,
    "finished_requests": 126532,
    "scheduler_time": 162.4071591777782
}
#Debug simulation 
Total elapsed time: 156.4498474788852. Arrivals time: 0.6771111041307449 Scheduler time: 155.5140428985469 Scheduler overhead time: 0.1029527299106121 Adapter cache time: 0.018462849780917168 Engine time: 0.10349351819604635 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-32/adapters_32_slots_16_rate_3.2-1.6-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-32/adapters_32_slots_16_rate_3.2-1.6-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 270, 270, 17280, 270, 34560, 17280, 270, 270, 270, 34560, 34560, 270, 270, 17280, 17280, 17280, 34560, 34560, 270, 34560, 34560, 34560, 34560, 17280, 270, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 572940 . Total input tokens: 127851067 . Total output tokens: 114578169
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 157.30253343097866,
    "estimated_duration": 3600.093441527444,
    "input_throughput": 8681.804655253345,
    "output_throughput": 7714.122550168339,
    "total_throughput": 16395.927205421685,
    "itl": 110.9795300813019,
    "ttft": 1104524.7750563982,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 44,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.14436950167641044,
    "arrivals": 190474,
    "finished_requests": 126532,
    "scheduler_time": 162.4071130101628
}
#Debug simulation 
Total elapsed time: 157.30272065289319. Arrivals time: 0.6837869989685714 Scheduler time: 156.36042604967952 Scheduler overhead time: 0.10352517431601882 Adapter cache time: 0.018527433276176453 Engine time: 0.10315758269280195 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-16-16/adapters_32_slots_16_rate_3.2-1.6-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-16-16/adapters_32_slots_16_rate_3.2-1.6-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 270, 270, 17280, 270, 34560, 17280, 270, 270, 270, 34560, 34560, 270, 270, 17280, 17280, 17280, 34560, 34560, 270, 34560, 34560, 34560, 34560, 17280, 270, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 572940 . Total input tokens: 127851067 . Total output tokens: 114578169
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 152.62012031301856,
    "estimated_duration": 3600.1104721922084,
    "input_throughput": 8681.763585151253,
    "output_throughput": 7714.086057778421,
    "total_throughput": 16395.849642929676,
    "itl": 110.97959812286936,
    "ttft": 1104527.0521549128,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 44,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.1385083333891817,
    "arrivals": 190474,
    "finished_requests": 126532,
    "scheduler_time": 162.40924310920357
}
#Debug simulation 
Total elapsed time: 152.62029943196103. Arrivals time: 0.6612712000496686 Scheduler time: 151.7054560892284 Scheduler overhead time: 0.10157010331749916 Adapter cache time: 0.01839329767972231 Engine time: 0.1006956584751606 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-16-32/adapters_32_slots_16_rate_3.2-1.6-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-16-32/adapters_32_slots_16_rate_3.2-1.6-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 270, 270, 17280, 270, 34560, 17280, 270, 270, 270, 34560, 34560, 270, 270, 17280, 17280, 17280, 34560, 34560, 270, 34560, 34560, 34560, 34560, 17280, 270, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 572940 . Total input tokens: 127851067 . Total output tokens: 114578169
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 148.77004769816995,
    "estimated_duration": 3600.0947187974,
    "input_throughput": 8681.801575054318,
    "output_throughput": 7714.1198132911895,
    "total_throughput": 16395.92138834551,
    "itl": 110.97948735206754,
    "ttft": 1104525.2639839607,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 44,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.14613005468621845,
    "arrivals": 190474,
    "finished_requests": 126532,
    "scheduler_time": 162.40713400328414
}
#Debug simulation 
Total elapsed time: 148.77021572506055. Arrivals time: 0.655144146643579 Scheduler time: 147.86817721603438 Scheduler overhead time: 0.09765557944774628 Adapter cache time: 0.017869543749839067 Engine time: 0.09854898368939757 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_16-16-16/adapters_32_slots_16_rate_3.2-1.6-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_16-16-16/adapters_32_slots_16_rate_3.2-1.6-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 270, 270, 17280, 270, 34560, 17280, 270, 270, 270, 34560, 34560, 270, 270, 17280, 17280, 17280, 34560, 34560, 270, 34560, 34560, 34560, 34560, 17280, 270, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 572940 . Total input tokens: 127851067 . Total output tokens: 114578169
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 153.05032080505043,
    "estimated_duration": 3600.102780405576,
    "input_throughput": 8681.78213414198,
    "output_throughput": 7714.10253928121,
    "total_throughput": 16395.884673423192,
    "itl": 110.97963348450602,
    "ttft": 1104524.8697568257,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 44,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.1315622129756958,
    "arrivals": 190474,
    "finished_requests": 126532,
    "scheduler_time": 162.40895591858478
}
#Debug simulation 
Total elapsed time: 153.05050683300942. Arrivals time: 0.6689503719098866 Scheduler time: 152.129879148677 Scheduler overhead time: 0.09918669750913978 Adapter cache time: 0.018420626875013113 Engine time: 0.1011013425886631 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_16-16-32/adapters_32_slots_16_rate_3.2-1.6-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_16-16-32/adapters_32_slots_16_rate_3.2-1.6-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 270, 270, 17280, 270, 34560, 17280, 270, 270, 270, 34560, 34560, 270, 270, 17280, 17280, 17280, 34560, 34560, 270, 34560, 34560, 34560, 34560, 17280, 270, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 572940 . Total input tokens: 127851067 . Total output tokens: 114578169
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 156.90300033520907,
    "estimated_duration": 3600.0963139102523,
    "input_throughput": 8681.797728364656,
    "output_throughput": 7714.116395357172,
    "total_throughput": 16395.91412372183,
    "itl": 110.9793714399241,
    "ttft": 1104525.5861228458,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 44,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.14826786905527106,
    "arrivals": 190474,
    "finished_requests": 126532,
    "scheduler_time": 162.40719078462055
}
#Debug simulation 
Total elapsed time: 156.9031891231425. Arrivals time: 0.6453198087401688 Scheduler time: 155.99989742133766 Scheduler overhead time: 0.10290118446573615 Adapter cache time: 0.019021756947040558 Engine time: 0.10228044725954533 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-8/adapters_32_slots_16_rate_3.2-1.6-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-8/adapters_32_slots_16_rate_3.2-1.6-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 135, 135, 17280, 135, 34560, 17280, 135, 135, 135, 34560, 34560, 135, 135, 17280, 17280, 17280, 34560, 34560, 135, 34560, 34560, 34560, 34560, 17280, 135, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 571590 . Total input tokens: 127539524 . Total output tokens: 114313627
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 131.41379453008994,
    "estimated_duration": 3600.036225466731,
    "input_throughput": 8773.886989402434,
    "output_throughput": 7726.877247295928,
    "total_throughput": 16500.764236698364,
    "itl": 110.00554977898464,
    "ttft": 1087041.181590044,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 44,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.13466146073304108,
    "arrivals": 190041,
    "finished_requests": 127124,
    "scheduler_time": 163.02378837648996
}
#Debug simulation 
Total elapsed time: 131.41397829912603. Arrivals time: 0.6403455664403737 Scheduler time: 130.53333626314998 Scheduler overhead time: 0.09510574070736766 Adapter cache time: 0.017115467693656683 Engine time: 0.0959417256526649 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-16/adapters_32_slots_16_rate_3.2-1.6-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-16/adapters_32_slots_16_rate_3.2-1.6-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 135, 135, 17280, 135, 34560, 17280, 135, 135, 135, 34560, 34560, 135, 135, 17280, 17280, 17280, 34560, 34560, 135, 34560, 34560, 34560, 34560, 17280, 135, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 571590 . Total input tokens: 127539524 . Total output tokens: 114313627
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 133.52116791764274,
    "estimated_duration": 3600.0459263922276,
    "input_throughput": 8773.863346697386,
    "output_throughput": 7726.856425933638,
    "total_throughput": 16500.719772631022,
    "itl": 110.00577108601279,
    "ttft": 1087043.1851376432,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 44,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.14422866784734653,
    "arrivals": 190041,
    "finished_requests": 127124,
    "scheduler_time": 163.02465044788593
}
#Debug simulation 
Total elapsed time: 133.52147108782083. Arrivals time: 0.6560446824878454 Scheduler time: 132.6223485134542 Scheduler overhead time: 0.09627505205571651 Adapter cache time: 0.017099592834711075 Engine time: 0.09777748258784413 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-32/adapters_32_slots_16_rate_3.2-1.6-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-32/adapters_32_slots_16_rate_3.2-1.6-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 135, 135, 17280, 135, 34560, 17280, 135, 135, 135, 34560, 34560, 135, 135, 17280, 17280, 17280, 34560, 34560, 135, 34560, 34560, 34560, 34560, 17280, 135, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 571590 . Total input tokens: 127539524 . Total output tokens: 114313627
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 134.00246966909617,
    "estimated_duration": 3600.046167863577,
    "input_throughput": 8773.86275819476,
    "output_throughput": 7726.855907658493,
    "total_throughput": 16500.718665853252,
    "itl": 110.00578617588741,
    "ttft": 1087043.244606721,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 44,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.14436950167641044,
    "arrivals": 190041,
    "finished_requests": 127124,
    "scheduler_time": 163.02465104682386
}
#Debug simulation 
Total elapsed time: 134.0026427283883. Arrivals time: 0.6462814998812973 Scheduler time: 133.1129544004798 Scheduler overhead time: 0.09554843278601766 Adapter cache time: 0.016931981779634953 Engine time: 0.0982788223773241 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-16/adapters_32_slots_16_rate_3.2-1.6-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-16/adapters_32_slots_16_rate_3.2-1.6-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 135, 135, 17280, 135, 34560, 17280, 135, 135, 135, 34560, 34560, 135, 135, 17280, 17280, 17280, 34560, 34560, 135, 34560, 34560, 34560, 34560, 17280, 135, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 571590 . Total input tokens: 127539524 . Total output tokens: 114313627
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 134.02848134702072,
    "estimated_duration": 3600.0372007079022,
    "input_throughput": 8773.884612578155,
    "output_throughput": 7726.875154103998,
    "total_throughput": 16500.759766682153,
    "itl": 110.00584703182136,
    "ttft": 1087038.9123402429,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 44,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.13809973807074136,
    "arrivals": 190041,
    "finished_requests": 127124,
    "scheduler_time": 163.02425862537788
}
#Debug simulation 
Total elapsed time: 134.02867357060313. Arrivals time: 0.6755600017495453 Scheduler time: 133.11015415284783 Scheduler overhead time: 0.09516788413748145 Adapter cache time: 0.017570521216839552 Engine time: 0.09727316442877054 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-32/adapters_32_slots_16_rate_3.2-1.6-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-32/adapters_32_slots_16_rate_3.2-1.6-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 135, 135, 17280, 135, 34560, 17280, 135, 135, 135, 34560, 34560, 135, 135, 17280, 17280, 17280, 34560, 34560, 135, 34560, 34560, 34560, 34560, 17280, 135, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 571590 . Total input tokens: 127539524 . Total output tokens: 114313627
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 133.30408780416474,
    "estimated_duration": 3600.0457766292006,
    "input_throughput": 8773.863711692837,
    "output_throughput": 7726.856747373275,
    "total_throughput": 16500.720459066113,
    "itl": 110.00572332973297,
    "ttft": 1087042.7648199343,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 44,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.14625580847263334,
    "arrivals": 190041,
    "finished_requests": 127124,
    "scheduler_time": 163.02457435442122
}
#Debug simulation 
Total elapsed time: 133.30426540179178. Arrivals time: 0.6569001814350486 Scheduler time: 132.40045598847792 Scheduler overhead time: 0.09808556456118822 Adapter cache time: 0.01776221999898553 Engine time: 0.0989741082303226 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-16/adapters_32_slots_16_rate_3.2-1.6-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-16/adapters_32_slots_16_rate_3.2-1.6-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 135, 135, 17280, 135, 34560, 17280, 135, 135, 135, 34560, 34560, 135, 135, 17280, 17280, 17280, 34560, 34560, 135, 34560, 34560, 34560, 34560, 17280, 135, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 571590 . Total input tokens: 127539524 . Total output tokens: 114313627
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 132.75109542300925,
    "estimated_duration": 3600.033044904643,
    "input_throughput": 8773.894740968039,
    "output_throughput": 7726.884073847943,
    "total_throughput": 16500.77881481598,
    "itl": 110.00552241123258,
    "ttft": 1087040.034591764,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 44,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.1315622129756958,
    "arrivals": 190041,
    "finished_requests": 127124,
    "scheduler_time": 163.0236980789619
}
#Debug simulation 
Total elapsed time: 132.75128369312733. Arrivals time: 0.6608343841508031 Scheduler time: 131.84830286772922 Scheduler overhead time: 0.09526308253407478 Adapter cache time: 0.017307871021330357 Engine time: 0.09715251252055168 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-32/adapters_32_slots_16_rate_3.2-1.6-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-32/adapters_32_slots_16_rate_3.2-1.6-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 135, 135, 17280, 135, 34560, 17280, 135, 135, 135, 34560, 34560, 135, 135, 17280, 17280, 17280, 34560, 34560, 135, 34560, 34560, 34560, 34560, 17280, 135, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 571590 . Total input tokens: 127539524 . Total output tokens: 114313627
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 129.39664507005364,
    "estimated_duration": 3600.0451533513938,
    "input_throughput": 8773.86523071671,
    "output_throughput": 7726.858085128253,
    "total_throughput": 16500.723315844964,
    "itl": 110.00546329252245,
    "ttft": 1087041.345258478,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 44,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.14826786905527106,
    "arrivals": 190041,
    "finished_requests": 127124,
    "scheduler_time": 163.02445394313855
}
#Debug simulation 
Total elapsed time: 129.39683071384206. Arrivals time: 0.65149807324633 Scheduler time: 128.50751576106995 Scheduler overhead time: 0.09602713631466031 Adapter cache time: 0.016949205193668604 Engine time: 0.0927841467782855 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-8/adapters_32_slots_16_rate_3.2-1.6-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-8/adapters_32_slots_16_rate_3.2-1.6-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 66, 66, 17280, 66, 34560, 17280, 66, 66, 66, 34560, 34560, 66, 66, 17280, 17280, 17280, 34560, 34560, 66, 34560, 34560, 34560, 34560, 17280, 66, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 570900 . Total input tokens: 127384163 . Total output tokens: 114175699
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 130.25964116072282,
    "estimated_duration": 3600.008555398031,
    "input_throughput": 8830.69123608933,
    "output_throughput": 7756.46017788774,
    "total_throughput": 16587.15141397707,
    "itl": 109.32831141953969,
    "ttft": 1084076.107289567,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 51,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.15608487494057033,
    "arrivals": 189807,
    "finished_requests": 127881,
    "scheduler_time": 163.90678910217613
}
#Debug simulation 
Total elapsed time: 130.259833722841. Arrivals time: 0.6406443100422621 Scheduler time: 129.37978407926857 Scheduler overhead time: 0.09590044245123863 Adapter cache time: 0.016346946358680725 Engine time: 0.09516795817762613 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-16/adapters_32_slots_16_rate_3.2-1.6-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-16/adapters_32_slots_16_rate_3.2-1.6-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 66, 66, 17280, 66, 34560, 17280, 66, 66, 66, 34560, 34560, 66, 66, 17280, 17280, 17280, 34560, 34560, 66, 34560, 34560, 34560, 34560, 17280, 66, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 570900 . Total input tokens: 127384163 . Total output tokens: 114175699
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 124.65681430278346,
    "estimated_duration": 3600.0260903037497,
    "input_throughput": 8815.61638830297,
    "output_throughput": 7743.592768697931,
    "total_throughput": 16559.2091570009,
    "itl": 109.49267731052923,
    "ttft": 1085865.8502040515,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 59,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19316537545528265,
    "arrivals": 189807,
    "finished_requests": 127671,
    "scheduler_time": 163.64179702112617
}
#Debug simulation 
Total elapsed time: 124.65711347199976. Arrivals time: 0.636402128264308 Scheduler time: 123.79058493860066 Scheduler overhead time: 0.09140099864453077 Adapter cache time: 0.015800548251718283 Engine time: 0.09043245716020465 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-32/adapters_32_slots_16_rate_3.2-1.6-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-32/adapters_32_slots_16_rate_3.2-1.6-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 66, 66, 17280, 66, 34560, 17280, 66, 66, 66, 34560, 34560, 66, 66, 17280, 17280, 17280, 34560, 34560, 66, 34560, 34560, 34560, 34560, 17280, 66, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 570900 . Total input tokens: 127384163 . Total output tokens: 114175699
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 131.20138904592022,
    "estimated_duration": 3600.0272553205627,
    "input_throughput": 8815.613535451981,
    "output_throughput": 7743.590262768078,
    "total_throughput": 16559.20379822006,
    "itl": 109.49272300979393,
    "ttft": 1085866.2638555514,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 59,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19339475935325018,
    "arrivals": 189807,
    "finished_requests": 127671,
    "scheduler_time": 163.64183230681894
}
#Debug simulation 
Total elapsed time: 131.2015659129247. Arrivals time: 0.6556742251850665 Scheduler time: 130.30380096053705 Scheduler overhead time: 0.09492105059325695 Adapter cache time: 0.016651893500238657 Engine time: 0.09761685691773891 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-16/adapters_32_slots_16_rate_3.2-1.6-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-16/adapters_32_slots_16_rate_3.2-1.6-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 66, 66, 17280, 66, 34560, 17280, 66, 66, 66, 34560, 34560, 66, 66, 17280, 17280, 17280, 34560, 34560, 66, 34560, 34560, 34560, 34560, 17280, 66, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 570900 . Total input tokens: 127384163 . Total output tokens: 114175699
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 130.4353354210034,
    "estimated_duration": 3600.016186008129,
    "input_throughput": 8830.672518517453,
    "output_throughput": 7756.443737260727,
    "total_throughput": 16587.11625577818,
    "itl": 109.3279768249972,
    "ttft": 1084078.2437676445,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 52,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.16365452170372016,
    "arrivals": 189807,
    "finished_requests": 127881,
    "scheduler_time": 163.90722298793898
}
#Debug simulation 
Total elapsed time: 130.4355287128128. Arrivals time: 0.666497549507767 Scheduler time: 129.5314683225006 Scheduler overhead time: 0.09494519513100386 Adapter cache time: 0.01688572159036994 Engine time: 0.09342576144263148 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-32/adapters_32_slots_16_rate_3.2-1.6-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-32/adapters_32_slots_16_rate_3.2-1.6-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 66, 66, 17280, 66, 34560, 17280, 66, 66, 66, 34560, 34560, 66, 66, 17280, 17280, 17280, 34560, 34560, 66, 34560, 34560, 34560, 34560, 17280, 66, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 570900 . Total input tokens: 127384163 . Total output tokens: 114175699
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 130.17407663119957,
    "estimated_duration": 3600.028054018016,
    "input_throughput": 8815.611579631644,
    "output_throughput": 7743.588544785404,
    "total_throughput": 16559.20012441705,
    "itl": 109.49263068090595,
    "ttft": 1085865.998839528,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 59,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19616134265437707,
    "arrivals": 189807,
    "finished_requests": 127671,
    "scheduler_time": 163.64176515399043
}
#Debug simulation 
Total elapsed time: 130.17426576511934. Arrivals time: 0.6712755607441068 Scheduler time: 129.25811435747892 Scheduler overhead time: 0.09643240738660097 Adapter cache time: 0.017543203197419643 Engine time: 0.09791856585070491 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-16/adapters_32_slots_16_rate_3.2-1.6-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-16/adapters_32_slots_16_rate_3.2-1.6-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 66, 66, 17280, 66, 34560, 17280, 66, 66, 66, 34560, 34560, 66, 66, 17280, 17280, 17280, 34560, 34560, 66, 34560, 34560, 34560, 34560, 17280, 66, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 570900 . Total input tokens: 127384163 . Total output tokens: 114175699
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 130.32354774698615,
    "estimated_duration": 3600.005354500413,
    "input_throughput": 8830.699087782803,
    "output_throughput": 7756.467074442735,
    "total_throughput": 16587.166162225538,
    "itl": 109.32820828087736,
    "ttft": 1084074.9184247602,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 51,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.15249256504001107,
    "arrivals": 189807,
    "finished_requests": 127881,
    "scheduler_time": 163.90650730990757
}
#Debug simulation 
Total elapsed time: 130.3237425526604. Arrivals time: 0.6240580691955984 Scheduler time: 129.45703406166285 Scheduler overhead time: 0.09637157618999481 Adapter cache time: 0.01674592262133956 Engine time: 0.09659452736377716 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-32/adapters_32_slots_16_rate_3.2-1.6-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-32/adapters_32_slots_16_rate_3.2-1.6-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 66, 66, 17280, 66, 34560, 17280, 66, 66, 66, 34560, 34560, 66, 66, 17280, 17280, 17280, 34560, 34560, 66, 34560, 34560, 34560, 34560, 17280, 66, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 570900 . Total input tokens: 127384163 . Total output tokens: 114175699
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 131.04910554317757,
    "estimated_duration": 3600.025531040038,
    "input_throughput": 8830.64959564767,
    "output_throughput": 7756.423602899567,
    "total_throughput": 16587.073198547238,
    "itl": 109.32840158920477,
    "ttft": 1084079.169621914,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 51,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.17281350996345266,
    "arrivals": 189807,
    "finished_requests": 127881,
    "scheduler_time": 163.90758218213875
}
#Debug simulation 
Total elapsed time: 131.0492928493768. Arrivals time: 0.6539609553292394 Scheduler time: 130.14922053646296 Scheduler overhead time: 0.09810034884139895 Adapter cache time: 0.01708243740722537 Engine time: 0.09781324351206422 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-8/adapters_32_slots_16_rate_3.2-1.6-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-8/adapters_32_slots_16_rate_3.2-1.6-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 33, 33, 17280, 33, 34560, 17280, 33, 33, 33, 34560, 34560, 33, 33, 17280, 17280, 17280, 34560, 34560, 33, 34560, 34560, 34560, 34560, 17280, 33, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 570570 . Total input tokens: 127313451 . Total output tokens: 114108338
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 156.1838133893907,
    "estimated_duration": 3600.0899656922657,
    "input_throughput": 8783.384110213357,
    "output_throughput": 7777.793684835235,
    "total_throughput": 16561.177795048592,
    "itl": 109.78789602679146,
    "ttft": 1092268.825063694,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 48,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.14690341170877208,
    "arrivals": 189688,
    "finished_requests": 127875,
    "scheduler_time": 163.60251885704218
}
#Debug simulation 
Total elapsed time: 156.18398351222277. Arrivals time: 0.6607155739329755 Scheduler time: 155.26707058493048 Scheduler overhead time: 0.10234709130600095 Adapter cache time: 0.018087001517415047 Engine time: 0.10194019041955471 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-16/adapters_32_slots_16_rate_3.2-1.6-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-16/adapters_32_slots_16_rate_3.2-1.6-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 33, 33, 17280, 33, 34560, 17280, 33, 33, 33, 34560, 34560, 33, 33, 17280, 17280, 17280, 34560, 34560, 33, 34560, 34560, 34560, 34560, 17280, 33, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 570570 . Total input tokens: 127313451 . Total output tokens: 114108338
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 155.00059404969215,
    "estimated_duration": 3600.096593489105,
    "input_throughput": 8783.36793995683,
    "output_throughput": 7777.779365875989,
    "total_throughput": 16561.14730583282,
    "itl": 109.78790401946964,
    "ttft": 1092269.6593387066,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 48,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.15741465498227628,
    "arrivals": 189688,
    "finished_requests": 127875,
    "scheduler_time": 163.60317088109824
}
#Debug simulation 
Total elapsed time: 155.0008922717534. Arrivals time: 0.667370489332825 Scheduler time: 154.07970020268112 Scheduler overhead time: 0.10146855562925339 Adapter cache time: 0.0181611655279994 Engine time: 0.1007193666882813 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-32/adapters_32_slots_16_rate_3.2-1.6-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-32/adapters_32_slots_16_rate_3.2-1.6-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 33, 33, 17280, 33, 34560, 17280, 33, 33, 33, 34560, 34560, 33, 33, 17280, 17280, 17280, 34560, 34560, 33, 34560, 34560, 34560, 34560, 17280, 33, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 570570 . Total input tokens: 127313451 . Total output tokens: 114108338
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 155.56630364293233,
    "estimated_duration": 3600.0967302421514,
    "input_throughput": 8783.367606312371,
    "output_throughput": 7777.779070429755,
    "total_throughput": 16561.146676742126,
    "itl": 109.78790973093514,
    "ttft": 1092269.6336972702,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 48,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.15755531955510377,
    "arrivals": 189688,
    "finished_requests": 127875,
    "scheduler_time": 163.60316696957003
}
#Debug simulation 
Total elapsed time: 155.566475125961. Arrivals time: 0.6848170817829669 Scheduler time: 154.62523130746558 Scheduler overhead time: 0.10194055596366525 Adapter cache time: 0.017888723872601986 Engine time: 0.10347437020391226 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-16/adapters_32_slots_16_rate_3.2-1.6-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-16/adapters_32_slots_16_rate_3.2-1.6-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 33, 33, 17280, 33, 34560, 17280, 33, 33, 33, 34560, 34560, 33, 33, 17280, 17280, 17280, 34560, 34560, 33, 34560, 34560, 34560, 34560, 17280, 33, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 570570 . Total input tokens: 127313451 . Total output tokens: 114108338
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 151.7603576038964,
    "estimated_duration": 3600.0902695721024,
    "input_throughput": 8783.383368817134,
    "output_throughput": 7777.793028319842,
    "total_throughput": 16561.176397136976,
    "itl": 109.78755877556277,
    "ttft": 1092268.4515117311,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 48,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.15087712988723076,
    "arrivals": 189688,
    "finished_requests": 127875,
    "scheduler_time": 163.60247824179964
}
#Debug simulation 
Total elapsed time: 151.76054559787735. Arrivals time: 0.6691129757091403 Scheduler time: 150.84492706647143 Scheduler overhead time: 0.09710674453526735 Adapter cache time: 0.01736446376889944 Engine time: 0.0986005449667573 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-32/adapters_32_slots_16_rate_3.2-1.6-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-32/adapters_32_slots_16_rate_3.2-1.6-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 33, 33, 17280, 33, 34560, 17280, 33, 33, 33, 34560, 34560, 33, 33, 17280, 17280, 17280, 34560, 34560, 33, 34560, 34560, 34560, 34560, 17280, 33, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 570570 . Total input tokens: 127313451 . Total output tokens: 114108338
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 153.75814164802432,
    "estimated_duration": 3600.0986114980888,
    "input_throughput": 8783.36301650408,
    "output_throughput": 7777.77500609857,
    "total_throughput": 16561.13802260265,
    "itl": 109.78790044737056,
    "ttft": 1092269.4033073108,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 48,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.15956738013774147,
    "arrivals": 189688,
    "finished_requests": 127875,
    "scheduler_time": 163.60314477693052
}
#Debug simulation 
Total elapsed time: 153.75831633294. Arrivals time: 0.6721112844534218 Scheduler time: 152.8300039526075 Scheduler overhead time: 0.10220021288841963 Adapter cache time: 0.01841543661430478 Engine time: 0.1023063980974257 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-16/adapters_32_slots_16_rate_3.2-1.6-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-16/adapters_32_slots_16_rate_3.2-1.6-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 33, 33, 17280, 33, 34560, 17280, 33, 33, 33, 34560, 34560, 33, 33, 17280, 17280, 17280, 34560, 34560, 33, 34560, 34560, 34560, 34560, 17280, 33, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 570570 . Total input tokens: 127313451 . Total output tokens: 114108338
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 156.3177799792029,
    "estimated_duration": 3600.1039201518797,
    "input_throughput": 8783.350064702017,
    "output_throughput": 7777.763537119983,
    "total_throughput": 16561.113601822,
    "itl": 109.7874636072727,
    "ttft": 1092273.2060837122,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 48,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.14352241415530453,
    "arrivals": 189688,
    "finished_requests": 127875,
    "scheduler_time": 163.6044647641158
}
#Debug simulation 
Total elapsed time: 156.3179592071101. Arrivals time: 0.6752023063600063 Scheduler time: 155.38613404007629 Scheduler overhead time: 0.1019477709196508 Adapter cache time: 0.018057420384138823 Engine time: 0.10254768142476678 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-32/adapters_32_slots_16_rate_3.2-1.6-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-32/adapters_32_slots_16_rate_3.2-1.6-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 33, 33, 17280, 33, 34560, 17280, 33, 33, 33, 34560, 34560, 33, 33, 17280, 17280, 17280, 34560, 34560, 33, 34560, 34560, 34560, 34560, 17280, 33, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 570570 . Total input tokens: 127313451 . Total output tokens: 114108338
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 147.98078768886626,
    "estimated_duration": 3600.1010206532687,
    "input_throughput": 8783.357138756654,
    "output_throughput": 7777.769801281584,
    "total_throughput": 16561.126940038237,
    "itl": 109.78779860783617,
    "ttft": 1092269.9007558862,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 48,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.16183094829320893,
    "arrivals": 189688,
    "finished_requests": 127875,
    "scheduler_time": 163.60322067756314
}
#Debug simulation 
Total elapsed time: 147.98097004601732. Arrivals time: 0.6387252071872354 Scheduler time: 147.09856315422803 Scheduler overhead time: 0.09725025668740273 Adapter cache time: 0.0169993843883276 Engine time: 0.09679119288921356 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-8/adapters_32_slots_16_rate_3.2-0.8-0.4_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-8/adapters_32_slots_16_rate_3.2-0.8-0.4_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 4320, 4320, 8640, 4320, 34560, 8640, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 8640, 8640, 8640, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 8640, 4320, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 518400 . Total input tokens: 115631222 . Total output tokens: 103641843
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 175.2895029420033,
    "estimated_duration": 3600.1184317772586,
    "input_throughput": 8679.069200669337,
    "output_throughput": 7706.156762821874,
    "total_throughput": 16385.22596349121,
    "itl": 110.73181989708006,
    "ttft": 984536.4909489285,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 33,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10099609554978084,
    "arrivals": 172540,
    "finished_requests": 126482,
    "scheduler_time": 156.15253897597574
}
#Debug simulation 
Total elapsed time: 175.2896846900694. Arrivals time: 0.6951960609294474 Scheduler time: 174.32651066686958 Scheduler overhead time: 0.10638270014896989 Adapter cache time: 0.018900289200246334 Engine time: 0.10764115303754807 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-16/adapters_32_slots_16_rate_3.2-0.8-0.4_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-16/adapters_32_slots_16_rate_3.2-0.8-0.4_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 4320, 4320, 8640, 4320, 34560, 8640, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 8640, 8640, 8640, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 8640, 4320, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 518400 . Total input tokens: 115631222 . Total output tokens: 103641843
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 174.3568909568712,
    "estimated_duration": 3600.124877796816,
    "input_throughput": 8679.053660805665,
    "output_throughput": 7706.14296495683,
    "total_throughput": 16385.196625762495,
    "itl": 110.7316254929793,
    "ttft": 984537.6168237709,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 33,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10766075673745945,
    "arrivals": 172540,
    "finished_requests": 126482,
    "scheduler_time": 156.15284686420082
}
#Debug simulation 
Total elapsed time: 174.35717720305547. Arrivals time: 0.6989306220784783 Scheduler time: 173.3916930705309 Scheduler overhead time: 0.1063720528036356 Adapter cache time: 0.018936428241431713 Engine time: 0.10611894959583879 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-32/adapters_32_slots_16_rate_3.2-0.8-0.4_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-32/adapters_32_slots_16_rate_3.2-0.8-0.4_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 4320, 4320, 8640, 4320, 34560, 8640, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 8640, 8640, 8640, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 8640, 4320, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 518400 . Total input tokens: 115631222 . Total output tokens: 103641843
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 175.46076199878007,
    "estimated_duration": 3600.001476776147,
    "input_throughput": 8679.16116189495,
    "output_throughput": 7706.279894319353,
    "total_throughput": 16385.441056214302,
    "itl": 110.73144951918323,
    "ttft": 984478.2767288983,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 33,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10785556688904761,
    "arrivals": 172540,
    "finished_requests": 126479,
    "scheduler_time": 156.14688772100993
}
#Debug simulation 
Total elapsed time: 175.46094335010275. Arrivals time: 0.6849169009365141 Scheduler time: 174.50486593600363 Scheduler overhead time: 0.11037197895348072 Adapter cache time: 0.01893901778385043 Engine time: 0.10669646551832557 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-16-16/adapters_32_slots_16_rate_3.2-0.8-0.4_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-16-16/adapters_32_slots_16_rate_3.2-0.8-0.4_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 4320, 4320, 8640, 4320, 34560, 8640, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 8640, 8640, 8640, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 8640, 4320, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 518400 . Total input tokens: 115631222 . Total output tokens: 103641843
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 169.7938660220243,
    "estimated_duration": 3600.120273320539,
    "input_throughput": 8679.064761128335,
    "output_throughput": 7706.152820947678,
    "total_throughput": 16385.217582076013,
    "itl": 110.73170235635125,
    "ttft": 984537.1437832603,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 33,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10316620823461564,
    "arrivals": 172540,
    "finished_requests": 126482,
    "scheduler_time": 156.15262546465823
}
#Debug simulation 
Total elapsed time: 169.79404917685315. Arrivals time: 0.6841109157539904 Scheduler time: 168.85183049133047 Scheduler overhead time: 0.10318647092208266 Adapter cache time: 0.017575456760823727 Engine time: 0.10408552549779415 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-16-32/adapters_32_slots_16_rate_3.2-0.8-0.4_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-16-32/adapters_32_slots_16_rate_3.2-0.8-0.4_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 4320, 4320, 8640, 4320, 34560, 8640, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 8640, 8640, 8640, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 8640, 4320, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 518400 . Total input tokens: 115631222 . Total output tokens: 103641843
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 173.1142959096469,
    "estimated_duration": 3600.126143608302,
    "input_throughput": 8679.0506092332,
    "output_throughput": 7706.140255461693,
    "total_throughput": 16385.190864694894,
    "itl": 110.7315701839412,
    "ttft": 984537.743616177,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 33,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10923885853961107,
    "arrivals": 172540,
    "finished_requests": 126482,
    "scheduler_time": 156.15283468962852
}
#Debug simulation 
Total elapsed time: 173.11446442687884. Arrivals time: 0.6981743448413908 Scheduler time: 172.1482471586205 Scheduler overhead time: 0.10707835992798209 Adapter cache time: 0.01868244679644704 Engine time: 0.10764892864972353 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_16-16-16/adapters_32_slots_16_rate_3.2-0.8-0.4_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_16-16-16/adapters_32_slots_16_rate_3.2-0.8-0.4_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 4320, 4320, 8640, 4320, 34560, 8640, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 8640, 8640, 8640, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 8640, 4320, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 518400 . Total input tokens: 115631222 . Total output tokens: 103641843
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 174.06308737862855,
    "estimated_duration": 3600.0766875281283,
    "input_throughput": 8679.965931907902,
    "output_throughput": 7707.174987722594,
    "total_throughput": 16387.140919630496,
    "itl": 110.71245592509804,
    "ttft": 984627.1959564745,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 33,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09867165973177183,
    "arrivals": 172540,
    "finished_requests": 126500,
    "scheduler_time": 156.17963488412278
}
#Debug simulation 
Total elapsed time: 174.06326289195567. Arrivals time: 0.683941688388586 Scheduler time: 173.0976311811246 Scheduler overhead time: 0.10699734790250659 Adapter cache time: 0.017949254252016544 Engine time: 0.10809268150478601 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_16-16-32/adapters_32_slots_16_rate_3.2-0.8-0.4_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_16-16-32/adapters_32_slots_16_rate_3.2-0.8-0.4_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 4320, 4320, 8640, 4320, 34560, 8640, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 8640, 8640, 8640, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 8640, 4320, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 518400 . Total input tokens: 115631222 . Total output tokens: 103641843
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 167.09646383626387,
    "estimated_duration": 3600.0024027129025,
    "input_throughput": 8679.158929575793,
    "output_throughput": 7706.27791222962,
    "total_throughput": 16385.436841805415,
    "itl": 110.73192049460008,
    "ttft": 984479.2784440143,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 33,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.11062215019017455,
    "arrivals": 172540,
    "finished_requests": 126479,
    "scheduler_time": 156.14694862416633
}
#Debug simulation 
Total elapsed time: 167.0966298081912. Arrivals time: 0.595796128269285 Scheduler time: 166.2681504576467 Scheduler overhead time: 0.09327969886362553 Adapter cache time: 0.015474660787731409 Engine time: 0.09253529412671924 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-8/adapters_32_slots_16_rate_3.2-0.8-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-8/adapters_32_slots_16_rate_3.2-0.8-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 1080, 1080, 8640, 1080, 34560, 8640, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 8640, 8640, 8640, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 8640, 1080, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 486000 . Total input tokens: 108390605 . Total output tokens: 97143304
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 149.50963862566277,
    "estimated_duration": 3600.0866133872705,
    "input_throughput": 8721.096010092737,
    "output_throughput": 7735.524722222637,
    "total_throughput": 16456.620732315376,
    "itl": 110.79367208136856,
    "ttft": 746362.5755850568,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 17,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05202829164685682,
    "arrivals": 161835,
    "finished_requests": 127012,
    "scheduler_time": 149.47896578991708
}
#Debug simulation 
Total elapsed time: 149.50982442684472. Arrivals time: 0.6117375935427845 Scheduler time: 148.6600912148133 Scheduler overhead time: 0.09534270502626896 Adapter cache time: 0.01560185058042407 Engine time: 0.09461119724437594 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-16/adapters_32_slots_16_rate_3.2-0.8-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-16/adapters_32_slots_16_rate_3.2-0.8-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 1080, 1080, 8640, 1080, 34560, 8640, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 8640, 8640, 8640, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 8640, 1080, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 486000 . Total input tokens: 108390605 . Total output tokens: 97143304
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 147.21157108899206,
    "estimated_duration": 3600.1117790850826,
    "input_throughput": 8721.035325180661,
    "output_throughput": 7735.530369303525,
    "total_throughput": 16456.565694484187,
    "itl": 110.7936662917031,
    "ttft": 746396.6020788973,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 17,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.056551189471501846,
    "arrivals": 161835,
    "finished_requests": 127013,
    "scheduler_time": 149.48020763851136
}
#Debug simulation 
Total elapsed time: 147.2118195667863. Arrivals time: 0.5907970033586025 Scheduler time: 146.3808823567815 Scheduler overhead time: 0.09552285959944129 Adapter cache time: 0.015431294217705727 Engine time: 0.09686577739194036 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-32/adapters_32_slots_16_rate_3.2-0.8-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-32/adapters_32_slots_16_rate_3.2-0.8-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 1080, 1080, 8640, 1080, 34560, 8640, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 8640, 8640, 8640, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 8640, 1080, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 486000 . Total input tokens: 108390605 . Total output tokens: 97143304
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 146.80817783111706,
    "estimated_duration": 3600.110776420658,
    "input_throughput": 8721.037754070328,
    "output_throughput": 7735.532523720872,
    "total_throughput": 16456.5702777912,
    "itl": 110.79369131364047,
    "ttft": 746396.0148591497,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 17,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.0564612853527069,
    "arrivals": 161835,
    "finished_requests": 127013,
    "scheduler_time": 149.4800951868495
}
#Debug simulation 
Total elapsed time: 146.8083599372767. Arrivals time: 0.6095842970535159 Scheduler time: 145.96158516127616 Scheduler overhead time: 0.09459502203390002 Adapter cache time: 0.015334742609411478 Engine time: 0.09508614800870419 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-16-16/adapters_32_slots_16_rate_3.2-0.8-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-16-16/adapters_32_slots_16_rate_3.2-0.8-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 1080, 1080, 8640, 1080, 34560, 8640, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 8640, 8640, 8640, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 8640, 1080, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 486000 . Total input tokens: 108390605 . Total output tokens: 97143304
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 148.2391562918201,
    "estimated_duration": 3600.090998895766,
    "input_throughput": 8721.085386349989,
    "output_throughput": 7735.515299069334,
    "total_throughput": 16456.600685419322,
    "itl": 110.79342474685639,
    "ttft": 746363.29645872,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 17,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05409961756085976,
    "arrivals": 161835,
    "finished_requests": 127012,
    "scheduler_time": 149.4791807956179
}
#Debug simulation 
Total elapsed time: 148.23933483287692. Arrivals time: 0.6147562633268535 Scheduler time: 147.38727934798226 Scheduler overhead time: 0.0965125747025013 Adapter cache time: 0.015250006224960089 Engine time: 0.09392380015924573 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-16-32/adapters_32_slots_16_rate_3.2-0.8-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-16-32/adapters_32_slots_16_rate_3.2-0.8-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 1080, 1080, 8640, 1080, 34560, 8640, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 8640, 8640, 8640, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 8640, 1080, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 486000 . Total input tokens: 108390605 . Total output tokens: 97143304
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 147.44125544512644,
    "estimated_duration": 3600.112244364614,
    "input_throughput": 8721.034198071573,
    "output_throughput": 7735.529369561378,
    "total_throughput": 16456.56356763295,
    "itl": 110.79356587422822,
    "ttft": 746396.8541809388,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 17,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05721580807119607,
    "arrivals": 161835,
    "finished_requests": 127013,
    "scheduler_time": 149.48021572648517
}
#Debug simulation 
Total elapsed time: 147.44142442103475. Arrivals time: 0.6155512062832713 Scheduler time: 146.5826011430472 Scheduler overhead time: 0.09815055504441261 Adapter cache time: 0.015680665615946054 Engine time: 0.09666991839185357 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_16-16-16/adapters_32_slots_16_rate_3.2-0.8-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_16-16-16/adapters_32_slots_16_rate_3.2-0.8-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 1080, 1080, 8640, 1080, 34560, 8640, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 8640, 8640, 8640, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 8640, 1080, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 486000 . Total input tokens: 108390605 . Total output tokens: 97143304
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 143.32772356411442,
    "estimated_duration": 3600.080195887803,
    "input_throughput": 8721.111278538441,
    "output_throughput": 7735.38879267452,
    "total_throughput": 16456.500071212962,
    "itl": 110.79364074985212,
    "ttft": 746383.5987430009,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 17,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05083085501333698,
    "arrivals": 161835,
    "finished_requests": 127011,
    "scheduler_time": 149.47862386655524
}
#Debug simulation 
Total elapsed time: 143.32789824018255. Arrivals time: 0.591558092739433 Scheduler time: 142.50050655659288 Scheduler overhead time: 0.09446787042543292 Adapter cache time: 0.015483214985579252 Engine time: 0.09381049498915672 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_16-16-32/adapters_32_slots_16_rate_3.2-0.8-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_16-16-32/adapters_32_slots_16_rate_3.2-0.8-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 1080, 1080, 8640, 1080, 34560, 8640, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 8640, 8640, 8640, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 8640, 1080, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 486000 . Total input tokens: 108390605 . Total output tokens: 97143304
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 147.47570502804592,
    "estimated_duration": 3600.116076768261,
    "input_throughput": 8721.024914336673,
    "output_throughput": 7735.52113491829,
    "total_throughput": 16456.546049254965,
    "itl": 110.79347024546207,
    "ttft": 746397.2996885752,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 17,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05822183836251497,
    "arrivals": 161835,
    "finished_requests": 127013,
    "scheduler_time": 149.48041748182428
}
#Debug simulation 
Total elapsed time: 147.47585322987288. Arrivals time: 0.6189571972936392 Scheduler time: 146.61129125813022 Scheduler overhead time: 0.09841017844155431 Adapter cache time: 0.018849619664251804 Engine time: 0.09573343675583601 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-8/adapters_32_slots_16_rate_3.2-0.8-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-8/adapters_32_slots_16_rate_3.2-0.8-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 540, 540, 8640, 540, 34560, 8640, 540, 540, 540, 34560, 34560, 540, 540, 8640, 8640, 8640, 34560, 34560, 540, 34560, 34560, 34560, 34560, 8640, 540, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 480600 . Total input tokens: 107195754 . Total output tokens: 96078594
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 188.89563139807433,
    "estimated_duration": 3600.050059178745,
    "input_throughput": 8759.306254534034,
    "output_throughput": 7707.088663741938,
    "total_throughput": 16466.39491827597,
    "itl": 109.55929256324312,
    "ttft": 773248.0697875451,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 33,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10099609554978084,
    "arrivals": 160041,
    "finished_requests": 126912,
    "scheduler_time": 148.33378107778623
}
#Debug simulation 
Total elapsed time: 188.895764966961. Arrivals time: 0.6283276644535363 Scheduler time: 188.0031051686965 Scheduler overhead time: 0.10536819836124778 Adapter cache time: 0.019456527661532164 Engine time: 0.10495236655697227 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-16/adapters_32_slots_16_rate_3.2-0.8-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-16/adapters_32_slots_16_rate_3.2-0.8-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 540, 540, 8640, 540, 34560, 8640, 540, 540, 540, 34560, 34560, 540, 540, 8640, 8640, 8640, 34560, 34560, 540, 34560, 34560, 34560, 34560, 8640, 540, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 480600 . Total input tokens: 107195754 . Total output tokens: 96078594
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 180.9765132847242,
    "estimated_duration": 3600.119862762238,
    "input_throughput": 8758.736987108614,
    "output_throughput": 7707.035614839594,
    "total_throughput": 16465.772601948207,
    "itl": 109.55563691645482,
    "ttft": 773809.3318102611,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 35,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.11445804796414451,
    "arrivals": 160041,
    "finished_requests": 126909,
    "scheduler_time": 148.33760113361825
}
#Debug simulation 
Total elapsed time: 180.97668280871585. Arrivals time: 0.6241511502303183 Scheduler time: 180.09988425206393 Scheduler overhead time: 0.1014647213742137 Adapter cache time: 0.018369579687714577 Engine time: 0.09978100750595331 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-32/adapters_32_slots_16_rate_3.2-0.8-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-32/adapters_32_slots_16_rate_3.2-0.8-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 540, 540, 8640, 540, 34560, 8640, 540, 540, 540, 34560, 34560, 540, 540, 8640, 8640, 8640, 34560, 34560, 540, 34560, 34560, 34560, 34560, 8640, 540, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 480600 . Total input tokens: 107195754 . Total output tokens: 96078594
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 180.0270061637275,
    "estimated_duration": 3600.120123568948,
    "input_throughput": 8758.736352591624,
    "output_throughput": 7707.035056511945,
    "total_throughput": 16465.77140910357,
    "itl": 109.5556513031317,
    "ttft": 773809.3230098189,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 35,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.11461709957569838,
    "arrivals": 160041,
    "finished_requests": 126909,
    "scheduler_time": 148.33760285013565
}
#Debug simulation 
Total elapsed time: 180.027134783566. Arrivals time: 0.6017140564508736 Scheduler time: 179.16958747664467 Scheduler overhead time: 0.10205259220674634 Adapter cache time: 0.019778713583946228 Engine time: 0.10050077829509974 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-16-16/adapters_32_slots_16_rate_3.2-0.8-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-16-16/adapters_32_slots_16_rate_3.2-0.8-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 540, 540, 8640, 540, 34560, 8640, 540, 540, 540, 34560, 34560, 540, 540, 8640, 8640, 8640, 34560, 34560, 540, 34560, 34560, 34560, 34560, 8640, 540, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 480600 . Total input tokens: 107195754 . Total output tokens: 96078594
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 186.80114047741517,
    "estimated_duration": 3600.0547912090497,
    "input_throughput": 8759.294741014088,
    "output_throughput": 7707.0785332913665,
    "total_throughput": 16466.373274305453,
    "itl": 109.55957202970052,
    "ttft": 773246.5986002065,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 33,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10275761291617531,
    "arrivals": 160041,
    "finished_requests": 126912,
    "scheduler_time": 148.33415303758858
}
#Debug simulation 
Total elapsed time: 186.80126894731075. Arrivals time: 0.6019834564067423 Scheduler time: 185.9443863965571 Scheduler overhead time: 0.10131327621638775 Adapter cache time: 0.019430941436439753 Engine time: 0.10083943931385875 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-16-32/adapters_32_slots_16_rate_3.2-0.8-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-16-32/adapters_32_slots_16_rate_3.2-0.8-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 540, 540, 8640, 540, 34560, 8640, 540, 540, 540, 34560, 34560, 540, 540, 8640, 8640, 8640, 34560, 34560, 540, 34560, 34560, 34560, 34560, 8640, 540, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 480600 . Total input tokens: 107195754 . Total output tokens: 96078594
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 184.53563545597717,
    "estimated_duration": 3600.1195271980646,
    "input_throughput": 8758.737803503269,
    "output_throughput": 7707.036333206031,
    "total_throughput": 16465.7741367093,
    "itl": 109.55546164415952,
    "ttft": 773808.7140713584,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 35,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.1161261450126767,
    "arrivals": 160041,
    "finished_requests": 126909,
    "scheduler_time": 148.33749820541016
}
#Debug simulation 
Total elapsed time: 184.53575713699684. Arrivals time: 0.6161818807013333 Scheduler time: 183.66321479855105 Scheduler overhead time: 0.1030679577961564 Adapter cache time: 0.019550663884729147 Engine time: 0.09987967507913709 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_16-16-16/adapters_32_slots_16_rate_3.2-0.8-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_16-16-16/adapters_32_slots_16_rate_3.2-0.8-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 540, 540, 8640, 540, 34560, 8640, 540, 540, 540, 34560, 34560, 540, 540, 8640, 8640, 8640, 34560, 34560, 540, 34560, 34560, 34560, 34560, 8640, 540, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 480600 . Total input tokens: 107195754 . Total output tokens: 96078594
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 185.5806218329817,
    "estimated_duration": 3600.0457556879164,
    "input_throughput": 8759.31672539932,
    "output_throughput": 7707.097876787447,
    "total_throughput": 16466.414602186767,
    "itl": 109.55925107744446,
    "ttft": 773245.781787454,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 33,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09867165973177183,
    "arrivals": 160041,
    "finished_requests": 126912,
    "scheduler_time": 148.33330096814012
}
#Debug simulation 
Total elapsed time: 185.58075854321942. Arrivals time: 0.6159109738655388 Scheduler time: 184.70662416145205 Scheduler overhead time: 0.10374213475733995 Adapter cache time: 0.01917150430381298 Engine time: 0.10219758003950119 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_16-16-32/adapters_32_slots_16_rate_3.2-0.8-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_16-16-32/adapters_32_slots_16_rate_3.2-0.8-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 540, 540, 8640, 540, 34560, 8640, 540, 540, 540, 34560, 34560, 540, 540, 8640, 8640, 8640, 34560, 34560, 540, 34560, 34560, 34560, 34560, 8640, 540, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 480600 . Total input tokens: 107195754 . Total output tokens: 96078594
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 183.71180910477415,
    "estimated_duration": 3600.1202395682617,
    "input_throughput": 8758.736070376772,
    "output_throughput": 7707.034808183913,
    "total_throughput": 16465.770878560685,
    "itl": 109.55530737328183,
    "ttft": 773808.9840679871,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 35,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.11763519044965502,
    "arrivals": 160041,
    "finished_requests": 126909,
    "scheduler_time": 148.33750347212225
}
#Debug simulation 
Total elapsed time: 183.71194018190727. Arrivals time: 0.624832640402019 Scheduler time: 182.83308463636786 Scheduler overhead time: 0.10217336751520634 Adapter cache time: 0.018494604155421257 Engine time: 0.09979980951175094 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-8/adapters_32_slots_16_rate_3.2-0.8-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-8/adapters_32_slots_16_rate_3.2-0.8-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 270, 270, 8640, 270, 34560, 8640, 270, 270, 270, 34560, 34560, 270, 270, 8640, 8640, 8640, 34560, 34560, 270, 34560, 34560, 34560, 34560, 8640, 270, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 477900 . Total input tokens: 106601693 . Total output tokens: 95531295
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 125.91525319591165,
    "estimated_duration": 3600.0550635798854,
    "input_throughput": 8720.632725206468,
    "output_throughput": 7744.129327921141,
    "total_throughput": 16464.762053127608,
    "itl": 111.0785491830551,
    "ttft": 751076.8511329155,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 159140,
    "finished_requests": 126554,
    "scheduler_time": 147.5297869209934
}
#Debug simulation 
Total elapsed time: 125.91540603758767. Arrivals time: 0.6059567416086793 Scheduler time: 125.07146224891767 Scheduler overhead time: 0.09524069912731647 Adapter cache time: 0.0171620175242424 Engine time: 0.0944245127029717 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-16/adapters_32_slots_16_rate_3.2-0.8-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-16/adapters_32_slots_16_rate_3.2-0.8-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 270, 270, 8640, 270, 34560, 8640, 270, 270, 270, 34560, 34560, 270, 270, 8640, 8640, 8640, 34560, 34560, 270, 34560, 34560, 34560, 34560, 8640, 270, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 477900 . Total input tokens: 106601693 . Total output tokens: 95531295
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 126.68746314104646,
    "estimated_duration": 3600.0764542073607,
    "input_throughput": 8720.580909694118,
    "output_throughput": 7744.083314513459,
    "total_throughput": 16464.664224207576,
    "itl": 111.07842063463578,
    "ttft": 751097.3974581107,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.053152543858159325,
    "arrivals": 159140,
    "finished_requests": 126554,
    "scheduler_time": 147.53101453790816
}
#Debug simulation 
Total elapsed time: 126.68767076684162. Arrivals time: 0.6034749718382955 Scheduler time: 125.84886416466907 Scheduler overhead time: 0.09234980028122663 Adapter cache time: 0.017717243637889624 Engine time: 0.09401943348348141 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-32/adapters_32_slots_16_rate_3.2-0.8-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-32/adapters_32_slots_16_rate_3.2-0.8-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 270, 270, 8640, 270, 34560, 8640, 270, 270, 270, 34560, 34560, 270, 270, 8640, 8640, 8640, 34560, 34560, 270, 34560, 34560, 34560, 34560, 8640, 270, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 477900 . Total input tokens: 106601693 . Total output tokens: 95531295
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 126.48850804194808,
    "estimated_duration": 3600.0762698104095,
    "input_throughput": 8720.581356364803,
    "output_throughput": 7744.083711167654,
    "total_throughput": 16464.665067532456,
    "itl": 111.07842559427672,
    "ttft": 751097.3258101236,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05308051900938152,
    "arrivals": 159140,
    "finished_requests": 126554,
    "scheduler_time": 147.53100220438557
}
#Debug simulation 
Total elapsed time: 126.48865356808528. Arrivals time: 0.6049903612583876 Scheduler time: 125.64674063725397 Scheduler overhead time: 0.09275642689317465 Adapter cache time: 0.01778072537854314 Engine time: 0.09418571647256613 
